{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# set seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import utils as ut\n",
    "import experiment as exp\n",
    "from evaluation import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import random\n",
    "#define fixed_hyperparams and create a config gen\n",
    "from configurations import RandomConfigGen, Configuration\n",
    "from torch import nn\n",
    "from deep_net import RandomNet\n",
    "from experiment import run_experiment\n",
    "import regex as re\n",
    "from pathlib import *\n",
    "from plot import *\n",
    "from sk_models import setup_pls_models_slim\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "random_state = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory is D:\\workspace\\lazydeep\\experiments\\1.02\\mango_684_990\n"
     ]
    }
   ],
   "source": [
    "#setup input and outpu t formats, load data\n",
    "\n",
    "#we need to set parametesr\n",
    "file_name = \"mango_684_990.csv\"#fitlered=513-1050 #\"mango_684_990.csv\" #\"mango_729_975.csv\" \n",
    "n_components = 59\n",
    "id_cols =['Set','Season','Region','Date','Type','Cultivar','Pop','Temp',\"FruitID\"]#\n",
    "output_cols = ['DM']\n",
    "\n",
    "data_path = Path('D:/workspace/lazydeep/data/soil_data/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/1.02\") #1.01/\")\n",
    "model_path = Path(\"D:/workspace/lazydeep/experiments/1.01\") #1.01/\")\n",
    "if not log_path.exists():\n",
    "    log_path.mkdir()\n",
    "\n",
    "data_file = data_path / file_name\n",
    "log_dir = log_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "model_dir = model_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "print(f\"Output directory is {log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% load data\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is (11691, 113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "nrow, ncol = data.shape\n",
    "n_features = ncol - 1-len(id_cols)\n",
    "n_comps = [i for i in range(1,min(101,n_features))]\n",
    "data = ut.sample_data(data,random_state)\n",
    "dataset = ut.TabularDataset(data,id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "eval = MangoesSplitter(preprocessing=None,tensorboard=None,time=True,random_state=random_state)\n",
    "print(f\"Dataset shape is {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% load models\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 models\n"
     ]
    }
   ],
   "source": [
    "n_models = 100\n",
    "model_names = [f\"random_{i}\" for i in range(0,n_models)]\n",
    "deep_models = {name:torch.load(model_dir/\"models\"/name/\"_model\") for name in model_names}\n",
    "#for each model, load state\n",
    "print(f\"Loaded {len(deep_models)} models\")\n",
    "#print(deep_models)\n",
    "for name in model_names:\n",
    "    sub_path = log_dir / name\n",
    "    if not sub_path.exists():\n",
    "        sub_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup logging and tensorboard outputs\n"
    }
   },
   "outputs": [],
   "source": [
    "# set logging, in this case the root logger\n",
    "ut.setup_logger(logger_name=\"\",file_name=log_dir/\"log.txt\")\n",
    "ut.setup_logger(logger_name=\"summary\",file_name=log_dir/\"summary.txt\")\n",
    "summary_logger = logging.getLogger(\"summary\")\n",
    "tb = SummaryWriter(log_dir/\"tb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup experiment\n"
    }
   },
   "outputs": [],
   "source": [
    "fixed_hyperparams = {'bs': 32,'loss': nn.MSELoss(),'epochs': 100}\n",
    "preprocessing = Preprocess_PLS(n_components=n_components)\n",
    "eval = CrossValEvaluation(preprocessing=preprocessing,tensorboard=None,time=True)\n",
    "scores={} #->model->knn:{fold_0:number,...,fold_n:number,mean:number,median:number\n",
    "preds={} #model-> foldsxknn_models\n",
    "deep_scores_dict={}\n",
    "deep_preds_dict={}\n",
    "actual_y = None\n",
    "\n",
    "device = \"cpu\" #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_fun_cv = lambda name,model, fold : model.load_state(model_dir/\"models\"/name/f\"_fold_{fold}\")\n",
    "load_fun_build = lambda name,model : model.load_state(model_dir/\"models\"/name/f\"_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% deep experiment\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Tested (test) on 1949 instances with mean losses of: random_0:1.8087,random_1:1.8726,random_2:1.5135,random_3:261.2037,random_4:1.7238,random_5:1.6729,random_6:268.1199,random_7:1.3661,random_8:2.198,random_9:2.6786,random_10:1.6515,random_11:1.6705,random_12:1.4557,random_13:1.7706,random_14:6.3774,random_15:1.9348,random_16:1.6065,random_17:2.5205,random_18:1.5721,random_19:1.4255,random_20:1.6257,random_21:1.6515,random_22:1.615,random_23:2.0131,random_24:1.6973,random_25:1.6275,random_26:1.7241,random_27:1.8813,random_28:2.0463,random_29:1.6978,random_30:1.4468,random_31:1.7168,random_32:1.526,random_33:270.1994,random_34:1.3661,random_35:1.4317,random_36:1.845,random_37:2.2843,random_38:6.3871,random_39:1.5425,random_40:1.7943,random_41:1.8847,random_42:2.0035,random_43:1.5724,random_44:1.5696,random_45:276.5443,random_46:2.0542,random_47:6.1866,random_48:1.6921,random_49:1.6176,random_50:1.5984,random_51:1.598,random_52:1.5515,random_53:1.4664,random_54:2.1507,random_55:269.7294,random_56:1.4993,random_57:1.5163,random_58:6.3926,random_59:1.5222,random_60:1.5749,random_61:1.848,random_62:1.7701,random_63:1.428,random_64:1.5614,random_65:1.664,random_66:1.6831,random_67:6.3878,random_68:1.8904,random_69:1.3935,random_70:1.5222,random_71:269.5717,random_72:1.5644,random_73:2.0413,random_74:2.0141,random_75:1.9429,random_76:1.532,random_77:1.6053,random_78:1.6326,random_79:1.5248,random_80:1.853,random_81:1.3518,random_82:1.5806,random_83:10.725,random_84:1.9432,random_85:1.5726,random_86:6.3866,random_87:5.3306,random_88:1.7715,random_89:260.8699,random_90:266.7985,random_91:1.665,random_92:2.4774,random_93:1.5242,random_94:1.7157,random_95:1.5478,random_96:1.4144,random_97:1.5531,random_98:1.7974,random_99:1.7772'\n",
      "Testing (test) took 0:00:03.257729'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Tested (test) on 1949 instances with mean losses of: random_0:0.8529,random_1:0.814,random_2:0.8052,random_3:261.2597,random_4:0.7713,random_5:0.6948,random_6:268.3263,random_7:0.7241,random_8:0.7449,random_9:0.8251,random_10:1.0465,random_11:0.737,random_12:0.8367,random_13:0.8479,random_14:6.0919,random_15:0.8139,random_16:0.8399,random_17:0.7437,random_18:0.7829,random_19:0.8695,random_20:0.8019,random_21:0.7336,random_22:1.1822,random_23:0.8423,random_24:0.7429,random_25:0.7237,random_26:0.6955,random_27:0.7542,random_28:0.8896,random_29:0.6981,random_30:0.8744,random_31:0.8704,random_32:0.7063,random_33:270.3703,random_34:0.8621,random_35:0.9171,random_36:0.8007,random_37:1.0231,random_38:0.7224,random_39:0.6825,random_40:0.7132,random_41:0.7965,random_42:0.7164,random_43:0.777,random_44:0.7679,random_45:0.8303,random_46:0.8016,random_47:6.1031,random_48:0.7034,random_49:0.9093,random_50:0.7709,random_51:0.818,random_52:0.8533,random_53:0.8216,random_54:0.8194,random_55:269.9019,random_56:0.7728,random_57:0.8388,random_58:3.146,random_59:0.6904,random_60:0.7806,random_61:0.8804,random_62:0.7798,random_63:0.7891,random_64:0.7269,random_65:0.8243,random_66:0.7449,random_67:0.8052,random_68:0.8301,random_69:0.7006,random_70:0.8061,random_71:0.8417,random_72:0.7789,random_73:0.8358,random_74:0.7633,random_75:0.7599,random_76:0.8261,random_77:0.6995,random_78:0.7786,random_79:0.9384,random_80:0.8085,random_81:0.9121,random_82:0.6752,random_83:3.6135,random_84:0.77,random_85:0.6781,random_86:6.103,random_87:3.9581,random_88:0.8613,random_89:261.0962,random_90:6.0919,random_91:0.7806,random_92:0.7852,random_93:0.685,random_94:0.7902,random_95:0.7811,random_96:0.7907,random_97:0.7047,random_98:0.8938,random_99:0.8493'\n",
      "Testing (test) took 0:00:03.115882'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Tested (test) on 1948 instances with mean losses of: random_0:1.378,random_1:1.8396,random_2:1.7537,random_3:1.7504,random_4:1.3726,random_5:1.8988,random_6:269.0526,random_7:2.0701,random_8:1.9301,random_9:1.6392,random_10:1.6289,random_11:1.6813,random_12:1.804,random_13:1.667,random_14:6.1627,random_15:1.618,random_16:1.6202,random_17:1.7921,random_18:1.4222,random_19:1.6293,random_20:1.4047,random_21:2.6643,random_22:1.6755,random_23:1.9326,random_24:1.6572,random_25:1.6263,random_26:1.6578,random_27:1.7569,random_28:1.622,random_29:1.4493,random_30:1.4931,random_31:2.1067,random_32:1.7146,random_33:271.1009,random_34:1.928,random_35:6.1627,random_36:1.4799,random_37:1.6236,random_38:6.1623,random_39:1.7879,random_40:1.8012,random_41:1.7294,random_42:2.0844,random_43:1.6269,random_44:1.6143,random_45:277.4389,random_46:1.8983,random_47:6.5491,random_48:1.9733,random_49:1.4438,random_50:1.6269,random_51:1.4889,random_52:1.5001,random_53:1.5321,random_54:1.8747,random_55:270.6016,random_56:1.5872,random_57:1.5396,random_58:1.4891,random_59:1.6495,random_60:1.4672,random_61:1.583,random_62:1.8809,random_63:1.4999,random_64:1.4919,random_65:1.6488,random_66:1.7004,random_67:2.1365,random_68:1.9839,random_69:1.9668,random_70:1.5467,random_71:1.4173,random_72:1.7233,random_73:1.4152,random_74:2.0853,random_75:1.8867,random_76:1.5353,random_77:2.0845,random_78:1.5524,random_79:1.6252,random_80:2.3437,random_81:1.5709,random_82:2.1372,random_83:1.9313,random_84:1.9906,random_85:1.923,random_86:6.1623,random_87:5.1534,random_88:1.8927,random_89:261.8014,random_90:267.476,random_91:1.8622,random_92:6.5385,random_93:1.7597,random_94:2.187,random_95:1.7138,random_96:2.4145,random_97:1.6213,random_98:1.5417,random_99:1.8116'\n",
      "Testing (test) took 0:00:03.117552'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Tested (test) on 1948 instances with mean losses of: random_0:2.2616,random_1:5.2059,random_2:4.8699,random_3:4.5507,random_4:2.9546,random_5:4.5785,random_6:272.081,random_7:2.123,random_8:3.4439,random_9:2.6573,random_10:3.0175,random_11:2.7815,random_12:3.6153,random_13:2.968,random_14:5.863,random_15:2.645,random_16:2.9857,random_17:2.6605,random_18:2.9178,random_19:2.5954,random_20:3.8274,random_21:5.6379,random_22:2.8286,random_23:3.4274,random_24:3.0747,random_25:3.2278,random_26:4.2853,random_27:4.5951,random_28:3.1982,random_29:3.3187,random_30:2.2232,random_31:3.1943,random_32:1.969,random_33:274.1765,random_34:3.1066,random_35:4.1416,random_36:2.3319,random_37:4.2822,random_38:4.2536,random_39:3.2914,random_40:4.2877,random_41:3.8117,random_42:3.5316,random_43:3.6713,random_44:2.6831,random_45:280.597,random_46:2.9624,random_47:5.8241,random_48:3.1728,random_49:4.3677,random_50:3.4901,random_51:3.423,random_52:2.9278,random_53:2.4892,random_54:2.7715,random_55:273.7155,random_56:2.8518,random_57:2.6957,random_58:143.4108,random_59:4.7333,random_60:3.0696,random_61:3.2624,random_62:277.5367,random_63:3.3044,random_64:3.1045,random_65:3.8137,random_66:3.7503,random_67:4.7428,random_68:4.0007,random_69:3.7027,random_70:3.0443,random_71:273.3336,random_72:2.9983,random_73:5.8629,random_74:2.9481,random_75:3.7253,random_76:3.3773,random_77:4.5363,random_78:2.864,random_79:3.0554,random_80:2.3767,random_81:3.3366,random_82:5.7256,random_83:3.1342,random_84:3.1614,random_85:2.5454,random_86:5.8662,random_87:8.54,random_88:5.863,random_89:264.7036,random_90:270.7449,random_91:3.3766,random_92:8.5221,random_93:3.3303,random_94:7.683,random_95:3.0572,random_96:3.6877,random_97:3.225,random_98:2.09,random_99:3.3672'\n",
      "Testing (test) took 0:00:03.248833'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Tested (test) on 1948 instances with mean losses of: random_0:1.2997,random_1:1.2909,random_2:1.2932,random_3:1.3509,random_4:1.2967,random_5:1.2249,random_6:268.6047,random_7:1.2014,random_8:1.1795,random_9:1.6887,random_10:1.3022,random_11:1.1184,random_12:1.2253,random_13:1.2134,random_14:5.908,random_15:1.2738,random_16:1.2228,random_17:1.3638,random_18:1.1677,random_19:1.0851,random_20:1.2577,random_21:1.4072,random_22:1.6848,random_23:1.09,random_24:1.3712,random_25:1.2899,random_26:1.2957,random_27:1.2414,random_28:1.1543,random_29:1.3776,random_30:1.2424,random_31:1.4474,random_32:1.1196,random_33:270.6533,random_34:1.1782,random_35:1.4776,random_36:1.2291,random_37:1.644,random_38:5.9055,random_39:1.1302,random_40:1.1752,random_41:1.1825,random_42:1.1837,random_43:1.4743,random_44:3.0534,random_45:276.9942,random_46:1.1852,random_47:5.9069,random_48:1.2612,random_49:1.4736,random_50:1.2283,random_51:1.2972,random_52:1.3654,random_53:1.3864,random_54:1.3303,random_55:270.1569,random_56:1.5397,random_57:1.2807,random_58:3.0387,random_59:1.1477,random_60:1.2588,random_61:1.238,random_62:274.6307,random_63:1.1477,random_64:1.2799,random_65:1.3329,random_66:1.374,random_67:1.3069,random_68:1.1883,random_69:1.2702,random_70:1.363,random_71:270.0032,random_72:1.2084,random_73:1.3708,random_74:1.6051,random_75:1.1102,random_76:1.2506,random_77:1.1995,random_78:1.4138,random_79:1.424,random_80:1.1909,random_81:1.5152,random_82:1.2571,random_83:1.1997,random_84:1.6823,random_85:1.4762,random_86:5.9059,random_87:4.5547,random_88:1.4643,random_89:261.3426,random_90:1.1968,random_91:1.3105,random_92:1.6462,random_93:1.161,random_94:1.3656,random_95:1.2768,random_96:1.5912,random_97:1.1808,random_98:1.4441,random_99:1.3335'\n",
      "Testing (test) took 0:00:03.151382'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Tested (test) on 1949 instances with mean losses of: random_0:0.7104,random_1:0.9427,random_2:0.6883,random_3:0.7719,random_4:0.7899,random_5:0.5488,random_6:269.3014,random_7:0.5857,random_8:0.6394,random_9:0.7364,random_10:0.8575,random_11:0.5728,random_12:0.6001,random_13:0.8161,random_14:5.9064,random_15:0.9773,random_16:1.0094,random_17:0.7613,random_18:0.5863,random_19:0.7849,random_20:0.7948,random_21:0.5732,random_22:0.7922,random_23:0.766,random_24:0.8349,random_25:0.8043,random_26:0.6021,random_27:0.7995,random_28:1.1933,random_29:0.627,random_30:0.6338,random_31:0.7417,random_32:0.6115,random_33:271.2925,random_34:0.7237,random_35:0.7947,random_36:0.6563,random_37:0.8149,random_38:0.6845,random_39:273.6336,random_40:0.8094,random_41:0.548,random_42:0.676,random_43:0.7516,random_44:0.726,random_45:277.6673,random_46:0.9123,random_47:0.807,random_48:0.6668,random_49:0.7947,random_50:0.7495,random_51:0.7977,random_52:0.7479,random_53:0.6804,random_54:277.6897,random_55:270.8211,random_56:0.6731,random_57:0.7488,random_58:0.6375,random_59:0.5437,random_60:0.7208,random_61:0.6561,random_62:0.5828,random_63:0.704,random_64:0.722,random_65:0.7625,random_66:0.6799,random_67:5.8646,random_68:0.6269,random_69:0.595,random_70:0.7807,random_71:0.5987,random_72:0.6416,random_73:0.8354,random_74:0.671,random_75:1.0636,random_76:0.6678,random_77:0.5507,random_78:0.7149,random_79:0.7266,random_80:0.7897,random_81:0.715,random_82:0.5425,random_83:0.6544,random_84:0.7358,random_85:0.9129,random_86:5.8848,random_87:4.4809,random_88:0.8649,random_89:9.096,random_90:267.6269,random_91:0.7106,random_92:0.5964,random_93:0.5648,random_94:0.6082,random_95:0.6073,random_96:0.741,random_97:0.5288,random_98:0.8171,random_99:0.7712'\n",
      "Testing (test) took 0:00:03.248387'\n"
     ]
    }
   ],
   "source": [
    "deep_scheme = DeepScheme(None, fixed_hyperparams=fixed_hyperparams,loss_eval=loss_target,device=device,tensorboard=tb,adaptive_lr=True,update=False)\n",
    "deep_scores, deep_preds, _ , _, _ = eval.evaluate(deep_models,dataset,deep_scheme,logger_name=\"log\",load_fun=load_fun_cv)\n",
    "deep_scores_final, deep_preds_final, _ ,_, _ = eval.build(deep_models,dataset,deep_scheme,logger_name=\"test_log\",load_fun=load_fun_build)\n",
    "\n",
    "all_scores = []\n",
    "for k,v in ut.flip_dicts(deep_scores).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores.append({**dict1,**v})\n",
    "\n",
    "all_scores_final = []\n",
    "for k,v in ut.flip_dicts(deep_scores_final).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores_final.append({**dict1,**v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% lwr part\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_0'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8103,knn_k=1:0.0,knn_k=5:0.5372,knn_k=10:0.6705,knn_k=20:0.7714,knn_k=50:0.8765,knn_k=100:0.9609,lwr_k=20:0.4716,lwr_k=50:0.5432,lwr_k=100:0.592,lwr_k=200:0.6392,lwr_k=500:0.7024,lwr_k=1000:0.7497'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8351,knn_k=1:1.0543,knn_k=5:0.8528,knn_k=10:0.8562,knn_k=20:0.9026,knn_k=50:0.9686,knn_k=100:1.029,lwr_k=20:0.739,lwr_k=50:0.7329,lwr_k=100:0.7289,lwr_k=200:0.7254,lwr_k=500:0.7561,lwr_k=1000:0.7911'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7459,knn_k=1:0.0,knn_k=5:0.4843,knn_k=10:0.5913,knn_k=20:0.6608,knn_k=50:0.7175,knn_k=100:0.7473,lwr_k=20:0.415,lwr_k=50:0.4882,lwr_k=100:0.5373,lwr_k=200:0.5836,lwr_k=500:0.6343,lwr_k=1000:0.6682'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8017,knn_k=1:0.9895,knn_k=5:0.7821,knn_k=10:0.7792,knn_k=20:0.7846,knn_k=50:0.7991,knn_k=100:0.8208,lwr_k=20:0.6874,lwr_k=50:0.6986,lwr_k=100:0.7036,lwr_k=200:0.7223,lwr_k=500:0.7403,lwr_k=1000:0.7524'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7836,knn_k=1:0.0,knn_k=5:0.6142,knn_k=10:0.7607,knn_k=20:0.8746,knn_k=50:0.9838,knn_k=100:1.0661,lwr_k=20:0.4859,lwr_k=50:0.5454,lwr_k=100:0.585,lwr_k=200:0.6232,lwr_k=500:0.6765,lwr_k=1000:0.7062'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8054,knn_k=1:1.1801,knn_k=5:0.922,knn_k=10:0.9268,knn_k=20:0.9539,knn_k=50:1.0117,knn_k=100:1.0848,lwr_k=20:0.7314,lwr_k=50:0.6991,lwr_k=100:0.6898,lwr_k=200:0.6932,lwr_k=500:0.7171,lwr_k=1000:0.7355'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8423,knn_k=1:0.0,knn_k=5:0.5939,knn_k=10:0.7244,knn_k=20:0.8148,knn_k=50:0.9433,knn_k=100:1.0554,lwr_k=20:0.4788,lwr_k=50:0.5533,lwr_k=100:0.5975,lwr_k=200:0.6509,lwr_k=500:0.7254,lwr_k=1000:0.7715'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7904,knn_k=1:1.1151,knn_k=5:0.8278,knn_k=10:0.8304,knn_k=20:0.8546,knn_k=50:0.9225,knn_k=100:1.0307,lwr_k=20:0.6911,lwr_k=50:0.6752,lwr_k=100:0.666,lwr_k=200:0.6798,lwr_k=500:0.7187,lwr_k=1000:0.7486'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8328,knn_k=1:0.0,knn_k=5:0.4965,knn_k=10:0.622,knn_k=20:0.7017,knn_k=50:0.7915,knn_k=100:0.8625,lwr_k=20:0.4276,lwr_k=50:0.5038,lwr_k=100:0.5577,lwr_k=200:0.6054,lwr_k=500:0.6672,lwr_k=1000:0.7139'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8558,knn_k=1:0.8406,knn_k=5:0.7868,knn_k=10:0.8092,knn_k=20:0.8397,knn_k=50:0.8712,knn_k=100:0.9266,lwr_k=20:0.6789,lwr_k=50:0.6784,lwr_k=100:0.6902,lwr_k=200:0.7207,lwr_k=500:0.7492,lwr_k=1000:0.7745'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6837,knn_k=1:0.0,knn_k=5:0.4177,knn_k=10:0.5403,knn_k=20:0.607,knn_k=50:0.6576,knn_k=100:0.6806,lwr_k=20:0.3693,lwr_k=50:0.4431,lwr_k=100:0.501,lwr_k=200:0.5497,lwr_k=500:0.6008,lwr_k=1000:0.6313'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6974,knn_k=1:0.7102,knn_k=5:0.6788,knn_k=10:0.6618,knn_k=20:0.6812,knn_k=50:0.6952,knn_k=100:0.7042,lwr_k=20:0.5674,lwr_k=50:0.5796,lwr_k=100:0.6005,lwr_k=200:0.6205,lwr_k=500:0.6391,lwr_k=1000:0.6537'\n",
      "Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.'\n",
      "NumExpr defaulting to 8 threads.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_1'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8654,knn_k=1:0.0,knn_k=5:0.7084,knn_k=10:0.8736,knn_k=20:1.0118,knn_k=50:1.1797,knn_k=100:1.3075,lwr_k=20:0.8933,lwr_k=50:0.9328,lwr_k=100:0.9244,lwr_k=200:0.9097,lwr_k=500:0.8866,lwr_k=1000:0.8751'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9046,knn_k=1:1.5971,knn_k=5:1.1712,knn_k=10:1.1534,knn_k=20:1.1762,knn_k=50:1.2865,knn_k=100:1.4149,lwr_k=20:1.0859,lwr_k=50:1.0677,lwr_k=100:1.0316,lwr_k=200:0.9821,lwr_k=500:0.9363,lwr_k=1000:0.9111'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6675,knn_k=1:0.0,knn_k=5:0.5119,knn_k=10:0.6016,knn_k=20:0.6455,knn_k=50:0.6781,knn_k=100:0.6949,lwr_k=20:0.6089,lwr_k=50:0.6255,lwr_k=100:0.6359,lwr_k=200:0.6451,lwr_k=500:0.658,lwr_k=1000:0.6606'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7234,knn_k=1:1.3188,knn_k=5:0.8557,knn_k=10:0.7942,knn_k=20:0.7609,knn_k=50:0.7597,knn_k=100:0.7596,lwr_k=20:0.758,lwr_k=50:0.7489,lwr_k=100:0.7378,lwr_k=200:0.7293,lwr_k=500:0.7249,lwr_k=1000:0.7233'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8734,knn_k=1:0.0,knn_k=5:0.7549,knn_k=10:0.921,knn_k=20:1.0401,knn_k=50:1.2052,knn_k=100:1.3661,lwr_k=20:0.9542,lwr_k=50:1.008,lwr_k=100:1.0106,lwr_k=200:0.9993,lwr_k=500:0.9847,lwr_k=1000:0.9689'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9164,knn_k=1:1.7385,knn_k=5:1.1818,knn_k=10:1.1611,knn_k=20:1.1837,knn_k=50:1.2804,knn_k=100:1.4245,lwr_k=20:1.1305,lwr_k=50:1.1192,lwr_k=100:1.0908,lwr_k=200:1.0551,lwr_k=500:1.016,lwr_k=1000:0.9928'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9338,knn_k=1:0.0,knn_k=5:0.8264,knn_k=10:1.0609,knn_k=20:1.3045,knn_k=50:1.742,knn_k=100:2.255,lwr_k=20:1.0396,lwr_k=50:1.0538,lwr_k=100:1.0123,lwr_k=200:0.9783,lwr_k=500:0.9561,lwr_k=1000:0.937'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8817,knn_k=1:1.8997,knn_k=5:1.2853,knn_k=10:1.3387,knn_k=20:1.4881,knn_k=50:1.8953,knn_k=100:2.3622,lwr_k=20:1.2074,lwr_k=50:1.1401,lwr_k=100:1.0463,lwr_k=200:0.996,lwr_k=500:0.9512,lwr_k=1000:0.913'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0594,knn_k=1:0.0,knn_k=5:0.771,knn_k=10:0.9137,knn_k=20:0.9957,knn_k=50:1.0667,knn_k=100:1.1014,lwr_k=20:0.9328,lwr_k=50:0.9768,lwr_k=100:0.99,lwr_k=200:0.9963,lwr_k=500:1.004,lwr_k=1000:1.0106'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0897,knn_k=1:1.7472,knn_k=5:1.1728,knn_k=10:1.1545,knn_k=20:1.1444,knn_k=50:1.1641,knn_k=100:1.1823,lwr_k=20:1.1033,lwr_k=50:1.1012,lwr_k=100:1.0899,lwr_k=200:1.0794,lwr_k=500:1.0721,lwr_k=1000:1.0668'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7259,knn_k=1:0.0,knn_k=5:0.5565,knn_k=10:0.6478,knn_k=20:0.7063,knn_k=50:0.771,knn_k=100:0.8324,lwr_k=20:0.6625,lwr_k=50:0.6841,lwr_k=100:0.6944,lwr_k=200:0.701,lwr_k=500:0.7071,lwr_k=1000:0.7137'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7435,knn_k=1:1.2319,knn_k=5:0.8277,knn_k=10:0.7924,knn_k=20:0.7898,knn_k=50:0.8195,knn_k=100:0.8668,lwr_k=20:0.7681,lwr_k=50:0.7604,lwr_k=100:0.7529,lwr_k=200:0.7464,lwr_k=500:0.7383,lwr_k=1000:0.7336'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_2'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9917,knn_k=1:0.0,knn_k=5:0.6126,knn_k=10:0.752,knn_k=20:0.8645,knn_k=50:0.9848,knn_k=100:1.076,lwr_k=20:0.2761,lwr_k=50:0.444,lwr_k=100:0.5324,lwr_k=200:0.6,lwr_k=500:0.6766,lwr_k=1000:0.7333'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.0188,knn_k=1:1.4094,knn_k=5:0.9639,knn_k=10:0.941,knn_k=20:0.98,knn_k=50:1.0576,knn_k=100:1.1263,lwr_k=20:0.8561,lwr_k=50:0.7166,lwr_k=100:0.6947,lwr_k=200:0.7047,lwr_k=500:0.7499,lwr_k=1000:0.7756'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7048,knn_k=1:0.0,knn_k=5:0.4961,knn_k=10:0.5817,knn_k=20:0.6354,knn_k=50:0.6829,knn_k=100:0.7142,lwr_k=20:0.245,lwr_k=50:0.3978,lwr_k=100:0.4842,lwr_k=200:0.5426,lwr_k=500:0.6036,lwr_k=1000:0.6421'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7335,knn_k=1:1.2112,knn_k=5:0.8285,knn_k=10:0.7762,knn_k=20:0.7529,knn_k=50:0.7558,knn_k=100:0.7702,lwr_k=20:0.9363,lwr_k=50:0.7921,lwr_k=100:0.724,lwr_k=200:0.6954,lwr_k=500:0.6878,lwr_k=1000:0.6938'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1597,knn_k=1:0.0,knn_k=5:0.9422,knn_k=10:1.125,knn_k=20:1.258,knn_k=50:1.3935,knn_k=100:1.4687,lwr_k=20:0.5118,lwr_k=50:0.657,lwr_k=100:0.7347,lwr_k=200:0.7987,lwr_k=500:0.8542,lwr_k=1000:0.9054'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1535,knn_k=1:2.2608,knn_k=5:1.4493,knn_k=10:1.4203,knn_k=20:1.4539,knn_k=50:1.4917,knn_k=100:1.5335,lwr_k=20:1.2404,lwr_k=50:1.0624,lwr_k=100:0.9934,lwr_k=200:0.9611,lwr_k=500:0.9341,lwr_k=1000:0.9321'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2317,knn_k=1:0.0,knn_k=5:0.6712,knn_k=10:0.8363,knn_k=20:0.9663,knn_k=50:1.1202,knn_k=100:1.2688,lwr_k=20:0.2404,lwr_k=50:0.4325,lwr_k=100:0.5296,lwr_k=200:0.608,lwr_k=500:0.7014,lwr_k=1000:0.7824'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2689,knn_k=1:1.4725,knn_k=5:1.0124,knn_k=10:1.0053,knn_k=20:1.0267,knn_k=50:1.1459,knn_k=100:1.2674,lwr_k=20:1.0126,lwr_k=50:0.775,lwr_k=100:0.7422,lwr_k=200:0.7328,lwr_k=500:0.7469,lwr_k=1000:0.8038'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9208,knn_k=1:0.0,knn_k=5:0.5893,knn_k=10:0.7107,knn_k=20:0.7925,knn_k=50:0.8815,knn_k=100:0.938,lwr_k=20:0.2361,lwr_k=50:0.4105,lwr_k=100:0.5003,lwr_k=200:0.5702,lwr_k=500:0.6438,lwr_k=1000:0.7074'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9633,knn_k=1:1.34,knn_k=5:0.9112,knn_k=10:0.8941,knn_k=20:0.907,knn_k=50:0.957,knn_k=100:1.0113,lwr_k=20:1.0368,lwr_k=50:0.7736,lwr_k=100:0.695,lwr_k=200:0.7021,lwr_k=500:0.7212,lwr_k=1000:0.761'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.5766,knn_k=1:0.0,knn_k=5:0.4068,knn_k=10:0.4901,knn_k=20:0.5369,knn_k=50:0.5879,knn_k=100:0.6251,lwr_k=20:0.2172,lwr_k=50:0.3566,lwr_k=100:0.4251,lwr_k=200:0.4723,lwr_k=500:0.5173,lwr_k=1000:0.5393'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6034,knn_k=1:0.9444,knn_k=5:0.6261,knn_k=10:0.6077,knn_k=20:0.6077,knn_k=50:0.6282,knn_k=100:0.6558,lwr_k=20:0.7907,lwr_k=50:0.5966,lwr_k=100:0.5836,lwr_k=200:0.5739,lwr_k=500:0.5806,lwr_k=1000:0.5835'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_3'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.0298,knn_k=1:0.0,knn_k=5:2.4072,knn_k=10:3.1122,knn_k=20:3.6113,knn_k=50:4.0825,knn_k=100:4.3682,lwr_k=20:3.3516,lwr_k=50:3.566,lwr_k=100:3.6318,lwr_k=200:3.6717,lwr_k=500:3.8935,lwr_k=1000:4.1862'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.2571,knn_k=1:3.7966,knn_k=5:4.0303,knn_k=10:4.0218,knn_k=20:4.1722,knn_k=50:4.3944,knn_k=100:4.5943,lwr_k=20:4.012,lwr_k=50:3.9943,lwr_k=100:3.9656,lwr_k=200:3.9342,lwr_k=500:4.0962,lwr_k=1000:4.3616'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.1276,knn_k=1:0.0,knn_k=5:2.4498,knn_k=10:3.1449,knn_k=20:3.6482,knn_k=50:4.1347,knn_k=100:4.4732,lwr_k=20:3.3821,lwr_k=50:3.5901,lwr_k=100:3.6572,lwr_k=200:3.6965,lwr_k=500:3.8736,lwr_k=1000:4.1394'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.0765,knn_k=1:3.8021,knn_k=5:3.8371,knn_k=10:3.9174,knn_k=20:4.1076,knn_k=50:4.3308,knn_k=100:4.5564,lwr_k=20:3.9162,lwr_k=50:3.8823,lwr_k=100:3.8107,lwr_k=200:3.792,lwr_k=500:3.8724,lwr_k=1000:4.1233'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4312,knn_k=1:0.0,knn_k=5:0.9051,knn_k=10:1.1022,knn_k=20:1.2331,knn_k=50:1.3378,knn_k=100:1.406,lwr_k=20:0.8565,lwr_k=50:0.9826,lwr_k=100:1.0333,lwr_k=200:1.098,lwr_k=500:1.185,lwr_k=1000:1.2564'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.4826,knn_k=1:1.9104,knn_k=5:1.4155,knn_k=10:1.3893,knn_k=20:1.4048,knn_k=50:1.4448,knn_k=100:1.4786,lwr_k=20:1.19,lwr_k=50:1.167,lwr_k=100:1.1532,lwr_k=200:1.1832,lwr_k=500:1.2364,lwr_k=1000:1.2945'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4075,knn_k=1:0.0,knn_k=5:0.68,knn_k=10:0.8842,knn_k=20:1.0264,knn_k=50:1.1836,knn_k=100:1.3054,lwr_k=20:0.4572,lwr_k=50:0.6316,lwr_k=100:0.7342,lwr_k=200:0.8189,lwr_k=500:0.9197,lwr_k=1000:0.9998'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.3676,knn_k=1:1.1257,knn_k=5:1.0512,knn_k=10:1.0655,knn_k=20:1.0975,knn_k=50:1.2166,knn_k=100:1.2966,lwr_k=20:0.8441,lwr_k=50:0.7854,lwr_k=100:0.8094,lwr_k=200:0.8403,lwr_k=500:0.8976,lwr_k=1000:0.966'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0317,knn_k=1:0.0,knn_k=5:0.5269,knn_k=10:0.6868,knn_k=20:0.8192,knn_k=50:0.9961,knn_k=100:1.1766,lwr_k=20:0.4051,lwr_k=50:0.5579,lwr_k=100:0.6393,lwr_k=200:0.6995,lwr_k=500:0.7602,lwr_k=1000:0.8063'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.97,knn_k=1:0.8378,knn_k=5:0.8644,knn_k=10:0.871,knn_k=20:0.9155,knn_k=50:1.047,knn_k=100:1.1931,lwr_k=20:0.7586,lwr_k=50:0.747,lwr_k=100:0.7399,lwr_k=200:0.7384,lwr_k=500:0.7675,lwr_k=1000:0.7929'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.713,knn_k=1:0.0,knn_k=5:0.459,knn_k=10:0.5945,knn_k=20:0.681,knn_k=50:0.8189,knn_k=100:0.9668,lwr_k=20:0.3492,lwr_k=50:0.5044,lwr_k=100:0.573,lwr_k=200:0.6157,lwr_k=500:0.6566,lwr_k=1000:0.6816'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7403,knn_k=1:0.7665,knn_k=5:0.7443,knn_k=10:0.733,knn_k=20:0.7527,knn_k=50:0.8433,knn_k=100:0.9657,lwr_k=20:0.6475,lwr_k=50:0.6673,lwr_k=100:0.6779,lwr_k=200:0.6753,lwr_k=500:0.6975,lwr_k=1000:0.714'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_4'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7566,knn_k=1:0.0,knn_k=5:0.4921,knn_k=10:0.6092,knn_k=20:0.6893,knn_k=50:0.7802,knn_k=100:0.862,lwr_k=20:0.3961,lwr_k=50:0.4902,lwr_k=100:0.5426,lwr_k=200:0.5892,lwr_k=500:0.6442,lwr_k=1000:0.6779'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7916,knn_k=1:0.8749,knn_k=5:0.7613,knn_k=10:0.7774,knn_k=20:0.8026,knn_k=50:0.8564,knn_k=100:0.9286,lwr_k=20:0.6398,lwr_k=50:0.6447,lwr_k=100:0.6567,lwr_k=200:0.671,lwr_k=500:0.7062,lwr_k=1000:0.7243'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6826,knn_k=1:0.0,knn_k=5:0.4542,knn_k=10:0.5533,knn_k=20:0.6127,knn_k=50:0.6729,knn_k=100:0.7052,lwr_k=20:0.3914,lwr_k=50:0.4717,lwr_k=100:0.5159,lwr_k=200:0.5491,lwr_k=500:0.5956,lwr_k=1000:0.6255'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7104,knn_k=1:0.8462,knn_k=5:0.736,knn_k=10:0.7273,knn_k=20:0.7434,knn_k=50:0.7585,knn_k=100:0.7702,lwr_k=20:0.6643,lwr_k=50:0.6582,lwr_k=100:0.6645,lwr_k=200:0.6684,lwr_k=500:0.6848,lwr_k=1000:0.6948'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7968,knn_k=1:0.0,knn_k=5:0.552,knn_k=10:0.6869,knn_k=20:0.7908,knn_k=50:0.8879,knn_k=100:0.9586,lwr_k=20:0.4562,lwr_k=50:0.5376,lwr_k=100:0.59,lwr_k=200:0.6369,lwr_k=500:0.6832,lwr_k=1000:0.7158'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8227,knn_k=1:1.0606,knn_k=5:0.8313,knn_k=10:0.8457,knn_k=20:0.8508,knn_k=50:0.9167,knn_k=100:0.9848,lwr_k=20:0.6908,lwr_k=50:0.6972,lwr_k=100:0.6997,lwr_k=200:0.7093,lwr_k=500:0.7348,lwr_k=1000:0.7446'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9314,knn_k=1:0.0,knn_k=5:0.6934,knn_k=10:0.9006,knn_k=20:1.0422,knn_k=50:1.1977,knn_k=100:1.3201,lwr_k=20:0.5731,lwr_k=50:0.6698,lwr_k=100:0.7138,lwr_k=200:0.7462,lwr_k=500:0.7885,lwr_k=1000:0.8389'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8613,knn_k=1:1.2233,knn_k=5:1.0315,knn_k=10:1.0279,knn_k=20:1.0489,knn_k=50:1.1361,knn_k=100:1.2373,lwr_k=20:0.8131,lwr_k=50:0.8092,lwr_k=100:0.7945,lwr_k=200:0.7856,lwr_k=500:0.7917,lwr_k=1000:0.8209'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7595,knn_k=1:0.0,knn_k=5:0.4778,knn_k=10:0.6059,knn_k=20:0.6865,knn_k=50:0.7616,knn_k=100:0.8204,lwr_k=20:0.3967,lwr_k=50:0.484,lwr_k=100:0.5392,lwr_k=200:0.5894,lwr_k=500:0.6439,lwr_k=1000:0.678'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7807,knn_k=1:0.873,knn_k=5:0.7478,knn_k=10:0.7402,knn_k=20:0.7726,knn_k=50:0.8142,knn_k=100:0.8657,lwr_k=20:0.6325,lwr_k=50:0.6444,lwr_k=100:0.6596,lwr_k=200:0.6844,lwr_k=500:0.7149,lwr_k=1000:0.7292'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7506,knn_k=1:0.0,knn_k=5:0.4339,knn_k=10:0.5605,knn_k=20:0.6383,knn_k=50:0.7043,knn_k=100:0.7375,lwr_k=20:0.394,lwr_k=50:0.4873,lwr_k=100:0.5431,lwr_k=200:0.5913,lwr_k=500:0.6437,lwr_k=1000:0.673'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7584,knn_k=1:0.7893,knn_k=5:0.7121,knn_k=10:0.7042,knn_k=20:0.7149,knn_k=50:0.7345,knn_k=100:0.7564,lwr_k=20:0.6356,lwr_k=50:0.6354,lwr_k=100:0.6541,lwr_k=200:0.6737,lwr_k=500:0.6814,lwr_k=1000:0.6981'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_5'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0695,knn_k=1:0.0,knn_k=5:0.8274,knn_k=10:0.98,knn_k=20:1.087,knn_k=50:1.2006,knn_k=100:1.2727,lwr_k=20:0.7297,lwr_k=50:0.7562,lwr_k=100:0.7724,lwr_k=200:0.7927,lwr_k=500:0.8199,lwr_k=1000:0.8377'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.998,knn_k=1:2.0868,knn_k=5:1.3179,knn_k=10:1.2802,knn_k=20:1.2665,knn_k=50:1.3332,knn_k=100:1.3972,lwr_k=20:1.0281,lwr_k=50:0.9278,lwr_k=100:0.9015,lwr_k=200:0.883,lwr_k=500:0.8891,lwr_k=1000:0.8957'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6386,knn_k=1:0.0,knn_k=5:0.4515,knn_k=10:0.5326,knn_k=20:0.5667,knn_k=50:0.5983,knn_k=100:0.6138,lwr_k=20:0.4616,lwr_k=50:0.5261,lwr_k=100:0.5507,lwr_k=200:0.5681,lwr_k=500:0.5799,lwr_k=1000:0.5888'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6919,knn_k=1:1.1489,knn_k=5:0.7326,knn_k=10:0.6905,knn_k=20:0.6768,knn_k=50:0.675,knn_k=100:0.6816,lwr_k=20:0.6769,lwr_k=50:0.6637,lwr_k=100:0.6517,lwr_k=200:0.6368,lwr_k=500:0.6318,lwr_k=1000:0.6391'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9546,knn_k=1:0.0,knn_k=5:1.1539,knn_k=10:1.3311,knn_k=20:1.4184,knn_k=50:1.5,knn_k=100:1.5595,lwr_k=20:1.2612,lwr_k=50:1.3256,lwr_k=100:1.3542,lwr_k=200:1.3706,lwr_k=500:1.3963,lwr_k=1000:1.4233'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9769,knn_k=1:2.8587,knn_k=5:1.7958,knn_k=10:1.7147,knn_k=20:1.6931,knn_k=50:1.6734,knn_k=100:1.6841,lwr_k=20:1.6518,lwr_k=50:1.5905,lwr_k=100:1.5389,lwr_k=200:1.5079,lwr_k=500:1.498,lwr_k=1000:1.5026'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0304,knn_k=1:0.0,knn_k=5:0.9859,knn_k=10:1.187,knn_k=20:1.3403,knn_k=50:1.5023,knn_k=100:1.6542,lwr_k=20:1.0423,lwr_k=50:1.0953,lwr_k=100:1.1161,lwr_k=200:1.1218,lwr_k=500:1.0769,lwr_k=1000:1.0572'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9932,knn_k=1:2.441,knn_k=5:1.6158,knn_k=10:1.517,knn_k=20:1.5316,knn_k=50:1.5948,knn_k=100:1.7056,lwr_k=20:1.3451,lwr_k=50:1.2422,lwr_k=100:1.2066,lwr_k=200:1.1474,lwr_k=500:1.093,lwr_k=1000:1.0689'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7482,knn_k=1:0.0,knn_k=5:0.6247,knn_k=10:0.7433,knn_k=20:0.8208,knn_k=50:0.9169,knn_k=100:0.9875,lwr_k=20:0.5864,lwr_k=50:0.651,lwr_k=100:0.6874,lwr_k=200:0.7246,lwr_k=500:0.7564,lwr_k=1000:0.7721'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7373,knn_k=1:1.4599,knn_k=5:0.9182,knn_k=10:0.8678,knn_k=20:0.8863,knn_k=50:0.9394,knn_k=100:0.9967,lwr_k=20:0.7983,lwr_k=50:0.7435,lwr_k=100:0.742,lwr_k=200:0.7435,lwr_k=500:0.7545,lwr_k=1000:0.7687'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.5002,knn_k=1:0.0,knn_k=5:0.3847,knn_k=10:0.4403,knn_k=20:0.4718,knn_k=50:0.494,knn_k=100:0.507,lwr_k=20:0.4021,lwr_k=50:0.4469,lwr_k=100:0.4685,lwr_k=200:0.4802,lwr_k=500:0.49,lwr_k=1000:0.4952'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5265,knn_k=1:0.886,knn_k=5:0.5906,knn_k=10:0.5571,knn_k=20:0.5392,knn_k=50:0.5423,knn_k=100:0.5475,lwr_k=20:0.536,lwr_k=50:0.5389,lwr_k=100:0.5287,lwr_k=200:0.5242,lwr_k=500:0.522,lwr_k=1000:0.5237'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_6'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.4959,knn_k=1:0.0,knn_k=5:2.0176,knn_k=10:2.701,knn_k=20:3.185,knn_k=50:3.7017,knn_k=100:4.0767,lwr_k=20:2.8107,lwr_k=50:2.9507,lwr_k=100:2.8853,lwr_k=200:2.7335,lwr_k=500:2.5906,lwr_k=1000:2.6471'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.8514,knn_k=1:3.0661,knn_k=5:3.3025,knn_k=10:3.4643,knn_k=20:3.6127,knn_k=50:3.9739,knn_k=100:4.3404,lwr_k=20:3.3388,lwr_k=50:3.3533,lwr_k=100:3.2243,lwr_k=200:3.0462,lwr_k=500:2.8759,lwr_k=1000:2.9303'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.3525,knn_k=1:0.0,knn_k=5:1.9844,knn_k=10:2.6577,knn_k=20:3.173,knn_k=50:3.71,knn_k=100:4.1007,lwr_k=20:2.7891,lwr_k=50:2.9671,lwr_k=100:2.8841,lwr_k=200:2.7078,lwr_k=500:2.5463,lwr_k=1000:2.6069'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.587,knn_k=1:3.0992,knn_k=5:3.2688,knn_k=10:3.4472,knn_k=20:3.5989,knn_k=50:3.9055,knn_k=100:4.2145,lwr_k=20:3.3455,lwr_k=50:3.3171,lwr_k=100:3.1865,lwr_k=200:2.9586,lwr_k=500:2.6999,lwr_k=1000:2.711'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.1076,knn_k=1:0.0,knn_k=5:1.9939,knn_k=10:2.6297,knn_k=20:3.1686,knn_k=50:3.742,knn_k=100:4.1589,lwr_k=20:2.7944,lwr_k=50:2.9325,lwr_k=100:2.8374,lwr_k=200:2.6678,lwr_k=500:2.5177,lwr_k=1000:2.5888'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.2085,knn_k=1:2.8669,knn_k=5:3.0738,knn_k=10:3.2546,knn_k=20:3.5433,knn_k=50:3.9058,knn_k=100:4.2507,lwr_k=20:3.2478,lwr_k=50:3.2083,lwr_k=100:3.0739,lwr_k=200:2.8463,lwr_k=500:2.6321,lwr_k=1000:2.6643'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.5519,knn_k=1:0.0,knn_k=5:2.1568,knn_k=10:2.7877,knn_k=20:3.3145,knn_k=50:3.9186,knn_k=100:4.2794,lwr_k=20:2.9334,lwr_k=50:3.1273,lwr_k=100:3.0627,lwr_k=200:2.8999,lwr_k=500:2.7915,lwr_k=1000:2.9319'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.4339,knn_k=1:3.3184,knn_k=5:3.3219,knn_k=10:3.5045,knn_k=20:3.6324,knn_k=50:3.9315,knn_k=100:4.1841,lwr_k=20:3.3356,lwr_k=50:3.2895,lwr_k=100:3.1658,lwr_k=200:2.9625,lwr_k=500:2.7786,lwr_k=1000:2.876'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.3752,knn_k=1:0.0,knn_k=5:2.0808,knn_k=10:2.7566,knn_k=20:3.2896,knn_k=50:3.8768,knn_k=100:4.2974,lwr_k=20:2.9199,lwr_k=50:3.0763,lwr_k=100:2.9896,lwr_k=200:2.7941,lwr_k=500:2.6116,lwr_k=1000:2.6655'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.5226,knn_k=1:2.9644,knn_k=5:3.3755,knn_k=10:3.5512,knn_k=20:3.704,knn_k=50:4.0506,knn_k=100:4.3479,lwr_k=20:3.4294,lwr_k=50:3.3802,lwr_k=100:3.2034,lwr_k=200:2.9661,lwr_k=500:2.7549,lwr_k=1000:2.8254'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.2614,knn_k=1:0.0,knn_k=5:1.9198,knn_k=10:2.5911,knn_k=20:3.1267,knn_k=50:3.7645,knn_k=100:4.1728,lwr_k=20:2.7592,lwr_k=50:3.0004,lwr_k=100:2.9316,lwr_k=200:2.7352,lwr_k=500:2.5205,lwr_k=1000:2.5165'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.0926,knn_k=1:2.0494,knn_k=5:2.8686,knn_k=10:3.0721,knn_k=20:3.4034,knn_k=50:3.794,knn_k=100:4.1624,lwr_k=20:3.0834,lwr_k=50:3.0729,lwr_k=100:2.8987,lwr_k=200:2.6305,lwr_k=500:2.3712,lwr_k=1000:2.3876'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_7'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0341,knn_k=1:0.0,knn_k=5:0.8431,knn_k=10:0.9783,knn_k=20:1.0766,knn_k=50:1.1581,knn_k=100:1.2162,lwr_k=20:1.0074,lwr_k=50:1.0377,lwr_k=100:1.0432,lwr_k=200:1.0398,lwr_k=500:1.0395,lwr_k=1000:1.0443'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.1026,knn_k=1:2.1875,knn_k=5:1.3814,knn_k=10:1.28,knn_k=20:1.2617,knn_k=50:1.2821,knn_k=100:1.3324,lwr_k=20:1.2179,lwr_k=50:1.1893,lwr_k=100:1.1626,lwr_k=200:1.1244,lwr_k=500:1.1046,lwr_k=1000:1.1063'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6428,knn_k=1:0.0,knn_k=5:0.514,knn_k=10:0.5874,knn_k=20:0.6304,knn_k=50:0.6577,knn_k=100:0.685,lwr_k=20:0.6127,lwr_k=50:0.6272,lwr_k=100:0.6333,lwr_k=200:0.6406,lwr_k=500:0.6432,lwr_k=1000:0.6443'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6843,knn_k=1:1.3255,knn_k=5:0.8092,knn_k=10:0.7468,knn_k=20:0.7167,knn_k=50:0.7081,knn_k=100:0.7274,lwr_k=20:0.7139,lwr_k=50:0.6912,lwr_k=100:0.6887,lwr_k=200:0.6859,lwr_k=500:0.6804,lwr_k=1000:0.6793'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.7837,knn_k=1:0.0,knn_k=5:1.4359,knn_k=10:1.646,knn_k=20:1.7662,knn_k=50:1.8459,knn_k=100:1.8792,lwr_k=20:1.7618,lwr_k=50:1.8344,lwr_k=100:1.8613,lwr_k=200:1.8791,lwr_k=500:1.8767,lwr_k=1000:1.8743'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.7864,knn_k=1:3.4798,knn_k=5:2.1923,knn_k=10:1.9899,knn_k=20:1.9539,knn_k=50:1.9099,knn_k=100:1.9226,lwr_k=20:1.9539,lwr_k=50:1.9044,lwr_k=100:1.9118,lwr_k=200:1.9073,lwr_k=500:1.9038,lwr_k=1000:1.8988'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4064,knn_k=1:0.0,knn_k=5:1.1616,knn_k=10:1.365,knn_k=20:1.5087,knn_k=50:1.6501,knn_k=100:1.7131,lwr_k=20:1.475,lwr_k=50:1.585,lwr_k=100:1.6156,lwr_k=200:1.6081,lwr_k=500:1.5806,lwr_k=1000:1.5726'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.4446,knn_k=1:2.8135,knn_k=5:1.7869,knn_k=10:1.7234,knn_k=20:1.7019,knn_k=50:1.7262,knn_k=100:1.7407,lwr_k=20:1.6908,lwr_k=50:1.6846,lwr_k=100:1.6622,lwr_k=200:1.6354,lwr_k=500:1.5918,lwr_k=1000:1.5812'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0917,knn_k=1:0.0,knn_k=5:0.884,knn_k=10:1.0039,knn_k=20:1.0874,knn_k=50:1.1613,knn_k=100:1.2052,lwr_k=20:1.0254,lwr_k=50:1.0599,lwr_k=100:1.0772,lwr_k=200:1.0895,lwr_k=500:1.0998,lwr_k=1000:1.1011'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1111,knn_k=1:2.2014,knn_k=5:1.2955,knn_k=10:1.2456,knn_k=20:1.2203,knn_k=50:1.2275,knn_k=100:1.2383,lwr_k=20:1.1739,lwr_k=50:1.1506,lwr_k=100:1.1422,lwr_k=200:1.1415,lwr_k=500:1.1352,lwr_k=1000:1.1299'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.5105,knn_k=1:0.0,knn_k=5:0.4078,knn_k=10:0.4592,knn_k=20:0.485,knn_k=50:0.5004,knn_k=100:0.508,lwr_k=20:0.4845,lwr_k=50:0.4991,lwr_k=100:0.5055,lwr_k=200:0.508,lwr_k=500:0.5091,lwr_k=1000:0.5103'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5402,knn_k=1:1.0728,knn_k=5:0.6303,knn_k=10:0.5806,knn_k=20:0.5604,knn_k=50:0.5477,knn_k=100:0.5454,lwr_k=20:0.5606,lwr_k=50:0.5481,lwr_k=100:0.5455,lwr_k=200:0.5447,lwr_k=500:0.545,lwr_k=1000:0.5441'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_8'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9242,knn_k=1:0.0,knn_k=5:0.6372,knn_k=10:0.8017,knn_k=20:0.9457,knn_k=50:1.1092,knn_k=100:1.2355,lwr_k=20:0.0507,lwr_k=50:0.2173,lwr_k=100:0.3515,lwr_k=200:0.4613,lwr_k=500:0.5775,lwr_k=1000:0.6491'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9546,knn_k=1:1.1591,knn_k=5:0.949,knn_k=10:0.9968,knn_k=20:1.0497,knn_k=50:1.1443,knn_k=100:1.264,lwr_k=20:1.5317,lwr_k=50:1.1841,lwr_k=100:0.7976,lwr_k=200:0.6627,lwr_k=500:0.6809,lwr_k=1000:0.7177'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6355,knn_k=1:0.0,knn_k=5:0.4304,knn_k=10:0.5228,knn_k=20:0.5882,knn_k=50:0.6411,knn_k=100:0.6719,lwr_k=20:0.0267,lwr_k=50:0.1887,lwr_k=100:0.3154,lwr_k=200:0.4111,lwr_k=500:0.5008,lwr_k=1000:0.5518'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6929,knn_k=1:1.0281,knn_k=5:0.7324,knn_k=10:0.7213,knn_k=20:0.7052,knn_k=50:0.7111,knn_k=100:0.7209,lwr_k=20:1.8099,lwr_k=50:1.1786,lwr_k=100:0.8574,lwr_k=200:0.7507,lwr_k=500:0.68,lwr_k=1000:0.6767'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9952,knn_k=1:0.0,knn_k=5:0.6311,knn_k=10:0.7859,knn_k=20:0.9054,knn_k=50:1.0663,knn_k=100:1.1873,lwr_k=20:0.0328,lwr_k=50:0.184,lwr_k=100:0.3285,lwr_k=200:0.4517,lwr_k=500:0.603,lwr_k=1000:0.7079'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9988,knn_k=1:1.3118,knn_k=5:0.9895,knn_k=10:0.9828,knn_k=20:1.005,knn_k=50:1.1164,knn_k=100:1.2138,lwr_k=20:2.549,lwr_k=50:1.518,lwr_k=100:1.1785,lwr_k=200:0.8362,lwr_k=500:0.7762,lwr_k=1000:0.7791'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0041,knn_k=1:0.0,knn_k=5:0.6833,knn_k=10:0.8865,knn_k=20:1.0491,knn_k=50:1.3126,knn_k=100:1.5837,lwr_k=20:0.0118,lwr_k=50:0.2082,lwr_k=100:0.3338,lwr_k=200:0.4838,lwr_k=500:0.6895,lwr_k=1000:0.7327'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9789,knn_k=1:1.3058,knn_k=5:1.0596,knn_k=10:1.0764,knn_k=20:1.1364,knn_k=50:1.3056,knn_k=100:1.5405,lwr_k=20:2.6161,lwr_k=50:1.7669,lwr_k=100:0.8718,lwr_k=200:0.7927,lwr_k=500:0.8333,lwr_k=1000:0.733'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8603,knn_k=1:0.0,knn_k=5:0.5576,knn_k=10:0.6925,knn_k=20:0.8037,knn_k=50:0.9164,knn_k=100:0.9981,lwr_k=20:0.031,lwr_k=50:0.1635,lwr_k=100:0.3028,lwr_k=200:0.4191,lwr_k=500:0.5513,lwr_k=1000:0.6382'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9088,knn_k=1:1.2992,knn_k=5:0.9526,knn_k=10:0.9305,knn_k=20:0.9519,knn_k=50:0.9973,knn_k=100:1.059,lwr_k=20:1.7637,lwr_k=50:1.2631,lwr_k=100:0.8584,lwr_k=200:0.7361,lwr_k=500:0.6845,lwr_k=1000:0.7214'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.5886,knn_k=1:0.0,knn_k=5:0.3959,knn_k=10:0.4775,knn_k=20:0.5331,knn_k=50:0.5733,knn_k=100:0.603,lwr_k=20:0.0771,lwr_k=50:0.2422,lwr_k=100:0.3465,lwr_k=200:0.421,lwr_k=500:0.4922,lwr_k=1000:0.5314'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5761,knn_k=1:0.846,knn_k=5:0.6025,knn_k=10:0.5865,knn_k=20:0.5806,knn_k=50:0.5908,knn_k=100:0.6086,lwr_k=20:1.1503,lwr_k=50:0.7857,lwr_k=100:0.6474,lwr_k=200:0.5933,lwr_k=500:0.5733,lwr_k=1000:0.5703'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_9'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8137,knn_k=1:0.0,knn_k=5:0.6128,knn_k=10:0.8001,knn_k=20:0.9637,knn_k=50:1.2296,knn_k=100:1.5089,lwr_k=20:0.0411,lwr_k=50:0.1634,lwr_k=100:0.308,lwr_k=200:0.4408,lwr_k=500:0.5789,lwr_k=1000:0.6562'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8309,knn_k=1:0.913,knn_k=5:0.9331,knn_k=10:0.9778,knn_k=20:1.0707,knn_k=50:1.3018,knn_k=100:1.5602,lwr_k=20:0.7956,lwr_k=50:0.7086,lwr_k=100:0.6702,lwr_k=200:0.6419,lwr_k=500:0.677,lwr_k=1000:0.7145'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7039,knn_k=1:0.0,knn_k=5:0.4836,knn_k=10:0.6253,knn_k=20:0.7472,knn_k=50:0.886,knn_k=100:1.0384,lwr_k=20:0.0562,lwr_k=50:0.1746,lwr_k=100:0.2976,lwr_k=200:0.4128,lwr_k=500:0.5416,lwr_k=1000:0.6051'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7588,knn_k=1:0.7682,knn_k=5:0.8074,knn_k=10:0.8217,knn_k=20:0.8623,knn_k=50:0.9774,knn_k=100:1.1135,lwr_k=20:0.6987,lwr_k=50:0.6324,lwr_k=100:0.6072,lwr_k=200:0.633,lwr_k=500:0.6775,lwr_k=1000:0.7084'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7385,knn_k=1:0.0,knn_k=5:0.5102,knn_k=10:0.6449,knn_k=20:0.7416,knn_k=50:0.894,knn_k=100:1.0329,lwr_k=20:0.0895,lwr_k=50:0.2185,lwr_k=100:0.3353,lwr_k=200:0.4315,lwr_k=500:0.5492,lwr_k=1000:0.6248'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7751,knn_k=1:0.8015,knn_k=5:0.8098,knn_k=10:0.8125,knn_k=20:0.8434,knn_k=50:0.9363,knn_k=100:1.0668,lwr_k=20:0.6345,lwr_k=50:0.615,lwr_k=100:0.5838,lwr_k=200:0.6047,lwr_k=500:0.6378,lwr_k=1000:0.6778'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8179,knn_k=1:0.0,knn_k=5:0.6139,knn_k=10:0.8054,knn_k=20:0.9573,knn_k=50:1.2039,knn_k=100:1.4685,lwr_k=20:0.0537,lwr_k=50:0.181,lwr_k=100:0.3246,lwr_k=200:0.4597,lwr_k=500:0.591,lwr_k=1000:0.6627'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7545,knn_k=1:0.9041,knn_k=5:0.8897,knn_k=10:0.9133,knn_k=20:0.9914,knn_k=50:1.1463,knn_k=100:1.3708,lwr_k=20:0.7125,lwr_k=50:0.6158,lwr_k=100:0.6277,lwr_k=200:0.6282,lwr_k=500:0.6623,lwr_k=1000:0.676'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7543,knn_k=1:0.0,knn_k=5:0.5441,knn_k=10:0.7055,knn_k=20:0.8343,knn_k=50:0.9929,knn_k=100:1.151,lwr_k=20:0.0704,lwr_k=50:0.1952,lwr_k=100:0.3186,lwr_k=200:0.4348,lwr_k=500:0.5599,lwr_k=1000:0.621'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7603,knn_k=1:0.7934,knn_k=5:0.8596,knn_k=10:0.8888,knn_k=20:0.9409,knn_k=50:1.0556,knn_k=100:1.1927,lwr_k=20:0.5906,lwr_k=50:0.5828,lwr_k=100:0.584,lwr_k=200:0.6073,lwr_k=500:0.6554,lwr_k=1000:0.7079'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6989,knn_k=1:0.0,knn_k=5:0.4653,knn_k=10:0.624,knn_k=20:0.7372,knn_k=50:0.8833,knn_k=100:1.0108,lwr_k=20:0.0448,lwr_k=50:0.1459,lwr_k=100:0.2741,lwr_k=200:0.3945,lwr_k=500:0.5179,lwr_k=1000:0.5871'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7097,knn_k=1:0.6019,knn_k=5:0.7691,knn_k=10:0.766,knn_k=20:0.8075,knn_k=50:0.8781,knn_k=100:0.9973,lwr_k=20:0.5531,lwr_k=50:0.5281,lwr_k=100:0.5497,lwr_k=200:0.5918,lwr_k=500:0.6151,lwr_k=1000:0.6305'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_10'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1199,knn_k=1:0.0,knn_k=5:0.5836,knn_k=10:0.7472,knn_k=20:0.8712,knn_k=50:1.023,knn_k=100:1.1432,lwr_k=20:0.4784,lwr_k=50:0.5716,lwr_k=100:0.6352,lwr_k=200:0.6985,lwr_k=500:0.7558,lwr_k=1000:0.792'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.1576,knn_k=1:1.1088,knn_k=5:0.9003,knn_k=10:0.9377,knn_k=20:0.9833,knn_k=50:1.0787,knn_k=100:1.1816,lwr_k=20:0.7809,lwr_k=50:0.7672,lwr_k=100:0.7725,lwr_k=200:0.7755,lwr_k=500:0.7929,lwr_k=1000:0.8169'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7308,knn_k=1:0.0,knn_k=5:0.5098,knn_k=10:0.5966,knn_k=20:0.6516,knn_k=50:0.7023,knn_k=100:0.7302,lwr_k=20:0.5452,lwr_k=50:0.6075,lwr_k=100:0.6362,lwr_k=200:0.6598,lwr_k=500:0.6893,lwr_k=1000:0.7021'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8016,knn_k=1:1.2069,knn_k=5:0.8524,knn_k=10:0.8023,knn_k=20:0.7872,knn_k=50:0.7789,knn_k=100:0.7908,lwr_k=20:0.7693,lwr_k=50:0.7628,lwr_k=100:0.7504,lwr_k=200:0.751,lwr_k=500:0.7668,lwr_k=1000:0.7746'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2886,knn_k=1:0.0,knn_k=5:0.9405,knn_k=10:1.1102,knn_k=20:1.2178,knn_k=50:1.337,knn_k=100:1.4024,lwr_k=20:1.1761,lwr_k=50:1.2542,lwr_k=100:1.2807,lwr_k=200:1.2989,lwr_k=500:1.3021,lwr_k=1000:1.3044'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.3465,knn_k=1:2.1614,knn_k=5:1.4518,knn_k=10:1.4059,knn_k=20:1.392,knn_k=50:1.4387,knn_k=100:1.4826,lwr_k=20:1.3607,lwr_k=50:1.3603,lwr_k=100:1.3587,lwr_k=200:1.3658,lwr_k=500:1.3582,lwr_k=1000:1.3594'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.7415,knn_k=1:0.0,knn_k=5:1.468,knn_k=10:1.7719,knn_k=20:1.9545,knn_k=50:2.1621,knn_k=100:2.3069,lwr_k=20:1.7388,lwr_k=50:1.7983,lwr_k=100:1.813,lwr_k=200:1.8126,lwr_k=500:1.825,lwr_k=1000:1.8507'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.7694,knn_k=1:3.4554,knn_k=5:2.2414,knn_k=10:2.1785,knn_k=20:2.2017,knn_k=50:2.3403,knn_k=100:2.4413,lwr_k=20:2.0279,lwr_k=50:1.9782,lwr_k=100:1.9232,lwr_k=200:1.8859,lwr_k=500:1.8545,lwr_k=1000:1.8781'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9056,knn_k=1:0.0,knn_k=5:0.542,knn_k=10:0.6613,knn_k=20:0.7507,knn_k=50:0.8545,knn_k=100:0.943,lwr_k=20:0.3998,lwr_k=50:0.5333,lwr_k=100:0.6106,lwr_k=200:0.6664,lwr_k=500:0.7341,lwr_k=1000:0.775'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9466,knn_k=1:0.9604,knn_k=5:0.8715,knn_k=10:0.8693,knn_k=20:0.8858,knn_k=50:0.9401,knn_k=100:1.0082,lwr_k=20:0.7165,lwr_k=50:0.7451,lwr_k=100:0.7433,lwr_k=200:0.7521,lwr_k=500:0.7744,lwr_k=1000:0.7972'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7317,knn_k=1:0.0,knn_k=5:0.5543,knn_k=10:0.631,knn_k=20:0.6875,knn_k=50:0.7222,knn_k=100:0.7412,lwr_k=20:0.6822,lwr_k=50:0.7112,lwr_k=100:0.7232,lwr_k=200:0.7296,lwr_k=500:0.7336,lwr_k=1000:0.7319'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7288,knn_k=1:1.2575,knn_k=5:0.8327,knn_k=10:0.7818,knn_k=20:0.7596,knn_k=50:0.7486,knn_k=100:0.7554,lwr_k=20:0.7572,lwr_k=50:0.7387,lwr_k=100:0.737,lwr_k=200:0.7351,lwr_k=500:0.7349,lwr_k=1000:0.7298'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_11'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6481,knn_k=1:0.0,knn_k=5:0.5263,knn_k=10:0.6561,knn_k=20:0.756,knn_k=50:0.8665,knn_k=100:0.9674,lwr_k=20:0.2464,lwr_k=50:0.3913,lwr_k=100:0.4584,lwr_k=200:0.5132,lwr_k=500:0.5707,lwr_k=1000:0.605'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6802,knn_k=1:1.1145,knn_k=5:0.8421,knn_k=10:0.8518,knn_k=20:0.8875,knn_k=50:0.9551,knn_k=100:1.0531,lwr_k=20:0.7494,lwr_k=50:0.6289,lwr_k=100:0.6193,lwr_k=200:0.6133,lwr_k=500:0.628,lwr_k=1000:0.6384'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6057,knn_k=1:0.0,knn_k=5:0.3853,knn_k=10:0.4859,knn_k=20:0.5464,knn_k=50:0.6037,knn_k=100:0.6412,lwr_k=20:0.1838,lwr_k=50:0.3318,lwr_k=100:0.4162,lwr_k=200:0.4775,lwr_k=500:0.5355,lwr_k=1000:0.5665'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6494,knn_k=1:0.9372,knn_k=5:0.6718,knn_k=10:0.6456,knn_k=20:0.6475,knn_k=50:0.6668,knn_k=100:0.6982,lwr_k=20:0.7601,lwr_k=50:0.6309,lwr_k=100:0.6055,lwr_k=200:0.6154,lwr_k=500:0.6143,lwr_k=1000:0.6251'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7425,knn_k=1:0.0,knn_k=5:0.5875,knn_k=10:0.7173,knn_k=20:0.8343,knn_k=50:0.975,knn_k=100:1.0767,lwr_k=20:0.2061,lwr_k=50:0.3719,lwr_k=100:0.4686,lwr_k=200:0.5502,lwr_k=500:0.6218,lwr_k=1000:0.6748'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7801,knn_k=1:1.248,knn_k=5:0.9048,knn_k=10:0.8875,knn_k=20:0.9271,knn_k=50:1.0304,knn_k=100:1.1292,lwr_k=20:0.8039,lwr_k=50:0.6559,lwr_k=100:0.6518,lwr_k=200:0.6611,lwr_k=500:0.6962,lwr_k=1000:0.7261'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6821,knn_k=1:0.0,knn_k=5:0.5064,knn_k=10:0.6375,knn_k=20:0.7391,knn_k=50:0.851,knn_k=100:0.9403,lwr_k=20:0.2665,lwr_k=50:0.395,lwr_k=100:0.47,lwr_k=200:0.534,lwr_k=500:0.5939,lwr_k=1000:0.6387'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6752,knn_k=1:0.9662,knn_k=5:0.8035,knn_k=10:0.8093,knn_k=20:0.8397,knn_k=50:0.8979,knn_k=100:0.9713,lwr_k=20:0.6964,lwr_k=50:0.5993,lwr_k=100:0.5921,lwr_k=200:0.595,lwr_k=500:0.6064,lwr_k=1000:0.6279'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7103,knn_k=1:0.0,knn_k=5:0.4594,knn_k=10:0.5557,knn_k=20:0.6437,knn_k=50:0.7456,knn_k=100:0.8315,lwr_k=20:0.2298,lwr_k=50:0.3719,lwr_k=100:0.4558,lwr_k=200:0.5144,lwr_k=500:0.5729,lwr_k=1000:0.6109'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6795,knn_k=1:0.88,knn_k=5:0.6456,knn_k=10:0.648,knn_k=20:0.6896,knn_k=50:0.7778,knn_k=100:0.8477,lwr_k=20:0.6174,lwr_k=50:0.5672,lwr_k=100:0.5542,lwr_k=200:0.5631,lwr_k=500:0.6009,lwr_k=1000:0.6218'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.5674,knn_k=1:0.0,knn_k=5:0.3527,knn_k=10:0.4318,knn_k=20:0.4824,knn_k=50:0.5262,knn_k=100:0.5566,lwr_k=20:0.2306,lwr_k=50:0.3453,lwr_k=100:0.4149,lwr_k=200:0.464,lwr_k=500:0.5074,lwr_k=1000:0.528'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5764,knn_k=1:0.7222,knn_k=5:0.5547,knn_k=10:0.536,knn_k=20:0.542,knn_k=50:0.5486,knn_k=100:0.5652,lwr_k=20:0.5569,lwr_k=50:0.5156,lwr_k=100:0.5069,lwr_k=200:0.5109,lwr_k=500:0.5346,lwr_k=1000:0.5422'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_12'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3257,knn_k=1:0.0019,knn_k=5:0.9869,knn_k=10:1.139,knn_k=20:1.217,knn_k=50:1.2736,knn_k=100:1.3064,lwr_k=20:1.1186,lwr_k=50:1.1815,lwr_k=100:1.2137,lwr_k=200:1.2341,lwr_k=500:1.2633,lwr_k=1000:1.2809'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.4013,knn_k=1:2.4351,knn_k=5:1.525,knn_k=10:1.415,knn_k=20:1.3892,knn_k=50:1.3749,knn_k=100:1.3981,lwr_k=20:1.3725,lwr_k=50:1.3159,lwr_k=100:1.3135,lwr_k=200:1.3129,lwr_k=500:1.3244,lwr_k=1000:1.33'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7476,knn_k=1:0.2406,knn_k=5:0.5879,knn_k=10:0.6321,knn_k=20:0.6704,knn_k=50:0.6878,knn_k=100:0.699,lwr_k=20:0.603,lwr_k=50:0.6411,lwr_k=100:0.6604,lwr_k=200:0.6769,lwr_k=500:0.6896,lwr_k=1000:0.7057'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7983,knn_k=1:1.4189,knn_k=5:0.8579,knn_k=10:0.7861,knn_k=20:0.7723,knn_k=50:0.7627,knn_k=100:0.7579,lwr_k=20:0.7798,lwr_k=50:0.7623,lwr_k=100:0.7442,lwr_k=200:0.7383,lwr_k=500:0.7461,lwr_k=1000:0.7521'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3661,knn_k=1:0.2195,knn_k=5:1.0675,knn_k=10:1.1025,knn_k=20:1.1993,knn_k=50:1.2927,knn_k=100:1.3591,lwr_k=20:1.0528,lwr_k=50:1.1321,lwr_k=100:1.1783,lwr_k=200:1.2115,lwr_k=500:1.2432,lwr_k=1000:1.2697'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.4299,knn_k=1:2.0388,knn_k=5:1.484,knn_k=10:1.3452,knn_k=20:1.3197,knn_k=50:1.3583,knn_k=100:1.4094,lwr_k=20:1.2587,lwr_k=50:1.2631,lwr_k=100:1.2584,lwr_k=200:1.2642,lwr_k=500:1.2811,lwr_k=1000:1.3084'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.525,knn_k=1:0.0,knn_k=5:1.4053,knn_k=10:1.6244,knn_k=20:1.775,knn_k=50:1.9312,knn_k=100:2.0776,lwr_k=20:1.6329,lwr_k=50:1.6921,lwr_k=100:1.7293,lwr_k=200:1.7673,lwr_k=500:1.8456,lwr_k=1000:1.9514'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.5902,knn_k=1:3.2817,knn_k=5:2.0972,knn_k=10:1.9903,knn_k=20:1.9836,knn_k=50:2.0316,knn_k=100:2.1585,lwr_k=20:1.8955,lwr_k=50:1.8147,lwr_k=100:1.7997,lwr_k=200:1.8096,lwr_k=500:1.8526,lwr_k=1000:1.934'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1002,knn_k=1:0.1572,knn_k=5:0.6712,knn_k=10:0.7708,knn_k=20:0.8474,knn_k=50:0.93,knn_k=100:0.99,lwr_k=20:0.6883,lwr_k=50:0.7663,lwr_k=100:0.8116,lwr_k=200:0.8558,lwr_k=500:0.9108,lwr_k=1000:0.9602'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1046,knn_k=1:1.4835,knn_k=5:0.9128,knn_k=10:0.8717,knn_k=20:0.8693,knn_k=50:0.935,knn_k=100:0.9952,lwr_k=20:0.8229,lwr_k=50:0.8162,lwr_k=100:0.8277,lwr_k=200:0.8468,lwr_k=500:0.8912,lwr_k=1000:0.9532'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6171,knn_k=1:0.0,knn_k=5:0.4688,knn_k=10:0.5295,knn_k=20:0.5685,knn_k=50:0.5945,knn_k=100:0.6065,lwr_k=20:0.5429,lwr_k=50:0.572,lwr_k=100:0.5871,lwr_k=200:0.5988,lwr_k=500:0.6064,lwr_k=1000:0.6088'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5993,knn_k=1:1.0921,knn_k=5:0.7149,knn_k=10:0.6536,knn_k=20:0.6327,knn_k=50:0.6184,knn_k=100:0.6164,lwr_k=20:0.6296,lwr_k=50:0.6157,lwr_k=100:0.6106,lwr_k=200:0.6013,lwr_k=500:0.5982,lwr_k=1000:0.5966'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_13'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.272,knn_k=1:0.0,knn_k=5:0.7005,knn_k=10:0.8631,knn_k=20:1.0238,knn_k=50:1.2117,knn_k=100:1.3408,lwr_k=20:0.7812,lwr_k=50:0.8022,lwr_k=100:0.7939,lwr_k=200:0.7831,lwr_k=500:0.8109,lwr_k=1000:0.8781'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.3213,knn_k=1:1.4352,knn_k=5:1.0513,knn_k=10:1.0404,knn_k=20:1.1299,knn_k=50:1.2702,knn_k=100:1.3813,lwr_k=20:0.9337,lwr_k=50:0.8831,lwr_k=100:0.8323,lwr_k=200:0.811,lwr_k=500:0.8217,lwr_k=1000:0.8937'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7314,knn_k=1:0.0,knn_k=5:0.5035,knn_k=10:0.6044,knn_k=20:0.6525,knn_k=50:0.6884,knn_k=100:0.7068,lwr_k=20:0.5481,lwr_k=50:0.5974,lwr_k=100:0.6223,lwr_k=200:0.6514,lwr_k=500:0.6779,lwr_k=1000:0.6911'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7773,knn_k=1:1.2283,knn_k=5:0.7945,knn_k=10:0.7726,knn_k=20:0.761,knn_k=50:0.7604,knn_k=100:0.7678,lwr_k=20:0.7513,lwr_k=50:0.7381,lwr_k=100:0.7402,lwr_k=200:0.7377,lwr_k=500:0.7443,lwr_k=1000:0.7463'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3768,knn_k=1:0.0,knn_k=5:0.9305,knn_k=10:1.1203,knn_k=20:1.2474,knn_k=50:1.3648,knn_k=100:1.4476,lwr_k=20:1.0271,lwr_k=50:1.0385,lwr_k=100:1.0399,lwr_k=200:1.0538,lwr_k=500:1.0971,lwr_k=1000:1.1529'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.4185,knn_k=1:2.0708,knn_k=5:1.3891,knn_k=10:1.3316,knn_k=20:1.3674,knn_k=50:1.4325,knn_k=100:1.5034,lwr_k=20:1.2089,lwr_k=50:1.1291,lwr_k=100:1.094,lwr_k=200:1.0821,lwr_k=500:1.1022,lwr_k=1000:1.1664'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0915,knn_k=1:0.0,knn_k=5:0.6852,knn_k=10:0.8399,knn_k=20:0.9675,knn_k=50:1.1528,knn_k=100:1.3339,lwr_k=20:0.7317,lwr_k=50:0.7688,lwr_k=100:0.795,lwr_k=200:0.8207,lwr_k=500:0.8567,lwr_k=1000:0.958'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0205,knn_k=1:1.4536,knn_k=5:1.0296,knn_k=10:0.9959,knn_k=20:1.0435,knn_k=50:1.1807,knn_k=100:1.3665,lwr_k=20:0.8842,lwr_k=50:0.8275,lwr_k=100:0.8103,lwr_k=200:0.8137,lwr_k=500:0.8211,lwr_k=1000:0.92'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.932,knn_k=1:0.0,knn_k=5:0.6042,knn_k=10:0.6902,knn_k=20:0.7619,knn_k=50:0.8399,knn_k=100:0.8936,lwr_k=20:0.6659,lwr_k=50:0.708,lwr_k=100:0.737,lwr_k=200:0.759,lwr_k=500:0.7879,lwr_k=1000:0.8146'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9536,knn_k=1:1.4056,knn_k=5:0.924,knn_k=10:0.8665,knn_k=20:0.8736,knn_k=50:0.9026,knn_k=100:0.9378,lwr_k=20:0.8026,lwr_k=50:0.7883,lwr_k=100:0.7889,lwr_k=200:0.7992,lwr_k=500:0.8104,lwr_k=1000:0.8283'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7294,knn_k=1:0.0,knn_k=5:0.4915,knn_k=10:0.5799,knn_k=20:0.6257,knn_k=50:0.6675,knn_k=100:0.69,lwr_k=20:0.5174,lwr_k=50:0.5818,lwr_k=100:0.6087,lwr_k=200:0.633,lwr_k=500:0.6664,lwr_k=1000:0.6813'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7226,knn_k=1:1.0271,knn_k=5:0.7258,knn_k=10:0.7021,knn_k=20:0.6935,knn_k=50:0.6962,knn_k=100:0.7002,lwr_k=20:0.667,lwr_k=50:0.6517,lwr_k=100:0.6486,lwr_k=200:0.659,lwr_k=500:0.6731,lwr_k=1000:0.6833'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_14'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0405,knn_k=1:6.0822,knn_k=5:6.7052,knn_k=10:6.7308,knn_k=20:6.0563,knn_k=50:6.154,knn_k=100:6.0422,lwr_k=20:6.0563,lwr_k=50:6.154,lwr_k=100:6.0422,lwr_k=200:6.0592,lwr_k=500:6.0405,lwr_k=1000:6.0417'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.3796,knn_k=1:6.4466,knn_k=5:6.9434,knn_k=10:7.1728,knn_k=20:6.411,knn_k=50:6.5349,knn_k=100:6.3762,lwr_k=20:6.411,lwr_k=50:6.5349,lwr_k=100:6.3762,lwr_k=200:6.3814,lwr_k=500:6.3792,lwr_k=1000:6.3766'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9787,knn_k=1:6.0394,knn_k=5:7.2257,knn_k=10:8.1335,knn_k=20:6.2596,knn_k=50:6.0859,knn_k=100:6.0105,lwr_k=20:6.2596,lwr_k=50:6.0859,lwr_k=100:6.0105,lwr_k=200:5.983,lwr_k=500:5.9852,lwr_k=1000:5.9788'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0941,knn_k=1:6.1809,knn_k=5:7.459,knn_k=10:8.404,knn_k=20:6.431,knn_k=50:6.2359,knn_k=100:6.1448,lwr_k=20:6.431,lwr_k=50:6.2359,lwr_k=100:6.1448,lwr_k=200:6.1053,lwr_k=500:6.1091,lwr_k=1000:6.0931'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0502,knn_k=1:6.1165,knn_k=5:7.3221,knn_k=10:7.2611,knn_k=20:6.1739,knn_k=50:6.1193,knn_k=100:6.0732,lwr_k=20:6.1739,lwr_k=50:6.1193,lwr_k=100:6.0732,lwr_k=200:6.0535,lwr_k=500:6.0573,lwr_k=1000:6.0502'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:6.1621,knn_k=1:6.2399,knn_k=5:7.4843,knn_k=10:7.422,knn_k=20:6.3015,knn_k=50:6.2429,knn_k=100:6.1918,lwr_k=20:6.3015,lwr_k=50:6.2429,lwr_k=100:6.1918,lwr_k=200:6.1679,lwr_k=500:6.1729,lwr_k=1000:6.1619'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.126,knn_k=1:6.2153,knn_k=5:7.493,knn_k=10:7.0518,knn_k=20:6.218,knn_k=50:6.1979,knn_k=100:6.1566,lwr_k=20:6.218,lwr_k=50:6.1979,lwr_k=100:6.1566,lwr_k=200:6.1341,lwr_k=500:6.1408,lwr_k=1000:6.1273'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.8721,knn_k=1:5.8875,knn_k=5:6.9499,knn_k=10:6.56,knn_k=20:5.8891,knn_k=50:5.8777,knn_k=100:5.8595,lwr_k=20:5.8891,lwr_k=50:5.8777,lwr_k=100:5.8595,lwr_k=200:5.8579,lwr_k=500:5.8568,lwr_k=1000:5.8645'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.2115,knn_k=1:10.0682,knn_k=5:6.5531,knn_k=10:6.2155,knn_k=20:6.2119,knn_k=50:6.2337,knn_k=100:6.2308,lwr_k=20:6.2119,lwr_k=50:6.2337,lwr_k=100:6.2308,lwr_k=200:6.2164,lwr_k=500:6.2243,lwr_k=1000:6.212'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.9051,knn_k=1:9.7164,knn_k=5:6.2601,knn_k=10:5.9105,knn_k=20:5.905,knn_k=50:5.9238,knn_k=100:5.9211,lwr_k=20:5.905,lwr_k=50:5.9238,lwr_k=100:5.9211,lwr_k=200:5.9115,lwr_k=500:5.9204,lwr_k=1000:5.905'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:6.1355,knn_k=1:6.7786,knn_k=5:6.9025,knn_k=10:6.3274,knn_k=20:6.1934,knn_k=50:6.1692,knn_k=100:6.1388,lwr_k=20:6.1934,lwr_k=50:6.1692,lwr_k=100:6.1388,lwr_k=200:6.1374,lwr_k=500:6.1543,lwr_k=1000:6.136'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.8856,knn_k=1:6.5761,knn_k=5:6.7044,knn_k=10:6.1035,knn_k=20:5.9577,knn_k=50:5.9085,knn_k=100:5.8856,lwr_k=20:5.9577,lwr_k=50:5.9085,lwr_k=100:5.8856,lwr_k=200:5.885,lwr_k=500:5.8964,lwr_k=1000:5.8848'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_15'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9197,knn_k=1:0.0,knn_k=5:0.643,knn_k=10:0.8161,knn_k=20:0.9188,knn_k=50:1.0223,knn_k=100:1.118,lwr_k=20:0.4259,lwr_k=50:0.5473,lwr_k=100:0.6139,lwr_k=200:0.6647,lwr_k=500:0.7146,lwr_k=1000:0.754'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9456,knn_k=1:0.9774,knn_k=5:0.9478,knn_k=10:0.9625,knn_k=20:0.9905,knn_k=50:1.0675,knn_k=100:1.1618,lwr_k=20:0.8073,lwr_k=50:0.7356,lwr_k=100:0.7335,lwr_k=200:0.7415,lwr_k=500:0.7645,lwr_k=1000:0.7916'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.718,knn_k=1:0.0,knn_k=5:0.4264,knn_k=10:0.5336,knn_k=20:0.6131,knn_k=50:0.6833,knn_k=100:0.72,lwr_k=20:0.3505,lwr_k=50:0.4459,lwr_k=100:0.5037,lwr_k=200:0.5587,lwr_k=500:0.6063,lwr_k=1000:0.6429'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.777,knn_k=1:0.8138,knn_k=5:0.7487,knn_k=10:0.7394,knn_k=20:0.7546,knn_k=50:0.7753,knn_k=100:0.7932,lwr_k=20:0.6429,lwr_k=50:0.6474,lwr_k=100:0.6537,lwr_k=200:0.6762,lwr_k=500:0.702,lwr_k=1000:0.7186'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8746,knn_k=1:0.0,knn_k=5:0.5461,knn_k=10:0.6941,knn_k=20:0.812,knn_k=50:0.9322,knn_k=100:1.0136,lwr_k=20:0.3844,lwr_k=50:0.5066,lwr_k=100:0.581,lwr_k=200:0.6405,lwr_k=500:0.6994,lwr_k=1000:0.7445'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8733,knn_k=1:0.9484,knn_k=5:0.8299,knn_k=10:0.8311,knn_k=20:0.8782,knn_k=50:0.9676,knn_k=100:1.0427,lwr_k=20:0.6714,lwr_k=50:0.6721,lwr_k=100:0.6878,lwr_k=200:0.7021,lwr_k=500:0.7355,lwr_k=1000:0.7508'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7985,knn_k=1:0.0,knn_k=5:0.5456,knn_k=10:0.6603,knn_k=20:0.7497,knn_k=50:0.864,knn_k=100:0.9708,lwr_k=20:0.368,lwr_k=50:0.5,lwr_k=100:0.5716,lwr_k=200:0.6242,lwr_k=500:0.6832,lwr_k=1000:0.7183'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7538,knn_k=1:1.0842,knn_k=5:0.8358,knn_k=10:0.7897,knn_k=20:0.8086,knn_k=50:0.8656,knn_k=100:0.9471,lwr_k=20:0.666,lwr_k=50:0.6697,lwr_k=100:0.6588,lwr_k=200:0.6665,lwr_k=500:0.6758,lwr_k=1000:0.6957'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7809,knn_k=1:0.0,knn_k=5:0.4995,knn_k=10:0.6329,knn_k=20:0.7378,knn_k=50:0.8443,knn_k=100:0.9395,lwr_k=20:0.3864,lwr_k=50:0.4836,lwr_k=100:0.5512,lwr_k=200:0.603,lwr_k=500:0.6569,lwr_k=1000:0.6853'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7912,knn_k=1:0.894,knn_k=5:0.7659,knn_k=10:0.7718,knn_k=20:0.8112,knn_k=50:0.8859,knn_k=100:0.9788,lwr_k=20:0.6436,lwr_k=50:0.6615,lwr_k=100:0.6784,lwr_k=200:0.6889,lwr_k=500:0.7103,lwr_k=1000:0.7259'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.8136,knn_k=1:0.0,knn_k=5:0.4637,knn_k=10:0.6038,knn_k=20:0.6934,knn_k=50:0.7776,knn_k=100:0.8338,lwr_k=20:0.3766,lwr_k=50:0.4987,lwr_k=100:0.5649,lwr_k=200:0.6221,lwr_k=500:0.6806,lwr_k=1000:0.7117'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8006,knn_k=1:0.8106,knn_k=5:0.7325,knn_k=10:0.7276,knn_k=20:0.7592,knn_k=50:0.8006,knn_k=100:0.8413,lwr_k=20:0.6101,lwr_k=50:0.6311,lwr_k=100:0.6567,lwr_k=200:0.6778,lwr_k=500:0.6981,lwr_k=1000:0.696'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_16'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4848,knn_k=1:0.1134,knn_k=5:1.2184,knn_k=10:1.3419,knn_k=20:1.399,knn_k=50:1.4476,knn_k=100:1.456,lwr_k=20:1.3983,lwr_k=50:1.4475,lwr_k=100:1.4555,lwr_k=200:1.4595,lwr_k=500:1.4674,lwr_k=1000:1.4758'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.5504,knn_k=1:2.8758,knn_k=5:1.7819,knn_k=10:1.6333,knn_k=20:1.5749,knn_k=50:1.559,knn_k=100:1.5498,lwr_k=20:1.5745,lwr_k=50:1.5537,lwr_k=100:1.5459,lwr_k=200:1.5408,lwr_k=500:1.5436,lwr_k=1000:1.5487'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7569,knn_k=1:0.074,knn_k=5:0.6041,knn_k=10:0.66,knn_k=20:0.6962,knn_k=50:0.7175,knn_k=100:0.7251,lwr_k=20:0.6957,lwr_k=50:0.7163,lwr_k=100:0.7222,lwr_k=200:0.7244,lwr_k=500:0.7291,lwr_k=1000:0.7326'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8288,knn_k=1:1.4846,knn_k=5:0.9482,knn_k=10:0.8751,knn_k=20:0.8372,knn_k=50:0.8082,knn_k=100:0.8014,lwr_k=20:0.8376,lwr_k=50:0.8087,lwr_k=100:0.801,lwr_k=200:0.7965,lwr_k=500:0.8015,lwr_k=1000:0.8061'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.5225,knn_k=1:0.1368,knn_k=5:1.3027,knn_k=10:1.3901,knn_k=20:1.4273,knn_k=50:1.4669,knn_k=100:1.4844,lwr_k=20:1.4256,lwr_k=50:1.4612,lwr_k=100:1.4765,lwr_k=200:1.4864,lwr_k=500:1.495,lwr_k=1000:1.5001'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.5267,knn_k=1:2.9997,knn_k=5:1.8641,knn_k=10:1.6465,knn_k=20:1.554,knn_k=50:1.5167,knn_k=100:1.4977,lwr_k=20:1.5548,lwr_k=50:1.5178,lwr_k=100:1.4969,lwr_k=200:1.49,lwr_k=500:1.4953,lwr_k=1000:1.5029'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.6522,knn_k=1:0.2749,knn_k=5:1.7598,knn_k=10:1.9648,knn_k=20:2.0747,knn_k=50:2.1657,knn_k=100:2.2157,lwr_k=20:2.0386,lwr_k=50:2.0929,lwr_k=100:2.1111,lwr_k=200:2.135,lwr_k=500:2.1681,lwr_k=1000:2.2149'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.7496,knn_k=1:4.1851,knn_k=5:2.5397,knn_k=10:2.3499,knn_k=20:2.2586,knn_k=50:2.2774,knn_k=100:2.3235,lwr_k=20:2.2634,lwr_k=50:2.2382,lwr_k=100:2.2306,lwr_k=200:2.2132,lwr_k=500:2.2308,lwr_k=1000:2.2758'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1786,knn_k=1:0.0995,knn_k=5:0.9189,knn_k=10:1.0229,knn_k=20:1.086,knn_k=50:1.1298,knn_k=100:1.1541,lwr_k=20:1.0664,lwr_k=50:1.1038,lwr_k=100:1.1239,lwr_k=200:1.1348,lwr_k=500:1.1544,lwr_k=1000:1.1604'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2017,knn_k=1:2.3286,knn_k=5:1.4109,knn_k=10:1.29,knn_k=20:1.2447,knn_k=50:1.217,knn_k=100:1.2124,lwr_k=20:1.2342,lwr_k=50:1.1993,lwr_k=100:1.1951,lwr_k=200:1.1861,lwr_k=500:1.1886,lwr_k=1000:1.1912'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.5965,knn_k=1:0.0665,knn_k=5:0.4895,knn_k=10:0.5279,knn_k=20:0.5607,knn_k=50:0.577,knn_k=100:0.5852,lwr_k=20:0.5601,lwr_k=50:0.5756,lwr_k=100:0.5822,lwr_k=200:0.5833,lwr_k=500:0.5868,lwr_k=1000:0.5888'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6174,knn_k=1:1.2191,knn_k=5:0.7479,knn_k=10:0.6679,knn_k=20:0.6366,knn_k=50:0.6255,knn_k=100:0.6161,lwr_k=20:0.6357,lwr_k=50:0.6238,lwr_k=100:0.6143,lwr_k=200:0.6122,lwr_k=500:0.6075,lwr_k=1000:0.6039'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_17'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9175,knn_k=1:0.0,knn_k=5:0.6248,knn_k=10:0.7977,knn_k=20:0.9179,knn_k=50:1.059,knn_k=100:1.165,lwr_k=20:0.4429,lwr_k=50:0.5433,lwr_k=100:0.6006,lwr_k=200:0.6385,lwr_k=500:0.6917,lwr_k=1000:0.734'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.915,knn_k=1:1.251,knn_k=5:0.9733,knn_k=10:1.0,knn_k=20:1.0225,knn_k=50:1.1086,knn_k=100:1.1994,lwr_k=20:0.7357,lwr_k=50:0.7369,lwr_k=100:0.7341,lwr_k=200:0.7217,lwr_k=500:0.7445,lwr_k=1000:0.7737'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6418,knn_k=1:0.0,knn_k=5:0.4365,knn_k=10:0.5761,knn_k=20:0.6858,knn_k=50:0.8225,knn_k=100:0.9361,lwr_k=20:0.1253,lwr_k=50:0.2643,lwr_k=100:0.3771,lwr_k=200:0.4694,lwr_k=500:0.5473,lwr_k=1000:0.5906'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6766,knn_k=1:0.7695,knn_k=5:0.7467,knn_k=10:0.7749,knn_k=20:0.7951,knn_k=50:0.8916,knn_k=100:0.9997,lwr_k=20:0.676,lwr_k=50:0.6593,lwr_k=100:0.6622,lwr_k=200:0.658,lwr_k=500:0.6543,lwr_k=1000:0.6672'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1761,knn_k=1:0.0,knn_k=5:0.7141,knn_k=10:0.9265,knn_k=20:1.0821,knn_k=50:1.2656,knn_k=100:1.4264,lwr_k=20:0.3962,lwr_k=50:0.5193,lwr_k=100:0.6026,lwr_k=200:0.6706,lwr_k=500:0.7478,lwr_k=1000:0.8238'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.202,knn_k=1:1.3608,knn_k=5:1.146,knn_k=10:1.1846,knn_k=20:1.2223,knn_k=50:1.3708,knn_k=100:1.5047,lwr_k=20:0.8075,lwr_k=50:0.7781,lwr_k=100:0.782,lwr_k=200:0.7978,lwr_k=500:0.8456,lwr_k=1000:0.8938'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8969,knn_k=1:0.0,knn_k=5:0.5807,knn_k=10:0.7718,knn_k=20:0.9233,knn_k=50:1.1097,knn_k=100:1.2921,lwr_k=20:0.1245,lwr_k=50:0.3064,lwr_k=100:0.4472,lwr_k=200:0.5464,lwr_k=500:0.6542,lwr_k=1000:0.723'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8934,knn_k=1:0.991,knn_k=5:0.8878,knn_k=10:0.8876,knn_k=20:0.9416,knn_k=50:1.068,knn_k=100:1.2093,lwr_k=20:0.6665,lwr_k=50:0.6512,lwr_k=100:0.6603,lwr_k=200:0.672,lwr_k=500:0.7006,lwr_k=1000:0.751'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.836,knn_k=1:0.0,knn_k=5:0.5365,knn_k=10:0.6833,knn_k=20:0.8027,knn_k=50:0.9741,knn_k=100:1.1594,lwr_k=20:0.1627,lwr_k=50:0.3322,lwr_k=100:0.4592,lwr_k=200:0.5596,lwr_k=500:0.6593,lwr_k=1000:0.711'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8283,knn_k=1:0.8982,knn_k=5:0.821,knn_k=10:0.8471,knn_k=20:0.9087,knn_k=50:1.0311,knn_k=100:1.191,lwr_k=20:0.6986,lwr_k=50:0.6843,lwr_k=100:0.6856,lwr_k=200:0.6921,lwr_k=500:0.7075,lwr_k=1000:0.7341'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6351,knn_k=1:0.0,knn_k=5:0.4102,knn_k=10:0.5414,knn_k=20:0.641,knn_k=50:0.7542,knn_k=100:0.8539,lwr_k=20:0.111,lwr_k=50:0.2573,lwr_k=100:0.3822,lwr_k=200:0.4822,lwr_k=500:0.5589,lwr_k=1000:0.5934'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6637,knn_k=1:0.6897,knn_k=5:0.7016,knn_k=10:0.7093,knn_k=20:0.7315,knn_k=50:0.8099,knn_k=100:0.8949,lwr_k=20:0.6365,lwr_k=50:0.6168,lwr_k=100:0.6205,lwr_k=200:0.6125,lwr_k=500:0.6265,lwr_k=1000:0.6378'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_18'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7177,knn_k=1:0.0,knn_k=5:0.5138,knn_k=10:0.6269,knn_k=20:0.7109,knn_k=50:0.8139,knn_k=100:0.9197,lwr_k=20:0.6282,lwr_k=50:0.6519,lwr_k=100:0.658,lwr_k=200:0.6625,lwr_k=500:0.6765,lwr_k=1000:0.687'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7376,knn_k=1:1.0805,knn_k=5:0.7893,knn_k=10:0.7955,knn_k=20:0.8265,knn_k=50:0.8881,knn_k=100:0.9899,lwr_k=20:0.7737,lwr_k=50:0.7486,lwr_k=100:0.737,lwr_k=200:0.7261,lwr_k=500:0.722,lwr_k=1000:0.733'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6826,knn_k=1:0.0,knn_k=5:0.5044,knn_k=10:0.5893,knn_k=20:0.6347,knn_k=50:0.675,knn_k=100:0.6996,lwr_k=20:0.6038,lwr_k=50:0.6319,lwr_k=100:0.6439,lwr_k=200:0.6509,lwr_k=500:0.6628,lwr_k=1000:0.6731'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7299,knn_k=1:1.2042,knn_k=5:0.8188,knn_k=10:0.7678,knn_k=20:0.7487,knn_k=50:0.7437,knn_k=100:0.7552,lwr_k=20:0.7409,lwr_k=50:0.7273,lwr_k=100:0.7238,lwr_k=200:0.7224,lwr_k=500:0.7272,lwr_k=1000:0.7299'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7138,knn_k=1:0.0,knn_k=5:0.6348,knn_k=10:0.7947,knn_k=20:0.9038,knn_k=50:1.0296,knn_k=100:1.12,lwr_k=20:0.8131,lwr_k=50:0.8484,lwr_k=100:0.8386,lwr_k=200:0.8127,lwr_k=500:0.7803,lwr_k=1000:0.7711'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7619,knn_k=1:1.4425,knn_k=5:0.9816,knn_k=10:0.976,knn_k=20:1.0122,knn_k=50:1.0845,knn_k=100:1.158,lwr_k=20:0.9477,lwr_k=50:0.9231,lwr_k=100:0.8859,lwr_k=200:0.8395,lwr_k=500:0.7963,lwr_k=1000:0.7765'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7279,knn_k=1:0.0,knn_k=5:0.6043,knn_k=10:0.7219,knn_k=20:0.8209,knn_k=50:0.9682,knn_k=100:1.1111,lwr_k=20:0.7473,lwr_k=50:0.779,lwr_k=100:0.7713,lwr_k=200:0.7685,lwr_k=500:0.772,lwr_k=1000:0.7742'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6971,knn_k=1:1.3293,knn_k=5:0.8911,knn_k=10:0.8823,knn_k=20:0.9012,knn_k=50:1.0,knn_k=100:1.1299,lwr_k=20:0.8397,lwr_k=50:0.8207,lwr_k=100:0.8114,lwr_k=200:0.7975,lwr_k=500:0.811,lwr_k=1000:0.8196'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6941,knn_k=1:0.0,knn_k=5:0.5674,knn_k=10:0.6875,knn_k=20:0.7776,knn_k=50:0.8743,knn_k=100:0.9416,lwr_k=20:0.7258,lwr_k=50:0.7608,lwr_k=100:0.7629,lwr_k=200:0.7586,lwr_k=500:0.759,lwr_k=1000:0.7679'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6886,knn_k=1:1.3199,knn_k=5:0.8378,knn_k=10:0.8259,knn_k=20:0.8509,knn_k=50:0.9227,knn_k=100:0.9747,lwr_k=20:0.8135,lwr_k=50:0.8244,lwr_k=100:0.8032,lwr_k=200:0.7809,lwr_k=500:0.7793,lwr_k=1000:0.7791'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.5889,knn_k=1:0.0,knn_k=5:0.4139,knn_k=10:0.49,knn_k=20:0.5378,knn_k=50:0.5795,knn_k=100:0.6003,lwr_k=20:0.5064,lwr_k=50:0.5315,lwr_k=100:0.544,lwr_k=200:0.5537,lwr_k=500:0.5637,lwr_k=1000:0.5712'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5697,knn_k=1:0.9571,knn_k=5:0.6334,knn_k=10:0.6055,knn_k=20:0.5938,knn_k=50:0.5921,knn_k=100:0.6008,lwr_k=20:0.5803,lwr_k=50:0.5637,lwr_k=100:0.5609,lwr_k=200:0.5586,lwr_k=500:0.564,lwr_k=1000:0.5712'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_19'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3342,knn_k=1:0.1669,knn_k=5:1.0277,knn_k=10:1.1494,knn_k=20:1.2169,knn_k=50:1.2493,knn_k=100:1.2725,lwr_k=20:1.1933,lwr_k=50:1.224,lwr_k=100:1.2463,lwr_k=200:1.2621,lwr_k=500:1.2851,lwr_k=1000:1.2992'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.3942,knn_k=1:2.5387,knn_k=5:1.5616,knn_k=10:1.4475,knn_k=20:1.3893,knn_k=50:1.3543,knn_k=100:1.3553,lwr_k=20:1.3951,lwr_k=50:1.3609,lwr_k=100:1.336,lwr_k=200:1.3352,lwr_k=500:1.3361,lwr_k=1000:1.3555'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7832,knn_k=1:0.5181,knn_k=5:0.6521,knn_k=10:0.6923,knn_k=20:0.7281,knn_k=50:0.7392,knn_k=100:0.7472,lwr_k=20:0.7269,lwr_k=50:0.7373,lwr_k=100:0.744,lwr_k=200:0.7475,lwr_k=500:0.75,lwr_k=1000:0.753'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8254,knn_k=1:1.6634,knn_k=5:0.9126,knn_k=10:0.8303,knn_k=20:0.8169,knn_k=50:0.7954,knn_k=100:0.796,lwr_k=20:0.8173,lwr_k=50:0.7945,lwr_k=100:0.7932,lwr_k=200:0.786,lwr_k=500:0.7867,lwr_k=1000:0.791'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4439,knn_k=1:0.5575,knn_k=5:1.2058,knn_k=10:1.3162,knn_k=20:1.3923,knn_k=50:1.4104,knn_k=100:1.4287,lwr_k=20:1.3905,lwr_k=50:1.4062,lwr_k=100:1.4228,lwr_k=200:1.4235,lwr_k=500:1.4271,lwr_k=1000:1.4273'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.5421,knn_k=1:2.846,knn_k=5:1.7399,knn_k=10:1.6266,knn_k=20:1.6006,knn_k=50:1.5317,knn_k=100:1.5204,lwr_k=20:1.6011,lwr_k=50:1.5314,lwr_k=100:1.519,lwr_k=200:1.5156,lwr_k=500:1.5179,lwr_k=1000:1.5206'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.3212,knn_k=1:0.3827,knn_k=5:1.79,knn_k=10:1.9164,knn_k=20:2.043,knn_k=50:2.1175,knn_k=100:2.1689,lwr_k=20:1.9968,lwr_k=50:2.0463,lwr_k=100:2.071,lwr_k=200:2.0859,lwr_k=500:2.1092,lwr_k=1000:2.1352'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.3792,knn_k=1:4.2049,knn_k=5:2.5389,knn_k=10:2.3692,knn_k=20:2.304,knn_k=50:2.2685,knn_k=100:2.293,lwr_k=20:2.3061,lwr_k=50:2.2638,lwr_k=100:2.2547,lwr_k=200:2.2318,lwr_k=500:2.2285,lwr_k=1000:2.2253'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.997,knn_k=1:0.0,knn_k=5:0.742,knn_k=10:0.8398,knn_k=20:0.8952,knn_k=50:0.9435,knn_k=100:0.965,lwr_k=20:0.8738,lwr_k=50:0.9102,lwr_k=100:0.9217,lwr_k=200:0.9351,lwr_k=500:0.9471,lwr_k=1000:0.9592'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0185,knn_k=1:1.9404,knn_k=5:1.1244,knn_k=10:1.0458,knn_k=20:0.9991,knn_k=50:1.0011,knn_k=100:1.0046,lwr_k=20:0.989,lwr_k=50:0.9723,lwr_k=100:0.9592,lwr_k=200:0.9601,lwr_k=500:0.9685,lwr_k=1000:0.9783'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6568,knn_k=1:0.2392,knn_k=5:0.5617,knn_k=10:0.5916,knn_k=20:0.6208,knn_k=50:0.6387,knn_k=100:0.6445,lwr_k=20:0.6184,lwr_k=50:0.6352,lwr_k=100:0.6396,lwr_k=200:0.6429,lwr_k=500:0.6435,lwr_k=1000:0.6442'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6639,knn_k=1:1.2058,knn_k=5:0.765,knn_k=10:0.695,knn_k=20:0.6674,knn_k=50:0.6605,knn_k=100:0.6589,lwr_k=20:0.664,lwr_k=50:0.6545,lwr_k=100:0.6516,lwr_k=200:0.6509,lwr_k=500:0.6506,lwr_k=1000:0.6518'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_20'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2104,knn_k=1:0.0,knn_k=5:0.7623,knn_k=10:0.9068,knn_k=20:1.0091,knn_k=50:1.123,knn_k=100:1.1858,lwr_k=20:0.7248,lwr_k=50:0.8036,lwr_k=100:0.8459,lwr_k=200:0.8983,lwr_k=500:0.9695,lwr_k=1000:1.0263'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.2533,knn_k=1:1.4798,knn_k=5:1.1356,knn_k=10:1.1257,knn_k=20:1.1597,knn_k=50:1.21,knn_k=100:1.2595,lwr_k=20:0.9684,lwr_k=50:0.9324,lwr_k=100:0.9338,lwr_k=200:0.9625,lwr_k=500:1.0344,lwr_k=1000:1.094'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7483,knn_k=1:0.0,knn_k=5:0.5199,knn_k=10:0.6032,knn_k=20:0.6681,knn_k=50:0.7121,knn_k=100:0.7353,lwr_k=20:0.5459,lwr_k=50:0.6136,lwr_k=100:0.6495,lwr_k=200:0.6789,lwr_k=500:0.7101,lwr_k=1000:0.7249'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.795,knn_k=1:1.1689,knn_k=5:0.8496,knn_k=10:0.808,knn_k=20:0.7971,knn_k=50:0.7911,knn_k=100:0.7968,lwr_k=20:0.7787,lwr_k=50:0.7764,lwr_k=100:0.7658,lwr_k=200:0.7697,lwr_k=500:0.7807,lwr_k=1000:0.7906'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1333,knn_k=1:0.0,knn_k=5:0.7207,knn_k=10:0.8613,knn_k=20:0.964,knn_k=50:1.0601,knn_k=100:1.117,lwr_k=20:0.7788,lwr_k=50:0.842,lwr_k=100:0.8851,lwr_k=200:0.93,lwr_k=500:0.9804,lwr_k=1000:1.0072'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.168,knn_k=1:1.6664,knn_k=5:1.1308,knn_k=10:1.1057,knn_k=20:1.1133,knn_k=50:1.1309,knn_k=100:1.1546,lwr_k=20:0.9927,lwr_k=50:0.9588,lwr_k=100:0.9576,lwr_k=200:0.9687,lwr_k=500:0.9938,lwr_k=1000:1.0191'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4053,knn_k=1:0.0,knn_k=5:0.856,knn_k=10:1.0691,knn_k=20:1.2115,knn_k=50:1.3307,knn_k=100:1.4005,lwr_k=20:0.8327,lwr_k=50:0.9798,lwr_k=100:1.0624,lwr_k=200:1.1303,lwr_k=500:1.1971,lwr_k=1000:1.2427'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2979,knn_k=1:1.5304,knn_k=5:1.2465,knn_k=10:1.2601,knn_k=20:1.2719,knn_k=50:1.3006,knn_k=100:1.3379,lwr_k=20:1.0824,lwr_k=50:1.0622,lwr_k=100:1.0565,lwr_k=200:1.0777,lwr_k=500:1.1053,lwr_k=1000:1.1469'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9375,knn_k=1:0.0,knn_k=5:0.6446,knn_k=10:0.785,knn_k=20:0.8932,knn_k=50:0.9893,knn_k=100:1.0546,lwr_k=20:0.7086,lwr_k=50:0.7475,lwr_k=100:0.7723,lwr_k=200:0.7898,lwr_k=500:0.8195,lwr_k=1000:0.8425'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9825,knn_k=1:1.4565,knn_k=5:1.0413,knn_k=10:1.0111,knn_k=20:1.0355,knn_k=50:1.0853,knn_k=100:1.1244,lwr_k=20:0.9138,lwr_k=50:0.8803,lwr_k=100:0.8723,lwr_k=200:0.8731,lwr_k=500:0.8706,lwr_k=1000:0.8806'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.8,knn_k=1:0.0,knn_k=5:0.5155,knn_k=10:0.6112,knn_k=20:0.673,knn_k=50:0.7262,knn_k=100:0.7545,lwr_k=20:0.5621,lwr_k=50:0.6199,lwr_k=100:0.6577,lwr_k=200:0.6938,lwr_k=500:0.7293,lwr_k=1000:0.7479'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.78,knn_k=1:1.0986,knn_k=5:0.7646,knn_k=10:0.7353,knn_k=20:0.7305,knn_k=50:0.751,knn_k=100:0.7564,lwr_k=20:0.6849,lwr_k=50:0.6883,lwr_k=100:0.6937,lwr_k=200:0.7051,lwr_k=500:0.7264,lwr_k=1000:0.7398'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_21'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4256,knn_k=1:0.4842,knn_k=5:1.1169,knn_k=10:1.2444,knn_k=20:1.3015,knn_k=50:1.343,knn_k=100:1.3635,lwr_k=20:1.2826,lwr_k=50:1.3238,lwr_k=100:1.3451,lwr_k=200:1.3549,lwr_k=500:1.3674,lwr_k=1000:1.3751'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.4487,knn_k=1:3.14,knn_k=5:1.6801,knn_k=10:1.526,knn_k=20:1.4678,knn_k=50:1.421,knn_k=100:1.4319,lwr_k=20:1.47,lwr_k=50:1.4131,lwr_k=100:1.4165,lwr_k=200:1.4092,lwr_k=500:1.4094,lwr_k=1000:1.4099'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6984,knn_k=1:0.007,knn_k=5:0.5532,knn_k=10:0.6197,knn_k=20:0.6571,knn_k=50:0.6742,knn_k=100:0.6822,lwr_k=20:0.6493,lwr_k=50:0.6674,lwr_k=100:0.6766,lwr_k=200:0.6837,lwr_k=500:0.6881,lwr_k=1000:0.6895'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7185,knn_k=1:1.4202,knn_k=5:0.8275,knn_k=10:0.7628,knn_k=20:0.7332,knn_k=50:0.7169,knn_k=100:0.7172,lwr_k=20:0.7357,lwr_k=50:0.7195,lwr_k=100:0.7172,lwr_k=200:0.7114,lwr_k=500:0.7096,lwr_k=1000:0.7108'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.9668,knn_k=1:0.1288,knn_k=5:1.4515,knn_k=10:1.638,knn_k=20:1.7383,knn_k=50:1.8009,knn_k=100:1.8367,lwr_k=20:1.6895,lwr_k=50:1.7509,lwr_k=100:1.7867,lwr_k=200:1.8054,lwr_k=500:1.8389,lwr_k=1000:1.8665'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.0384,knn_k=1:3.6542,knn_k=5:2.2482,knn_k=10:2.0662,knn_k=20:1.9782,knn_k=50:1.9266,knn_k=100:1.9265,lwr_k=20:1.9759,lwr_k=50:1.9103,lwr_k=100:1.8951,lwr_k=200:1.8875,lwr_k=500:1.9074,lwr_k=1000:1.9351'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.514,knn_k=1:1.0286,knn_k=5:2.6307,knn_k=10:3.0069,knn_k=20:3.1906,knn_k=50:3.2923,knn_k=100:3.3458,lwr_k=20:3.1464,lwr_k=50:3.2342,lwr_k=100:3.2726,lwr_k=200:3.3091,lwr_k=500:3.3565,lwr_k=1000:3.3925'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.6531,knn_k=1:7.2527,knn_k=5:4.0896,knn_k=10:3.804,knn_k=20:3.5743,knn_k=50:3.5781,knn_k=100:3.5696,lwr_k=20:3.6075,lwr_k=50:3.5863,lwr_k=100:3.5404,lwr_k=200:3.5205,lwr_k=500:3.5152,lwr_k=1000:3.5276'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.305,knn_k=1:0.0338,knn_k=5:0.991,knn_k=10:1.0928,knn_k=20:1.1642,knn_k=50:1.2102,knn_k=100:1.2349,lwr_k=20:1.1403,lwr_k=50:1.1794,lwr_k=100:1.1998,lwr_k=200:1.2082,lwr_k=500:1.2222,lwr_k=1000:1.2394'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.3386,knn_k=1:2.41,knn_k=5:1.4413,knn_k=10:1.3469,knn_k=20:1.2917,knn_k=50:1.2672,knn_k=100:1.2709,lwr_k=20:1.2968,lwr_k=50:1.2639,lwr_k=100:1.2563,lwr_k=200:1.2545,lwr_k=500:1.2518,lwr_k=1000:1.2671'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.4995,knn_k=1:0.0025,knn_k=5:0.3956,knn_k=10:0.4479,knn_k=20:0.4721,knn_k=50:0.4861,knn_k=100:0.4928,lwr_k=20:0.4669,lwr_k=50:0.4816,lwr_k=100:0.4881,lwr_k=200:0.4911,lwr_k=500:0.4934,lwr_k=1000:0.4954'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5682,knn_k=1:1.0269,knn_k=5:0.6546,knn_k=10:0.6138,knn_k=20:0.5913,knn_k=50:0.5793,knn_k=100:0.5703,lwr_k=20:0.5929,lwr_k=50:0.5816,lwr_k=100:0.5709,lwr_k=200:0.5641,lwr_k=500:0.563,lwr_k=1000:0.5621'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_22'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1929,knn_k=1:0.1235,knn_k=5:0.8166,knn_k=10:0.9708,knn_k=20:1.0717,knn_k=50:1.1635,knn_k=100:1.2192,lwr_k=20:0.9255,lwr_k=50:0.9763,lwr_k=100:0.9981,lwr_k=200:1.0247,lwr_k=500:1.0688,lwr_k=1000:1.0947'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.2189,knn_k=1:1.7721,knn_k=5:1.2419,knn_k=10:1.1795,knn_k=20:1.1895,knn_k=50:1.2452,knn_k=100:1.2836,lwr_k=20:1.0938,lwr_k=50:1.0799,lwr_k=100:1.0715,lwr_k=200:1.0691,lwr_k=500:1.0945,lwr_k=1000:1.1198'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7988,knn_k=1:0.0304,knn_k=5:0.5366,knn_k=10:0.6303,knn_k=20:0.6876,knn_k=50:0.7367,knn_k=100:0.7606,lwr_k=20:0.5972,lwr_k=50:0.6525,lwr_k=100:0.6798,lwr_k=200:0.7029,lwr_k=500:0.73,lwr_k=1000:0.749'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8702,knn_k=1:1.2798,knn_k=5:0.8723,knn_k=10:0.817,knn_k=20:0.8204,knn_k=50:0.8107,knn_k=100:0.8206,lwr_k=20:0.7712,lwr_k=50:0.7574,lwr_k=100:0.7664,lwr_k=200:0.7694,lwr_k=500:0.7924,lwr_k=1000:0.8081'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4619,knn_k=1:0.0,knn_k=5:0.7977,knn_k=10:0.9981,knn_k=20:1.1385,knn_k=50:1.2893,knn_k=100:1.4319,lwr_k=20:0.7173,lwr_k=50:0.8812,lwr_k=100:0.96,lwr_k=200:1.0335,lwr_k=500:1.1511,lwr_k=1000:1.2463'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.5189,knn_k=1:1.6163,knn_k=5:1.2653,knn_k=10:1.267,knn_k=20:1.2874,knn_k=50:1.3774,knn_k=100:1.5045,lwr_k=20:1.091,lwr_k=50:1.0873,lwr_k=100:1.1034,lwr_k=200:1.137,lwr_k=500:1.2198,lwr_k=1000:1.305'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4827,knn_k=1:0.0,knn_k=5:0.8054,knn_k=10:1.0049,knn_k=20:1.1617,knn_k=50:1.3672,knn_k=100:1.5059,lwr_k=20:0.8243,lwr_k=50:0.8662,lwr_k=100:0.894,lwr_k=200:0.9149,lwr_k=500:0.945,lwr_k=1000:0.9931'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.4911,knn_k=1:1.7549,knn_k=5:1.2598,knn_k=10:1.2445,knn_k=20:1.2798,knn_k=50:1.4061,knn_k=100:1.5248,lwr_k=20:1.0162,lwr_k=50:0.9448,lwr_k=100:0.9141,lwr_k=200:0.8965,lwr_k=500:0.8958,lwr_k=1000:0.9402'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9932,knn_k=1:0.0,knn_k=5:0.5655,knn_k=10:0.7187,knn_k=20:0.8155,knn_k=50:0.9184,knn_k=100:1.0042,lwr_k=20:0.547,lwr_k=50:0.6697,lwr_k=100:0.7344,lwr_k=200:0.7805,lwr_k=500:0.8372,lwr_k=1000:0.8752'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0028,knn_k=1:1.1688,knn_k=5:0.9492,knn_k=10:0.938,knn_k=20:0.9411,knn_k=50:0.9871,knn_k=100:1.0478,lwr_k=20:0.8157,lwr_k=50:0.8021,lwr_k=100:0.8069,lwr_k=200:0.8142,lwr_k=500:0.8571,lwr_k=1000:0.8898'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7405,knn_k=1:0.0,knn_k=5:0.504,knn_k=10:0.5948,knn_k=20:0.6555,knn_k=50:0.6993,knn_k=100:0.7181,lwr_k=20:0.5655,lwr_k=50:0.6143,lwr_k=100:0.648,lwr_k=200:0.6736,lwr_k=500:0.6947,lwr_k=1000:0.7083'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7259,knn_k=1:1.108,knn_k=5:0.7576,knn_k=10:0.719,knn_k=20:0.7057,knn_k=50:0.7027,knn_k=100:0.7091,lwr_k=20:0.6782,lwr_k=50:0.6689,lwr_k=100:0.659,lwr_k=200:0.6636,lwr_k=500:0.6816,lwr_k=1000:0.6921'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_23'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9329,knn_k=1:0.0,knn_k=5:0.4925,knn_k=10:0.6637,knn_k=20:0.802,knn_k=50:0.9738,knn_k=100:1.1199,lwr_k=20:0.2498,lwr_k=50:0.406,lwr_k=100:0.4979,lwr_k=200:0.5782,lwr_k=500:0.6654,lwr_k=1000:0.7293'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9339,knn_k=1:0.8005,knn_k=5:0.7871,knn_k=10:0.8238,knn_k=20:0.8961,knn_k=50:1.0156,knn_k=100:1.1532,lwr_k=20:0.6371,lwr_k=50:0.6517,lwr_k=100:0.6535,lwr_k=200:0.6811,lwr_k=500:0.737,lwr_k=1000:0.7838'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6859,knn_k=1:0.0,knn_k=5:0.4771,knn_k=10:0.5832,knn_k=20:0.6699,knn_k=50:0.7721,knn_k=100:0.8619,lwr_k=20:0.2361,lwr_k=50:0.3977,lwr_k=100:0.4805,lwr_k=200:0.5467,lwr_k=500:0.6003,lwr_k=1000:0.6292'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7565,knn_k=1:0.8618,knn_k=5:0.8058,knn_k=10:0.817,knn_k=20:0.84,knn_k=50:0.895,knn_k=100:0.9697,lwr_k=20:0.6818,lwr_k=50:0.6579,lwr_k=100:0.6729,lwr_k=200:0.674,lwr_k=500:0.6854,lwr_k=1000:0.7089'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2294,knn_k=1:0.0,knn_k=5:0.6977,knn_k=10:0.9014,knn_k=20:1.0687,knn_k=50:1.2885,knn_k=100:1.4709,lwr_k=20:0.3054,lwr_k=50:0.4824,lwr_k=100:0.5967,lwr_k=200:0.7005,lwr_k=500:0.8316,lwr_k=1000:0.9262'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.3001,knn_k=1:1.3147,knn_k=5:1.0938,knn_k=10:1.1386,knn_k=20:1.1984,knn_k=50:1.3433,knn_k=100:1.4987,lwr_k=20:0.8912,lwr_k=50:0.8178,lwr_k=100:0.8215,lwr_k=200:0.8458,lwr_k=500:0.9039,lwr_k=1000:0.9667'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.6325,knn_k=1:0.0,knn_k=5:1.1638,knn_k=10:1.4783,knn_k=20:1.7016,knn_k=50:1.9319,knn_k=100:2.0946,lwr_k=20:0.9665,lwr_k=50:0.9794,lwr_k=100:0.9985,lwr_k=200:1.0349,lwr_k=500:1.1016,lwr_k=1000:1.1761'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.637,knn_k=1:2.4617,knn_k=5:1.8409,knn_k=10:1.8267,knn_k=20:1.9251,knn_k=50:2.0855,knn_k=100:2.2043,lwr_k=20:1.2888,lwr_k=50:1.1374,lwr_k=100:1.0792,lwr_k=200:1.0597,lwr_k=500:1.1126,lwr_k=1000:1.1893'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8188,knn_k=1:0.0,knn_k=5:0.4793,knn_k=10:0.5884,knn_k=20:0.6642,knn_k=50:0.7372,knn_k=100:0.7961,lwr_k=20:0.4041,lwr_k=50:0.5065,lwr_k=100:0.5593,lwr_k=200:0.6086,lwr_k=500:0.6582,lwr_k=1000:0.6963'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8229,knn_k=1:0.9159,knn_k=5:0.7257,knn_k=10:0.7338,knn_k=20:0.7498,knn_k=50:0.7757,knn_k=100:0.8274,lwr_k=20:0.6351,lwr_k=50:0.6295,lwr_k=100:0.6459,lwr_k=200:0.6634,lwr_k=500:0.6854,lwr_k=1000:0.7068'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.637,knn_k=1:0.0,knn_k=5:0.4202,knn_k=10:0.5135,knn_k=20:0.5818,knn_k=50:0.6371,knn_k=100:0.6748,lwr_k=20:0.4135,lwr_k=50:0.4966,lwr_k=100:0.5361,lwr_k=200:0.569,lwr_k=500:0.6,lwr_k=1000:0.6118'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6562,knn_k=1:0.8668,knn_k=5:0.6751,knn_k=10:0.6453,knn_k=20:0.6556,knn_k=50:0.6798,knn_k=100:0.703,lwr_k=20:0.6072,lwr_k=50:0.6051,lwr_k=100:0.593,lwr_k=200:0.6076,lwr_k=500:0.6278,lwr_k=1000:0.6331'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_24'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.5797,knn_k=1:0.0,knn_k=5:1.1516,knn_k=10:1.3286,knn_k=20:1.4216,knn_k=50:1.4946,knn_k=100:1.537,lwr_k=20:1.4124,lwr_k=50:1.4674,lwr_k=100:1.492,lwr_k=200:1.4977,lwr_k=500:1.5051,lwr_k=1000:1.5327'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.6548,knn_k=1:2.7996,knn_k=5:1.8245,knn_k=10:1.701,knn_k=20:1.6347,knn_k=50:1.6479,knn_k=100:1.6449,lwr_k=20:1.6272,lwr_k=50:1.6178,lwr_k=100:1.5919,lwr_k=200:1.5864,lwr_k=500:1.5957,lwr_k=1000:1.6213'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.684,knn_k=1:0.0,knn_k=5:0.5386,knn_k=10:0.6114,knn_k=20:0.6385,knn_k=50:0.664,knn_k=100:0.6747,lwr_k=20:0.6348,lwr_k=50:0.6559,lwr_k=100:0.6651,lwr_k=200:0.6684,lwr_k=500:0.6729,lwr_k=1000:0.6763'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7289,knn_k=1:1.3757,knn_k=5:0.8278,knn_k=10:0.7786,knn_k=20:0.7487,knn_k=50:0.7288,knn_k=100:0.7297,lwr_k=20:0.748,lwr_k=50:0.7272,lwr_k=100:0.7247,lwr_k=200:0.7212,lwr_k=500:0.7198,lwr_k=1000:0.72'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.5476,knn_k=1:0.0,knn_k=5:1.1256,knn_k=10:1.2674,knn_k=20:1.3473,knn_k=50:1.4155,knn_k=100:1.442,lwr_k=20:1.3397,lwr_k=50:1.3996,lwr_k=100:1.4214,lwr_k=200:1.4331,lwr_k=500:1.4422,lwr_k=1000:1.4473'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.6521,knn_k=1:2.9561,knn_k=5:1.7541,knn_k=10:1.6244,knn_k=20:1.5671,knn_k=50:1.5266,knn_k=100:1.5155,lwr_k=20:1.567,lwr_k=50:1.5233,lwr_k=100:1.5089,lwr_k=200:1.5066,lwr_k=500:1.5066,lwr_k=1000:1.5097'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.7659,knn_k=1:0.0,knn_k=5:2.0888,knn_k=10:2.3557,knn_k=20:2.5076,knn_k=50:2.6218,knn_k=100:2.6944,lwr_k=20:2.4973,lwr_k=50:2.5859,lwr_k=100:2.6324,lwr_k=200:2.6496,lwr_k=500:2.6811,lwr_k=1000:2.7092'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.8779,knn_k=1:5.0036,knn_k=5:3.1555,knn_k=10:2.9978,knn_k=20:2.8708,knn_k=50:2.8455,knn_k=100:2.86,lwr_k=20:2.8648,lwr_k=50:2.816,lwr_k=100:2.7957,lwr_k=200:2.7957,lwr_k=500:2.8062,lwr_k=1000:2.8181'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3263,knn_k=1:0.0,knn_k=5:0.8704,knn_k=10:1.0079,knn_k=20:1.1109,knn_k=50:1.2291,knn_k=100:1.2756,lwr_k=20:1.0884,lwr_k=50:1.1806,lwr_k=100:1.1999,lwr_k=200:1.1974,lwr_k=500:1.1886,lwr_k=1000:1.195'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.3659,knn_k=1:2.1538,knn_k=5:1.3672,knn_k=10:1.2741,knn_k=20:1.2669,knn_k=50:1.3156,knn_k=100:1.3505,lwr_k=20:1.2395,lwr_k=50:1.2567,lwr_k=100:1.2607,lwr_k=200:1.2477,lwr_k=500:1.2126,lwr_k=1000:1.2218'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7951,knn_k=1:0.0,knn_k=5:0.544,knn_k=10:0.6158,knn_k=20:0.6538,knn_k=50:0.6737,knn_k=100:0.6848,lwr_k=20:0.651,lwr_k=50:0.6679,lwr_k=100:0.6771,lwr_k=200:0.6853,lwr_k=500:0.7025,lwr_k=1000:0.7269'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.785,knn_k=1:1.4113,knn_k=5:0.8311,knn_k=10:0.7432,knn_k=20:0.7105,knn_k=50:0.6962,knn_k=100:0.6922,lwr_k=20:0.7066,lwr_k=50:0.6912,lwr_k=100:0.6842,lwr_k=200:0.6806,lwr_k=500:0.6946,lwr_k=1000:0.7167'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_25'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9087,knn_k=1:0.0,knn_k=5:0.6509,knn_k=10:0.7968,knn_k=20:0.9246,knn_k=50:1.0804,knn_k=100:1.2144,lwr_k=20:0.779,lwr_k=50:0.8011,lwr_k=100:0.806,lwr_k=200:0.8086,lwr_k=500:0.8186,lwr_k=1000:0.8247'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9331,knn_k=1:1.3878,knn_k=5:1.022,knn_k=10:1.0249,knn_k=20:1.0658,knn_k=50:1.1792,knn_k=100:1.3066,lwr_k=20:0.9696,lwr_k=50:0.9403,lwr_k=100:0.9124,lwr_k=200:0.8855,lwr_k=500:0.8739,lwr_k=1000:0.8691'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6718,knn_k=1:0.0,knn_k=5:0.4852,knn_k=10:0.5712,knn_k=20:0.6202,knn_k=50:0.653,knn_k=100:0.6695,lwr_k=20:0.5644,lwr_k=50:0.5942,lwr_k=100:0.6167,lwr_k=200:0.6361,lwr_k=500:0.6495,lwr_k=1000:0.658'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7118,knn_k=1:1.1896,knn_k=5:0.8272,knn_k=10:0.7806,knn_k=20:0.7519,knn_k=50:0.728,knn_k=100:0.7198,lwr_k=20:0.7457,lwr_k=50:0.7259,lwr_k=100:0.7178,lwr_k=200:0.7168,lwr_k=500:0.7153,lwr_k=1000:0.7141'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.012,knn_k=1:0.0,knn_k=5:0.7228,knn_k=10:0.8885,knn_k=20:1.0356,knn_k=50:1.2041,knn_k=100:1.3234,lwr_k=20:0.8577,lwr_k=50:0.8851,lwr_k=100:0.884,lwr_k=200:0.8983,lwr_k=500:0.9218,lwr_k=1000:0.93'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0159,knn_k=1:1.526,knn_k=5:1.0566,knn_k=10:1.0583,knn_k=20:1.1408,knn_k=50:1.2691,knn_k=100:1.3761,lwr_k=20:1.0032,lwr_k=50:0.9732,lwr_k=100:0.9439,lwr_k=200:0.9286,lwr_k=500:0.9378,lwr_k=1000:0.9361'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0582,knn_k=1:0.0,knn_k=5:0.6692,knn_k=10:0.7932,knn_k=20:0.9116,knn_k=50:1.0915,knn_k=100:1.3197,lwr_k=20:0.7536,lwr_k=50:0.7893,lwr_k=100:0.8053,lwr_k=200:0.8247,lwr_k=500:0.8569,lwr_k=1000:0.8905'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0317,knn_k=1:1.4088,knn_k=5:1.0093,knn_k=10:0.9653,knn_k=20:0.9919,knn_k=50:1.1176,knn_k=100:1.3463,lwr_k=20:0.8795,lwr_k=50:0.8472,lwr_k=100:0.832,lwr_k=200:0.8354,lwr_k=500:0.8461,lwr_k=1000:0.8606'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9219,knn_k=1:0.0,knn_k=5:0.6159,knn_k=10:0.7379,knn_k=20:0.8238,knn_k=50:0.9354,knn_k=100:1.0241,lwr_k=20:0.7187,lwr_k=50:0.7578,lwr_k=100:0.7808,lwr_k=200:0.8052,lwr_k=500:0.8311,lwr_k=1000:0.846'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9024,knn_k=1:1.4477,knn_k=5:0.9613,knn_k=10:0.9138,knn_k=20:0.9381,knn_k=50:0.9939,knn_k=100:1.0659,lwr_k=20:0.8747,lwr_k=50:0.8606,lwr_k=100:0.8506,lwr_k=200:0.8444,lwr_k=500:0.8542,lwr_k=1000:0.8513'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7914,knn_k=1:0.0,knn_k=5:0.5202,knn_k=10:0.6294,knn_k=20:0.6901,knn_k=50:0.732,knn_k=100:0.7564,lwr_k=20:0.6224,lwr_k=50:0.6522,lwr_k=100:0.6753,lwr_k=200:0.6988,lwr_k=500:0.7238,lwr_k=1000:0.7373'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.789,knn_k=1:1.0844,knn_k=5:0.767,knn_k=10:0.7459,knn_k=20:0.7365,knn_k=50:0.7597,knn_k=100:0.7694,lwr_k=20:0.7077,lwr_k=50:0.715,lwr_k=100:0.7115,lwr_k=200:0.7263,lwr_k=500:0.728,lwr_k=1000:0.7342'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_26'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4379,knn_k=1:0.0,knn_k=5:1.0441,knn_k=10:1.2,knn_k=20:1.2864,knn_k=50:1.3658,knn_k=100:1.4128,lwr_k=20:1.1789,lwr_k=50:1.2459,lwr_k=100:1.2819,lwr_k=200:1.3037,lwr_k=500:1.336,lwr_k=1000:1.3622'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.5312,knn_k=1:2.5559,knn_k=5:1.6597,knn_k=10:1.5415,knn_k=20:1.5109,knn_k=50:1.5053,knn_k=100:1.5351,lwr_k=20:1.4727,lwr_k=50:1.4325,lwr_k=100:1.4151,lwr_k=200:1.4156,lwr_k=500:1.4287,lwr_k=1000:1.4429'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6488,knn_k=1:0.0,knn_k=5:0.4861,knn_k=10:0.5668,knn_k=20:0.5967,knn_k=50:0.6394,knn_k=100:0.6686,lwr_k=20:0.5632,lwr_k=50:0.6018,lwr_k=100:0.6163,lwr_k=200:0.6274,lwr_k=500:0.6348,lwr_k=1000:0.6386'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6874,knn_k=1:1.3041,knn_k=5:0.7915,knn_k=10:0.7339,knn_k=20:0.6996,knn_k=50:0.697,knn_k=100:0.7151,lwr_k=20:0.7107,lwr_k=50:0.6862,lwr_k=100:0.6761,lwr_k=200:0.6726,lwr_k=500:0.6703,lwr_k=1000:0.6738'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.5708,knn_k=1:0.0,knn_k=5:1.2349,knn_k=10:1.404,knn_k=20:1.4695,knn_k=50:1.5205,knn_k=100:1.5378,lwr_k=20:1.4552,lwr_k=50:1.5068,lwr_k=100:1.5234,lwr_k=200:1.5342,lwr_k=500:1.5409,lwr_k=1000:1.5425'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.6371,knn_k=1:3.1676,knn_k=5:1.9412,knn_k=10:1.7783,knn_k=20:1.685,knn_k=50:1.6409,knn_k=100:1.625,lwr_k=20:1.6856,lwr_k=50:1.6375,lwr_k=100:1.6183,lwr_k=200:1.6066,lwr_k=500:1.5984,lwr_k=1000:1.6028'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.5394,knn_k=1:0.0,knn_k=5:1.2621,knn_k=10:1.4643,knn_k=20:1.6114,knn_k=50:1.7371,knn_k=100:1.8514,lwr_k=20:1.4425,lwr_k=50:1.5428,lwr_k=100:1.5975,lwr_k=200:1.6418,lwr_k=500:1.711,lwr_k=1000:1.7979'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.9258,knn_k=1:3.1134,knn_k=5:1.994,knn_k=10:1.8934,knn_k=20:1.8078,knn_k=50:1.8315,knn_k=100:1.8959,lwr_k=20:1.717,lwr_k=50:1.6633,lwr_k=100:1.6413,lwr_k=200:1.6818,lwr_k=500:1.7288,lwr_k=1000:1.7954'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2121,knn_k=1:0.0005,knn_k=5:0.8417,knn_k=10:0.9679,knn_k=20:1.0439,knn_k=50:1.09,knn_k=100:1.1195,lwr_k=20:0.9789,lwr_k=50:1.0344,lwr_k=100:1.057,lwr_k=200:1.079,lwr_k=500:1.1042,lwr_k=1000:1.1242'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2296,knn_k=1:2.0898,knn_k=5:1.2841,knn_k=10:1.1933,knn_k=20:1.1449,knn_k=50:1.1475,knn_k=100:1.1665,lwr_k=20:1.1556,lwr_k=50:1.1226,lwr_k=100:1.1317,lwr_k=200:1.135,lwr_k=500:1.1457,lwr_k=1000:1.1601'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.4902,knn_k=1:0.0198,knn_k=5:0.3907,knn_k=10:0.4349,knn_k=20:0.4595,knn_k=50:0.4781,knn_k=100:0.4858,lwr_k=20:0.4583,lwr_k=50:0.4767,lwr_k=100:0.4826,lwr_k=200:0.4851,lwr_k=500:0.4857,lwr_k=1000:0.4866'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5838,knn_k=1:1.0552,knn_k=5:0.6525,knn_k=10:0.6132,knn_k=20:0.5906,knn_k=50:0.5718,knn_k=100:0.5677,lwr_k=20:0.5905,lwr_k=50:0.5714,lwr_k=100:0.566,lwr_k=200:0.5662,lwr_k=500:0.5653,lwr_k=1000:0.5648'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_27'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9944,knn_k=1:0.0,knn_k=5:0.7497,knn_k=10:0.9348,knn_k=20:1.1019,knn_k=50:1.2811,knn_k=100:1.3948,lwr_k=20:0.9388,lwr_k=50:0.9732,lwr_k=100:0.976,lwr_k=200:0.965,lwr_k=500:0.9508,lwr_k=1000:0.9431'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.09,knn_k=1:1.6372,knn_k=5:1.1859,knn_k=10:1.207,knn_k=20:1.2955,knn_k=50:1.427,knn_k=100:1.527,lwr_k=20:1.1693,lwr_k=50:1.1403,lwr_k=100:1.1195,lwr_k=200:1.0874,lwr_k=500:1.0385,lwr_k=1000:1.02'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7037,knn_k=1:0.0045,knn_k=5:0.5455,knn_k=10:0.6228,knn_k=20:0.6648,knn_k=50:0.6909,knn_k=100:0.7023,lwr_k=20:0.6445,lwr_k=50:0.6668,lwr_k=100:0.6752,lwr_k=200:0.6798,lwr_k=500:0.6865,lwr_k=1000:0.6947'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7383,knn_k=1:1.4007,knn_k=5:0.8567,knn_k=10:0.797,knn_k=20:0.7642,knn_k=50:0.7561,knn_k=100:0.7498,lwr_k=20:0.7625,lwr_k=50:0.7532,lwr_k=100:0.7438,lwr_k=200:0.7422,lwr_k=500:0.7404,lwr_k=1000:0.7402'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1708,knn_k=1:0.0,knn_k=5:0.8217,knn_k=10:1.0133,knn_k=20:1.1556,knn_k=50:1.2879,knn_k=100:1.3792,lwr_k=20:1.0038,lwr_k=50:1.0368,lwr_k=100:1.0429,lwr_k=200:1.035,lwr_k=500:1.0327,lwr_k=1000:1.036'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2104,knn_k=1:1.7961,knn_k=5:1.2624,knn_k=10:1.2379,knn_k=20:1.2831,knn_k=50:1.3636,knn_k=100:1.4348,lwr_k=20:1.1809,lwr_k=50:1.1551,lwr_k=100:1.1213,lwr_k=200:1.0938,lwr_k=500:1.0738,lwr_k=1000:1.0667'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.6927,knn_k=1:0.0,knn_k=5:0.9566,knn_k=10:1.2223,knn_k=20:1.4589,knn_k=50:1.8408,knn_k=100:2.1863,lwr_k=20:1.2293,lwr_k=50:1.2656,lwr_k=100:1.2263,lwr_k=200:1.1951,lwr_k=500:1.2017,lwr_k=1000:1.2369'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.6539,knn_k=1:2.1268,knn_k=5:1.4659,knn_k=10:1.466,knn_k=20:1.6017,knn_k=50:1.8995,knn_k=100:2.2048,lwr_k=20:1.418,lwr_k=50:1.3758,lwr_k=100:1.2771,lwr_k=200:1.2141,lwr_k=500:1.1852,lwr_k=1000:1.2037'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8766,knn_k=1:0.0,knn_k=5:0.6634,knn_k=10:0.8032,knn_k=20:0.9078,knn_k=50:0.9918,knn_k=100:1.0526,lwr_k=20:0.8307,lwr_k=50:0.8526,lwr_k=100:0.8575,lwr_k=200:0.8556,lwr_k=500:0.8441,lwr_k=1000:0.837'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9009,knn_k=1:1.5114,knn_k=5:1.0447,knn_k=10:1.0275,knn_k=20:1.0367,knn_k=50:1.0865,knn_k=100:1.1297,lwr_k=20:0.9802,lwr_k=50:0.9663,lwr_k=100:0.9434,lwr_k=200:0.9186,lwr_k=500:0.8844,lwr_k=1000:0.8608'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6761,knn_k=1:0.0,knn_k=5:0.4946,knn_k=10:0.5753,knn_k=20:0.6218,knn_k=50:0.6599,knn_k=100:0.6858,lwr_k=20:0.5841,lwr_k=50:0.6052,lwr_k=100:0.6161,lwr_k=200:0.6273,lwr_k=500:0.643,lwr_k=1000:0.6526'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6908,knn_k=1:1.1714,knn_k=5:0.7462,knn_k=10:0.6925,knn_k=20:0.6852,knn_k=50:0.6989,knn_k=100:0.7112,lwr_k=20:0.675,lwr_k=50:0.6825,lwr_k=100:0.6805,lwr_k=200:0.6719,lwr_k=500:0.6649,lwr_k=1000:0.6633'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_28'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4015,knn_k=1:0.0,knn_k=5:1.0379,knn_k=10:1.1759,knn_k=20:1.2467,knn_k=50:1.3126,knn_k=100:1.3648,lwr_k=20:1.2147,lwr_k=50:1.2673,lwr_k=100:1.2934,lwr_k=200:1.3133,lwr_k=500:1.3382,lwr_k=1000:1.3554'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.4577,knn_k=1:2.5273,knn_k=5:1.5755,knn_k=10:1.4774,knn_k=20:1.4218,knn_k=50:1.4183,knn_k=100:1.4501,lwr_k=20:1.41,lwr_k=50:1.3656,lwr_k=100:1.3634,lwr_k=200:1.3693,lwr_k=500:1.3935,lwr_k=1000:1.407'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8062,knn_k=1:0.0,knn_k=5:0.6118,knn_k=10:0.6957,knn_k=20:0.7283,knn_k=50:0.7597,knn_k=100:0.777,lwr_k=20:0.7132,lwr_k=50:0.7434,lwr_k=100:0.7606,lwr_k=200:0.7723,lwr_k=500:0.781,lwr_k=1000:0.786'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8597,knn_k=1:1.5752,knn_k=5:0.9489,knn_k=10:0.9054,knn_k=20:0.86,knn_k=50:0.8411,knn_k=100:0.8469,lwr_k=20:0.8585,lwr_k=50:0.84,lwr_k=100:0.8344,lwr_k=200:0.8407,lwr_k=500:0.8449,lwr_k=1000:0.8497'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4186,knn_k=1:0.0,knn_k=5:0.996,knn_k=10:1.1377,knn_k=20:1.1971,knn_k=50:1.2584,knn_k=100:1.2929,lwr_k=20:1.1649,lwr_k=50:1.2134,lwr_k=100:1.2409,lwr_k=200:1.2629,lwr_k=500:1.2779,lwr_k=1000:1.2912'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.4946,knn_k=1:2.5484,knn_k=5:1.5402,knn_k=10:1.4041,knn_k=20:1.3767,knn_k=50:1.36,knn_k=100:1.3761,lwr_k=20:1.3651,lwr_k=50:1.3307,lwr_k=100:1.332,lwr_k=200:1.3443,lwr_k=500:1.3514,lwr_k=1000:1.3578'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.5972,knn_k=1:0.0,knn_k=5:1.9024,knn_k=10:2.2089,knn_k=20:2.317,knn_k=50:2.4043,knn_k=100:2.4494,lwr_k=20:2.2772,lwr_k=50:2.3702,lwr_k=100:2.4061,lwr_k=200:2.4254,lwr_k=500:2.4546,lwr_k=1000:2.4722'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.7169,knn_k=1:4.5683,knn_k=5:2.8714,knn_k=10:2.7338,knn_k=20:2.6562,knn_k=50:2.6102,knn_k=100:2.5832,lwr_k=20:2.6562,lwr_k=50:2.5989,lwr_k=100:2.579,lwr_k=200:2.5801,lwr_k=500:2.5843,lwr_k=1000:2.5893'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1349,knn_k=1:0.0,knn_k=5:0.8121,knn_k=10:0.9341,knn_k=20:1.0037,knn_k=50:1.0576,knn_k=100:1.0892,lwr_k=20:0.9737,lwr_k=50:1.0201,lwr_k=100:1.0455,lwr_k=200:1.0614,lwr_k=500:1.0788,lwr_k=1000:1.091'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1444,knn_k=1:2.0549,knn_k=5:1.3052,knn_k=10:1.1967,knn_k=20:1.1566,knn_k=50:1.1221,knn_k=100:1.1214,lwr_k=20:1.1393,lwr_k=50:1.1008,lwr_k=100:1.0937,lwr_k=200:1.0977,lwr_k=500:1.0986,lwr_k=1000:1.1029'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:1.1364,knn_k=1:0.0,knn_k=5:0.8515,knn_k=10:0.973,knn_k=20:1.0298,knn_k=50:1.0757,knn_k=100:1.0965,lwr_k=20:1.0114,lwr_k=50:1.0505,lwr_k=100:1.0715,lwr_k=200:1.0872,lwr_k=500:1.1018,lwr_k=1000:1.1134'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.124,knn_k=1:2.0865,knn_k=5:1.24,knn_k=10:1.1505,knn_k=20:1.0971,knn_k=50:1.0957,knn_k=100:1.0984,lwr_k=20:1.0985,lwr_k=50:1.0868,lwr_k=100:1.081,lwr_k=200:1.0795,lwr_k=500:1.0952,lwr_k=1000:1.1096'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_29'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.815,knn_k=1:0.0,knn_k=5:0.5197,knn_k=10:0.6491,knn_k=20:0.7485,knn_k=50:0.8671,knn_k=100:0.9659,lwr_k=20:0.4416,lwr_k=50:0.5218,lwr_k=100:0.5673,lwr_k=200:0.6098,lwr_k=500:0.6645,lwr_k=1000:0.7055'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8118,knn_k=1:1.0379,knn_k=5:0.7982,knn_k=10:0.8236,knn_k=20:0.853,knn_k=50:0.9268,knn_k=100:1.0234,lwr_k=20:0.6818,lwr_k=50:0.6812,lwr_k=100:0.6827,lwr_k=200:0.6958,lwr_k=500:0.7112,lwr_k=1000:0.7331'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6445,knn_k=1:0.0,knn_k=5:0.4118,knn_k=10:0.5213,knn_k=20:0.5866,knn_k=50:0.633,knn_k=100:0.6545,lwr_k=20:0.351,lwr_k=50:0.4362,lwr_k=100:0.4885,lwr_k=200:0.5343,lwr_k=500:0.5809,lwr_k=1000:0.6082'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6835,knn_k=1:0.7936,knn_k=5:0.681,knn_k=10:0.6902,knn_k=20:0.7006,knn_k=50:0.7047,knn_k=100:0.7044,lwr_k=20:0.618,lwr_k=50:0.6332,lwr_k=100:0.6529,lwr_k=200:0.6563,lwr_k=500:0.661,lwr_k=1000:0.6744'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8666,knn_k=1:0.0,knn_k=5:0.5729,knn_k=10:0.7181,knn_k=20:0.8155,knn_k=50:0.9277,knn_k=100:1.0124,lwr_k=20:0.4969,lwr_k=50:0.5641,lwr_k=100:0.6118,lwr_k=200:0.6611,lwr_k=500:0.7176,lwr_k=1000:0.7563'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8758,knn_k=1:1.1792,knn_k=5:0.8902,knn_k=10:0.8823,knn_k=20:0.9151,knn_k=50:0.9875,knn_k=100:1.0596,lwr_k=20:0.7423,lwr_k=50:0.7379,lwr_k=100:0.7492,lwr_k=200:0.747,lwr_k=500:0.7785,lwr_k=1000:0.7884'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8486,knn_k=1:0.0,knn_k=5:0.5369,knn_k=10:0.6569,knn_k=20:0.7591,knn_k=50:0.8654,knn_k=100:0.9495,lwr_k=20:0.4325,lwr_k=50:0.5188,lwr_k=100:0.584,lwr_k=200:0.634,lwr_k=500:0.6948,lwr_k=1000:0.7319'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7845,knn_k=1:0.9067,knn_k=5:0.7954,knn_k=10:0.8136,knn_k=20:0.8207,knn_k=50:0.8559,knn_k=100:0.9243,lwr_k=20:0.6853,lwr_k=50:0.6591,lwr_k=100:0.6651,lwr_k=200:0.6705,lwr_k=500:0.6911,lwr_k=1000:0.706'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7919,knn_k=1:0.0,knn_k=5:0.4622,knn_k=10:0.5865,knn_k=20:0.669,knn_k=50:0.7551,knn_k=100:0.8243,lwr_k=20:0.3739,lwr_k=50:0.4716,lwr_k=100:0.5329,lwr_k=200:0.5826,lwr_k=500:0.6441,lwr_k=1000:0.6898'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7919,knn_k=1:0.9055,knn_k=5:0.782,knn_k=10:0.7606,knn_k=20:0.7913,knn_k=50:0.8255,knn_k=100:0.8758,lwr_k=20:0.6299,lwr_k=50:0.6402,lwr_k=100:0.6681,lwr_k=200:0.6787,lwr_k=500:0.7032,lwr_k=1000:0.7235'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6089,knn_k=1:0.0,knn_k=5:0.381,knn_k=10:0.4892,knn_k=20:0.5522,knn_k=50:0.599,knn_k=100:0.6179,lwr_k=20:0.315,lwr_k=50:0.4034,lwr_k=100:0.4648,lwr_k=200:0.509,lwr_k=500:0.5531,lwr_k=1000:0.5784'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6295,knn_k=1:0.5685,knn_k=5:0.6117,knn_k=10:0.6174,knn_k=20:0.6292,knn_k=50:0.6312,knn_k=100:0.6332,lwr_k=20:0.5488,lwr_k=50:0.5645,lwr_k=100:0.5695,lwr_k=200:0.5849,lwr_k=500:0.6035,lwr_k=1000:0.6153'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_30'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2804,knn_k=1:0.0,knn_k=5:0.9111,knn_k=10:1.0689,knn_k=20:1.1647,knn_k=50:1.2501,knn_k=100:1.2869,lwr_k=20:1.0791,lwr_k=50:1.1176,lwr_k=100:1.1286,lwr_k=200:1.1476,lwr_k=500:1.1747,lwr_k=1000:1.2039'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.36,knn_k=1:2.2664,knn_k=5:1.4301,knn_k=10:1.3675,knn_k=20:1.3517,knn_k=50:1.373,knn_k=100:1.3812,lwr_k=20:1.309,lwr_k=50:1.2956,lwr_k=100:1.2802,lwr_k=200:1.2721,lwr_k=500:1.267,lwr_k=1000:1.2769'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7569,knn_k=1:0.1542,knn_k=5:0.6514,knn_k=10:0.7043,knn_k=20:0.7394,knn_k=50:0.746,knn_k=100:0.75,lwr_k=20:0.7334,lwr_k=50:0.7382,lwr_k=100:0.7413,lwr_k=200:0.744,lwr_k=500:0.7454,lwr_k=1000:0.7463'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8073,knn_k=1:1.4621,knn_k=5:0.9376,knn_k=10:0.8734,knn_k=20:0.8462,knn_k=50:0.8182,knn_k=100:0.8046,lwr_k=20:0.8454,lwr_k=50:0.8176,lwr_k=100:0.8047,lwr_k=200:0.8007,lwr_k=500:0.797,lwr_k=1000:0.7994'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3643,knn_k=1:0.2557,knn_k=5:1.0169,knn_k=10:1.2098,knn_k=20:1.2547,knn_k=50:1.3281,knn_k=100:1.3671,lwr_k=20:1.2185,lwr_k=50:1.2607,lwr_k=100:1.2717,lwr_k=200:1.2779,lwr_k=500:1.2728,lwr_k=1000:1.2802'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.423,knn_k=1:2.3702,knn_k=5:1.491,knn_k=10:1.479,knn_k=20:1.413,knn_k=50:1.4171,knn_k=100:1.4335,lwr_k=20:1.3905,lwr_k=50:1.3672,lwr_k=100:1.344,lwr_k=200:1.3283,lwr_k=500:1.3109,lwr_k=1000:1.3153'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.8527,knn_k=1:0.0,knn_k=5:1.2448,knn_k=10:1.4573,knn_k=20:1.597,knn_k=50:1.7509,knn_k=100:1.8614,lwr_k=20:1.5252,lwr_k=50:1.6003,lwr_k=100:1.6224,lwr_k=200:1.6297,lwr_k=500:1.6473,lwr_k=1000:1.672'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.9368,knn_k=1:2.974,knn_k=5:2.0007,knn_k=10:1.8896,knn_k=20:1.8494,knn_k=50:1.8985,knn_k=100:1.9675,lwr_k=20:1.811,lwr_k=50:1.7862,lwr_k=100:1.7668,lwr_k=200:1.7225,lwr_k=500:1.7157,lwr_k=1000:1.7421'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1958,knn_k=1:0.8638,knn_k=5:0.9485,knn_k=10:1.0949,knn_k=20:1.0936,knn_k=50:1.1525,knn_k=100:1.1781,lwr_k=20:1.0719,lwr_k=50:1.1089,lwr_k=100:1.1199,lwr_k=200:1.1147,lwr_k=500:1.1195,lwr_k=1000:1.1304'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2076,knn_k=1:2.6315,knn_k=5:1.3605,knn_k=10:1.2742,knn_k=20:1.1997,knn_k=50:1.1984,knn_k=100:1.2095,lwr_k=20:1.1939,lwr_k=50:1.1775,lwr_k=100:1.1732,lwr_k=200:1.1661,lwr_k=500:1.173,lwr_k=1000:1.1741'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.5625,knn_k=1:0.0001,knn_k=5:0.4424,knn_k=10:0.5055,knn_k=20:0.5296,knn_k=50:0.5493,knn_k=100:0.5573,lwr_k=20:0.5221,lwr_k=50:0.5374,lwr_k=100:0.5437,lwr_k=200:0.5484,lwr_k=500:0.5536,lwr_k=1000:0.5555'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5665,knn_k=1:1.1696,knn_k=5:0.6593,knn_k=10:0.6067,knn_k=20:0.5925,knn_k=50:0.5853,knn_k=100:0.5814,lwr_k=20:0.5862,lwr_k=50:0.5767,lwr_k=100:0.5728,lwr_k=200:0.5682,lwr_k=500:0.5662,lwr_k=1000:0.5644'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_31'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9709,knn_k=1:0.0,knn_k=5:0.5463,knn_k=10:0.7048,knn_k=20:0.8164,knn_k=50:0.9624,knn_k=100:1.0948,lwr_k=20:0.1529,lwr_k=50:0.3151,lwr_k=100:0.4373,lwr_k=200:0.55,lwr_k=500:0.6727,lwr_k=1000:0.7434'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9702,knn_k=1:0.9591,knn_k=5:0.8505,knn_k=10:0.878,knn_k=20:0.9314,knn_k=50:1.0208,knn_k=100:1.1365,lwr_k=20:0.786,lwr_k=50:0.778,lwr_k=100:0.7586,lwr_k=200:0.7426,lwr_k=500:0.7891,lwr_k=1000:0.8161'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7128,knn_k=1:0.0,knn_k=5:0.4944,knn_k=10:0.596,knn_k=20:0.6721,knn_k=50:0.7258,knn_k=100:0.7694,lwr_k=20:0.299,lwr_k=50:0.4304,lwr_k=100:0.5115,lwr_k=200:0.567,lwr_k=500:0.628,lwr_k=1000:0.6641'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7684,knn_k=1:1.0091,knn_k=5:0.8107,knn_k=10:0.796,knn_k=20:0.7885,knn_k=50:0.8109,knn_k=100:0.8444,lwr_k=20:0.8028,lwr_k=50:0.7492,lwr_k=100:0.7407,lwr_k=200:0.7433,lwr_k=500:0.7622,lwr_k=1000:0.7708'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2219,knn_k=1:0.0,knn_k=5:0.6903,knn_k=10:0.8793,knn_k=20:1.0632,knn_k=50:1.2536,knn_k=100:1.4102,lwr_k=20:0.1037,lwr_k=50:0.2958,lwr_k=100:0.4826,lwr_k=200:0.6281,lwr_k=500:0.7944,lwr_k=1000:0.921'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2491,knn_k=1:1.1625,knn_k=5:1.0519,knn_k=10:1.068,knn_k=20:1.1486,knn_k=50:1.287,knn_k=100:1.4248,lwr_k=20:0.939,lwr_k=50:0.9234,lwr_k=100:0.8488,lwr_k=200:0.8978,lwr_k=500:0.9508,lwr_k=1000:1.0218'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0392,knn_k=1:0.0,knn_k=5:0.5792,knn_k=10:0.7343,knn_k=20:0.8402,knn_k=50:0.9618,knn_k=100:1.087,lwr_k=20:0.1281,lwr_k=50:0.2957,lwr_k=100:0.4455,lwr_k=200:0.5601,lwr_k=500:0.694,lwr_k=1000:0.7742'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0201,knn_k=1:1.0031,knn_k=5:0.8521,knn_k=10:0.857,knn_k=20:0.9118,knn_k=50:0.9911,knn_k=100:1.0945,lwr_k=20:0.8484,lwr_k=50:0.7631,lwr_k=100:0.7455,lwr_k=200:0.743,lwr_k=500:0.7617,lwr_k=1000:0.8001'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9066,knn_k=1:0.0,knn_k=5:0.545,knn_k=10:0.6855,knn_k=20:0.7844,knn_k=50:0.8967,knn_k=100:1.0011,lwr_k=20:0.1155,lwr_k=50:0.2741,lwr_k=100:0.4168,lwr_k=200:0.5514,lwr_k=500:0.6624,lwr_k=1000:0.7393'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9229,knn_k=1:0.9405,knn_k=5:0.9022,knn_k=10:0.9042,knn_k=20:0.931,knn_k=50:0.9719,knn_k=100:1.0513,lwr_k=20:0.8541,lwr_k=50:0.7903,lwr_k=100:0.7625,lwr_k=200:0.7712,lwr_k=500:0.7987,lwr_k=1000:0.8343'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7028,knn_k=1:0.0,knn_k=5:0.4912,knn_k=10:0.5962,knn_k=20:0.648,knn_k=50:0.702,knn_k=100:0.7383,lwr_k=20:0.3887,lwr_k=50:0.4851,lwr_k=100:0.5431,lwr_k=200:0.5881,lwr_k=500:0.6341,lwr_k=1000:0.6577'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6979,knn_k=1:0.9833,knn_k=5:0.7435,knn_k=10:0.7229,knn_k=20:0.7063,knn_k=50:0.7114,knn_k=100:0.7309,lwr_k=20:0.6936,lwr_k=50:0.6743,lwr_k=100:0.6718,lwr_k=200:0.6733,lwr_k=500:0.6757,lwr_k=1000:0.6761'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_32'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9797,knn_k=1:0.0,knn_k=5:0.5792,knn_k=10:0.7318,knn_k=20:0.829,knn_k=50:0.9381,knn_k=100:1.0245,lwr_k=20:0.1603,lwr_k=50:0.3358,lwr_k=100:0.4465,lwr_k=200:0.5406,lwr_k=500:0.6403,lwr_k=1000:0.7211'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9716,knn_k=1:1.2678,knn_k=5:0.898,knn_k=10:0.8787,knn_k=20:0.9271,knn_k=50:1.0094,knn_k=100:1.0811,lwr_k=20:1.1459,lwr_k=50:0.8226,lwr_k=100:0.7093,lwr_k=200:0.6581,lwr_k=500:0.6808,lwr_k=1000:0.7153'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6348,knn_k=1:0.0,knn_k=5:0.4303,knn_k=10:0.5228,knn_k=20:0.5774,knn_k=50:0.6261,knn_k=100:0.6488,lwr_k=20:0.1224,lwr_k=50:0.2888,lwr_k=100:0.3857,lwr_k=200:0.458,lwr_k=500:0.5223,lwr_k=1000:0.5571'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6721,knn_k=1:1.0331,knn_k=5:0.711,knn_k=10:0.695,knn_k=20:0.6823,knn_k=50:0.6874,knn_k=100:0.6946,lwr_k=20:1.1,lwr_k=50:0.7769,lwr_k=100:0.6753,lwr_k=200:0.6422,lwr_k=500:0.6349,lwr_k=1000:0.6321'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0563,knn_k=1:0.0,knn_k=5:0.7521,knn_k=10:0.9042,knn_k=20:1.0362,knn_k=50:1.1685,knn_k=100:1.2607,lwr_k=20:0.1904,lwr_k=50:0.3973,lwr_k=100:0.5294,lwr_k=200:0.632,lwr_k=500:0.7394,lwr_k=1000:0.8169'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1275,knn_k=1:1.6032,knn_k=5:1.1804,knn_k=10:1.1711,knn_k=20:1.1826,knn_k=50:1.2538,knn_k=100:1.3362,lwr_k=20:1.4865,lwr_k=50:0.982,lwr_k=100:0.8845,lwr_k=200:0.8448,lwr_k=500:0.8631,lwr_k=1000:0.9029'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.153,knn_k=1:0.0,knn_k=5:0.7129,knn_k=10:0.91,knn_k=20:1.037,knn_k=50:1.186,knn_k=100:1.2923,lwr_k=20:0.0029,lwr_k=50:0.246,lwr_k=100:0.4731,lwr_k=200:0.6266,lwr_k=500:0.7616,lwr_k=1000:0.8464'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1032,knn_k=1:1.3462,knn_k=5:1.0508,knn_k=10:1.0533,knn_k=20:1.0772,knn_k=50:1.1411,knn_k=100:1.2413,lwr_k=20:4.9603,lwr_k=50:4.6276,lwr_k=100:1.3959,lwr_k=200:0.7598,lwr_k=500:0.8116,lwr_k=1000:0.8438'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8006,knn_k=1:0.0,knn_k=5:0.5391,knn_k=10:0.6502,knn_k=20:0.729,knn_k=50:0.81,knn_k=100:0.8659,lwr_k=20:0.161,lwr_k=50:0.3245,lwr_k=100:0.4205,lwr_k=200:0.4954,lwr_k=500:0.5728,lwr_k=1000:0.6284'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8144,knn_k=1:1.17,knn_k=5:0.8225,knn_k=10:0.806,knn_k=20:0.8306,knn_k=50:0.8704,knn_k=100:0.9205,lwr_k=20:1.0805,lwr_k=50:0.7543,lwr_k=100:0.6915,lwr_k=200:0.645,lwr_k=500:0.6277,lwr_k=1000:0.6494'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.5853,knn_k=1:0.0,knn_k=5:0.3968,knn_k=10:0.4762,knn_k=20:0.5243,knn_k=50:0.5635,knn_k=100:0.5809,lwr_k=20:0.171,lwr_k=50:0.3211,lwr_k=100:0.4024,lwr_k=200:0.4567,lwr_k=500:0.506,lwr_k=1000:0.534'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5668,knn_k=1:0.93,knn_k=5:0.6142,knn_k=10:0.5826,knn_k=20:0.5744,knn_k=50:0.5671,knn_k=100:0.5764,lwr_k=20:0.8138,lwr_k=50:0.6057,lwr_k=100:0.5559,lwr_k=200:0.5229,lwr_k=500:0.5262,lwr_k=1000:0.5361'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_33'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.9867,knn_k=1:0.0,knn_k=5:1.9977,knn_k=10:2.6792,knn_k=20:3.2248,knn_k=50:3.7378,knn_k=100:4.0246,lwr_k=20:3.1108,lwr_k=50:3.4649,lwr_k=100:3.5591,lwr_k=200:3.5204,lwr_k=500:3.333,lwr_k=1000:3.2465'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.0848,knn_k=1:3.0489,knn_k=5:3.2837,knn_k=10:3.5451,knn_k=20:3.8791,knn_k=50:4.1297,knn_k=100:4.3388,lwr_k=20:3.7918,lwr_k=50:3.8986,lwr_k=100:3.9256,lwr_k=200:3.8379,lwr_k=500:3.5917,lwr_k=1000:3.4624'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.8432,knn_k=1:0.0,knn_k=5:2.0599,knn_k=10:2.6852,knn_k=20:3.2249,knn_k=50:3.7587,knn_k=100:4.0625,lwr_k=20:3.1139,lwr_k=50:3.4811,lwr_k=100:3.5766,lwr_k=200:3.544,lwr_k=500:3.3495,lwr_k=1000:3.2441'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.0169,knn_k=1:3.1841,knn_k=5:3.4469,knn_k=10:3.5609,knn_k=20:3.7465,knn_k=50:4.0171,knn_k=100:4.2737,lwr_k=20:3.6696,lwr_k=50:3.7916,lwr_k=100:3.8235,lwr_k=200:3.7386,lwr_k=500:3.5127,lwr_k=1000:3.4157'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.9233,knn_k=1:0.0,knn_k=5:2.0692,knn_k=10:2.7003,knn_k=20:3.162,knn_k=50:3.6366,knn_k=100:3.9473,lwr_k=20:3.0646,lwr_k=50:3.4036,lwr_k=100:3.5069,lwr_k=200:3.4838,lwr_k=500:3.3058,lwr_k=1000:3.1871'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.9648,knn_k=1:2.9421,knn_k=5:3.2111,knn_k=10:3.288,knn_k=20:3.4663,knn_k=50:3.7514,knn_k=100:4.0265,lwr_k=20:3.4039,lwr_k=50:3.559,lwr_k=100:3.6202,lwr_k=200:3.5764,lwr_k=500:3.3698,lwr_k=1000:3.2252'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.8228,knn_k=1:0.0,knn_k=5:2.2502,knn_k=10:2.9241,knn_k=20:3.3839,knn_k=50:3.8573,knn_k=100:4.144,lwr_k=20:3.2667,lwr_k=50:3.582,lwr_k=100:3.6798,lwr_k=200:3.6434,lwr_k=500:3.4871,lwr_k=1000:3.4189'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.7149,knn_k=1:3.3117,knn_k=5:3.4326,knn_k=10:3.5175,knn_k=20:3.6419,knn_k=50:3.9164,knn_k=100:4.046,lwr_k=20:3.5505,lwr_k=50:3.6772,lwr_k=100:3.6756,lwr_k=200:3.6163,lwr_k=500:3.4249,lwr_k=1000:3.3109'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.9621,knn_k=1:0.0,knn_k=5:2.1363,knn_k=10:2.8969,knn_k=20:3.3679,knn_k=50:3.8548,knn_k=100:4.2107,lwr_k=20:3.2602,lwr_k=50:3.606,lwr_k=100:3.7237,lwr_k=200:3.6794,lwr_k=500:3.479,lwr_k=1000:3.3583'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.023,knn_k=1:3.3786,knn_k=5:3.3598,knn_k=10:3.4842,knn_k=20:3.6835,knn_k=50:3.9488,knn_k=100:4.1943,lwr_k=20:3.5902,lwr_k=50:3.7176,lwr_k=100:3.7449,lwr_k=200:3.6689,lwr_k=500:3.4446,lwr_k=1000:3.3337'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.033,knn_k=1:0.0,knn_k=5:2.0155,knn_k=10:2.7161,knn_k=20:3.1709,knn_k=50:3.6978,knn_k=100:4.0713,lwr_k=20:3.0757,lwr_k=50:3.4582,lwr_k=100:3.6098,lwr_k=200:3.5979,lwr_k=500:3.4008,lwr_k=1000:3.2446'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.0054,knn_k=1:2.3207,knn_k=5:3.0124,knn_k=10:3.253,knn_k=20:3.4288,knn_k=50:3.8073,knn_k=100:4.0601,lwr_k=20:3.3569,lwr_k=50:3.597,lwr_k=100:3.6476,lwr_k=200:3.5674,lwr_k=500:3.3242,lwr_k=1000:3.1478'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_34'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9875,knn_k=1:0.0,knn_k=5:0.6581,knn_k=10:0.8045,knn_k=20:0.9137,knn_k=50:1.0001,knn_k=100:1.049,lwr_k=20:0.615,lwr_k=50:0.6671,lwr_k=100:0.6996,lwr_k=200:0.7275,lwr_k=500:0.77,lwr_k=1000:0.7979'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.0409,knn_k=1:1.3616,knn_k=5:1.0185,knn_k=10:1.0039,knn_k=20:1.0349,knn_k=50:1.0739,knn_k=100:1.11,lwr_k=20:0.8642,lwr_k=50:0.8277,lwr_k=100:0.8212,lwr_k=200:0.8206,lwr_k=500:0.8284,lwr_k=1000:0.8583'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.709,knn_k=1:0.0,knn_k=5:0.4819,knn_k=10:0.5881,knn_k=20:0.6565,knn_k=50:0.7164,knn_k=100:0.7548,lwr_k=20:0.2166,lwr_k=50:0.3612,lwr_k=100:0.4663,lwr_k=200:0.5481,lwr_k=500:0.6155,lwr_k=1000:0.6541'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7656,knn_k=1:1.0029,knn_k=5:0.7614,knn_k=10:0.7507,knn_k=20:0.7638,knn_k=50:0.7896,knn_k=100:0.8171,lwr_k=20:0.7425,lwr_k=50:0.7187,lwr_k=100:0.7245,lwr_k=200:0.7446,lwr_k=500:0.7336,lwr_k=1000:0.7515'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1942,knn_k=1:0.0,knn_k=5:0.6881,knn_k=10:0.8768,knn_k=20:1.0507,knn_k=50:1.2493,knn_k=100:1.4054,lwr_k=20:0.1285,lwr_k=50:0.3144,lwr_k=100:0.4756,lwr_k=200:0.6101,lwr_k=500:0.747,lwr_k=1000:0.8446'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2605,knn_k=1:1.1219,knn_k=5:1.0947,knn_k=10:1.1015,knn_k=20:1.1772,knn_k=50:1.3315,knn_k=100:1.4588,lwr_k=20:0.9392,lwr_k=50:0.8626,lwr_k=100:0.8123,lwr_k=200:0.8062,lwr_k=500:0.8684,lwr_k=1000:0.942'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3073,knn_k=1:0.0,knn_k=5:0.8933,knn_k=10:1.1119,knn_k=20:1.2978,knn_k=50:1.5664,knn_k=100:1.8068,lwr_k=20:0.8172,lwr_k=50:0.8589,lwr_k=100:0.893,lwr_k=200:0.9277,lwr_k=500:0.9933,lwr_k=1000:1.0442'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.3907,knn_k=1:1.8998,knn_k=5:1.3901,knn_k=10:1.4111,knn_k=20:1.4881,knn_k=50:1.7303,knn_k=100:1.9427,lwr_k=20:1.1028,lwr_k=50:1.0254,lwr_k=100:1.0172,lwr_k=200:1.0058,lwr_k=500:1.0223,lwr_k=1000:1.0607'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7872,knn_k=1:0.0,knn_k=5:0.5618,knn_k=10:0.6671,knn_k=20:0.7273,knn_k=50:0.7841,knn_k=100:0.8351,lwr_k=20:0.5935,lwr_k=50:0.6449,lwr_k=100:0.6739,lwr_k=200:0.701,lwr_k=500:0.7295,lwr_k=1000:0.7414'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7835,knn_k=1:1.2216,knn_k=5:0.8677,knn_k=10:0.8407,knn_k=20:0.8266,knn_k=50:0.8298,knn_k=100:0.8553,lwr_k=20:0.7592,lwr_k=50:0.7475,lwr_k=100:0.7479,lwr_k=200:0.7451,lwr_k=500:0.747,lwr_k=1000:0.7506'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6817,knn_k=1:0.0,knn_k=5:0.4845,knn_k=10:0.5725,knn_k=20:0.6301,knn_k=50:0.6795,knn_k=100:0.7078,lwr_k=20:0.4293,lwr_k=50:0.5097,lwr_k=100:0.5629,lwr_k=200:0.5967,lwr_k=500:0.629,lwr_k=1000:0.6527'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6913,knn_k=1:1.0706,knn_k=5:0.7348,knn_k=10:0.7104,knn_k=20:0.7048,knn_k=50:0.7022,knn_k=100:0.7179,lwr_k=20:0.671,lwr_k=50:0.6606,lwr_k=100:0.6651,lwr_k=200:0.6683,lwr_k=500:0.6678,lwr_k=1000:0.6724'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_35'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8605,knn_k=1:0.0,knn_k=5:0.524,knn_k=10:0.691,knn_k=20:0.8048,knn_k=50:0.9344,knn_k=100:1.0324,lwr_k=20:0.1792,lwr_k=50:0.3146,lwr_k=100:0.4207,lwr_k=200:0.52,lwr_k=500:0.6272,lwr_k=1000:0.6891'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.85,knn_k=1:0.8921,knn_k=5:0.8077,knn_k=10:0.8328,knn_k=20:0.8762,knn_k=50:0.9712,knn_k=100:1.0549,lwr_k=20:0.6609,lwr_k=50:0.6571,lwr_k=100:0.6881,lwr_k=200:0.6797,lwr_k=500:0.7029,lwr_k=1000:0.7179'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6459,knn_k=1:0.0,knn_k=5:0.4531,knn_k=10:0.5509,knn_k=20:0.6232,knn_k=50:0.7,knn_k=100:0.7631,lwr_k=20:0.2213,lwr_k=50:0.3381,lwr_k=100:0.4179,lwr_k=200:0.4942,lwr_k=500:0.556,lwr_k=1000:0.5934'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.684,knn_k=1:0.9316,knn_k=5:0.7623,knn_k=10:0.7409,knn_k=20:0.7602,knn_k=50:0.7977,knn_k=100:0.8442,lwr_k=20:0.7091,lwr_k=50:0.6892,lwr_k=100:0.694,lwr_k=200:0.681,lwr_k=500:0.6909,lwr_k=1000:0.6889'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0502,knn_k=1:6.1165,knn_k=5:7.3221,knn_k=10:7.2611,knn_k=20:6.1739,knn_k=50:6.1193,knn_k=100:6.0732,lwr_k=20:6.1739,lwr_k=50:6.1193,lwr_k=100:6.0732,lwr_k=200:6.0535,lwr_k=500:6.0573,lwr_k=1000:6.0502'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:6.1621,knn_k=1:6.2399,knn_k=5:7.4843,knn_k=10:7.422,knn_k=20:6.3015,knn_k=50:6.2429,knn_k=100:6.1918,lwr_k=20:6.3015,lwr_k=50:6.2429,lwr_k=100:6.1918,lwr_k=200:6.1679,lwr_k=500:6.1729,lwr_k=1000:6.1619'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0821,knn_k=1:0.0,knn_k=5:0.5812,knn_k=10:0.7644,knn_k=20:0.9007,knn_k=50:1.1215,knn_k=100:1.3933,lwr_k=20:0.0947,lwr_k=50:0.2373,lwr_k=100:0.3842,lwr_k=200:0.5183,lwr_k=500:0.6574,lwr_k=1000:0.7503'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0385,knn_k=1:0.9528,knn_k=5:0.8736,knn_k=10:0.8943,knn_k=20:0.9464,knn_k=50:1.1286,knn_k=100:1.3862,lwr_k=20:0.7996,lwr_k=50:0.7631,lwr_k=100:0.7462,lwr_k=200:0.728,lwr_k=500:0.7272,lwr_k=1000:0.784'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8415,knn_k=1:0.0,knn_k=5:0.5404,knn_k=10:0.6877,knn_k=20:0.7845,knn_k=50:0.8774,knn_k=100:0.9747,lwr_k=20:0.1536,lwr_k=50:0.3055,lwr_k=100:0.4355,lwr_k=200:0.5534,lwr_k=500:0.6551,lwr_k=1000:0.7204'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8367,knn_k=1:0.8926,knn_k=5:0.8694,knn_k=10:0.8732,knn_k=20:0.89,knn_k=50:0.9345,knn_k=100:0.9991,lwr_k=20:0.7542,lwr_k=50:0.7218,lwr_k=100:0.6909,lwr_k=200:0.717,lwr_k=500:0.7637,lwr_k=1000:0.7826'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6764,knn_k=1:0.0,knn_k=5:0.4095,knn_k=10:0.5315,knn_k=20:0.6101,knn_k=50:0.693,knn_k=100:0.7575,lwr_k=20:0.0953,lwr_k=50:0.2234,lwr_k=100:0.3437,lwr_k=200:0.4503,lwr_k=500:0.5493,lwr_k=1000:0.6052'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6901,knn_k=1:0.7375,knn_k=5:0.6901,knn_k=10:0.6904,knn_k=20:0.7074,knn_k=50:0.7381,knn_k=100:0.7859,lwr_k=20:0.6794,lwr_k=50:0.7024,lwr_k=100:0.6519,lwr_k=200:0.6581,lwr_k=500:0.6524,lwr_k=1000:0.6652'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_36'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8595,knn_k=1:0.0,knn_k=5:0.5632,knn_k=10:0.7053,knn_k=20:0.8083,knn_k=50:0.9293,knn_k=100:1.0208,lwr_k=20:0.4733,lwr_k=50:0.5393,lwr_k=100:0.5872,lwr_k=200:0.6381,lwr_k=500:0.7142,lwr_k=1000:0.7622'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8842,knn_k=1:1.0269,knn_k=5:0.8835,knn_k=10:0.9233,knn_k=20:0.9599,knn_k=50:1.0373,knn_k=100:1.1144,lwr_k=20:0.7679,lwr_k=50:0.7384,lwr_k=100:0.7416,lwr_k=200:0.7579,lwr_k=500:0.7868,lwr_k=1000:0.8132'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.716,knn_k=1:0.0,knn_k=5:0.4552,knn_k=10:0.5684,knn_k=20:0.636,knn_k=50:0.6882,knn_k=100:0.7157,lwr_k=20:0.3937,lwr_k=50:0.4579,lwr_k=100:0.5113,lwr_k=200:0.5641,lwr_k=500:0.62,lwr_k=1000:0.6476'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.771,knn_k=1:0.9448,knn_k=5:0.7614,knn_k=10:0.7368,knn_k=20:0.7485,knn_k=50:0.7696,knn_k=100:0.7748,lwr_k=20:0.6604,lwr_k=50:0.6785,lwr_k=100:0.6828,lwr_k=200:0.694,lwr_k=500:0.7099,lwr_k=1000:0.7194'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8264,knn_k=1:0.0,knn_k=5:0.5893,knn_k=10:0.7513,knn_k=20:0.8646,knn_k=50:0.9868,knn_k=100:1.0693,lwr_k=20:0.4801,lwr_k=50:0.5466,lwr_k=100:0.5878,lwr_k=200:0.6334,lwr_k=500:0.6904,lwr_k=1000:0.7299'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8568,knn_k=1:1.1372,knn_k=5:0.9339,knn_k=10:0.9312,knn_k=20:0.959,knn_k=50:1.0287,knn_k=100:1.102,lwr_k=20:0.7474,lwr_k=50:0.7279,lwr_k=100:0.726,lwr_k=200:0.7271,lwr_k=500:0.7587,lwr_k=1000:0.7768'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8576,knn_k=1:0.0,knn_k=5:0.5659,knn_k=10:0.7111,knn_k=20:0.8109,knn_k=50:0.9336,knn_k=100:1.0341,lwr_k=20:0.4727,lwr_k=50:0.549,lwr_k=100:0.602,lwr_k=200:0.6513,lwr_k=500:0.7141,lwr_k=1000:0.763'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8036,knn_k=1:1.1069,knn_k=5:0.8418,knn_k=10:0.8151,knn_k=20:0.8438,knn_k=50:0.9051,knn_k=100:0.9981,lwr_k=20:0.6635,lwr_k=50:0.6765,lwr_k=100:0.6757,lwr_k=200:0.6803,lwr_k=500:0.7152,lwr_k=1000:0.7449'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8461,knn_k=1:0.0,knn_k=5:0.4997,knn_k=10:0.6348,knn_k=20:0.7416,knn_k=50:0.849,knn_k=100:0.9339,lwr_k=20:0.3686,lwr_k=50:0.4831,lwr_k=100:0.5585,lwr_k=200:0.6196,lwr_k=500:0.6882,lwr_k=1000:0.7316'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8806,knn_k=1:0.8735,knn_k=5:0.7845,knn_k=10:0.8036,knn_k=20:0.8332,knn_k=50:0.8987,knn_k=100:0.9717,lwr_k=20:0.6506,lwr_k=50:0.6704,lwr_k=100:0.6866,lwr_k=200:0.7227,lwr_k=500:0.7391,lwr_k=1000:0.7756'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6416,knn_k=1:0.0,knn_k=5:0.4021,knn_k=10:0.5177,knn_k=20:0.5826,knn_k=50:0.6273,knn_k=100:0.6456,lwr_k=20:0.3398,lwr_k=50:0.4232,lwr_k=100:0.4748,lwr_k=200:0.5253,lwr_k=500:0.5746,lwr_k=1000:0.6003'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6552,knn_k=1:0.6802,knn_k=5:0.6283,knn_k=10:0.6304,knn_k=20:0.6398,knn_k=50:0.6534,knn_k=100:0.6637,lwr_k=20:0.5455,lwr_k=50:0.5444,lwr_k=100:0.5657,lwr_k=200:0.5834,lwr_k=500:0.6082,lwr_k=1000:0.6276'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_37'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9299,knn_k=1:0.0,knn_k=5:0.5319,knn_k=10:0.6862,knn_k=20:0.8194,knn_k=50:0.9863,knn_k=100:1.1449,lwr_k=20:0.3371,lwr_k=50:0.4448,lwr_k=100:0.5152,lwr_k=200:0.5676,lwr_k=500:0.6328,lwr_k=1000:0.6812'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9621,knn_k=1:0.9794,knn_k=5:0.8722,knn_k=10:0.8993,knn_k=20:0.9397,knn_k=50:1.0699,knn_k=100:1.2127,lwr_k=20:0.6842,lwr_k=50:0.6584,lwr_k=100:0.6659,lwr_k=200:0.6845,lwr_k=500:0.7059,lwr_k=1000:0.7354'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6584,knn_k=1:0.0,knn_k=5:0.497,knn_k=10:0.673,knn_k=20:0.8207,knn_k=50:1.0416,knn_k=100:1.2475,lwr_k=20:0.0318,lwr_k=50:0.1348,lwr_k=100:0.2912,lwr_k=200:0.423,lwr_k=500:0.544,lwr_k=1000:0.5921'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7394,knn_k=1:0.8701,knn_k=5:0.85,knn_k=10:0.8727,knn_k=20:0.9669,knn_k=50:1.1565,knn_k=100:1.3834,lwr_k=20:0.7798,lwr_k=50:0.7566,lwr_k=100:0.702,lwr_k=200:0.6675,lwr_k=500:0.6695,lwr_k=1000:0.6886'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9225,knn_k=1:0.0,knn_k=5:0.619,knn_k=10:0.7724,knn_k=20:0.9048,knn_k=50:1.0557,knn_k=100:1.1662,lwr_k=20:0.3075,lwr_k=50:0.4491,lwr_k=100:0.5382,lwr_k=200:0.6069,lwr_k=500:0.6886,lwr_k=1000:0.7501'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9363,knn_k=1:1.0776,knn_k=5:0.9678,knn_k=10:0.9644,knn_k=20:1.0027,knn_k=50:1.0807,knn_k=100:1.1761,lwr_k=20:0.784,lwr_k=50:0.7572,lwr_k=100:0.7499,lwr_k=200:0.7681,lwr_k=500:0.7694,lwr_k=1000:0.7965'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7925,knn_k=1:0.0,knn_k=5:0.6955,knn_k=10:0.8748,knn_k=20:1.0333,knn_k=50:1.2071,knn_k=100:1.3394,lwr_k=20:0.5825,lwr_k=50:0.7132,lwr_k=100:0.7737,lwr_k=200:0.817,lwr_k=500:0.8705,lwr_k=1000:0.9346'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7617,knn_k=1:1.4381,knn_k=5:1.1544,knn_k=10:1.1646,knn_k=20:1.2153,knn_k=50:1.3182,knn_k=100:1.4359,lwr_k=20:1.0365,lwr_k=50:0.9212,lwr_k=100:0.8859,lwr_k=200:0.8696,lwr_k=500:0.8772,lwr_k=1000:0.9215'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8386,knn_k=1:0.0,knn_k=5:0.5731,knn_k=10:0.7527,knn_k=20:0.91,knn_k=50:1.1768,knn_k=100:1.4741,lwr_k=20:0.0391,lwr_k=50:0.1625,lwr_k=100:0.3245,lwr_k=200:0.4679,lwr_k=500:0.5951,lwr_k=1000:0.6665'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8234,knn_k=1:0.8098,knn_k=5:0.9368,knn_k=10:0.9793,knn_k=20:1.0349,knn_k=50:1.2374,knn_k=100:1.4911,lwr_k=20:0.6961,lwr_k=50:0.6762,lwr_k=100:0.6813,lwr_k=200:0.662,lwr_k=500:0.6791,lwr_k=1000:0.707'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6075,knn_k=1:0.0,knn_k=5:0.44,knn_k=10:0.5888,knn_k=20:0.6968,knn_k=50:0.858,knn_k=100:1.0085,lwr_k=20:0.0419,lwr_k=50:0.1538,lwr_k=100:0.2838,lwr_k=200:0.4069,lwr_k=500:0.5095,lwr_k=1000:0.5526'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6567,knn_k=1:0.6488,knn_k=5:0.7517,knn_k=10:0.7488,knn_k=20:0.7835,knn_k=50:0.9015,knn_k=100:1.0281,lwr_k=20:0.6019,lwr_k=50:0.7649,lwr_k=100:0.6897,lwr_k=200:0.6611,lwr_k=500:0.6335,lwr_k=1000:0.6328'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_38'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0405,knn_k=1:6.0798,knn_k=5:6.7048,knn_k=10:6.7293,knn_k=20:6.056,knn_k=50:6.1536,knn_k=100:6.0422,lwr_k=20:6.0551,lwr_k=50:6.1527,lwr_k=100:6.0412,lwr_k=200:6.0582,lwr_k=500:6.0396,lwr_k=1000:6.0408'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.3796,knn_k=1:6.4466,knn_k=5:6.9434,knn_k=10:7.1728,knn_k=20:6.411,knn_k=50:6.5349,knn_k=100:6.3762,lwr_k=20:6.411,lwr_k=50:6.5349,lwr_k=100:6.3762,lwr_k=200:6.3814,lwr_k=500:6.3792,lwr_k=1000:6.3766'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6416,knn_k=1:0.0,knn_k=5:0.4745,knn_k=10:0.5522,knn_k=20:0.5935,knn_k=50:0.6268,knn_k=100:0.6472,lwr_k=20:0.3794,lwr_k=50:0.5111,lwr_k=100:0.5567,lwr_k=200:0.5866,lwr_k=500:0.6103,lwr_k=1000:0.6224'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6931,knn_k=1:1.1905,knn_k=5:0.7688,knn_k=10:0.7299,knn_k=20:0.7122,knn_k=50:0.6987,knn_k=100:0.702,lwr_k=20:0.8305,lwr_k=50:0.7135,lwr_k=100:0.693,lwr_k=200:0.688,lwr_k=500:0.6908,lwr_k=1000:0.6888'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0502,knn_k=1:6.1165,knn_k=5:7.3221,knn_k=10:7.2611,knn_k=20:6.1739,knn_k=50:6.1193,knn_k=100:6.0732,lwr_k=20:6.1739,lwr_k=50:6.1193,lwr_k=100:6.0732,lwr_k=200:6.0535,lwr_k=500:6.0573,lwr_k=1000:6.0502'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:6.1621,knn_k=1:6.2399,knn_k=5:7.4843,knn_k=10:7.422,knn_k=20:6.3015,knn_k=50:6.2429,knn_k=100:6.1918,lwr_k=20:6.3015,lwr_k=50:6.2429,lwr_k=100:6.1918,lwr_k=200:6.1679,lwr_k=500:6.1729,lwr_k=1000:6.1619'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.5698,knn_k=1:2.9965,knn_k=5:3.0743,knn_k=10:3.4189,knn_k=20:3.42,knn_k=50:3.4394,knn_k=100:3.4496,lwr_k=20:3.4197,lwr_k=50:3.4372,lwr_k=100:3.4464,lwr_k=200:3.457,lwr_k=500:3.467,lwr_k=1000:3.4692'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.6593,knn_k=1:8.5519,knn_k=5:4.1896,knn_k=10:4.0675,knn_k=20:3.705,knn_k=50:3.5989,knn_k=100:3.5632,lwr_k=20:3.7067,lwr_k=50:3.5988,lwr_k=100:3.5579,lwr_k=200:3.5587,lwr_k=500:3.5383,lwr_k=1000:3.5421'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:66.1937,knn_k=1:10.0682,knn_k=5:6.5531,knn_k=10:6.2155,knn_k=20:6.2119,knn_k=50:6.2337,knn_k=100:6.2308,lwr_k=20:6.2119,lwr_k=50:6.2337,lwr_k=100:6.2308,lwr_k=200:6.2164,lwr_k=500:6.2243,lwr_k=1000:6.212'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:65.7084,knn_k=1:9.7164,knn_k=5:6.2601,knn_k=10:5.9105,knn_k=20:5.905,knn_k=50:5.9238,knn_k=100:5.9211,lwr_k=20:5.905,lwr_k=50:5.9238,lwr_k=100:5.9211,lwr_k=200:5.9115,lwr_k=500:5.9204,lwr_k=1000:5.905'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6675,knn_k=1:0.1638,knn_k=5:0.5774,knn_k=10:0.6557,knn_k=20:0.6366,knn_k=50:0.6262,knn_k=100:0.6245,lwr_k=20:0.636,lwr_k=50:0.6257,lwr_k=100:0.6234,lwr_k=200:0.628,lwr_k=500:0.6284,lwr_k=1000:0.6362'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.684,knn_k=1:1.1702,knn_k=5:0.825,knn_k=10:0.8113,knn_k=20:0.746,knn_k=50:0.6951,knn_k=100:0.6798,lwr_k=20:0.7464,lwr_k=50:0.6946,lwr_k=100:0.6784,lwr_k=200:0.6698,lwr_k=500:0.6663,lwr_k=1000:0.6694'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_39'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7258,knn_k=1:0.0,knn_k=5:0.6579,knn_k=10:0.8189,knn_k=20:0.9385,knn_k=50:1.0937,knn_k=100:1.2282,lwr_k=20:0.6832,lwr_k=50:0.6943,lwr_k=100:0.6984,lwr_k=200:0.7033,lwr_k=500:0.707,lwr_k=1000:0.7189'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7459,knn_k=1:1.5264,knn_k=5:1.0199,knn_k=10:1.0304,knn_k=20:1.0865,knn_k=50:1.1835,knn_k=100:1.2914,lwr_k=20:0.8926,lwr_k=50:0.8114,lwr_k=100:0.7791,lwr_k=200:0.7623,lwr_k=500:0.7377,lwr_k=1000:0.745'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6281,knn_k=1:0.0,knn_k=5:0.4997,knn_k=10:0.5776,knn_k=20:0.6198,knn_k=50:0.6425,knn_k=100:0.6554,lwr_k=20:0.4302,lwr_k=50:0.5005,lwr_k=100:0.529,lwr_k=200:0.5548,lwr_k=500:0.5755,lwr_k=1000:0.5909'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6527,knn_k=1:1.2507,knn_k=5:0.7852,knn_k=10:0.7212,knn_k=20:0.6942,knn_k=50:0.6877,knn_k=100:0.6879,lwr_k=20:0.7424,lwr_k=50:0.699,lwr_k=100:0.6692,lwr_k=200:0.6509,lwr_k=500:0.634,lwr_k=1000:0.6345'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9831,knn_k=1:0.0,knn_k=5:0.7293,knn_k=10:0.8864,knn_k=20:1.0046,knn_k=50:1.1607,knn_k=100:1.2521,lwr_k=20:0.115,lwr_k=50:0.3041,lwr_k=100:0.4318,lwr_k=200:0.5234,lwr_k=500:0.6269,lwr_k=1000:0.7048'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0279,knn_k=1:1.6622,knn_k=5:1.135,knn_k=10:1.1252,knn_k=20:1.1873,knn_k=50:1.2757,knn_k=100:1.3506,lwr_k=20:1.5517,lwr_k=50:0.9659,lwr_k=100:0.8606,lwr_k=200:0.7812,lwr_k=500:0.769,lwr_k=1000:0.7875'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8193,knn_k=1:0.0,knn_k=5:0.8169,knn_k=10:1.0467,knn_k=20:1.3283,knn_k=50:1.7782,knn_k=100:2.174,lwr_k=20:0.7463,lwr_k=50:0.7198,lwr_k=100:0.7074,lwr_k=200:0.7053,lwr_k=500:0.7001,lwr_k=1000:0.7005'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7737,knn_k=1:1.7158,knn_k=5:1.2444,knn_k=10:1.3319,knn_k=20:1.498,knn_k=50:1.8999,knn_k=100:2.2716,lwr_k=20:0.9614,lwr_k=50:0.8177,lwr_k=100:0.7564,lwr_k=200:0.7292,lwr_k=500:0.6951,lwr_k=1000:0.6825'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7266,knn_k=1:0.0,knn_k=5:0.5927,knn_k=10:0.7064,knn_k=20:0.7913,knn_k=50:0.8984,knn_k=100:0.9653,lwr_k=20:0.4217,lwr_k=50:0.5088,lwr_k=100:0.5524,lwr_k=200:0.5902,lwr_k=500:0.6173,lwr_k=1000:0.6356'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7344,knn_k=1:1.3482,knn_k=5:0.9202,knn_k=10:0.8834,knn_k=20:0.9061,knn_k=50:0.9684,knn_k=100:1.0268,lwr_k=20:0.8132,lwr_k=50:0.7305,lwr_k=100:0.6979,lwr_k=200:0.6844,lwr_k=500:0.6702,lwr_k=1000:0.6693'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:2.9732,knn_k=1:0.0,knn_k=5:2.0084,knn_k=10:2.7146,knn_k=20:3.2056,knn_k=50:3.6801,knn_k=100:4.0181,lwr_k=20:3.1146,lwr_k=50:3.4723,lwr_k=100:3.611,lwr_k=200:3.6165,lwr_k=500:3.4294,lwr_k=1000:3.3313'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.9705,knn_k=1:2.2113,knn_k=5:2.946,knn_k=10:3.1419,knn_k=20:3.3952,knn_k=50:3.6932,knn_k=100:3.951,lwr_k=20:3.3187,lwr_k=50:3.4992,lwr_k=100:3.5437,lwr_k=200:3.484,lwr_k=500:3.2628,lwr_k=1000:3.1707'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_40'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8182,knn_k=1:0.0,knn_k=5:0.7238,knn_k=10:0.8684,knn_k=20:0.9917,knn_k=50:1.1494,knn_k=100:1.2733,lwr_k=20:0.8688,lwr_k=50:0.9024,lwr_k=100:0.8872,lwr_k=200:0.8657,lwr_k=500:0.8533,lwr_k=1000:0.8557'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8203,knn_k=1:1.5309,knn_k=5:1.089,knn_k=10:1.072,knn_k=20:1.1284,knn_k=50:1.2509,knn_k=100:1.3698,lwr_k=20:1.0326,lwr_k=50:1.016,lwr_k=100:0.9759,lwr_k=200:0.9292,lwr_k=500:0.8997,lwr_k=1000:0.8881'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6534,knn_k=1:0.0,knn_k=5:0.4752,knn_k=10:0.5526,knn_k=20:0.6045,knn_k=50:0.6395,knn_k=100:0.6603,lwr_k=20:0.5414,lwr_k=50:0.5716,lwr_k=100:0.5909,lwr_k=200:0.6082,lwr_k=500:0.624,lwr_k=1000:0.6327'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6914,knn_k=1:1.0801,knn_k=5:0.7796,knn_k=10:0.7265,knn_k=20:0.7163,knn_k=50:0.7016,knn_k=100:0.7032,lwr_k=20:0.6986,lwr_k=50:0.6909,lwr_k=100:0.6832,lwr_k=200:0.6841,lwr_k=500:0.684,lwr_k=1000:0.683'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.915,knn_k=1:0.0,knn_k=5:0.9813,knn_k=10:1.1843,knn_k=20:1.3235,knn_k=50:1.47,knn_k=100:1.5489,lwr_k=20:1.2672,lwr_k=50:1.341,lwr_k=100:1.3398,lwr_k=200:1.3078,lwr_k=500:1.2424,lwr_k=1000:1.1769'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9315,knn_k=1:2.2785,knn_k=5:1.5907,knn_k=10:1.5164,knn_k=20:1.5396,knn_k=50:1.5933,knn_k=100:1.6452,lwr_k=20:1.5061,lwr_k=50:1.4895,lwr_k=100:1.4573,lwr_k=200:1.4043,lwr_k=500:1.3098,lwr_k=1000:1.2226'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9128,knn_k=1:0.0,knn_k=5:0.6725,knn_k=10:0.8571,knn_k=20:1.0073,knn_k=50:1.2589,knn_k=100:1.5547,lwr_k=20:0.7862,lwr_k=50:0.7948,lwr_k=100:0.7973,lwr_k=200:0.811,lwr_k=500:0.838,lwr_k=1000:0.8475'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8411,knn_k=1:1.5041,knn_k=5:0.9985,knn_k=10:0.9764,knn_k=20:1.0184,knn_k=50:1.2352,knn_k=100:1.5304,lwr_k=20:0.857,lwr_k=50:0.8057,lwr_k=100:0.7927,lwr_k=200:0.7941,lwr_k=500:0.7923,lwr_k=1000:0.7846'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.814,knn_k=1:0.0,knn_k=5:0.6483,knn_k=10:0.769,knn_k=20:0.8526,knn_k=50:0.931,knn_k=100:0.9973,lwr_k=20:0.8144,lwr_k=50:0.8481,lwr_k=100:0.8574,lwr_k=200:0.8571,lwr_k=500:0.8508,lwr_k=1000:0.8485'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8336,knn_k=1:1.5315,knn_k=5:1.0109,knn_k=10:0.998,knn_k=20:0.9961,knn_k=50:1.0212,knn_k=100:1.0664,lwr_k=20:0.9688,lwr_k=50:0.9474,lwr_k=100:0.9354,lwr_k=200:0.9188,lwr_k=500:0.9014,lwr_k=1000:0.8875'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6968,knn_k=1:0.0,knn_k=5:0.5259,knn_k=10:0.6058,knn_k=20:0.6589,knn_k=50:0.7047,knn_k=100:0.7345,lwr_k=20:0.636,lwr_k=50:0.6647,lwr_k=100:0.6711,lwr_k=200:0.6778,lwr_k=500:0.6922,lwr_k=1000:0.6961'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7205,knn_k=1:1.2314,knn_k=5:0.7915,knn_k=10:0.7457,knn_k=20:0.7304,knn_k=50:0.7413,knn_k=100:0.7607,lwr_k=20:0.7215,lwr_k=50:0.718,lwr_k=100:0.7125,lwr_k=200:0.7163,lwr_k=500:0.7161,lwr_k=1000:0.7155'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_41'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1321,knn_k=1:0.0,knn_k=5:0.6994,knn_k=10:0.8379,knn_k=20:0.9538,knn_k=50:1.0658,knn_k=100:1.1521,lwr_k=20:0.6273,lwr_k=50:0.7012,lwr_k=100:0.7396,lwr_k=200:0.7761,lwr_k=500:0.82,lwr_k=1000:0.8585'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.2168,knn_k=1:1.602,knn_k=5:1.1603,knn_k=10:1.1409,knn_k=20:1.1523,knn_k=50:1.229,knn_k=100:1.305,lwr_k=20:0.9607,lwr_k=50:0.9331,lwr_k=100:0.9193,lwr_k=200:0.9079,lwr_k=500:0.9258,lwr_k=1000:0.944'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7403,knn_k=1:0.0,knn_k=5:0.509,knn_k=10:0.6105,knn_k=20:0.6715,knn_k=50:0.7194,knn_k=100:0.7567,lwr_k=20:0.4147,lwr_k=50:0.5094,lwr_k=100:0.5653,lwr_k=200:0.6044,lwr_k=500:0.6384,lwr_k=1000:0.6603'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7695,knn_k=1:1.3027,knn_k=5:0.8292,knn_k=10:0.7898,knn_k=20:0.7753,knn_k=50:0.7945,knn_k=100:0.8137,lwr_k=20:0.772,lwr_k=50:0.7494,lwr_k=100:0.7353,lwr_k=200:0.7311,lwr_k=500:0.7341,lwr_k=1000:0.74'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0465,knn_k=1:0.0,knn_k=5:0.7547,knn_k=10:0.8664,knn_k=20:0.9459,knn_k=50:1.0387,knn_k=100:1.1158,lwr_k=20:0.5939,lwr_k=50:0.6685,lwr_k=100:0.7103,lwr_k=200:0.747,lwr_k=500:0.7928,lwr_k=1000:0.8368'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0888,knn_k=1:1.7314,knn_k=5:1.125,knn_k=10:1.0746,knn_k=20:1.0711,knn_k=50:1.1285,knn_k=100:1.1956,lwr_k=20:1.0002,lwr_k=50:0.9189,lwr_k=100:0.9045,lwr_k=200:0.8548,lwr_k=500:0.8733,lwr_k=1000:0.8983'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4203,knn_k=1:0.0,knn_k=5:0.653,knn_k=10:0.8146,knn_k=20:0.9543,knn_k=50:1.1278,knn_k=100:1.2694,lwr_k=20:0.3273,lwr_k=50:0.4899,lwr_k=100:0.5657,lwr_k=200:0.6346,lwr_k=500:0.7241,lwr_k=1000:0.7943'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.3973,knn_k=1:1.3221,knn_k=5:0.9746,knn_k=10:0.9732,knn_k=20:1.0364,knn_k=50:1.1488,knn_k=100:1.2858,lwr_k=20:0.9956,lwr_k=50:0.74,lwr_k=100:0.7005,lwr_k=200:0.704,lwr_k=500:0.7282,lwr_k=1000:0.7591'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7139,knn_k=1:0.0,knn_k=5:0.5557,knn_k=10:0.6555,knn_k=20:0.7404,knn_k=50:0.8281,knn_k=100:0.8799,lwr_k=20:0.3647,lwr_k=50:0.5337,lwr_k=100:0.6043,lwr_k=200:0.6439,lwr_k=500:0.6746,lwr_k=1000:0.6799'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6971,knn_k=1:1.2893,knn_k=5:0.8472,knn_k=10:0.8045,knn_k=20:0.8217,knn_k=50:0.8647,knn_k=100:0.9076,lwr_k=20:0.9189,lwr_k=50:0.7394,lwr_k=100:0.699,lwr_k=200:0.6904,lwr_k=500:0.6824,lwr_k=1000:0.6767'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.5043,knn_k=1:0.0,knn_k=5:0.3778,knn_k=10:0.435,knn_k=20:0.4733,knn_k=50:0.5029,knn_k=100:0.5212,lwr_k=20:0.3002,lwr_k=50:0.3764,lwr_k=100:0.4167,lwr_k=200:0.445,lwr_k=500:0.4692,lwr_k=1000:0.479'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5342,knn_k=1:0.9125,knn_k=5:0.5871,knn_k=10:0.5463,knn_k=20:0.5355,knn_k=50:0.5403,knn_k=100:0.5507,lwr_k=20:0.5763,lwr_k=50:0.5445,lwr_k=100:0.5158,lwr_k=200:0.5095,lwr_k=500:0.5121,lwr_k=1000:0.5177'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_42'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0709,knn_k=1:0.0,knn_k=5:0.9559,knn_k=10:1.1488,knn_k=20:1.2624,knn_k=50:1.4074,knn_k=100:1.5018,lwr_k=20:0.886,lwr_k=50:0.9262,lwr_k=100:0.9502,lwr_k=200:0.9748,lwr_k=500:1.0082,lwr_k=1000:1.0195'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.0948,knn_k=1:2.3019,knn_k=5:1.504,knn_k=10:1.4692,knn_k=20:1.4849,knn_k=50:1.5645,knn_k=100:1.6273,lwr_k=20:1.2972,lwr_k=50:1.1979,lwr_k=100:1.1455,lwr_k=200:1.1018,lwr_k=500:1.0905,lwr_k=1000:1.0975'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6078,knn_k=1:0.0,knn_k=5:0.465,knn_k=10:0.5288,knn_k=20:0.5698,knn_k=50:0.6034,knn_k=100:0.6259,lwr_k=20:0.4649,lwr_k=50:0.5235,lwr_k=100:0.5509,lwr_k=200:0.5687,lwr_k=500:0.5848,lwr_k=1000:0.5952'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6469,knn_k=1:1.2338,knn_k=5:0.7219,knn_k=10:0.671,knn_k=20:0.655,knn_k=50:0.6523,knn_k=100:0.6629,lwr_k=20:0.6827,lwr_k=50:0.6406,lwr_k=100:0.6265,lwr_k=200:0.6231,lwr_k=500:0.6284,lwr_k=1000:0.6301'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1379,knn_k=1:0.0,knn_k=5:0.9125,knn_k=10:1.059,knn_k=20:1.1602,knn_k=50:1.2628,knn_k=100:1.3378,lwr_k=20:0.836,lwr_k=50:0.9607,lwr_k=100:1.0263,lwr_k=200:1.0654,lwr_k=500:1.1107,lwr_k=1000:1.1292'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2029,knn_k=1:2.1964,knn_k=5:1.4515,knn_k=10:1.3543,knn_k=20:1.322,knn_k=50:1.3607,knn_k=100:1.4192,lwr_k=20:1.2568,lwr_k=50:1.1905,lwr_k=100:1.1647,lwr_k=200:1.1697,lwr_k=500:1.1779,lwr_k=1000:1.1841'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7996,knn_k=1:0.0,knn_k=5:0.9015,knn_k=10:1.0696,knn_k=20:1.2093,knn_k=50:1.343,knn_k=100:1.4455,lwr_k=20:0.772,lwr_k=50:0.7606,lwr_k=100:0.7596,lwr_k=200:0.7576,lwr_k=500:0.7767,lwr_k=1000:0.795'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7904,knn_k=1:2.1224,knn_k=5:1.4216,knn_k=10:1.4035,knn_k=20:1.4119,knn_k=50:1.4502,knn_k=100:1.4971,lwr_k=20:1.077,lwr_k=50:0.8965,lwr_k=100:0.8273,lwr_k=200:0.8024,lwr_k=500:0.792,lwr_k=1000:0.8017'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7829,knn_k=1:0.0,knn_k=5:0.6921,knn_k=10:0.8084,knn_k=20:0.8769,knn_k=50:0.9531,knn_k=100:1.0032,lwr_k=20:0.641,lwr_k=50:0.6993,lwr_k=100:0.728,lwr_k=200:0.7438,lwr_k=500:0.7591,lwr_k=1000:0.7688'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.798,knn_k=1:1.637,knn_k=5:1.0294,knn_k=10:0.9606,knn_k=20:0.9477,knn_k=50:0.9833,knn_k=100:1.0197,lwr_k=20:0.839,lwr_k=50:0.7928,lwr_k=100:0.7807,lwr_k=200:0.7721,lwr_k=500:0.7686,lwr_k=1000:0.778'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.5429,knn_k=1:0.0,knn_k=5:0.4094,knn_k=10:0.4713,knn_k=20:0.5075,knn_k=50:0.5397,knn_k=100:0.5543,lwr_k=20:0.3945,lwr_k=50:0.4524,lwr_k=100:0.4749,lwr_k=200:0.489,lwr_k=500:0.5041,lwr_k=1000:0.5142'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5657,knn_k=1:1.0839,knn_k=5:0.6328,knn_k=10:0.5901,knn_k=20:0.5749,knn_k=50:0.5784,knn_k=100:0.585,lwr_k=20:0.5683,lwr_k=50:0.5515,lwr_k=100:0.548,lwr_k=200:0.5439,lwr_k=500:0.5433,lwr_k=1000:0.5464'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_43'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9093,knn_k=1:0.0,knn_k=5:0.6492,knn_k=10:0.8148,knn_k=20:0.9616,knn_k=50:1.124,knn_k=100:1.2237,lwr_k=20:0.7465,lwr_k=50:0.7734,lwr_k=100:0.7719,lwr_k=200:0.7825,lwr_k=500:0.8038,lwr_k=1000:0.824'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9903,knn_k=1:1.3697,knn_k=5:1.0542,knn_k=10:1.0398,knn_k=20:1.0923,knn_k=50:1.2232,knn_k=100:1.3135,lwr_k=20:0.9447,lwr_k=50:0.9298,lwr_k=100:0.9097,lwr_k=200:0.8941,lwr_k=500:0.8988,lwr_k=1000:0.9076'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6836,knn_k=1:0.0,knn_k=5:0.5164,knn_k=10:0.5967,knn_k=20:0.6483,knn_k=50:0.6901,knn_k=100:0.7116,lwr_k=20:0.598,lwr_k=50:0.6202,lwr_k=100:0.6331,lwr_k=200:0.647,lwr_k=500:0.6614,lwr_k=1000:0.6693'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7285,knn_k=1:1.2238,knn_k=5:0.8337,knn_k=10:0.7836,knn_k=20:0.7737,knn_k=50:0.7563,knn_k=100:0.754,lwr_k=20:0.7616,lwr_k=50:0.7388,lwr_k=100:0.7309,lwr_k=200:0.7284,lwr_k=500:0.7211,lwr_k=1000:0.7241'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8504,knn_k=1:0.0,knn_k=5:0.6652,knn_k=10:0.8237,knn_k=20:0.9537,knn_k=50:1.1121,knn_k=100:1.2415,lwr_k=20:0.7903,lwr_k=50:0.8031,lwr_k=100:0.7944,lwr_k=200:0.7839,lwr_k=500:0.789,lwr_k=1000:0.7897'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8677,knn_k=1:1.3979,knn_k=5:1.0407,knn_k=10:1.039,knn_k=20:1.0858,knn_k=50:1.1953,knn_k=100:1.3202,lwr_k=20:0.9694,lwr_k=50:0.9336,lwr_k=100:0.8941,lwr_k=200:0.8602,lwr_k=500:0.8437,lwr_k=1000:0.8302'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8874,knn_k=1:0.0,knn_k=5:0.6404,knn_k=10:0.7708,knn_k=20:0.9123,knn_k=50:1.1453,knn_k=100:1.4235,lwr_k=20:0.7078,lwr_k=50:0.7262,lwr_k=100:0.7288,lwr_k=200:0.7474,lwr_k=500:0.7755,lwr_k=1000:0.7907'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8694,knn_k=1:1.4442,knn_k=5:0.9433,knn_k=10:0.948,knn_k=20:0.9952,knn_k=50:1.2079,knn_k=100:1.4808,lwr_k=20:0.84,lwr_k=50:0.7964,lwr_k=100:0.7784,lwr_k=200:0.7729,lwr_k=500:0.7735,lwr_k=1000:0.7683'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8362,knn_k=1:0.0,knn_k=5:0.6291,knn_k=10:0.7553,knn_k=20:0.8677,knn_k=50:1.023,knn_k=100:1.1516,lwr_k=20:0.7669,lwr_k=50:0.8181,lwr_k=100:0.8269,lwr_k=200:0.8289,lwr_k=500:0.8232,lwr_k=1000:0.8216'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8641,knn_k=1:1.4823,knn_k=5:0.9831,knn_k=10:0.9757,knn_k=20:0.996,knn_k=50:1.1031,knn_k=100:1.2092,lwr_k=20:0.9217,lwr_k=50:0.9228,lwr_k=100:0.9114,lwr_k=200:0.8918,lwr_k=500:0.8778,lwr_k=1000:0.86'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7047,knn_k=1:0.0,knn_k=5:0.5392,knn_k=10:0.6212,knn_k=20:0.666,knn_k=50:0.6985,knn_k=100:0.7151,lwr_k=20:0.6372,lwr_k=50:0.656,lwr_k=100:0.6636,lwr_k=200:0.6695,lwr_k=500:0.6795,lwr_k=1000:0.6883'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7005,knn_k=1:1.2365,knn_k=5:0.7845,knn_k=10:0.74,knn_k=20:0.7155,knn_k=50:0.7157,knn_k=100:0.7215,lwr_k=20:0.7019,lwr_k=50:0.6954,lwr_k=100:0.6927,lwr_k=200:0.6948,lwr_k=500:0.6892,lwr_k=1000:0.6905'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_44'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3898,knn_k=1:0.0,knn_k=5:0.9589,knn_k=10:1.1213,knn_k=20:1.2325,knn_k=50:1.3263,knn_k=100:1.3824,lwr_k=20:1.1451,lwr_k=50:1.1959,lwr_k=100:1.2165,lwr_k=200:1.245,lwr_k=500:1.267,lwr_k=1000:1.2851'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.4618,knn_k=1:2.2461,knn_k=5:1.4791,knn_k=10:1.4148,knn_k=20:1.4368,knn_k=50:1.4691,knn_k=100:1.4975,lwr_k=20:1.3788,lwr_k=50:1.3543,lwr_k=100:1.3374,lwr_k=200:1.3299,lwr_k=500:1.3472,lwr_k=1000:1.3634'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7056,knn_k=1:0.0,knn_k=5:0.545,knn_k=10:0.6264,knn_k=20:0.6595,knn_k=50:0.6831,knn_k=100:0.6944,lwr_k=20:0.6456,lwr_k=50:0.6658,lwr_k=100:0.6747,lwr_k=200:0.6839,lwr_k=500:0.6867,lwr_k=1000:0.6929'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7435,knn_k=1:1.4172,knn_k=5:0.84,knn_k=10:0.8064,knn_k=20:0.7705,knn_k=50:0.7489,knn_k=100:0.7476,lwr_k=20:0.7723,lwr_k=50:0.7498,lwr_k=100:0.7435,lwr_k=200:0.7364,lwr_k=500:0.7326,lwr_k=1000:0.7329'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4568,knn_k=1:0.0,knn_k=5:0.9608,knn_k=10:1.1486,knn_k=20:1.279,knn_k=50:1.3941,knn_k=100:1.4585,lwr_k=20:1.2503,lwr_k=50:1.3285,lwr_k=100:1.3482,lwr_k=200:1.3453,lwr_k=500:1.3229,lwr_k=1000:1.3157'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.5128,knn_k=1:2.2128,knn_k=5:1.5586,knn_k=10:1.4828,knn_k=20:1.4861,knn_k=50:1.5026,knn_k=100:1.5337,lwr_k=20:1.4685,lwr_k=50:1.4574,lwr_k=100:1.444,lwr_k=200:1.4214,lwr_k=500:1.3906,lwr_k=1000:1.381'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.0463,knn_k=1:0.0,knn_k=5:1.5089,knn_k=10:1.8608,knn_k=20:2.0515,knn_k=50:2.1976,knn_k=100:2.2409,lwr_k=20:2.0368,lwr_k=50:2.1597,lwr_k=100:2.1739,lwr_k=200:2.1789,lwr_k=500:2.1945,lwr_k=1000:2.2117'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.1139,knn_k=1:3.3888,knn_k=5:2.4469,knn_k=10:2.3794,knn_k=20:2.3752,knn_k=50:2.3742,knn_k=100:2.3651,lwr_k=20:2.3662,lwr_k=50:2.3508,lwr_k=100:2.324,lwr_k=200:2.2828,lwr_k=500:2.2813,lwr_k=1000:2.2996'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.5073,knn_k=1:0.0,knn_k=5:1.7685,knn_k=10:2.1074,knn_k=20:2.3708,knn_k=50:2.5434,knn_k=100:2.6082,lwr_k=20:2.3432,lwr_k=50:2.4741,lwr_k=100:2.4893,lwr_k=200:2.4925,lwr_k=500:2.4775,lwr_k=1000:2.4739'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.5854,knn_k=1:3.9044,knn_k=5:2.7364,knn_k=10:2.6991,knn_k=20:2.7079,knn_k=50:2.7275,knn_k=100:2.7679,lwr_k=20:2.6879,lwr_k=50:2.672,lwr_k=100:2.6712,lwr_k=200:2.6372,lwr_k=500:2.5892,lwr_k=1000:2.5685'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7237,knn_k=1:0.0,knn_k=5:0.5534,knn_k=10:0.6301,knn_k=20:0.6746,knn_k=50:0.7025,knn_k=100:0.7153,lwr_k=20:0.6648,lwr_k=50:0.6879,lwr_k=100:0.6965,lwr_k=200:0.7052,lwr_k=500:0.7119,lwr_k=1000:0.7144'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7141,knn_k=1:1.3652,knn_k=5:0.8167,knn_k=10:0.7458,knn_k=20:0.7217,knn_k=50:0.7169,knn_k=100:0.7203,lwr_k=20:0.721,lwr_k=50:0.7082,lwr_k=100:0.7086,lwr_k=200:0.7117,lwr_k=500:0.7124,lwr_k=1000:0.7142'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_45'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.7765,knn_k=1:0.0,knn_k=5:2.9989,knn_k=10:3.7685,knn_k=20:4.3022,knn_k=50:4.756,knn_k=100:4.9865,lwr_k=20:4.2991,lwr_k=50:4.7438,lwr_k=100:4.9539,lwr_k=200:5.1218,lwr_k=500:5.2669,lwr_k=1000:5.3353'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.8942,knn_k=1:5.9014,knn_k=5:5.0954,knn_k=10:4.9585,knn_k=20:4.9515,knn_k=50:5.1084,knn_k=100:5.2041,lwr_k=20:4.9495,lwr_k=50:5.0961,lwr_k=100:5.1741,lwr_k=200:5.3076,lwr_k=500:5.4838,lwr_k=1000:5.5608'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7255,knn_k=1:0.0,knn_k=5:0.5607,knn_k=10:0.6365,knn_k=20:0.6815,knn_k=50:0.7108,knn_k=100:0.7244,lwr_k=20:0.6251,lwr_k=50:0.6665,lwr_k=100:0.685,lwr_k=200:0.7004,lwr_k=500:0.7098,lwr_k=1000:0.7154'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7769,knn_k=1:1.4266,knn_k=5:0.9032,knn_k=10:0.8283,knn_k=20:0.8042,knn_k=50:0.7881,knn_k=100:0.7895,lwr_k=20:0.8212,lwr_k=50:0.7905,lwr_k=100:0.7781,lwr_k=200:0.7746,lwr_k=500:0.7658,lwr_k=1000:0.7709'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.8862,knn_k=1:0.0,knn_k=5:3.1959,knn_k=10:4.0249,knn_k=20:4.4909,knn_k=50:4.8962,knn_k=100:5.1338,lwr_k=20:4.4875,lwr_k=50:4.8852,lwr_k=100:5.1021,lwr_k=200:5.2287,lwr_k=500:5.3688,lwr_k=1000:5.4393'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.9607,knn_k=1:6.3558,knn_k=5:5.1059,knn_k=10:4.9817,knn_k=20:5.0156,knn_k=50:5.0877,knn_k=100:5.2225,lwr_k=20:5.0131,lwr_k=50:5.0805,lwr_k=100:5.2056,lwr_k=200:5.3486,lwr_k=500:5.4802,lwr_k=1000:5.5565'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.9288,knn_k=1:0.0,knn_k=5:3.0657,knn_k=10:3.9378,knn_k=20:4.4465,knn_k=50:4.886,knn_k=100:5.184,lwr_k=20:4.4441,lwr_k=50:4.8792,lwr_k=100:5.1675,lwr_k=200:5.3834,lwr_k=500:5.5331,lwr_k=1000:5.5626'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.9127,knn_k=1:5.3707,knn_k=5:4.7624,knn_k=10:4.6012,knn_k=20:4.6553,knn_k=50:4.8487,knn_k=100:5.0115,lwr_k=20:4.6538,lwr_k=50:4.8442,lwr_k=100:4.9992,lwr_k=200:5.1657,lwr_k=500:5.3258,lwr_k=1000:5.3588'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.9867,knn_k=1:0.0,knn_k=5:3.2948,knn_k=10:3.9939,knn_k=20:4.4999,knn_k=50:4.9512,knn_k=100:5.1691,lwr_k=20:4.4964,lwr_k=50:4.9418,lwr_k=100:5.1461,lwr_k=200:5.334,lwr_k=500:5.529,lwr_k=1000:5.593'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.8772,knn_k=1:5.8627,knn_k=5:4.9764,knn_k=10:4.9905,knn_k=20:4.9143,knn_k=50:4.9807,knn_k=100:5.0303,lwr_k=20:4.9118,lwr_k=50:4.9739,lwr_k=100:5.0112,lwr_k=200:5.1322,lwr_k=500:5.2698,lwr_k=1000:5.3439'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.9561,knn_k=1:0.0,knn_k=5:3.1263,knn_k=10:3.9853,knn_k=20:4.4515,knn_k=50:4.8974,knn_k=100:5.1132,lwr_k=20:4.4489,lwr_k=50:4.8902,lwr_k=100:5.0955,lwr_k=200:5.2722,lwr_k=500:5.4291,lwr_k=1000:5.5145'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.8519,knn_k=1:4.9031,knn_k=5:4.756,knn_k=10:4.7828,knn_k=20:4.8373,knn_k=50:4.8972,knn_k=100:4.9925,lwr_k=20:4.8358,lwr_k=50:4.8908,lwr_k=100:4.9674,lwr_k=200:5.0574,lwr_k=500:5.1974,lwr_k=1000:5.2599'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_46'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0306,knn_k=1:0.0,knn_k=5:0.8216,knn_k=10:1.0313,knn_k=20:1.2095,knn_k=50:1.3935,knn_k=100:1.5061,lwr_k=20:1.086,lwr_k=50:1.1274,lwr_k=100:1.1358,lwr_k=200:1.1418,lwr_k=500:1.1379,lwr_k=1000:1.114'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.0562,knn_k=1:1.7702,knn_k=5:1.2879,knn_k=10:1.3185,knn_k=20:1.4013,knn_k=50:1.5453,knn_k=100:1.6352,lwr_k=20:1.3015,lwr_k=50:1.2876,lwr_k=100:1.2604,lwr_k=200:1.2423,lwr_k=500:1.1911,lwr_k=1000:1.1474'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6817,knn_k=1:0.0,knn_k=5:0.5399,knn_k=10:0.6212,knn_k=20:0.6596,knn_k=50:0.6967,knn_k=100:0.7128,lwr_k=20:0.6345,lwr_k=50:0.6578,lwr_k=100:0.6689,lwr_k=200:0.6737,lwr_k=500:0.6801,lwr_k=1000:0.6846'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7286,knn_k=1:1.3146,knn_k=5:0.8525,knn_k=10:0.7975,knn_k=20:0.7761,knn_k=50:0.7709,knn_k=100:0.7734,lwr_k=20:0.7733,lwr_k=50:0.7656,lwr_k=100:0.7598,lwr_k=200:0.7533,lwr_k=500:0.7449,lwr_k=1000:0.7464'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.5112,knn_k=1:0.0,knn_k=5:1.0856,knn_k=10:1.2775,knn_k=20:1.4038,knn_k=50:1.5109,knn_k=100:1.5665,lwr_k=20:1.3085,lwr_k=50:1.3584,lwr_k=100:1.3802,lwr_k=200:1.3991,lwr_k=500:1.4231,lwr_k=1000:1.4581'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.5368,knn_k=1:2.4282,knn_k=5:1.6469,knn_k=10:1.5434,knn_k=20:1.5661,knn_k=50:1.6148,knn_k=100:1.6496,lwr_k=20:1.5125,lwr_k=50:1.4946,lwr_k=100:1.4839,lwr_k=200:1.466,lwr_k=500:1.464,lwr_k=1000:1.4948'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.154,knn_k=1:0.0,knn_k=5:0.8308,knn_k=10:1.0097,knn_k=20:1.2143,knn_k=50:1.6371,knn_k=100:2.0525,lwr_k=20:1.0844,lwr_k=50:1.2042,lwr_k=100:1.2093,lwr_k=200:1.1735,lwr_k=500:1.1441,lwr_k=1000:1.1397'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0826,knn_k=1:1.8552,knn_k=5:1.2576,knn_k=10:1.2284,knn_k=20:1.3438,knn_k=50:1.7031,knn_k=100:2.0963,lwr_k=20:1.2296,lwr_k=50:1.2871,lwr_k=100:1.2531,lwr_k=200:1.1811,lwr_k=500:1.1175,lwr_k=1000:1.0897'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8888,knn_k=1:0.0,knn_k=5:0.6616,knn_k=10:0.8047,knn_k=20:0.8977,knn_k=50:0.9819,knn_k=100:1.022,lwr_k=20:0.852,lwr_k=50:0.8937,lwr_k=100:0.9049,lwr_k=200:0.9315,lwr_k=500:0.9435,lwr_k=1000:0.9348'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8939,knn_k=1:1.5415,knn_k=5:1.0788,knn_k=10:1.0534,knn_k=20:1.0463,knn_k=50:1.0764,knn_k=100:1.1012,lwr_k=20:1.018,lwr_k=50:1.0086,lwr_k=100:0.9996,lwr_k=200:1.0024,lwr_k=500:0.9889,lwr_k=1000:0.9698'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7307,knn_k=1:0.0,knn_k=5:0.6045,knn_k=10:0.7094,knn_k=20:0.7711,knn_k=50:0.8333,knn_k=100:0.8606,lwr_k=20:0.7496,lwr_k=50:0.7848,lwr_k=100:0.789,lwr_k=200:0.7864,lwr_k=500:0.7773,lwr_k=1000:0.7717'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7613,knn_k=1:1.4357,knn_k=5:0.9494,knn_k=10:0.8959,knn_k=20:0.8711,knn_k=50:0.8711,knn_k=100:0.8806,lwr_k=20:0.8585,lwr_k=50:0.843,lwr_k=100:0.8355,lwr_k=200:0.8264,lwr_k=500:0.8063,lwr_k=1000:0.7925'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_47'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.8233,knn_k=1:33.657,knn_k=5:6.7221,knn_k=10:6.2679,knn_k=20:5.8461,knn_k=50:5.9294,knn_k=100:5.8353,lwr_k=20:5.8363,lwr_k=50:5.925,lwr_k=100:5.8261,lwr_k=200:5.8246,lwr_k=500:5.8234,lwr_k=1000:5.8221'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.1638,knn_k=1:34.6509,knn_k=5:7.1933,knn_k=10:6.6925,knn_k=20:6.1633,knn_k=50:6.2956,knn_k=100:6.1621,lwr_k=20:6.1774,lwr_k=50:6.2987,lwr_k=100:6.1626,lwr_k=200:6.1737,lwr_k=500:6.1717,lwr_k=1000:6.1627'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2280.712,knn_k=1:6.0394,knn_k=5:7.2257,knn_k=10:8.1335,knn_k=20:6.2596,knn_k=50:6.0859,knn_k=100:6.0105,lwr_k=20:6.2596,lwr_k=50:6.0859,lwr_k=100:6.0105,lwr_k=200:5.983,lwr_k=500:5.9852,lwr_k=1000:5.9788'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2284.8425,knn_k=1:6.1809,knn_k=5:7.459,knn_k=10:8.404,knn_k=20:6.431,knn_k=50:6.2359,knn_k=100:6.1448,lwr_k=20:6.431,lwr_k=50:6.2359,lwr_k=100:6.1448,lwr_k=200:6.1053,lwr_k=500:6.1091,lwr_k=1000:6.0931'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1011.0284,knn_k=1:6.1165,knn_k=5:7.3221,knn_k=10:7.2611,knn_k=20:6.1739,knn_k=50:6.1193,knn_k=100:6.0732,lwr_k=20:6.1739,lwr_k=50:6.1193,lwr_k=100:6.0732,lwr_k=200:6.0535,lwr_k=500:6.0573,lwr_k=1000:6.0502'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1012.8024,knn_k=1:6.2399,knn_k=5:7.4843,knn_k=10:7.422,knn_k=20:6.3015,knn_k=50:6.2429,knn_k=100:6.1918,lwr_k=20:6.3015,lwr_k=50:6.2429,lwr_k=100:6.1918,lwr_k=200:6.1679,lwr_k=500:6.1729,lwr_k=1000:6.1619'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.958,knn_k=1:11.6198,knn_k=5:7.5115,knn_k=10:6.1795,knn_k=20:6.2981,knn_k=50:6.2428,knn_k=100:6.0983,lwr_k=20:6.2915,lwr_k=50:6.2309,lwr_k=100:6.0855,lwr_k=200:5.994,lwr_k=500:5.9631,lwr_k=1000:5.9561'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.7269,knn_k=1:10.7986,knn_k=5:6.9659,knn_k=10:5.8075,knn_k=20:6.1178,knn_k=50:6.0362,knn_k=100:5.8523,lwr_k=20:6.1255,lwr_k=50:6.0435,lwr_k=100:5.8588,lwr_k=200:5.7915,lwr_k=500:5.7322,lwr_k=1000:5.7159'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:594.4521,knn_k=1:10.0682,knn_k=5:6.5531,knn_k=10:6.2155,knn_k=20:6.2119,knn_k=50:6.2337,knn_k=100:6.2308,lwr_k=20:6.2119,lwr_k=50:6.2337,lwr_k=100:6.2308,lwr_k=200:6.2164,lwr_k=500:6.2243,lwr_k=1000:6.212'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:594.7792,knn_k=1:9.7164,knn_k=5:6.2601,knn_k=10:5.9105,knn_k=20:5.905,knn_k=50:5.9238,knn_k=100:5.9211,lwr_k=20:5.905,lwr_k=50:5.9238,lwr_k=100:5.9211,lwr_k=200:5.9115,lwr_k=500:5.9204,lwr_k=1000:5.905'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6318,knn_k=1:0.0,knn_k=5:0.4996,knn_k=10:0.5582,knn_k=20:0.5921,knn_k=50:0.619,knn_k=100:0.6385,lwr_k=20:0.531,lwr_k=50:0.57,lwr_k=100:0.5845,lwr_k=200:0.5956,lwr_k=500:0.6075,lwr_k=1000:0.614'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6638,knn_k=1:1.1921,knn_k=5:0.7612,knn_k=10:0.7142,knn_k=20:0.6941,knn_k=50:0.6725,knn_k=100:0.6847,lwr_k=20:0.694,lwr_k=50:0.6657,lwr_k=100:0.6474,lwr_k=200:0.6462,lwr_k=500:0.6537,lwr_k=1000:0.65'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_48'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7953,knn_k=1:0.0,knn_k=5:0.6062,knn_k=10:0.7568,knn_k=20:0.861,knn_k=50:0.9595,knn_k=100:1.0258,lwr_k=20:0.4533,lwr_k=50:0.5219,lwr_k=100:0.5701,lwr_k=200:0.6072,lwr_k=500:0.6484,lwr_k=1000:0.6803'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8029,knn_k=1:1.1636,knn_k=5:0.9497,knn_k=10:0.9283,knn_k=20:0.9666,knn_k=50:1.0247,knn_k=100:1.0808,lwr_k=20:0.7235,lwr_k=50:0.6965,lwr_k=100:0.6825,lwr_k=200:0.6835,lwr_k=500:0.6893,lwr_k=1000:0.7041'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6224,knn_k=1:0.0,knn_k=5:0.4246,knn_k=10:0.5561,knn_k=20:0.6459,knn_k=50:0.7474,knn_k=100:0.8392,lwr_k=20:0.0971,lwr_k=50:0.2238,lwr_k=100:0.3382,lwr_k=200:0.4382,lwr_k=500:0.5333,lwr_k=1000:0.5742'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6577,knn_k=1:0.7753,knn_k=5:0.7342,knn_k=10:0.7529,knn_k=20:0.7616,knn_k=50:0.809,knn_k=100:0.8918,lwr_k=20:0.6672,lwr_k=50:0.6602,lwr_k=100:0.6512,lwr_k=200:0.6226,lwr_k=500:0.6429,lwr_k=1000:0.6544'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9572,knn_k=1:0.0,knn_k=5:0.6659,knn_k=10:0.8852,knn_k=20:1.0853,knn_k=50:1.3308,knn_k=100:1.5388,lwr_k=20:0.0988,lwr_k=50:0.2485,lwr_k=100:0.3822,lwr_k=200:0.5,lwr_k=500:0.6355,lwr_k=1000:0.7185'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9838,knn_k=1:1.1594,knn_k=5:1.0855,knn_k=10:1.1201,knn_k=20:1.2356,knn_k=50:1.4118,knn_k=100:1.6219,lwr_k=20:0.7827,lwr_k=50:0.727,lwr_k=100:0.6795,lwr_k=200:0.6955,lwr_k=500:0.7349,lwr_k=1000:0.773'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0552,knn_k=1:0.0,knn_k=5:0.7786,knn_k=10:0.9928,knn_k=20:1.1781,knn_k=50:1.4175,knn_k=100:1.5876,lwr_k=20:0.5403,lwr_k=50:0.6047,lwr_k=100:0.6484,lwr_k=200:0.6822,lwr_k=500:0.7322,lwr_k=1000:0.7693'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0767,knn_k=1:1.4595,knn_k=5:1.1809,knn_k=10:1.2416,knn_k=20:1.3332,knn_k=50:1.5211,knn_k=100:1.671,lwr_k=20:0.8318,lwr_k=50:0.732,lwr_k=100:0.7189,lwr_k=200:0.7129,lwr_k=500:0.7389,lwr_k=1000:0.7697'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7457,knn_k=1:0.0,knn_k=5:0.4913,knn_k=10:0.6029,knn_k=20:0.6844,knn_k=50:0.7637,knn_k=100:0.8219,lwr_k=20:0.4713,lwr_k=50:0.55,lwr_k=100:0.5837,lwr_k=200:0.6134,lwr_k=500:0.6508,lwr_k=1000:0.677'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7655,knn_k=1:1.0902,knn_k=5:0.8042,knn_k=10:0.7902,knn_k=20:0.799,knn_k=50:0.8344,knn_k=100:0.8723,lwr_k=20:0.7077,lwr_k=50:0.6894,lwr_k=100:0.6925,lwr_k=200:0.7031,lwr_k=500:0.714,lwr_k=1000:0.7308'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6095,knn_k=1:0.0,knn_k=5:0.4521,knn_k=10:0.5275,knn_k=20:0.569,knn_k=50:0.6041,knn_k=100:0.6204,lwr_k=20:0.4858,lwr_k=50:0.5352,lwr_k=100:0.5586,lwr_k=200:0.5734,lwr_k=500:0.5894,lwr_k=1000:0.5991'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6237,knn_k=1:0.9892,knn_k=5:0.7018,knn_k=10:0.6573,knn_k=20:0.6337,knn_k=50:0.6273,knn_k=100:0.6334,lwr_k=20:0.619,lwr_k=50:0.5992,lwr_k=100:0.6048,lwr_k=200:0.6107,lwr_k=500:0.6115,lwr_k=1000:0.6176'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_49'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1561,knn_k=1:0.0,knn_k=5:0.6612,knn_k=10:0.7756,knn_k=20:0.8587,knn_k=50:0.9549,knn_k=100:1.0303,lwr_k=20:0.7845,lwr_k=50:0.8335,lwr_k=100:0.8572,lwr_k=200:0.8783,lwr_k=500:0.9124,lwr_k=1000:0.9419'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.2181,knn_k=1:1.5309,knn_k=5:1.027,knn_k=10:1.01,knn_k=20:0.9923,knn_k=50:1.0353,knn_k=100:1.0983,lwr_k=20:0.9416,lwr_k=50:0.9388,lwr_k=100:0.9408,lwr_k=200:0.9392,lwr_k=500:0.9524,lwr_k=1000:0.983'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8454,knn_k=1:0.0,knn_k=5:0.6241,knn_k=10:0.7217,knn_k=20:0.7609,knn_k=50:0.7965,knn_k=100:0.8159,lwr_k=20:0.7449,lwr_k=50:0.7705,lwr_k=100:0.783,lwr_k=200:0.7953,lwr_k=500:0.8114,lwr_k=1000:0.8221'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9023,knn_k=1:1.5178,knn_k=5:0.9707,knn_k=10:0.9088,knn_k=20:0.9011,knn_k=50:0.8882,knn_k=100:0.8907,lwr_k=20:0.8943,lwr_k=50:0.873,lwr_k=100:0.8678,lwr_k=200:0.8691,lwr_k=500:0.8709,lwr_k=1000:0.8772'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2496,knn_k=1:0.0,knn_k=5:0.8526,knn_k=10:0.9782,knn_k=20:1.0578,knn_k=50:1.1329,knn_k=100:1.1734,lwr_k=20:0.9286,lwr_k=50:1.0106,lwr_k=100:1.0413,lwr_k=200:1.0706,lwr_k=500:1.1049,lwr_k=1000:1.137'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2887,knn_k=1:2.0467,knn_k=5:1.3054,knn_k=10:1.2162,knn_k=20:1.1688,knn_k=50:1.1787,knn_k=100:1.2056,lwr_k=20:1.1406,lwr_k=50:1.1038,lwr_k=100:1.0956,lwr_k=200:1.0996,lwr_k=500:1.1283,lwr_k=1000:1.1588'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.5116,knn_k=1:0.0,knn_k=5:0.8866,knn_k=10:1.0892,knn_k=20:1.3039,knn_k=50:1.6188,knn_k=100:1.9291,lwr_k=20:1.1875,lwr_k=50:1.306,lwr_k=100:1.2994,lwr_k=200:1.2167,lwr_k=500:1.197,lwr_k=1000:1.204'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.5189,knn_k=1:2.3008,knn_k=5:1.4844,knn_k=10:1.4677,knn_k=20:1.548,knn_k=50:1.7737,knn_k=100:2.0472,lwr_k=20:1.391,lwr_k=50:1.4152,lwr_k=100:1.3686,lwr_k=200:1.2534,lwr_k=500:1.1873,lwr_k=1000:1.1737'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2427,knn_k=1:0.0,knn_k=5:0.7809,knn_k=10:0.9295,knn_k=20:1.0297,knn_k=50:1.1299,knn_k=100:1.1905,lwr_k=20:0.9962,lwr_k=50:1.0533,lwr_k=100:1.056,lwr_k=200:1.0356,lwr_k=500:1.0217,lwr_k=1000:1.0312'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2697,knn_k=1:1.9276,knn_k=5:1.218,knn_k=10:1.1571,knn_k=20:1.1828,knn_k=50:1.2206,knn_k=100:1.2599,lwr_k=20:1.1506,lwr_k=50:1.1441,lwr_k=100:1.1261,lwr_k=200:1.0945,lwr_k=500:1.0672,lwr_k=1000:1.0758'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.8078,knn_k=1:0.0,knn_k=5:0.5811,knn_k=10:0.6705,knn_k=20:0.7223,knn_k=50:0.7578,knn_k=100:0.7774,lwr_k=20:0.6814,lwr_k=50:0.7202,lwr_k=100:0.7403,lwr_k=200:0.7567,lwr_k=500:0.7765,lwr_k=1000:0.7864'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7905,knn_k=1:1.3948,knn_k=5:0.8401,knn_k=10:0.7839,knn_k=20:0.7633,knn_k=50:0.7695,knn_k=100:0.77,lwr_k=20:0.7443,lwr_k=50:0.7404,lwr_k=100:0.7431,lwr_k=200:0.753,lwr_k=500:0.7647,lwr_k=1000:0.7694'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_50'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9357,knn_k=1:0.0,knn_k=5:0.7644,knn_k=10:0.9287,knn_k=20:1.0446,knn_k=50:1.1887,knn_k=100:1.3064,lwr_k=20:0.9776,lwr_k=50:1.022,lwr_k=100:1.0192,lwr_k=200:1.013,lwr_k=500:1.0096,lwr_k=1000:1.0012'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9468,knn_k=1:1.7227,knn_k=5:1.2391,knn_k=10:1.2054,knn_k=20:1.2235,knn_k=50:1.3136,knn_k=100:1.4073,lwr_k=20:1.1817,lwr_k=50:1.1636,lwr_k=100:1.1304,lwr_k=200:1.1026,lwr_k=500:1.0855,lwr_k=1000:1.0664'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7301,knn_k=1:0.0,knn_k=5:0.579,knn_k=10:0.6479,knn_k=20:0.6865,knn_k=50:0.711,knn_k=100:0.7242,lwr_k=20:0.6722,lwr_k=50:0.6932,lwr_k=100:0.7013,lwr_k=200:0.7081,lwr_k=500:0.7176,lwr_k=1000:0.7235'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7649,knn_k=1:1.3965,knn_k=5:0.8684,knn_k=10:0.8175,knn_k=20:0.7797,knn_k=50:0.7707,knn_k=100:0.7705,lwr_k=20:0.7786,lwr_k=50:0.7674,lwr_k=100:0.7614,lwr_k=200:0.7585,lwr_k=500:0.7583,lwr_k=1000:0.7575'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2239,knn_k=1:0.0,knn_k=5:0.9438,knn_k=10:1.1169,knn_k=20:1.2451,knn_k=50:1.3866,knn_k=100:1.4593,lwr_k=20:1.2064,lwr_k=50:1.292,lwr_k=100:1.2953,lwr_k=200:1.2656,lwr_k=500:1.2172,lwr_k=1000:1.2003'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.281,knn_k=1:2.3374,knn_k=5:1.4384,knn_k=10:1.4183,knn_k=20:1.4428,knn_k=50:1.4737,knn_k=100:1.5091,lwr_k=20:1.4195,lwr_k=50:1.4059,lwr_k=100:1.3762,lwr_k=200:1.3343,lwr_k=500:1.2904,lwr_k=1000:1.2659'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3672,knn_k=1:0.0,knn_k=5:0.9804,knn_k=10:1.2156,knn_k=20:1.3785,knn_k=50:1.6142,knn_k=100:1.8944,lwr_k=20:1.3098,lwr_k=50:1.387,lwr_k=100:1.3819,lwr_k=200:1.3512,lwr_k=500:1.3235,lwr_k=1000:1.3179'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.422,knn_k=1:2.2453,knn_k=5:1.5417,knn_k=10:1.5439,knn_k=20:1.5868,knn_k=50:1.7431,knn_k=100:1.9971,lwr_k=20:1.5301,lwr_k=50:1.534,lwr_k=100:1.4917,lwr_k=200:1.4358,lwr_k=500:1.3742,lwr_k=1000:1.3493'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1404,knn_k=1:0.0,knn_k=5:0.797,knn_k=10:0.943,knn_k=20:1.0286,knn_k=50:1.1153,knn_k=100:1.1576,lwr_k=20:0.9982,lwr_k=50:1.0495,lwr_k=100:1.0619,lwr_k=200:1.0718,lwr_k=500:1.0757,lwr_k=1000:1.0792'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1727,knn_k=1:1.9306,knn_k=5:1.2602,knn_k=10:1.2223,knn_k=20:1.2026,knn_k=50:1.2038,knn_k=100:1.2211,lwr_k=20:1.1822,lwr_k=50:1.1558,lwr_k=100:1.1438,lwr_k=200:1.1402,lwr_k=500:1.1236,lwr_k=1000:1.1201'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.737,knn_k=1:0.0,knn_k=5:0.5708,knn_k=10:0.6486,knn_k=20:0.6876,knn_k=50:0.7183,knn_k=100:0.729,lwr_k=20:0.6762,lwr_k=50:0.698,lwr_k=100:0.7052,lwr_k=200:0.7128,lwr_k=500:0.7221,lwr_k=1000:0.7258'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7483,knn_k=1:1.3159,knn_k=5:0.8499,knn_k=10:0.7906,knn_k=20:0.7654,knn_k=50:0.7532,knn_k=100:0.7527,lwr_k=20:0.7602,lwr_k=50:0.7419,lwr_k=100:0.7401,lwr_k=200:0.7426,lwr_k=500:0.7394,lwr_k=1000:0.7432'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_51'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7975,knn_k=1:0.0,knn_k=5:0.5556,knn_k=10:0.6847,knn_k=20:0.7819,knn_k=50:0.9011,knn_k=100:0.9914,lwr_k=20:0.5571,lwr_k=50:0.6153,lwr_k=100:0.6562,lwr_k=200:0.6876,lwr_k=500:0.7319,lwr_k=1000:0.7614'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8305,knn_k=1:1.1019,knn_k=5:0.8771,knn_k=10:0.8835,knn_k=20:0.9114,knn_k=50:0.9934,knn_k=100:1.0687,lwr_k=20:0.7477,lwr_k=50:0.74,lwr_k=100:0.7459,lwr_k=200:0.7556,lwr_k=500:0.7743,lwr_k=1000:0.8017'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7066,knn_k=1:0.0,knn_k=5:0.4968,knn_k=10:0.6034,knn_k=20:0.6651,knn_k=50:0.7143,knn_k=100:0.7313,lwr_k=20:0.5565,lwr_k=50:0.6027,lwr_k=100:0.6256,lwr_k=200:0.6492,lwr_k=500:0.6735,lwr_k=1000:0.6882'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7616,knn_k=1:1.1917,knn_k=5:0.852,knn_k=10:0.8072,knn_k=20:0.7991,knn_k=50:0.7946,knn_k=100:0.8016,lwr_k=20:0.7522,lwr_k=50:0.7638,lwr_k=100:0.7651,lwr_k=200:0.7549,lwr_k=500:0.7533,lwr_k=1000:0.7519'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7546,knn_k=1:0.0,knn_k=5:0.6061,knn_k=10:0.7438,knn_k=20:0.8336,knn_k=50:0.941,knn_k=100:1.0429,lwr_k=20:0.6143,lwr_k=50:0.6489,lwr_k=100:0.6756,lwr_k=200:0.7041,lwr_k=500:0.7314,lwr_k=1000:0.7536'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7794,knn_k=1:1.2934,knn_k=5:0.9334,knn_k=10:0.9252,knn_k=20:0.9299,knn_k=50:0.992,knn_k=100:1.0806,lwr_k=20:0.8057,lwr_k=50:0.7786,lwr_k=100:0.774,lwr_k=200:0.776,lwr_k=500:0.7833,lwr_k=1000:0.7812'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8202,knn_k=1:0.0,knn_k=5:0.5708,knn_k=10:0.707,knn_k=20:0.8073,knn_k=50:0.927,knn_k=100:1.0421,lwr_k=20:0.5932,lwr_k=50:0.6428,lwr_k=100:0.6706,lwr_k=200:0.6986,lwr_k=500:0.7382,lwr_k=1000:0.7634'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7868,knn_k=1:1.1822,knn_k=5:0.8414,knn_k=10:0.8487,knn_k=20:0.8633,knn_k=50:0.9316,knn_k=100:1.0274,lwr_k=20:0.7333,lwr_k=50:0.7313,lwr_k=100:0.7249,lwr_k=200:0.7104,lwr_k=500:0.7233,lwr_k=1000:0.7331'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7832,knn_k=1:0.0,knn_k=5:0.5325,knn_k=10:0.6516,knn_k=20:0.7339,knn_k=50:0.8033,knn_k=100:0.8611,lwr_k=20:0.5936,lwr_k=50:0.6332,lwr_k=100:0.6617,lwr_k=200:0.693,lwr_k=500:0.7227,lwr_k=1000:0.7461'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7988,knn_k=1:1.1893,knn_k=5:0.8345,knn_k=10:0.8094,knn_k=20:0.8303,knn_k=50:0.8677,knn_k=100:0.9123,lwr_k=20:0.7606,lwr_k=50:0.7452,lwr_k=100:0.7538,lwr_k=200:0.7653,lwr_k=500:0.7745,lwr_k=1000:0.7777'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7519,knn_k=1:0.0,knn_k=5:0.5204,knn_k=10:0.6121,knn_k=20:0.6738,knn_k=50:0.7251,knn_k=100:0.7471,lwr_k=20:0.567,lwr_k=50:0.6115,lwr_k=100:0.6407,lwr_k=200:0.6656,lwr_k=500:0.689,lwr_k=1000:0.7057'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7787,knn_k=1:1.0473,knn_k=5:0.79,knn_k=10:0.7523,knn_k=20:0.7487,knn_k=50:0.7735,knn_k=100:0.7802,lwr_k=20:0.6951,lwr_k=50:0.7049,lwr_k=100:0.716,lwr_k=200:0.7309,lwr_k=500:0.7431,lwr_k=1000:0.7442'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_52'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9928,knn_k=1:0.0,knn_k=5:0.5911,knn_k=10:0.7469,knn_k=20:0.872,knn_k=50:1.0148,knn_k=100:1.1242,lwr_k=20:0.4079,lwr_k=50:0.5081,lwr_k=100:0.5797,lwr_k=200:0.639,lwr_k=500:0.7028,lwr_k=1000:0.7568'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.0313,knn_k=1:1.1295,knn_k=5:0.9104,knn_k=10:0.936,knn_k=20:0.9791,knn_k=50:1.0651,knn_k=100:1.169,lwr_k=20:0.7776,lwr_k=50:0.7801,lwr_k=100:0.7757,lwr_k=200:0.7726,lwr_k=500:0.7871,lwr_k=1000:0.8128'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7028,knn_k=1:0.0,knn_k=5:0.4762,knn_k=10:0.5868,knn_k=20:0.6577,knn_k=50:0.7107,knn_k=100:0.7588,lwr_k=20:0.303,lwr_k=50:0.4203,lwr_k=100:0.502,lwr_k=200:0.5625,lwr_k=500:0.6181,lwr_k=1000:0.6564'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7623,knn_k=1:0.9544,knn_k=5:0.7832,knn_k=10:0.7689,knn_k=20:0.7742,knn_k=50:0.7957,knn_k=100:0.8356,lwr_k=20:0.7366,lwr_k=50:0.7202,lwr_k=100:0.7157,lwr_k=200:0.7096,lwr_k=500:0.7242,lwr_k=1000:0.7481'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1702,knn_k=1:0.0,knn_k=5:0.8298,knn_k=10:1.0049,knn_k=20:1.1068,knn_k=50:1.2242,knn_k=100:1.3,lwr_k=20:0.8436,lwr_k=50:0.8887,lwr_k=100:0.9182,lwr_k=200:0.9397,lwr_k=500:0.9669,lwr_k=1000:0.9957'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1689,knn_k=1:1.7597,knn_k=5:1.1833,knn_k=10:1.1643,knn_k=20:1.2103,knn_k=50:1.2701,knn_k=100:1.3281,lwr_k=20:1.047,lwr_k=50:0.989,lwr_k=100:0.9713,lwr_k=200:0.9747,lwr_k=500:0.9777,lwr_k=1000:0.993'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4747,knn_k=1:0.0,knn_k=5:0.8028,knn_k=10:1.0189,knn_k=20:1.2015,knn_k=50:1.435,knn_k=100:1.6128,lwr_k=20:0.7209,lwr_k=50:0.8038,lwr_k=100:0.8471,lwr_k=200:0.8865,lwr_k=500:0.9485,lwr_k=1000:1.0165'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.5494,knn_k=1:1.6581,knn_k=5:1.2281,knn_k=10:1.2827,knn_k=20:1.3874,knn_k=50:1.5391,knn_k=100:1.6864,lwr_k=20:1.0759,lwr_k=50:1.0312,lwr_k=100:1.0087,lwr_k=200:0.9818,lwr_k=500:1.0206,lwr_k=1000:1.0736'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9145,knn_k=1:0.0,knn_k=5:0.5952,knn_k=10:0.7045,knn_k=20:0.7873,knn_k=50:0.865,knn_k=100:0.9365,lwr_k=20:0.6476,lwr_k=50:0.6945,lwr_k=100:0.7194,lwr_k=200:0.7389,lwr_k=500:0.7634,lwr_k=1000:0.7857'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9538,knn_k=1:1.3303,knn_k=5:0.9317,knn_k=10:0.8976,knn_k=20:0.9057,knn_k=50:0.9196,knn_k=100:0.9849,lwr_k=20:0.8265,lwr_k=50:0.8025,lwr_k=100:0.7894,lwr_k=200:0.7875,lwr_k=500:0.7987,lwr_k=1000:0.8192'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6888,knn_k=1:0.0,knn_k=5:0.4864,knn_k=10:0.5741,knn_k=20:0.6233,knn_k=50:0.6665,knn_k=100:0.6876,lwr_k=20:0.5133,lwr_k=50:0.5694,lwr_k=100:0.5962,lwr_k=200:0.6139,lwr_k=500:0.6339,lwr_k=1000:0.6483'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6835,knn_k=1:1.0321,knn_k=5:0.7305,knn_k=10:0.7099,knn_k=20:0.6937,knn_k=50:0.6923,knn_k=100:0.7018,lwr_k=20:0.6658,lwr_k=50:0.6577,lwr_k=100:0.6486,lwr_k=200:0.6496,lwr_k=500:0.6511,lwr_k=1000:0.6553'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_53'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.003,knn_k=1:0.0,knn_k=5:0.8015,knn_k=10:0.9523,knn_k=20:1.0693,knn_k=50:1.1869,knn_k=100:1.2648,lwr_k=20:1.0436,lwr_k=50:1.1074,lwr_k=100:1.1301,lwr_k=200:1.1413,lwr_k=500:1.1285,lwr_k=1000:1.1192'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.013,knn_k=1:1.8849,knn_k=5:1.2031,knn_k=10:1.1592,knn_k=20:1.1515,knn_k=50:1.2598,knn_k=100:1.3336,lwr_k=20:1.1306,lwr_k=50:1.1757,lwr_k=100:1.1798,lwr_k=200:1.1746,lwr_k=500:1.1565,lwr_k=1000:1.1447'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7265,knn_k=1:0.0,knn_k=5:0.5603,knn_k=10:0.6335,knn_k=20:0.6781,knn_k=50:0.7099,knn_k=100:0.7311,lwr_k=20:0.6667,lwr_k=50:0.6883,lwr_k=100:0.6997,lwr_k=200:0.7067,lwr_k=500:0.7117,lwr_k=1000:0.7176'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7825,knn_k=1:1.4489,knn_k=5:0.9122,knn_k=10:0.8463,knn_k=20:0.8132,knn_k=50:0.8035,knn_k=100:0.7978,lwr_k=20:0.8105,lwr_k=50:0.7951,lwr_k=100:0.7847,lwr_k=200:0.7792,lwr_k=500:0.7797,lwr_k=1000:0.7776'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1261,knn_k=1:0.0,knn_k=5:1.0005,knn_k=10:1.1585,knn_k=20:1.2559,knn_k=50:1.3565,knn_k=100:1.4037,lwr_k=20:1.237,lwr_k=50:1.3147,lwr_k=100:1.3337,lwr_k=200:1.3295,lwr_k=500:1.3129,lwr_k=1000:1.2967'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1226,knn_k=1:2.3983,knn_k=5:1.477,knn_k=10:1.4114,knn_k=20:1.4049,knn_k=50:1.437,knn_k=100:1.4574,lwr_k=20:1.3978,lwr_k=50:1.4119,lwr_k=100:1.4075,lwr_k=200:1.3973,lwr_k=500:1.3605,lwr_k=1000:1.3261'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8613,knn_k=1:0.0,knn_k=5:0.6926,knn_k=10:0.8372,knn_k=20:0.9373,knn_k=50:1.1084,knn_k=100:1.2928,lwr_k=20:0.8943,lwr_k=50:0.9709,lwr_k=100:0.9921,lwr_k=200:0.9752,lwr_k=500:0.9361,lwr_k=1000:0.9226'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8528,knn_k=1:1.6268,knn_k=5:1.1092,knn_k=10:1.0715,knn_k=20:1.0755,knn_k=50:1.2195,knn_k=100:1.4124,lwr_k=20:1.0411,lwr_k=50:1.0719,lwr_k=100:1.0746,lwr_k=200:1.0337,lwr_k=500:0.9643,lwr_k=1000:0.9282'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9189,knn_k=1:0.0,knn_k=5:0.7994,knn_k=10:0.9405,knn_k=20:1.0475,knn_k=50:1.1528,knn_k=100:1.2165,lwr_k=20:1.0333,lwr_k=50:1.1151,lwr_k=100:1.1441,lwr_k=200:1.1519,lwr_k=500:1.1283,lwr_k=1000:1.1005'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9392,knn_k=1:1.8636,knn_k=5:1.2333,knn_k=10:1.1856,knn_k=20:1.199,knn_k=50:1.2438,knn_k=100:1.2838,lwr_k=20:1.1883,lwr_k=50:1.2153,lwr_k=100:1.2256,lwr_k=200:1.2241,lwr_k=500:1.1806,lwr_k=1000:1.1458'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6238,knn_k=1:0.0,knn_k=5:0.4671,knn_k=10:0.537,knn_k=20:0.5786,knn_k=50:0.6078,knn_k=100:0.6189,lwr_k=20:0.57,lwr_k=50:0.5931,lwr_k=100:0.5995,lwr_k=200:0.605,lwr_k=500:0.6111,lwr_k=1000:0.6142'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.629,knn_k=1:1.1477,knn_k=5:0.7181,knn_k=10:0.6689,knn_k=20:0.6433,knn_k=50:0.6365,knn_k=100:0.6321,lwr_k=20:0.641,lwr_k=50:0.6289,lwr_k=100:0.6192,lwr_k=200:0.6188,lwr_k=500:0.6158,lwr_k=1000:0.6205'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_54'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4134,knn_k=1:0.0,knn_k=5:0.6572,knn_k=10:0.8792,knn_k=20:1.0614,knn_k=50:1.3308,knn_k=100:1.5964,lwr_k=20:0.2276,lwr_k=50:0.4635,lwr_k=100:0.617,lwr_k=200:0.7417,lwr_k=500:0.8638,lwr_k=1000:0.9518'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.437,knn_k=1:1.0702,knn_k=5:1.0552,knn_k=10:1.1107,knn_k=20:1.2317,knn_k=50:1.4398,knn_k=100:1.6845,lwr_k=20:1.0249,lwr_k=50:0.8716,lwr_k=100:0.882,lwr_k=200:0.8738,lwr_k=500:0.9219,lwr_k=1000:0.9846'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7194,knn_k=1:0.0,knn_k=5:0.4705,knn_k=10:0.6145,knn_k=20:0.7213,knn_k=50:0.8827,knn_k=100:1.041,lwr_k=20:0.19,lwr_k=50:0.3944,lwr_k=100:0.5039,lwr_k=200:0.5741,lwr_k=500:0.6321,lwr_k=1000:0.6652'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7627,knn_k=1:0.8314,knn_k=5:0.8038,knn_k=10:0.8153,knn_k=20:0.8484,knn_k=50:0.9901,knn_k=100:1.1229,lwr_k=20:0.7988,lwr_k=50:0.7032,lwr_k=100:0.6949,lwr_k=200:0.6987,lwr_k=500:0.7096,lwr_k=1000:0.73'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2914,knn_k=1:0.0,knn_k=5:0.7054,knn_k=10:0.9207,knn_k=20:1.1051,knn_k=50:1.3411,knn_k=100:1.5352,lwr_k=20:0.2589,lwr_k=50:0.4878,lwr_k=100:0.6187,lwr_k=200:0.7219,lwr_k=500:0.8396,lwr_k=1000:0.9483'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.289,knn_k=1:1.183,knn_k=5:1.1661,knn_k=10:1.1858,knn_k=20:1.2791,knn_k=50:1.4377,knn_k=100:1.6107,lwr_k=20:0.8954,lwr_k=50:0.8194,lwr_k=100:0.8034,lwr_k=200:0.8259,lwr_k=500:0.8592,lwr_k=1000:0.9475'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3898,knn_k=1:0.0,knn_k=5:0.6893,knn_k=10:0.9059,knn_k=20:1.0825,knn_k=50:1.3241,knn_k=100:1.5449,lwr_k=20:0.1882,lwr_k=50:0.4469,lwr_k=100:0.6186,lwr_k=200:0.7308,lwr_k=500:0.8544,lwr_k=1000:0.9512'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.394,knn_k=1:0.9714,knn_k=5:1.0082,knn_k=10:1.0732,knn_k=20:1.1276,knn_k=50:1.2917,knn_k=100:1.4968,lwr_k=20:0.9218,lwr_k=50:0.8291,lwr_k=100:0.8057,lwr_k=200:0.8453,lwr_k=500:0.9047,lwr_k=1000:0.9777'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9025,knn_k=1:0.0,knn_k=5:0.5249,knn_k=10:0.6578,knn_k=20:0.7425,knn_k=50:0.8349,knn_k=100:0.9215,lwr_k=20:0.3599,lwr_k=50:0.501,lwr_k=100:0.5837,lwr_k=200:0.653,lwr_k=500:0.7171,lwr_k=1000:0.7689'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9041,knn_k=1:0.9555,knn_k=5:0.7842,knn_k=10:0.7895,knn_k=20:0.8133,knn_k=50:0.8713,knn_k=100:0.9375,lwr_k=20:0.6883,lwr_k=50:0.6937,lwr_k=100:0.6925,lwr_k=200:0.7113,lwr_k=500:0.7584,lwr_k=1000:0.8071'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.4987,knn_k=1:0.0,knn_k=5:2.0509,knn_k=10:2.7875,knn_k=20:3.2492,knn_k=50:3.6863,knn_k=100:4.0317,lwr_k=20:3.0745,lwr_k=50:3.3338,lwr_k=100:3.41,lwr_k=200:3.4011,lwr_k=500:3.3773,lwr_k=1000:3.4356'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.3429,knn_k=1:2.2428,knn_k=5:3.0727,knn_k=10:3.2063,knn_k=20:3.4327,knn_k=50:3.7467,knn_k=100:4.0492,lwr_k=20:3.2918,lwr_k=50:3.4069,lwr_k=100:3.4046,lwr_k=200:3.3218,lwr_k=500:3.2821,lwr_k=1000:3.344'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_55'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.3729,knn_k=1:0.0,knn_k=5:1.7403,knn_k=10:2.261,knn_k=20:2.7037,knn_k=50:3.2309,knn_k=100:3.6079,lwr_k=20:2.6273,lwr_k=50:2.9968,lwr_k=100:3.1078,lwr_k=200:3.0809,lwr_k=500:2.8737,lwr_k=1000:2.7469'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.5294,knn_k=1:2.5323,knn_k=5:2.8234,knn_k=10:2.9855,knn_k=20:3.1531,knn_k=50:3.4523,knn_k=100:3.7892,lwr_k=20:3.0992,lwr_k=50:3.2657,lwr_k=100:3.3381,lwr_k=200:3.2955,lwr_k=500:3.0309,lwr_k=1000:2.8805'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.2982,knn_k=1:0.0,knn_k=5:1.643,knn_k=10:2.1956,knn_k=20:2.6565,knn_k=50:3.1833,knn_k=100:3.5609,lwr_k=20:2.576,lwr_k=50:2.9519,lwr_k=100:3.0879,lwr_k=200:3.0631,lwr_k=500:2.8247,lwr_k=1000:2.6676'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.324,knn_k=1:2.5362,knn_k=5:2.7162,knn_k=10:2.8798,knn_k=20:3.0882,knn_k=50:3.408,knn_k=100:3.723,lwr_k=20:3.031,lwr_k=50:3.214,lwr_k=100:3.2758,lwr_k=200:3.195,lwr_k=500:2.9352,lwr_k=1000:2.752'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.3257,knn_k=1:0.0,knn_k=5:1.7994,knn_k=10:2.3808,knn_k=20:2.817,knn_k=50:3.3208,knn_k=100:3.7249,lwr_k=20:2.727,lwr_k=50:3.0836,lwr_k=100:3.2289,lwr_k=200:3.2128,lwr_k=500:3.0125,lwr_k=1000:2.88'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.4214,knn_k=1:2.6631,knn_k=5:2.7983,knn_k=10:2.9181,knn_k=20:3.1304,knn_k=50:3.5258,knn_k=100:3.8514,lwr_k=20:3.0691,lwr_k=50:3.3107,lwr_k=100:3.3772,lwr_k=200:3.2898,lwr_k=500:3.0402,lwr_k=1000:2.8679'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.6159,knn_k=1:0.0,knn_k=5:1.9705,knn_k=10:2.5656,knn_k=20:3.0225,knn_k=50:3.5221,knn_k=100:3.8303,lwr_k=20:2.9284,lwr_k=50:3.2784,lwr_k=100:3.3664,lwr_k=200:3.3306,lwr_k=500:3.1366,lwr_k=1000:3.029'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.5527,knn_k=1:2.8994,knn_k=5:2.9381,knn_k=10:2.9897,knn_k=20:3.1756,knn_k=50:3.5115,knn_k=100:3.7798,lwr_k=20:3.1006,lwr_k=50:3.2981,lwr_k=100:3.3505,lwr_k=200:3.2662,lwr_k=500:3.0292,lwr_k=1000:2.8829'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.4124,knn_k=1:0.0,knn_k=5:1.7903,knn_k=10:2.3212,knn_k=20:2.7618,knn_k=50:3.2809,knn_k=100:3.7149,lwr_k=20:2.6808,lwr_k=50:3.0451,lwr_k=100:3.1913,lwr_k=200:3.1538,lwr_k=500:2.9209,lwr_k=1000:2.7944'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.5254,knn_k=1:2.4902,knn_k=5:2.8403,knn_k=10:2.8898,knn_k=20:3.0323,knn_k=50:3.3945,knn_k=100:3.7384,lwr_k=20:2.9683,lwr_k=50:3.1914,lwr_k=100:3.2675,lwr_k=200:3.1909,lwr_k=500:2.9424,lwr_k=1000:2.8287'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:2.3859,knn_k=1:0.0,knn_k=5:1.5971,knn_k=10:2.1399,knn_k=20:2.5829,knn_k=50:3.1067,knn_k=100:3.5397,lwr_k=20:2.5122,lwr_k=50:2.8991,lwr_k=100:3.0748,lwr_k=200:3.0664,lwr_k=500:2.8588,lwr_k=1000:2.7215'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.4202,knn_k=1:1.828,knn_k=5:2.3797,knn_k=10:2.5882,knn_k=20:2.772,knn_k=50:3.1625,knn_k=100:3.5604,lwr_k=20:2.7235,lwr_k=50:2.9803,lwr_k=100:3.1038,lwr_k=200:3.0349,lwr_k=500:2.7972,lwr_k=1000:2.6517'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_56'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.743,knn_k=1:0.0,knn_k=5:0.439,knn_k=10:0.5612,knn_k=20:0.6434,knn_k=50:0.7303,knn_k=100:0.7916,lwr_k=20:0.2916,lwr_k=50:0.4164,lwr_k=100:0.5045,lwr_k=200:0.5686,lwr_k=500:0.6279,lwr_k=1000:0.6626'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7643,knn_k=1:0.764,knn_k=5:0.697,knn_k=10:0.6888,knn_k=20:0.7079,knn_k=50:0.7529,knn_k=100:0.8139,lwr_k=20:0.6058,lwr_k=50:0.6009,lwr_k=100:0.6143,lwr_k=200:0.6328,lwr_k=500:0.6505,lwr_k=1000:0.6828'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6921,knn_k=1:0.0,knn_k=5:0.4578,knn_k=10:0.5682,knn_k=20:0.6461,knn_k=50:0.7321,knn_k=100:0.8113,lwr_k=20:0.232,lwr_k=50:0.3839,lwr_k=100:0.4743,lwr_k=200:0.556,lwr_k=500:0.616,lwr_k=1000:0.6422'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7293,knn_k=1:0.7674,knn_k=5:0.7376,knn_k=10:0.7324,knn_k=20:0.7522,knn_k=50:0.8059,knn_k=100:0.8828,lwr_k=20:0.7344,lwr_k=50:0.6514,lwr_k=100:0.6498,lwr_k=200:0.6654,lwr_k=500:0.684,lwr_k=1000:0.7054'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9169,knn_k=1:0.0,knn_k=5:0.5629,knn_k=10:0.7293,knn_k=20:0.8614,knn_k=50:1.01,knn_k=100:1.1399,lwr_k=20:0.2178,lwr_k=50:0.3869,lwr_k=100:0.496,lwr_k=200:0.5884,lwr_k=500:0.6793,lwr_k=1000:0.7375'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9267,knn_k=1:0.9178,knn_k=5:0.9168,knn_k=10:0.9269,knn_k=20:0.968,knn_k=50:1.0717,knn_k=100:1.1851,lwr_k=20:0.7072,lwr_k=50:0.701,lwr_k=100:0.6995,lwr_k=200:0.7147,lwr_k=500:0.7534,lwr_k=1000:0.7624'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8229,knn_k=1:0.0,knn_k=5:0.6002,knn_k=10:0.754,knn_k=20:0.8778,knn_k=50:1.0126,knn_k=100:1.1208,lwr_k=20:0.4351,lwr_k=50:0.5412,lwr_k=100:0.5977,lwr_k=200:0.6363,lwr_k=500:0.68,lwr_k=1000:0.7081'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7798,knn_k=1:1.0326,knn_k=5:0.8451,knn_k=10:0.8739,knn_k=20:0.9167,knn_k=50:1.005,knn_k=100:1.0786,lwr_k=20:0.6555,lwr_k=50:0.643,lwr_k=100:0.6282,lwr_k=200:0.647,lwr_k=500:0.6608,lwr_k=1000:0.6772'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8463,knn_k=1:0.0,knn_k=5:0.5106,knn_k=10:0.6523,knn_k=20:0.7531,knn_k=50:0.8932,knn_k=100:1.0287,lwr_k=20:0.2016,lwr_k=50:0.3776,lwr_k=100:0.4907,lwr_k=200:0.5805,lwr_k=500:0.6554,lwr_k=1000:0.6995'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8384,knn_k=1:0.8257,knn_k=5:0.8163,knn_k=10:0.8288,knn_k=20:0.875,knn_k=50:0.956,knn_k=100:1.0753,lwr_k=20:0.6358,lwr_k=50:0.6341,lwr_k=100:0.677,lwr_k=200:0.6788,lwr_k=500:0.7044,lwr_k=1000:0.727'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6726,knn_k=1:0.0,knn_k=5:0.389,knn_k=10:0.5162,knn_k=20:0.5965,knn_k=50:0.6764,knn_k=100:0.7301,lwr_k=20:0.214,lwr_k=50:0.3731,lwr_k=100:0.4641,lwr_k=200:0.53,lwr_k=500:0.5955,lwr_k=1000:0.6256'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6537,knn_k=1:0.5252,knn_k=5:0.6099,knn_k=10:0.6258,knn_k=20:0.6512,knn_k=50:0.6776,knn_k=100:0.7205,lwr_k=20:0.5774,lwr_k=50:0.588,lwr_k=100:0.5891,lwr_k=200:0.6018,lwr_k=500:0.6113,lwr_k=1000:0.6209'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_57'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9465,knn_k=1:0.0,knn_k=5:0.5888,knn_k=10:0.7156,knn_k=20:0.8316,knn_k=50:0.9591,knn_k=100:1.0483,lwr_k=20:0.6166,lwr_k=50:0.6521,lwr_k=100:0.6718,lwr_k=200:0.6967,lwr_k=500:0.721,lwr_k=1000:0.7421'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9742,knn_k=1:1.226,knn_k=5:0.9184,knn_k=10:0.9206,knn_k=20:0.957,knn_k=50:1.0463,knn_k=100:1.1121,lwr_k=20:0.7957,lwr_k=50:0.7482,lwr_k=100:0.7358,lwr_k=200:0.7394,lwr_k=500:0.7591,lwr_k=1000:0.7708'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7425,knn_k=1:0.0,knn_k=5:0.469,knn_k=10:0.5898,knn_k=20:0.6633,knn_k=50:0.7301,knn_k=100:0.7832,lwr_k=20:0.4705,lwr_k=50:0.5717,lwr_k=100:0.6208,lwr_k=200:0.6581,lwr_k=500:0.6934,lwr_k=1000:0.7133'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7911,knn_k=1:0.9533,knn_k=5:0.8007,knn_k=10:0.7837,knn_k=20:0.7907,knn_k=50:0.8129,knn_k=100:0.8504,lwr_k=20:0.7467,lwr_k=50:0.7384,lwr_k=100:0.7518,lwr_k=200:0.748,lwr_k=500:0.7589,lwr_k=1000:0.7706'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2044,knn_k=1:0.0,knn_k=5:0.9353,knn_k=10:1.1226,knn_k=20:1.2406,knn_k=50:1.3585,knn_k=100:1.4137,lwr_k=20:1.0304,lwr_k=50:1.0396,lwr_k=100:1.011,lwr_k=200:0.9876,lwr_k=500:0.9875,lwr_k=1000:1.0021'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2534,knn_k=1:2.2704,knn_k=5:1.4634,knn_k=10:1.39,knn_k=20:1.414,knn_k=50:1.4517,knn_k=100:1.4785,lwr_k=20:1.2736,lwr_k=50:1.1743,lwr_k=100:1.1016,lwr_k=200:1.0598,lwr_k=500:1.0377,lwr_k=1000:1.034'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1696,knn_k=1:0.0,knn_k=5:0.6397,knn_k=10:0.8235,knn_k=20:0.9526,knn_k=50:1.1048,knn_k=100:1.2298,lwr_k=20:0.5201,lwr_k=50:0.6509,lwr_k=100:0.7119,lwr_k=200:0.7637,lwr_k=500:0.8256,lwr_k=1000:0.8912'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1202,knn_k=1:1.1857,knn_k=5:0.9822,knn_k=10:1.0029,knn_k=20:1.0396,knn_k=50:1.1198,knn_k=100:1.2209,lwr_k=20:0.7524,lwr_k=50:0.7281,lwr_k=100:0.7329,lwr_k=200:0.7437,lwr_k=500:0.7836,lwr_k=1000:0.8433'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.821,knn_k=1:0.0,knn_k=5:0.58,knn_k=10:0.667,knn_k=20:0.725,knn_k=50:0.7735,knn_k=100:0.809,lwr_k=20:0.6369,lwr_k=50:0.6824,lwr_k=100:0.7103,lwr_k=200:0.7312,lwr_k=500:0.7557,lwr_k=1000:0.7659'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8336,knn_k=1:1.3785,knn_k=5:0.8696,knn_k=10:0.8203,knn_k=20:0.8081,knn_k=50:0.8325,knn_k=100:0.8533,lwr_k=20:0.7724,lwr_k=50:0.7673,lwr_k=100:0.7688,lwr_k=200:0.7729,lwr_k=500:0.7806,lwr_k=1000:0.7901'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7362,knn_k=1:0.0,knn_k=5:0.5134,knn_k=10:0.6015,knn_k=20:0.6565,knn_k=50:0.6902,knn_k=100:0.7065,lwr_k=20:0.5698,lwr_k=50:0.6155,lwr_k=100:0.6459,lwr_k=200:0.6667,lwr_k=500:0.6883,lwr_k=1000:0.7039'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7172,knn_k=1:1.0845,knn_k=5:0.7913,knn_k=10:0.7392,knn_k=20:0.7216,knn_k=50:0.7024,knn_k=100:0.7083,lwr_k=20:0.6967,lwr_k=50:0.671,lwr_k=100:0.6743,lwr_k=200:0.6802,lwr_k=500:0.6764,lwr_k=1000:0.6886'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_58'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6349,knn_k=1:0.0,knn_k=5:2.7256,knn_k=10:3.1878,knn_k=20:3.4408,knn_k=50:3.6455,knn_k=100:3.7618,lwr_k=20:3.1151,lwr_k=50:3.2802,lwr_k=100:3.3395,lwr_k=200:3.3867,lwr_k=500:3.4459,lwr_k=1000:3.4859'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.8013,knn_k=1:7.4522,knn_k=5:4.6185,knn_k=10:4.2438,knn_k=20:4.0324,knn_k=50:3.9755,knn_k=100:3.9709,lwr_k=20:3.9658,lwr_k=50:3.7654,lwr_k=100:3.6313,lwr_k=200:3.6075,lwr_k=500:3.6351,lwr_k=1000:3.6862'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.0259,knn_k=1:0.0,knn_k=5:2.0677,knn_k=10:2.5132,knn_k=20:2.7611,knn_k=50:2.9169,knn_k=100:2.9983,lwr_k=20:2.549,lwr_k=50:2.6076,lwr_k=100:2.6211,lwr_k=200:2.6241,lwr_k=500:2.6642,lwr_k=1000:2.7371'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.8809,knn_k=1:4.7147,knn_k=5:3.1739,knn_k=10:2.9921,knn_k=20:2.9402,knn_k=50:2.9442,knn_k=100:2.9524,lwr_k=20:2.8156,lwr_k=50:2.7166,lwr_k=100:2.6557,lwr_k=200:2.6057,lwr_k=500:2.6064,lwr_k=1000:2.6543'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.216,knn_k=1:0.0,knn_k=5:1.0032,knn_k=10:1.155,knn_k=20:1.2512,knn_k=50:1.3245,knn_k=100:1.3555,lwr_k=20:1.1704,lwr_k=50:1.2414,lwr_k=100:1.2727,lwr_k=200:1.2987,lwr_k=500:1.3146,lwr_k=1000:1.3209'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2665,knn_k=1:2.4879,knn_k=5:1.5421,knn_k=10:1.4588,knn_k=20:1.4456,knn_k=50:1.4319,knn_k=100:1.4308,lwr_k=20:1.3967,lwr_k=50:1.3794,lwr_k=100:1.3753,lwr_k=200:1.3724,lwr_k=500:1.3743,lwr_k=1000:1.3808'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.9746,knn_k=1:0.0,knn_k=5:1.1829,knn_k=10:1.4151,knn_k=20:1.6077,knn_k=50:1.8494,knn_k=100:2.0069,lwr_k=20:1.299,lwr_k=50:1.4106,lwr_k=100:1.464,lwr_k=200:1.5103,lwr_k=500:1.6195,lwr_k=1000:1.7306'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.2012,knn_k=1:2.7393,knn_k=5:1.7601,knn_k=10:1.7074,knn_k=20:1.7537,knn_k=50:1.8722,knn_k=100:2.0382,lwr_k=20:2.1348,lwr_k=50:1.5971,lwr_k=100:1.662,lwr_k=200:1.6806,lwr_k=500:1.7378,lwr_k=1000:1.7524'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.643,knn_k=1:0.0,knn_k=5:1.8577,knn_k=10:2.188,knn_k=20:2.4079,knn_k=50:2.5821,knn_k=100:2.6686,lwr_k=20:2.0564,lwr_k=50:2.2384,lwr_k=100:2.3312,lwr_k=200:2.4257,lwr_k=500:2.5301,lwr_k=1000:2.6087'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.5895,knn_k=1:3.9649,knn_k=5:2.7149,knn_k=10:2.6125,knn_k=20:2.6321,knn_k=50:2.6385,knn_k=100:2.666,lwr_k=20:2.5517,lwr_k=50:2.4799,lwr_k=100:2.4874,lwr_k=200:2.5218,lwr_k=500:2.5707,lwr_k=1000:2.5909'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6261,knn_k=1:0.0,knn_k=5:0.4969,knn_k=10:0.5578,knn_k=20:0.5846,knn_k=50:0.6087,knn_k=100:0.6214,lwr_k=20:0.574,lwr_k=50:0.5947,lwr_k=100:0.6008,lwr_k=200:0.6074,lwr_k=500:0.6132,lwr_k=1000:0.6173'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6235,knn_k=1:1.2032,knn_k=5:0.7505,knn_k=10:0.6858,knn_k=20:0.6682,knn_k=50:0.6507,knn_k=100:0.6451,lwr_k=20:0.6656,lwr_k=50:0.6418,lwr_k=100:0.6332,lwr_k=200:0.631,lwr_k=500:0.6284,lwr_k=1000:0.6275'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_59'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9567,knn_k=1:0.0,knn_k=5:0.5552,knn_k=10:0.6775,knn_k=20:0.7881,knn_k=50:0.9188,knn_k=100:1.0213,lwr_k=20:0.0388,lwr_k=50:0.3001,lwr_k=100:0.4242,lwr_k=200:0.5261,lwr_k=500:0.636,lwr_k=1000:0.7075'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9574,knn_k=1:1.3201,knn_k=5:0.9244,knn_k=10:0.9118,knn_k=20:0.9347,knn_k=50:1.0033,knn_k=100:1.0863,lwr_k=20:2.4765,lwr_k=50:0.8992,lwr_k=100:0.7028,lwr_k=200:0.688,lwr_k=500:0.7158,lwr_k=1000:0.7512'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6373,knn_k=1:0.0,knn_k=5:0.4278,knn_k=10:0.5142,knn_k=20:0.5736,knn_k=50:0.6465,knn_k=100:0.6926,lwr_k=20:0.0361,lwr_k=50:0.2631,lwr_k=100:0.3753,lwr_k=200:0.4419,lwr_k=500:0.5094,lwr_k=1000:0.5524'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6607,knn_k=1:1.0374,knn_k=5:0.7155,knn_k=10:0.6822,knn_k=20:0.6961,knn_k=50:0.7224,knn_k=100:0.7564,lwr_k=20:1.9592,lwr_k=50:0.7276,lwr_k=100:0.6156,lwr_k=200:0.5724,lwr_k=500:0.5861,lwr_k=1000:0.6019'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9962,knn_k=1:0.0,knn_k=5:0.6374,knn_k=10:0.7796,knn_k=20:0.8957,knn_k=50:1.0512,knn_k=100:1.1891,lwr_k=20:0.0311,lwr_k=50:0.3206,lwr_k=100:0.4753,lwr_k=200:0.579,lwr_k=500:0.6934,lwr_k=1000:0.772'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0952,knn_k=1:1.4473,knn_k=5:1.0056,knn_k=10:1.0245,knn_k=20:1.0555,knn_k=50:1.1482,knn_k=100:1.2625,lwr_k=20:2.5004,lwr_k=50:0.9,lwr_k=100:0.7475,lwr_k=200:0.7299,lwr_k=500:0.7759,lwr_k=1000:0.8486'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8619,knn_k=1:0.0,knn_k=5:0.5757,knn_k=10:0.7291,knn_k=20:0.8598,knn_k=50:1.034,knn_k=100:1.1968,lwr_k=20:0.0328,lwr_k=50:0.2762,lwr_k=100:0.4046,lwr_k=200:0.4957,lwr_k=500:0.5858,lwr_k=1000:0.6464'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8626,knn_k=1:1.3025,knn_k=5:0.9368,knn_k=10:0.9171,knn_k=20:0.9556,knn_k=50:1.0599,knn_k=100:1.1835,lwr_k=20:2.2614,lwr_k=50:0.7932,lwr_k=100:0.6113,lwr_k=200:0.5885,lwr_k=500:0.6218,lwr_k=1000:0.6625'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8753,knn_k=1:0.0,knn_k=5:0.5029,knn_k=10:0.6099,knn_k=20:0.6793,knn_k=50:0.775,knn_k=100:0.8544,lwr_k=20:0.0399,lwr_k=50:0.305,lwr_k=100:0.4313,lwr_k=200:0.5105,lwr_k=500:0.5885,lwr_k=1000:0.6485'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.92,knn_k=1:1.138,knn_k=5:0.7956,knn_k=10:0.7841,knn_k=20:0.7914,knn_k=50:0.8456,knn_k=100:0.9231,lwr_k=20:2.0982,lwr_k=50:0.7791,lwr_k=100:0.6729,lwr_k=200:0.6504,lwr_k=500:0.6637,lwr_k=1000:0.6938'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.4735,knn_k=1:0.0,knn_k=5:0.3587,knn_k=10:0.419,knn_k=20:0.4575,knn_k=50:0.5013,knn_k=100:0.5308,lwr_k=20:0.0396,lwr_k=50:0.2159,lwr_k=100:0.312,lwr_k=200:0.3633,lwr_k=500:0.4099,lwr_k=1000:0.4365'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5178,knn_k=1:0.8465,knn_k=5:0.554,knn_k=10:0.5275,knn_k=20:0.5227,knn_k=50:0.5353,knn_k=100:0.5512,lwr_k=20:1.3613,lwr_k=50:0.6137,lwr_k=100:0.505,lwr_k=200:0.4844,lwr_k=500:0.4827,lwr_k=1000:0.4896'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_60'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4088,knn_k=1:0.0,knn_k=5:0.9101,knn_k=10:1.0747,knn_k=20:1.1885,knn_k=50:1.3075,knn_k=100:1.3889,lwr_k=20:1.1169,lwr_k=50:1.1616,lwr_k=100:1.17,lwr_k=200:1.1646,lwr_k=500:1.1475,lwr_k=1000:1.148'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.4376,knn_k=1:2.1531,knn_k=5:1.4118,knn_k=10:1.3644,knn_k=20:1.3533,knn_k=50:1.4172,knn_k=100:1.485,lwr_k=20:1.3046,lwr_k=50:1.2822,lwr_k=100:1.2553,lwr_k=200:1.2196,lwr_k=500:1.1886,lwr_k=1000:1.1805'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7347,knn_k=1:0.0,knn_k=5:0.5711,knn_k=10:0.6491,knn_k=20:0.6857,knn_k=50:0.7172,knn_k=100:0.7284,lwr_k=20:0.6768,lwr_k=50:0.7038,lwr_k=100:0.7124,lwr_k=200:0.7193,lwr_k=500:0.7231,lwr_k=1000:0.726'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7732,knn_k=1:1.4778,knn_k=5:0.9048,knn_k=10:0.8393,knn_k=20:0.804,knn_k=50:0.7822,knn_k=100:0.7799,lwr_k=20:0.8058,lwr_k=50:0.783,lwr_k=100:0.777,lwr_k=200:0.7729,lwr_k=500:0.7686,lwr_k=1000:0.7669'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3697,knn_k=1:0.0,knn_k=5:0.9479,knn_k=10:1.116,knn_k=20:1.2051,knn_k=50:1.2956,knn_k=100:1.343,lwr_k=20:1.1744,lwr_k=50:1.228,lwr_k=100:1.2322,lwr_k=200:1.2307,lwr_k=500:1.2261,lwr_k=1000:1.222'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.4215,knn_k=1:2.3387,knn_k=5:1.5057,knn_k=10:1.411,knn_k=20:1.4069,knn_k=50:1.4094,knn_k=100:1.4308,lwr_k=20:1.3892,lwr_k=50:1.3669,lwr_k=100:1.3455,lwr_k=200:1.3064,lwr_k=500:1.285,lwr_k=1000:1.2704'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.2432,knn_k=1:0.0,knn_k=5:1.1161,knn_k=10:1.365,knn_k=20:1.6122,knn_k=50:1.9683,knn_k=100:2.2252,lwr_k=20:1.4948,lwr_k=50:1.604,lwr_k=100:1.543,lwr_k=200:1.4463,lwr_k=500:1.3361,lwr_k=1000:1.2722'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.2635,knn_k=1:2.5223,knn_k=5:1.723,knn_k=10:1.7771,knn_k=20:1.9,knn_k=50:2.1333,knn_k=100:2.338,lwr_k=20:1.7699,lwr_k=50:1.7537,lwr_k=100:1.643,lwr_k=200:1.5175,lwr_k=500:1.3748,lwr_k=1000:1.2864'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1374,knn_k=1:0.0,knn_k=5:0.8077,knn_k=10:0.938,knn_k=20:1.01,knn_k=50:1.086,knn_k=100:1.1229,lwr_k=20:0.9605,lwr_k=50:0.9979,lwr_k=100:1.0073,lwr_k=200:1.0131,lwr_k=500:1.0144,lwr_k=1000:1.0264'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1332,knn_k=1:2.081,knn_k=5:1.2858,knn_k=10:1.2034,knn_k=20:1.1633,knn_k=50:1.1639,knn_k=100:1.1827,lwr_k=20:1.1305,lwr_k=50:1.1018,lwr_k=100:1.0845,lwr_k=200:1.0679,lwr_k=500:1.0498,lwr_k=1000:1.0475'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.718,knn_k=1:0.0,knn_k=5:0.5538,knn_k=10:0.638,knn_k=20:0.6759,knn_k=50:0.704,knn_k=100:0.7129,lwr_k=20:0.6619,lwr_k=50:0.6844,lwr_k=100:0.6918,lwr_k=200:0.7004,lwr_k=500:0.7072,lwr_k=1000:0.7105'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7124,knn_k=1:1.3736,knn_k=5:0.8297,knn_k=10:0.758,knn_k=20:0.7334,knn_k=50:0.7227,knn_k=100:0.7223,lwr_k=20:0.7309,lwr_k=50:0.714,lwr_k=100:0.7106,lwr_k=200:0.7088,lwr_k=500:0.7124,lwr_k=1000:0.713'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_61'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8546,knn_k=1:0.0,knn_k=5:0.6464,knn_k=10:0.7657,knn_k=20:0.8642,knn_k=50:1.0031,knn_k=100:1.1192,lwr_k=20:0.6077,lwr_k=50:0.662,lwr_k=100:0.6934,lwr_k=200:0.7192,lwr_k=500:0.756,lwr_k=1000:0.8032'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8887,knn_k=1:1.396,knn_k=5:0.9791,knn_k=10:0.9495,knn_k=20:0.9777,knn_k=50:1.0649,knn_k=100:1.1627,lwr_k=20:0.86,lwr_k=50:0.8088,lwr_k=100:0.7796,lwr_k=200:0.7921,lwr_k=500:0.8114,lwr_k=1000:0.8553'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.754,knn_k=1:0.0,knn_k=5:0.5474,knn_k=10:0.6478,knn_k=20:0.7001,knn_k=50:0.7352,knn_k=100:0.7576,lwr_k=20:0.6163,lwr_k=50:0.6514,lwr_k=100:0.6671,lwr_k=200:0.684,lwr_k=500:0.6987,lwr_k=1000:0.7082'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7912,knn_k=1:1.3685,knn_k=5:0.8819,knn_k=10:0.8124,knn_k=20:0.7916,knn_k=50:0.791,knn_k=100:0.8,lwr_k=20:0.779,lwr_k=50:0.7701,lwr_k=100:0.769,lwr_k=200:0.7598,lwr_k=500:0.762,lwr_k=1000:0.7653'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0568,knn_k=1:0.0,knn_k=5:0.9641,knn_k=10:1.1187,knn_k=20:1.2105,knn_k=50:1.3121,knn_k=100:1.364,lwr_k=20:0.9561,lwr_k=50:1.0384,lwr_k=100:1.0597,lwr_k=200:1.0617,lwr_k=500:1.0558,lwr_k=1000:1.0287'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0706,knn_k=1:2.2211,knn_k=5:1.4543,knn_k=10:1.3681,knn_k=20:1.3499,knn_k=50:1.3688,knn_k=100:1.4024,lwr_k=20:1.2753,lwr_k=50:1.2133,lwr_k=100:1.1582,lwr_k=200:1.133,lwr_k=500:1.0961,lwr_k=1000:1.06'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.6884,knn_k=1:0.0,knn_k=5:1.3574,knn_k=10:1.5662,knn_k=20:1.7378,knn_k=50:1.8985,knn_k=100:2.0294,lwr_k=20:1.5182,lwr_k=50:1.5767,lwr_k=100:1.6103,lwr_k=200:1.6299,lwr_k=500:1.6401,lwr_k=1000:1.6295'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.7373,knn_k=1:3.3569,knn_k=5:2.0001,knn_k=10:1.9163,knn_k=20:1.9159,knn_k=50:2.0076,knn_k=100:2.1392,lwr_k=20:1.804,lwr_k=50:1.7191,lwr_k=100:1.6974,lwr_k=200:1.6902,lwr_k=500:1.6644,lwr_k=1000:1.6387'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8583,knn_k=1:0.0,knn_k=5:0.5762,knn_k=10:0.6911,knn_k=20:0.7718,knn_k=50:0.8605,knn_k=100:0.9317,lwr_k=20:0.6207,lwr_k=50:0.6723,lwr_k=100:0.7188,lwr_k=200:0.7574,lwr_k=500:0.7866,lwr_k=1000:0.807'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8585,knn_k=1:1.3435,knn_k=5:0.8939,knn_k=10:0.8646,knn_k=20:0.8639,knn_k=50:0.8944,knn_k=100:0.9511,lwr_k=20:0.813,lwr_k=50:0.7751,lwr_k=100:0.7716,lwr_k=200:0.7809,lwr_k=500:0.7992,lwr_k=1000:0.8047'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6352,knn_k=1:0.0,knn_k=5:0.5014,knn_k=10:0.5615,knn_k=20:0.5954,knn_k=50:0.6206,knn_k=100:0.6327,lwr_k=20:0.579,lwr_k=50:0.606,lwr_k=100:0.6161,lwr_k=200:0.6236,lwr_k=500:0.627,lwr_k=1000:0.6305'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6372,knn_k=1:1.2427,knn_k=5:0.7405,knn_k=10:0.6933,knn_k=20:0.675,knn_k=50:0.6583,knn_k=100:0.6514,lwr_k=20:0.6708,lwr_k=50:0.6477,lwr_k=100:0.6449,lwr_k=200:0.6408,lwr_k=500:0.6385,lwr_k=1000:0.6369'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_62'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8543,knn_k=1:0.0,knn_k=5:0.6827,knn_k=10:0.8381,knn_k=20:0.9469,knn_k=50:1.0594,knn_k=100:1.1577,lwr_k=20:0.4924,lwr_k=50:0.5896,lwr_k=100:0.6378,lwr_k=200:0.6711,lwr_k=500:0.7126,lwr_k=1000:0.7458'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.893,knn_k=1:1.4963,knn_k=5:1.0377,knn_k=10:1.0613,knn_k=20:1.0741,knn_k=50:1.1449,knn_k=100:1.2265,lwr_k=20:0.8334,lwr_k=50:0.7873,lwr_k=100:0.7686,lwr_k=200:0.7619,lwr_k=500:0.7842,lwr_k=1000:0.808'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6932,knn_k=1:0.0,knn_k=5:0.5307,knn_k=10:0.6107,knn_k=20:0.6585,knn_k=50:0.6877,knn_k=100:0.7083,lwr_k=20:0.4965,lwr_k=50:0.564,lwr_k=100:0.5992,lwr_k=200:0.6328,lwr_k=500:0.6588,lwr_k=1000:0.6738'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7209,knn_k=1:1.2943,knn_k=5:0.8447,knn_k=10:0.8015,knn_k=20:0.7737,knn_k=50:0.7574,knn_k=100:0.7604,lwr_k=20:0.7643,lwr_k=50:0.7306,lwr_k=100:0.7169,lwr_k=200:0.7091,lwr_k=500:0.7161,lwr_k=1000:0.7216'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8179,knn_k=1:0.0,knn_k=5:0.7784,knn_k=10:0.9282,knn_k=20:1.0629,knn_k=50:1.2206,knn_k=100:1.3408,lwr_k=20:0.5697,lwr_k=50:0.6538,lwr_k=100:0.7099,lwr_k=200:0.7829,lwr_k=500:0.8461,lwr_k=1000:0.8733'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8533,knn_k=1:1.7352,knn_k=5:1.158,knn_k=10:1.1608,knn_k=20:1.1987,knn_k=50:1.3201,knn_k=100:1.4142,lwr_k=20:0.9278,lwr_k=50:0.8611,lwr_k=100:0.8642,lwr_k=200:0.8682,lwr_k=500:0.8948,lwr_k=1000:0.9074'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5712,knn_k=1:0.0,knn_k=5:2.441,knn_k=10:3.137,knn_k=20:3.5965,knn_k=50:4.0602,knn_k=100:4.3976,lwr_k=20:3.077,lwr_k=50:3.1586,lwr_k=100:3.1465,lwr_k=200:3.1804,lwr_k=500:3.4253,lwr_k=1000:3.804'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.4177,knn_k=1:3.7116,knn_k=5:3.7379,knn_k=10:3.7642,knn_k=20:3.8885,knn_k=50:4.1121,knn_k=100:4.3218,lwr_k=20:3.5063,lwr_k=50:3.3682,lwr_k=100:3.2565,lwr_k=200:3.2047,lwr_k=500:3.3401,lwr_k=1000:3.657'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.1929,knn_k=1:0.0,knn_k=5:2.4267,knn_k=10:3.0673,knn_k=20:3.5506,knn_k=50:4.0217,knn_k=100:4.338,lwr_k=20:3.0055,lwr_k=50:3.0819,lwr_k=100:2.9828,lwr_k=200:2.9475,lwr_k=500:3.0248,lwr_k=1000:3.2364'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.3171,knn_k=1:3.7021,knn_k=5:3.7689,knn_k=10:3.854,knn_k=20:4.0352,knn_k=50:4.2715,knn_k=100:4.4576,lwr_k=20:3.6061,lwr_k=50:3.4486,lwr_k=100:3.279,lwr_k=200:3.1597,lwr_k=500:3.2524,lwr_k=1000:3.5105'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.521,knn_k=1:0.0,knn_k=5:0.3982,knn_k=10:0.4582,knn_k=20:0.4937,knn_k=50:0.5231,knn_k=100:0.5432,lwr_k=20:0.296,lwr_k=50:0.3863,lwr_k=100:0.4349,lwr_k=200:0.4669,lwr_k=500:0.4946,lwr_k=1000:0.5083'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5387,knn_k=1:0.9991,knn_k=5:0.6308,knn_k=10:0.5924,knn_k=20:0.5737,knn_k=50:0.57,knn_k=100:0.576,lwr_k=20:0.6314,lwr_k=50:0.5863,lwr_k=100:0.5663,lwr_k=200:0.5494,lwr_k=500:0.5421,lwr_k=1000:0.5412'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_63'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3392,knn_k=1:0.0,knn_k=5:0.9653,knn_k=10:1.1291,knn_k=20:1.2289,knn_k=50:1.2909,knn_k=100:1.3399,lwr_k=20:1.1443,lwr_k=50:1.1812,lwr_k=100:1.1976,lwr_k=200:1.2159,lwr_k=500:1.244,lwr_k=1000:1.2736'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.3717,knn_k=1:2.2734,knn_k=5:1.4902,knn_k=10:1.4125,knn_k=20:1.3815,knn_k=50:1.3995,knn_k=100:1.4076,lwr_k=20:1.3357,lwr_k=50:1.3003,lwr_k=100:1.2742,lwr_k=200:1.2573,lwr_k=500:1.2662,lwr_k=1000:1.2963'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7314,knn_k=1:0.0001,knn_k=5:0.5605,knn_k=10:0.642,knn_k=20:0.6821,knn_k=50:0.7068,knn_k=100:0.7218,lwr_k=20:0.6659,lwr_k=50:0.6863,lwr_k=100:0.6995,lwr_k=200:0.7082,lwr_k=500:0.715,lwr_k=1000:0.7191'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7716,knn_k=1:1.4473,knn_k=5:0.8991,knn_k=10:0.8311,knn_k=20:0.8027,knn_k=50:0.7872,knn_k=100:0.7863,lwr_k=20:0.8097,lwr_k=50:0.7997,lwr_k=100:0.7904,lwr_k=200:0.779,lwr_k=500:0.7724,lwr_k=1000:0.7708'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3796,knn_k=1:0.0001,knn_k=5:0.9864,knn_k=10:1.1452,knn_k=20:1.2448,knn_k=50:1.3458,knn_k=100:1.4006,lwr_k=20:1.1834,lwr_k=50:1.2281,lwr_k=100:1.2405,lwr_k=200:1.2399,lwr_k=500:1.2476,lwr_k=1000:1.2577'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.4156,knn_k=1:2.4298,knn_k=5:1.5612,knn_k=10:1.4686,knn_k=20:1.4151,knn_k=50:1.4443,knn_k=100:1.4724,lwr_k=20:1.3845,lwr_k=50:1.3537,lwr_k=100:1.3347,lwr_k=200:1.3195,lwr_k=500:1.301,lwr_k=1000:1.3005'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.5436,knn_k=1:0.0,knn_k=5:1.7005,knn_k=10:1.979,knn_k=20:2.1584,knn_k=50:2.3493,knn_k=100:2.4712,lwr_k=20:2.1021,lwr_k=50:2.2032,lwr_k=100:2.1975,lwr_k=200:2.1866,lwr_k=500:2.1645,lwr_k=1000:2.1795'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.5646,knn_k=1:4.2422,knn_k=5:2.6593,knn_k=10:2.4848,knn_k=20:2.4209,knn_k=50:2.4306,knn_k=100:2.5443,lwr_k=20:2.3846,lwr_k=50:2.3022,lwr_k=100:2.2629,lwr_k=200:2.224,lwr_k=500:2.1617,lwr_k=1000:2.1662'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.113,knn_k=1:0.001,knn_k=5:0.8299,knn_k=10:0.9718,knn_k=20:1.0392,knn_k=50:1.084,knn_k=100:1.1006,lwr_k=20:1.0302,lwr_k=50:1.0656,lwr_k=100:1.0754,lwr_k=200:1.079,lwr_k=500:1.0809,lwr_k=1000:1.0812'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.13,knn_k=1:2.0289,knn_k=5:1.2453,knn_k=10:1.1928,knn_k=20:1.1667,knn_k=50:1.1383,knn_k=100:1.1425,lwr_k=20:1.1604,lwr_k=50:1.1263,lwr_k=100:1.1222,lwr_k=200:1.1145,lwr_k=500:1.1069,lwr_k=1000:1.1045'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6895,knn_k=1:0.0005,knn_k=5:0.5423,knn_k=10:0.6127,knn_k=20:0.653,knn_k=50:0.6758,knn_k=100:0.6866,lwr_k=20:0.6398,lwr_k=50:0.6568,lwr_k=100:0.6666,lwr_k=200:0.6732,lwr_k=500:0.6789,lwr_k=1000:0.6827'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6898,knn_k=1:1.294,knn_k=5:0.8092,knn_k=10:0.7391,knn_k=20:0.7084,knn_k=50:0.6924,knn_k=100:0.693,lwr_k=20:0.7057,lwr_k=50:0.6843,lwr_k=100:0.6849,lwr_k=200:0.6883,lwr_k=500:0.6889,lwr_k=1000:0.6851'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_64'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.439,knn_k=1:0.0,knn_k=5:1.0802,knn_k=10:1.2274,knn_k=20:1.3067,knn_k=50:1.3677,knn_k=100:1.4015,lwr_k=20:1.2663,lwr_k=50:1.3141,lwr_k=100:1.3405,lwr_k=200:1.3575,lwr_k=500:1.3691,lwr_k=1000:1.3851'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.5305,knn_k=1:2.8007,knn_k=5:1.7557,knn_k=10:1.6366,knn_k=20:1.5598,knn_k=50:1.5259,knn_k=100:1.5217,lwr_k=20:1.5483,lwr_k=50:1.502,lwr_k=100:1.4953,lwr_k=200:1.4965,lwr_k=500:1.4902,lwr_k=1000:1.4919'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.666,knn_k=1:0.0,knn_k=5:0.5091,knn_k=10:0.5788,knn_k=20:0.6204,knn_k=50:0.6432,knn_k=100:0.6551,lwr_k=20:0.5995,lwr_k=50:0.6193,lwr_k=100:0.6299,lwr_k=200:0.6362,lwr_k=500:0.6428,lwr_k=1000:0.6492'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.691,knn_k=1:1.2701,knn_k=5:0.7735,knn_k=10:0.7134,knn_k=20:0.7025,knn_k=50:0.6905,knn_k=100:0.6927,lwr_k=20:0.7028,lwr_k=50:0.6876,lwr_k=100:0.6835,lwr_k=200:0.6793,lwr_k=500:0.6811,lwr_k=1000:0.6819'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3981,knn_k=1:0.4735,knn_k=5:1.0727,knn_k=10:1.1739,knn_k=20:1.2319,knn_k=50:1.3151,knn_k=100:1.3536,lwr_k=20:1.2004,lwr_k=50:1.2536,lwr_k=100:1.26,lwr_k=200:1.2732,lwr_k=500:1.2828,lwr_k=1000:1.304'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.4721,knn_k=1:2.6436,knn_k=5:1.5841,knn_k=10:1.4893,knn_k=20:1.4309,knn_k=50:1.4355,knn_k=100:1.4604,lwr_k=20:1.4116,lwr_k=50:1.3838,lwr_k=100:1.371,lwr_k=200:1.3573,lwr_k=500:1.3629,lwr_k=1000:1.3796'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.5737,knn_k=1:0.0,knn_k=5:1.6706,knn_k=10:1.9476,knn_k=20:2.1154,knn_k=50:2.2856,knn_k=100:2.392,lwr_k=20:2.0344,lwr_k=50:2.1039,lwr_k=100:2.1394,lwr_k=200:2.1706,lwr_k=500:2.2096,lwr_k=1000:2.2717'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.6454,knn_k=1:4.1147,knn_k=5:2.5331,knn_k=10:2.432,knn_k=20:2.3672,knn_k=50:2.4237,knn_k=100:2.4763,lwr_k=20:2.315,lwr_k=50:2.2578,lwr_k=100:2.2446,lwr_k=200:2.2515,lwr_k=500:2.26,lwr_k=1000:2.3075'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2147,knn_k=1:0.0,knn_k=5:0.9084,knn_k=10:1.0407,knn_k=20:1.1113,knn_k=50:1.1627,knn_k=100:1.1882,lwr_k=20:1.0794,lwr_k=50:1.1173,lwr_k=100:1.1358,lwr_k=200:1.1478,lwr_k=500:1.1628,lwr_k=1000:1.1783'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2622,knn_k=1:2.2897,knn_k=5:1.4178,knn_k=10:1.3032,knn_k=20:1.2754,knn_k=50:1.2679,knn_k=100:1.273,lwr_k=20:1.2505,lwr_k=50:1.2202,lwr_k=100:1.2175,lwr_k=200:1.2149,lwr_k=500:1.2073,lwr_k=1000:1.2174'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6224,knn_k=1:0.0774,knn_k=5:0.5001,knn_k=10:0.5784,knn_k=20:0.5867,knn_k=50:0.6071,knn_k=100:0.6096,lwr_k=20:0.5802,lwr_k=50:0.5986,lwr_k=100:0.6009,lwr_k=200:0.6043,lwr_k=500:0.6082,lwr_k=1000:0.6127'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6233,knn_k=1:1.2035,knn_k=5:0.725,knn_k=10:0.6884,knn_k=20:0.6444,knn_k=50:0.6314,knn_k=100:0.6267,lwr_k=20:0.6394,lwr_k=50:0.6237,lwr_k=100:0.6222,lwr_k=200:0.6187,lwr_k=500:0.6161,lwr_k=1000:0.6165'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_65'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8653,knn_k=1:0.0,knn_k=5:0.5669,knn_k=10:0.7352,knn_k=20:0.8591,knn_k=50:0.999,knn_k=100:1.0958,lwr_k=20:0.4702,lwr_k=50:0.544,lwr_k=100:0.5853,lwr_k=200:0.6233,lwr_k=500:0.6625,lwr_k=1000:0.6923'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8558,knn_k=1:1.0499,knn_k=5:0.9124,knn_k=10:0.9125,knn_k=20:0.9741,knn_k=50:1.0481,knn_k=100:1.1362,lwr_k=20:0.7139,lwr_k=50:0.686,lwr_k=100:0.6846,lwr_k=200:0.6829,lwr_k=500:0.6884,lwr_k=1000:0.709'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.689,knn_k=1:0.0,knn_k=5:0.4366,knn_k=10:0.5524,knn_k=20:0.646,knn_k=50:0.7342,knn_k=100:0.8127,lwr_k=20:0.1452,lwr_k=50:0.2801,lwr_k=100:0.3876,lwr_k=200:0.4803,lwr_k=500:0.5797,lwr_k=1000:0.6282'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.745,knn_k=1:0.7837,knn_k=5:0.714,knn_k=10:0.7428,knn_k=20:0.76,knn_k=50:0.8082,knn_k=100:0.8814,lwr_k=20:0.6816,lwr_k=50:0.6611,lwr_k=100:0.6611,lwr_k=200:0.6667,lwr_k=500:0.6883,lwr_k=1000:0.7088'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9488,knn_k=1:0.0,knn_k=5:0.6453,knn_k=10:0.8553,knn_k=20:0.9996,knn_k=50:1.1653,knn_k=100:1.297,lwr_k=20:0.1593,lwr_k=50:0.3024,lwr_k=100:0.417,lwr_k=200:0.5226,lwr_k=500:0.6413,lwr_k=1000:0.7184'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9598,knn_k=1:1.0807,knn_k=5:1.0302,knn_k=10:1.0719,knn_k=20:1.1174,knn_k=50:1.2342,knn_k=100:1.3362,lwr_k=20:0.8267,lwr_k=50:0.7183,lwr_k=100:0.698,lwr_k=200:0.7075,lwr_k=500:0.7351,lwr_k=1000:0.764'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8454,knn_k=1:0.0,knn_k=5:0.5633,knn_k=10:0.7243,knn_k=20:0.8343,knn_k=50:0.9776,knn_k=100:1.1226,lwr_k=20:0.1868,lwr_k=50:0.3329,lwr_k=100:0.4443,lwr_k=200:0.5382,lwr_k=500:0.6206,lwr_k=1000:0.677'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7904,knn_k=1:0.8927,knn_k=5:0.8099,knn_k=10:0.8314,knn_k=20:0.859,knn_k=50:0.9509,knn_k=100:1.0557,lwr_k=20:0.6762,lwr_k=50:0.6237,lwr_k=100:0.6219,lwr_k=200:0.6343,lwr_k=500:0.6477,lwr_k=1000:0.6703'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7463,knn_k=1:0.0,knn_k=5:0.4828,knn_k=10:0.6156,knn_k=20:0.7099,knn_k=50:0.8135,knn_k=100:0.9224,lwr_k=20:0.1544,lwr_k=50:0.3029,lwr_k=100:0.4185,lwr_k=200:0.5071,lwr_k=500:0.5951,lwr_k=1000:0.647'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7594,knn_k=1:0.7502,knn_k=5:0.7911,knn_k=10:0.7788,knn_k=20:0.7969,knn_k=50:0.8671,knn_k=100:0.9555,lwr_k=20:0.65,lwr_k=50:0.6598,lwr_k=100:0.6456,lwr_k=200:0.6711,lwr_k=500:0.684,lwr_k=1000:0.6963'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6742,knn_k=1:0.0,knn_k=5:0.41,knn_k=10:0.5309,knn_k=20:0.6066,knn_k=50:0.682,knn_k=100:0.7419,lwr_k=20:0.1811,lwr_k=50:0.3188,lwr_k=100:0.409,lwr_k=200:0.4894,lwr_k=500:0.5705,lwr_k=1000:0.615'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6691,knn_k=1:0.6894,knn_k=5:0.6744,knn_k=10:0.6682,knn_k=20:0.6794,knn_k=50:0.7111,knn_k=100:0.7485,lwr_k=20:0.6194,lwr_k=50:0.5798,lwr_k=100:0.5957,lwr_k=200:0.6085,lwr_k=500:0.6246,lwr_k=1000:0.6415'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_66'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2027,knn_k=1:0.0,knn_k=5:0.6842,knn_k=10:0.8691,knn_k=20:1.0059,knn_k=50:1.1224,knn_k=100:1.2261,lwr_k=20:0.4972,lwr_k=50:0.6392,lwr_k=100:0.7278,lwr_k=200:0.8027,lwr_k=500:0.9243,lwr_k=1000:0.9962'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.2053,knn_k=1:1.1837,knn_k=5:1.0276,knn_k=10:1.0279,knn_k=20:1.0639,knn_k=50:1.1424,knn_k=100:1.2495,lwr_k=20:0.8609,lwr_k=50:0.8032,lwr_k=100:0.8275,lwr_k=200:0.8758,lwr_k=500:0.9613,lwr_k=1000:1.016'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6783,knn_k=1:0.0,knn_k=5:0.4601,knn_k=10:0.5688,knn_k=20:0.6513,knn_k=50:0.7378,knn_k=100:0.8082,lwr_k=20:0.383,lwr_k=50:0.5017,lwr_k=100:0.5636,lwr_k=200:0.6038,lwr_k=500:0.6372,lwr_k=1000:0.6531'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7145,knn_k=1:0.9325,knn_k=5:0.7654,knn_k=10:0.7448,knn_k=20:0.7522,knn_k=50:0.7904,knn_k=100:0.8565,lwr_k=20:0.702,lwr_k=50:0.7054,lwr_k=100:0.6999,lwr_k=200:0.6952,lwr_k=500:0.7,lwr_k=1000:0.7068'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.347,knn_k=1:0.0,knn_k=5:0.7975,knn_k=10:1.0037,knn_k=20:1.1427,knn_k=50:1.2821,knn_k=100:1.402,lwr_k=20:0.626,lwr_k=50:0.7411,lwr_k=100:0.8083,lwr_k=200:0.8628,lwr_k=500:0.9449,lwr_k=1000:1.0194'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.4183,knn_k=1:1.6089,knn_k=5:1.2381,knn_k=10:1.2476,knn_k=20:1.3005,knn_k=50:1.3884,knn_k=100:1.4919,lwr_k=20:0.9499,lwr_k=50:0.9258,lwr_k=100:0.9165,lwr_k=200:0.9442,lwr_k=500:0.9967,lwr_k=1000:1.0602'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.6434,knn_k=1:0.0,knn_k=5:0.7287,knn_k=10:0.9391,knn_k=20:1.1118,knn_k=50:1.296,knn_k=100:1.4692,lwr_k=20:0.5118,lwr_k=50:0.6673,lwr_k=100:0.7583,lwr_k=200:0.8355,lwr_k=500:0.945,lwr_k=1000:1.066'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.5854,knn_k=1:1.4276,knn_k=5:1.1856,knn_k=10:1.1716,knn_k=20:1.2382,knn_k=50:1.3489,knn_k=100:1.4898,lwr_k=20:0.8485,lwr_k=50:0.7941,lwr_k=100:0.8008,lwr_k=200:0.8363,lwr_k=500:0.9166,lwr_k=1000:1.0512'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9399,knn_k=1:0.0,knn_k=5:0.5189,knn_k=10:0.6329,knn_k=20:0.7121,knn_k=50:0.8089,knn_k=100:0.8975,lwr_k=20:0.51,lwr_k=50:0.5947,lwr_k=100:0.6445,lwr_k=200:0.6812,lwr_k=500:0.7294,lwr_k=1000:0.7694'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9319,knn_k=1:1.1042,knn_k=5:0.8197,knn_k=10:0.8109,knn_k=20:0.8418,knn_k=50:0.8808,knn_k=100:0.9372,lwr_k=20:0.7058,lwr_k=50:0.6961,lwr_k=100:0.7112,lwr_k=200:0.7286,lwr_k=500:0.7584,lwr_k=1000:0.7816'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6126,knn_k=1:0.0,knn_k=5:0.4435,knn_k=10:0.5225,knn_k=20:0.5681,knn_k=50:0.5998,knn_k=100:0.6242,lwr_k=20:0.476,lwr_k=50:0.5356,lwr_k=100:0.5612,lwr_k=200:0.5784,lwr_k=500:0.5948,lwr_k=1000:0.6029'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6447,knn_k=1:1.0829,knn_k=5:0.7193,knn_k=10:0.675,knn_k=20:0.6542,knn_k=50:0.6471,knn_k=100:0.6575,lwr_k=20:0.6374,lwr_k=50:0.6183,lwr_k=100:0.6233,lwr_k=200:0.6251,lwr_k=500:0.6324,lwr_k=1000:0.6369'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_67'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0405,knn_k=1:6.0822,knn_k=5:6.7052,knn_k=10:6.7308,knn_k=20:6.0563,knn_k=50:6.154,knn_k=100:6.0422,lwr_k=20:6.0563,lwr_k=50:6.154,lwr_k=100:6.0422,lwr_k=200:6.0592,lwr_k=500:6.0405,lwr_k=1000:6.0417'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.3796,knn_k=1:6.4466,knn_k=5:6.9434,knn_k=10:7.1728,knn_k=20:6.411,knn_k=50:6.5349,knn_k=100:6.3762,lwr_k=20:6.411,lwr_k=50:6.5349,lwr_k=100:6.3762,lwr_k=200:6.3814,lwr_k=500:6.3792,lwr_k=1000:6.3766'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7426,knn_k=1:0.021,knn_k=5:0.5896,knn_k=10:0.6657,knn_k=20:0.6924,knn_k=50:0.7203,knn_k=100:0.7284,lwr_k=20:0.6896,lwr_k=50:0.718,lwr_k=100:0.725,lwr_k=200:0.7286,lwr_k=500:0.7289,lwr_k=1000:0.7311'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7845,knn_k=1:1.5249,knn_k=5:0.9262,knn_k=10:0.8538,knn_k=20:0.8163,knn_k=50:0.7994,knn_k=100:0.7857,lwr_k=20:0.8174,lwr_k=50:0.7994,lwr_k=100:0.7846,lwr_k=200:0.785,lwr_k=500:0.7803,lwr_k=1000:0.7788'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.8908,knn_k=1:0.1329,knn_k=5:1.5711,knn_k=10:1.7234,knn_k=20:1.7903,knn_k=50:1.8466,knn_k=100:1.8642,lwr_k=20:1.7859,lwr_k=50:1.8398,lwr_k=100:1.8554,lwr_k=200:1.8666,lwr_k=500:1.8748,lwr_k=1000:1.8795'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.9138,knn_k=1:3.6327,knn_k=5:2.2122,knn_k=10:2.0434,knn_k=20:1.9679,knn_k=50:1.9242,knn_k=100:1.9054,lwr_k=20:1.97,lwr_k=50:1.9235,lwr_k=100:1.9023,lwr_k=200:1.8961,lwr_k=500:1.8978,lwr_k=1000:1.9004'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.1048,knn_k=1:0.6637,knn_k=5:2.5914,knn_k=10:2.9135,knn_k=20:2.9984,knn_k=50:3.0567,knn_k=100:3.0807,lwr_k=20:2.9852,lwr_k=50:3.0457,lwr_k=100:3.0644,lwr_k=200:3.0758,lwr_k=500:3.0882,lwr_k=1000:3.0899'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.2867,knn_k=1:6.0329,knn_k=5:3.7206,knn_k=10:3.5877,knn_k=20:3.3932,knn_k=50:3.2795,knn_k=100:3.2673,lwr_k=20:3.3898,lwr_k=50:3.272,lwr_k=100:3.2565,lwr_k=200:3.2674,lwr_k=500:3.272,lwr_k=1000:3.2736'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2987,knn_k=1:0.0706,knn_k=5:1.0397,knn_k=10:1.1662,knn_k=20:1.2313,knn_k=50:1.2672,knn_k=100:1.2845,lwr_k=20:1.2284,lwr_k=50:1.2631,lwr_k=100:1.2798,lwr_k=200:1.286,lwr_k=500:1.2903,lwr_k=1000:1.2933'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2774,knn_k=1:2.5101,knn_k=5:1.5256,knn_k=10:1.3997,knn_k=20:1.3506,knn_k=50:1.2998,knn_k=100:1.292,lwr_k=20:1.347,lwr_k=50:1.2961,lwr_k=100:1.2879,lwr_k=200:1.2801,lwr_k=500:1.2767,lwr_k=1000:1.2709'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:6.094,knn_k=1:9.9599,knn_k=5:6.1353,knn_k=10:6.1998,knn_k=20:6.2252,knn_k=50:6.676,knn_k=100:6.1836,lwr_k=20:6.225,lwr_k=50:6.6745,lwr_k=100:6.1807,lwr_k=200:6.1693,lwr_k=500:6.0991,lwr_k=1000:6.0945'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.8656,knn_k=1:9.8944,knn_k=5:5.9291,knn_k=10:5.9919,knn_k=20:5.9786,knn_k=50:6.4069,knn_k=100:5.9352,lwr_k=20:5.9795,lwr_k=50:6.4076,lwr_k=100:5.9393,lwr_k=200:5.924,lwr_k=500:5.8661,lwr_k=1000:5.8633'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_68'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9723,knn_k=1:0.0,knn_k=5:1.0099,knn_k=10:1.1912,knn_k=20:1.3304,knn_k=50:1.449,knn_k=100:1.5027,lwr_k=20:1.1964,lwr_k=50:1.2394,lwr_k=100:1.2498,lwr_k=200:1.2274,lwr_k=500:1.1933,lwr_k=1000:1.1775'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.0241,knn_k=1:2.51,knn_k=5:1.6651,knn_k=10:1.5875,knn_k=20:1.5812,knn_k=50:1.5906,knn_k=100:1.6204,lwr_k=20:1.4963,lwr_k=50:1.4352,lwr_k=100:1.3831,lwr_k=200:1.3278,lwr_k=500:1.2522,lwr_k=1000:1.2291'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7192,knn_k=1:0.0,knn_k=5:0.5004,knn_k=10:0.5757,knn_k=20:0.6207,knn_k=50:0.656,knn_k=100:0.6698,lwr_k=20:0.5669,lwr_k=50:0.6061,lwr_k=100:0.6222,lwr_k=200:0.6324,lwr_k=500:0.6374,lwr_k=1000:0.64'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7624,knn_k=1:1.2989,knn_k=5:0.8114,knn_k=10:0.7566,knn_k=20:0.7237,knn_k=50:0.7112,knn_k=100:0.7133,lwr_k=20:0.7293,lwr_k=50:0.6983,lwr_k=100:0.6883,lwr_k=200:0.6818,lwr_k=500:0.6749,lwr_k=1000:0.6748'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2578,knn_k=1:0.0,knn_k=5:0.9848,knn_k=10:1.1348,knn_k=20:1.2378,knn_k=50:1.3319,knn_k=100:1.3938,lwr_k=20:1.1082,lwr_k=50:1.1567,lwr_k=100:1.1668,lwr_k=200:1.1727,lwr_k=500:1.1802,lwr_k=1000:1.188'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.3289,knn_k=1:2.4726,knn_k=5:1.5115,knn_k=10:1.4064,knn_k=20:1.3825,knn_k=50:1.399,knn_k=100:1.4529,lwr_k=20:1.3279,lwr_k=50:1.2832,lwr_k=100:1.2665,lwr_k=200:1.2341,lwr_k=500:1.2186,lwr_k=1000:1.227'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0054,knn_k=1:0.0,knn_k=5:1.1263,knn_k=10:1.3469,knn_k=20:1.4983,knn_k=50:1.7214,knn_k=100:1.9678,lwr_k=20:1.1171,lwr_k=50:1.1066,lwr_k=100:1.098,lwr_k=200:1.0809,lwr_k=500:1.0743,lwr_k=1000:1.0924'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9883,knn_k=1:2.8086,knn_k=5:1.7718,knn_k=10:1.7417,knn_k=20:1.7465,knn_k=50:1.8719,knn_k=100:2.1083,lwr_k=20:1.4343,lwr_k=50:1.2727,lwr_k=100:1.1984,lwr_k=200:1.1321,lwr_k=500:1.0695,lwr_k=1000:1.0674'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7949,knn_k=1:0.0,knn_k=5:0.8678,knn_k=10:1.0064,knn_k=20:1.0789,knn_k=50:1.1364,knn_k=100:1.1594,lwr_k=20:1.0192,lwr_k=50:1.0556,lwr_k=100:1.0649,lwr_k=200:1.065,lwr_k=500:1.053,lwr_k=1000:1.0506'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7975,knn_k=1:2.0115,knn_k=5:1.2806,knn_k=10:1.1967,knn_k=20:1.1803,knn_k=50:1.1664,knn_k=100:1.1708,lwr_k=20:1.149,lwr_k=50:1.0981,lwr_k=100:1.0816,lwr_k=200:1.0606,lwr_k=500:1.0458,lwr_k=1000:1.0403'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.5313,knn_k=1:0.0,knn_k=5:0.4342,knn_k=10:0.4894,knn_k=20:0.5221,knn_k=50:0.5437,knn_k=100:0.558,lwr_k=20:0.5037,lwr_k=50:0.5212,lwr_k=100:0.5325,lwr_k=200:0.5385,lwr_k=500:0.5425,lwr_k=1000:0.5448'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5621,knn_k=1:1.0858,knn_k=5:0.699,knn_k=10:0.6284,knn_k=20:0.6017,knn_k=50:0.5838,knn_k=100:0.5901,lwr_k=20:0.6094,lwr_k=50:0.5879,lwr_k=100:0.586,lwr_k=200:0.5852,lwr_k=500:0.5832,lwr_k=1000:0.5824'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_69'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2799,knn_k=1:0.0974,knn_k=5:0.8947,knn_k=10:0.9984,knn_k=20:1.0678,knn_k=50:1.1267,knn_k=100:1.1648,lwr_k=20:1.0137,lwr_k=50:1.0719,lwr_k=100:1.0954,lwr_k=200:1.1111,lwr_k=500:1.1307,lwr_k=1000:1.1519'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.3257,knn_k=1:2.1993,knn_k=5:1.3537,knn_k=10:1.2689,knn_k=20:1.2094,knn_k=50:1.2261,knn_k=100:1.2419,lwr_k=20:1.206,lwr_k=50:1.1898,lwr_k=100:1.172,lwr_k=200:1.1811,lwr_k=500:1.1962,lwr_k=1000:1.2179'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.661,knn_k=1:0.0054,knn_k=5:0.5243,knn_k=10:0.5895,knn_k=20:0.6173,knn_k=50:0.6426,knn_k=100:0.6541,lwr_k=20:0.602,lwr_k=50:0.6279,lwr_k=100:0.6363,lwr_k=200:0.6445,lwr_k=500:0.6521,lwr_k=1000:0.6558'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7,knn_k=1:1.3253,knn_k=5:0.8136,knn_k=10:0.7413,knn_k=20:0.7109,knn_k=50:0.6994,knn_k=100:0.7056,lwr_k=20:0.7245,lwr_k=50:0.7057,lwr_k=100:0.7043,lwr_k=200:0.7036,lwr_k=500:0.7027,lwr_k=1000:0.7002'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.7311,knn_k=1:0.4682,knn_k=5:1.4378,knn_k=10:1.5799,knn_k=20:1.6189,knn_k=50:1.6564,knn_k=100:1.684,lwr_k=20:1.5962,lwr_k=50:1.6388,lwr_k=100:1.6614,lwr_k=200:1.675,lwr_k=500:1.6894,lwr_k=1000:1.6977'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.8004,knn_k=1:3.6377,knn_k=5:2.1338,knn_k=10:1.9385,knn_k=20:1.8194,knn_k=50:1.7795,knn_k=100:1.7692,lwr_k=20:1.8142,lwr_k=50:1.7678,lwr_k=100:1.7539,lwr_k=200:1.7498,lwr_k=500:1.7526,lwr_k=1000:1.7679'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.7163,knn_k=1:0.6242,knn_k=5:1.6863,knn_k=10:1.507,knn_k=20:1.5063,knn_k=50:1.5841,knn_k=100:1.6377,lwr_k=20:1.4299,lwr_k=50:1.4959,lwr_k=100:1.5185,lwr_k=200:1.5406,lwr_k=500:1.579,lwr_k=1000:1.6199'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.8938,knn_k=1:2.981,knn_k=5:2.3258,knn_k=10:1.8181,knn_k=20:1.619,knn_k=50:1.6569,knn_k=100:1.7092,lwr_k=20:1.6102,lwr_k=50:1.5946,lwr_k=100:1.5935,lwr_k=200:1.5653,lwr_k=500:1.5788,lwr_k=1000:1.6133'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2641,knn_k=1:0.204,knn_k=5:0.9271,knn_k=10:1.0379,knn_k=20:1.1143,knn_k=50:1.1767,knn_k=100:1.2072,lwr_k=20:1.0446,lwr_k=50:1.1225,lwr_k=100:1.1446,lwr_k=200:1.1637,lwr_k=500:1.1814,lwr_k=1000:1.201'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2443,knn_k=1:2.3846,knn_k=5:1.359,knn_k=10:1.2584,knn_k=20:1.193,knn_k=50:1.185,knn_k=100:1.2017,lwr_k=20:1.2053,lwr_k=50:1.1667,lwr_k=100:1.1593,lwr_k=200:1.1561,lwr_k=500:1.1705,lwr_k=1000:1.185'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.5955,knn_k=1:0.1253,knn_k=5:0.4813,knn_k=10:0.546,knn_k=20:0.5478,knn_k=50:0.5674,knn_k=100:0.5764,lwr_k=20:0.5423,lwr_k=50:0.5604,lwr_k=100:0.5684,lwr_k=200:0.5714,lwr_k=500:0.574,lwr_k=1000:0.5804'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5852,knn_k=1:1.1756,knn_k=5:0.6787,knn_k=10:0.6319,knn_k=20:0.5825,knn_k=50:0.5735,knn_k=100:0.5741,lwr_k=20:0.5795,lwr_k=50:0.57,lwr_k=100:0.5653,lwr_k=200:0.5645,lwr_k=500:0.5643,lwr_k=1000:0.5705'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_70'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.475,knn_k=1:0.0014,knn_k=5:1.1586,knn_k=10:1.3235,knn_k=20:1.3919,knn_k=50:1.4368,knn_k=100:1.4503,lwr_k=20:1.3915,lwr_k=50:1.436,lwr_k=100:1.4471,lwr_k=200:1.4537,lwr_k=500:1.4599,lwr_k=1000:1.4623'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.5125,knn_k=1:3.0029,knn_k=5:1.8397,knn_k=10:1.6398,knn_k=20:1.5664,knn_k=50:1.545,knn_k=100:1.5351,lwr_k=20:1.5682,lwr_k=50:1.5414,lwr_k=100:1.5286,lwr_k=200:1.5144,lwr_k=500:1.5087,lwr_k=1000:1.5139'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7203,knn_k=1:0.0,knn_k=5:0.5707,knn_k=10:0.6469,knn_k=20:0.6776,knn_k=50:0.7041,knn_k=100:0.7164,lwr_k=20:0.6757,lwr_k=50:0.7027,lwr_k=100:0.7114,lwr_k=200:0.7138,lwr_k=500:0.7151,lwr_k=1000:0.7169'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7541,knn_k=1:1.4469,knn_k=5:0.9062,knn_k=10:0.8311,knn_k=20:0.7932,knn_k=50:0.7693,knn_k=100:0.7641,lwr_k=20:0.7934,lwr_k=50:0.7678,lwr_k=100:0.7584,lwr_k=200:0.7504,lwr_k=500:0.7481,lwr_k=1000:0.7488'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4909,knn_k=1:0.0,knn_k=5:1.1788,knn_k=10:1.3099,knn_k=20:1.3937,knn_k=50:1.4462,knn_k=100:1.4614,lwr_k=20:1.3917,lwr_k=50:1.4408,lwr_k=100:1.452,lwr_k=200:1.46,lwr_k=500:1.4721,lwr_k=1000:1.479'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.5466,knn_k=1:3.0669,knn_k=5:1.7941,knn_k=10:1.6522,knn_k=20:1.5602,knn_k=50:1.5143,knn_k=100:1.5114,lwr_k=20:1.562,lwr_k=50:1.5168,lwr_k=100:1.5131,lwr_k=200:1.5243,lwr_k=500:1.5288,lwr_k=1000:1.5324'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.7052,knn_k=1:0.0054,knn_k=5:2.1211,knn_k=10:2.3773,knn_k=20:2.4924,knn_k=50:2.5768,knn_k=100:2.6147,lwr_k=20:2.491,lwr_k=50:2.5747,lwr_k=100:2.6106,lwr_k=200:2.6351,lwr_k=500:2.6414,lwr_k=1000:2.6405'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.8431,knn_k=1:5.5107,knn_k=5:3.2822,knn_k=10:3.0096,knn_k=20:2.9305,knn_k=50:2.8365,knn_k=100:2.7871,lwr_k=20:2.9279,lwr_k=50:2.8359,lwr_k=100:2.7907,lwr_k=200:2.7866,lwr_k=500:2.7699,lwr_k=1000:2.7682'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2303,knn_k=1:0.0015,knn_k=5:0.9787,knn_k=10:1.0976,knn_k=20:1.1515,knn_k=50:1.1928,knn_k=100:1.2032,lwr_k=20:1.1512,lwr_k=50:1.1919,lwr_k=100:1.2017,lwr_k=200:1.2114,lwr_k=500:1.2166,lwr_k=1000:1.2188'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2587,knn_k=1:2.4349,knn_k=5:1.4834,knn_k=10:1.3918,knn_k=20:1.3204,knn_k=50:1.2807,knn_k=100:1.2687,lwr_k=20:1.3203,lwr_k=50:1.2788,lwr_k=100:1.2668,lwr_k=200:1.2557,lwr_k=500:1.2516,lwr_k=1000:1.248'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7388,knn_k=1:0.0,knn_k=5:0.5865,knn_k=10:0.6623,knn_k=20:0.6989,knn_k=50:0.7205,knn_k=100:0.7308,lwr_k=20:0.6983,lwr_k=50:0.7176,lwr_k=100:0.7259,lwr_k=200:0.732,lwr_k=500:0.7344,lwr_k=1000:0.737'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7404,knn_k=1:1.4803,knn_k=5:0.875,knn_k=10:0.8046,knn_k=20:0.7786,knn_k=50:0.7595,knn_k=100:0.7551,lwr_k=20:0.7761,lwr_k=50:0.7506,lwr_k=100:0.7442,lwr_k=200:0.742,lwr_k=500:0.7376,lwr_k=1000:0.7396'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_71'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.2007,knn_k=1:0.0,knn_k=5:1.6189,knn_k=10:2.1255,knn_k=20:2.5335,knn_k=50:3.0555,knn_k=100:3.4373,lwr_k=20:1.6168,lwr_k=50:1.5528,lwr_k=100:1.4557,lwr_k=200:1.3723,lwr_k=500:1.3565,lwr_k=1000:1.4263'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.3562,knn_k=1:2.3593,knn_k=5:2.5737,knn_k=10:2.7736,knn_k=20:2.9634,knn_k=50:3.3306,knn_k=100:3.6683,lwr_k=20:2.2397,lwr_k=50:1.9581,lwr_k=100:1.7735,lwr_k=200:1.6052,lwr_k=500:1.5191,lwr_k=1000:1.5743'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.699,knn_k=1:0.0,knn_k=5:0.5278,knn_k=10:0.6195,knn_k=20:0.673,knn_k=50:0.7179,knn_k=100:0.7374,lwr_k=20:0.3872,lwr_k=50:0.4768,lwr_k=100:0.5297,lwr_k=200:0.5731,lwr_k=500:0.6186,lwr_k=1000:0.6458'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7681,knn_k=1:1.2884,knn_k=5:0.8584,knn_k=10:0.8108,knn_k=20:0.8135,knn_k=50:0.8137,knn_k=100:0.8198,lwr_k=20:0.7816,lwr_k=50:0.7564,lwr_k=100:0.7374,lwr_k=200:0.7239,lwr_k=500:0.7392,lwr_k=1000:0.7479'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7258,knn_k=1:0.0,knn_k=5:0.6586,knn_k=10:0.7937,knn_k=20:0.9056,knn_k=50:1.0385,knn_k=100:1.1204,lwr_k=20:0.415,lwr_k=50:0.5105,lwr_k=100:0.5534,lwr_k=200:0.5992,lwr_k=500:0.6428,lwr_k=1000:0.6705'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7516,knn_k=1:1.4268,knn_k=5:1.0127,knn_k=10:0.9856,knn_k=20:1.0085,knn_k=50:1.0886,knn_k=100:1.165,lwr_k=20:0.7939,lwr_k=50:0.7396,lwr_k=100:0.7121,lwr_k=200:0.7037,lwr_k=500:0.7002,lwr_k=1000:0.7058'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.377,knn_k=1:0.0,knn_k=5:1.8211,knn_k=10:2.3822,knn_k=20:2.9067,knn_k=50:3.5061,knn_k=100:3.9909,lwr_k=20:1.8323,lwr_k=50:1.6994,lwr_k=100:1.5339,lwr_k=200:1.4002,lwr_k=500:1.3523,lwr_k=1000:1.4417'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.1761,knn_k=1:2.5619,knn_k=5:2.8083,knn_k=10:2.8948,knn_k=20:3.1527,knn_k=50:3.5777,knn_k=100:3.962,lwr_k=20:2.2749,lwr_k=50:1.9079,lwr_k=100:1.6487,lwr_k=200:1.4533,lwr_k=500:1.3429,lwr_k=1000:1.3992'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.376,knn_k=1:0.0,knn_k=5:1.755,knn_k=10:2.2186,knn_k=20:2.7177,knn_k=50:3.3272,knn_k=100:3.774,lwr_k=20:1.7396,lwr_k=50:1.6646,lwr_k=100:1.5487,lwr_k=200:1.4516,lwr_k=500:1.4296,lwr_k=1000:1.4822'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.3352,knn_k=1:2.3968,knn_k=5:2.7118,knn_k=10:2.7599,knn_k=20:2.9993,knn_k=50:3.4222,knn_k=100:3.7785,lwr_k=20:2.2047,lwr_k=50:1.9301,lwr_k=100:1.7218,lwr_k=200:1.5791,lwr_k=500:1.4709,lwr_k=1000:1.5134'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.5798,knn_k=1:0.0,knn_k=5:0.4161,knn_k=10:0.4863,knn_k=20:0.5343,knn_k=50:0.5689,knn_k=100:0.5856,lwr_k=20:0.2936,lwr_k=50:0.3758,lwr_k=100:0.4298,lwr_k=200:0.4714,lwr_k=500:0.5132,lwr_k=1000:0.5366'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5774,knn_k=1:1.0051,knn_k=5:0.6584,knn_k=10:0.6106,knn_k=20:0.5984,knn_k=50:0.5917,knn_k=100:0.599,lwr_k=20:0.6307,lwr_k=50:0.5849,lwr_k=100:0.5667,lwr_k=200:0.5661,lwr_k=500:0.5556,lwr_k=1000:0.5591'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_72'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4432,knn_k=1:0.1994,knn_k=5:1.2164,knn_k=10:1.2881,knn_k=20:1.3531,knn_k=50:1.3942,knn_k=100:1.3994,lwr_k=20:1.3528,lwr_k=50:1.3925,lwr_k=100:1.3973,lwr_k=200:1.4072,lwr_k=500:1.4125,lwr_k=1000:1.4283'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.5281,knn_k=1:2.674,knn_k=5:1.7619,knn_k=10:1.6181,knn_k=20:1.5658,knn_k=50:1.5272,knn_k=100:1.5282,lwr_k=20:1.5659,lwr_k=50:1.5262,lwr_k=100:1.526,lwr_k=200:1.5204,lwr_k=500:1.5218,lwr_k=1000:1.5274'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.705,knn_k=1:0.0952,knn_k=5:0.5768,knn_k=10:0.6436,knn_k=20:0.6751,knn_k=50:0.6809,knn_k=100:0.6872,lwr_k=20:0.6741,lwr_k=50:0.6796,lwr_k=100:0.685,lwr_k=200:0.6879,lwr_k=500:0.6899,lwr_k=1000:0.6961'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7392,knn_k=1:1.3356,knn_k=5:0.8424,knn_k=10:0.7953,knn_k=20:0.7769,knn_k=50:0.742,knn_k=100:0.7365,lwr_k=20:0.777,lwr_k=50:0.7419,lwr_k=100:0.7344,lwr_k=200:0.7283,lwr_k=500:0.7284,lwr_k=1000:0.7317'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.5972,knn_k=1:0.335,knn_k=5:1.3915,knn_k=10:1.4496,knn_k=20:1.5198,knn_k=50:1.5717,knn_k=100:1.5893,lwr_k=20:1.5181,lwr_k=50:1.5667,lwr_k=100:1.5827,lwr_k=200:1.5835,lwr_k=500:1.5903,lwr_k=1000:1.5914'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.6893,knn_k=1:3.1218,knn_k=5:2.034,knn_k=10:1.804,knn_k=20:1.7476,knn_k=50:1.7127,knn_k=100:1.6918,lwr_k=20:1.7476,lwr_k=50:1.7121,lwr_k=100:1.6911,lwr_k=200:1.6847,lwr_k=500:1.6851,lwr_k=1000:1.6835'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.6316,knn_k=1:0.4039,knn_k=5:2.1757,knn_k=10:2.3685,knn_k=20:2.4956,knn_k=50:2.5572,knn_k=100:2.583,lwr_k=20:2.4911,lwr_k=50:2.5505,lwr_k=100:2.5781,lwr_k=200:2.5888,lwr_k=500:2.5937,lwr_k=1000:2.5993'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.7675,knn_k=1:5.0712,knn_k=5:3.2918,knn_k=10:3.0085,knn_k=20:2.8675,knn_k=50:2.7859,knn_k=100:2.7444,lwr_k=20:2.8725,lwr_k=50:2.7934,lwr_k=100:2.7461,lwr_k=200:2.7374,lwr_k=500:2.7364,lwr_k=1000:2.7324'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1411,knn_k=1:0.044,knn_k=5:0.8989,knn_k=10:1.0188,knn_k=20:1.0789,knn_k=50:1.1146,knn_k=100:1.1253,lwr_k=20:1.0782,lwr_k=50:1.1132,lwr_k=100:1.1231,lwr_k=200:1.1303,lwr_k=500:1.1337,lwr_k=1000:1.1353'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1681,knn_k=1:2.2731,knn_k=5:1.3848,knn_k=10:1.2533,knn_k=20:1.1889,knn_k=50:1.1705,knn_k=100:1.1621,lwr_k=20:1.189,lwr_k=50:1.1681,lwr_k=100:1.1606,lwr_k=200:1.1596,lwr_k=500:1.1623,lwr_k=1000:1.1595'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6284,knn_k=1:0.4961,knn_k=5:0.5208,knn_k=10:0.5917,knn_k=20:0.5913,knn_k=50:0.6064,knn_k=100:0.6087,lwr_k=20:0.591,lwr_k=50:0.6054,lwr_k=100:0.607,lwr_k=200:0.6103,lwr_k=500:0.6119,lwr_k=1000:0.6139'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6341,knn_k=1:1.4235,knn_k=5:0.7071,knn_k=10:0.6854,knn_k=20:0.6406,knn_k=50:0.6344,knn_k=100:0.6292,lwr_k=20:0.6404,lwr_k=50:0.6342,lwr_k=100:0.6294,lwr_k=200:0.6282,lwr_k=500:0.6287,lwr_k=1000:0.6302'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_73'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8223,knn_k=1:0.0,knn_k=5:0.4867,knn_k=10:0.6216,knn_k=20:0.7313,knn_k=50:0.8504,knn_k=100:0.9707,lwr_k=20:0.2791,lwr_k=50:0.402,lwr_k=100:0.4878,lwr_k=200:0.5609,lwr_k=500:0.6385,lwr_k=1000:0.6966'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8473,knn_k=1:0.7852,knn_k=5:0.7518,knn_k=10:0.7905,knn_k=20:0.8266,knn_k=50:0.9304,knn_k=100:1.0332,lwr_k=20:0.6312,lwr_k=50:0.6275,lwr_k=100:0.655,lwr_k=200:0.6731,lwr_k=500:0.6979,lwr_k=1000:0.7299'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6936,knn_k=1:0.0,knn_k=5:0.4186,knn_k=10:0.529,knn_k=20:0.6066,knn_k=50:0.6773,knn_k=100:0.7121,lwr_k=20:0.2741,lwr_k=50:0.3776,lwr_k=100:0.4439,lwr_k=200:0.5063,lwr_k=500:0.5769,lwr_k=1000:0.6235'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7336,knn_k=1:0.8235,knn_k=5:0.7474,knn_k=10:0.7244,knn_k=20:0.7263,knn_k=50:0.7558,knn_k=100:0.7765,lwr_k=20:0.5913,lwr_k=50:0.6466,lwr_k=100:0.6315,lwr_k=200:0.6488,lwr_k=500:0.6605,lwr_k=1000:0.6878'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8441,knn_k=1:0.0,knn_k=5:0.5283,knn_k=10:0.6825,knn_k=20:0.7758,knn_k=50:0.8849,knn_k=100:0.981,lwr_k=20:0.3213,lwr_k=50:0.4347,lwr_k=100:0.5025,lwr_k=200:0.5581,lwr_k=500:0.6362,lwr_k=1000:0.6964'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8621,knn_k=1:0.9111,knn_k=5:0.8348,knn_k=10:0.8466,knn_k=20:0.8726,knn_k=50:0.9374,knn_k=100:1.0106,lwr_k=20:0.6639,lwr_k=50:0.649,lwr_k=100:0.6507,lwr_k=200:0.661,lwr_k=500:0.6819,lwr_k=1000:0.7154'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.126,knn_k=1:6.2153,knn_k=5:7.493,knn_k=10:7.0518,knn_k=20:6.218,knn_k=50:6.1979,knn_k=100:6.1566,lwr_k=20:6.218,lwr_k=50:6.1979,lwr_k=100:6.1566,lwr_k=200:6.1341,lwr_k=500:6.1408,lwr_k=1000:6.1273'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.8721,knn_k=1:5.8875,knn_k=5:6.9499,knn_k=10:6.56,knn_k=20:5.8891,knn_k=50:5.8777,knn_k=100:5.8595,lwr_k=20:5.8891,lwr_k=50:5.8777,lwr_k=100:5.8595,lwr_k=200:5.8579,lwr_k=500:5.8568,lwr_k=1000:5.8645'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.795,knn_k=1:0.0,knn_k=5:0.4905,knn_k=10:0.616,knn_k=20:0.7031,knn_k=50:0.7938,knn_k=100:0.8644,lwr_k=20:0.321,lwr_k=50:0.4381,lwr_k=100:0.5054,lwr_k=200:0.5703,lwr_k=500:0.641,lwr_k=1000:0.6852'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7987,knn_k=1:0.7468,knn_k=5:0.7766,knn_k=10:0.776,knn_k=20:0.8047,knn_k=50:0.8422,knn_k=100:0.8906,lwr_k=20:0.6575,lwr_k=50:0.6342,lwr_k=100:0.6578,lwr_k=200:0.6748,lwr_k=500:0.7021,lwr_k=1000:0.7241'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7351,knn_k=1:0.0,knn_k=5:0.4022,knn_k=10:0.5406,knn_k=20:0.635,knn_k=50:0.7049,knn_k=100:0.7506,lwr_k=20:0.2892,lwr_k=50:0.3965,lwr_k=100:0.4645,lwr_k=200:0.5284,lwr_k=500:0.5917,lwr_k=1000:0.6363'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7269,knn_k=1:0.6823,knn_k=5:0.6685,knn_k=10:0.6781,knn_k=20:0.6873,knn_k=50:0.7198,knn_k=100:0.7459,lwr_k=20:0.5445,lwr_k=50:0.5472,lwr_k=100:0.5779,lwr_k=200:0.5863,lwr_k=500:0.6182,lwr_k=1000:0.6425'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_74'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9042,knn_k=1:0.0,knn_k=5:0.5118,knn_k=10:0.676,knn_k=20:0.7941,knn_k=50:0.979,knn_k=100:1.1595,lwr_k=20:0.0505,lwr_k=50:0.1948,lwr_k=100:0.3506,lwr_k=200:0.4823,lwr_k=500:0.6057,lwr_k=1000:0.6774'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.926,knn_k=1:0.7839,knn_k=5:0.804,knn_k=10:0.8511,knn_k=20:0.9108,knn_k=50:1.0448,knn_k=100:1.2116,lwr_k=20:0.7028,lwr_k=50:0.7068,lwr_k=100:0.6244,lwr_k=200:0.6296,lwr_k=500:0.6901,lwr_k=1000:0.7281'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6552,knn_k=1:0.0,knn_k=5:0.4236,knn_k=10:0.5553,knn_k=20:0.6462,knn_k=50:0.7567,knn_k=100:0.8538,lwr_k=20:0.1195,lwr_k=50:0.2687,lwr_k=100:0.3774,lwr_k=200:0.4733,lwr_k=500:0.5637,lwr_k=1000:0.6098'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7129,knn_k=1:0.7655,knn_k=5:0.7693,knn_k=10:0.7635,knn_k=20:0.7796,knn_k=50:0.8316,knn_k=100:0.9191,lwr_k=20:0.617,lwr_k=50:0.6352,lwr_k=100:0.634,lwr_k=200:0.6332,lwr_k=500:0.665,lwr_k=1000:0.682'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9247,knn_k=1:0.0,knn_k=5:0.53,knn_k=10:0.6794,knn_k=20:0.7983,knn_k=50:0.957,knn_k=100:1.1147,lwr_k=20:0.0562,lwr_k=50:0.2184,lwr_k=100:0.3814,lwr_k=200:0.5092,lwr_k=500:0.6219,lwr_k=1000:0.698'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9951,knn_k=1:0.8729,knn_k=5:0.8864,knn_k=10:0.9069,knn_k=20:0.9209,knn_k=50:1.0357,knn_k=100:1.174,lwr_k=20:0.7431,lwr_k=50:0.707,lwr_k=100:0.6774,lwr_k=200:0.6702,lwr_k=500:0.7216,lwr_k=1000:0.7772'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8081,knn_k=1:0.0,knn_k=5:0.5508,knn_k=10:0.7036,knn_k=20:0.837,knn_k=50:0.986,knn_k=100:1.141,lwr_k=20:0.1789,lwr_k=50:0.3489,lwr_k=100:0.4581,lwr_k=200:0.5331,lwr_k=500:0.6199,lwr_k=1000:0.6716'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7604,knn_k=1:0.8366,knn_k=5:0.8216,knn_k=10:0.8039,knn_k=20:0.8575,knn_k=50:0.9644,knn_k=100:1.0934,lwr_k=20:0.6684,lwr_k=50:0.6081,lwr_k=100:0.6075,lwr_k=200:0.6345,lwr_k=500:0.6494,lwr_k=1000:0.6661'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8474,knn_k=1:0.0,knn_k=5:0.5085,knn_k=10:0.6533,knn_k=20:0.7576,knn_k=50:0.9081,knn_k=100:1.0448,lwr_k=20:0.0832,lwr_k=50:0.2436,lwr_k=100:0.3857,lwr_k=200:0.5042,lwr_k=500:0.613,lwr_k=1000:0.6711'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8537,knn_k=1:0.8204,knn_k=5:0.793,knn_k=10:0.8118,knn_k=20:0.8722,knn_k=50:0.9641,knn_k=100:1.0883,lwr_k=20:0.7024,lwr_k=50:0.6632,lwr_k=100:0.6447,lwr_k=200:0.6498,lwr_k=500:0.6942,lwr_k=1000:0.723'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6596,knn_k=1:0.0,knn_k=5:0.4131,knn_k=10:0.5642,knn_k=20:0.6509,knn_k=50:0.7538,knn_k=100:0.85,lwr_k=20:0.0777,lwr_k=50:0.217,lwr_k=100:0.3472,lwr_k=200:0.459,lwr_k=500:0.5523,lwr_k=1000:0.6044'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.652,knn_k=1:0.5385,knn_k=5:0.6596,knn_k=10:0.6911,knn_k=20:0.704,knn_k=50:0.7652,knn_k=100:0.8503,lwr_k=20:0.55,lwr_k=50:0.5775,lwr_k=100:0.5758,lwr_k=200:0.5856,lwr_k=500:0.5964,lwr_k=1000:0.6031'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_75'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7964,knn_k=1:0.0,knn_k=5:0.4816,knn_k=10:0.6006,knn_k=20:0.7033,knn_k=50:0.8198,knn_k=100:0.9193,lwr_k=20:0.4455,lwr_k=50:0.5288,lwr_k=100:0.5743,lwr_k=200:0.6246,lwr_k=500:0.6789,lwr_k=1000:0.7149'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8124,knn_k=1:0.9339,knn_k=5:0.7698,knn_k=10:0.7814,knn_k=20:0.8269,knn_k=50:0.8978,knn_k=100:0.9938,lwr_k=20:0.6632,lwr_k=50:0.6559,lwr_k=100:0.6837,lwr_k=200:0.7007,lwr_k=500:0.7261,lwr_k=1000:0.7437'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6649,knn_k=1:0.0,knn_k=5:0.4065,knn_k=10:0.52,knn_k=20:0.5889,knn_k=50:0.6446,knn_k=100:0.6782,lwr_k=20:0.3468,lwr_k=50:0.4346,lwr_k=100:0.4963,lwr_k=200:0.5448,lwr_k=500:0.6004,lwr_k=1000:0.629'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7024,knn_k=1:0.7588,knn_k=5:0.7085,knn_k=10:0.7007,knn_k=20:0.7223,knn_k=50:0.7284,knn_k=100:0.7334,lwr_k=20:0.6518,lwr_k=50:0.6651,lwr_k=100:0.6747,lwr_k=200:0.6811,lwr_k=500:0.6891,lwr_k=1000:0.6891'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8718,knn_k=1:0.0,knn_k=5:0.5573,knn_k=10:0.7007,knn_k=20:0.7999,knn_k=50:0.9178,knn_k=100:1.0034,lwr_k=20:0.4691,lwr_k=50:0.5493,lwr_k=100:0.6109,lwr_k=200:0.6664,lwr_k=500:0.7258,lwr_k=1000:0.7623'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8752,knn_k=1:1.0295,knn_k=5:0.8717,knn_k=10:0.8569,knn_k=20:0.8861,knn_k=50:0.9589,knn_k=100:1.0235,lwr_k=20:0.73,lwr_k=50:0.7319,lwr_k=100:0.7523,lwr_k=200:0.7602,lwr_k=500:0.79,lwr_k=1000:0.8011'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9131,knn_k=1:0.0,knn_k=5:0.5479,knn_k=10:0.7083,knn_k=20:0.8212,knn_k=50:0.9501,knn_k=100:1.0875,lwr_k=20:0.4914,lwr_k=50:0.5689,lwr_k=100:0.6214,lwr_k=200:0.6757,lwr_k=500:0.7347,lwr_k=1000:0.7785'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8799,knn_k=1:1.0497,knn_k=5:0.8116,knn_k=10:0.8231,knn_k=20:0.8713,knn_k=50:0.9687,knn_k=100:1.078,lwr_k=20:0.6666,lwr_k=50:0.654,lwr_k=100:0.6719,lwr_k=200:0.683,lwr_k=500:0.7175,lwr_k=1000:0.7441'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7965,knn_k=1:0.0,knn_k=5:0.5096,knn_k=10:0.6323,knn_k=20:0.7079,knn_k=50:0.7734,knn_k=100:0.8147,lwr_k=20:0.4983,lwr_k=50:0.5572,lwr_k=100:0.6035,lwr_k=200:0.6507,lwr_k=500:0.6986,lwr_k=1000:0.7276'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8024,knn_k=1:1.1005,knn_k=5:0.8061,knn_k=10:0.7774,knn_k=20:0.8069,knn_k=50:0.8412,knn_k=100:0.8631,lwr_k=20:0.6992,lwr_k=50:0.7005,lwr_k=100:0.7117,lwr_k=200:0.7288,lwr_k=500:0.7491,lwr_k=1000:0.7616'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6977,knn_k=1:0.0,knn_k=5:0.4329,knn_k=10:0.5394,knn_k=20:0.6068,knn_k=50:0.6672,knn_k=100:0.7044,lwr_k=20:0.4014,lwr_k=50:0.4765,lwr_k=100:0.5255,lwr_k=200:0.5722,lwr_k=500:0.6218,lwr_k=1000:0.6438'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7087,knn_k=1:0.7713,knn_k=5:0.6846,knn_k=10:0.6744,knn_k=20:0.681,knn_k=50:0.7011,knn_k=100:0.7177,lwr_k=20:0.5901,lwr_k=50:0.6046,lwr_k=100:0.6189,lwr_k=200:0.6241,lwr_k=500:0.6506,lwr_k=1000:0.6587'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_76'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9809,knn_k=1:0.0,knn_k=5:0.6115,knn_k=10:0.7536,knn_k=20:0.8656,knn_k=50:1.0097,knn_k=100:1.1086,lwr_k=20:0.4489,lwr_k=50:0.5646,lwr_k=100:0.6352,lwr_k=200:0.6979,lwr_k=500:0.7648,lwr_k=1000:0.8147'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.0086,knn_k=1:1.1614,knn_k=5:0.9268,knn_k=10:0.9382,knn_k=20:0.9882,knn_k=50:1.0782,knn_k=100:1.1661,lwr_k=20:0.7806,lwr_k=50:0.7827,lwr_k=100:0.7916,lwr_k=200:0.802,lwr_k=500:0.8385,lwr_k=1000:0.8734'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7282,knn_k=1:0.0,knn_k=5:0.4745,knn_k=10:0.5778,knn_k=20:0.6427,knn_k=50:0.7009,knn_k=100:0.7279,lwr_k=20:0.4913,lwr_k=50:0.5455,lwr_k=100:0.5877,lwr_k=200:0.6237,lwr_k=500:0.6652,lwr_k=1000:0.6872'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7834,knn_k=1:1.0663,knn_k=5:0.7933,knn_k=10:0.7703,knn_k=20:0.7716,knn_k=50:0.7889,knn_k=100:0.797,lwr_k=20:0.7077,lwr_k=50:0.7266,lwr_k=100:0.7403,lwr_k=200:0.7429,lwr_k=500:0.7595,lwr_k=1000:0.7689'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9597,knn_k=1:0.0,knn_k=5:0.6377,knn_k=10:0.7857,knn_k=20:0.8975,knn_k=50:1.0112,knn_k=100:1.0884,lwr_k=20:0.5962,lwr_k=50:0.6533,lwr_k=100:0.6931,lwr_k=200:0.7288,lwr_k=500:0.7796,lwr_k=1000:0.8242'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9392,knn_k=1:1.2391,knn_k=5:0.9635,knn_k=10:0.9387,knn_k=20:0.991,knn_k=50:1.0592,knn_k=100:1.1174,lwr_k=20:0.8186,lwr_k=50:0.7814,lwr_k=100:0.7697,lwr_k=200:0.7588,lwr_k=500:0.7883,lwr_k=1000:0.8247'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9615,knn_k=1:0.0,knn_k=5:0.5637,knn_k=10:0.6909,knn_k=20:0.7779,knn_k=50:0.8851,knn_k=100:0.9856,lwr_k=20:0.5041,lwr_k=50:0.5808,lwr_k=100:0.6373,lwr_k=200:0.6858,lwr_k=500:0.7486,lwr_k=1000:0.7873'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9002,knn_k=1:1.0869,knn_k=5:0.8038,knn_k=10:0.7774,knn_k=20:0.7963,knn_k=50:0.8771,knn_k=100:0.9474,lwr_k=20:0.6734,lwr_k=50:0.6822,lwr_k=100:0.6891,lwr_k=200:0.6981,lwr_k=500:0.721,lwr_k=1000:0.7407'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8455,knn_k=1:0.0,knn_k=5:0.5492,knn_k=10:0.6667,knn_k=20:0.7421,knn_k=50:0.846,knn_k=100:0.916,lwr_k=20:0.5293,lwr_k=50:0.596,lwr_k=100:0.6468,lwr_k=200:0.6932,lwr_k=500:0.7443,lwr_k=1000:0.7717'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8505,knn_k=1:1.1435,knn_k=5:0.8299,knn_k=10:0.8358,knn_k=20:0.854,knn_k=50:0.9105,knn_k=100:0.9685,lwr_k=20:0.729,lwr_k=50:0.7426,lwr_k=100:0.7574,lwr_k=200:0.7808,lwr_k=500:0.7945,lwr_k=1000:0.801'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6427,knn_k=1:0.0,knn_k=5:0.4553,knn_k=10:0.5396,knn_k=20:0.59,knn_k=50:0.6254,knn_k=100:0.6428,lwr_k=20:0.4135,lwr_k=50:0.4951,lwr_k=100:0.5436,lwr_k=200:0.5789,lwr_k=500:0.6087,lwr_k=1000:0.6246'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6615,knn_k=1:0.9085,knn_k=5:0.6937,knn_k=10:0.6698,knn_k=20:0.6717,knn_k=50:0.6655,knn_k=100:0.6686,lwr_k=20:0.6105,lwr_k=50:0.6185,lwr_k=100:0.6177,lwr_k=200:0.6406,lwr_k=500:0.6439,lwr_k=1000:0.6482'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_77'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9819,knn_k=1:0.0,knn_k=5:0.8162,knn_k=10:0.9534,knn_k=20:1.0462,knn_k=50:1.1385,knn_k=100:1.1966,lwr_k=20:0.8669,lwr_k=50:0.93,lwr_k=100:0.9685,lwr_k=200:0.9945,lwr_k=500:1.0312,lwr_k=1000:1.0506'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.0261,knn_k=1:2.0072,knn_k=5:1.3182,knn_k=10:1.256,knn_k=20:1.2339,knn_k=50:1.2662,knn_k=100:1.3155,lwr_k=20:1.1544,lwr_k=50:1.1075,lwr_k=100:1.0875,lwr_k=200:1.0955,lwr_k=500:1.0999,lwr_k=1000:1.1174'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6537,knn_k=1:0.0,knn_k=5:0.496,knn_k=10:0.5655,knn_k=20:0.6098,knn_k=50:0.6414,knn_k=100:0.6582,lwr_k=20:0.493,lwr_k=50:0.5637,lwr_k=100:0.5929,lwr_k=200:0.6177,lwr_k=500:0.6341,lwr_k=1000:0.6444'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6646,knn_k=1:1.1653,knn_k=5:0.7322,knn_k=10:0.6908,knn_k=20:0.6716,knn_k=50:0.6733,knn_k=100:0.68,lwr_k=20:0.7085,lwr_k=50:0.6716,lwr_k=100:0.6649,lwr_k=200:0.6617,lwr_k=500:0.6605,lwr_k=1000:0.6661'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0846,knn_k=1:0.0,knn_k=5:1.1554,knn_k=10:1.3374,knn_k=20:1.4113,knn_k=50:1.4851,knn_k=100:1.5425,lwr_k=20:1.2541,lwr_k=50:1.3356,lwr_k=100:1.3645,lwr_k=200:1.3829,lwr_k=500:1.3924,lwr_k=1000:1.3963'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0937,knn_k=1:2.7746,knn_k=5:1.654,knn_k=10:1.5503,knn_k=20:1.55,knn_k=50:1.5846,knn_k=100:1.6178,lwr_k=20:1.4776,lwr_k=50:1.4606,lwr_k=100:1.4376,lwr_k=200:1.4355,lwr_k=500:1.4404,lwr_k=1000:1.459'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9183,knn_k=1:0.0,knn_k=5:1.6701,knn_k=10:2.1118,knn_k=20:2.4249,knn_k=50:2.6736,knn_k=100:2.791,lwr_k=20:1.415,lwr_k=50:1.2749,lwr_k=100:1.1593,lwr_k=200:1.0639,lwr_k=500:0.9705,lwr_k=1000:0.9498'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8857,knn_k=1:3.6642,knn_k=5:2.6792,knn_k=10:2.7559,knn_k=20:2.8373,knn_k=50:2.9682,knn_k=100:3.0175,lwr_k=20:1.8413,lwr_k=50:1.4743,lwr_k=100:1.2573,lwr_k=200:1.094,lwr_k=500:0.9669,lwr_k=1000:0.9362'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7214,knn_k=1:0.0,knn_k=5:0.5908,knn_k=10:0.6934,knn_k=20:0.7675,knn_k=50:0.8507,knn_k=100:0.9244,lwr_k=20:0.6364,lwr_k=50:0.6637,lwr_k=100:0.6778,lwr_k=200:0.7013,lwr_k=500:0.7214,lwr_k=1000:0.7233'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7054,knn_k=1:1.3324,knn_k=5:0.8634,knn_k=10:0.8405,knn_k=20:0.8332,knn_k=50:0.8865,knn_k=100:0.9499,lwr_k=20:0.7641,lwr_k=50:0.7444,lwr_k=100:0.7232,lwr_k=200:0.7107,lwr_k=500:0.7128,lwr_k=1000:0.7046'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.505,knn_k=1:0.0,knn_k=5:0.4071,knn_k=10:0.4563,knn_k=20:0.484,knn_k=50:0.502,knn_k=100:0.5132,lwr_k=20:0.457,lwr_k=50:0.4788,lwr_k=100:0.4892,lwr_k=200:0.4967,lwr_k=500:0.5025,lwr_k=1000:0.5051'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5306,knn_k=1:0.9971,knn_k=5:0.6395,knn_k=10:0.589,knn_k=20:0.5604,knn_k=50:0.5585,knn_k=100:0.5564,lwr_k=20:0.5699,lwr_k=50:0.5457,lwr_k=100:0.5383,lwr_k=200:0.5357,lwr_k=500:0.534,lwr_k=1000:0.5359'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_78'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.846,knn_k=1:0.0,knn_k=5:0.5199,knn_k=10:0.6765,knn_k=20:0.7873,knn_k=50:0.9344,knn_k=100:1.0986,lwr_k=20:0.303,lwr_k=50:0.4601,lwr_k=100:0.5536,lwr_k=200:0.6194,lwr_k=500:0.6923,lwr_k=1000:0.7374'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8549,knn_k=1:0.9726,knn_k=5:0.8325,knn_k=10:0.861,knn_k=20:0.9053,knn_k=50:1.004,knn_k=100:1.1523,lwr_k=20:0.659,lwr_k=50:0.6975,lwr_k=100:0.7007,lwr_k=200:0.7022,lwr_k=500:0.7378,lwr_k=1000:0.7597'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6926,knn_k=1:0.0,knn_k=5:0.473,knn_k=10:0.5852,knn_k=20:0.6644,knn_k=50:0.7536,knn_k=100:0.8301,lwr_k=20:0.3162,lwr_k=50:0.4667,lwr_k=100:0.5458,lwr_k=200:0.5978,lwr_k=500:0.6428,lwr_k=1000:0.6683'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7383,knn_k=1:0.9117,knn_k=5:0.7883,knn_k=10:0.7884,knn_k=20:0.7871,knn_k=50:0.8426,knn_k=100:0.9001,lwr_k=20:0.7274,lwr_k=50:0.7063,lwr_k=100:0.7165,lwr_k=200:0.7149,lwr_k=500:0.7197,lwr_k=1000:0.7332'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3979,knn_k=1:0.0,knn_k=5:0.9242,knn_k=10:1.105,knn_k=20:1.2378,knn_k=50:1.3335,knn_k=100:1.4127,lwr_k=20:0.8819,lwr_k=50:0.9618,lwr_k=100:1.0028,lwr_k=200:1.0542,lwr_k=500:1.1345,lwr_k=1000:1.2182'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.4516,knn_k=1:2.0277,knn_k=5:1.4845,knn_k=10:1.4143,knn_k=20:1.4073,knn_k=50:1.4298,knn_k=100:1.47,lwr_k=20:1.2268,lwr_k=50:1.1619,lwr_k=100:1.1424,lwr_k=200:1.1396,lwr_k=500:1.1918,lwr_k=1000:1.2827'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.0172,knn_k=1:0.0,knn_k=5:1.1911,knn_k=10:1.4932,knn_k=20:1.7217,knn_k=50:1.9701,knn_k=100:2.1378,lwr_k=20:1.1792,lwr_k=50:1.1963,lwr_k=100:1.1973,lwr_k=200:1.2048,lwr_k=500:1.2697,lwr_k=1000:1.3489'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.0245,knn_k=1:2.5323,knn_k=5:1.8834,knn_k=10:1.9039,knn_k=20:1.9614,knn_k=50:2.1317,knn_k=100:2.2419,lwr_k=20:1.5277,lwr_k=50:1.3538,lwr_k=100:1.2993,lwr_k=200:1.2651,lwr_k=500:1.298,lwr_k=1000:1.3611'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8456,knn_k=1:0.0,knn_k=5:0.4863,knn_k=10:0.6133,knn_k=20:0.7024,knn_k=50:0.7996,knn_k=100:0.9006,lwr_k=20:0.4095,lwr_k=50:0.5268,lwr_k=100:0.5909,lwr_k=200:0.6362,lwr_k=500:0.681,lwr_k=1000:0.7218'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8621,knn_k=1:0.861,knn_k=5:0.7984,knn_k=10:0.7724,knn_k=20:0.7955,knn_k=50:0.8658,knn_k=100:0.9555,lwr_k=20:0.6779,lwr_k=50:0.679,lwr_k=100:0.6838,lwr_k=200:0.6921,lwr_k=500:0.7109,lwr_k=1000:0.7309'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6861,knn_k=1:0.0,knn_k=5:0.4463,knn_k=10:0.5676,knn_k=20:0.6439,knn_k=50:0.7207,knn_k=100:0.7902,lwr_k=20:0.3359,lwr_k=50:0.4712,lwr_k=100:0.5511,lwr_k=200:0.6048,lwr_k=500:0.6427,lwr_k=1000:0.6628'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6961,knn_k=1:0.7775,knn_k=5:0.7014,knn_k=10:0.6833,knn_k=20:0.7072,knn_k=50:0.7389,knn_k=100:0.7903,lwr_k=20:0.6666,lwr_k=50:0.6575,lwr_k=100:0.6361,lwr_k=200:0.6462,lwr_k=500:0.659,lwr_k=1000:0.6771'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_79'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9524,knn_k=1:0.0,knn_k=5:0.5093,knn_k=10:0.6592,knn_k=20:0.7859,knn_k=50:0.9497,knn_k=100:1.0964,lwr_k=20:0.2215,lwr_k=50:0.3712,lwr_k=100:0.4726,lwr_k=200:0.5645,lwr_k=500:0.6601,lwr_k=1000:0.7214'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9823,knn_k=1:0.8919,knn_k=5:0.8232,knn_k=10:0.8072,knn_k=20:0.8772,knn_k=50:1.0068,knn_k=100:1.1337,lwr_k=20:0.7028,lwr_k=50:0.6812,lwr_k=100:0.6861,lwr_k=200:0.7046,lwr_k=500:0.7438,lwr_k=1000:0.7823'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6814,knn_k=1:0.0,knn_k=5:0.4116,knn_k=10:0.5228,knn_k=20:0.5942,knn_k=50:0.6527,knn_k=100:0.6963,lwr_k=20:0.2786,lwr_k=50:0.3976,lwr_k=100:0.4752,lwr_k=200:0.5368,lwr_k=500:0.5964,lwr_k=1000:0.6351'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7452,knn_k=1:0.803,knn_k=5:0.7452,knn_k=10:0.7372,knn_k=20:0.7422,knn_k=50:0.764,knn_k=100:0.7811,lwr_k=20:0.6721,lwr_k=50:0.6831,lwr_k=100:0.6759,lwr_k=200:0.6784,lwr_k=500:0.6913,lwr_k=1000:0.7059'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1668,knn_k=1:0.0,knn_k=5:0.7148,knn_k=10:0.9063,knn_k=20:1.0593,knn_k=50:1.1974,knn_k=100:1.2869,lwr_k=20:0.4501,lwr_k=50:0.5732,lwr_k=100:0.6471,lwr_k=200:0.7218,lwr_k=500:0.7846,lwr_k=1000:0.8456'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2573,knn_k=1:1.3064,knn_k=5:1.1794,knn_k=10:1.2087,knn_k=20:1.2279,knn_k=50:1.2813,knn_k=100:1.3391,lwr_k=20:0.8766,lwr_k=50:0.8252,lwr_k=100:0.8139,lwr_k=200:0.816,lwr_k=500:0.8556,lwr_k=1000:0.8965'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0205,knn_k=1:0.1077,knn_k=5:0.6992,knn_k=10:0.884,knn_k=20:1.0163,knn_k=50:1.189,knn_k=100:1.3466,lwr_k=20:0.5514,lwr_k=50:0.6382,lwr_k=100:0.7027,lwr_k=200:0.7442,lwr_k=500:0.8062,lwr_k=1000:0.85'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9899,knn_k=1:1.3118,knn_k=5:1.0864,knn_k=10:1.1042,knn_k=20:1.1303,knn_k=50:1.2299,knn_k=100:1.3733,lwr_k=20:0.8089,lwr_k=50:0.7818,lwr_k=100:0.7867,lwr_k=200:0.7867,lwr_k=500:0.8147,lwr_k=1000:0.8463'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9103,knn_k=1:0.0,knn_k=5:0.5243,knn_k=10:0.6822,knn_k=20:0.7978,knn_k=50:0.9334,knn_k=100:1.0546,lwr_k=20:0.1919,lwr_k=50:0.3647,lwr_k=100:0.4878,lwr_k=200:0.5927,lwr_k=500:0.6944,lwr_k=1000:0.7509'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9183,knn_k=1:0.7863,knn_k=5:0.826,knn_k=10:0.8597,knn_k=20:0.9039,knn_k=50:0.9868,knn_k=100:1.097,lwr_k=20:0.6538,lwr_k=50:0.6794,lwr_k=100:0.6739,lwr_k=200:0.6956,lwr_k=500:0.7275,lwr_k=1000:0.771'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6703,knn_k=1:0.0,knn_k=5:0.4084,knn_k=10:0.5298,knn_k=20:0.5988,knn_k=50:0.6622,knn_k=100:0.7044,lwr_k=20:0.2867,lwr_k=50:0.4151,lwr_k=100:0.4973,lwr_k=200:0.5547,lwr_k=500:0.6084,lwr_k=1000:0.631'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6668,knn_k=1:0.6999,knn_k=5:0.6826,knn_k=10:0.6838,knn_k=20:0.6861,knn_k=50:0.6961,knn_k=100:0.7195,lwr_k=20:0.6186,lwr_k=50:0.605,lwr_k=100:0.628,lwr_k=200:0.6272,lwr_k=500:0.6426,lwr_k=1000:0.6483'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_80'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8667,knn_k=1:0.0,knn_k=5:0.5539,knn_k=10:0.7302,knn_k=20:0.873,knn_k=50:1.0897,knn_k=100:1.3096,lwr_k=20:0.0304,lwr_k=50:0.1351,lwr_k=100:0.2886,lwr_k=200:0.4358,lwr_k=500:0.5796,lwr_k=1000:0.646'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8768,knn_k=1:0.8444,knn_k=5:0.8574,knn_k=10:0.8946,knn_k=20:0.9847,knn_k=50:1.1643,knn_k=100:1.3835,lwr_k=20:0.707,lwr_k=50:0.7048,lwr_k=100:0.6629,lwr_k=200:0.6264,lwr_k=500:0.6437,lwr_k=1000:0.6867'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6575,knn_k=1:0.0,knn_k=5:0.4683,knn_k=10:0.5995,knn_k=20:0.7063,knn_k=50:0.8333,knn_k=100:0.9541,lwr_k=20:0.0311,lwr_k=50:0.1241,lwr_k=100:0.2657,lwr_k=200:0.3915,lwr_k=500:0.5156,lwr_k=1000:0.5782'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7135,knn_k=1:0.7858,knn_k=5:0.7834,knn_k=10:0.7893,knn_k=20:0.8277,knn_k=50:0.9148,knn_k=100:1.0301,lwr_k=20:0.7073,lwr_k=50:0.6825,lwr_k=100:0.6712,lwr_k=200:0.6469,lwr_k=500:0.649,lwr_k=1000:0.6703'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8571,knn_k=1:0.0,knn_k=5:0.525,knn_k=10:0.6813,knn_k=20:0.8074,knn_k=50:0.9825,knn_k=100:1.1497,lwr_k=20:0.0307,lwr_k=50:0.1414,lwr_k=100:0.2928,lwr_k=200:0.4354,lwr_k=500:0.5718,lwr_k=1000:0.6448'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8826,knn_k=1:0.8458,knn_k=5:0.8388,knn_k=10:0.852,knn_k=20:0.8846,knn_k=50:1.0173,knn_k=100:1.1886,lwr_k=20:0.7038,lwr_k=50:0.6769,lwr_k=100:0.6779,lwr_k=200:0.658,lwr_k=500:0.6749,lwr_k=1000:0.7004'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8266,knn_k=1:0.0,knn_k=5:0.5404,knn_k=10:0.7012,knn_k=20:0.8147,knn_k=50:0.991,knn_k=100:1.1567,lwr_k=20:0.0735,lwr_k=50:0.2187,lwr_k=100:0.3542,lwr_k=200:0.4738,lwr_k=500:0.5962,lwr_k=1000:0.6581'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7799,knn_k=1:0.8224,knn_k=5:0.7856,knn_k=10:0.7883,knn_k=20:0.833,knn_k=50:0.9375,knn_k=100:1.0817,lwr_k=20:0.6846,lwr_k=50:0.6494,lwr_k=100:0.6464,lwr_k=200:0.6258,lwr_k=500:0.6291,lwr_k=1000:0.6658'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7241,knn_k=1:0.0,knn_k=5:0.448,knn_k=10:0.5728,knn_k=20:0.6466,knn_k=50:0.7525,knn_k=100:0.8345,lwr_k=20:0.2087,lwr_k=50:0.3541,lwr_k=100:0.4432,lwr_k=200:0.5176,lwr_k=500:0.5848,lwr_k=1000:0.6227'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7342,knn_k=1:0.6996,knn_k=5:0.7049,knn_k=10:0.7188,knn_k=20:0.7354,knn_k=50:0.7968,knn_k=100:0.8627,lwr_k=20:0.5713,lwr_k=50:0.5756,lwr_k=100:0.6006,lwr_k=200:0.6347,lwr_k=500:0.6514,lwr_k=1000:0.6661'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6824,knn_k=1:0.0,knn_k=5:0.4485,knn_k=10:0.601,knn_k=20:0.6968,knn_k=50:0.835,knn_k=100:0.9503,lwr_k=20:0.0224,lwr_k=50:0.1055,lwr_k=100:0.2374,lwr_k=200:0.3771,lwr_k=500:0.5125,lwr_k=1000:0.5765'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.688,knn_k=1:0.6074,knn_k=5:0.7246,knn_k=10:0.7301,knn_k=20:0.7784,knn_k=50:0.8584,knn_k=100:0.9617,lwr_k=20:0.522,lwr_k=50:0.5906,lwr_k=100:0.5819,lwr_k=200:0.5815,lwr_k=500:0.5997,lwr_k=1000:0.6223'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_81'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2525,knn_k=1:0.0035,knn_k=5:0.98,knn_k=10:1.09,knn_k=20:1.1545,knn_k=50:1.2044,knn_k=100:1.2202,lwr_k=20:1.1345,lwr_k=50:1.1818,lwr_k=100:1.1918,lwr_k=200:1.2029,lwr_k=500:1.2142,lwr_k=1000:1.2226'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.3355,knn_k=1:2.5057,knn_k=5:1.5406,knn_k=10:1.4454,knn_k=20:1.3735,knn_k=50:1.3291,knn_k=100:1.338,lwr_k=20:1.3451,lwr_k=50:1.3018,lwr_k=100:1.298,lwr_k=200:1.2963,lwr_k=500:1.2946,lwr_k=1000:1.2998'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8392,knn_k=1:0.5377,knn_k=5:0.686,knn_k=10:0.7446,knn_k=20:0.7882,knn_k=50:0.7997,knn_k=100:0.8118,lwr_k=20:0.787,lwr_k=50:0.7962,lwr_k=100:0.8073,lwr_k=200:0.8088,lwr_k=500:0.8095,lwr_k=1000:0.8172'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.895,knn_k=1:1.9518,knn_k=5:0.9967,knn_k=10:0.9329,knn_k=20:0.9131,knn_k=50:0.8791,knn_k=100:0.8702,lwr_k=20:0.9134,lwr_k=50:0.8797,lwr_k=100:0.869,lwr_k=200:0.8636,lwr_k=500:0.8606,lwr_k=1000:0.8693'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4706,knn_k=1:0.1943,knn_k=5:1.1947,knn_k=10:1.3269,knn_k=20:1.4011,knn_k=50:1.4381,knn_k=100:1.4486,lwr_k=20:1.3982,lwr_k=50:1.4335,lwr_k=100:1.4417,lwr_k=200:1.4485,lwr_k=500:1.455,lwr_k=1000:1.459'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.5587,knn_k=1:2.8226,knn_k=5:1.8145,knn_k=10:1.6696,knn_k=20:1.596,knn_k=50:1.5465,knn_k=100:1.5332,lwr_k=20:1.5961,lwr_k=50:1.5465,lwr_k=100:1.5323,lwr_k=200:1.5209,lwr_k=500:1.5201,lwr_k=1000:1.5331'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.8045,knn_k=1:0.6014,knn_k=5:2.3286,knn_k=10:2.562,knn_k=20:2.6558,knn_k=50:2.7249,knn_k=100:2.7553,lwr_k=20:2.651,lwr_k=50:2.7206,lwr_k=100:2.7534,lwr_k=200:2.7625,lwr_k=500:2.7663,lwr_k=1000:2.7701'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.9589,knn_k=1:5.0511,knn_k=5:3.3455,knn_k=10:3.118,knn_k=20:3.0026,knn_k=50:2.9459,knn_k=100:2.9195,lwr_k=20:3.016,lwr_k=50:2.9518,lwr_k=100:2.9212,lwr_k=200:2.9158,lwr_k=500:2.9027,lwr_k=1000:2.9051'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3666,knn_k=1:0.0072,knn_k=5:1.0675,knn_k=10:1.196,knn_k=20:1.265,knn_k=50:1.3152,knn_k=100:1.3367,lwr_k=20:1.256,lwr_k=50:1.3049,lwr_k=100:1.3213,lwr_k=200:1.3287,lwr_k=500:1.335,lwr_k=1000:1.3458'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.4215,knn_k=1:2.6308,knn_k=5:1.7009,knn_k=10:1.5347,knn_k=20:1.4547,knn_k=50:1.4187,knn_k=100:1.3985,lwr_k=20:1.4584,lwr_k=50:1.4197,lwr_k=100:1.3893,lwr_k=200:1.3866,lwr_k=500:1.3858,lwr_k=1000:1.4014'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6999,knn_k=1:0.1257,knn_k=5:0.6102,knn_k=10:0.6818,knn_k=20:0.6603,knn_k=50:0.6747,knn_k=100:0.6759,lwr_k=20:0.6595,lwr_k=50:0.6716,lwr_k=100:0.6729,lwr_k=200:0.6775,lwr_k=500:0.6833,lwr_k=1000:0.6855'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6845,knn_k=1:1.2867,knn_k=5:0.7998,knn_k=10:0.7643,knn_k=20:0.6973,knn_k=50:0.6824,knn_k=100:0.6705,lwr_k=20:0.6949,lwr_k=50:0.6743,lwr_k=100:0.6622,lwr_k=200:0.6644,lwr_k=500:0.6654,lwr_k=1000:0.6661'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_82'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7001,knn_k=1:0.0,knn_k=5:0.6267,knn_k=10:0.7277,knn_k=20:0.7977,knn_k=50:0.8848,knn_k=100:0.9558,lwr_k=20:0.5273,lwr_k=50:0.595,lwr_k=100:0.6354,lwr_k=200:0.6702,lwr_k=500:0.7033,lwr_k=1000:0.7285'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7329,knn_k=1:1.5057,knn_k=5:0.9709,knn_k=10:0.9375,knn_k=20:0.9375,knn_k=50:0.9763,knn_k=100:1.0355,lwr_k=20:0.8663,lwr_k=50:0.7825,lwr_k=100:0.7699,lwr_k=200:0.7571,lwr_k=500:0.7783,lwr_k=1000:0.7924'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.5877,knn_k=1:0.0,knn_k=5:0.4755,knn_k=10:0.5413,knn_k=20:0.5806,knn_k=50:0.6161,knn_k=100:0.6404,lwr_k=20:0.4717,lwr_k=50:0.5204,lwr_k=100:0.5402,lwr_k=200:0.5564,lwr_k=500:0.5706,lwr_k=1000:0.5791'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6357,knn_k=1:1.2185,knn_k=5:0.7351,knn_k=10:0.6962,knn_k=20:0.6732,knn_k=50:0.6707,knn_k=100:0.6821,lwr_k=20:0.6812,lwr_k=50:0.6434,lwr_k=100:0.6392,lwr_k=200:0.6388,lwr_k=500:0.633,lwr_k=1000:0.6324'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7903,knn_k=1:0.0,knn_k=5:0.891,knn_k=10:1.0245,knn_k=20:1.1231,knn_k=50:1.216,knn_k=100:1.2773,lwr_k=20:0.7657,lwr_k=50:0.8744,lwr_k=100:0.9133,lwr_k=200:0.9442,lwr_k=500:0.9721,lwr_k=1000:1.0052'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8169,knn_k=1:2.0598,knn_k=5:1.3494,knn_k=10:1.2832,knn_k=20:1.2867,knn_k=50:1.3132,knn_k=100:1.3471,lwr_k=20:1.1854,lwr_k=50:1.0913,lwr_k=100:1.055,lwr_k=200:1.0317,lwr_k=500:1.0352,lwr_k=1000:1.045'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6924,knn_k=1:0.0,knn_k=5:0.9567,knn_k=10:1.1309,knn_k=20:1.2664,knn_k=50:1.4142,knn_k=100:1.5173,lwr_k=20:0.6985,lwr_k=50:0.7654,lwr_k=100:0.7838,lwr_k=200:0.7997,lwr_k=500:0.8196,lwr_k=1000:0.8292'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7001,knn_k=1:2.2906,knn_k=5:1.4723,knn_k=10:1.4179,knn_k=20:1.4425,knn_k=50:1.5352,knn_k=100:1.6105,lwr_k=20:1.0937,lwr_k=50:0.9466,lwr_k=100:0.8938,lwr_k=200:0.8736,lwr_k=500:0.8536,lwr_k=1000:0.8538'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7033,knn_k=1:0.0,knn_k=5:0.7039,knn_k=10:0.8508,knn_k=20:0.9458,knn_k=50:1.0469,knn_k=100:1.0983,lwr_k=20:0.5804,lwr_k=50:0.6349,lwr_k=100:0.6614,lwr_k=200:0.6768,lwr_k=500:0.6882,lwr_k=1000:0.6888'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6641,knn_k=1:1.4728,knn_k=5:1.016,knn_k=10:0.9926,knn_k=20:1.0219,knn_k=50:1.0815,knn_k=100:1.1267,lwr_k=20:0.7927,lwr_k=50:0.7363,lwr_k=100:0.71,lwr_k=200:0.6974,lwr_k=500:0.6853,lwr_k=1000:0.6833'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.4949,knn_k=1:0.0,knn_k=5:0.383,knn_k=10:0.4343,knn_k=20:0.4631,knn_k=50:0.4856,knn_k=100:0.5022,lwr_k=20:0.3596,lwr_k=50:0.4099,lwr_k=100:0.4349,lwr_k=200:0.4505,lwr_k=500:0.4638,lwr_k=1000:0.47'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5233,knn_k=1:0.964,knn_k=5:0.6106,knn_k=10:0.5544,knn_k=20:0.537,knn_k=50:0.5324,knn_k=100:0.5369,lwr_k=20:0.5496,lwr_k=50:0.5107,lwr_k=100:0.5046,lwr_k=200:0.5061,lwr_k=500:0.5028,lwr_k=1000:0.5051'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_83'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.2275,knn_k=1:0.0,knn_k=5:2.7718,knn_k=10:3.3363,knn_k=20:3.7191,knn_k=50:4.109,knn_k=100:4.3747,lwr_k=20:1.1013,lwr_k=50:1.8663,lwr_k=100:2.2875,lwr_k=200:2.6265,lwr_k=500:3.0066,lwr_k=1000:3.2805'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.6394,knn_k=1:5.9535,knn_k=5:4.4278,knn_k=10:4.2424,knn_k=20:4.2972,knn_k=50:4.5587,knn_k=100:4.7503,lwr_k=20:5.7069,lwr_k=50:4.3995,lwr_k=100:3.5456,lwr_k=200:3.6664,lwr_k=500:4.1404,lwr_k=1000:4.5642'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.8136,knn_k=1:0.0,knn_k=5:1.2488,knn_k=10:1.5455,knn_k=20:1.8178,knn_k=50:2.0821,knn_k=100:2.2471,lwr_k=20:0.3595,lwr_k=50:0.6851,lwr_k=100:0.9044,lwr_k=200:1.0819,lwr_k=500:1.2745,lwr_k=1000:1.3856'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.985,knn_k=1:2.5888,knn_k=5:2.0565,knn_k=10:2.1343,knn_k=20:2.1982,knn_k=50:2.3843,knn_k=100:2.5174,lwr_k=20:1.9158,lwr_k=50:1.4242,lwr_k=100:1.278,lwr_k=200:1.3015,lwr_k=500:1.3866,lwr_k=1000:1.5035'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0888,knn_k=1:0.0,knn_k=5:0.7901,knn_k=10:0.9587,knn_k=20:1.0673,knn_k=50:1.183,knn_k=100:1.2651,lwr_k=20:0.2308,lwr_k=50:0.4466,lwr_k=100:0.5754,lwr_k=200:0.6627,lwr_k=500:0.7606,lwr_k=1000:0.8229'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1336,knn_k=1:1.7444,knn_k=5:1.2105,knn_k=10:1.1742,knn_k=20:1.1936,knn_k=50:1.2626,knn_k=100:1.3329,lwr_k=20:1.2706,lwr_k=50:0.9664,lwr_k=100:0.8473,lwr_k=200:0.8422,lwr_k=500:0.8791,lwr_k=1000:0.8847'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7903,knn_k=1:0.0,knn_k=5:0.8213,knn_k=10:1.0542,knn_k=20:1.333,knn_k=50:1.7874,knn_k=100:2.1742,lwr_k=20:0.7612,lwr_k=50:0.7275,lwr_k=100:0.7224,lwr_k=200:0.721,lwr_k=500:0.71,lwr_k=1000:0.7155'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7406,knn_k=1:1.8101,knn_k=5:1.283,knn_k=10:1.3397,knn_k=20:1.522,knn_k=50:1.9483,knn_k=100:2.3115,lwr_k=20:0.9594,lwr_k=50:0.8284,lwr_k=100:0.7722,lwr_k=200:0.7407,lwr_k=500:0.7104,lwr_k=1000:0.7082'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7472,knn_k=1:0.0,knn_k=5:0.6433,knn_k=10:0.7911,knn_k=20:0.9144,knn_k=50:1.0389,knn_k=100:1.0893,lwr_k=20:0.6413,lwr_k=50:0.6585,lwr_k=100:0.66,lwr_k=200:0.6539,lwr_k=500:0.6505,lwr_k=1000:0.6582'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7684,knn_k=1:1.464,knn_k=5:0.9794,knn_k=10:0.9815,knn_k=20:1.0308,knn_k=50:1.1185,knn_k=100:1.1446,lwr_k=20:0.8554,lwr_k=50:0.7806,lwr_k=100:0.7295,lwr_k=200:0.696,lwr_k=500:0.6739,lwr_k=1000:0.6717'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6065,knn_k=1:0.0,knn_k=5:0.4266,knn_k=10:0.5034,knn_k=20:0.548,knn_k=50:0.5836,knn_k=100:0.5982,lwr_k=20:0.2063,lwr_k=50:0.3646,lwr_k=100:0.4429,lwr_k=200:0.4903,lwr_k=500:0.5364,lwr_k=1000:0.5627'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6052,knn_k=1:1.0235,knn_k=5:0.6481,knn_k=10:0.6098,knn_k=20:0.6028,knn_k=50:0.6066,knn_k=100:0.6146,lwr_k=20:0.8989,lwr_k=50:0.6389,lwr_k=100:0.6065,lwr_k=200:0.5878,lwr_k=500:0.5943,lwr_k=1000:0.5975'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_84'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0306,knn_k=1:0.0,knn_k=5:0.6041,knn_k=10:0.7962,knn_k=20:0.984,knn_k=50:1.2504,knn_k=100:1.5248,lwr_k=20:0.0517,lwr_k=50:0.1862,lwr_k=100:0.3468,lwr_k=200:0.5016,lwr_k=500:0.6543,lwr_k=1000:0.7599'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.0273,knn_k=1:0.9137,knn_k=5:0.9445,knn_k=10:1.0015,knn_k=20:1.0943,knn_k=50:1.3391,knn_k=100:1.6016,lwr_k=20:0.7991,lwr_k=50:0.7653,lwr_k=100:0.7753,lwr_k=200:0.7111,lwr_k=500:0.7527,lwr_k=1000:0.7977'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6737,knn_k=1:0.0,knn_k=5:0.4742,knn_k=10:0.6141,knn_k=20:0.7143,knn_k=50:0.8757,knn_k=100:1.0423,lwr_k=20:0.0983,lwr_k=50:0.2397,lwr_k=100:0.3658,lwr_k=200:0.4721,lwr_k=500:0.5669,lwr_k=1000:0.6094'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7237,knn_k=1:0.7466,knn_k=5:0.7755,knn_k=10:0.791,knn_k=20:0.8521,knn_k=50:0.971,knn_k=100:1.1215,lwr_k=20:0.6847,lwr_k=50:0.7153,lwr_k=100:0.6854,lwr_k=200:0.6937,lwr_k=500:0.6713,lwr_k=1000:0.6834'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0283,knn_k=1:0.0,knn_k=5:0.7054,knn_k=10:0.9176,knn_k=20:1.1211,knn_k=50:1.404,knn_k=100:1.6554,lwr_k=20:0.0672,lwr_k=50:0.2202,lwr_k=100:0.3804,lwr_k=200:0.5297,lwr_k=500:0.6792,lwr_k=1000:0.7647'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0343,knn_k=1:1.0766,knn_k=5:1.1146,knn_k=10:1.1476,knn_k=20:1.2646,knn_k=50:1.4763,knn_k=100:1.7172,lwr_k=20:0.8786,lwr_k=50:0.8463,lwr_k=100:0.7778,lwr_k=200:0.732,lwr_k=500:0.7657,lwr_k=1000:0.8168'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9707,knn_k=1:0.0,knn_k=5:0.572,knn_k=10:0.7483,knn_k=20:0.8688,knn_k=50:1.043,knn_k=100:1.2056,lwr_k=20:0.0933,lwr_k=50:0.2444,lwr_k=100:0.3988,lwr_k=200:0.531,lwr_k=500:0.6644,lwr_k=1000:0.7487'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9554,knn_k=1:0.938,knn_k=5:0.8466,knn_k=10:0.8779,knn_k=20:0.9245,knn_k=50:1.0442,knn_k=100:1.169,lwr_k=20:0.7677,lwr_k=50:0.7302,lwr_k=100:0.6823,lwr_k=200:0.6838,lwr_k=500:0.7348,lwr_k=1000:0.7796'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0168,knn_k=1:0.0,knn_k=5:0.6791,knn_k=10:0.8872,knn_k=20:1.074,knn_k=50:1.4092,knn_k=100:1.7004,lwr_k=20:0.0492,lwr_k=50:0.1898,lwr_k=100:0.3564,lwr_k=200:0.4999,lwr_k=500:0.6497,lwr_k=1000:0.7401'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0179,knn_k=1:0.9622,knn_k=5:1.0757,knn_k=10:1.1327,knn_k=20:1.2312,knn_k=50:1.4794,knn_k=100:1.7488,lwr_k=20:0.7945,lwr_k=50:0.8153,lwr_k=100:0.7606,lwr_k=200:0.7386,lwr_k=500:0.7761,lwr_k=1000:0.8149'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.65,knn_k=1:0.0,knn_k=5:0.4678,knn_k=10:0.618,knn_k=20:0.7282,knn_k=50:0.8709,knn_k=100:1.0118,lwr_k=20:0.0607,lwr_k=50:0.1964,lwr_k=100:0.3351,lwr_k=200:0.4465,lwr_k=500:0.5481,lwr_k=1000:0.5929'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6904,knn_k=1:0.6981,knn_k=5:0.785,knn_k=10:0.7892,knn_k=20:0.8196,knn_k=50:0.9165,knn_k=100:1.0408,lwr_k=20:0.6647,lwr_k=50:0.7205,lwr_k=100:0.6481,lwr_k=200:0.6232,lwr_k=500:0.6347,lwr_k=1000:0.6449'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_85'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2458,knn_k=1:0.0,knn_k=5:0.7859,knn_k=10:0.9412,knn_k=20:1.0707,knn_k=50:1.1861,knn_k=100:1.2593,lwr_k=20:0.3687,lwr_k=50:0.5388,lwr_k=100:0.6385,lwr_k=200:0.7052,lwr_k=500:0.7963,lwr_k=1000:0.8762'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.3169,knn_k=1:1.8246,knn_k=5:1.286,knn_k=10:1.2439,knn_k=20:1.2519,knn_k=50:1.2993,knn_k=100:1.3509,lwr_k=20:1.2189,lwr_k=50:0.9996,lwr_k=100:0.9217,lwr_k=200:0.8946,lwr_k=500:0.9224,lwr_k=1000:0.9572'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6134,knn_k=1:0.0,knn_k=5:0.4517,knn_k=10:0.5296,knn_k=20:0.5696,knn_k=50:0.5983,knn_k=100:0.6117,lwr_k=20:0.2891,lwr_k=50:0.4135,lwr_k=100:0.471,lwr_k=200:0.5115,lwr_k=500:0.5455,lwr_k=1000:0.569'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6584,knn_k=1:1.2434,knn_k=5:0.749,knn_k=10:0.7001,knn_k=20:0.6716,knn_k=50:0.6662,knn_k=100:0.6673,lwr_k=20:0.9111,lwr_k=50:0.7553,lwr_k=100:0.7067,lwr_k=200:0.6834,lwr_k=500:0.6562,lwr_k=1000:0.6497'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0801,knn_k=1:0.0,knn_k=5:0.72,knn_k=10:0.8688,knn_k=20:0.9773,knn_k=50:1.1125,knn_k=100:1.2032,lwr_k=20:0.1717,lwr_k=50:0.4198,lwr_k=100:0.5605,lwr_k=200:0.6499,lwr_k=500:0.7498,lwr_k=1000:0.8183'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1668,knn_k=1:1.4972,knn_k=5:1.1109,knn_k=10:1.0644,knn_k=20:1.0837,knn_k=50:1.1605,knn_k=100:1.242,lwr_k=20:2.3033,lwr_k=50:1.0943,lwr_k=100:0.8866,lwr_k=200:0.8632,lwr_k=500:0.872,lwr_k=1000:0.9205'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.7672,knn_k=1:0.0,knn_k=5:0.8351,knn_k=10:1.0529,knn_k=20:1.2319,knn_k=50:1.4647,knn_k=100:1.6382,lwr_k=20:0.1401,lwr_k=50:0.3943,lwr_k=100:0.5497,lwr_k=200:0.6622,lwr_k=500:0.8225,lwr_k=1000:0.9591'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.8102,knn_k=1:1.6799,knn_k=5:1.327,knn_k=10:1.3674,knn_k=20:1.4402,knn_k=50:1.5742,knn_k=100:1.7316,lwr_k=20:2.2431,lwr_k=50:0.9816,lwr_k=100:0.8582,lwr_k=200:1.4534,lwr_k=500:0.9032,lwr_k=1000:1.0107'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0417,knn_k=1:0.0,knn_k=5:0.6201,knn_k=10:0.7754,knn_k=20:0.8959,knn_k=50:1.0224,knn_k=100:1.1208,lwr_k=20:0.2939,lwr_k=50:0.4787,lwr_k=100:0.5694,lwr_k=200:0.6347,lwr_k=500:0.6927,lwr_k=1000:0.7395'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0237,knn_k=1:1.2907,knn_k=5:0.9858,knn_k=10:0.9917,knn_k=20:1.0126,knn_k=50:1.0739,knn_k=100:1.1619,lwr_k=20:0.9507,lwr_k=50:0.7689,lwr_k=100:0.7184,lwr_k=200:0.7112,lwr_k=500:0.7181,lwr_k=1000:0.7519'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7281,knn_k=1:0.0,knn_k=5:0.4673,knn_k=10:0.5717,knn_k=20:0.6379,knn_k=50:0.6939,knn_k=100:0.7262,lwr_k=20:0.1339,lwr_k=50:0.3577,lwr_k=100:0.4782,lwr_k=200:0.5583,lwr_k=500:0.6205,lwr_k=1000:0.6551'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7415,knn_k=1:1.0032,knn_k=5:0.7115,knn_k=10:0.6846,knn_k=20:0.6937,knn_k=50:0.7018,knn_k=100:0.7273,lwr_k=20:1.5593,lwr_k=50:0.8303,lwr_k=100:0.703,lwr_k=200:0.6927,lwr_k=500:0.6738,lwr_k=1000:0.6828'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_86'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0389,knn_k=1:6.0761,knn_k=5:6.7041,knn_k=10:6.7268,knn_k=20:6.0557,knn_k=50:6.1532,knn_k=100:6.0421,lwr_k=20:6.0504,lwr_k=50:6.1475,lwr_k=100:6.0368,lwr_k=200:6.054,lwr_k=500:6.035,lwr_k=1000:6.0363'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.379,knn_k=1:6.4466,knn_k=5:6.9434,knn_k=10:7.1728,knn_k=20:6.411,knn_k=50:6.5349,knn_k=100:6.3762,lwr_k=20:6.411,lwr_k=50:6.5349,lwr_k=100:6.3762,lwr_k=200:6.3814,lwr_k=500:6.3792,lwr_k=1000:6.3766'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:271.859,knn_k=1:6.0394,knn_k=5:7.2257,knn_k=10:8.1335,knn_k=20:6.2596,knn_k=50:6.0859,knn_k=100:6.0105,lwr_k=20:6.2596,lwr_k=50:6.0859,lwr_k=100:6.0105,lwr_k=200:5.983,lwr_k=500:5.9852,lwr_k=1000:5.9788'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:270.2513,knn_k=1:6.1809,knn_k=5:7.459,knn_k=10:8.404,knn_k=20:6.431,knn_k=50:6.2359,knn_k=100:6.1448,lwr_k=20:6.431,lwr_k=50:6.2359,lwr_k=100:6.1448,lwr_k=200:6.1053,lwr_k=500:6.1091,lwr_k=1000:6.0931'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.1371,knn_k=1:6.1165,knn_k=5:7.3221,knn_k=10:7.2611,knn_k=20:6.1739,knn_k=50:6.1193,knn_k=100:6.0732,lwr_k=20:6.1739,lwr_k=50:6.1193,lwr_k=100:6.0732,lwr_k=200:6.0535,lwr_k=500:6.0573,lwr_k=1000:6.0502'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:6.2358,knn_k=1:6.2399,knn_k=5:7.4843,knn_k=10:7.422,knn_k=20:6.3015,knn_k=50:6.2429,knn_k=100:6.1918,lwr_k=20:6.3015,lwr_k=50:6.2429,lwr_k=100:6.1918,lwr_k=200:6.1679,lwr_k=500:6.1729,lwr_k=1000:6.1619'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.126,knn_k=1:6.2137,knn_k=5:7.4937,knn_k=10:7.053,knn_k=20:6.219,knn_k=50:6.1982,knn_k=100:6.1566,lwr_k=20:6.219,lwr_k=50:6.1982,lwr_k=100:6.1566,lwr_k=200:6.1342,lwr_k=500:6.141,lwr_k=1000:6.1274'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.8721,knn_k=1:5.8875,knn_k=5:6.9499,knn_k=10:6.56,knn_k=20:5.8891,knn_k=50:5.8777,knn_k=100:5.8595,lwr_k=20:5.8891,lwr_k=50:5.8777,lwr_k=100:5.8595,lwr_k=200:5.8579,lwr_k=500:5.8568,lwr_k=1000:5.8645'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.2108,knn_k=1:10.0681,knn_k=5:6.5519,knn_k=10:6.2151,knn_k=20:6.2113,knn_k=50:6.2336,knn_k=100:6.2305,lwr_k=20:6.2105,lwr_k=50:6.2325,lwr_k=100:6.2296,lwr_k=200:6.215,lwr_k=500:6.2255,lwr_k=1000:6.2104'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.9051,knn_k=1:9.7164,knn_k=5:6.2601,knn_k=10:5.9105,knn_k=20:5.905,knn_k=50:5.9238,knn_k=100:5.9211,lwr_k=20:5.905,lwr_k=50:5.9238,lwr_k=100:5.9211,lwr_k=200:5.9115,lwr_k=500:5.9233,lwr_k=1000:5.9049'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:6.1457,knn_k=1:6.7786,knn_k=5:6.9025,knn_k=10:6.3274,knn_k=20:6.1934,knn_k=50:6.1692,knn_k=100:6.1388,lwr_k=20:6.1934,lwr_k=50:6.1692,lwr_k=100:6.1388,lwr_k=200:6.1374,lwr_k=500:6.1543,lwr_k=1000:6.136'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.8899,knn_k=1:6.5761,knn_k=5:6.7044,knn_k=10:6.1035,knn_k=20:5.9577,knn_k=50:5.9085,knn_k=100:5.8856,lwr_k=20:5.9577,lwr_k=50:5.9085,lwr_k=100:5.8856,lwr_k=200:5.885,lwr_k=500:5.8964,lwr_k=1000:5.8848'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_87'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9305,knn_k=1:0.0,knn_k=5:3.0433,knn_k=10:3.505,knn_k=20:3.7017,knn_k=50:3.8871,knn_k=100:3.9411,lwr_k=20:3.4753,lwr_k=50:3.6406,lwr_k=100:3.7015,lwr_k=200:3.7007,lwr_k=500:3.6618,lwr_k=1000:3.6204'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.1066,knn_k=1:7.5567,knn_k=5:4.7721,knn_k=10:4.3993,knn_k=20:4.2885,knn_k=50:4.2141,knn_k=100:4.1976,lwr_k=20:4.2675,lwr_k=50:4.1538,lwr_k=100:4.0823,lwr_k=200:3.9759,lwr_k=500:3.87,lwr_k=1000:3.7925'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.4988,knn_k=1:0.0,knn_k=5:2.5756,knn_k=10:2.9383,knn_k=20:3.1939,knn_k=50:3.3202,knn_k=100:3.3938,lwr_k=20:3.099,lwr_k=50:3.2596,lwr_k=100:3.3404,lwr_k=200:3.3758,lwr_k=500:3.4223,lwr_k=1000:3.4441'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.6708,knn_k=1:6.3365,knn_k=5:4.2956,knn_k=10:3.8633,knn_k=20:3.7082,knn_k=50:3.6539,knn_k=100:3.6509,lwr_k=20:3.7462,lwr_k=50:3.6606,lwr_k=100:3.6281,lwr_k=200:3.632,lwr_k=500:3.6236,lwr_k=1000:3.641'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7773,knn_k=1:0.0,knn_k=5:2.706,knn_k=10:3.1502,knn_k=20:3.405,knn_k=50:3.6196,knn_k=100:3.745,lwr_k=20:2.6698,lwr_k=50:2.9724,lwr_k=100:3.1077,lwr_k=200:3.2603,lwr_k=500:3.361,lwr_k=1000:3.5026'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.677,knn_k=1:5.5874,knn_k=5:3.9407,knn_k=10:3.6775,knn_k=20:3.587,knn_k=50:3.691,knn_k=100:3.7542,lwr_k=20:3.4659,lwr_k=50:3.3819,lwr_k=100:3.385,lwr_k=200:3.3823,lwr_k=500:3.4026,lwr_k=1000:3.4829'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.6486,knn_k=1:0.0,knn_k=5:3.8939,knn_k=10:4.4686,knn_k=20:4.7717,knn_k=50:5.0124,knn_k=100:5.1703,lwr_k=20:3.7745,lwr_k=50:4.2583,lwr_k=100:4.5186,lwr_k=200:4.707,lwr_k=500:4.8419,lwr_k=1000:5.0108'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.4216,knn_k=1:9.2272,knn_k=5:5.5894,knn_k=10:5.24,knn_k=20:5.0057,knn_k=50:5.0352,knn_k=100:5.0947,lwr_k=20:4.9601,lwr_k=50:4.7351,lwr_k=100:4.7335,lwr_k=200:4.7194,lwr_k=500:4.7751,lwr_k=1000:5.1105'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.145,knn_k=1:0.0,knn_k=5:2.3716,knn_k=10:2.8052,knn_k=20:3.0584,knn_k=50:3.2252,knn_k=100:3.3187,lwr_k=20:2.9381,lwr_k=50:3.0797,lwr_k=100:3.1088,lwr_k=200:3.0942,lwr_k=500:3.0492,lwr_k=1000:3.0208'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.2112,knn_k=1:5.848,knn_k=5:3.6872,knn_k=10:3.4293,knn_k=20:3.367,knn_k=50:3.362,knn_k=100:3.4106,lwr_k=20:3.31,lwr_k=50:3.2643,lwr_k=100:3.2434,lwr_k=200:3.2241,lwr_k=500:3.1696,lwr_k=1000:3.146'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:2.3025,knn_k=1:0.0,knn_k=5:1.5255,knn_k=10:1.8302,knn_k=20:2.0153,knn_k=50:2.1754,knn_k=100:2.2495,lwr_k=20:1.6564,lwr_k=50:1.89,lwr_k=100:1.9833,lwr_k=200:2.0642,lwr_k=500:2.1334,lwr_k=1000:2.1797'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.2589,knn_k=1:3.3464,knn_k=5:2.3138,knn_k=10:2.2153,knn_k=20:2.2144,knn_k=50:2.2649,knn_k=100:2.3079,lwr_k=20:2.1189,lwr_k=50:2.0801,lwr_k=100:2.0729,lwr_k=200:2.102,lwr_k=500:2.1419,lwr_k=1000:2.1553'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_88'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8488,knn_k=1:0.0,knn_k=5:0.539,knn_k=10:0.6894,knn_k=20:0.8078,knn_k=50:0.9824,knn_k=100:1.1439,lwr_k=20:0.0518,lwr_k=50:0.1708,lwr_k=100:0.3116,lwr_k=200:0.4435,lwr_k=500:0.5807,lwr_k=1000:0.6469'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8684,knn_k=1:0.7871,knn_k=5:0.8321,knn_k=10:0.8526,knn_k=20:0.9207,knn_k=50:1.0675,knn_k=100:1.208,lwr_k=20:0.7676,lwr_k=50:0.6996,lwr_k=100:0.6592,lwr_k=200:0.6732,lwr_k=500:0.6786,lwr_k=1000:0.7216'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7185,knn_k=1:0.0,knn_k=5:0.4776,knn_k=10:0.6372,knn_k=20:0.7549,knn_k=50:0.9184,knn_k=100:1.0761,lwr_k=20:0.0417,lwr_k=50:0.1602,lwr_k=100:0.2954,lwr_k=200:0.4325,lwr_k=500:0.5665,lwr_k=1000:0.6247'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.761,knn_k=1:0.7724,knn_k=5:0.8052,knn_k=10:0.8343,knn_k=20:0.8878,knn_k=50:0.9869,knn_k=100:1.1448,lwr_k=20:0.6647,lwr_k=50:0.6983,lwr_k=100:0.6694,lwr_k=200:0.6558,lwr_k=500:0.6765,lwr_k=1000:0.7086'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8159,knn_k=1:0.0,knn_k=5:0.6005,knn_k=10:0.7778,knn_k=20:0.92,knn_k=50:1.1186,knn_k=100:1.2663,lwr_k=20:0.1459,lwr_k=50:0.2947,lwr_k=100:0.4086,lwr_k=200:0.5069,lwr_k=500:0.6031,lwr_k=1000:0.6704'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8111,knn_k=1:0.9844,knn_k=5:0.9495,knn_k=10:0.9549,knn_k=20:1.0082,knn_k=50:1.149,knn_k=100:1.2859,lwr_k=20:0.7081,lwr_k=50:0.6899,lwr_k=100:0.6702,lwr_k=200:0.6731,lwr_k=500:0.7084,lwr_k=1000:0.7306'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-da787ff6ca39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlwr_scheme\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeepLWRScheme_1_to_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlwr_models\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetup_pls_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_neighbours\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_fun_sk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mlwr_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlwr_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlwr_scheme\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogger_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"log\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mload_fun\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_fun_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mtemp_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mdeep_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlwr_scores_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlwr_preds_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlwr_scheme\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogger_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"test_log\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mload_fun\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_fun_build\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_root\\evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, original_models, data, eval, pretrain, logger_name, load_fun)\u001b[0m\n\u001b[0;32m    774\u001b[0m                 \u001b[1;31m#self.logger.info(f\"Pretraining took {end - start}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m             \u001b[1;31m# train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 776\u001b[1;33m             \u001b[0mtrained_models_fold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_scores_fold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    777\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mtrain_times\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"fold_{fold}\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mend_time\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_root\\evaluation.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, models, train_data, val_data)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mlwr_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlwr_model\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlwr_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlwr_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlwr_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m                     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlwr_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlwr_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_fun_sk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_root\\sk_models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_root\\sk_models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\lazydeep\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0m\u001b[0;32m    506\u001b[0m                                    y_numeric=True, multi_output=True)\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\lazydeep\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\lazydeep\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\lazydeep\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\lazydeep\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\lazydeep\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\lazydeep\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "for deep_name,deep_model in deep_models.items():\n",
    "    logging.getLogger().info(f\"Running model {deep_name}\")\n",
    "    temp_dict = {deep_name:deepcopy(deep_model)}\n",
    "\n",
    "    lwr_scheme = DeepLWRScheme_1_to_n(lwr_models = setup_pls_models_slim(nrow),n_neighbours=500,loss_fun_sk = mean_squared_error)\n",
    "    lwr_scores, lwr_preds, _ , _, _= eval.evaluate(temp_dict,dataset,lwr_scheme,logger_name=\"log\",load_fun=load_fun_cv)\n",
    "    temp_dict = {deep_name:deepcopy(deep_model)}\n",
    "    lwr_scores_final, lwr_preds_final, _ , _, _= eval.build(temp_dict,dataset,lwr_scheme,logger_name=\"test_log\",load_fun=load_fun_build)\n",
    "\n",
    "    #scores\n",
    "    for k,v in ut.flip_dicts(lwr_scores).items():\n",
    "        dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "        all_scores.append({**dict1,**v})\n",
    "\n",
    "    for k,v in ut.flip_dicts(lwr_scores_final).items():\n",
    "        dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "        all_scores_final.append({**dict1,**v})\n",
    "\n",
    "    lwr_preds['deep'] = deep_preds[deep_name]\n",
    "    lwr_preds_final['deep'] = deep_preds_final[deep_name]\n",
    "\n",
    "    lwr_preds.to_csv(log_dir/deep_name/ f\"predictions.csv\",index=False)\n",
    "    lwr_preds_final.to_csv(log_dir/deep_name/ f\"predictions_test.csv\",index=False)\n",
    "\n",
    "    #preds\n",
    "    # todo save predictions - appending solns\n",
    "    plot_preds_and_res(lwr_preds,name_lambda=lambda x:f\"{deep_name} with {x} predictor\",save_lambda= lambda x:f\"deep_lwr{x}\",save_loc=log_dir/deep_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save scores\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank - model_num - predictor - fold_0 - fold_1 - fold_2 - fold_3 - fold_4 - MSE - R2'\n",
      "0 - random_11 - lwr_k=100 - 0.6192908879979441 - 0.6054641038457931 - 0.6518468758484397 - 0.5920960123425377 - 0.554196401867009 - 0.6045804574149457 - 0.9005710815529029'\n",
      "1 - random_11 - lwr_k=200 - 0.613297045093904 - 0.6154407917453284 - 0.6610557434146188 - 0.5949510430485895 - 0.5631439167046788 - 0.6095786916208898 - 0.8997490751265502'\n",
      "2 - random_9 - lwr_k=100 - 0.6702036776290773 - 0.6071622074494877 - 0.5838167846288272 - 0.6276974481784297 - 0.5839543762480458 - 0.6145718497698474 - 0.898927903505309'\n",
      "3 - random_11 - lwr_k=50 - 0.6289366431774767 - 0.6309121156715998 - 0.6558725186793263 - 0.599313578300705 - 0.5672096945996918 - 0.6164516765545218 - 0.8986187483849678'\n",
      "4 - random_9 - lwr_k=200 - 0.6419346184826209 - 0.6330093546896125 - 0.6047128388762008 - 0.6281740069908682 - 0.6073310568968237 - 0.6230353395911254 - 0.8975360033390088'\n",
      "5 - random_11 - lwr_k=500 - 0.6280157553199316 - 0.6143156101270557 - 0.6961948697753824 - 0.6064316331193041 - 0.6008836380511311 - 0.629166658367751 - 0.8965276505430536'\n",
      "6 - random_9 - lwr_k=50 - 0.7085886285036479 - 0.6324230944527613 - 0.6149921631249304 - 0.6158120905380309 - 0.5827520305863239 - 0.6309217295996356 - 0.8962390126417724'\n",
      "7 - random_74 - lwr_k=100 - 0.6244483083997296 - 0.6339946237346725 - 0.6774160730572762 - 0.6074918116782293 - 0.6446735373121186 - 0.6376031497514599 - 0.8951401905226668'\n",
      "8 - random_80 - lwr_k=200 - 0.6264077346298824 - 0.6469263106970733 - 0.6579739611656106 - 0.6257932041877271 - 0.6347309424597334 - 0.638366081745237 - 0.8950147192110165'\n",
      "9 - random_74 - lwr_k=200 - 0.6295881427764868 - 0.6331702099249827 - 0.6702061453150351 - 0.634540283813589 - 0.6497617888845888 - 0.6434508353628519 - 0.8941784838571132'\n",
      "10 - random_59 - lwr_k=200 - 0.6879779341222515 - 0.5724182037289525 - 0.7299344949783261 - 0.5885140852910926 - 0.6503515582813931 - 0.6458360441971851 - 0.8937862139255275'\n",
      "11 - random_56 - lwr_k=50 - 0.6008597665381875 - 0.6514459999115895 - 0.7009860046165839 - 0.643038618981666 - 0.6341216959048606 - 0.6460863240815721 - 0.8937450530545327'\n",
      "12 - random_11 - lwr_k=1000 - 0.6383875789440628 - 0.6250725213242966 - 0.7260991011361069 - 0.6278895151417361 - 0.6217975968642327 - 0.6478459534616913 - 0.8934556655230848'\n",
      "13 - random_80 - lwr_k=500 - 0.6437144457305547 - 0.6489896451625999 - 0.6748856000708409 - 0.6291273783466842 - 0.6514453580074526 - 0.6496318120002684 - 0.893161964360878'\n",
      "14 - random_80 - lwr_k=100 - 0.6628828103499954 - 0.6711628498085943 - 0.6779409803091809 - 0.6463999165419608 - 0.6006365287873062 - 0.6518077414075948 - 0.8928041123910794'\n",
      "15 - random_56 - lwr_k=100 - 0.6143350660223169 - 0.6497821994331692 - 0.6995056312226464 - 0.6281848483212518 - 0.6769801449020634 - 0.6537531232594411 - 0.8924841761259829'\n",
      "16 - random_80 - lwr_k=50 - 0.7048384575058604 - 0.6825430850788698 - 0.6768644968967513 - 0.6494123267928087 - 0.5756464236727723 - 0.6578683137301851 - 0.8918073945120694'\n",
      "17 - random_9 - lwr_k=500 - 0.677033632295578 - 0.6774621046533894 - 0.6377953987709076 - 0.6622841233650524 - 0.6554346938161923 - 0.6620051205079379 - 0.8911270578940197'\n",
      "18 - random_65 - lwr_k=100 - 0.6846320082844167 - 0.6610679264838971 - 0.6980371004839799 - 0.6219073447159187 - 0.6455920458160558 - 0.6622494618520347 - 0.8910868736715932'\n",
      "19 - random_74 - lwr_k=50 - 0.7068038864711772 - 0.6351896620478182 - 0.7070082805504347 - 0.6081446944332061 - 0.6632458538919096 - 0.6640798957824978 - 0.890785841668718'\n",
      "20 - random_56 - lwr_k=20 - 0.6057662329235192 - 0.7343846926650699 - 0.7071842676359719 - 0.6554808802959048 - 0.6357984715900511 - 0.6677233919935203 - 0.8901866345934892'\n",
      "21 - random_56 - lwr_k=200 - 0.6328387236478401 - 0.6654392155230476 - 0.7146532780359336 - 0.64702310963984 - 0.6788103657306095 - 0.6677491171299214 - 0.8901824038538783'\n",
      "22 - random_65 - lwr_k=50 - 0.685986210244661 - 0.6611231042642206 - 0.7183333701239852 - 0.6236996885979521 - 0.6598131412778533 - 0.6697918755468489 - 0.8898464531006696'\n",
      "23 - random_59 - lwr_k=100 - 0.7028008858524413 - 0.6155657729565097 - 0.7475209901543239 - 0.6113266324345678 - 0.6729353324023586 - 0.6700276959907208 - 0.8898076702200879'\n",
      "24 - random_29 - lwr_k=50 - 0.6812010417116854 - 0.6332151245708009 - 0.7379168669576087 - 0.6591306998668954 - 0.6402235464899175 - 0.6703347605030855 - 0.8897571705852032'\n",
      "25 - random_29 - lwr_k=20 - 0.6818161189416858 - 0.6179877480887895 - 0.742288405841572 - 0.6853387513381605 - 0.6298826003374149 - 0.6714582985512009 - 0.8895723942306449'\n",
      "26 - random_65 - lwr_k=200 - 0.6829262185567532 - 0.6667391688905359 - 0.7074782729525467 - 0.6343195130605471 - 0.671114581967823 - 0.6725160267872707 - 0.8893984409160224'\n",
      "27 - random_59 - lwr_k=500 - 0.7157594340539698 - 0.5861338588587783 - 0.7758817275378921 - 0.6218196918306234 - 0.6637017173397791 - 0.6726548283919835 - 0.8893756136921747'\n",
      "28 - random_80 - lwr_k=20 - 0.7069809555864103 - 0.7072511126402186 - 0.7037576142476417 - 0.684595184411208 - 0.5713153759373332 - 0.6747866870341884 - 0.889025009572447'\n",
      "29 - random_15 - lwr_k=50 - 0.7356165365876502 - 0.6474010278271728 - 0.6720927751901036 - 0.669745221620552 - 0.6614703141791194 - 0.6772680992457988 - 0.8886169180944711'\n",
      "30 - random_80 - lwr_k=1000 - 0.686724760831185 - 0.6703047620450288 - 0.7004195302377766 - 0.6657884726111789 - 0.6661269485473013 - 0.6778730266275559 - 0.8885174321210668'\n",
      "31 - random_75 - lwr_k=50 - 0.6558838149309785 - 0.6651212196552162 - 0.7318610900657888 - 0.6540391169533023 - 0.7005327361620453 - 0.6814832873871226 - 0.887923690927098'\n",
      "32 - random_75 - lwr_k=20 - 0.663217664864008 - 0.6517992810531443 - 0.7299843929778133 - 0.6666291009061661 - 0.6991744110660612 - 0.6821559090982559 - 0.8878130719872336'\n",
      "33 - random_15 - lwr_k=100 - 0.7335290680101862 - 0.653690767773734 - 0.6878196791794378 - 0.6588375680619273 - 0.6783839647267246 - 0.6824545001905871 - 0.8877639658856316'\n",
      "34 - random_48 - lwr_k=200 - 0.6834946918824266 - 0.6225565913111457 - 0.6955104805523292 - 0.7128802106633919 - 0.7030601235531445 - 0.6834941632225439 - 0.8875929835630159'\n",
      "35 - random_29 - lwr_k=100 - 0.6826595516748646 - 0.6529171632243885 - 0.7491932430598629 - 0.6650951931830996 - 0.668132161329919 - 0.6835962165274704 - 0.8875761999412358'\n",
      "36 - random_74 - lwr_k=500 - 0.6901148352848695 - 0.6650121302302638 - 0.721596391210635 - 0.6493844084377468 - 0.6941937992875195 - 0.6840589791127214 - 0.8875000943000677'\n",
      "37 - random_48 - lwr_k=100 - 0.6825414410306313 - 0.6511578994084449 - 0.6794652519620515 - 0.7188861521102345 - 0.6925379210096797 - 0.6849140237913599 - 0.8873594741947066'\n",
      "38 - random_15 - lwr_k=20 - 0.8072893635829799 - 0.6428993517908373 - 0.671436774065627 - 0.6659935101065596 - 0.6435785121932244 - 0.6862474791196254 - 0.887140174977438'\n",
      "39 - random_9 - lwr_k=20 - 0.7955796481056037 - 0.6986622146358727 - 0.6345071232016253 - 0.7125317497617281 - 0.590592965657411 - 0.6863872112622035 - 0.8871171947179235'\n",
      "40 - random_74 - lwr_k=20 - 0.702795330986803 - 0.6170388319717879 - 0.7431118853364576 - 0.6683864932485014 - 0.7024475132840272 - 0.6867505010231039 - 0.887057448314337'\n",
      "41 - random_4 - lwr_k=20 - 0.6397533578714008 - 0.6642690693471822 - 0.6908028404296458 - 0.8131455070530282 - 0.632505089459742 - 0.6880877649161204 - 0.8868375227429258'\n",
      "42 - random_65 - lwr_k=500 - 0.688393100348282 - 0.6882712217788801 - 0.7350612570103584 - 0.6477388596382525 - 0.6840331517160753 - 0.6886994426811998 - 0.8867369266057632'\n",
      "43 - random_29 - lwr_k=200 - 0.6957777381970844 - 0.6562557619076239 - 0.7470289026234725 - 0.6704540690870937 - 0.6786866503361542 - 0.689637827494466 - 0.8865826004347368'\n",
      "44 - random_56 - lwr_k=500 - 0.6504940794762958 - 0.6839659115815532 - 0.7533585885691518 - 0.6607629624404826 - 0.7043821109409034 - 0.6905879343103466 - 0.8864263464705975'\n",
      "45 - random_4 - lwr_k=50 - 0.6446772716552819 - 0.6582408859201804 - 0.6972053965945934 - 0.809188425000271 - 0.6443924978512403 - 0.6907328309788121 - 0.8864025168564321'\n",
      "46 - random_11 - lr - 0.6802378715188073 - 0.6493820548521865 - 0.7801003902764015 - 0.6752456253499941 - 0.6795420293681265 - 0.6928958271552449 - 0.8860467918775807'\n",
      "47 - random_4 - lwr_k=100 - 0.6567216263173029 - 0.6645310658009597 - 0.6997238922489035 - 0.7944789980466002 - 0.659564289972992 - 0.6949969168652765 - 0.8857012479969167'\n",
      "48 - random_15 - lwr_k=200 - 0.7415051793149506 - 0.6762032025748782 - 0.7021114704539896 - 0.6664787609951585 - 0.6889198722061378 - 0.6950465323571928 - 0.8856930882645949'\n",
      "49 - random_0 - lwr_k=100 - 0.7289350630689877 - 0.703603531671449 - 0.6897515358056516 - 0.6660274588833212 - 0.690241476335364 - 0.6957160335356724 - 0.8855829825255509'\n",
      "50 - random_0 - lwr_k=50 - 0.7328845908669207 - 0.6985707845961135 - 0.6990806597348355 - 0.6751853015322331 - 0.6783868630304212 - 0.6968255213004478 - 0.8854005168716764'\n",
      "51 - random_9 - lwr_k=1000 - 0.7145010889114431 - 0.7083598107827289 - 0.6778206045607955 - 0.6759531664117374 - 0.7078529215109145 - 0.6969005019977106 - 0.8853881855937765'\n",
      "52 - random_36 - lwr_k=20 - 0.7679242832134396 - 0.6603646270530941 - 0.7473796933333052 - 0.6634931262420918 - 0.6506061555018335 - 0.6979569010018394 - 0.8852144508837956'\n",
      "53 - random_36 - lwr_k=50 - 0.7383512389613258 - 0.6785227215152237 - 0.7278902728575662 - 0.6765456611242648 - 0.6704056469733705 - 0.6983451805244844 - 0.8851505946798475'\n",
      "54 - random_75 - lwr_k=100 - 0.6836590338307452 - 0.6746516494040589 - 0.7523148804892512 - 0.671920266410138 - 0.7117110922976149 - 0.69884734095467 - 0.8850680096940976'\n",
      "55 - random_48 - lwr_k=50 - 0.6965202708767623 - 0.6601844070358692 - 0.7269584014397589 - 0.731955987090108 - 0.6894085288902043 - 0.7010008684444691 - 0.8847138419294425'\n",
      "56 - random_39 - lwr_k=500 - 0.7377481674961921 - 0.6340106519011783 - 0.7689951265897262 - 0.6951300803027366 - 0.6702457857681101 - 0.7012228118156715 - 0.8846773412634277'\n",
      "57 - random_17 - lwr_k=50 - 0.7369330692829617 - 0.6593230012055409 - 0.7780600306790596 - 0.6511662251476573 - 0.6842525675247224 - 0.7019461947516624 - 0.8845583741647289'\n",
      "58 - random_36 - lwr_k=100 - 0.7416461158148684 - 0.682822572013243 - 0.7259805657216061 - 0.6756508076765186 - 0.6865989945467293 - 0.7025418014097273 - 0.8844604210716294'\n",
      "59 - random_4 - lwr_k=200 - 0.670955457426618 - 0.6683525759987595 - 0.7093432471191332 - 0.7855850856051746 - 0.684415780508731 - 0.7037234335582037 - 0.884266090598184'\n",
      "60 - random_39 - lwr_k=1000 - 0.7450413016681867 - 0.6345455225822278 - 0.7874749137308757 - 0.6824933233814918 - 0.6692556373882778 - 0.7037592720171746 - 0.8842601966279595'\n",
      "61 - random_48 - lwr_k=500 - 0.6893131246319496 - 0.6429469805858791 - 0.7349148371867937 - 0.7389430810733958 - 0.7139822561883539 - 0.7040122772423846 - 0.884218587549142'\n",
      "62 - random_17 - lwr_k=100 - 0.7340718751470908 - 0.6621891386849511 - 0.7819510424220258 - 0.6603173539479185 - 0.685649404055584 - 0.7048343862849086 - 0.8840833840176001'\n",
      "63 - random_0 - lwr_k=20 - 0.7389780430362076 - 0.6873628975489057 - 0.7313865912970692 - 0.691130899617053 - 0.6789313323853927 - 0.7055595156012976 - 0.8839641297102889'\n",
      "64 - random_0 - lwr_k=200 - 0.725363298845763 - 0.7222759830573572 - 0.693223410040775 - 0.6798094241631388 - 0.7207281715341008 - 0.7082832477527031 - 0.8835161864487555'\n",
      "65 - random_17 - lwr_k=200 - 0.7217312657986126 - 0.6580140468977823 - 0.7977845853057005 - 0.672035512190987 - 0.6920619910675324 - 0.7083216919491248 - 0.8835098639406032'\n",
      "66 - random_29 - lwr_k=500 - 0.7112089003556549 - 0.6609816955380361 - 0.7785478128223925 - 0.6911068516702539 - 0.7031560115881832 - 0.708995552083993 - 0.883399041330357'\n",
      "67 - random_65 - lwr_k=1000 - 0.7090251423017808 - 0.7087587454948838 - 0.7639644385943407 - 0.6702889724921817 - 0.6963116872675881 - 0.709669637539469 - 0.8832881816640266'\n",
      "68 - random_65 - lwr_k=20 - 0.7138832343476238 - 0.6815750019797873 - 0.8267015174024025 - 0.6762340287381057 - 0.650041846430676 - 0.7096846708407709 - 0.8832857092968324'\n",
      "69 - random_82 - lr - 0.7328781044408059 - 0.6356513691977396 - 0.8168680503940534 - 0.7000785337964966 - 0.6640527266862954 - 0.7099004928874585 - 0.8832502153399636'\n",
      "70 - random_32 - lwr_k=200 - 0.6581265261876671 - 0.6422427416203841 - 0.844825433328959 - 0.7597580122886387 - 0.6449894408711945 - 0.7099761533399773 - 0.8832377722699456'\n",
      "71 - random_75 - lwr_k=200 - 0.700679279019107 - 0.6810712606878047 - 0.7602010671012516 - 0.683040301694643 - 0.7287793555733756 - 0.710750171726556 - 0.883110477697169'\n",
      "72 - random_56 - lwr_k=1000 - 0.6827732879538329 - 0.7054427491902998 - 0.7623881399764719 - 0.677175234935383 - 0.7269694350600906 - 0.7109463118681241 - 0.8830782206139289'\n",
      "73 - random_59 - lwr_k=1000 - 0.7511774430815279 - 0.6019118452516082 - 0.8486103102863647 - 0.6624908324036378 - 0.6938259399684029 - 0.7115960767788807 - 0.8829713606889528'\n",
      "74 - random_84 - lwr_k=200 - 0.711088515786956 - 0.6937343858231313 - 0.731962403519422 - 0.683832505399469 - 0.7386246757524878 - 0.7118465598622363 - 0.8829301663999845'\n",
      "75 - random_74 - lwr_k=1000 - 0.728107595075397 - 0.6819511837816735 - 0.7772263113230666 - 0.6660607206084519 - 0.7230268540936607 - 0.7152724296827632 - 0.8823667500228624'\n",
      "76 - random_36 - lwr_k=200 - 0.7579496788014058 - 0.6939575763989437 - 0.727058173709406 - 0.6803338909076051 - 0.7226522765826568 - 0.7163922825951995 - 0.8821825797233799'\n",
      "77 - random_17 - lwr_k=20 - 0.7356747464341249 - 0.6760028245317274 - 0.8075229865623876 - 0.6664812568440378 - 0.6985736187988129 - 0.7168488258456427 - 0.8821074969100684'\n",
      "78 - random_15 - lwr_k=500 - 0.7644768781152999 - 0.7020394321443927 - 0.7354537877730244 - 0.6757956661780424 - 0.7102892403585407 - 0.7176142132222598 - 0.8819816217877141'\n",
      "79 - random_39 - lwr_k=200 - 0.7622625175489073 - 0.6509398199988017 - 0.7811939851327817 - 0.7292257804170348 - 0.6843668914256753 - 0.721594720146658 - 0.8813269901443819'\n",
      "80 - random_18 - lr - 0.7376044303242324 - 0.7299205644091168 - 0.7619022971780125 - 0.6970668151431775 - 0.688584857879265 - 0.723017999249208 - 0.8810929185661837'\n",
      "81 - random_32 - lwr_k=500 - 0.6808160690094536 - 0.6349212558321775 - 0.8631320177128031 - 0.8115842229630531 - 0.6277272544717946 - 0.7236226621498628 - 0.8809934760891737'\n",
      "82 - random_29 - lwr_k=1000 - 0.7331208350648325 - 0.6743810563685009 - 0.7883832371037264 - 0.7060189603389286 - 0.7235499616182912 - 0.7250864290961087 - 0.880752745905889'\n",
      "83 - random_11 - lwr_k=20 - 0.7494472504809878 - 0.7600776258659614 - 0.8039413282160627 - 0.6963732384893623 - 0.6174092031053361 - 0.7254557470325976 - 0.8806920081123698'\n",
      "84 - random_8 - lwr_k=1000 - 0.717666204023598 - 0.6767283199505936 - 0.7791011449337631 - 0.732983696990434 - 0.7214372886749817 - 0.7255775033497126 - 0.880671984145706'\n",
      "85 - random_48 - lwr_k=1000 - 0.7040606308175427 - 0.6544291914754401 - 0.772961030653649 - 0.7696882054225664 - 0.7307615699637777 - 0.7263704489647844 - 0.88054157681294'\n",
      "86 - random_4 - lwr_k=500 - 0.706185649856591 - 0.6848209931092767 - 0.734761314512179 - 0.7917249859088656 - 0.7149490602768506 - 0.7264820395996692 - 0.8805232246879261'\n",
      "87 - random_79 - lwr_k=100 - 0.6861487232788812 - 0.6758766822244848 - 0.8138877268783934 - 0.78669455650257 - 0.673925831794843 - 0.7272972001322655 - 0.8803891639039183'\n",
      "88 - random_79 - lwr_k=50 - 0.6811824838645908 - 0.6830757070736861 - 0.8252164823828912 - 0.7818184077050583 - 0.6794000685297642 - 0.7301287737144332 - 0.8799234851091023'\n",
      "89 - random_37 - lwr_k=200 - 0.6845192210836274 - 0.6674974511183283 - 0.7680652000842749 - 0.8696298769248868 - 0.6619814856074298 - 0.7303274931326966 - 0.8798908038396533'\n",
      "90 - random_17 - lwr_k=500 - 0.7445097463335579 - 0.6543078629857855 - 0.8456268113545424 - 0.7005557788493685 - 0.7075477333128729 - 0.7305032016807734 - 0.8798619069233159'\n",
      "91 - random_8 - lwr_k=500 - 0.6809408796140792 - 0.6800385132674187 - 0.776245653826205 - 0.8333135766003348 - 0.6844934388172786 - 0.7309960415123177 - 0.8797808547973051'\n",
      "92 - random_75 - lwr_k=500 - 0.7260861191383916 - 0.6891244025375465 - 0.7900434787192975 - 0.717480493505336 - 0.7490691667191883 - 0.7343552393152297 - 0.8792284032578994'\n",
      "93 - random_79 - lwr_k=200 - 0.7046308808176892 - 0.6783573759094293 - 0.8160380346091344 - 0.786720466909845 - 0.6955596355388182 - 0.7362520882108134 - 0.8789164486919979'\n",
      "94 - random_0 - lwr_k=500 - 0.7560505687904489 - 0.7402830445718885 - 0.71707457658799 - 0.7187445322800194 - 0.7492215493264809 - 0.7362772956893926 - 0.8789123030860638'\n",
      "95 - random_84 - lwr_k=100 - 0.7753388986627626 - 0.6853777946977638 - 0.7778495540315661 - 0.682321369448152 - 0.7606146738119625 - 0.736299238234845 - 0.8789086944289602'\n",
      "96 - random_15 - lwr_k=1000 - 0.791574205331644 - 0.7185567751415837 - 0.75082202161268 - 0.6957448457370496 - 0.7259246614852594 - 0.7365283082645123 - 0.8788710217172159'\n",
      "97 - random_37 - lwr_k=100 - 0.6659304158766498 - 0.7019657101653705 - 0.7498961843840549 - 0.885856365828604 - 0.6812977065625202 - 0.7369783873797933 - 0.8787970019914719'\n",
      "98 - random_84 - lwr_k=500 - 0.7527085423672775 - 0.6712783608744475 - 0.7656972079055948 - 0.7347772511938404 - 0.7761463175260879 - 0.740115761371858 - 0.878281031455261'\n",
      "99 - random_37 - lwr_k=500 - 0.7058553872228549 - 0.669539798998868 - 0.769410748612649 - 0.877230710521437 - 0.6791460285212835 - 0.7402257487065077 - 0.8782629430079866'\n",
      "100 - random_76 - lwr_k=20 - 0.7806088114179331 - 0.7076762684817133 - 0.8186292914103045 - 0.6733715915010882 - 0.7290480326002108 - 0.7418672662842346 - 0.8779929800686234'\n",
      "101 - random_36 - lwr_k=500 - 0.7867774999081806 - 0.7098598144885515 - 0.7586694204314283 - 0.7151991696766391 - 0.73913254707984 - 0.7419290023610423 - 0.8779828269926003'\n",
      "102 - random_48 - lwr_k=20 - 0.7235046471046377 - 0.6671837532727396 - 0.7827288474718249 - 0.8317621161901654 - 0.7077139102088497 - 0.7425689577741639 - 0.8778775803313816'\n",
      "103 - random_4 - lwr_k=1000 - 0.7242625679973204 - 0.6947954344429822 - 0.7445771137200435 - 0.8208573828835597 - 0.7292295112199605 - 0.7427375830421322 - 0.8778498483267967'\n",
      "104 - random_79 - lwr_k=20 - 0.7027754636802984 - 0.6721390647829479 - 0.8765703082715862 - 0.8089444001955631 - 0.6537550959969356 - 0.7428254973384217 - 0.8778353899974066'\n",
      "105 - random_76 - lwr_k=50 - 0.7827415154536956 - 0.7265747508410747 - 0.7814412120732065 - 0.6822068913043249 - 0.7425873267586328 - 0.7431127100096239 - 0.8777881551837244'\n",
      "106 - random_75 - lwr_k=1000 - 0.7436628045234872 - 0.6890563029367424 - 0.8010849428569675 - 0.7441110865540049 - 0.7615610453265934 - 0.7478887622694278 - 0.8770026886592694'\n",
      "107 - random_32 - lwr_k=1000 - 0.7152683329151891 - 0.6320766417382729 - 0.9028975555863995 - 0.8438066055916912 - 0.6493874538797118 - 0.7486719176485523 - 0.8768738914224958'\n",
      "108 - random_76 - lwr_k=100 - 0.7915802147540514 - 0.7403359323801338 - 0.7696561525190787 - 0.6890537115946865 - 0.7574161143246434 - 0.7496117816426349 - 0.8767193219863308'\n",
      "109 - random_51 - lwr_k=50 - 0.7399733465825766 - 0.7637874966811515 - 0.7786469223631938 - 0.7313346832446573 - 0.745235932658891 - 0.7517956937040258 - 0.8763601571943094'\n",
      "110 - random_51 - lwr_k=200 - 0.7555736279666411 - 0.7548984617088599 - 0.7759953975173042 - 0.7103893939329344 - 0.7652907091963062 - 0.7524300942349642 - 0.8762558240854901'\n",
      "111 - random_39 - lwr_k=100 - 0.7791000431392554 - 0.6691793267908372 - 0.8605707004429906 - 0.7564476299322751 - 0.6979322652920649 - 0.7526401408698122 - 0.8762212799491882'\n",
      "112 - random_51 - lwr_k=100 - 0.7459447868369602 - 0.7651231774717058 - 0.7740472941568931 - 0.7248948204502678 - 0.7538356931382967 - 0.7527697220207084 - 0.8761999691153254'\n",
      "113 - random_37 - lwr_k=50 - 0.658419782322617 - 0.7565840929625313 - 0.7571850145000691 - 0.9212010955521174 - 0.6762358541570085 - 0.7539156373650449 - 0.876011512604828'\n",
      "114 - random_8 - lwr_k=200 - 0.6626906496988508 - 0.7506757828996895 - 0.8361949323226089 - 0.7926937856862832 - 0.736137801315291 - 0.7556685317982 - 0.8757232326984847'\n",
      "115 - random_76 - lwr_k=200 - 0.8019861375936908 - 0.7428900949227295 - 0.7588419422961725 - 0.6980568050714864 - 0.780819506566998 - 0.7565221654525985 - 0.8755828446492748'\n",
      "116 - random_2 - lwr_k=200 - 0.7046579058433545 - 0.6953981989629286 - 0.9610718290258519 - 0.732796513358782 - 0.7021157453546836 - 0.7591958890560088 - 0.8751431257618165'\n",
      "117 - random_51 - lwr_k=20 - 0.7476874477492085 - 0.7522439779627312 - 0.80566316651237 - 0.7332635394902921 - 0.7605945423450727 - 0.7598884972791992 - 0.8750292198528596'\n",
      "118 - random_0 - lwr_k=1000 - 0.7910822742158633 - 0.7523597997574704 - 0.7355013890042523 - 0.7486438971180309 - 0.7744948293213357 - 0.7604187586797575 - 0.8749420133993511'\n",
      "119 - random_51 - lwr_k=500 - 0.7742986734629724 - 0.7532853994512567 - 0.7833315059100885 - 0.7232706199267167 - 0.7744831320228555 - 0.7617342886902537 - 0.87472566216847'\n",
      "120 - random_17 - lwr_k=1000 - 0.7736998197388778 - 0.6672189352890326 - 0.8937771646658509 - 0.7510114276533327 - 0.7340796964621151 - 0.7639484787615857 - 0.8743615178741437'\n",
      "121 - random_36 - lwr_k=1000 - 0.8131957381241618 - 0.7193939510817365 - 0.7768342577700037 - 0.7448908449463895 - 0.7755599371896685 - 0.7659750114965411 - 0.8740282355862977'\n",
      "122 - random_79 - lwr_k=500 - 0.7437636118519921 - 0.6913222210411429 - 0.8556151445886861 - 0.8146721209260636 - 0.7274830777719913 - 0.7665611698861929 - 0.873931836349427'\n",
      "123 - random_18 - lwr_k=500 - 0.7220108479566727 - 0.7271883200278173 - 0.7962867826804507 - 0.8110201014205417 - 0.7793303282014958 - 0.7671585370526605 - 0.8738335937242325'\n",
      "124 - random_18 - lwr_k=1000 - 0.733022409645742 - 0.7298605419548251 - 0.7764927757662706 - 0.8195639912692826 - 0.7791155956506535 - 0.7676036373621674 - 0.8737603928097274'\n",
      "125 - random_2 - lwr_k=500 - 0.7498651194470215 - 0.6878041000484133 - 0.9341237665236181 - 0.7469488904972257 - 0.7212253259776117 - 0.7679833483553267 - 0.8736979457807021'\n",
      "126 - random_11 - knn_k=10 - 0.8517961855693861 - 0.6455940896735963 - 0.8875471365405248 - 0.8092993069530316 - 0.647997460287567 - 0.7684427808472799 - 0.8736223878045649'\n",
      "127 - random_51 - lwr_k=1000 - 0.80168034011917 - 0.7519238650516517 - 0.7811697049456843 - 0.7330618075705955 - 0.7777324651582994 - 0.7691152149854251 - 0.8735117997128351'\n",
      "128 - random_37 - lwr_k=1000 - 0.7354143796160805 - 0.6885576601068344 - 0.7965282202130765 - 0.921484632764836 - 0.7070298566913971 - 0.7697910802561873 - 0.873400647339212'\n",
      "129 - random_2 - lwr_k=100 - 0.6947184800662817 - 0.7240340232662881 - 0.9933558576750503 - 0.7422487796303356 - 0.6950218089527416 - 0.7698633695653881 - 0.8733887586852851'\n",
      "130 - random_31 - lwr_k=100 - 0.7585957823252748 - 0.7406660593670662 - 0.8487552192319072 - 0.7454626688652638 - 0.7624817869643941 - 0.7711878768711047 - 0.8731709310541278'\n",
      "131 - random_18 - lwr_k=200 - 0.7260650571288797 - 0.722391639914607 - 0.839542469357043 - 0.7975149494672701 - 0.7809486790321072 - 0.7732824862617597 - 0.872826452922677'\n",
      "132 - random_11 - knn_k=5 - 0.8420881070667785 - 0.6717999703766717 - 0.9047987761919094 - 0.8035291362493664 - 0.645647244794272 - 0.7735692331381782 - 0.8727792947133094'\n",
      "133 - random_84 - lwr_k=50 - 0.765306792153962 - 0.7152793071644095 - 0.8462651293487681 - 0.7301745645379192 - 0.8152554612117716 - 0.7744492372924763 - 0.8726345697884169'\n",
      "134 - random_23 - lwr_k=100 - 0.65348434644048 - 0.6729147619378499 - 0.8214962425201469 - 1.0791745507573514 - 0.6459440389825877 - 0.7745799174165482 - 0.8726130782181228'\n",
      "135 - random_54 - lwr_k=100 - 0.8820485202343371 - 0.6949067360239132 - 0.803362207660946 - 0.8056638126433764 - 0.6924878360783571 - 0.7756964470006968 - 0.872429454471102'\n",
      "136 - random_9 - lr - 0.8309416439290582 - 0.7588090779693716 - 0.7750724565702082 - 0.7544510513515961 - 0.7602608907184399 - 0.775910918243814 - 0.8723941826665313'\n",
      "137 - random_41 - lwr_k=200 - 0.907914681469477 - 0.7310774100430593 - 0.8547852829121946 - 0.703975001779807 - 0.6904193346310732 - 0.7776429362347858 - 0.8721093360866244'\n",
      "138 - random_84 - lwr_k=1000 - 0.7976993089846548 - 0.6834178572885139 - 0.8168180025199595 - 0.779614960860519 - 0.814912855577445 - 0.7784848093201028 - 0.8719708821731442'\n",
      "139 - random_23 - lwr_k=50 - 0.6517099069368748 - 0.6578794482891339 - 0.8178207602665029 - 1.13740335209152 - 0.6295288477922393 - 0.7788429911422914 - 0.8719119758179175'\n",
      "140 - random_31 - lwr_k=200 - 0.7425525304498892 - 0.7433086419351495 - 0.8978042751827384 - 0.7430154663268015 - 0.7712193105427158 - 0.7795725208762302 - 0.871791997820728'\n",
      "141 - random_76 - lwr_k=500 - 0.8385138483800584 - 0.7595330253104745 - 0.7882702250060262 - 0.7210280547937497 - 0.794516487617706 - 0.7803761572317904 - 0.871659832295564'\n",
      "142 - random_54 - lwr_k=50 - 0.8716188206968467 - 0.7032010982826978 - 0.8194490500320737 - 0.8290924368260985 - 0.6937188479980099 - 0.7834168707032412 - 0.8711597584872465'\n",
      "143 - random_23 - lwr_k=200 - 0.6810573363425697 - 0.6739783630000219 - 0.8458306615075138 - 1.0597250405438807 - 0.663410101661448 - 0.7847782758829119 - 0.8709358626551487'\n",
      "144 - random_66 - lwr_k=50 - 0.8032343808358016 - 0.705421688199376 - 0.9257521938590584 - 0.7941007470468252 - 0.6960501587404527 - 0.7849055549846669 - 0.870914930414827'\n",
      "145 - random_84 - lwr_k=20 - 0.7990697658515643 - 0.6846697707188135 - 0.8786366240345918 - 0.767731537332737 - 0.794525471738687 - 0.7849177945048437 - 0.8709129175111041'\n",
      "146 - random_39 - lr - 0.7459277227734881 - 0.6527141787129163 - 1.0279011269145004 - 0.7736696554494535 - 0.7343712408442239 - 0.7868988018072812 - 0.8705871223070062'\n",
      "147 - random_75 - knn_k=10 - 0.7814268763058936 - 0.7007326530876098 - 0.8568575324356607 - 0.8231185176410464 - 0.7774455860251368 - 0.7879066177288369 - 0.8704213775399614'\n",
      "148 - random_41 - lwr_k=500 - 0.9258406246588536 - 0.7341301424573368 - 0.8732727681079722 - 0.7282394111491912 - 0.6824312428606576 - 0.7887912965915592 - 0.8702758838154874'\n",
      "149 - random_29 - knn_k=5 - 0.798177031051406 - 0.680996479108493 - 0.8902318926006927 - 0.7953536672034083 - 0.782024152709851 - 0.7893464269430119 - 0.870184587430093'\n",
      "150 - random_29 - lr - 0.8118398887128925 - 0.6835217742771432 - 0.8757827355142971 - 0.7844845433371754 - 0.7918604213454581 - 0.7894892877387806 - 0.8701610926342597'\n",
      "151 - random_54 - lwr_k=200 - 0.8738020943383787 - 0.6986563881685293 - 0.8259001387605439 - 0.8453252011962511 - 0.7113497342873903 - 0.7910057305515948 - 0.8699116994113797'\n",
      "152 - random_66 - lwr_k=100 - 0.8275177873037795 - 0.6998690541217375 - 0.9164534002155001 - 0.8007878341682915 - 0.7111710186405562 - 0.791154180130339 - 0.8698872854878441'\n",
      "153 - random_51 - lr - 0.8305186678274112 - 0.7616325518473968 - 0.7794288966573817 - 0.7868309848572348 - 0.7988013994998702 - 0.7914434512997763 - 0.869839712134848'\n",
      "154 - random_41 - lwr_k=100 - 0.919252198398831 - 0.7353151932607783 - 0.9044607232449214 - 0.7005484804868839 - 0.6990444329272021 - 0.7917315059080603 - 0.8697923388567275'\n",
      "155 - random_18 - lwr_k=100 - 0.7369886410616714 - 0.7237534469549537 - 0.8858831420066072 - 0.8114428091738606 - 0.8032130714548529 - 0.7922435173104092 - 0.8697081337863456'\n",
      "156 - random_2 - lwr_k=1000 - 0.7756095462066003 - 0.6938299555724371 - 0.9321476651947235 - 0.8038440226326674 - 0.7610201600969866 - 0.7932782456091184 - 0.8695379630268288'\n",
      "157 - random_4 - lr - 0.7916495088544485 - 0.710422862354831 - 0.8227492401539737 - 0.8613159895907679 - 0.7807012912433937 - 0.7933590879051297 - 0.8695246677541177'\n",
      "158 - random_75 - knn_k=5 - 0.7698393530224341 - 0.7084720847487769 - 0.8717409426401006 - 0.8115738728580593 - 0.8061487488046052 - 0.7935438324243356 - 0.8694942847877013'\n",
      "159 - random_80 - knn_k=5 - 0.8573653082262576 - 0.7833703660601927 - 0.8388292045077678 - 0.7856438915902647 - 0.7048977944415292 - 0.7940267218184519 - 0.8694148691043166'\n",
      "160 - random_29 - knn_k=10 - 0.8235650930688981 - 0.6902329886630676 - 0.8822710936634268 - 0.8136140013794845 - 0.7606360016259938 - 0.7940562058721647 - 0.8694100201755495'\n",
      "161 - random_37 - lwr_k=20 - 0.6841916533825285 - 0.7798170049382943 - 0.7839916641553347 - 1.0364820561799708 - 0.6961273534228702 - 0.7961087832835363 - 0.8690724545967442'\n",
      "162 - random_82 - lwr_k=500 - 0.7782691921750464 - 0.6329852689181109 - 1.035167732965559 - 0.8536064419704261 - 0.6853268870118828 - 0.797052331486862 - 0.8689172792578645'\n",
      "163 - random_80 - lr - 0.8767747188063522 - 0.7135012515471948 - 0.8825503598594487 - 0.7799358073063829 - 0.7342054352882885 - 0.7973930515088985 - 0.8688612446592121'\n",
      "164 - random_11 - knn_k=20 - 0.8874772800764961 - 0.6474901831161106 - 0.9271017011502249 - 0.8397454113362621 - 0.6896239650707996 - 0.7982813841966726 - 0.8687151500289882'\n",
      "165 - random_80 - knn_k=1 - 0.844404574809862 - 0.7857584989832277 - 0.8457842586731907 - 0.822391981875835 - 0.699604168443001 - 0.7995918771853008 - 0.8684996271835279'\n",
      "166 - random_82 - lwr_k=200 - 0.7570882354145845 - 0.6388008712152252 - 1.0317264935093444 - 0.8736257856022244 - 0.69744664817618 - 0.7997167090102683 - 0.868479097420794'\n",
      "167 - random_79 - lwr_k=1000 - 0.7822592831329237 - 0.7058784595322223 - 0.8965374777656562 - 0.8463079311060323 - 0.7710449127767615 - 0.8003940471182047 - 0.8683677028253036'\n",
      "168 - random_31 - lwr_k=50 - 0.7779707302756484 - 0.7492490047917314 - 0.9233855792852355 - 0.7630836774520942 - 0.7902895650619953 - 0.8007880772440369 - 0.8683029008808038'\n",
      "169 - random_82 - lwr_k=1000 - 0.7924280765898114 - 0.6324459484957662 - 1.0449798162919612 - 0.8537552288142184 - 0.683331056589466 - 0.8013697640109739 - 0.8682072370441677'\n",
      "170 - random_76 - lwr_k=1000 - 0.8733859210520769 - 0.7689105317069858 - 0.8246667489910164 - 0.7406638308854829 - 0.8010118434879323 - 0.8017317621783335 - 0.8681477030552354'\n",
      "171 - random_56 - knn_k=5 - 0.6970155590038949 - 0.737627606438891 - 0.9168454350806696 - 0.845129987973956 - 0.816309468419896 - 0.8025681069636992 - 0.8680101583224576'\n",
      "172 - random_41 - lwr_k=1000 - 0.9440136503235398 - 0.7400047304107343 - 0.8983166630102154 - 0.7591208746557501 - 0.6766941822979574 - 0.8036378992548575 - 0.8678342209609893'\n",
      "173 - random_39 - lwr_k=50 - 0.8113948504075006 - 0.6989855718416276 - 0.9659069277352484 - 0.8177225101392717 - 0.7304828441110571 - 0.8048883358931899 - 0.8676285749447955'\n",
      "174 - random_56 - lr - 0.7642716352251973 - 0.7292551514952278 - 0.926658002311523 - 0.7797889259124069 - 0.8384407710660157 - 0.8076703906317924 - 0.8671710399875747'\n",
      "175 - random_80 - knn_k=10 - 0.8945761465203431 - 0.7893027687359061 - 0.8519964995972895 - 0.7882683632650783 - 0.718824275111216 - 0.8086004564367657 - 0.8670180819553741'\n",
      "176 - random_18 - lwr_k=50 - 0.74859995452327 - 0.7273032446964204 - 0.9230857229673484 - 0.8206932042873035 - 0.8244072931689648 - 0.8088033353176332 - 0.8669847166233443'\n",
      "177 - random_56 - knn_k=10 - 0.6887722694169106 - 0.7323980005700503 - 0.9268630210686419 - 0.8739409200639952 - 0.8287851258890405 - 0.8101314266847479 - 0.8667662995597234'\n",
      "178 - random_31 - lwr_k=500 - 0.7891393004015098 - 0.7622480190262914 - 0.9508472905388344 - 0.7617175405653569 - 0.7987329445469714 - 0.8125294551974184 - 0.8663719213119718'\n",
      "179 - random_57 - lwr_k=200 - 0.7393794510825115 - 0.7479990254253696 - 1.0597714322864413 - 0.7437214731332701 - 0.7729233765079742 - 0.8127447719060757 - 0.8663365104626749'\n",
      "180 - random_66 - lwr_k=20 - 0.8609010400320702 - 0.7020335480048784 - 0.9498833611768701 - 0.8485003278666842 - 0.7058072478197246 - 0.8134185441483968 - 0.8662257023071813'\n",
      "181 - random_82 - lwr_k=100 - 0.7699236581049405 - 0.6392042934144305 - 1.0550106918136255 - 0.8938037934427736 - 0.7100170408981615 - 0.8135695124677005 - 0.8662008741531713'\n",
      "182 - random_85 - lwr_k=500 - 0.9223739004443858 - 0.6561513594152838 - 0.8719812403619088 - 0.9032016735583172 - 0.7181188104396529 - 0.8143602433298646 - 0.8660708310572633'\n",
      "183 - random_75 - lr - 0.8124493331402256 - 0.702360615238693 - 0.8751932959223991 - 0.8798745211052115 - 0.8023739544957481 - 0.8144386327569304 - 0.8660579391818226'\n",
      "184 - random_74 - knn_k=5 - 0.803967758793716 - 0.769333295513936 - 0.8863978967831401 - 0.821599477186232 - 0.7930172973778299 - 0.8148573531749089 - 0.8659890766875413'\n",
      "185 - random_74 - knn_k=1 - 0.7838806118467156 - 0.7654992869159178 - 0.8728608649605856 - 0.8365927420698412 - 0.8204096128661936 - 0.8158401739937374 - 0.8658274425992328'\n",
      "186 - random_66 - lwr_k=200 - 0.8758225175957893 - 0.6951510111039757 - 0.9441851549778207 - 0.8362846023817833 - 0.7286227720927001 - 0.8160069446529389 - 0.8658000156024291'\n",
      "187 - random_29 - knn_k=20 - 0.8530181152176175 - 0.7006248010767178 - 0.9151231921516053 - 0.8206635625341799 - 0.7912770900139494 - 0.8161332799561427 - 0.8657792385786183'\n",
      "188 - random_41 - lwr_k=50 - 0.9330924108508625 - 0.7493553346121314 - 0.9188742916395867 - 0.7400188375925698 - 0.7393584551732697 - 0.816145015636332 - 0.8657773085361001'\n",
      "189 - random_0 - lr - 0.8350615078592797 - 0.8016926639490881 - 0.8054163235447185 - 0.7903601777781145 - 0.8557675520372835 - 0.8176597923219067 - 0.8655281893234489'\n",
      "190 - random_43 - lwr_k=1000 - 0.9075926695587906 - 0.7241492405612164 - 0.8301899329791943 - 0.7683449000221747 - 0.860029807832631 - 0.8180608605182226 - 0.8654622299023427'\n",
      "191 - random_57 - lwr_k=100 - 0.735772811370875 - 0.7518447968718479 - 1.1016124392791256 - 0.7329340645660225 - 0.7688492539259588 - 0.8181874003903903 - 0.8654414192352499'\n",
      "192 - random_85 - lwr_k=100 - 0.921717511850462 - 0.7066982869382258 - 0.8866284116418625 - 0.8581859235091032 - 0.7183508387055333 - 0.8183153511097939 - 0.8654203765411158'\n",
      "193 - random_15 - knn_k=10 - 0.962517816287146 - 0.7393501974097857 - 0.8310845598570599 - 0.7897432595520804 - 0.7717595277026962 - 0.8188976504690183 - 0.8653246119579407'\n",
      "194 - random_59 - lwr_k=50 - 0.899209100824239 - 0.727576539748055 - 0.9000419999800084 - 0.7931908114322688 - 0.7790773798208428 - 0.8198178470537384 - 0.8651732770114414'\n",
      "195 - random_4 - knn_k=5 - 0.7613310836269404 - 0.7360448841774283 - 0.8313497777784241 - 1.0314795892817672 - 0.7477657641903338 - 0.8215792524047154 - 0.8648835974049529'\n",
      "196 - random_65 - lr - 0.8557676979570112 - 0.7450306013501414 - 0.9598179752744556 - 0.7904318854743911 - 0.7593540637941796 - 0.8220759936727012 - 0.8648019036511803'\n",
      "197 - random_75 - knn_k=20 - 0.8268535887067886 - 0.7223499476199551 - 0.8861403355395667 - 0.8713340413837273 - 0.8068560163892957 - 0.8226969101286951 - 0.8646997881247713'\n",
      "198 - random_43 - lwr_k=500 - 0.898842036893979 - 0.7210776025257377 - 0.8436861165241722 - 0.7735242821731373 - 0.8778301867034285 - 0.8229893694918565 - 0.8646516904434582'\n",
      "199 - random_18 - lwr_k=20 - 0.7736858735800958 - 0.7409267067836295 - 0.9476706353967875 - 0.8397287064971334 - 0.8134754010802177 - 0.8230839579596102 - 0.8646361344840636'\n",
      "200 - random_40 - lr - 0.8203350552803299 - 0.691374535223777 - 0.9315224422385812 - 0.8410970593806506 - 0.833558492890448 - 0.823563613754605 - 0.864557250596339'\n",
      "201 - random_4 - knn_k=10 - 0.7774007951400599 - 0.7272600189520307 - 0.8457236178885847 - 1.0279485007231124 - 0.7401774841999169 - 0.823687431014423 - 0.8645368876883458'\n",
      "202 - random_2 - lwr_k=50 - 0.7165869671787336 - 0.792053764979635 - 1.062360833971383 - 0.7749583830772796 - 0.7735730353718552 - 0.8238923110954453 - 0.8645031932402082'\n",
      "203 - random_57 - lwr_k=500 - 0.7590634640855889 - 0.7588915682878487 - 1.0376959262706507 - 0.7835932878710977 - 0.7805726592623686 - 0.8239500397748973 - 0.8644936992182117'\n",
      "204 - random_34 - lwr_k=200 - 0.8206280739110212 - 0.7445507487418197 - 0.8061669405911347 - 1.0057944259953793 - 0.7450646295878867 - 0.8244323717817819 - 0.8644143752023777'\n",
      "205 - random_34 - lwr_k=100 - 0.8211604164491766 - 0.7244682870825384 - 0.8122721101880624 - 1.0171547833367447 - 0.7478950980057362 - 0.8245795096165892 - 0.8643901770074177'\n",
      "206 - random_23 - lwr_k=500 - 0.7370232800845737 - 0.6853796725270389 - 0.9039252238430511 - 1.112608160925858 - 0.6853508175605914 - 0.8248340978010572 - 0.8643483075961249'\n",
      "207 - random_15 - knn_k=5 - 0.947841835765551 - 0.7487314193247906 - 0.8299209032455941 - 0.8358062377490764 - 0.7658951985852552 - 0.8256437683917851 - 0.8642151496844738'\n",
      "208 - random_23 - lwr_k=20 - 0.6370801819343074 - 0.6818368188148103 - 0.8912371621322486 - 1.288819303983715 - 0.6351204338647981 - 0.8267844216405825 - 0.8640275585748702'\n",
      "209 - random_74 - knn_k=10 - 0.8510974694061458 - 0.7635466211450654 - 0.9068511519586134 - 0.8038597920108795 - 0.8117557762232073 - 0.82741803566205 - 0.8639233548148996'\n",
      "210 - random_15 - lr - 0.9455747984022035 - 0.7769780491526583 - 0.8733278626178451 - 0.7537628108870128 - 0.7912021209868587 - 0.8281759252262666 - 0.8637987127780157'\n",
      "211 - random_43 - lwr_k=200 - 0.8941015031832378 - 0.7284091312028129 - 0.8602043663477239 - 0.7728717012811666 - 0.8918237649006164 - 0.8294783514869527 - 0.8635845165815146'\n",
      "212 - random_54 - lwr_k=500 - 0.921851089538903 - 0.7096437060646281 - 0.8592033189519287 - 0.9046964161349246 - 0.7584362463112977 - 0.8307630720996593 - 0.8633732322446469'\n",
      "213 - random_57 - lwr_k=50 - 0.7481613332390558 - 0.738432073547532 - 1.1743302454071558 - 0.7280700655770072 - 0.7672982652553247 - 0.8312403383639481 - 0.8632947413376262'\n",
      "214 - random_0 - knn_k=5 - 0.8528143841198287 - 0.7820727715338055 - 0.9219971373608172 - 0.8278012097659282 - 0.7867732257709469 - 0.8342882868377784 - 0.8627934776654076'\n",
      "215 - random_9 - knn_k=1 - 0.9130020452005407 - 0.7681946892908701 - 0.8015233741933255 - 0.9040612811338411 - 0.7934399215362188 - 0.8360451972134709 - 0.8625045372997024'\n",
      "216 - random_34 - lwr_k=50 - 0.8276745131988492 - 0.7187372325559896 - 0.8625759480581123 - 1.0254208290867297 - 0.747468469420177 - 0.836362429971755 - 0.8624523654015451'\n",
      "217 - random_36 - lr - 0.8841743576777392 - 0.7709664126363149 - 0.8568017630293078 - 0.8035791790725694 - 0.8805859840373583 - 0.839219147347703 - 0.8619825514743567'\n",
      "218 - random_34 - lwr_k=500 - 0.8284343320880253 - 0.733601439168435 - 0.8683649738312464 - 1.0222746669560925 - 0.7470329259214936 - 0.8399295707377998 - 0.8618657156943533'\n",
      "219 - random_82 - lwr_k=50 - 0.7824797990853304 - 0.6433562475891025 - 1.0913450991714755 - 0.9466145077606386 - 0.7363455828502616 - 0.8400021519877374 - 0.8618537790280382'\n",
      "220 - random_0 - knn_k=10 - 0.8562442559626509 - 0.7791772493703049 - 0.9268470807067787 - 0.8304182495031424 - 0.809224346214916 - 0.8403775819718244 - 0.8617920360510488'\n",
      "221 - random_36 - knn_k=5 - 0.8834701986093572 - 0.7613776508372133 - 0.9339129446741884 - 0.8417662517352846 - 0.7844823372196076 - 0.840998062623775 - 0.8616899921966963'\n",
      "222 - random_57 - lwr_k=1000 - 0.7707563498161953 - 0.770563721115927 - 1.0339861000685198 - 0.8432793150111332 - 0.7901386757087382 - 0.8417302388731772 - 0.8615695789552529'\n",
      "223 - random_36 - knn_k=10 - 0.9233420106443405 - 0.736832947249597 - 0.93118829479984 - 0.8150895336276325 - 0.8035775670936292 - 0.8420036238360081 - 0.8615246182377163'\n",
      "224 - random_25 - lwr_k=200 - 0.8854750517035153 - 0.7167732287413516 - 0.9285759897908382 - 0.8353812392593234 - 0.844399188490657 - 0.8421125230914145 - 0.8615067087352639'\n",
      "225 - random_4 - knn_k=20 - 0.8025830750798296 - 0.7434350428324191 - 0.85079284675932 - 1.0488918057656433 - 0.7725923930339902 - 0.8436445284910505 - 0.8612547560992289'\n",
      "226 - random_56 - knn_k=20 - 0.7078737566872205 - 0.7521594649359296 - 0.9679840349755687 - 0.9166511572742413 - 0.8750353532565148 - 0.8439173651806446 - 0.8612098855503609'\n",
      "227 - random_37 - lr - 0.9621291250948354 - 0.7393615453193674 - 0.9363261601752937 - 0.7616583744901135 - 0.8234122322169013 - 0.8445787536978051 - 0.8611011140144503'\n",
      "228 - random_43 - lwr_k=100 - 0.9097467395576067 - 0.7308884107057034 - 0.8941284103705428 - 0.77844646474102 - 0.9113574158960205 - 0.8449084387955208 - 0.8610468942124505'\n",
      "229 - random_52 - lwr_k=200 - 0.7726465876819826 - 0.7096079970349192 - 0.974706886190698 - 0.9817661459797176 - 0.7874884171029694 - 0.8452218321492296 - 0.8609953537403336'\n",
      "230 - random_25 - lwr_k=500 - 0.8739256158797726 - 0.7153392547617424 - 0.937800366377632 - 0.8460764000045279 - 0.854170027189274 - 0.8454518976347225 - 0.8609575173165558'\n",
      "231 - random_31 - lwr_k=20 - 0.7859897944077523 - 0.802829290007511 - 0.9389556392593559 - 0.8483656591185758 - 0.8541266400496115 - 0.8460428022564362 - 0.8608603375173715'\n",
      "232 - random_25 - lwr_k=1000 - 0.8690870998701421 - 0.7140690356898286 - 0.9361014884538696 - 0.8605792699148866 - 0.8513074236065548 - 0.8462176438815734 - 0.8608315831746306'\n",
      "233 - random_15 - knn_k=20 - 0.9904504962821634 - 0.7546003957521591 - 0.8781990817736188 - 0.8085862550721685 - 0.8111689932001868 - 0.8486059560156488 - 0.8604388028763381'\n",
      "234 - random_31 - lwr_k=1000 - 0.8160922234245299 - 0.7708269722601714 - 1.0217792224264033 - 0.8000901573930177 - 0.834306842510835 - 0.8486077595451468 - 0.8604385062690212'\n",
      "235 - random_13 - lwr_k=200 - 0.8110496061129163 - 0.7376869440027551 - 1.0820837114154573 - 0.8136534714904128 - 0.7991516851085406 - 0.8487098184220402 - 0.8604217217308792'\n",
      "236 - random_18 - knn_k=10 - 0.7955108813759525 - 0.7678284025499219 - 0.9759627895303605 - 0.8823018830408568 - 0.8259317778398134 - 0.849493220054631 - 0.8602928839954167'\n",
      "237 - random_74 - lr - 0.9260098323537576 - 0.7129168353929105 - 0.995111349349659 - 0.7603769312398985 - 0.8536868244363092 - 0.8496141634190765 - 0.8602729937264332'\n",
      "238 - random_25 - lwr_k=100 - 0.9123584837287058 - 0.7178180176686845 - 0.943921536802098 - 0.8320036979600615 - 0.8506154826762612 - 0.8513360006973474 - 0.8599898214600777'\n",
      "239 - random_65 - knn_k=5 - 0.9123721061782177 - 0.7139874980057135 - 1.0302146289222007 - 0.8099164777720201 - 0.7910814286367123 - 0.8515065579325743 - 0.8599617717253834'\n",
      "240 - random_76 - knn_k=10 - 0.9382210186576216 - 0.7703476072455209 - 0.938736343044415 - 0.7774153264308256 - 0.8357520174648483 - 0.8520949121376019 - 0.859865011366109'\n",
      "241 - random_52 - lwr_k=100 - 0.7757302399321558 - 0.715724275757935 - 0.9713377836370966 - 1.0087151293800842 - 0.789414770545195 - 0.852162584547269 - 0.8598538820045503'\n",
      "242 - random_80 - knn_k=20 - 0.9846539496961286 - 0.827715461724481 - 0.8846218664249401 - 0.8330088396589779 - 0.7353730307828915 - 0.8530855329783733 - 0.8597020944911405'\n",
      "243 - random_13 - lwr_k=100 - 0.8323196013009432 - 0.7402452264123554 - 1.0940495690267429 - 0.8102996226033301 - 0.788879888241372 - 0.8531450520224587 - 0.8596923060269124'\n",
      "244 - random_51 - knn_k=10 - 0.8834606181049985 - 0.8071634161867886 - 0.9251927719366773 - 0.8486914849648373 - 0.8093516994243791 - 0.8547700560210977 - 0.8594250589002889'\n",
      "245 - random_48 - lr - 0.8029104202079611 - 0.6576897257010588 - 0.9837762834865965 - 1.0767261912282375 - 0.7655363736700334 - 0.8573017204917267 - 0.8590087029676776'\n",
      "246 - random_85 - lwr_k=1000 - 0.9571933151006612 - 0.6497246978225112 - 0.9204829484259905 - 1.0106607861570895 - 0.7519352019071792 - 0.8579881929244805 - 0.8588958061469231'\n",
      "247 - random_13 - lwr_k=500 - 0.8217252875487577 - 0.7443340248793813 - 1.102221723795227 - 0.8210727718546181 - 0.8104106232435884 - 0.8599370941825963 - 0.8585752910825043'\n",
      "248 - random_9 - knn_k=5 - 0.9331143185099828 - 0.8074114170475966 - 0.8098481291548703 - 0.8896956380027116 - 0.8596226429929767 - 0.8599405487143309 - 0.858574722952407'\n",
      "249 - random_29 - knn_k=50 - 0.9267875505348008 - 0.7046877638419101 - 0.987537675569491 - 0.8559119077959703 - 0.8255192557200615 - 0.8600797255449403 - 0.8585518340191465'\n",
      "250 - random_56 - knn_k=1 - 0.7640053143395626 - 0.7674303897319686 - 0.9177779846077937 - 1.0326260079226948 - 0.8257348078931095 - 0.8614952340854634 - 0.8583190403826492'\n",
      "251 - random_52 - lwr_k=500 - 0.787143997809181 - 0.7242418147900979 - 0.9777015038086743 - 1.0205653965668027 - 0.7987315185920661 - 0.8616550881651374 - 0.8582927508821263'\n",
      "252 - random_76 - knn_k=5 - 0.9268316550990124 - 0.7933451926740621 - 0.9635134155360903 - 0.8037582474357938 - 0.8299436896446064 - 0.863477744118933 - 0.8579929980403591'\n",
      "253 - random_18 - knn_k=5 - 0.789317904237971 - 0.8188379318274771 - 0.9816017855483118 - 0.8911176157162869 - 0.837765736972772 - 0.8637159488583408 - 0.8579538230400463'\n",
      "254 - random_59 - knn_k=10 - 0.9117775086266502 - 0.6822107664185266 - 1.0245045129510482 - 0.91708944987234 - 0.7841421157972419 - 0.8639311259716728 - 0.8579184351485081'\n",
      "255 - random_43 - lr - 0.990307796245235 - 0.7284865331786454 - 0.8676815716377294 - 0.8694071913074644 - 0.8640786381133946 - 0.8639914027211324 - 0.8579085220725349'\n",
      "256 - random_43 - lwr_k=50 - 0.929753007276046 - 0.7387974590236452 - 0.9335733950757427 - 0.7963523317977271 - 0.9228389088662409 - 0.8642568640155055 - 0.8578648644764856'\n",
      "257 - random_52 - lwr_k=50 - 0.7801280199830387 - 0.720150313310351 - 0.9889562346136077 - 1.031244573214635 - 0.8024578576342902 - 0.8645639039119103 - 0.857814368889926'\n",
      "258 - random_11 - knn_k=50 - 0.9550700321928836 - 0.6668093896060012 - 1.0303935949423717 - 0.8978799592079135 - 0.7778192405476946 - 0.8655832228657043 - 0.8576467323414975'\n",
      "259 - random_54 - lwr_k=20 - 1.0248960631594197 - 0.7988108443457896 - 0.8954110353752771 - 0.9218443271082841 - 0.68830918139969 - 0.865863733752025 - 0.8576005996991048'\n",
      "260 - random_66 - lwr_k=500 - 0.9613305868146251 - 0.7000030862366178 - 0.9967327926111562 - 0.9166465632169566 - 0.7584129840047253 - 0.8666178204445946 - 0.8574765830800792'\n",
      "261 - random_51 - knn_k=20 - 0.9113680633148459 - 0.7991041907551683 - 0.9299439886841658 - 0.8633048562373841 - 0.8303195816435825 - 0.8668057604322864 - 0.857445674588943'\n",
      "262 - random_0 - knn_k=20 - 0.9025862916846232 - 0.7845923858571288 - 0.9538910441107644 - 0.8545518296587095 - 0.8396703771409989 - 0.8670535675736477 - 0.8574049203836973'\n",
      "263 - random_65 - knn_k=10 - 0.9125319867702015 - 0.7427812098377957 - 1.0718667421829051 - 0.8314396319280831 - 0.7787523346002553 - 0.8674662066062911 - 0.8573370580301899'\n",
      "264 - random_51 - knn_k=5 - 0.8770721277774838 - 0.8520285597611705 - 0.9333887050550371 - 0.8413958391831243 - 0.8344849322200948 - 0.867673391516477 - 0.8573029845313103'\n",
      "265 - random_18 - knn_k=20 - 0.8265460507238658 - 0.7487484093606926 - 1.0122278111066771 - 0.9012132060550853 - 0.8509170150870244 - 0.8679140165803163 - 0.8572634114859772'\n",
      "266 - random_57 - lwr_k=20 - 0.7956551724478649 - 0.746725320731614 - 1.273599068402644 - 0.7524442393232452 - 0.7724001352198658 - 0.8681448786763635 - 0.857225444052133'\n",
      "267 - random_74 - knn_k=20 - 0.9108108126443432 - 0.7796146082318112 - 0.9209172724603231 - 0.8575190891140174 - 0.8722083682902857 - 0.8682093080541897 - 0.8572148480375332'\n",
      "268 - random_36 - knn_k=20 - 0.9598802754201139 - 0.7484764717835121 - 0.9590051299771926 - 0.843772738361163 - 0.8331665767389067 - 0.8688572243184536 - 0.8571082921397863'\n",
      "269 - random_25 - lwr_k=50 - 0.9403215349378514 - 0.7259457287285167 - 0.9732172170204889 - 0.8472032976659503 - 0.8605807219943333 - 0.8694462436809585 - 0.8570114223891354'\n",
      "270 - random_23 - lwr_k=1000 - 0.7837582004257432 - 0.708864737268055 - 0.9666541281801998 - 1.1892616389363604 - 0.7068422448103193 - 0.871050576144403 - 0.8567475748900748'\n",
      "271 - random_32 - lwr_k=100 - 0.7093390202461283 - 0.6752793105286486 - 0.8845407157906877 - 1.3958854224307526 - 0.6915119179135466 - 0.8712745288473615 - 0.8567107437706343'\n",
      "272 - random_34 - lwr_k=1000 - 0.8582832034548284 - 0.7514684814164293 - 0.9420036447973976 - 1.0607437181476966 - 0.7506259543611006 - 0.8726110917600645 - 0.8564909334820008'\n",
      "273 - random_13 - lwr_k=50 - 0.8830774939084425 - 0.738097066272173 - 1.1290819271795083 - 0.8274830092685945 - 0.7883326256015575 - 0.8732015673028904 - 0.856393824248858'\n",
      "274 - random_77 - lr - 1.0260805672746223 - 0.6645509269049774 - 1.0936552747458463 - 0.8857311524458439 - 0.7053704562647904 - 0.8750715655029012 - 0.8560862855313147'\n",
      "275 - random_59 - knn_k=5 - 0.9243704466655901 - 0.7154508943862873 - 1.005581679616246 - 0.9367518547288406 - 0.7955591208196432 - 0.8755313781534595 - 0.8560106650345346'\n",
      "276 - random_75 - knn_k=50 - 0.8977801605929682 - 0.7283830787013698 - 0.9589469406796965 - 0.9686508309999616 - 0.8411505101147438 - 0.8789687750277315 - 0.855445352925467'\n",
      "277 - random_5 - lr - 0.9980000304514618 - 0.6919372861194116 - 0.9769195893528501 - 0.9931605094743493 - 0.7372525574060365 - 0.879446914836684 - 0.8553667183558451'\n",
      "278 - random_76 - knn_k=20 - 0.9881569819516982 - 0.7715577734739674 - 0.9910317380049924 - 0.7963242370894861 - 0.8540273399570284 - 0.8802195397295173 - 0.8552396529561658'\n",
      "279 - random_34 - lwr_k=20 - 0.8641704107130702 - 0.7424536720767021 - 0.9391501750027943 - 1.1028313650047468 - 0.759221955726016 - 0.8815494505282523 - 0.855020936669975'\n",
      "280 - random_9 - knn_k=10 - 0.9778328671339533 - 0.8217353761185483 - 0.812501653957486 - 0.9133012691263855 - 0.888765533952401 - 0.882830821228268 - 0.854810203257623'\n",
      "281 - random_59 - knn_k=20 - 0.9346509604884462 - 0.6961257142065851 - 1.0555264916168785 - 0.95561394196731 - 0.7914241399559009 - 0.8866536161195557 - 0.854181508835195'\n",
      "282 - random_43 - lwr_k=20 - 0.9447164986560178 - 0.7615814592307413 - 0.9693891144653828 - 0.8399725427067095 - 0.9217244409143026 - 0.8874697638055422 - 0.8540472857045669'\n",
      "283 - random_52 - lwr_k=1000 - 0.8127654330846008 - 0.748137763516932 - 0.9929508138486803 - 1.073599786017776 - 0.8191513254124144 - 0.889298673847221 - 0.8537465043194743'\n",
      "284 - random_54 - lwr_k=1000 - 0.9846378221614701 - 0.7299665862812474 - 0.9475473446614513 - 0.9777165123483197 - 0.8070988887792554 - 0.8893868426249106 - 0.8537320041382346'\n",
      "285 - random_42 - lwr_k=500 - 1.0905108505982373 - 0.6283958044709415 - 1.1778943099747101 - 0.7919984531983905 - 0.768607394860431 - 0.8914747873721154 - 0.8533886220698172'\n",
      "286 - random_52 - lwr_k=20 - 0.7776371659127101 - 0.7365504596341492 - 1.0469862498180407 - 1.0759346882255671 - 0.8265073578970541 - 0.8926953400413918 - 0.8531878907522144'\n",
      "287 - random_40 - lwr_k=1000 - 0.8881450409122863 - 0.6829912406425191 - 1.2225684412090008 - 0.7845947920749639 - 0.887548213973138 - 0.8931474555540087 - 0.8531135361218566'\n",
      "288 - random_31 - knn_k=5 - 0.8505030516694679 - 0.8106785369140957 - 1.051878816289294 - 0.8520815344421402 - 0.9022302213498737 - 0.8934615223325552 - 0.8530618848987181'\n",
      "289 - random_42 - lwr_k=200 - 1.1018389096083285 - 0.6230522984943263 - 1.1696975724280814 - 0.8023919546560628 - 0.7721359168784848 - 0.8938168886708353 - 0.8530034415761887'\n",
      "290 - random_25 - lwr_k=20 - 0.9695513092595902 - 0.7457200185344245 - 1.0032279494778014 - 0.8795030789583341 - 0.874688654150153 - 0.8945306261084608 - 0.8528860607700315'\n",
      "291 - random_4 - knn_k=50 - 0.8564089302781549 - 0.7584755863152118 - 0.9166760361603807 - 1.1361454682052448 - 0.8142103685244086 - 0.8963650186029827 - 0.8525843777442227'\n",
      "292 - random_76 - lr - 1.0085550973082984 - 0.7833968324663637 - 0.9392066357345041 - 0.9001732576917003 - 0.8505059967289094 - 0.8963674835919707 - 0.8525839723536976'\n",
      "293 - random_42 - lwr_k=1000 - 1.0974516207780307 - 0.630111220917174 - 1.1840612241274242 - 0.8016529070172618 - 0.7779934456596509 - 0.8982470065775818 - 0.8522748671959577'\n",
      "294 - random_59 - lr - 0.9573717620836406 - 0.6607396886280094 - 1.0951685069652481 - 0.8626457391590858 - 0.9200018560955215 - 0.8991670072429978 - 0.8521235644702227'\n",
      "295 - random_31 - knn_k=10 - 0.8779786346713485 - 0.7960120763667051 - 1.0680434931369578 - 0.8569887069282028 - 0.904244880711567 - 0.9006404895469341 - 0.8518812365053763'\n",
      "296 - random_65 - knn_k=20 - 0.9741401685243607 - 0.7599525216780167 - 1.1174229590446247 - 0.8589703270189475 - 0.7969207150276735 - 0.9014742688698604 - 0.8517441136869237'\n",
      "297 - random_78 - lwr_k=200 - 0.7022035013261494 - 0.7149194037123122 - 1.1395515154794846 - 1.2650977231514688 - 0.6920987144958064 - 0.9027343004117113 - 0.8515368896989848'\n",
      "298 - random_17 - lr - 0.9149606558884955 - 0.6766413848062394 - 1.202012808081754 - 0.8934383756027345 - 0.8282961378972767 - 0.90304785051892 - 0.8514853234472868'\n",
      "299 - random_1 - lr - 0.9046186836287757 - 0.7233987607809877 - 0.916439007756139 - 0.8817439523330962 - 1.089706171540963 - 0.9031630083730503 - 0.8514663846596591'\n",
      "300 - random_42 - lr - 1.0947782678760525 - 0.6469303022466154 - 1.2029227200979746 - 0.7903635771197108 - 0.7979966653365039 - 0.9065909684073742 - 0.850902624527302'\n",
      "301 - random_8 - lr - 0.9545594602244709 - 0.6929258719135657 - 0.9988009174084197 - 0.9788841770760215 - 0.908844150484491 - 0.906785863430149 - 0.8508705722155087'\n",
      "302 - random_78 - lwr_k=100 - 0.7006751448300875 - 0.7164893768662867 - 1.1423647103899042 - 1.2993140138684394 - 0.6837869273906758 - 0.9084849868813923 - 0.8505911354507354'\n",
      "303 - random_42 - lwr_k=100 - 1.1454708829105225 - 0.6265359070455722 - 1.1646954949885635 - 0.8272587152597857 - 0.7807003128330414 - 0.9089275553877003 - 0.850518350914978'\n",
      "304 - random_13 - lwr_k=1000 - 0.8937022877038268 - 0.7462552798625905 - 1.166400200550087 - 0.9200364405840429 - 0.8283458469871979 - 0.9109293354595867 - 0.8501891394343958'\n",
      "305 - random_65 - knn_k=1 - 1.0498829614654894 - 0.7836828677836216 - 1.0806729707932827 - 0.8927178752108593 - 0.7501844208304045 - 0.9114293185177801 - 0.8501069125378622'\n",
      "306 - random_15 - knn_k=50 - 1.0675145286745293 - 0.7752935747360443 - 0.9675960309931164 - 0.8655567611985641 - 0.8858861882537604 - 0.9123712715515219 - 0.8499519995395604'\n",
      "307 - random_8 - lwr_k=100 - 0.7976329804673546 - 0.8573869175078823 - 1.1785336060221008 - 0.8718252644841301 - 0.8583849817276572 - 0.9127352499800196 - 0.8498921398781376'\n",
      "308 - random_0 - knn_k=50 - 0.9686318727001804 - 0.7991434594118896 - 1.0117048607935695 - 0.9225415675813495 - 0.8712395266917843 - 0.914645941568093 - 0.8495779087518118'\n",
      "309 - random_17 - knn_k=5 - 0.9732570128337571 - 0.7466506703682907 - 1.14603676411207 - 0.8878308536274081 - 0.821037178252191 - 0.9149512027461058 - 0.8495277056921504'\n",
      "310 - random_51 - knn_k=50 - 0.9933674222435652 - 0.7945620861768883 - 0.9920198968398791 - 0.9315668225409682 - 0.8677417490522309 - 0.9158471020754569 - 0.8493803666568536'\n",
      "311 - random_13 - lwr_k=20 - 0.9336882187726802 - 0.751332568939732 - 1.208897497938741 - 0.884198317441883 - 0.8026218950689282 - 0.9161325821399321 - 0.8493334167865744'\n",
      "312 - random_20 - lwr_k=100 - 0.9337822230497732 - 0.7658493702598264 - 0.9575819860909972 - 1.0565185322418968 - 0.8723089185877682 - 0.9171943706099219 - 0.8491587957284573'\n",
      "313 - random_40 - lwr_k=500 - 0.899666591307404 - 0.6840231221830235 - 1.3097615941015661 - 0.7923324597905098 - 0.9014412804011722 - 0.9174192242656632 - 0.8491218164388937'\n",
      "314 - random_29 - knn_k=100 - 1.0233953000944667 - 0.7044392217563235 - 1.0595573023854985 - 0.9243312409155477 - 0.8758125458947127 - 0.917496120390118 - 0.8491091701510531'\n",
      "315 - random_56 - knn_k=50 - 0.7529204388166505 - 0.8058855724870778 - 1.0717161081046533 - 1.0050149864062465 - 0.9559755165770842 - 0.9182740088719318 - 0.8489812391048696'\n",
      "316 - random_25 - lr - 0.9330721517715311 - 0.7117729365633448 - 1.0158935249091654 - 1.0317107351658772 - 0.902437612381917 - 0.9189575697711795 - 0.8488688211130682'\n",
      "317 - random_78 - lwr_k=50 - 0.6974663668964092 - 0.7062617416585206 - 1.1618827559831049 - 1.353808137093926 - 0.6789691453644532 - 0.9196329130011877 - 0.8487577545939362'\n",
      "318 - random_85 - lwr_k=50 - 0.9995951650238413 - 0.7553412685716142 - 1.094311931582536 - 0.9815986942667505 - 0.7688792418535375 - 0.9199365398647756 - 0.8487078203125883'\n",
      "319 - random_32 - knn_k=10 - 0.8786876821940298 - 0.695044761597139 - 1.1710712977203528 - 1.0532759134972296 - 0.8059949784147616 - 0.9207874274638467 - 0.8485678838778954'\n",
      "320 - random_85 - lwr_k=200 - 0.894618860884483 - 0.6833997444352011 - 0.8631763468173651 - 1.453368964040449 - 0.71121335649504 - 0.9211283253717331 - 0.8485118200242489'\n",
      "321 - random_1 - lwr_k=1000 - 0.9110528273446519 - 0.7233152832804861 - 0.9927541538493181 - 0.912987634319646 - 1.066822890339467 - 0.9213651654016443 - 0.8484728694631941'\n",
      "322 - random_20 - lwr_k=50 - 0.9324207515755759 - 0.776360745762829 - 0.9587757901280192 - 1.0621672758987448 - 0.8802778254969048 - 0.9219865977212746 - 0.8483706690981788'\n",
      "323 - random_66 - lwr_k=1000 - 1.01602325740139 - 0.7067977657928481 - 1.0602299670371733 - 1.0512333713641393 - 0.7815710118201744 - 0.923158395446215 - 0.8481779559877886'\n",
      "324 - random_82 - lwr_k=20 - 0.8662867563460952 - 0.6812431291874148 - 1.1853543119734442 - 1.0936797074671611 - 0.7927461214713737 - 0.923831190864437 - 0.8480673084801665'\n",
      "325 - random_84 - knn_k=1 - 0.9136628681709051 - 0.7465576415788732 - 1.0765777037851552 - 0.9379843941815994 - 0.9621856248116335 - 0.9273736745508743 - 0.8474847138606432'\n",
      "326 - random_18 - knn_k=50 - 0.8881334265130698 - 0.7436915013096306 - 1.0844510192445704 - 0.9999549719104589 - 0.9226747165066588 - 0.9277581608346757 - 0.8474214814903486'\n",
      "327 - random_36 - knn_k=50 - 1.0372534407194618 - 0.7695935329736943 - 1.0287375794887612 - 0.9050740302182034 - 0.8986700957200918 - 0.9278607179121194 - 0.8474046150184601'\n",
      "328 - random_41 - lwr_k=20 - 0.9607166673665891 - 0.7720077415281761 - 1.0002087146377132 - 0.9955700968620251 - 0.9189471218456631 - 0.929477108508801 - 0.8471387844464576'\n",
      "329 - random_20 - lwr_k=200 - 0.9625206284849865 - 0.7696563586397642 - 0.9686889845736703 - 1.0777328390735508 - 0.8731255381518173 - 0.9303316781657429 - 0.8469982424628634'\n",
      "330 - random_78 - lwr_k=500 - 0.7378361714208319 - 0.7196616975129401 - 1.1918350267420217 - 1.2979856050199785 - 0.7109489195591954 - 0.9316118284259505 - 0.8467877097632679'\n",
      "331 - random_79 - knn_k=5 - 0.82316510288665 - 0.745197449467234 - 1.1793568093965252 - 1.0863960916791493 - 0.825957658253232 - 0.9319842726452915 - 0.8467264578232543'\n",
      "332 - random_22 - lwr_k=100 - 1.0714778106818406 - 0.7664391638243931 - 1.1034344586741696 - 0.914078121831151 - 0.8069057727071718 - 0.9324642922778263 - 0.8466475140990387'\n",
      "333 - random_32 - knn_k=5 - 0.8979637898561001 - 0.7109928768949446 - 1.1803618895304981 - 1.050842825218624 - 0.8224827420137112 - 0.9325025363654061 - 0.8466412245006596'\n",
      "334 - random_22 - lwr_k=50 - 1.0799058312503271 - 0.7573750563400298 - 1.0873052263038083 - 0.9447694489585445 - 0.8020853768391575 - 0.9342849755088635 - 0.8463480856900047'\n",
      "335 - random_8 - knn_k=5 - 0.9490486673589303 - 0.7324252500194277 - 0.989543638318295 - 1.0596383250495134 - 0.9525594352164476 - 0.9366233739902022 - 0.8459635141593734'\n",
      "336 - random_22 - lwr_k=200 - 1.0690572080177925 - 0.7694339422504706 - 1.1369693732605795 - 0.8964924512161263 - 0.8142183053803553 - 0.937230563009074 - 0.8458636562385642'\n",
      "337 - random_32 - lr - 0.9715864417443834 - 0.672141088653435 - 1.127517662518021 - 1.103172385441544 - 0.8144366046663529 - 0.9377470412708516 - 0.8457787165513146'\n",
      "338 - random_75 - knn_k=100 - 0.9938478280715971 - 0.7334407432758414 - 1.023525877754678 - 1.0779652422074428 - 0.8630500117272984 - 0.9383506005016574 - 0.8456794555831478'\n",
      "339 - random_17 - knn_k=10 - 1.0000292948341682 - 0.7749056985701768 - 1.1846479500859082 - 0.8875601700215845 - 0.8470704711959756 - 0.9388321697807663 - 0.8456002570050398'\n",
      "340 - random_11 - knn_k=100 - 1.0530666694653736 - 0.6981562275022799 - 1.1291551701149858 - 0.9713268629114019 - 0.8477461685702699 - 0.939877023496227 - 0.8454284210259082'\n",
      "341 - random_32 - knn_k=20 - 0.9271463405119754 - 0.6823050411766839 - 1.182593021374422 - 1.0771698706899215 - 0.8306108861154824 - 0.9399372677895195 - 0.8454185132876557'\n",
      "342 - random_1 - lwr_k=500 - 0.936313580586669 - 0.7248639205258699 - 1.0160307959131936 - 0.951177332904464 - 1.0720914558671104 - 0.9400729358072538 - 0.8453962014115344'\n",
      "343 - random_8 - knn_k=10 - 0.996835520992402 - 0.7212794579681583 - 0.9828303120408508 - 1.076417780783265 - 0.9305316180204289 - 0.9415619965837924 - 0.8451513114209677'\n",
      "344 - random_9 - knn_k=20 - 1.070698753219076 - 0.862307664543117 - 0.8433651960786139 - 0.9914206960561648 - 0.9408527943873561 - 0.9417341069147642 - 0.8451230062651324'\n",
      "345 - random_53 - lr - 1.013004139198555 - 0.7825294982105535 - 1.1226212826840203 - 0.8527504347707764 - 0.9392450488756595 - 0.9420209936483351 - 0.8450758250549462'\n",
      "346 - random_31 - knn_k=20 - 0.9314464845039917 - 0.7884515321257312 - 1.1486316169206232 - 0.9118183505543279 - 0.9310151804507935 - 0.9422557321464465 - 0.8450372201104779'\n",
      "347 - random_76 - knn_k=50 - 1.0781739558376096 - 0.7888968710994382 - 1.0592089398198605 - 0.8770702480742376 - 0.910455246070214 - 0.9427591581875165 - 0.8449544269831648'\n",
      "348 - random_79 - knn_k=10 - 0.8072353225088483 - 0.7371808890355804 - 1.2086616473025869 - 1.1042157481926973 - 0.8596822345554553 - 0.9433600241879422 - 0.8448556089419575'\n",
      "349 - random_15 - knn_k=1 - 0.9773565889172469 - 0.8138033774130278 - 0.9484278142856123 - 1.0841857217973498 - 0.8939560010697742 - 0.9435360534542432 - 0.8448266592805045'\n",
      "350 - random_42 - lwr_k=50 - 1.1978522169269652 - 0.6405768529140519 - 1.1905418721228898 - 0.8964817029768293 - 0.7927590695657104 - 0.9436373279540544 - 0.8448100037405196'\n",
      "351 - random_40 - lwr_k=200 - 0.9292223605077011 - 0.6841346456205515 - 1.4042933590138995 - 0.7941248778651475 - 0.9187551844521441 - 0.9460774614757878 - 0.8444087009296913'\n",
      "352 - random_20 - lwr_k=20 - 0.9684303778453953 - 0.7786632913503061 - 0.9927390780043941 - 1.0823892037835259 - 0.913845362124945 - 0.9471983391094931 - 0.8442243621051991'\n",
      "353 - random_25 - knn_k=10 - 1.024936608289992 - 0.7806131819548967 - 1.0583028496534819 - 0.9652687853085455 - 0.9138178699847109 - 0.948578453790139 - 0.8439973893204413'\n",
      "354 - random_48 - knn_k=5 - 0.9497392383537474 - 0.7342380993789174 - 1.0855269925389095 - 1.180949261927867 - 0.8042130989448282 - 0.9509109722527991 - 0.8436137848139513'\n",
      "355 - random_84 - knn_k=5 - 0.9444659675735856 - 0.775528005696179 - 1.1146125245873784 - 0.846644471234053 - 1.075719690160683 - 0.9513753683223087 - 0.8435374105309984'\n",
      "356 - random_84 - lr - 1.0273024359485108 - 0.72367378848713 - 1.0343143766149192 - 0.9554150163759799 - 1.017866879016444 - 0.9516988502664104 - 0.8434842108957064'\n",
      "357 - random_59 - knn_k=50 - 1.0033184986251866 - 0.7224359886590954 - 1.148249352807488 - 1.0598957224939556 - 0.8455799196173075 - 0.9558768000224589 - 0.8427971079295495'\n",
      "358 - random_37 - knn_k=5 - 0.8721816383729526 - 0.8500129155962716 - 0.9678037631421204 - 1.1543816630848576 - 0.9368319921866957 - 0.9562228615023457 - 0.8427401948781279'\n",
      "359 - random_41 - knn_k=10 - 1.1409239638663564 - 0.7897786665132572 - 1.0746274332092767 - 0.9732095255383585 - 0.8044660093511633 - 0.9566029160815364 - 0.842677691343162'\n",
      "360 - random_20 - lwr_k=500 - 1.0343672778481137 - 0.7806874089856688 - 0.9938310652299747 - 1.1053499874038089 - 0.8706137034244675 - 0.9569597381893363 - 0.8426190086057009'\n",
      "361 - random_43 - knn_k=10 - 1.0397784551895142 - 0.7835546967372787 - 1.0389501155989356 - 0.9479616156358569 - 0.9757260547086591 - 0.9571848409077358 - 0.8425819883554506'\n",
      "362 - random_4 - knn_k=100 - 0.9285539737567623 - 0.7702259883719378 - 0.9847563807198452 - 1.2372945899326317 - 0.8656773804419727 - 0.9572795087375101 - 0.8425664193442284'\n",
      "363 - random_22 - lwr_k=20 - 1.0937820718659323 - 0.7712016807294059 - 1.0910327860405595 - 1.0161858075213253 - 0.8157219712018471 - 0.9575797119655167 - 0.842517048111816'\n",
      "364 - random_54 - knn_k=5 - 1.0552288411034056 - 0.8037778011591773 - 1.1660981495025664 - 1.008182732007407 - 0.7841776917436487 - 0.9634860651270611 - 0.8415456930181864'\n",
      "365 - random_78 - lwr_k=20 - 0.6589939091586549 - 0.727436746812752 - 1.226759014136725 - 1.527657693984841 - 0.6778886697449424 - 0.9636916674781595 - 0.8415118797859703'\n",
      "366 - random_29 - knn_k=1 - 1.0379073250312498 - 0.7935856385922394 - 1.1791977441836805 - 0.9067459505348922 - 0.9055328769161528 - 0.9645838788387011 - 0.841365147271684'\n",
      "367 - random_80 - knn_k=50 - 1.1643214573600709 - 0.9147533926764586 - 1.0173284452035596 - 0.9374902574818631 - 0.7967889873342744 - 0.9661515769738829 - 0.8411073246310066'\n",
      "368 - random_48 - knn_k=10 - 0.9282589378771445 - 0.7528925008495616 - 1.1200676610620206 - 1.24158449104345 - 0.7902157737881027 - 0.9665779997658626 - 0.8410371954091839'\n",
      "369 - random_74 - knn_k=50 - 1.0447577599553404 - 0.8316244648737261 - 1.0356807407354125 - 0.9643558120058591 - 0.9641246646563256 - 0.9681025464670878 - 0.8407864694259573'\n",
      "370 - random_1 - lwr_k=200 - 0.9820868120272781 - 0.7292935101257436 - 1.0551284392469003 - 0.9960227613291183 - 1.0794161376431897 - 0.96836639527071 - 0.8407430770191139'\n",
      "371 - random_40 - lwr_k=100 - 0.9758858675403959 - 0.6831837553541354 - 1.4573191858414873 - 0.7927189560177879 - 0.935443522207178 - 0.9688816440795414 - 0.8406583395269159'\n",
      "372 - random_8 - knn_k=20 - 1.0496687977802635 - 0.7051691385988573 - 1.005010635904979 - 1.1363525939755061 - 0.9518624599058187 - 0.9695937981632752 - 0.8405412191181352'\n",
      "373 - random_43 - knn_k=5 - 1.0541595142402542 - 0.83371605294013 - 1.0406518911659666 - 0.9433284869798051 - 0.9831414545009619 - 0.9709939242897152 - 0.8403109552636985'\n",
      "374 - random_41 - knn_k=20 - 1.1523040567225697 - 0.7753199485442084 - 1.0710559025355388 - 1.0364173547090918 - 0.821746318990587 - 0.9713671649323706 - 0.8402495723444119'\n",
      "375 - random_22 - lwr_k=500 - 1.0944852499769187 - 0.7924443668744311 - 1.2198085997967827 - 0.8957792094503534 - 0.8570892639208278 - 0.9719154959735655 - 0.8401593941692685'\n",
      "376 - random_5 - lwr_k=500 - 0.8890771618724416 - 0.631807610866352 - 1.49801664824031 - 1.0930309723822609 - 0.7544634500235826 - 0.9732354739978049 - 0.8399423114208694'\n",
      "377 - random_78 - lwr_k=1000 - 0.7596880254550378 - 0.7331687471895666 - 1.2827331408742746 - 1.3611229296271679 - 0.7308936427039937 - 0.9734746757553402 - 0.8399029724515881'\n",
      "378 - random_75 - knn_k=1 - 0.9338584253526875 - 0.7588338599169985 - 1.0294918923776812 - 1.0496687571815493 - 1.1004905455257958 - 0.9744423929394633 - 0.8397438222974606'\n",
      "379 - random_5 - lwr_k=1000 - 0.89571067548569 - 0.6390906535536106 - 1.502556461591387 - 1.0688993787203376 - 0.76867066827679 - 0.9749429510396245 - 0.8396615008298899'\n",
      "380 - random_25 - knn_k=5 - 1.0219569478331945 - 0.8271536553870528 - 1.0565708078180462 - 1.0093483026271737 - 0.9613496841301139 - 0.9752654667941912 - 0.8396084600935156'\n",
      "381 - random_4 - knn_k=1 - 0.8749266763374113 - 0.8462220044895222 - 1.0606455374531532 - 1.2232836221927958 - 0.8730004645545867 - 0.9755920434073432 - 0.8395547515109151'\n",
      "382 - random_37 - knn_k=10 - 0.8993201290272622 - 0.8726551870630612 - 0.9643825915097973 - 1.1645748648250795 - 0.9793139989781114 - 0.9760308649158019 - 0.8394825832040467'\n",
      "383 - random_77 - lwr_k=500 - 1.099855096912189 - 0.6604577350340765 - 1.4403744789756507 - 0.9668610416748177 - 0.7128228012776222 - 0.9760545391684655 - 0.8394786897514739'\n",
      "384 - random_79 - knn_k=20 - 0.8771912576057573 - 0.7422248501950083 - 1.2279424450999288 - 1.1303496761891367 - 0.9038583809143625 - 0.9762791184968148 - 0.839441755577619'\n",
      "385 - random_77 - lwr_k=1000 - 1.1174408238982836 - 0.6660547328180499 - 1.4589582031782564 - 0.9361839722686203 - 0.7046120879075211 - 0.9766325338795422 - 0.839383633108002'\n",
      "386 - random_25 - knn_k=20 - 1.0658477466269267 - 0.7519468444388031 - 1.140770376185353 - 0.9918602740451815 - 0.9380912551580376 - 0.9776891736485369 - 0.8392098588019841'\n",
      "387 - random_17 - knn_k=20 - 1.02251083199317 - 0.7950989208708684 - 1.222332854410794 - 0.9415742664403958 - 0.9087341046475111 - 0.9780359798402258 - 0.8391528232757319'\n",
      "388 - random_51 - knn_k=100 - 1.0687036566214412 - 0.8016284048389671 - 1.080631907812624 - 1.0274476652851987 - 0.9123210861375052 - 0.9781377203835715 - 0.8391360910905232'\n",
      "389 - random_27 - lwr_k=1000 - 1.0199782025485669 - 0.7402475878717043 - 1.0666873228021005 - 1.203732456037481 - 0.8608377061484801 - 0.9782764982843208 - 0.8391132677650144'\n",
      "390 - random_0 - knn_k=100 - 1.0290216049838223 - 0.82084121666004 - 1.0848017311254043 - 1.0306516070322382 - 0.9265647171793218 - 0.9783652033648422 - 0.8390986793837512'\n",
      "391 - random_79 - lr - 0.982324849125751 - 0.7451671505510877 - 1.2572644984905947 - 0.9898795733495708 - 0.9182692472710977 - 0.9785574885032744 - 0.8390670562918809'\n",
      "392 - random_68 - lr - 1.024052742142073 - 0.7623832988777113 - 1.3289179136957021 - 0.9882707808310359 - 0.7974996233674398 - 0.9802070095673804 - 0.8387957771042258'\n",
      "393 - random_65 - knn_k=50 - 1.0480717424072727 - 0.8081966367275878 - 1.2341690339697016 - 0.9509035503202641 - 0.8671135093993594 - 0.98167989955252 - 0.8385535465517527'\n",
      "394 - random_57 - knn_k=10 - 0.9205614661650555 - 0.7836891171177207 - 1.3899585190242063 - 1.0028650749736314 - 0.8203118492848502 - 0.9834502392047634 - 0.8382623976157465'\n",
      "395 - random_5 - lwr_k=200 - 0.8830073085892153 - 0.6367934878795285 - 1.507898447060873 - 1.1473619123654173 - 0.7434660064354076 - 0.9836594860414873 - 0.8382279850137366'\n",
      "396 - random_27 - lwr_k=500 - 1.0384764349941855 - 0.7404255936515073 - 1.0738023318724157 - 1.185201195203853 - 0.8843980592399624 - 0.9844412178171293 - 0.8380994219018886'\n",
      "397 - random_15 - knn_k=100 - 1.161776462233949 - 0.7931899333178374 - 1.0427204334033169 - 0.9471281299189238 - 0.9788490026963739 - 0.9847313039965812 - 0.8380517145128626'\n",
      "398 - random_31 - lr - 0.9701767276516359 - 0.7683676241660546 - 1.2491041287417326 - 1.0200982402491354 - 0.9229358020316814 - 0.9861125127124415 - 0.8378245618037676'\n",
      "399 - random_20 - lwr_k=1000 - 1.0940163289000602 - 0.790596221698039 - 1.0191429603803441 - 1.1469189469884333 - 0.8806155282741419 - 0.9862489741067648 - 0.837802119449436'\n",
      "400 - random_41 - knn_k=5 - 1.1602546750303144 - 0.8292311933359391 - 1.1250167100250883 - 0.9746141455948647 - 0.8471957961253006 - 0.9872640397295815 - 0.8376351824011214'\n",
      "401 - random_43 - knn_k=20 - 1.09227242182225 - 0.7737196022261659 - 1.0858086257104442 - 0.9951889390177093 - 0.9960145372427947 - 0.9885894097217994 - 0.8374172128930895'\n",
      "402 - random_40 - lwr_k=50 - 1.0159989377547476 - 0.6909264320812226 - 1.4895097666793031 - 0.8057217417960444 - 0.9473742253975108 - 0.9898782093404468 - 0.8372052577254926'\n",
      "403 - random_84 - knn_k=10 - 1.0015355660215992 - 0.7909571420165251 - 1.1476315463784592 - 0.8778607599774036 - 1.1326698864774147 - 0.9901117059747002 - 0.8371668570171665'\n",
      "404 - random_36 - knn_k=100 - 1.114371305629931 - 0.7748005100111585 - 1.1019974905804522 - 0.9981044338390057 - 0.9716944846072315 - 0.992183871224438 - 0.8368260700348912'\n",
      "405 - random_39 - lwr_k=20 - 0.8926165578359092 - 0.7423714577568207 - 1.5516834939860589 - 0.9613591845294276 - 0.8131771636928125 - 0.9922056964701288 - 0.836822480668832'\n",
      "406 - random_32 - knn_k=50 - 1.0094256893414943 - 0.6874456760288971 - 1.2538426360480908 - 1.1410531300591416 - 0.8703562721676101 - 0.9923951202695839 - 0.8367913281509546'\n",
      "407 - random_57 - lr - 0.9742360968004141 - 0.7911332159431622 - 1.2533621024709038 - 1.120171908857209 - 0.8336208396145345 - 0.9944818764292248 - 0.8364481415568938'\n",
      "408 - random_54 - knn_k=10 - 1.1107429860712494 - 0.8153499581302844 - 1.1857913804926548 - 1.073176889692203 - 0.7895028815553808 - 0.9949062771339329 - 0.836378344886261'\n",
      "409 - random_1 - lwr_k=100 - 1.0315916676210393 - 0.7378028870181264 - 1.0908468556882183 - 1.0462627227619308 - 1.0899489639353959 - 0.9992670937752798 - 0.8356611677481689'\n",
      "410 - random_76 - knn_k=100 - 1.166071234198823 - 0.7969861298894991 - 1.1173807065326482 - 0.9473790918956146 - 0.9685486377064686 - 0.9992695171626561 - 0.8356607691994185'\n",
      "411 - random_77 - lwr_k=200 - 1.095452706414105 - 0.6617342823808893 - 1.435467131205149 - 1.0940472821768488 - 0.7106801003534469 - 0.9994514836705081 - 0.8356308431029869'\n",
      "412 - random_66 - knn_k=10 - 1.0278715972713695 - 0.7447624457102865 - 1.2475976952582515 - 1.171575852978239 - 0.810947784192334 - 1.0005276232131592 - 0.835453861876565'\n",
      "413 - random_13 - knn_k=10 - 1.0403899958025202 - 0.7725756847258445 - 1.3316403801536703 - 0.9959361726935003 - 0.8664615804783162 - 1.001381276438907 - 0.8353134706086635'\n",
      "414 - random_18 - knn_k=100 - 0.9899331195954646 - 0.755243966730763 - 1.1579907174993014 - 1.129882054017312 - 0.9747378208618168 - 1.0015310588383286 - 0.8352888374902848'\n",
      "415 - random_57 - knn_k=20 - 0.9569995861429946 - 0.790681582763425 - 1.4140202577190832 - 1.039614687046893 - 0.808090897527525 - 1.00185511588856 - 0.8352355432734035'\n",
      "416 - random_54 - knn_k=1 - 1.070151005774245 - 0.8313785730121711 - 1.1830349528213362 - 0.9713565211148387 - 0.9554703103006343 - 1.002267697058923 - 0.83516769043589'\n",
      "417 - random_57 - knn_k=5 - 0.9184345154017548 - 0.8006589535569079 - 1.4634357275553114 - 0.9821794691791161 - 0.8695645629502187 - 1.0068244039074237 - 0.8344182973186131'\n",
      "418 - random_56 - knn_k=100 - 0.8139123750582952 - 0.882775282291291 - 1.1850681619510637 - 1.0786459059370088 - 1.075292405606643 - 1.007106226087256 - 0.8343719490217214'\n",
      "419 - random_66 - knn_k=5 - 1.0276041922220691 - 0.7654092769366917 - 1.2380760414960994 - 1.185570018259378 - 0.8196579822556587 - 1.0072407642402093 - 0.8343498229624452'\n",
      "420 - random_52 - knn_k=5 - 0.9103929483912628 - 0.7832346424456775 - 1.183276174742776 - 1.2281115783928358 - 0.9316850810803596 - 1.0073071295005038 - 0.834338908573843'\n",
      "421 - random_2 - knn_k=10 - 0.9409581202941487 - 0.776209551731407 - 1.4202539881837293 - 1.0052971778110553 - 0.8941461152312667 - 1.0073424447347727 - 0.8343331006528211'\n",
      "422 - random_5 - lwr_k=100 - 0.9015314716144377 - 0.6517371870128372 - 1.538904138690518 - 1.2065822840424134 - 0.7420261995423302 - 1.0081087255036718 - 0.834207078603739'\n",
      "423 - random_52 - knn_k=10 - 0.93599229760085 - 0.768866976741233 - 1.164265067004055 - 1.2827084494480765 - 0.8975848431120126 - 1.009851202024602 - 0.8339205120206306'\n",
      "424 - random_27 - lwr_k=200 - 1.0873657757278168 - 0.7421789274879945 - 1.0937724211582314 - 1.2141070940781598 - 0.9186427832900877 - 1.0111936013238756 - 0.8336997418835645'\n",
      "425 - random_22 - lwr_k=1000 - 1.1197905787875728 - 0.8080830353756878 - 1.3049950408752773 - 0.940217271695414 - 0.8897676089440838 - 1.0125607227586715 - 0.8334749059597756'\n",
      "426 - random_40 - lwr_k=20 - 1.0326197553427365 - 0.6985642118967709 - 1.5061453727322274 - 0.8569795197668669 - 0.9688235571169563 - 1.0125962976803395 - 0.8334690553307288'\n",
      "427 - random_31 - knn_k=1 - 0.9591131655101363 - 1.0090629999560528 - 1.1624749026992434 - 1.003104046830487 - 0.9405134065539513 - 1.0148473882308167 - 0.833098842407014'\n",
      "428 - random_31 - knn_k=50 - 1.0207646860275388 - 0.8108754083282055 - 1.2870451387272253 - 0.9911245217180085 - 0.9719289742193064 - 1.0163271078039284 - 0.8328554886648362'\n",
      "429 - random_2 - lwr_k=20 - 0.856110923263099 - 0.9362797943002493 - 1.2403572497404802 - 1.012645191492763 - 1.036773388191544 - 1.016408624948722 - 0.8328420824069224'\n",
      "430 - random_36 - knn_k=1 - 1.0268586680398708 - 0.9447659811826293 - 1.1372189176254952 - 1.106938298335922 - 0.8735252228855886 - 1.0178548380423547 - 0.8326042391191013'\n",
      "431 - random_39 - knn_k=10 - 1.0304166472716507 - 0.7212004897112366 - 1.1251930313473038 - 1.331869341544425 - 0.883446246474714 - 1.0183958725626643 - 0.8325152609251535'\n",
      "432 - random_48 - knn_k=20 - 0.9665772870635374 - 0.7615534379502785 - 1.2356101950113587 - 1.3331759038355366 - 0.7990399185231989 - 1.0191595016309662 - 0.8323896749730693'\n",
      "433 - random_79 - knn_k=1 - 0.891913026465927 - 0.8030409132145814 - 1.3063793756501294 - 1.3118299274699512 - 0.7862767673776938 - 1.019852606627692 - 0.832275687365052'\n",
      "434 - random_39 - knn_k=5 - 1.019900410899437 - 0.7851633660795947 - 1.1350201259904174 - 1.2443615400283656 - 0.9202198419216683 - 1.0209087496202147 - 0.8321019947585774'\n",
      "435 - random_34 - knn_k=10 - 1.0038910228955664 - 0.7507439400033173 - 1.1014644741945534 - 1.4111076215764786 - 0.8406982929177608 - 1.021551453485495 - 0.8319962960886603'\n",
      "436 - random_2 - knn_k=20 - 0.9799687975783139 - 0.752902715558367 - 1.4539167537398254 - 1.0266862330975912 - 0.9069528069886647 - 1.0240530964357006 - 0.8315848774762504'\n",
      "437 - random_61 - lwr_k=1000 - 0.8552905012450065 - 0.7652727927450413 - 1.0599701143542064 - 1.6386639254455422 - 0.804668217531506 - 1.024729075884612 - 0.8314737063249614'\n",
      "438 - random_34 - knn_k=5 - 1.0185323294241626 - 0.7613894990734205 - 1.0946546349619222 - 1.3900882134973005 - 0.867737093911128 - 1.02645232718941 - 0.8311903015087004'\n",
      "439 - random_61 - lwr_k=500 - 0.8114348260143027 - 0.7620280133240829 - 1.0961485310602783 - 1.6644434030006479 - 0.7991822667377503 - 1.0265981540778417 - 0.8311663189111497'\n",
      "440 - random_2 - lr - 1.0188343255573469 - 0.7335469855709135 - 1.1535021760977018 - 1.2688665834901365 - 0.9633472728619061 - 1.0275883808869928 - 0.8310034668383715'\n",
      "441 - random_11 - knn_k=1 - 1.1144797986469033 - 0.9372009246608805 - 1.2479820800901626 - 0.9661529232593618 - 0.8799565376347764 - 1.0291537724865827 - 0.8307460235290741'\n",
      "442 - random_42 - lwr_k=20 - 1.2972061848443783 - 0.6827172250636058 - 1.256780898173149 - 1.0769846500379203 - 0.8389921830418469 - 1.0305278984183268 - 0.8305200356501612'\n",
      "443 - random_61 - lwr_k=200 - 0.7920689587297199 - 0.7597633222690029 - 1.132984214725138 - 1.6902242949559063 - 0.7809034090053515 - 1.0311364333060573 - 0.8304199563886133'\n",
      "444 - random_37 - knn_k=20 - 0.9396595154611186 - 0.9668732683119083 - 1.0027307434026407 - 1.2153484564730346 - 1.0349190975021476 - 1.0318900717373876 - 0.8302960134903468'\n",
      "445 - random_2 - knn_k=5 - 0.9639308659990837 - 0.8284842413905797 - 1.4493289134264982 - 1.0124160513422469 - 0.9112060636894672 - 1.0330451291048093 - 0.830106053488533'\n",
      "446 - random_41 - knn_k=50 - 1.2289508513455552 - 0.7945102610016043 - 1.128511652473503 - 1.1487883737097349 - 0.8646717855124292 - 1.0330822004873512 - 0.8300999567524803'\n",
      "447 - random_5 - lwr_k=50 - 0.9277642694278387 - 0.6637158637158437 - 1.5904698325584572 - 1.2422378344869136 - 0.7434753446580525 - 1.0334838109520945 - 0.8300339081502526'\n",
      "448 - random_41 - lr - 1.216825188608277 - 0.7695283566388845 - 1.0887676658047902 - 1.3972681566908822 - 0.6970748160029886 - 1.033884477877449 - 0.8299680147219141'\n",
      "449 - random_77 - lwr_k=100 - 1.087452735945147 - 0.6648703476960561 - 1.437557893268375 - 1.2573197476633837 - 0.7231932347701306 - 1.0340463719856279 - 0.8299413897195975'\n",
      "450 - random_37 - knn_k=1 - 0.979449744094476 - 0.8701308016569528 - 1.0775897163226664 - 1.4380796672764382 - 0.8098414308162517 - 1.03499564259399 - 0.8297852732776163'\n",
      "451 - random_13 - knn_k=20 - 1.129896060893094 - 0.7610480869916777 - 1.3673861345817935 - 1.0434547672317744 - 0.873602412869537 - 1.0350590968209925 - 0.8297748376357023'\n",
      "452 - random_61 - lwr_k=100 - 0.7795887399308388 - 0.7690487441277146 - 1.1581858975455315 - 1.6973863724426754 - 0.7716453169196492 - 1.035117462094706 - 0.8297652389198176'\n",
      "453 - random_1 - lwr_k=50 - 1.0676903585680078 - 0.7489399893140609 - 1.119170928424627 - 1.1400881340306428 - 1.1011776295210036 - 1.0353873151295352 - 0.8297208590609193'\n",
      "454 - random_0 - knn_k=1 - 1.0542666411109618 - 0.9895175265721319 - 1.1800682272333975 - 1.115133362364617 - 0.8406179165616301 - 1.035917854733457 - 0.829633606854262'\n",
      "455 - random_13 - knn_k=5 - 1.051311261107782 - 0.7945317821030818 - 1.3891327425638667 - 1.0296147282484178 - 0.9239689678545839 - 1.0376883302957334 - 0.8293424355665779'\n",
      "456 - random_66 - knn_k=20 - 1.0639273572997385 - 0.7521685431582329 - 1.3004963837800627 - 1.2381531049936385 - 0.8418070557609012 - 1.0392835412385537 - 0.829080088187012'\n",
      "457 - random_27 - lwr_k=100 - 1.119452510754037 - 0.7437592182360562 - 1.1213490737404026 - 1.277067287899107 - 0.9434384680471682 - 1.0409908507525498 - 0.828799305147552'\n",
      "458 - random_49 - lwr_k=500 - 0.9524355456580891 - 0.870891961884719 - 1.128270571496201 - 1.1872608281316839 - 1.0672112061482413 - 1.041187426427102 - 0.8287669764368336'\n",
      "459 - random_59 - knn_k=100 - 1.086277413909057 - 0.7563604446322691 - 1.2624560418476996 - 1.1835457493520185 - 0.9230950632002698 - 1.0423220959421293 - 0.8285803694082895'\n",
      "460 - random_68 - lwr_k=1000 - 1.2290731988046604 - 0.6748110601663917 - 1.2270241989823079 - 1.0673554526564857 - 1.040279012484274 - 1.0476889240860516 - 0.8276977442567534'\n",
      "461 - random_34 - lr - 1.0409188541972552 - 0.7656039035529747 - 1.26046771563895 - 1.3907483374584089 - 0.7834815971278062 - 1.0482143171313716 - 0.8276113384498586'\n",
      "462 - random_23 - knn_k=5 - 0.7871256792900134 - 0.8058024157398523 - 1.0938319382311794 - 1.8408578733899392 - 0.7256851238694926 - 1.050608420401244 - 0.8272176057450471'\n",
      "463 - random_49 - lwr_k=200 - 0.9392097272283227 - 0.8691039421547568 - 1.0995595508290092 - 1.2533509624823862 - 1.0944624328982973 - 1.0511071485161263 - 0.8271355852356944'\n",
      "464 - random_52 - knn_k=20 - 0.9791127165588127 - 0.774197460671267 - 1.2102949644576606 - 1.3873910064479906 - 0.9057319903188813 - 1.0513097643078233 - 0.8271022631711427'\n",
      "465 - random_68 - lwr_k=500 - 1.2522397505339449 - 0.6749206521395513 - 1.2185758578011154 - 1.0694830136084021 - 1.0458047722012878 - 1.052186614921422 - 0.8269580568755528'\n",
      "466 - random_57 - knn_k=50 - 1.0462969462275615 - 0.8128760024634878 - 1.4516530336898454 - 1.119783322271552 - 0.832484278984677 - 1.052593458619771 - 0.8268911476190466'\n",
      "467 - random_49 - lwr_k=1000 - 0.9829605845036122 - 0.877204422603241 - 1.1588486445174901 - 1.173685169418723 - 1.0758315453191152 - 1.053680693767259 - 0.826712341616493'\n",
      "468 - random_79 - knn_k=50 - 1.0068001275537417 - 0.7640067337182361 - 1.2812694838581962 - 1.229942163938841 - 0.9867625800587206 - 1.0537216555617022 - 0.8267056050657673'\n",
      "469 - random_17 - knn_k=1 - 1.2510478275579702 - 0.7694842875209794 - 1.3607888818874936 - 0.9910011090637953 - 0.898227720790132 - 1.054100964356514 - 0.826643224182027'\n",
      "470 - random_32 - knn_k=100 - 1.081148138168415 - 0.6946380100451346 - 1.3361716273407345 - 1.241315620736433 - 0.9204954790290673 - 1.0547195191204224 - 0.8265414970580001'\n",
      "471 - random_8 - knn_k=50 - 1.144321908216053 - 0.7110518202339823 - 1.1164185373657658 - 1.3056377276589741 - 0.9973467053878955 - 1.054929211980387 - 0.8265070111032911'\n",
      "472 - random_1 - lwr_k=20 - 1.0859003680207293 - 0.7579714781057986 - 1.1305163301526941 - 1.2073593057265761 - 1.103309388140229 - 1.05698364349113 - 0.8261691406004795'\n",
      "473 - random_61 - lwr_k=50 - 0.8088142011946167 - 0.7700604036906736 - 1.2133249682736462 - 1.7190878260738403 - 0.7750940762139319 - 1.0572213086404303 - 0.8261300543408135'\n",
      "474 - random_25 - knn_k=50 - 1.1791926682352711 - 0.7280244447056997 - 1.2691244783178437 - 1.11757249297978 - 0.9938525155470809 - 1.0575319804450252 - 0.8260789614529374'\n",
      "475 - random_40 - knn_k=10 - 1.0719711559671343 - 0.7264998416457489 - 1.5164087907745505 - 0.9763772211352013 - 0.9979523976375542 - 1.057809320072435 - 0.8260333503537731'\n",
      "476 - random_34 - knn_k=20 - 1.034863416644835 - 0.7637530845310423 - 1.1771730654550545 - 1.488120969874208 - 0.8266349941747699 - 1.0580765048517389 - 0.8259894093144857'\n",
      "477 - random_46 - lr - 1.0562297844745632 - 0.7286408594554589 - 1.536840142443675 - 1.0825538385431566 - 0.8939177351408505 - 1.0596021461749472 - 0.8257385033104223'\n",
      "478 - random_54 - knn_k=20 - 1.2316786209136752 - 0.8484282591206511 - 1.2790650038594524 - 1.1276337062176354 - 0.8132769344472378 - 1.0600124065613106 - 0.8256710321475729'\n",
      "479 - random_20 - knn_k=10 - 1.1257065810171742 - 0.8080084895245553 - 1.105658938298735 - 1.260097081860146 - 1.0111003258617393 - 1.062094727420858 - 0.8253285749801516'\n",
      "480 - random_53 - lwr_k=1000 - 1.1446958638798541 - 0.7776370502296428 - 1.326147355558622 - 0.9282050970911322 - 1.145819253684434 - 1.0644797098684466 - 0.8249363422799862'\n",
      "481 - random_82 - knn_k=10 - 0.9375035415473135 - 0.6961866537920516 - 1.2831881642084593 - 1.4179476478212105 - 0.9925905081141349 - 1.0654322585050866 - 0.824779686735554'\n",
      "482 - random_23 - knn_k=10 - 0.8238363136500243 - 0.8169831608704684 - 1.1385528193926002 - 1.8267059292769938 - 0.733811867180845 - 1.0679271931345817 - 0.8243693713693121'\n",
      "483 - random_61 - lr - 0.8887276313874557 - 0.7911724864604477 - 1.0706465387332489 - 1.7373052559591848 - 0.8585031232262259 - 1.069223928330026 - 0.8241561111217901'\n",
      "484 - random_82 - knn_k=20 - 0.937493404061056 - 0.6732384828546012 - 1.2866562225570557 - 1.4424923024838014 - 1.0219316515314893 - 1.0723075992159254 - 0.8236489725643469'\n",
      "485 - random_65 - knn_k=100 - 1.1361709204823354 - 0.8814101167961589 - 1.3362163442332855 - 1.0556573151395097 - 0.9555127276685411 - 1.072980304209845 - 0.8235383399278482'\n",
      "486 - random_84 - knn_k=20 - 1.0942643698154437 - 0.8521358752618221 - 1.2645742833029807 - 0.9244880929725919 - 1.2311772661430342 - 1.0733074215856124 - 0.8234845424117709'\n",
      "487 - random_85 - knn_k=10 - 1.2439196339707277 - 0.7001178495663991 - 1.0643881739178458 - 1.3674054427555025 - 0.9916781553427046 - 1.0734810169678846 - 0.823455993025341'\n",
      "488 - random_39 - knn_k=20 - 1.0864931379600784 - 0.6942463187404516 - 1.1873015215526908 - 1.497997828676872 - 0.9061452928215654 - 1.0743990315923764 - 0.8233050169226365'\n",
      "489 - random_20 - knn_k=20 - 1.1596704475192403 - 0.797121615389256 - 1.1132653847769387 - 1.2719461631585385 - 1.0355144800322735 - 1.0754836823126503 - 0.8231266359533427'\n",
      "490 - random_27 - lwr_k=50 - 1.1402774991070106 - 0.75317244718826 - 1.1550748906699793 - 1.3758283708679953 - 0.9663311454197422 - 1.0781098922277883 - 0.8226947311369124'\n",
      "491 - random_40 - knn_k=20 - 1.1283529124545935 - 0.7163228089167885 - 1.5395715217118557 - 1.0183848872576848 - 0.9961356774996625 - 1.0797212446514917 - 0.8224297291396414'\n",
      "492 - random_49 - lwr_k=100 - 0.9407563321344964 - 0.8678420167749837 - 1.0955981967152313 - 1.368598148067308 - 1.1260804484453397 - 1.0797390038218522 - 0.8224268084777513'\n",
      "493 - random_20 - knn_k=5 - 1.1356130560144517 - 0.8496057918835436 - 1.1308459537333186 - 1.2464608259600085 - 1.041331673802265 - 1.0807533609076787 - 0.8222599879549807'\n",
      "494 - random_2 - knn_k=50 - 1.0575738343545016 - 0.7558036406541007 - 1.4916882481510625 - 1.1458613952343504 - 0.9569551548287533 - 1.0815405507814575 - 0.8221305272077759'\n",
      "495 - random_9 - knn_k=50 - 1.301833465188657 - 0.9774179972788932 - 0.936333179206717 - 1.1462847414148696 - 1.055620210253653 - 1.0835094415206552 - 0.8218067246859809'\n",
      "496 - random_68 - lwr_k=200 - 1.327812222454531 - 0.6817746266748209 - 1.2340696927096453 - 1.1321065096101486 - 1.0606281116836636 - 1.0872612987714887 - 0.8211896966228951'\n",
      "497 - random_53 - lwr_k=500 - 1.1564747666401742 - 0.7797451775555458 - 1.3605482349253175 - 0.964265645244758 - 1.1806081865263796 - 1.0883037217370308 - 0.821018260403353'\n",
      "498 - random_22 - knn_k=10 - 1.1794916832548896 - 0.8169655007990377 - 1.2670068109284387 - 1.244455616112438 - 0.9380268444233376 - 1.089170617176493 - 0.8208756913293855'\n",
      "499 - random_46 - lwr_k=1000 - 1.147365883253328 - 0.7464201687543862 - 1.4947675026368699 - 1.0896833825899763 - 0.9697595201403801 - 1.08956999435623 - 0.820810010011793'\n",
      "500 - random_23 - lr - 0.9339251220227083 - 0.7564833148885006 - 1.3000931758996122 - 1.6369866112569198 - 0.8228715159180887 - 1.0900216774717006 - 0.8207357264931956'\n",
      "501 - random_77 - lwr_k=50 - 1.1075016153225732 - 0.6716026422171106 - 1.4605914406397342 - 1.474274386168905 - 0.7444491557478569 - 1.0916423510536748 - 0.8204691915441493'\n",
      "502 - random_85 - knn_k=5 - 1.28597779925659 - 0.7490240518666617 - 1.1108669040670813 - 1.3269581884119956 - 0.9857910691998423 - 1.0917083648932202 - 0.8204583349499804'\n",
      "503 - random_85 - knn_k=20 - 1.251919281701582 - 0.671643954593306 - 1.0837016916415148 - 1.440205662121284 - 1.0125575613360738 - 1.0919788957248349 - 0.8204138436210529'\n",
      "504 - random_52 - lr - 1.0312947309566587 - 0.762269243555383 - 1.1688935942120313 - 1.5494082323354377 - 0.9537842651999098 - 1.0930897036591933 - 0.8202311608529265'\n",
      "505 - random_40 - knn_k=5 - 1.0889561362425826 - 0.7796114912335184 - 1.590736440037548 - 0.9985048962880092 - 1.0108873687926043 - 1.0937065308479879 - 0.8201297178448066'\n",
      "506 - random_17 - knn_k=50 - 1.1085673488048366 - 0.8915630833976936 - 1.370761619461617 - 1.068025641592438 - 1.03106212027851 - 1.0939766790390646 - 0.8200852894446992'\n",
      "507 - random_49 - lwr_k=50 - 0.9387706641254697 - 0.8730063173140863 - 1.1038122980189098 - 1.4151984944802976 - 1.1441251041853409 - 1.0949437552419623 - 0.8199262447059374'\n",
      "508 - random_43 - knn_k=50 - 1.22324087861007 - 0.7562749195467157 - 1.195252164275402 - 1.207900598839209 - 1.1031058799503677 - 1.0971328400018634 - 0.8195662292152008'\n",
      "509 - random_74 - knn_k=100 - 1.2115730925973334 - 0.9190759022395972 - 1.17395653051778 - 1.0934364251577477 - 1.0883013121213183 - 1.0972620944986073 - 0.8195449721026725'\n",
      "510 - random_13 - lr - 1.321301442656411 - 0.7773299731332294 - 1.4184919660137547 - 1.020462565342632 - 0.9535619894981943 - 1.0982195454730785 - 0.8193875103228709'\n",
      "511 - random_20 - lr - 1.2532722244214718 - 0.7950364095751141 - 1.1680071610133838 - 1.2979310293719384 - 0.9825124081436231 - 1.0993364087039348 - 0.8192038317045243'\n",
      "512 - random_5 - lwr_k=20 - 1.0281066216672823 - 0.6768589629817808 - 1.651803752706428 - 1.3450767225838793 - 0.7982927512236514 - 1.0999769420786507 - 0.8190984899921084'\n",
      "513 - random_46 - lwr_k=500 - 1.1911325518271798 - 0.7448531345028626 - 1.4639657045020114 - 1.1174629039639068 - 0.9889319903249242 - 1.1012418958223993 - 0.8188904565019683'\n",
      "514 - random_41 - knn_k=100 - 1.3049957696982895 - 0.8136599207700993 - 1.1956163107733604 - 1.2857660472750192 - 0.9076038844820913 - 1.1015197229698466 - 0.818844765225568'\n",
      "515 - random_27 - lwr_k=20 - 1.1692737638010446 - 0.7625494407770578 - 1.180890106287339 - 1.4179714850918248 - 0.9802349243334326 - 1.1021559678023873 - 0.8187401288040774'\n",
      "516 - random_57 - knn_k=100 - 1.1120820241685168 - 0.8503724459718082 - 1.4784749163683593 - 1.220895711840584 - 0.8533180851481794 - 1.1030036312793234 - 0.8186007226064652'\n",
      "517 - random_20 - knn_k=50 - 1.2100353764328964 - 0.7910725143555964 - 1.1309283364966631 - 1.3006339364721589 - 1.0852720041659683 - 1.1035672809490191 - 0.8185080251393977'\n",
      "518 - random_22 - knn_k=20 - 1.18948291936227 - 0.8204071125443597 - 1.287371219205633 - 1.279759919590439 - 0.9411184937373225 - 1.1036076736153844 - 0.8185013821871145'\n",
      "519 - random_49 - lwr_k=20 - 0.941634064108747 - 0.8943292083159422 - 1.1406407975097133 - 1.3910256398928753 - 1.150611303227666 - 1.1036100858862097 - 0.8185009854665851'\n",
      "520 - random_10 - lwr_k=200 - 0.7755034396617405 - 0.7509625818442893 - 1.365789457225601 - 1.8859046354581406 - 0.7520772213134925 - 1.105977088439937 - 0.8181117097283568'\n",
      "521 - random_61 - lwr_k=20 - 0.8600030677983993 - 0.7789634522475165 - 1.2753177506699087 - 1.8040118932316163 - 0.8129992951480495 - 1.1062002177004784 - 0.8180750140317338'\n",
      "522 - random_82 - knn_k=5 - 0.9708708164159819 - 0.7351326629987359 - 1.3494056747254974 - 1.4723008691722204 - 1.0159658641147298 - 1.1086826762664272 - 0.8176667504709871'\n",
      "523 - random_13 - knn_k=50 - 1.2701706511401876 - 0.7604032430374451 - 1.4325317170594682 - 1.1807148756173629 - 0.9025613526806121 - 1.1092570721934414 - 0.8175722856812591'\n",
      "524 - random_10 - lwr_k=500 - 0.7928911081201957 - 0.7668288532890748 - 1.3582220677368473 - 1.8544950764984907 - 0.7744022904019088 - 1.1093002323403842 - 0.817565187590876'\n",
      "525 - random_80 - knn_k=100 - 1.3835242448841878 - 1.030110023001335 - 1.1886087992970753 - 1.0817393909894149 - 0.862694351764159 - 1.10935537466881 - 0.8175561189185284'\n",
      "526 - random_10 - lwr_k=100 - 0.7725257292365076 - 0.7504041396782272 - 1.3587052861119409 - 1.9232285061447243 - 0.7432959859993025 - 1.1095604519151554 - 0.8175223920447069'\n",
      "527 - random_66 - knn_k=50 - 1.142389069571021 - 0.7904406578311678 - 1.3884309030883581 - 1.3488821434475862 - 0.8807759434094137 - 1.110154228199592 - 0.817424739973693'\n",
      "528 - random_31 - knn_k=100 - 1.1365122041567168 - 0.8444470244588366 - 1.4248206057431634 - 1.0944929355404942 - 1.051306129024257 - 1.1102911778209332 - 0.8174022173258557'\n",
      "529 - random_60 - lwr_k=1000 - 1.1805158502734547 - 0.7669156669556036 - 1.2703735748845335 - 1.2863858718823276 - 1.0474634364656528 - 1.1103028334650353 - 0.8174003004460216'\n",
      "530 - random_50 - lwr_k=1000 - 1.0663631397663853 - 0.7575180264694493 - 1.2659136845699448 - 1.3493342302213567 - 1.1200814912643506 - 1.1118010753428509 - 0.8171539005373638'\n",
      "531 - random_53 - lwr_k=20 - 1.1305830287063907 - 0.8105354895125907 - 1.3978187667574427 - 1.0410612604969114 - 1.1883434359213834 - 1.113639016451974 - 0.8168516339086491'\n",
      "532 - random_82 - knn_k=50 - 0.9762853754130194 - 0.6707162235647592 - 1.3132328825282045 - 1.5352407716332448 - 1.0814771175804 - 1.1153305501704798 - 0.8165734453465066'\n",
      "533 - random_50 - lr - 0.9467500439911904 - 0.764854055440325 - 1.2809973425892895 - 1.4219512599435498 - 1.1727103376497585 - 1.1173988919387934 - 0.8162332871715603'\n",
      "534 - random_22 - knn_k=5 - 1.2418812048361836 - 0.8723076198994624 - 1.2652740275365144 - 1.259816797586471 - 0.9492453349684552 - 1.1176925538152227 - 0.8161849917256782'\n",
      "535 - random_52 - knn_k=50 - 1.0651469973051149 - 0.795704372193329 - 1.2700852140954724 - 1.5390778453691447 - 0.9195943600542988 - 1.1178832654870987 - 0.8161536274051194'\n",
      "536 - random_27 - lr - 1.0900168718875904 - 0.7382937817076346 - 1.210430496906197 - 1.6539109956280482 - 0.9008999986081675 - 1.1186684344695663 - 0.8160244990124176'\n",
      "537 - random_48 - knn_k=50 - 1.024700727649056 - 0.8089730776576232 - 1.4118216073650454 - 1.5210828351068364 - 0.834447033963263 - 1.1201633055469495 - 0.8157786534634602'\n",
      "538 - random_1 - knn_k=10 - 1.153366663546537 - 0.7942043019821651 - 1.161078449146357 - 1.3386631456876836 - 1.1545401798530974 - 1.120340454619789 - 0.8157495196393343'\n",
      "539 - random_53 - lwr_k=200 - 1.1745741024042284 - 0.7792023146232885 - 1.3973187956531294 - 1.0337325195002094 - 1.2241150963448748 - 1.1217588181467002 - 0.8155162564735869'\n",
      "540 - random_23 - knn_k=20 - 0.8961089007920093 - 0.8399844001282567 - 1.1984246554634561 - 1.9251359281052054 - 0.7497666577111697 - 1.1218319964593215 - 0.8155042216147216'\n",
      "541 - random_10 - lwr_k=50 - 0.7672325897677702 - 0.7627630570883321 - 1.3603467755110648 - 1.9781983530333374 - 0.7451115558614098 - 1.1226570249379044 - 0.8153685379545776'\n",
      "542 - random_68 - lwr_k=100 - 1.3831011066353789 - 0.688335331074843 - 1.266462636102808 - 1.1983948632668855 - 1.081582990706271 - 1.123557348774913 - 0.8152204712675586'\n",
      "543 - random_10 - lwr_k=1000 - 0.8168566820334643 - 0.774649566515501 - 1.3593672157255439 - 1.8780662488250426 - 0.7972118229190122 - 1.1251626666405983 - 0.8149564617098707'\n",
      "544 - random_50 - lwr_k=500 - 1.085495788380428 - 0.7583115192874098 - 1.290391262036678 - 1.374160555524031 - 1.1235785651521175 - 1.1263455582189696 - 0.8147619241113837'\n",
      "545 - random_53 - knn_k=20 - 1.1515272002153778 - 0.8131502477221059 - 1.404866976420005 - 1.0754580364227386 - 1.1990286233480185 - 1.1287761475394953 - 0.8143621909338308'\n",
      "546 - random_46 - lwr_k=200 - 1.2422998337777693 - 0.7533136724505326 - 1.466048552553168 - 1.1811271951530857 - 1.0024325414529192 - 1.129017416436156 - 0.8143225120041603'\n",
      "547 - random_48 - knn_k=1 - 1.1635597859024254 - 0.7753498449521566 - 1.1593947679516186 - 1.4594564262698306 - 1.0902008705380557 - 1.1295594634250765 - 0.8142333673002671'\n",
      "548 - random_10 - lwr_k=20 - 0.7809424250781831 - 0.7693224759045428 - 1.360711863931384 - 2.0279009751582557 - 0.7164542279915438 - 1.1309933215653334 - 0.8139975559002395'\n",
      "549 - random_60 - lwr_k=500 - 1.18858994283672 - 0.7685898924181939 - 1.284979448808794 - 1.3747885537191014 - 1.0497602373551207 - 1.133309845021961 - 0.8136165819222935'\n",
      "550 - random_1 - knn_k=5 - 1.1712221955662296 - 0.8556799350711644 - 1.1818411689886725 - 1.285307627180652 - 1.1727541444457907 - 1.1333363971392452 - 0.813612215177931'\n",
      "551 - random_53 - lwr_k=50 - 1.1756845266471034 - 0.795075959383015 - 1.41187083667907 - 1.0718837467800584 - 1.2152762900071021 - 1.1339277693271317 - 0.8135149584831105'\n",
      "552 - random_53 - lwr_k=100 - 1.1797940854767228 - 0.7847028389854279 - 1.4075084688442434 - 1.0746338710751724 - 1.2255850025246808 - 1.1344136079714464 - 0.8134350577679095'\n",
      "553 - random_20 - knn_k=100 - 1.259520468668265 - 0.7967711779869288 - 1.1545550038538177 - 1.337907032228176 - 1.1243511480067627 - 1.1345991071582706 - 0.8134045506893354'\n",
      "554 - random_53 - knn_k=10 - 1.159184698784787 - 0.8463098567053879 - 1.411412132373434 - 1.0714766540052167 - 1.1855651734954158 - 1.1347625952047866 - 0.8133776635489313'\n",
      "555 - random_76 - knn_k=1 - 1.1613635111261384 - 1.0663048384394922 - 1.2391192538378886 - 1.0869293841387644 - 1.1435079720273627 - 1.1394397340988747 - 0.8126084642538458'\n",
      "556 - random_2 - knn_k=100 - 1.1263233754614044 - 0.770190982169582 - 1.533537811604998 - 1.2674402711026198 - 1.0113066745072226 - 1.1417200975238455 - 0.8122334371317641'\n",
      "557 - random_79 - knn_k=100 - 1.1337174515907906 - 0.7810524627522961 - 1.3390759998590809 - 1.3732678986697404 - 1.0969566622465279 - 1.1447756164488867 - 0.8117309284279424'\n",
      "558 - random_27 - knn_k=10 - 1.2070315307093384 - 0.7969505368384783 - 1.2379077507083964 - 1.4660481189508743 - 1.0275444360618378 - 1.1470666849923439 - 0.8113541407488664'\n",
      "559 - random_78 - knn_k=10 - 0.8610336054865398 - 0.7883735363841792 - 1.414328167531334 - 1.9039496947446495 - 0.7724304002429923 - 1.1479567044644834 - 0.811207768711156'\n",
      "560 - random_1 - knn_k=20 - 1.176162732961124 - 0.7609276467554849 - 1.1837495049797595 - 1.4880900727007145 - 1.144398475872712 - 1.150628297925403 - 0.8107684001455802'\n",
      "561 - random_34 - knn_k=50 - 1.0738744612855347 - 0.7895964180186957 - 1.3315424782060488 - 1.7303183425877222 - 0.8298147962161095 - 1.1509842789672748 - 0.810709855729288'\n",
      "562 - random_46 - lwr_k=100 - 1.2604352414444253 - 0.7597770573288222 - 1.483874395982643 - 1.2530877875034976 - 0.9996143345217943 - 1.151328764872564 - 0.8106532017958652'\n",
      "563 - random_49 - knn_k=10 - 1.0099912402960312 - 0.9088451376076877 - 1.2162366546428414 - 1.467746443890039 - 1.157109505965842 - 1.1519462629950585 - 0.8105516484464148'\n",
      "564 - random_50 - lwr_k=200 - 1.1026359498308258 - 0.7584825852286087 - 1.334278474058195 - 1.4358279132028324 - 1.1402468355955477 - 1.1542484195191385 - 0.8101730372450804'\n",
      "565 - random_71 - lwr_k=500 - 1.5191374568052987 - 0.7392255186690556 - 0.7001770042018175 - 1.3429256978714037 - 1.4708944158510315 - 1.1544668266183495 - 0.8101371181521136'\n",
      "566 - random_85 - knn_k=50 - 1.2993281914693873 - 0.6662031924115795 - 1.1604968841730605 - 1.574220085525397 - 1.073867207648172 - 1.1547877894328926 - 0.8100843328112705'\n",
      "567 - random_54 - lr - 1.4370351897205003 - 0.7626507797591263 - 1.2890383215802328 - 1.3939672415706166 - 0.9040516289582804 - 1.1573368266007367 - 0.8096651197758974'\n",
      "568 - random_78 - knn_k=5 - 0.8324939132165922 - 0.788328211586509 - 1.4845110531405408 - 1.8833699223828606 - 0.7983775215354829 - 1.1573448853943697 - 0.8096637944318094'\n",
      "569 - random_68 - lwr_k=50 - 1.4351993966776149 - 0.6983326599393067 - 1.2831623994897772 - 1.272709981621899 - 1.0981119699819335 - 1.1574846534876546 - 0.8096408082598644'\n",
      "570 - random_49 - knn_k=20 - 0.992301238851526 - 0.9010827415325187 - 1.168790616100298 - 1.5480000432795706 - 1.1828277788980148 - 1.1585569796277788 - 0.8094644541832028'\n",
      "571 - random_8 - knn_k=100 - 1.2640431878747878 - 0.7208571509811477 - 1.213766883027193 - 1.5405202813442742 - 1.0589828409455009 - 1.159599746539486 - 0.8092929613984925'\n",
      "572 - random_82 - knn_k=100 - 1.0355269693475353 - 0.6820602685608158 - 1.3470675600978645 - 1.6104929537736012 - 1.1267009818118716 - 1.1603078341484827 - 0.809176509759567'\n",
      "573 - random_40 - knn_k=50 - 1.2509132885487468 - 0.7016083948471942 - 1.5933231244398196 - 1.2351658998306907 - 1.0211786069741122 - 1.160400052001972 - 0.8091613436698902'\n",
      "574 - random_25 - knn_k=100 - 1.306591354420966 - 0.7197978835903797 - 1.3761121992614298 - 1.3462735219857345 - 1.0658892288080557 - 1.1629020968581074 - 0.8087498589602862'\n",
      "575 - random_27 - knn_k=5 - 1.1858547336382028 - 0.8567211574940994 - 1.2624087452017623 - 1.4658784119225303 - 1.0446760986550272 - 1.163078714234754 - 0.8087208125785788'\n",
      "576 - random_42 - knn_k=20 - 1.4848735114202045 - 0.654955049982947 - 1.3219894945586828 - 1.411891052402871 - 0.9477114575721326 - 1.1642647393765515 - 0.8085257596362388'\n",
      "577 - random_22 - knn_k=50 - 1.2452225660441758 - 0.8107399757110562 - 1.3773749395633468 - 1.4060593790923832 - 0.9871254107658382 - 1.165276262245346 - 0.8083594052270031'\n",
      "578 - random_46 - lwr_k=20 - 1.3014501595751005 - 0.7733079820636078 - 1.5125362694964635 - 1.2295500517097762 - 1.0180472422331088 - 1.1669517347191227 - 0.8080838580869785'\n",
      "579 - random_46 - lwr_k=50 - 1.2876425149944206 - 0.7655899240501777 - 1.4946121372584908 - 1.2871393149299968 - 1.0086127074714677 - 1.1686901464499604 - 0.8077979599966696'\n",
      "580 - random_66 - lr - 1.2053366856177055 - 0.7144579992781065 - 1.4182687533362044 - 1.5853515867403951 - 0.9319199410797436 - 1.171023640787774 - 0.807414194998371'\n",
      "581 - random_78 - knn_k=20 - 0.9053107952356749 - 0.7870960792276351 - 1.4072797854405943 - 1.961370789287983 - 0.7955406607693857 - 1.1712528767274708 - 0.8073764950011685'\n",
      "582 - random_42 - knn_k=10 - 1.4691579069239826 - 0.6710031379932305 - 1.3543172084816555 - 1.4034904659245198 - 0.9606280124908054 - 1.1716984802524086 - 0.8073032113281728'\n",
      "583 - random_37 - knn_k=50 - 1.0698888848821266 - 1.1564620122586455 - 1.0807424026973855 - 1.318218559590688 - 1.237422973385179 - 1.1725347777888382 - 0.8071656743659251'\n",
      "584 - random_60 - lwr_k=200 - 1.2195554222983713 - 0.7729181073155625 - 1.3064457344976441 - 1.5174988318829892 - 1.067929456730884 - 1.1768324272468482 - 0.8064588856627279'\n",
      "585 - random_61 - knn_k=20 - 0.9776878261206928 - 0.7915820968910955 - 1.349922619794164 - 1.9159254753322117 - 0.8639109335516749 - 1.179745192754549 - 0.8059798540953513'\n",
      "586 - random_50 - lwr_k=100 - 1.1303948335829865 - 0.761410077501957 - 1.376174258234882 - 1.4917227436486635 - 1.1437957193080281 - 1.1806513234023548 - 0.8058308324239127'\n",
      "587 - random_61 - knn_k=10 - 0.9495125205809026 - 0.8123998563807977 - 1.368105886520214 - 1.9162568757700331 - 0.8645577634275629 - 1.1821047430503642 - 0.8055918039507312'\n",
      "588 - random_78 - lr - 0.8548526835037963 - 0.7382540349899506 - 1.4516157400241936 - 2.0244663658829594 - 0.8621300025570879 - 1.1861837591493178 - 0.8049209715510512'\n",
      "589 - random_53 - knn_k=5 - 1.2031497358478216 - 0.9122484374485138 - 1.4770028552463208 - 1.109173089309602 - 1.2333059107280224 - 1.1869494655971753 - 0.8047950439544431'\n",
      "590 - random_71 - lwr_k=1000 - 1.5743325209043952 - 0.7478787740108062 - 0.7058360512665482 - 1.3991881886320297 - 1.513380473975113 - 1.1881176551442905 - 0.8046029242426889'\n",
      "591 - random_46 - knn_k=10 - 1.3185494183780835 - 0.7975378390852441 - 1.543400754175598 - 1.2284226772607412 - 1.0533730805630501 - 1.1882300215736847 - 0.8045844445310022'\n",
      "592 - random_12 - lwr_k=100 - 1.3134698177854602 - 0.7442031972976193 - 1.2584016929038873 - 1.7997475853457268 - 0.8276664101943079 - 1.188664921729181 - 0.8045129211273541'\n",
      "593 - random_77 - lwr_k=20 - 1.1543587623093277 - 0.7084636619770173 - 1.4775889462897354 - 1.8412735822377635 - 0.7640589586183508 - 1.1890958696257647 - 0.8044420477096991'\n",
      "594 - random_13 - knn_k=100 - 1.3812689752920866 - 0.7677938073983462 - 1.503420823434161 - 1.3664608523731725 - 0.9377709547033938 - 1.1913191015909004 - 0.8040764163912545'\n",
      "595 - random_51 - knn_k=1 - 1.1019141453319456 - 1.1917399041377255 - 1.2933661598717376 - 1.182218920014417 - 1.189317163803675 - 1.1917020440488788 - 0.8040134379175753'\n",
      "596 - random_53 - knn_k=50 - 1.2597801845344183 - 0.8035053274849013 - 1.4369504005377596 - 1.2194829406439813 - 1.2437593637499482 - 1.1926625797713595 - 0.8038554688220733'\n",
      "597 - random_12 - lwr_k=200 - 1.3128842607129343 - 0.7382783647336424 - 1.2642494737584038 - 1.8096473958541257 - 0.8467921742640571 - 1.194335682043417 - 0.8035803114839195'\n",
      "598 - random_12 - lwr_k=50 - 1.3159381204763618 - 0.7622795576861225 - 1.2630587026049722 - 1.8147054378489424 - 0.8161853945667222 - 1.1944015550152824 - 0.80356947805676'\n",
      "599 - random_85 - lr - 1.3168753269140585 - 0.6584236299367626 - 1.166802519273179 - 1.8101579852090974 - 1.0236751754285214 - 1.195144320608549 - 0.8034473232985431'\n",
      "600 - random_27 - knn_k=20 - 1.2954663381750153 - 0.764193414624233 - 1.2830831296053782 - 1.6016825616928787 - 1.0367209698635653 - 1.19619512155091 - 0.8032745092422489'\n",
      "601 - random_52 - knn_k=100 - 1.1690032841141305 - 0.8355851940844711 - 1.3281045388518202 - 1.686420016488278 - 0.9848930869557874 - 1.200760471279148 - 0.8025236947224538'\n",
      "602 - random_49 - knn_k=5 - 1.0270306489643022 - 0.9706694085453047 - 1.3053859130417864 - 1.4844101776278629 - 1.2179975665330598 - 1.2010572219582325 - 0.8024748912940466'\n",
      "603 - random_42 - knn_k=50 - 1.5645293350405554 - 0.6522616180936577 - 1.3607081954137341 - 1.4502170217210035 - 0.9833474014731208 - 1.2021934539834418 - 0.8022880272960693'\n",
      "604 - random_39 - knn_k=50 - 1.1835126187470821 - 0.6876741232754208 - 1.275673653817697 - 1.8998752325218835 - 0.9683868506518482 - 1.2029695930877808 - 0.8021603839513953'\n",
      "605 - random_10 - lr - 1.1576166146611924 - 0.801640626945411 - 1.346470923950467 - 1.7693734001812078 - 0.9465778116744318 - 1.2042897438351023 - 0.8019432727970677'\n",
      "606 - random_66 - knn_k=100 - 1.249515127435511 - 0.8565361581402343 - 1.4919013936264724 - 1.4898452103582613 - 0.9372282456139296 - 1.2049740261348105 - 0.8018307361642043'\n",
      "607 - random_50 - lwr_k=50 - 1.1636184095333586 - 0.7674164953887845 - 1.4058869904074043 - 1.534007186121506 - 1.1557714847697025 - 1.2052908784544196 - 0.8017786268327501'\n",
      "608 - random_54 - knn_k=50 - 1.4397988849629633 - 0.9900678153104583 - 1.4376838260184361 - 1.2917499098894616 - 0.8713296033634288 - 1.2061278160268367 - 0.80164098461059'\n",
      "609 - random_5 - knn_k=20 - 1.266452538146813 - 0.6768075207520179 - 1.693144031558607 - 1.5315965278414687 - 0.8862625327960127 - 1.2108035186195651 - 0.8008720215287148'\n",
      "610 - random_71 - lwr_k=200 - 1.6052457650187149 - 0.723934200240552 - 0.7037331609859847 - 1.4533174494905567 - 1.579107587178552 - 1.213057680283559 - 0.8005013035316195'\n",
      "611 - random_5 - knn_k=10 - 1.280191098419419 - 0.690477609426963 - 1.7147181583786737 - 1.5170166033144699 - 0.8678275037629106 - 1.2139992408849303 - 0.8003464550724964'\n",
      "612 - random_43 - knn_k=100 - 1.313511627087855 - 0.7540335537116826 - 1.3201836925332269 - 1.4807501087868098 - 1.2092403940008152 - 1.2155065581875713 - 0.8000985626252297'\n",
      "613 - random_50 - lwr_k=20 - 1.1817339727508391 - 0.7786482736803533 - 1.4194936655479753 - 1.530113039800236 - 1.1821520901201 - 1.2183792991035378 - 0.7996261134768159'\n",
      "614 - random_12 - lwr_k=500 - 1.324410398055054 - 0.7461324028694478 - 1.281088146270374 - 1.8526267030459984 - 0.8912309773506987 - 1.2190599865889251 - 0.799514168044835'\n",
      "615 - random_49 - knn_k=50 - 1.0352530165167873 - 0.888248524152741 - 1.1786775636982705 - 1.773707592205528 - 1.2205709526846549 - 1.2192386575954854 - 0.7994847839244549'\n",
      "616 - random_22 - lr - 1.218864734612787 - 0.8702414598786765 - 1.5189366918735692 - 1.491135042059514 - 1.0027870349389865 - 1.2203568933305948 - 0.7993008795849296'\n",
      "617 - random_17 - knn_k=100 - 1.1993866649022977 - 0.9996572958977789 - 1.5046651946045337 - 1.2092517653531314 - 1.1909635662326858 - 1.2207600025270122 - 0.7992345845022416'\n",
      "618 - random_8 - knn_k=1 - 1.1591185463036096 - 1.0280601350725085 - 1.3117711765446567 - 1.3058411042840914 - 1.299223824465022 - 1.22077684080418 - 0.7992318152898616'\n",
      "619 - random_60 - lwr_k=100 - 1.2553026091391266 - 0.7770021692234826 - 1.345518031409966 - 1.6430143748829398 - 1.0845267586744882 - 1.2210307191937189 - 0.7991900626109927'\n",
      "620 - random_23 - knn_k=50 - 1.0156213438422266 - 0.8949815999608507 - 1.343272401513358 - 2.085451684926191 - 0.7757113160672768 - 1.222952710075497 - 0.798873973209993'\n",
      "621 - random_46 - knn_k=5 - 1.2879063163669655 - 0.8524720597770645 - 1.6469094617845366 - 1.2576252609252936 - 1.0787700309744674 - 1.2247048978938335 - 0.7985858095130745'\n",
      "622 - random_61 - knn_k=50 - 1.0648874227257088 - 0.7910437714737848 - 1.3688295071159844 - 2.0075756234340085 - 0.8944076657246884 - 1.2252877463188148 - 0.7984899546308935'\n",
      "623 - random_42 - knn_k=5 - 1.5040049017874613 - 0.7218733464913936 - 1.4514777924488655 - 1.4215823299232804 - 1.029358291317348 - 1.2256361913121145 - 0.7984326495883682'\n",
      "624 - random_7 - lr - 1.1026173550505345 - 0.6843253372683744 - 1.7863718522294851 - 1.4446193488341 - 1.1110860489758985 - 1.2257357616923084 - 0.7984162743068145'\n",
      "625 - random_12 - lwr_k=20 - 1.3724510781952937 - 0.7797937607136818 - 1.2587329278895614 - 1.8954810587736037 - 0.8228525206574151 - 1.2258315281558287 - 0.7984005246149835'\n",
      "626 - random_46 - knn_k=20 - 1.4012665314659198 - 0.7761091740207063 - 1.5661472404404573 - 1.3438277863634007 - 1.0462918742463663 - 1.2267001820200445 - 0.7982576663515968'\n",
      "627 - random_68 - lwr_k=20 - 1.496251936836019 - 0.7293480904165393 - 1.3279360684715407 - 1.434309814472302 - 1.1490042603363821 - 1.2273465132647419 - 0.7981513711251622'\n",
      "628 - random_48 - knn_k=100 - 1.0808063643689687 - 0.891837911672562 - 1.6219368997078776 - 1.6710344935549721 - 0.8722940704241788 - 1.2275324181140703 - 0.7981207973315899'\n",
      "629 - random_85 - knn_k=100 - 1.3508548295904397 - 0.6672941193060766 - 1.2419800489947175 - 1.731573085886153 - 1.1618849793542039 - 1.2306719100728019 - 0.7976044784759247'\n",
      "630 - random_22 - knn_k=100 - 1.2836394035378214 - 0.8205585941683738 - 1.504535330401731 - 1.5247919878089387 - 1.0478369035478066 - 1.236234633700974 - 0.7966896364773359'\n",
      "631 - random_34 - knn_k=100 - 1.1100312593831467 - 0.817129342747888 - 1.458757008661872 - 1.9426876021102069 - 0.8552713008860764 - 1.2367192167381926 - 0.7966099422584813'\n",
      "632 - random_10 - knn_k=10 - 0.9376898537818582 - 0.8023484229614061 - 1.4058700096612815 - 2.178501029929152 - 0.8692792970778761 - 1.2386620259908119 - 0.7962904290814214'\n",
      "633 - random_49 - lr - 1.2180895379040844 - 0.9022623859570715 - 1.2887265278460638 - 1.5188608926282183 - 1.269698043448755 - 1.2394906572908506 - 0.7961541529035466'\n",
      "634 - random_50 - knn_k=10 - 1.2053896880622526 - 0.8175018399505314 - 1.4182768789998956 - 1.5438761576779685 - 1.2223370974613614 - 1.241429107924464 - 0.7958353565422032'\n",
      "635 - random_61 - knn_k=5 - 0.9791394985055157 - 0.881907011029965 - 1.4543007617836055 - 2.000061692199833 - 0.8939397745785248 - 1.2418058292263763 - 0.7957734011959036'\n",
      "636 - random_5 - knn_k=50 - 1.3331680627529776 - 0.6750257315164923 - 1.6734139763307818 - 1.5948248379730892 - 0.9394382384350917 - 1.2431250876377227 - 0.7955564367945842'\n",
      "637 - random_42 - knn_k=100 - 1.6272625153656255 - 0.6628588971361025 - 1.419172903472409 - 1.4970873128209237 - 1.0197073605337386 - 1.2451972359500108 - 0.7952156525978311'\n",
      "638 - random_50 - knn_k=20 - 1.2235462495285399 - 0.779743070537224 - 1.442833758084042 - 1.5867606523125735 - 1.2025742795825394 - 1.2470412125731438 - 0.7949123933723117'\n",
      "639 - random_59 - knn_k=1 - 1.3201349247300445 - 1.0373898707876936 - 1.4472797451612338 - 1.3024688090699936 - 1.1380342651318947 - 1.2490470908010094 - 0.7945825079115972'\n",
      "640 - random_10 - knn_k=20 - 0.98332392829251 - 0.787168049772826 - 1.391990578971939 - 2.2016576848559564 - 0.8858399296368296 - 1.2499211523422935 - 0.7944387603050708'\n",
      "641 - random_66 - knn_k=1 - 1.183728503131937 - 0.9325408467704924 - 1.6088592228394007 - 1.4275942794309735 - 1.1042313822285512 - 1.2513511720348738 - 0.7942035801737128'\n",
      "642 - random_30 - lwr_k=500 - 1.2670236588458994 - 0.7970285766713816 - 1.3109404911961116 - 1.7157328932851117 - 1.172982291270391 - 1.252696270107506 - 0.7939823661980925'\n",
      "643 - random_78 - knn_k=50 - 1.0039714804750428 - 0.8425694961430424 - 1.4297550050379566 - 2.13174221639954 - 0.8658332213704312 - 1.2547062272652938 - 0.793651809919151'\n",
      "644 - random_12 - lwr_k=1000 - 1.330016941408199 - 0.7521293859830328 - 1.3084220534169817 - 1.9339770207178073 - 0.9532265736252953 - 1.2555103627511965 - 0.7935195623073276'\n",
      "645 - random_53 - knn_k=100 - 1.3335717998889787 - 0.7977926355163825 - 1.4574042025391887 - 1.4124020593909583 - 1.2837517401807206 - 1.256945213787417 - 0.7932835876162598'\n",
      "646 - random_60 - lwr_k=50 - 1.2822246006311901 - 0.7830266750010655 - 1.366851215400649 - 1.7537469486168888 - 1.1018315848323306 - 1.2574900315096296 - 0.7931939872393273'\n",
      "647 - random_30 - lwr_k=200 - 1.2720614332768974 - 0.8007398469561366 - 1.3283233314146294 - 1.7225217154343782 - 1.166080574964066 - 1.2578998980154024 - 0.7931265808538299'\n",
      "648 - random_9 - knn_k=100 - 1.5602375551714902 - 1.113537197250614 - 1.0667819973919537 - 1.3707646466538639 - 1.192710164778271 - 1.2608219314370772 - 0.7926460250912013'\n",
      "649 - random_30 - lwr_k=1000 - 1.2769096313276862 - 0.7993809294824589 - 1.3153339908933037 - 1.7420732328548474 - 1.1740992001924757 - 1.2615135307796463 - 0.7925322851021114'\n",
      "650 - random_84 - knn_k=50 - 1.3391360749732206 - 0.9710125909858706 - 1.476285993866408 - 1.0442362657378845 - 1.4794204970768174 - 1.2619963292926575 - 0.7924528843649756'\n",
      "651 - random_40 - knn_k=100 - 1.3697554512301962 - 0.7031956351609998 - 1.6452328535045646 - 1.5303762316941627 - 1.06643009538999 - 1.2629515490826588 - 0.7922957895243565'\n",
      "652 - random_10 - knn_k=5 - 0.9003425544723613 - 0.8523581727003529 - 1.4517814738895014 - 2.241437552922413 - 0.8715034029684813 - 1.263405154020923 - 0.7922211899440017'\n",
      "653 - random_12 - knn_k=20 - 1.3891536890500122 - 0.772253433900407 - 1.3196851386080293 - 1.983598059502613 - 0.869312768712969 - 1.2667624128518542 - 0.7916690572866979'\n",
      "654 - random_50 - knn_k=5 - 1.2390622390647532 - 0.8683870985045502 - 1.4384081362996304 - 1.5416749546660224 - 1.2601795859518732 - 1.269498096238751 - 0.791219148532558'\n",
      "655 - random_23 - knn_k=1 - 0.8005167590589366 - 0.8617893994853331 - 1.3146511729625063 - 2.4616744038196248 - 0.9159415185588436 - 1.270824369198009 - 0.7910010305231396'\n",
      "656 - random_69 - lwr_k=200 - 1.1811381417204618 - 0.7036215389458852 - 1.7497714516978655 - 1.565268054569411 - 1.1561253493262773 - 1.271117404672034 - 0.7909528380949994'\n",
      "657 - random_30 - lwr_k=100 - 1.2802360324752975 - 0.8046854084200277 - 1.3440301718616718 - 1.7668471954374598 - 1.173230427184102 - 1.2737583526953733 - 0.7905185094586449'\n",
      "658 - random_18 - knn_k=1 - 1.0804656951520126 - 1.204182045104869 - 1.4424881138484325 - 1.3293101456403968 - 1.319925568095806 - 1.2752470192871619 - 0.790273684295452'\n",
      "659 - random_5 - knn_k=5 - 1.3178936267453232 - 0.7325641800397023 - 1.7958095547100914 - 1.6157528004072412 - 0.9181936171974855 - 1.2759912645753728 - 0.7901512861875433'\n",
      "660 - random_69 - lwr_k=100 - 1.1719824959892717 - 0.7042801826742973 - 1.7538730056883882 - 1.5935268339294366 - 1.1593055814769087 - 1.2765241347780574 - 0.7900636506920922'\n",
      "661 - random_1 - knn_k=50 - 1.2864918339102567 - 0.7596546521657479 - 1.2804132113161582 - 1.8953262999760299 - 1.1640856790667384 - 1.2771421650771217 - 0.7899620098212208'\n",
      "662 - random_7 - lwr_k=1000 - 1.106298466046144 - 0.6792672615663354 - 1.898843874852009 - 1.5812094351462307 - 1.1299019392557694 - 1.2790248848966876 - 0.7896523789141968'\n",
      "663 - random_60 - lwr_k=20 - 1.304612584755994 - 0.8058479004935125 - 1.3891867768670656 - 1.7699432463812481 - 1.130522563964321 - 1.2799764653707144 - 0.7894958825931737'\n",
      "664 - random_69 - lwr_k=500 - 1.1962291725043435 - 0.7026592865601029 - 1.752584484624126 - 1.5787724095114994 - 1.170501720679672 - 1.2800815221080688 - 0.7894786050288023'\n",
      "665 - random_12 - knn_k=10 - 1.4150046116153516 - 0.7861310164371197 - 1.345198478983517 - 1.990314806115088 - 0.8716619580736735 - 1.2816249961787998 - 0.7892247662623955'\n",
      "666 - random_7 - lwr_k=500 - 1.1045533349188668 - 0.6804301352047313 - 1.903811692388008 - 1.591812808253477 - 1.1351549347126222 - 1.2830723797311328 - 0.7889867304816791'\n",
      "667 - random_32 - knn_k=1 - 1.2677988303267678 - 1.0330830438999838 - 1.6032230975214985 - 1.3462294112096864 - 1.1699955313217072 - 1.284038550081192 - 0.7888278347189004'\n",
      "668 - random_69 - lwr_k=50 - 1.1898246731766629 - 0.7056503181629947 - 1.7678059507747939 - 1.5945982236239644 - 1.1667308524815714 - 1.2848527807928427 - 0.7886939268526554'\n",
      "669 - random_30 - lwr_k=50 - 1.2956458773834971 - 0.8175703197534994 - 1.3671916281603147 - 1.786166845271676 - 1.17750209670674 - 1.2887676820827605 - 0.788050084670346'\n",
      "670 - random_61 - knn_k=100 - 1.1627203028282185 - 0.7999883350149515 - 1.402412889234906 - 2.1391825896491747 - 0.9510960494164384 - 1.2910164475760366 - 0.7876802541240633'\n",
      "671 - random_12 - knn_k=50 - 1.3749267618108996 - 0.7627079298184692 - 1.3582747074049186 - 2.0315660812376577 - 0.9350490909729875 - 1.2924589919397205 - 0.787443014193242'\n",
      "672 - random_5 - knn_k=100 - 1.3972143536758892 - 0.6816229773773206 - 1.6841182159329318 - 1.7055783356840248 - 0.9966843869866461 - 1.2929915855699574 - 0.7873554241827201'\n",
      "673 - random_26 - lwr_k=100 - 1.4150759355834326 - 0.6761004712712041 - 1.6183228453387966 - 1.6413199318381897 - 1.1316962028021336 - 1.296451565382777 - 0.7867863980979068'\n",
      "674 - random_69 - lwr_k=1000 - 1.217872127981885 - 0.700210694795907 - 1.7678686183423522 - 1.6133492141102996 - 1.1849723431513133 - 1.2967852477592323 - 0.7867315209059816'\n",
      "675 - random_7 - lwr_k=200 - 1.1243807187291415 - 0.6859431796346387 - 1.9073096749151104 - 1.6354382436144088 - 1.1415232855148352 - 1.2988381834725322 - 0.7863938964010686'\n",
      "676 - random_49 - knn_k=100 - 1.0983020641607422 - 0.890700739231939 - 1.2055590316396154 - 2.0472216950206144 - 1.259906976651644 - 1.3002753140899062 - 0.7861575468115306'\n",
      "677 - random_50 - knn_k=50 - 1.3136429961040519 - 0.7707087641382396 - 1.473694571690865 - 1.7430809543936974 - 1.2037956259787699 - 1.3009314499005948 - 0.7860496391323937'\n",
      "678 - random_26 - lwr_k=200 - 1.41556903609502 - 0.6726494965355457 - 1.606625288624881 - 1.6817533840664076 - 1.1350190374623133 - 1.3022702380903501 - 0.785829462876108'\n",
      "679 - random_27 - knn_k=50 - 1.426955310050834 - 0.7561230875573112 - 1.3635598872083046 - 1.8994870801296617 - 1.0865397633147624 - 1.3064888881389647 - 0.7851356663656583'\n",
      "680 - random_26 - lwr_k=50 - 1.4325108477877706 - 0.6862229913887419 - 1.6375076224013594 - 1.663269167882012 - 1.1226471525799921 - 1.3083804242714898 - 0.7848245855333986'\n",
      "681 - random_69 - knn_k=50 - 1.2260965214199542 - 0.6994088602308238 - 1.7794908079751186 - 1.6568983403314135 - 1.18495625874691 - 1.3092989983347847 - 0.7846735174257435'\n",
      "682 - random_30 - lwr_k=20 - 1.3089549683070227 - 0.8453937906714243 - 1.3904926823461383 - 1.8109675805348584 - 1.1938898415194958 - 1.3098919867194778 - 0.7845759949322216'\n",
      "683 - random_69 - knn_k=20 - 1.2094020246441286 - 0.7109451676855796 - 1.8194314803529728 - 1.6190130381064773 - 1.1930127268090374 - 1.310288995240568 - 0.7845107031627273'\n",
      "684 - random_69 - lwr_k=20 - 1.206029679290217 - 0.7245309920424474 - 1.8141741312024136 - 1.610203798173312 - 1.20530415491906 - 1.311977360771259 - 0.7842330356387426'\n",
      "685 - random_7 - lwr_k=100 - 1.1625982286404215 - 0.6886509767520804 - 1.911778030871744 - 1.6622215769058137 - 1.1421899708292613 - 1.3134081297922469 - 0.7839977322733102'\n",
      "686 - random_26 - lwr_k=500 - 1.428748160458421 - 0.6703458408605538 - 1.5984327573303245 - 1.7288043480002975 - 1.1456863796714911 - 1.3143491231117634 - 0.7838429771090007'\n",
      "687 - random_10 - knn_k=50 - 1.0786993891734113 - 0.778906392493469 - 1.4386830705313791 - 2.3402767153529567 - 0.9401284972331069 - 1.3152594584255315 - 0.7836932639408657'\n",
      "688 - random_71 - lwr_k=100 - 1.7735298439526814 - 0.7373885221102352 - 0.7121394437425634 - 1.648723889019722 - 1.7217895321961854 - 1.3187012601514807 - 0.7831272274126859'\n",
      "689 - random_60 - knn_k=10 - 1.3643919423050426 - 0.8393152998922798 - 1.4110298198253566 - 1.777062456275297 - 1.203392997764205 - 1.3189939158829116 - 0.7830790974367718'\n",
      "690 - random_34 - knn_k=1 - 1.3615537739777575 - 1.002868473281592 - 1.1218621933341295 - 1.89983954040576 - 1.2215983613951955 - 1.3215158638094453 - 0.7826643394808377'\n",
      "691 - random_63 - lwr_k=500 - 1.2662188056081713 - 0.7724306217486494 - 1.3010315444863345 - 2.1617272122936098 - 1.1069477572075785 - 1.3216091175493878 - 0.7826490030299321'\n",
      "692 - random_68 - knn_k=20 - 1.5812387080986907 - 0.7236667877739358 - 1.382493497250895 - 1.7464765533681001 - 1.180327891605167 - 1.322805707545516 - 0.782452212598352'\n",
      "693 - random_7 - lwr_k=50 - 1.1893467445141597 - 0.6912259033365692 - 1.9044268654950558 - 1.6845566658293598 - 1.1505670527904244 - 1.3239458661996282 - 0.7822647028294765'\n",
      "694 - random_60 - knn_k=20 - 1.3533340377868215 - 0.8039782095926429 - 1.4068585201169035 - 1.9000329103530293 - 1.1632618075756358 - 1.3254424222803678 - 0.7820185801659362'\n",
      "695 - random_69 - knn_k=100 - 1.2418513753156333 - 0.7056239375158596 - 1.7691701649212648 - 1.709214340539706 - 1.2017292204377232 - 1.3254455884581438 - 0.7820180594583479'\n",
      "696 - random_39 - knn_k=100 - 1.2913553911733135 - 0.6879083892669972 - 1.3505954486958098 - 2.271596381518662 - 1.0267718686229004 - 1.325576513386714 - 0.7819965276276614'\n",
      "697 - random_63 - lwr_k=1000 - 1.296267177375583 - 0.7707994532664877 - 1.3004508573582916 - 2.1662278568826303 - 1.1045487246111916 - 1.3275984309182214 - 0.7816640043532462'\n",
      "698 - random_23 - knn_k=100 - 1.1531602930655867 - 0.9696875109043909 - 1.4987266348171608 - 2.2042993622240226 - 0.8274268957800444 - 1.330604866059663 - 0.7811695679373338'\n",
      "699 - random_30 - knn_k=20 - 1.3516614906870679 - 0.8462394675272078 - 1.412980300835064 - 1.8494274834027875 - 1.199686966110514 - 1.3319512976019545 - 0.7809481346601395'\n",
      "700 - random_26 - lwr_k=1000 - 1.4429306699184818 - 0.6738403133413707 - 1.6028127779418928 - 1.7953873947876509 - 1.1600551746467773 - 1.3349484770131927 - 0.780455220435744'\n",
      "701 - random_68 - knn_k=10 - 1.5875439007284697 - 0.7566371423145357 - 1.4063655638124213 - 1.7417143976531457 - 1.1966992079484156 - 1.3377580245236353 - 0.7799931640347093'\n",
      "702 - random_63 - lwr_k=200 - 1.2572757293084083 - 0.7789887315341844 - 1.3194761793524623 - 2.223975265200781 - 1.1145203428674433 - 1.3387814079324278 - 0.7798248590485906'\n",
      "703 - random_37 - knn_k=100 - 1.2126936253949407 - 1.3833587503628835 - 1.176073982207673 - 1.4359315977017864 - 1.4911421558756741 - 1.3398314380683063 - 0.7796521717586413'\n",
      "704 - random_30 - knn_k=50 - 1.37300377838505 - 0.8181568986178527 - 1.4171473696857768 - 1.8985382066462504 - 1.1984160901226224 - 1.3410020740846147 - 0.7794596497021156'\n",
      "705 - random_46 - knn_k=50 - 1.5453353451019054 - 0.7709300702579421 - 1.614773877876076 - 1.7030989755930424 - 1.0764177442870264 - 1.3420734324538404 - 0.7792834547844419'\n",
      "706 - random_12 - knn_k=100 - 1.3981312169725546 - 0.757928637652102 - 1.4093756993740763 - 2.1585476268905612 - 0.995179187300874 - 1.3437779052647374 - 0.7790031382673739'\n",
      "707 - random_78 - knn_k=100 - 1.1523284359239845 - 0.9000807423786888 - 1.4700364294096278 - 2.2418851811599843 - 0.955478289088591 - 1.343896581096909 - 0.7789836209153094'\n",
      "708 - random_30 - lr - 1.3600087185823997 - 0.8073403291877376 - 1.4229604063622854 - 1.9367579515225304 - 1.2075665670912403 - 1.3468727497390016 - 0.7784941621086773'\n",
      "709 - random_68 - knn_k=50 - 1.5905576428290757 - 0.7112373642285076 - 1.3989716409863557 - 1.8718893851580505 - 1.1664410549475752 - 1.3477789902199147 - 0.7783451223741555'\n",
      "710 - random_26 - lwr_k=20 - 1.4726821956075047 - 0.7107185623126268 - 1.685606923791876 - 1.7170374664240036 - 1.155627275225617 - 1.3482817985492066 - 0.7782624308353296'\n",
      "711 - random_7 - lwr_k=20 - 1.2178848623552945 - 0.7139081345970134 - 1.9539342926127516 - 1.6907606534445014 - 1.1739455117239477 - 1.350007817985817 - 0.7779785707738671'\n",
      "712 - random_63 - lwr_k=100 - 1.2742050438588652 - 0.7904010019050406 - 1.3347212854230008 - 2.262868381956363 - 1.1222405755193592 - 1.3568206216752787 - 0.7768581414015188'\n",
      "713 - random_30 - knn_k=100 - 1.381248639519134 - 0.8045959686098861 - 1.4335024137639076 - 1.9674936215389869 - 1.2095368276065128 - 1.3592208127890562 - 0.7764634074937612'\n",
      "714 - random_26 - knn_k=50 - 1.5052556643459605 - 0.6969525994583409 - 1.6409343036584143 - 1.8314944357899419 - 1.1475287819500517 - 1.3643790964728684 - 0.7756150794318226'\n",
      "715 - random_19 - lwr_k=200 - 1.335158062611931 - 0.786027870832648 - 1.5156033075404658 - 2.2318144696279076 - 0.9600790893335095 - 1.3656739150307076 - 0.7754021343933051'\n",
      "716 - random_60 - knn_k=5 - 1.4118298559294271 - 0.9047764641482751 - 1.50571782711495 - 1.7230190007950292 - 1.28584393121312 - 1.366194727633262 - 0.7753164818831214'\n",
      "717 - random_52 - knn_k=1 - 1.129511450911339 - 0.9544369275975371 - 1.7597308800417735 - 1.6580816403725902 - 1.3303466328570217 - 1.3663548984075606 - 0.7752901402992014'\n",
      "718 - random_19 - lwr_k=500 - 1.3361111472239902 - 0.7866841340279834 - 1.517890643480002 - 2.228476563820621 - 0.9685326439111496 - 1.3674761766906824 - 0.7751057355841603'\n",
      "719 - random_26 - knn_k=20 - 1.5109104141467533 - 0.699559197421231 - 1.684954276549623 - 1.8077754106923993 - 1.1449214035296873 - 1.3695698622222634 - 0.7747614093899867'\n",
      "720 - random_54 - knn_k=100 - 1.6845099665183447 - 1.122918628155345 - 1.6106776641715872 - 1.4968447059339343 - 0.9374842284156345 - 1.3704938600839904 - 0.7746094492878826'\n",
      "721 - random_7 - knn_k=50 - 1.2820529158595813 - 0.7081203866321726 - 1.9099098501653557 - 1.7262332982372537 - 1.2275278397204379 - 1.3706917318230472 - 0.7745769074272181'\n",
      "722 - random_7 - knn_k=20 - 1.261676923532832 - 0.7166848791287362 - 1.9538517978146739 - 1.7019035605094623 - 1.2203056245893482 - 1.3708061946317867 - 0.7745580829463143'\n",
      "723 - random_19 - lwr_k=100 - 1.3360204149197048 - 0.7931590495795605 - 1.5189989755384898 - 2.2547118058838946 - 0.9591914220712415 - 1.3723531378274123 - 0.7743036736498283'\n",
      "724 - random_19 - lwr_k=1000 - 1.3555271570925964 - 0.7910474460736485 - 1.5205907313021614 - 2.2252999378600067 - 0.9782856419863245 - 1.374088416720209 - 0.7740182907840761'\n",
      "725 - random_12 - knn_k=5 - 1.524999503612148 - 0.8579251183649454 - 1.4840453370671687 - 2.097246437903503 - 0.9128453582202727 - 1.375374586705945 - 0.7738067680842395'\n",
      "726 - random_63 - lwr_k=50 - 1.300299137027838 - 0.7997364895142436 - 1.3537082108296277 - 2.3022373902670297 - 1.1263408377578252 - 1.376397394684772 - 0.7736385577329676'\n",
      "727 - random_30 - knn_k=10 - 1.3675033191064028 - 0.873388477417009 - 1.4789707728895238 - 1.8896439824989728 - 1.2742003919849092 - 1.3766887721728112 - 0.7735906379761508'\n",
      "728 - random_10 - knn_k=100 - 1.1815848091987082 - 0.7907514082131754 - 1.4825590521818612 - 2.4412827952646152 - 1.008158983975309 - 1.3807863793210224 - 0.7729167481043051'\n",
      "729 - random_50 - knn_k=100 - 1.4073478634909369 - 0.7705342972817368 - 1.5090526551671624 - 1.997103933473857 - 1.221065946635155 - 1.3809609761921504 - 0.7728880340136535'\n",
      "730 - random_60 - knn_k=50 - 1.4172033840060665 - 0.782155604582976 - 1.4093693314616873 - 2.1333032309485884 - 1.1638611372444685 - 1.3811207468371467 - 0.7728617582347447'\n",
      "731 - random_8 - lwr_k=50 - 1.1840577393840777 - 1.1786084786035984 - 1.5180454796891576 - 1.7669142298792793 - 1.2631299189999734 - 1.3821099420354386 - 0.7726990758200338'\n",
      "732 - random_43 - knn_k=1 - 1.3697178890495374 - 1.2238025378158441 - 1.3978522618900744 - 1.4441914905158035 - 1.4822599092777473 - 1.3835469970150205 - 0.7724627386698392'\n",
      "733 - random_19 - lwr_k=50 - 1.3608538939385975 - 0.7944891422587392 - 1.5314014623969445 - 2.2637671273445723 - 0.9723103594552867 - 1.38450139299774 - 0.7723057793120429'\n",
      "734 - random_26 - knn_k=100 - 1.535059763042972 - 0.715050500156559 - 1.625020251545774 - 1.8958977101355294 - 1.1664616692070564 - 1.3874441001792663 - 0.7718218235559857'\n",
      "735 - random_19 - knn_k=50 - 1.3543284270741776 - 0.7953903587330284 - 1.5317165287423968 - 2.2684592552514573 - 1.0011251695519834 - 1.3901392086887225 - 0.7713785877204468'\n",
      "736 - random_25 - knn_k=1 - 1.387796009611251 - 1.1895848916897942 - 1.525980317171424 - 1.4087630746037432 - 1.4476946908995068 - 1.3919425951227675 - 0.771082003931672'\n",
      "737 - random_7 - knn_k=100 - 1.3323708890683645 - 0.727373840229338 - 1.9226132450070674 - 1.7406512651173267 - 1.2383320316986401 - 1.3921938555607158 - 0.7710406817994606'\n",
      "738 - random_69 - lr - 1.325745393901587 - 0.6999647160093287 - 1.800435307929014 - 1.8937889218400956 - 1.244266778942196 - 1.392762214040854 - 0.7709472099244152'\n",
      "739 - random_19 - knn_k=100 - 1.3553077609080273 - 0.7959765761341254 - 1.520392221129613 - 2.2929897262486114 - 1.004597120163417 - 1.3937873533634029 - 0.7707786161618341'\n",
      "740 - random_7 - knn_k=10 - 1.2799723106036929 - 0.7468068924166609 - 1.9899092134364949 - 1.7234384015117918 - 1.2455679605051013 - 1.3970601732364882 - 0.7702403702819649'\n",
      "741 - random_64 - lwr_k=200 - 1.4965363074501539 - 0.6792709771751749 - 1.357325618545533 - 2.251535864901816 - 1.2149292059868178 - 1.3998555389809613 - 0.7697806462051638'\n",
      "742 - random_64 - lwr_k=500 - 1.490210954013567 - 0.6810557866760698 - 1.3629225532827678 - 2.2600299812405353 - 1.2072570721177467 - 1.400230670431212 - 0.7697189523248598'\n",
      "743 - random_64 - lwr_k=100 - 1.4952942488884076 - 0.6835146716903646 - 1.3710368773632384 - 2.244550570662943 - 1.2175379497555858 - 1.4023226094320376 - 0.7693749133640262'\n",
      "744 - random_57 - knn_k=1 - 1.2260192895717181 - 0.9533185679240652 - 2.270447828377734 - 1.1857355978117345 - 1.3785467992256053 - 1.402749329025646 - 0.7693047353303959'\n",
      "745 - random_69 - knn_k=10 - 1.2689200638169866 - 0.741309523967954 - 1.9385331148526934 - 1.818062955037431 - 1.2583662501514163 - 1.4049562785910255 - 0.7689417818050848'\n",
      "746 - random_60 - lr - 1.4376335177141784 - 0.7731515214798367 - 1.421529127082176 - 2.2634860132985435 - 1.1331558897829497 - 1.405729543024837 - 0.7688146112269019'\n",
      "747 - random_32 - deep - 1.5259817744475748 - 0.7063289868825519 - 1.7145784773865764 - 1.9690116335479142 - 1.119566555875038 - 1.407033765030243 - 0.7686001206349085'\n",
      "748 - random_68 - knn_k=5 - 1.6650911532128025 - 0.8114268365976027 - 1.5115025714198642 - 1.7717711594036625 - 1.2806304940417645 - 1.4080495783389515 - 0.7684330596911018'\n",
      "749 - random_27 - knn_k=100 - 1.5269768122905965 - 0.7497694191139621 - 1.4348189074423972 - 2.204814334720164 - 1.1296956351032876 - 1.409159418797101 - 0.7682505360334988'\n",
      "750 - random_64 - lwr_k=50 - 1.5020295974185411 - 0.6876488871411025 - 1.3837708929538173 - 2.257762961248999 - 1.2201703237835362 - 1.4102117742890743 - 0.7680774663169615'\n",
      "751 - random_68 - knn_k=100 - 1.620396834303094 - 0.7133405743479247 - 1.452914779004832 - 2.1083195169519233 - 1.1708057483131384 - 1.4131049287311217 - 0.767601659973'\n",
      "752 - random_63 - lwr_k=20 - 1.3356641572618804 - 0.8097099597321078 - 1.3844821487227235 - 2.3845769496203717 - 1.160365776553385 - 1.4148895309299556 - 0.7673081654276304'\n",
      "753 - random_64 - lwr_k=1000 - 1.49192872815557 - 0.6818849347950416 - 1.3795537183755875 - 2.3074849148186263 - 1.2174332302111155 - 1.4155896139400868 - 0.7671930302199557'\n",
      "754 - random_77 - knn_k=10 - 1.256025429946395 - 0.6908082783737169 - 1.5503210948285924 - 2.7558927279092167 - 0.8404746835563098 - 1.4186130268709547 - 0.7666958016475659'\n",
      "755 - random_19 - lwr_k=20 - 1.3951162381549216 - 0.8173005366194286 - 1.6010955317488675 - 2.306128562243212 - 0.9890116691394909 - 1.4216657319457513 - 0.7661937557077703'\n",
      "756 - random_19 - knn_k=20 - 1.3892728356949657 - 0.8168675785692556 - 1.600576532218671 - 2.3040175009059696 - 0.9990910400965877 - 1.4218996294432273 - 0.7661552890737329'\n",
      "757 - random_77 - knn_k=20 - 1.2338933736736375 - 0.6716144400327736 - 1.5500000524727848 - 2.837265404837042 - 0.8331612903706804 - 1.4250899233622896 - 0.7656306153599033'\n",
      "758 - random_26 - knn_k=10 - 1.5415325210459125 - 0.7339309905207899 - 1.7782880043611964 - 1.8933887756355023 - 1.1932688934178415 - 1.4280222290961841 - 0.7651483702193242'\n",
      "759 - random_1 - knn_k=100 - 1.4149145950571844 - 0.7595608977352836 - 1.4244715163264876 - 2.3622214777447623 - 1.1823453277919755 - 1.4286326613059006 - 0.7650479789254063'\n",
      "760 - random_19 - lr - 1.3942033995042662 - 0.8253668286676694 - 1.5420736039890808 - 2.379249682312403 - 1.0185087885010042 - 1.4318143354980855 - 0.7645247228063902'\n",
      "761 - random_83 - lwr_k=100 - 3.5456417863041425 - 1.2780103059583774 - 0.8472761161066598 - 0.7721687532020886 - 0.7294885415655045 - 1.434717738883463 - 0.7640472309277111'\n",
      "762 - random_63 - knn_k=20 - 1.3815105814471877 - 0.8026649875349718 - 1.4151093139631044 - 2.4208853252100004 - 1.1666648336638727 - 1.4372961236945865 - 0.763623191397544'\n",
      "763 - random_63 - knn_k=50 - 1.3994518634586233 - 0.7872417149308327 - 1.4442956843549428 - 2.4306083608050213 - 1.1383059860694795 - 1.439909559137344 - 0.7631933874627365'\n",
      "764 - random_28 - lwr_k=100 - 1.3633765944315162 - 0.8343502605993872 - 1.3320312215520955 - 2.5789644771508944 - 1.0936704424901 - 1.4404084667932016 - 0.7631113374261889'\n",
      "765 - random_60 - knn_k=100 - 1.4850369877486806 - 0.779920178821742 - 1.4307680867611454 - 2.337978000398267 - 1.1826753547442983 - 1.4432119160823427 - 0.7626502839347603'\n",
      "766 - random_30 - knn_k=5 - 1.4301396257424506 - 0.937617344278787 - 1.491023669955745 - 2.0006961725237766 - 1.3604811707733626 - 1.4439381963034295 - 0.7625308403503929'\n",
      "767 - random_16 - lwr_k=200 - 1.5408333872299511 - 0.7964700149541442 - 1.4900019133573108 - 2.213240774631523 - 1.186064812745379 - 1.4452653810600542 - 0.762312572387358'\n",
      "768 - random_64 - lwr_k=20 - 1.548325408147056 - 0.7027687263387484 - 1.4116310292684167 - 2.3150219239335623 - 1.2505115828215283 - 1.445586017684934 - 0.7622598406914598'\n",
      "769 - random_28 - lwr_k=200 - 1.3693032341978915 - 0.840670671700754 - 1.344332103449381 - 2.580083801910915 - 1.0976886419711642 - 1.4463455964687073 - 0.7621349208465994'\n",
      "770 - random_28 - lwr_k=50 - 1.365559524049525 - 0.8399729020151719 - 1.3307321134789727 - 2.598871715119881 - 1.1007887180958644 - 1.4471142865285778 - 0.7620085025670527'\n",
      "771 - random_77 - knn_k=5 - 1.3182229062088955 - 0.7321761796822331 - 1.6539972783718182 - 2.67919103770312 - 0.8634369892441541 - 1.4493177903062415 - 0.7616461157338031'\n",
      "772 - random_41 - knn_k=1 - 1.6019694782913823 - 1.3027003614680897 - 1.731441921969487 - 1.3220503526890142 - 1.2893263252441873 - 1.4494982704066564 - 0.7616164340909954'\n",
      "773 - random_83 - lwr_k=200 - 3.666370546628323 - 1.3014700048957246 - 0.8422337104282666 - 0.740655351911479 - 0.6959775375314198 - 1.4495538258539726 - 0.7616072974773773'\n",
      "774 - random_63 - lr - 1.371666169935812 - 0.7716376839420712 - 1.415553430701649 - 2.5645721855833385 - 1.130023177196974 - 1.4506127141152594 - 0.7614331533857435'\n",
      "775 - random_46 - knn_k=100 - 1.6351821152779042 - 0.7734007727259276 - 1.6495944751030054 - 2.096322318165891 - 1.1012272775146978 - 1.4510947134680672 - 0.7613538840779879'\n",
      "776 - random_16 - lwr_k=500 - 1.5435777699079551 - 0.8014624808310121 - 1.4953418304840318 - 2.230827934160306 - 1.1885810474094525 - 1.4519008448543451 - 0.761221308221655'\n",
      "777 - random_16 - lwr_k=100 - 1.5458976383525938 - 0.8009688003220613 - 1.4969013810204177 - 2.2306421265858223 - 1.195119860723268 - 1.4538483812854428 - 0.7609010176158217'\n",
      "778 - random_28 - lwr_k=500 - 1.393517106417152 - 0.844859311127262 - 1.3514084024106494 - 2.5842883816053406 - 1.0985684221569896 - 1.4544594805398303 - 0.7608005166201605'\n",
      "779 - random_30 - deep - 1.4467996706284885 - 0.8744164644417975 - 1.4930515360293692 - 2.2231520534296054 - 1.2423759231332392 - 1.4558984950912293 - 0.7605638581639244'\n",
      "780 - random_71 - lwr_k=50 - 1.9580967321330343 - 0.7563906354404308 - 0.7395607114822684 - 1.9079322492777089 - 1.9300888265014495 - 1.4583930610743117 - 0.7601536024611413'\n",
      "781 - random_20 - knn_k=1 - 1.47976865834168 - 1.1689480697814827 - 1.666357475626451 - 1.530439962758683 - 1.4564506070849474 - 1.4603650272724042 - 0.7598292941513276'\n",
      "782 - random_78 - knn_k=1 - 0.9726284196572224 - 0.9116767571381568 - 2.0277093201909864 - 2.5323136196977982 - 0.8610261510843924 - 1.4609643213703492 - 0.759730734624205'\n",
      "783 - random_28 - lwr_k=1000 - 1.40697254591286 - 0.8496898909098058 - 1.357826355307644 - 2.5893304613084815 - 1.1028990053487802 - 1.4612752854193196 - 0.7596795936740042'\n",
      "784 - random_16 - lwr_k=50 - 1.5536678477819996 - 0.8087107705310115 - 1.517827809457797 - 2.238155147213608 - 1.1992569651224767 - 1.4634657457140772 - 0.7593193519636778'\n",
      "785 - random_19 - knn_k=10 - 1.4475175131325313 - 0.830257415559689 - 1.6266092828613938 - 2.369170987483315 - 1.0458348156776394 - 1.4638112834728672 - 0.7592625250430955'\n",
      "786 - random_12 - lr - 1.401259886742673 - 0.7982634096743909 - 1.4299008513236555 - 2.5902301576930586 - 1.1045801299882008 - 1.4647719363065526 - 0.7591045366875591'\n",
      "787 - random_16 - lwr_k=1000 - 1.5487112569844286 - 0.8060569570202819 - 1.50287339302862 - 2.275794895088912 - 1.1912357286519064 - 1.4648754130324415 - 0.7590875189708708'\n",
      "788 - random_64 - knn_k=20 - 1.559768942636389 - 0.7024777074282544 - 1.430927795937999 - 2.3672296309606424 - 1.2753839316080162 - 1.4670886150017408 - 0.7587235371791778'\n",
      "789 - random_64 - knn_k=50 - 1.5259091591782068 - 0.6905246243188313 - 1.4355356380384332 - 2.4236955750658464 - 1.2679451260312626 - 1.4686480140291278 - 0.758467079404503'\n",
      "790 - random_28 - knn_k=50 - 1.4183159058722203 - 0.8410581910498319 - 1.3599618466096959 - 2.610242184451833 - 1.1220586731953208 - 1.4702574279196698 - 0.7582023962171658'\n",
      "791 - random_63 - knn_k=100 - 1.4075548497968857 - 0.7863319221361814 - 1.4724148919362101 - 2.5443436487952096 - 1.142514206724731 - 1.4705551868756037 - 0.7581534269681878'\n",
      "792 - random_84 - knn_k=100 - 1.6016292284843072 - 1.1215247204575207 - 1.7171984989950613 - 1.1690179977315793 - 1.7488038858437287 - 1.471612271785537 - 0.7579795794545734'\n",
      "793 - random_28 - knn_k=100 - 1.450079841569472 - 0.8469371251118036 - 1.3760582976796967 - 2.5832168955557346 - 1.121405811194871 - 1.4754724558296073 - 0.7573447360358003'\n",
      "794 - random_16 - knn_k=50 - 1.559026496279354 - 0.8081577703928603 - 1.5167370035668168 - 2.2774376891914945 - 1.2170161157507082 - 1.475615051398041 - 0.7573212848590863'\n",
      "795 - random_77 - knn_k=50 - 1.2661744468533807 - 0.673315734576861 - 1.58459215776268 - 2.9682150731292545 - 0.8865314130885097 - 1.4756618807310042 - 0.7573135833366983'\n",
      "796 - random_16 - knn_k=100 - 1.5497514211164547 - 0.8014123062143138 - 1.4976651930396063 - 2.323525637114885 - 1.2124405863332564 - 1.4768971570402176 - 0.7571104305786128'\n",
      "797 - random_63 - knn_k=10 - 1.4124617931063417 - 0.8310749669041512 - 1.4685657625737087 - 2.4847996721208694 - 1.192758066534749 - 1.4778589330378957 - 0.7569522575082388'\n",
      "798 - random_64 - knn_k=100 - 1.521678134294438 - 0.6926785840043144 - 1.46039750074744 - 2.476284354036388 - 1.2729606374024114 - 1.4847223176701976 - 0.7558235096261221'\n",
      "799 - random_28 - lwr_k=20 - 1.4100407177373124 - 0.8585229799397162 - 1.3650655449320368 - 2.656215036724751 - 1.1392645816065439 - 1.4857496022181789 - 0.7556545630611274'\n",
      "800 - random_16 - lwr_k=20 - 1.5744918985279772 - 0.8375696782849107 - 1.5548471549964564 - 2.263360561917215 - 1.2342344342041405 - 1.492841852143894 - 0.7544881761380609'\n",
      "801 - random_7 - knn_k=5 - 1.3813648145515856 - 0.809200354348629 - 2.1923034082335096 - 1.7868944701725142 - 1.2955074054652356 - 1.4929724293951685 - 0.7544667014861618'\n",
      "802 - random_16 - knn_k=20 - 1.5749245552979054 - 0.8372107367462416 - 1.5540032800933945 - 2.2586062966859117 - 1.2447123273630794 - 1.4938323499757145 - 0.7543252794930665'\n",
      "803 - random_28 - knn_k=20 - 1.4217766745206255 - 0.8599560660129209 - 1.3767294056677835 - 2.6561515923103576 - 1.1566077677185251 - 1.4941717539393335 - 0.7542694613325464'\n",
      "804 - random_7 - deep - 1.3660897631838482 - 0.724116054145173 - 2.0701176456846984 - 2.122990587164 - 1.2014157757377233 - 1.4968531973565342 - 0.7538284738404208'\n",
      "805 - random_39 - knn_k=1 - 1.5263599288329899 - 1.2507493362330646 - 1.6622010288768965 - 1.715777961033262 - 1.3482006994678812 - 1.5006347764855432 - 0.7532065567450966'\n",
      "806 - random_85 - knn_k=1 - 1.8246230194462763 - 1.243400599088751 - 1.4972019686737068 - 1.6798528131542165 - 1.290678959523505 - 1.5071569863146532 - 0.7521339182546527'\n",
      "807 - random_64 - knn_k=10 - 1.636605389974385 - 0.71342766270227 - 1.4893157722595767 - 2.4319688310832217 - 1.3031700000358521 - 1.5148277547781166 - 0.7508723885399123'\n",
      "808 - random_77 - knn_k=100 - 1.3154794425827907 - 0.6799921202197344 - 1.6178385167424945 - 3.017526200705704 - 0.9498538312984368 - 1.5160315960645212 - 0.750674405565734'\n",
      "809 - random_22 - knn_k=1 - 1.7720762117489983 - 1.279841941164026 - 1.6162634008348786 - 1.7548851693223688 - 1.1688143482687228 - 1.5183777710040316 - 0.7502885551237255'\n",
      "810 - random_13 - knn_k=1 - 1.4352047998954993 - 1.228327493498701 - 2.070819314550529 - 1.4535972475206353 - 1.405561681801054 - 1.518663730126091 - 0.75024152646794'\n",
      "811 - random_0 - deep - 1.808739717218312 - 0.8529316722398663 - 1.377967255561014 - 2.2616106773548794 - 1.2996905567220105 - 1.5201491057607792 - 0.749997243539898'\n",
      "812 - random_64 - lr - 1.5304826156606637 - 0.6910013776291453 - 1.4721412475955318 - 2.6454181102208887 - 1.2622261478450851 - 1.5201698283669114 - 0.7499938345068069'\n",
      "813 - random_19 - deep - 1.4255369099181026 - 0.8694969139813521 - 1.629266836070427 - 2.5954372363903193 - 1.0850917213506521 - 1.5208892578781312 - 0.7498755185927619'\n",
      "814 - random_85 - lwr_k=20 - 1.2189139006968308 - 0.9111254579536797 - 2.303326972941403 - 2.243125044932979 - 0.9506745842130632 - 1.525338670794107 - 0.7491437699606305'\n",
      "815 - random_26 - knn_k=5 - 1.6596872155131948 - 0.7915302660523226 - 1.9411625936419974 - 1.9939822707932862 - 1.2840877752537259 - 1.5340266940756913 - 0.7477149431639049'\n",
      "816 - random_28 - lr - 1.4576788637602618 - 0.8597187497183856 - 1.4945850175363913 - 2.7168885184743896 - 1.1444220622060213 - 1.5345814590429292 - 0.7476237068693665'\n",
      "817 - random_36 - deep - 1.8450021616552597 - 0.8007016436083614 - 1.4799203334158206 - 2.331902152214207 - 1.2290725783890522 - 1.5372757450615118 - 0.7471806073179281'\n",
      "818 - random_2 - knn_k=1 - 1.409429376502983 - 1.2112006639583996 - 2.2607657524555504 - 1.472538548351282 - 1.340013430255926 - 1.5387426492475351 - 0.7469393601684069'\n",
      "819 - random_53 - deep - 1.4664175936110269 - 0.8215768744298407 - 1.532093813164768 - 2.48917340497951 - 1.3863955449764245 - 1.5390503278108505 - 0.7468887605660405'\n",
      "820 - random_28 - knn_k=10 - 1.4773582624495776 - 0.9053961060260903 - 1.4040544633219698 - 2.7338386149442497 - 1.1966582383824522 - 1.5433888553675517 - 0.7461752480577197'\n",
      "821 - random_98 - deep - 1.7974479843127904 - 0.8937957159307077 - 1.541744002571341 - 2.089967226100898 - 1.4440786865457618 - 1.5533640673390237 - 0.7445347320541438'\n",
      "822 - random_83 - lwr_k=500 - 4.140426823721499 - 1.3865732097466648 - 0.8791170067323943 - 0.7104240729572622 - 0.6739233478800338 - 1.5583403582565396 - 0.7437163333786592'\n",
      "823 - random_16 - knn_k=10 - 1.633268090525977 - 0.8750660280009253 - 1.6464680549499138 - 2.3498790061744 - 1.2899979997728233 - 1.558873267874826 - 0.7436286914009432'\n",
      "824 - random_70 - lwr_k=500 - 1.50870960070349 - 0.748113022850058 - 1.5288316167372704 - 2.769929963555498 - 1.2516018670368037 - 1.5613483154079113 - 0.7432216466539594'\n",
      "825 - random_70 - lwr_k=1000 - 1.5138694763073115 - 0.7488114735968305 - 1.532366522223513 - 2.768236157918935 - 1.248012432103344 - 1.5621707462551815 - 0.7430863901986131'\n",
      "826 - random_72 - lwr_k=200 - 1.520401267255744 - 0.7282882114651887 - 1.6847064894607575 - 2.7374418642748255 - 1.1595936530622186 - 1.5659956090401577 - 0.7424573556917009'\n",
      "827 - random_70 - lwr_k=200 - 1.5144250605497014 - 0.750409050561358 - 1.5242882954777495 - 2.7865989676629397 - 1.2556624227258382 - 1.5661876894501592 - 0.7424257662693385'\n",
      "828 - random_72 - lwr_k=500 - 1.5218286822193967 - 0.7283724837555006 - 1.685126964667215 - 2.7363521959206936 - 1.162261164314539 - 1.5666976211655763 - 0.74234190322295'\n",
      "829 - random_72 - lwr_k=1000 - 1.527378958240189 - 0.7317369656351139 - 1.6834906072927964 - 2.732362615997439 - 1.159520993645389 - 1.566808243710076 - 0.7423237103094666'\n",
      "830 - random_24 - lwr_k=500 - 1.5957009300671274 - 0.7197956534486343 - 1.5065778786613935 - 2.806189049922419 - 1.2125662286427323 - 1.5680816907769992 - 0.7421142800127859'\n",
      "831 - random_63 - knn_k=5 - 1.490236444073941 - 0.8991348502632696 - 1.561196330116164 - 2.6593276581619447 - 1.2452665832556888 - 1.570955110450735 - 0.7416417192363001'\n",
      "832 - random_16 - lr - 1.55044932637902 - 0.8288089920022691 - 1.5266856557162527 - 2.749611432248626 - 1.2017085613246226 - 1.5713744064197372 - 0.7415727620872626'\n",
      "833 - random_70 - lwr_k=100 - 1.528560864260163 - 0.7583762450691053 - 1.5131088028833712 - 2.7906578786385454 - 1.2667805744191172 - 1.5714090002726218 - 0.7415670728041655'\n",
      "834 - random_24 - lwr_k=200 - 1.5863897965280944 - 0.7211552243790574 - 1.5065509210636172 - 2.7957484132490005 - 1.2476736609315984 - 1.5714178444347946 - 0.7415656182988657'\n",
      "835 - random_72 - lwr_k=100 - 1.5259867375751035 - 0.7344005096845445 - 1.6910850608373393 - 2.746081197581415 - 1.1606222537617337 - 1.5715445254194873 - 0.7415447844244967'\n",
      "836 - random_18 - deep - 1.5721473463869755 - 0.7829401044126288 - 1.4221652188095468 - 2.9178226248684362 - 1.167709479708936 - 1.5724758605326905 - 0.7413916186837477'\n",
      "837 - random_72 - knn_k=100 - 1.528170773391264 - 0.736464803119089 - 1.6917842635864697 - 2.7444400512872393 - 1.1621355310771868 - 1.5725086962154613 - 0.7413862175071142'\n",
      "838 - random_70 - knn_k=100 - 1.535096518034541 - 0.7640855930069841 - 1.511361417528759 - 2.78707686623275 - 1.2686567497609045 - 1.5731684520346532 - 0.7412777144836755'\n",
      "839 - random_57 - deep - 1.5162525756839853 - 0.838761808292385 - 1.5396386477981505 - 2.6956658647290492 - 1.2807233502487871 - 1.5741270100791789 - 0.7411200716780062'\n",
      "840 - random_19 - knn_k=5 - 1.5616411824933942 - 0.9126287635804534 - 1.7399434192443777 - 2.5389265319563643 - 1.1244404440035358 - 1.5754465997491134 - 0.7409030517559386'\n",
      "841 - random_24 - lwr_k=100 - 1.5918620988578318 - 0.7247354688119841 - 1.5089299755272132 - 2.7957497202674344 - 1.2607029914110273 - 1.5763102170052479 - 0.7407610218099214'\n",
      "842 - random_24 - lwr_k=1000 - 1.621283993930133 - 0.7199566478070673 - 1.509727985898256 - 2.818145587370719 - 1.2217655000386225 - 1.5780922732035523 - 0.7404679459781836'\n",
      "843 - random_72 - lr - 1.528114733727794 - 0.7392112052171844 - 1.6893243433769227 - 2.767497251846282 - 1.168099587415776 - 1.578358111146017 - 0.7404242264388281'\n",
      "844 - random_70 - lr - 1.5125327723453579 - 0.7541488138221066 - 1.546649158146633 - 2.84311938184 - 1.2586686310923865 - 1.5829314330427344 - 0.739672100821263'\n",
      "845 - random_40 - knn_k=1 - 1.5309380341848937 - 1.0801004630946478 - 2.278532050704162 - 1.5040606483614978 - 1.5314866052994518 - 1.5849661790290561 - 0.7393374677873081'\n",
      "846 - random_72 - knn_k=50 - 1.527212094856471 - 0.742034032151832 - 1.71268451797505 - 2.7858974942170502 - 1.1705427265192654 - 1.5875811632671855 - 0.7389074091385964'\n",
      "847 - random_70 - lwr_k=50 - 1.5414092816033775 - 0.767809060942017 - 1.5168398956552485 - 2.8358574247268797 - 1.278832878337831 - 1.5880607038316008 - 0.7388285442016198'\n",
      "848 - random_24 - lwr_k=50 - 1.617828845244243 - 0.7271697871750257 - 1.5233397595541733 - 2.8160450404505286 - 1.2566582472812466 - 1.5881229922703946 - 0.738818300284495'\n",
      "849 - random_72 - lwr_k=50 - 1.5262477239523906 - 0.7419035664812768 - 1.7121298001594387 - 2.7933932872208205 - 1.1681091712977902 - 1.5882634474399564 - 0.7387952011164214'\n",
      "850 - random_70 - knn_k=50 - 1.544991723183198 - 0.7692943800630616 - 1.5142831103086305 - 2.8364782209069963 - 1.2806605261215351 - 1.589052904261933 - 0.7386653675483543'\n",
      "851 - random_32 - lwr_k=50 - 0.8225529561022487 - 0.7768767953541701 - 0.9819637964704061 - 4.627624505446598 - 0.7543217050694027 - 1.5925051610755578 - 0.7380976115830888'\n",
      "852 - random_81 - lwr_k=500 - 1.294583111772134 - 0.8606429223337961 - 1.520116594835026 - 2.9027196700743483 - 1.3858465185349778 - 1.5926760010903362 - 0.7380695153426486'\n",
      "853 - random_81 - lwr_k=200 - 1.2963033054655577 - 0.863582504442605 - 1.5209423182458899 - 2.915835896733762 - 1.3865824218048843 - 1.5965432112468982 - 0.737433516413873'\n",
      "854 - random_69 - knn_k=5 - 1.353727013216932 - 0.813575785679006 - 2.1338085038756622 - 2.3258119336247964 - 1.3590289103637496 - 1.5970850015076639 - 0.7373444139313293'\n",
      "855 - random_11 - deep - 1.6705170874108775 - 0.7369781293093455 - 1.6813452882688393 - 2.7815337646178886 - 1.1183740342422188 - 1.5976687806771401 - 0.7372484070372562'\n",
      "856 - random_81 - lwr_k=1000 - 1.2998445493736537 - 0.869338516792404 - 1.5331470330016352 - 2.905068682841678 - 1.4014212509671844 - 1.6016578328171316 - 0.736592368995432'\n",
      "857 - random_81 - lwr_k=100 - 1.2980472395241442 - 0.8690227373816952 - 1.5322999216910282 - 2.921186319059344 - 1.3893388376072633 - 1.6018725762297426 - 0.7365570524300391'\n",
      "858 - random_24 - lwr_k=20 - 1.627170044364633 - 0.7480033429964104 - 1.5670308502902517 - 2.8648424877479477 - 1.239476070046714 - 1.6092179818226324 - 0.735349031686565'\n",
      "859 - random_81 - knn_k=100 - 1.3380272149217687 - 0.8701909696631549 - 1.53318492510697 - 2.9194980425379167 - 1.3984808002457805 - 1.611772147567957 - 0.7349289752085933'\n",
      "860 - random_64 - knn_k=5 - 1.7557392258787328 - 0.7734936150544679 - 1.5841106368561506 - 2.5331499450192676 - 1.4177687951154474 - 1.6127809518945817 - 0.734763067889078'\n",
      "861 - random_24 - knn_k=50 - 1.6479019069487237 - 0.728816670080369 - 1.5265814749449977 - 2.845546093013239 - 1.3155815279530103 - 1.6127983807703563 - 0.734760201547226'\n",
      "862 - random_24 - knn_k=20 - 1.6346876907793413 - 0.7486879454843176 - 1.5670573725528023 - 2.870769384816736 - 1.2669439636605315 - 1.6175418271037207 - 0.7339800973727463'\n",
      "863 - random_81 - lwr_k=50 - 1.3018345317820486 - 0.8797338693674521 - 1.5465073141572474 - 2.9518449990393782 - 1.4196897194241118 - 1.619813456516688 - 0.7336065066407373'\n",
      "864 - random_24 - knn_k=100 - 1.6449057451365345 - 0.7296781946656544 - 1.515467629007758 - 2.8600138813993663 - 1.3504567885418073 - 1.6200155927968576 - 0.7335732634363471'\n",
      "865 - random_4 - deep - 1.7237528033474276 - 0.7712792170053876 - 1.3726297014792597 - 2.954594396712599 - 1.2966790250684201 - 1.6237097743975462 - 0.7329657217490895'\n",
      "866 - random_81 - knn_k=50 - 1.329082030392883 - 0.8790838534570289 - 1.5465495621693996 - 2.945879289970877 - 1.418740334190027 - 1.6237603041054105 - 0.732957410590395'\n",
      "867 - random_72 - knn_k=20 - 1.5658232413521425 - 0.7769498000346817 - 1.7476325142809193 - 2.8674709295168284 - 1.1889402158164457 - 1.6292693190917027 - 0.7320514014809739'\n",
      "868 - random_60 - deep - 1.5748759026769616 - 0.780616179987857 - 1.4671784296662411 - 3.0696125985171028 - 1.2588123017023232 - 1.6301261893378864 - 0.7319104822231786'\n",
      "869 - random_72 - lwr_k=20 - 1.565924674521604 - 0.7769519560374846 - 1.7476192047870638 - 2.8725142379097193 - 1.189049527857428 - 1.630317694477445 - 0.7318789863301822'\n",
      "870 - random_64 - deep - 1.5613776926752112 - 0.7269106659294704 - 1.4919380758577303 - 3.1044626872397547 - 1.279868953771415 - 1.6328112741608534 - 0.7314688948785377'\n",
      "871 - random_63 - deep - 1.4279885511021544 - 0.789095175394711 - 1.4999122122719548 - 3.304413588874394 - 1.1477120103777312 - 1.633716468652589 - 0.7313200271673319'\n",
      "872 - random_81 - lr - 1.3355282556816908 - 0.8949598476734648 - 1.5587492889016157 - 2.9589302359478062 - 1.4214688365680486 - 1.6338208090207789 - 0.7313028663349557'\n",
      "873 - random_70 - knn_k=20 - 1.5664038623899825 - 0.7931557390717832 - 1.5602317463691273 - 2.930459675693112 - 1.3203957731832074 - 1.6340360828974658 - 0.7312674625297774'\n",
      "874 - random_70 - lwr_k=20 - 1.5682349567003817 - 0.7933512825132161 - 1.562011583451184 - 2.9278620995210596 - 1.3203260940917125 - 1.6342640880669153 - 0.7312299649442688'\n",
      "875 - random_85 - deep - 1.5725653225975564 - 0.6781312836751747 - 1.9230073810358068 - 2.5453849538885347 - 1.4761618938778949 - 1.6389446984137712 - 0.7304601958213481'\n",
      "876 - random_52 - deep - 1.551549457048012 - 0.8533005597286801 - 1.500096317923779 - 2.9277710806907327 - 1.365406517864987 - 1.639535031761794 - 0.7303631099738633'\n",
      "877 - random_28 - knn_k=5 - 1.5755165734106322 - 0.9488968016520749 - 1.5402203612906948 - 2.8714034638950845 - 1.3051899252191965 - 1.6481661726325303 - 0.7289436369368612'\n",
      "878 - random_78 - deep - 1.632612489442938 - 0.7786326551816597 - 1.5523538342246774 - 2.864009751431506 - 1.4137677757157436 - 1.6481844218225392 - 0.7289406367778523'\n",
      "879 - random_56 - deep - 1.4993155527383992 - 0.7728488493295985 - 1.587212893017998 - 2.851801811057684 - 1.5397438099741692 - 1.650079041674429 - 0.7286290488003166'\n",
      "880 - random_72 - deep - 1.564425248620203 - 0.778852615128914 - 1.7232592607670496 - 2.9982774061833566 - 1.208439577041955 - 1.6545516529527806 - 0.7278934859901127'\n",
      "881 - random_16 - deep - 1.6064788044385876 - 0.8399345331952901 - 1.6201648292355468 - 2.9856581834797007 - 1.2228489516941674 - 1.6549284097142916 - 0.7278315248123994'\n",
      "882 - random_24 - lr - 1.6547765679077313 - 0.7288728455898822 - 1.6520926698811396 - 2.8779436382691257 - 1.365887923805294 - 1.6558194529620485 - 0.7276849833095339'\n",
      "883 - random_70 - deep - 1.5221784457357925 - 0.8061285824761016 - 1.5467196871857378 - 3.0443159843617154 - 1.3630028914132402 - 1.656368037526898 - 0.7275947645366709'\n",
      "884 - random_97 - deep - 1.5530833886059936 - 0.7046992311482554 - 1.6213307955916167 - 3.2250441060663495 - 1.1808392585425407 - 1.6568909459409553 - 0.7275087673510034'\n",
      "885 - random_15 - deep - 1.934811538155107 - 0.8138729169957145 - 1.618000371989773 - 2.6450005023141663 - 1.273784048992995 - 1.65703583473227 - 0.7274849390324052'\n",
      "886 - random_71 - lwr_k=20 - 2.23973130135583 - 0.7816422829469659 - 0.7939181689815423 - 2.274900778968212 - 2.2047029630841695 - 1.6589486551529695 - 0.7271703567025545'\n",
      "887 - random_1 - knn_k=1 - 1.5971018893051665 - 1.3188093169459474 - 1.738497383330582 - 1.8997432728793329 - 1.7471920394323566 - 1.6602272461603949 - 0.7269600804366823'\n",
      "888 - random_81 - lwr_k=20 - 1.345087349058472 - 0.9134444242515471 - 1.5961232062111756 - 3.015967680410773 - 1.4584173542632115 - 1.665697852538033 - 0.7260603879826719'\n",
      "889 - random_83 - lwr_k=1000 - 4.564191679390105 - 1.5034997324138213 - 0.8846738432715243 - 0.7081878016038676 - 0.6717443101393717 - 1.666740193181545 - 0.7258889653017586'\n",
      "890 - random_81 - knn_k=20 - 1.3735138701396372 - 0.9130760607371022 - 1.5960329140964793 - 3.0025754029237164 - 1.4546788102281418 - 1.66786769648517 - 0.7257035368237952'\n",
      "891 - random_44 - lwr_k=500 - 1.347150174898175 - 0.7326172447820516 - 1.3905947283879394 - 2.281314610939851 - 2.5892049816798983 - 1.6680473617614187 - 0.7256739891864529'\n",
      "892 - random_44 - lwr_k=1000 - 1.363372558657815 - 0.7328937431900967 - 1.380980187802359 - 2.2996151890568193 - 2.568486249643823 - 1.6689421094979908 - 0.7255268395413738'\n",
      "893 - random_24 - knn_k=10 - 1.7010121312657633 - 0.7786456934898344 - 1.624376061384782 - 2.997822555960586 - 1.2740766346980683 - 1.6750972378802373 - 0.7245145710327843'\n",
      "894 - random_95 - deep - 1.5478347560085963 - 0.7811063718281996 - 1.7137866960169108 - 3.0571861267089844 - 1.2768461718941126 - 1.6752471466302747 - 0.7244899182439825'\n",
      "895 - random_71 - lr - 2.356194364226738 - 0.7680853037064136 - 0.7516350368007884 - 2.1760530391245694 - 2.3352319151996297 - 1.677416261087373 - 0.7241331859474556'\n",
      "896 - random_83 - lwr_k=50 - 4.399495616086096 - 1.4242027452412434 - 0.9663855738580112 - 0.8283874312162091 - 0.7806104234781135 - 1.680069290191637 - 0.7236968704641971'\n",
      "897 - random_44 - lwr_k=200 - 1.329863806217047 - 0.7363609353355687 - 1.4214458416373683 - 2.2827854767623372 - 2.637226182361966 - 1.681403329169553 - 0.7234774752602773'\n",
      "898 - random_44 - lr - 1.4617805711122187 - 0.7434997742145643 - 1.5128051559173554 - 2.113948189458641 - 2.5853890789118554 - 1.6833653085151545 - 0.7231548093818883'\n",
      "899 - random_73 - lwr_k=20 - 0.6311706996485389 - 0.5912982537738425 - 0.6639118549560865 - 5.889101655988783 - 0.6574930465057055 - 1.6863743342367008 - 0.7226599469208155'\n",
      "900 - random_73 - lwr_k=50 - 0.6274517175795427 - 0.6466067649491272 - 0.649035181154459 - 5.877725245059973 - 0.6342042628873559 - 1.686789077891466 - 0.7225917384424891'\n",
      "901 - random_39 - deep - 1.5424648327604815 - 0.6824998402057274 - 1.787934530075081 - 3.29144588143429 - 1.1302354487550332 - 1.686798170449926 - 0.7225902442028601'\n",
      "902 - random_34 - deep - 1.3661363230661712 - 0.8620767366769927 - 1.9279693142344574 - 3.1066281501762187 - 1.1781947565029778 - 1.6880831902411482 - 0.7223789106641343'\n",
      "903 - random_73 - lwr_k=100 - 0.6549511501969555 - 0.6314692685823534 - 0.6507417262736772 - 5.859454980148711 - 0.6577547781169373 - 1.6906592987152003 - 0.7219552443813004'\n",
      "904 - random_93 - deep - 1.524222127653624 - 0.6849922462571517 - 1.7597221836172334 - 3.330326275659048 - 1.1610239834756086 - 1.6919367596945045 - 0.7217451550793047'\n",
      "905 - random_13 - deep - 1.7706050072773227 - 0.8478654543823801 - 1.6669895330738482 - 2.9680445576105763 - 1.213376730129704 - 1.6932973901117652 - 0.7215213866650423'\n",
      "906 - random_27 - knn_k=1 - 1.6371706982425405 - 1.4007464019776799 - 1.7960909378353076 - 2.126816342255383 - 1.5113967452621742 - 1.6944081984927726 - 0.7213387027023909'\n",
      "907 - random_72 - knn_k=10 - 1.6181077137033968 - 0.795309328750448 - 1.8039832990613947 - 3.0084584757892303 - 1.2532817016488174 - 1.6957276891771154 - 0.7211217001016019'\n",
      "908 - random_25 - deep - 1.627530901660792 - 0.7236810691880226 - 1.6262682879485144 - 3.227837391702546 - 1.2899300819549717 - 1.6989420828591826 - 0.7205930640808451'\n",
      "909 - random_73 - lwr_k=200 - 0.6731015006799892 - 0.6487561313745441 - 0.6610083514092784 - 5.857947583664328 - 0.6747665381568216 - 1.702902063511307 - 0.7199418070504215'\n",
      "910 - random_44 - lwr_k=100 - 1.3374453933013843 - 0.7435043694861815 - 1.4440159728101996 - 2.324049317574575 - 2.671218233698013 - 1.7039104283089956 - 0.7197759720155563'\n",
      "911 - random_76 - deep - 1.5320455640202733 - 0.8261177285993447 - 1.5352703660910134 - 3.377292487655577 - 1.2506080501133412 - 1.7041590162130575 - 0.7197350905348326'\n",
      "912 - random_70 - knn_k=10 - 1.6398289565428774 - 0.8310614732100362 - 1.6522051534344881 - 3.009607233691374 - 1.391802973973159 - 1.7048047804361859 - 0.7196288874321451'\n",
      "913 - random_29 - deep - 1.6977843297573774 - 0.6981490956874552 - 1.449266192359846 - 3.31873515401288 - 1.3776162659607873 - 1.7082054349531306 - 0.7190696190787916'\n",
      "914 - random_24 - deep - 1.697279457314434 - 0.7429080813771459 - 1.657201534179202 - 3.0747053696634343 - 1.3712211228004472 - 1.708562815100644 - 0.7190108445667099'\n",
      "915 - random_16 - knn_k=5 - 1.7819212174612773 - 0.9481573056769586 - 1.864050759460058 - 2.5396703842163584 - 1.4109399185015903 - 1.7088773137671092 - 0.7189591211843824'\n",
      "916 - random_82 - knn_k=1 - 1.5056857809668178 - 1.2184544698797883 - 2.059759397644894 - 2.290597482748132 - 1.4728276397307054 - 1.7093936351982204 - 0.7188742072894049'\n",
      "917 - random_79 - deep - 1.524798884521453 - 0.9384188382303855 - 1.6252258156848884 - 3.0553796085733653 - 1.42397169141554 - 1.7134600220155347 - 0.7182054530277888'\n",
      "918 - random_80 - deep - 1.8529882483631601 - 0.8085327156694685 - 2.343718401949998 - 2.376656326669932 - 1.1909460504931346 - 1.7144895510988212 - 0.7180361373286236'\n",
      "919 - random_44 - lwr_k=50 - 1.3542793847985979 - 0.7498072588683642 - 1.4574240944997439 - 2.350754177592267 - 2.671952644001476 - 1.7167070306977028 - 0.7176714509055836'\n",
      "920 - random_73 - lwr_k=500 - 0.6978779803967561 - 0.6604873936898079 - 0.6819173501501187 - 5.856816518779601 - 0.7020992727234683 - 1.7196260597449315 - 0.7171913892404702'\n",
      "921 - random_51 - deep - 1.5979686172391403 - 0.818006423817591 - 1.4888799447543322 - 3.4230370717371756 - 1.297192745140201 - 1.7249108237255557 - 0.7163222614511635'\n",
      "922 - random_10 - deep - 1.6514510746305573 - 1.046545645712338 - 1.6288649405542095 - 3.017491004305454 - 1.302199549253961 - 1.7292323709159232 - 0.715611542544926'\n",
      "923 - random_44 - lwr_k=20 - 1.3787592990830855 - 0.7723004244643722 - 1.4685153320461353 - 2.3662113955466175 - 2.6878815559460443 - 1.734598269095419 - 0.7147290691898889'\n",
      "924 - random_81 - deep - 1.351790875762227 - 0.9120667849582792 - 1.5708629360433966 - 3.3365969780289415 - 1.5151770364577275 - 1.7371746404883244 - 0.7143053619353235'\n",
      "925 - random_81 - knn_k=10 - 1.4453570810531824 - 0.9328678247184726 - 1.6696489727035317 - 3.117969715578498 - 1.5347044950307434 - 1.7399964999427466 - 0.7138412795696742'\n",
      "926 - random_62 - lwr_k=200 - 0.7619269770443171 - 0.7091257667806734 - 0.8681971320114688 - 3.2047417223448176 - 3.159742216169815 - 1.7405403944877595 - 0.7137518310178783'\n",
      "927 - random_50 - deep - 1.59838023902576 - 0.7709103557560736 - 1.6268844648553116 - 3.4900956736453015 - 1.2283468234220813 - 1.742808897235622 - 0.7133787556490779'\n",
      "928 - random_73 - lwr_k=1000 - 0.729949982592069 - 0.6878031491278607 - 0.7153707001320625 - 5.864482083524555 - 0.7240843526575959 - 1.7441254768283956 - 0.7131622306507124'\n",
      "929 - random_44 - knn_k=20 - 1.43680684763967 - 0.7705035166611851 - 1.486076852602624 - 2.375204764411491 - 2.7078805173695795 - 1.7551607203656134 - 0.7113473814999519'\n",
      "930 - random_44 - knn_k=10 - 1.4147724096898315 - 0.8063861054601283 - 1.482819993969409 - 2.379428995760209 - 2.6991187016563973 - 1.7563726348642195 - 0.711148070810417'\n",
      "931 - random_21 - lwr_k=200 - 1.4092469915954344 - 0.7114190763455153 - 1.887490485156369 - 3.5204729126511958 - 1.2544710738233926 - 1.7564771625081108 - 0.7111308802604206'\n",
      "932 - random_21 - lwr_k=500 - 1.4093832557672008 - 0.7095975171045447 - 1.9074388456687261 - 3.515200463222765 - 1.251763765107085 - 1.7585332287493591 - 0.7107927409108674'\n",
      "933 - random_48 - deep - 1.6920526502314686 - 0.7033631247150525 - 1.9732983452583486 - 3.1727807193810933 - 1.2612222315594401 - 1.7604278748336653 - 0.7104811497834249'\n",
      "934 - random_61 - deep - 1.8480269936428981 - 0.8803931926995928 - 1.5829591139141295 - 3.2623664676775923 - 1.238044903018881 - 1.7622763967856083 - 0.710177143037237'\n",
      "935 - random_44 - knn_k=50 - 1.4691367352873337 - 0.7488677614564555 - 1.5026295736835775 - 2.3741988653632666 - 2.7274653949619467 - 1.7643251029360267 - 0.7098402129568142'\n",
      "936 - random_21 - lwr_k=100 - 1.416492585024434 - 0.7171781135970606 - 1.8951177782007163 - 3.5404461786141384 - 1.256253600650221 - 1.7649543003033525 - 0.7097367355569815'\n",
      "937 - random_21 - lwr_k=1000 - 1.4098742898949725 - 0.7107968929912581 - 1.9350765715734066 - 3.527556177412896 - 1.2670785245359615 - 1.769930783849993 - 0.7089183062302581'\n",
      "938 - random_62 - lwr_k=100 - 0.7686167071876927 - 0.7168960425464317 - 0.8641687176434818 - 3.2564882531883295 - 3.279005636426036 - 1.7768227374430403 - 0.707784859914983'\n",
      "939 - random_10 - knn_k=1 - 1.1088261773662358 - 1.2069073861196693 - 2.1613894286268907 - 3.455433676018022 - 0.9603723933525704 - 1.778458380756839 - 0.7075158630533385'\n",
      "940 - random_21 - lwr_k=50 - 1.4130679425806716 - 0.7194956639548681 - 1.910344046200652 - 3.5862967029725414 - 1.2639107423008622 - 1.7784767783339381 - 0.7075128373994812'\n",
      "941 - random_46 - deep - 2.0542392086040797 - 0.801572197550318 - 1.8982886499447988 - 2.962446136885845 - 1.1851923026343392 - 1.7802753478190525 - 0.7072170469817257'\n",
      "942 - random_21 - knn_k=50 - 1.420992368150661 - 0.7169007025507396 - 1.9265504129162963 - 3.5780905462191606 - 1.2672142931588575 - 1.7818032874426561 - 0.7069657618219833'\n",
      "943 - random_46 - knn_k=1 - 1.7702273106074342 - 1.3146180408307897 - 2.4282456902666096 - 1.85516675229924 - 1.5415396808304558 - 1.781910318859485 - 0.7069481595030782'\n",
      "944 - random_28 - deep - 2.0463196247770212 - 0.8895547534943605 - 1.6219887040723766 - 3.198235383023961 - 1.1542831029000957 - 1.7820118252824562 - 0.7069314670009617'\n",
      "945 - random_44 - knn_k=100 - 1.497486409758177 - 0.7475690498460004 - 1.5337251486620418 - 2.3651083573258065 - 2.7679421580809955 - 1.7822307620996354 - 0.7068954596111101'\n",
      "946 - random_21 - knn_k=100 - 1.431940538371628 - 0.7172343614646415 - 1.9265279856080149 - 3.5695647784891147 - 1.2709318006848283 - 1.7830944089484855 - 0.7067534247982936'\n",
      "947 - random_20 - deep - 1.625705576236582 - 0.8018634781096151 - 1.404737399344082 - 3.8274168238747537 - 1.2577483323565255 - 1.78337735270415 - 0.7067068932284603'\n",
      "948 - random_24 - knn_k=5 - 1.8244873319205808 - 0.8277882724503617 - 1.7541223559484211 - 3.155453703549548 - 1.3671625225132944 - 1.7857084695829306 - 0.7063235180448579'\n",
      "949 - random_12 - deep - 1.4556758940189296 - 0.8366793908174983 - 1.804009787600633 - 3.6153207417631053 - 1.2252530481291504 - 1.7872561365289477 - 0.7060689909041176'\n",
      "950 - random_54 - deep - 2.1507379943863314 - 0.8193795280985002 - 1.8746507255938019 - 2.7714839436924676 - 1.3302518917549806 - 1.789238356501401 - 0.7057429962663905'\n",
      "951 - random_35 - lwr_k=200 - 0.67967177074662 - 0.6809521477351236 - 6.167948899924199 - 0.728002358163907 - 0.716998276238938 - 1.7944859074101829 - 0.7048799861886812'\n",
      "952 - random_22 - deep - 1.6149675060749789 - 1.1822229491067948 - 1.6754829144330974 - 2.8285957097517636 - 1.6848095129157974 - 1.797133892600241 - 0.7044445014141685'\n",
      "953 - random_62 - lwr_k=500 - 0.7842455223163781 - 0.716099994334971 - 0.8948210623337856 - 3.340145929301589 - 3.252391229847405 - 1.7973257264834668 - 0.7044129513456276'\n",
      "954 - random_91 - deep - 1.6650076502711422 - 0.7806098167256492 - 1.8622433052415475 - 3.376647499307715 - 1.3104578107289464 - 1.7988749173183072 - 0.7041581735947906'\n",
      "955 - random_35 - lwr_k=100 - 0.6880747098115589 - 0.6940066387556467 - 6.191821162485071 - 0.7461812618305358 - 0.6908711118115884 - 1.8019628615000263 - 0.7036503310628598'\n",
      "956 - random_26 - lr - 1.5312409163137068 - 0.687386625888704 - 1.6371367420569642 - 3.9257622272610044 - 1.2296216590255822 - 1.8020873808012456 - 0.7036298526975833'\n",
      "957 - random_69 - deep - 1.3935056189012993 - 0.7006292831842688 - 1.9667644106631896 - 3.7026779426441547 - 1.2701882880326414 - 1.806597137041381 - 0.7028881822436509'\n",
      "958 - random_21 - knn_k=20 - 1.4678036556635146 - 0.7331622113932376 - 1.978176163251934 - 3.5743363646228916 - 1.2917160124090232 - 1.808893417303074 - 0.7025105362526194'\n",
      "959 - random_35 - lwr_k=500 - 0.7028577704376576 - 0.6909185468019209 - 6.1728821818732715 - 0.7271896975786162 - 0.7636975649260755 - 1.8112803243633964 - 0.702117987031865'\n",
      "960 - random_44 - knn_k=5 - 1.4791472489361934 - 0.8399780046981347 - 1.5585824973870914 - 2.4468995622979715 - 2.7364416002963026 - 1.8120757964460077 - 0.7019871641978503'\n",
      "961 - random_35 - lwr_k=50 - 0.6570531278226925 - 0.6891803553061717 - 6.2428524976329784 - 0.7631488017319986 - 0.7217966245325413 - 1.8145718963632231 - 0.7015766571891293'\n",
      "962 - random_17 - deep - 2.5205124548730513 - 0.743731087449271 - 1.7920842224567577 - 2.6604748658331023 - 1.3637983642319633 - 1.816082423779332 - 0.7013282380109991'\n",
      "963 - random_21 - lwr_k=20 - 1.4699627399092703 - 0.7357279304410195 - 1.9759246013192946 - 3.607475230498985 - 1.296813702143585 - 1.8170341901735196 - 0.7011717099113036'\n",
      "964 - random_73 - lr - 0.8473080217145862 - 0.7336166963001332 - 0.86206370152753 - 5.872109960157973 - 0.7986714647303732 - 1.8225420428730046 - 0.7002658919508336'\n",
      "965 - random_73 - knn_k=20 - 0.8265743202622013 - 0.7262715646307076 - 0.8725837168989438 - 5.889102472007728 - 0.8046622944978875 - 1.823623842673821 - 0.700087979841945'\n",
      "966 - random_43 - deep - 1.5723628168414348 - 0.7770461154143097 - 1.6268852231928455 - 3.671318587336452 - 1.4742782977572213 - 1.8242448329466947 - 0.6999858533834237'\n",
      "967 - random_35 - lwr_k=1000 - 0.7179117603230717 - 0.6888953140201913 - 6.161921442268553 - 0.7839743707836482 - 0.7826190202403606 - 1.826833697715965 - 0.6995600891182241'\n",
      "968 - random_99 - deep - 1.777150770894927 - 0.8492575005545501 - 1.8116284716545434 - 3.367218134094802 - 1.3335131485114597 - 1.8276479639156036 - 0.699426176625665'\n",
      "969 - random_73 - knn_k=1 - 0.7852014105446998 - 0.823469661331187 - 0.9110806688549552 - 5.887523156601586 - 0.7468329274946909 - 1.8306108308186315 - 0.6989389042045822'\n",
      "970 - random_62 - lwr_k=50 - 0.7872713478148974 - 0.7306002167999822 - 0.8611390567646771 - 3.3682037994822753 - 3.4485548007926994 - 1.8389320791775445 - 0.6975703969789366'\n",
      "971 - random_21 - lr - 1.4486581023969183 - 0.7184713890918673 - 2.0383974218117307 - 3.6530648018662757 - 1.3386288999639258 - 1.8392889435194135 - 0.6975117072956875'\n",
      "972 - random_53 - knn_k=1 - 1.8848865250236606 - 1.4488972156227709 - 2.398322386803523 - 1.6268027992441074 - 1.863584290312736 - 1.8444621813251785 - 0.6966609198883402'\n",
      "973 - random_35 - lwr_k=20 - 0.6608746828998309 - 0.7090798412131435 - 6.301484121893587 - 0.7995869306118462 - 0.7541834739332389 - 1.8448036527405791 - 0.6966047617160118'\n",
      "974 - random_66 - deep - 1.6831003072140704 - 0.7449383636570515 - 1.700386275990543 - 3.7502918228721227 - 1.3739884900850927 - 1.8504103694916352 - 0.6956826858614332'\n",
      "975 - random_83 - lr - 4.63936550102844 - 1.9850120189683966 - 1.1336150047007643 - 0.7406115954713116 - 0.7684196966682405 - 1.8537042468403582 - 0.6951409756573926'\n",
      "976 - random_65 - deep - 1.6639911168168422 - 0.8242842391431484 - 1.648781285393654 - 3.813729516779373 - 1.3328572913116987 - 1.8566029240251964 - 0.6946642622758435'\n",
      "977 - random_23 - deep - 2.0130823752157134 - 0.8423362222618174 - 1.9325631068717284 - 3.4273882093370815 - 1.0900065852386507 - 1.860986330351711 - 0.693943370055363'\n",
      "978 - random_70 - knn_k=5 - 1.8396996859917887 - 0.9061836780304152 - 1.7940510199539228 - 3.2821783993413796 - 1.4833784922588678 - 1.860998038204352 - 0.6939414433572558'\n",
      "979 - random_72 - knn_k=5 - 1.7618987775703348 - 0.8423677906091218 - 2.0340102536832783 - 3.2917582487619783 - 1.384758487942181 - 1.862843576129798 - 0.6936379273609485'\n",
      "980 - random_49 - knn_k=1 - 1.5309445128286168 - 1.5178491763002906 - 2.046664026637836 - 2.3008166481341883 - 1.9276173177290805 - 1.8647084571447745 - 0.6933312302124095'\n",
      "981 - random_31 - deep - 1.716774326400796 - 0.8703835003494665 - 2.1066886201286708 - 3.1942550714990197 - 1.4474013118528488 - 1.8669828217361597 - 0.6929571908907532'\n",
      "982 - random_73 - knn_k=50 - 0.9303803558255447 - 0.7557704652241183 - 0.9373979153350511 - 5.877725084593729 - 0.8422003543754155 - 1.8684842788349787 - 0.6927102609728291'\n",
      "983 - random_81 - knn_k=5 - 1.5406332136481482 - 0.9967152661740196 - 1.8145453873996198 - 3.3454737384676747 - 1.7009311301669627 - 1.879534313891207 - 0.6908929792182368'\n",
      "984 - random_41 - deep - 1.8847498715749578 - 0.7965476506792502 - 1.7294043204622838 - 3.8116870430705485 - 1.1824939062463184 - 1.8808656455744128 - 0.6906740304995387'\n",
      "985 - random_74 - deep - 2.014076988412026 - 0.7633085744450678 - 2.085309711569878 - 2.9480547131454187 - 1.6051488889561052 - 1.8830782605306653 - 0.690310145249104'\n",
      "986 - random_75 - deep - 1.942941501851324 - 0.7599057026127168 - 1.8866678018589529 - 3.725315190928183 - 1.1101594712944736 - 1.8848883865034418 - 0.6900124530812638'\n",
      "987 - random_9 - deep - 2.678641189117197 - 0.825071617723918 - 1.6391601158608156 - 2.657300579964013 - 1.6886771205024798 - 1.8977401764661352 - 0.6878988558663961'\n",
      "988 - random_42 - knn_k=1 - 2.3019205399432976 - 1.233816912710521 - 2.1963718498041596 - 2.1224096697468138 - 1.6369749316627566 - 1.8982720039197947 - 0.6878113906043648'\n",
      "989 - random_8 - deep - 2.19802111671667 - 0.7448680605748912 - 1.9301054966033606 - 3.443947722290086 - 1.1794637441635132 - 1.8991933896670214 - 0.6876598613463395'\n",
      "990 - random_21 - knn_k=10 - 1.5259576238662491 - 0.7627959130761203 - 2.0661619349795175 - 3.8039924813430455 - 1.3469246918496076 - 1.9010111626175392 - 0.6873609103028078'\n",
      "991 - random_42 - deep - 2.0035150367948202 - 0.7164146846046565 - 2.0843937857195094 - 3.531560039128611 - 1.1837317865242458 - 1.9038114001997213 - 0.686900386267111'\n",
      "992 - random_84 - deep - 1.9432303121360281 - 0.7699879413693302 - 1.9905512247242232 - 3.1613954900471337 - 1.682283480554146 - 1.909376185643849 - 0.6859852051872625'\n",
      "993 - random_73 - knn_k=100 - 1.0332037445080755 - 0.7765349696502217 - 1.010634101266502 - 5.859455100149075 - 0.8905864610883939 - 1.9138756871743232 - 0.6852452187561668'\n",
      "994 - random_35 - lr - 0.8499717582316204 - 0.6840102704732621 - 6.162065407832034 - 1.038542850838853 - 0.8366849974902288 - 1.9140195275043799 - 0.685221562866746'\n",
      "995 - random_62 - lwr_k=1000 - 0.808013740373898 - 0.7215675937174352 - 0.9073989146253474 - 3.656987297295918 - 3.510533084088458 - 1.9206627806170138 - 0.6841290176746904'\n",
      "996 - random_50 - knn_k=1 - 1.722681391778043 - 1.396482608674642 - 2.3373936152114596 - 2.245321011189898 - 1.9306272829117908 - 1.9264258546729927 - 0.6831812261718578'\n",
      "997 - random_62 - lwr_k=20 - 0.8333769624886025 - 0.7642903352206695 - 0.927847708510522 - 3.506318733893359 - 3.6060789207270774 - 1.9273508037994742 - 0.6830291096253557'\n",
      "998 - random_26 - deep - 1.724051830767362 - 0.6955360088243187 - 1.65779784866427 - 4.285346058604653 - 1.2957360673489267 - 1.93154535841594 - 0.6823392771131942'\n",
      "999 - random_61 - knn_k=1 - 1.3959892206978495 - 1.368535429220931 - 2.221135037854541 - 3.356859701737456 - 1.343471460937059 - 1.9370842436175635 - 0.6814283542883066'\n",
      "1000 - random_44 - deep - 1.5695864179306853 - 0.7678726465350973 - 1.6143194282813729 - 2.6831133282404904 - 3.053427933177909 - 1.9375060960927661 - 0.6813589779806323'\n",
      "1001 - random_73 - knn_k=10 - 0.7905411575052465 - 0.724401687289585 - 0.8466468734240769 - 6.559967979065029 - 0.7760010876406416 - 1.9392690880597285 - 0.6810690361575347'\n",
      "1002 - random_59 - deep - 1.5221957942655358 - 0.6903605200866358 - 1.6494501623529674 - 4.73327543407495 - 1.1477032846004322 - 1.9484241071245503 - 0.6795634088205651'\n",
      "1003 - random_40 - deep - 1.7943170009483858 - 0.713234626433371 - 1.8011727181303427 - 4.287655257101666 - 1.1752395569910994 - 1.9541800194915735 - 0.6786167951283651'\n",
      "1004 - random_32 - lwr_k=20 - 1.14586569090145 - 1.1000476297615154 - 1.4865040757430925 - 4.960340045344785 - 1.0804873900841867 - 1.9544782227196984 - 0.6785677515208743'\n",
      "1005 - random_35 - knn_k=20 - 0.8761987712647715 - 0.7602204476432045 - 6.301486607324462 - 0.9464368736226875 - 0.8899942693985604 - 1.954634041811239 - 0.6785421256119398'\n",
      "1006 - random_49 - deep - 1.6176029328140251 - 0.909259745406762 - 1.443806570902987 - 4.367723404749218 - 1.4735772462840933 - 1.9622504770698659 - 0.677289532800728'\n",
      "1007 - random_83 - knn_k=10 - 4.242382587084614 - 2.13425588454521 - 1.1741837046336525 - 1.3396642450975544 - 0.9814785007087923 - 1.9746421994111731 - 0.6752515967073391'\n",
      "1008 - random_68 - deep - 1.8904082123104151 - 0.8300564059115116 - 1.9839044970898168 - 4.000733433807655 - 1.1883111543479152 - 1.9785557801345375 - 0.6746079730144956'\n",
      "1009 - random_96 - deep - 1.4144418844508782 - 0.7907137757940376 - 2.4144647992856694 - 3.687658637456091 - 1.5912406257290614 - 1.9795238648718003 - 0.674448762413453'\n",
      "1010 - random_35 - knn_k=1 - 0.8920552587214449 - 0.9315549245323961 - 6.239869201229517 - 0.9527592785207772 - 0.8925655351855712 - 1.9815411813033055 - 0.6741169945224558'\n",
      "1011 - random_83 - knn_k=5 - 4.427810703686812 - 2.0565009965442966 - 1.21049141032483 - 1.2829703733309634 - 0.9794462292448325 - 1.9917007095956532 - 0.6724461649452643'\n",
      "1012 - random_71 - knn_k=5 - 2.5737091265766585 - 0.8583904889736773 - 1.012676528539424 - 2.8083017571985933 - 2.7118224893708422 - 1.9929232252740365 - 0.6722451107924292'\n",
      "1013 - random_5 - knn_k=1 - 2.0868344733896333 - 1.1489107325408972 - 2.8586653632682757 - 2.4410012081140913 - 1.4599457081721787 - 1.9989932382396693 - 0.6712468403112539'\n",
      "1014 - random_71 - knn_k=1 - 2.3592947243619355 - 1.28844006042338 - 1.4267836218969694 - 2.5618514062749487 - 2.396781541942012 - 2.006592750372461 - 0.6699970293674469'\n",
      "1015 - random_73 - knn_k=5 - 0.7517848432299542 - 0.7474083878716064 - 0.8348497960347886 - 6.949924585796849 - 0.7766136882836139 - 2.011857069185121 - 0.6691312628354926'\n",
      "1016 - random_5 - deep - 1.6728860122720788 - 0.6947717494448372 - 1.8988242198309615 - 4.578549742943452 - 1.2248654015499953 - 2.013808986402196 - 0.6688102531016452'\n",
      "1017 - random_35 - knn_k=50 - 0.9712287958113276 - 0.7976781215936826 - 6.242852203614283 - 1.1286473726710484 - 0.93448237898938 - 2.014745681677017 - 0.6686562034577713'\n",
      "1018 - random_77 - deep - 1.6053029479217138 - 0.6994537242318863 - 2.084522325155427 - 4.536337846603237 - 1.199539459706332 - 2.024852093532908 - 0.6669941107165989'\n",
      "1019 - random_71 - knn_k=10 - 2.7736253692830664 - 0.8108255299137389 - 0.9856175306306711 - 2.894757997172329 - 2.7599114094949986 - 2.04489568429389 - 0.6636977531562338'\n",
      "1020 - random_27 - deep - 1.8813414569999574 - 0.7542444892636686 - 1.7568784724515567 - 4.595115843250031 - 1.24136204065973 - 2.0456390161603477 - 0.6635755066234288'\n",
      "1021 - random_2 - deep - 1.5135216835891974 - 0.8052096976690748 - 1.7536761087558597 - 4.8699379133737555 - 1.2932016548434813 - 2.0469271552700743 - 0.6633636600835628'\n",
      "1022 - random_83 - knn_k=20 - 4.29718068495928 - 2.1982247180265597 - 1.1935964749650145 - 1.5219509101511424 - 1.0307706692954848 - 2.0485909156654976 - 0.663090037749319'\n",
      "1023 - random_8 - lwr_k=20 - 1.5316518818480616 - 1.8099101216261944 - 2.549035803190647 - 2.6160703200122466 - 1.7637438802919443 - 2.0540037108991247 - 0.662199852879374'\n",
      "1024 - random_21 - knn_k=5 - 1.6800872653406993 - 0.8274503946435456 - 2.248233070479965 - 4.089569473475039 - 1.4412918446234975 - 2.057161442030406 - 0.6616805344209633'\n",
      "1025 - random_35 - knn_k=100 - 1.0548905802243957 - 0.8442436766896533 - 6.19182190714994 - 1.386243902448796 - 0.9991215191966155 - 2.0950291093429305 - 0.6554528418800932'\n",
      "1026 - random_3 - lwr_k=100 - 3.96563957087917 - 3.810717755817078 - 1.153160976910978 - 0.8094007909842523 - 0.739915385652933 - 2.096134872186698 - 0.6552709888243645'\n",
      "1027 - random_3 - lwr_k=200 - 3.9342130501433465 - 3.791992628620506 - 1.1832078799153996 - 0.8402717640427095 - 0.7383921388663384 - 2.0979779409620996 - 0.654967878902907'\n",
      "1028 - random_62 - knn_k=5 - 1.037697591230361 - 0.8447197421226775 - 1.1580093305516512 - 3.7379023294647413 - 3.7688969704938704 - 2.109205357723164 - 0.653121425065678'\n",
      "1029 - random_60 - knn_k=1 - 2.1530775517874936 - 1.4778263589545304 - 2.3386660772736536 - 2.5223158109851096 - 2.080955707870727 - 2.114506893789412 - 0.6522495378078115'\n",
      "1030 - random_3 - lwr_k=50 - 3.9943036841666912 - 3.882295225164542 - 1.1670172998875825 - 0.78535885160015 - 0.7469573694984624 - 2.115560765055192 - 0.6520762188080755'\n",
      "1031 - random_62 - knn_k=10 - 1.0612645264212903 - 0.8014868677287736 - 1.1608155273031253 - 3.764212259106398 - 3.8539550251427213 - 2.128101106970052 - 0.6500138421330459'\n",
      "1032 - random_12 - knn_k=1 - 2.435145579293923 - 1.4189317757989826 - 2.038809017593913 - 3.281689881887793 - 1.48348010216302 - 2.131569273278587 - 0.6494434697023412'\n",
      "1033 - random_83 - lwr_k=20 - 5.706914523091542 - 1.9157786820719713 - 1.2705863476060797 - 0.9593670822545138 - 0.8554041809147855 - 2.141952954491288 - 0.6477357760780835'\n",
      "1034 - random_3 - lwr_k=20 - 4.011988731688556 - 3.91619837891492 - 1.1900431902615611 - 0.8440640839265348 - 0.7585971682319753 - 2.1445519331143985 - 0.647308349702663'\n",
      "1035 - random_35 - knn_k=10 - 0.832822920822865 - 0.7409326070997378 - 7.4220055524996535 - 0.8943360896453891 - 0.8732453203708473 - 2.152388105820377 - 0.6460196177111401'\n",
      "1036 - random_35 - knn_k=5 - 0.8077388659381901 - 0.762287337656622 - 7.484300313055575 - 0.8735591287333051 - 0.8693950579253111 - 2.159173972105269 - 0.6449036184472566'\n",
      "1037 - random_37 - deep - 2.284265354512715 - 1.0231139311856523 - 1.6236068553748317 - 4.282249287168593 - 1.6439607718641998 - 2.1713329473171434 - 0.6429039625357988'\n",
      "1038 - random_3 - lwr_k=500 - 4.096234173393763 - 3.872376410654796 - 1.2363557435139694 - 0.89761721373233 - 0.767538699923558 - 2.174396092843105 - 0.6424001981284697'\n",
      "1039 - random_71 - knn_k=20 - 2.9633973348507476 - 0.8135181309921209 - 1.008503937812021 - 3.1527198694873175 - 2.9992523858292373 - 2.187416943865963 - 0.6402587972304002'\n",
      "1040 - random_77 - knn_k=1 - 2.0071747365440546 - 1.165344721419655 - 2.7746290255795856 - 3.6641640759261014 - 1.3323664702178761 - 2.1886121196149424 - 0.6400622393850088'\n",
      "1041 - random_62 - knn_k=20 - 1.0740597338932765 - 0.7737358133634082 - 1.1986676630628343 - 3.8884898715113465 - 4.035222919839781 - 2.1937744453707326 - 0.6392132465664773'\n",
      "1042 - random_1 - deep - 1.8726218424435455 - 0.8139536510436213 - 1.8395645040750994 - 5.205925023531277 - 1.29088165835923 - 2.2044125101671463 - 0.637463718638897'\n",
      "1043 - random_68 - knn_k=1 - 2.509989255208412 - 1.2988639257919428 - 2.4726017139199885 - 2.808588217391021 - 2.011535338724092 - 2.2202508392319924 - 0.6348589556301468'\n",
      "1044 - random_3 - knn_k=5 - 4.030276408834686 - 3.8371077551843285 - 1.4154826863434846 - 1.0512201319209122 - 0.8644279903211682 - 2.2400507648119214 - 0.6316026724314423'\n",
      "1045 - random_62 - lr - 0.892981934955972 - 0.7209487369125861 - 0.8532739066366536 - 4.41769431298661 - 4.317104444508917 - 2.2401063877233947 - 0.6315935247227118'\n",
      "1046 - random_3 - knn_k=10 - 4.0218019592744145 - 3.9174397163169874 - 1.389264715141843 - 1.06546825694038 - 0.8710381786026012 - 2.253354981242217 - 0.6294146694382485'\n",
      "1047 - random_83 - knn_k=50 - 4.558733522894682 - 2.3843149479088157 - 1.2625708077994946 - 1.9483323793305838 - 1.1185389326468957 - 2.2547479695053956 - 0.6291855794722752'\n",
      "1048 - random_59 - lwr_k=20 - 2.4765458064453827 - 1.9591518011684008 - 2.5004443735954363 - 2.261430478575888 - 2.0982361114815395 - 2.2591532328510615 - 0.6284610926573904'\n",
      "1049 - random_82 - deep - 1.5805609575475161 - 0.6752493017266628 - 2.13718235468228 - 5.725591376576825 - 1.2571491015275646 - 2.2749110886034867 - 0.6258695672041381'\n",
      "1050 - random_3 - knn_k=1 - 3.7965606549466444 - 3.8021255004480645 - 1.9103618037042671 - 1.1256853781148748 - 0.8377680054621501 - 2.2948092077282123 - 0.6225971336512216'\n",
      "1051 - random_73 - deep - 2.0412668006245207 - 0.835772320880469 - 1.4151862174333734 - 5.86293668276965 - 1.3708369846951056 - 2.3050218833242515 - 0.6209175650282541'\n",
      "1052 - random_3 - lwr_k=1000 - 4.361636931716693 - 4.123287558419277 - 1.2945479799587691 - 0.9660438771024229 - 0.7929083957686563 - 2.3080821518977164 - 0.6204142736741967'\n",
      "1053 - random_62 - knn_k=50 - 1.1448521134886382 - 0.7573701636464074 - 1.3201205457448446 - 4.112063067804041 - 4.271520492855121 - 2.3209040050719776 - 0.6183055998360523'\n",
      "1054 - random_3 - knn_k=20 - 4.172152142462051 - 4.107575213715054 - 1.4048486463246965 - 1.0974624643184152 - 0.9154743395352125 - 2.339872169383756 - 0.6151861075677924'\n",
      "1055 - random_30 - knn_k=1 - 2.266375837616978 - 1.4621315795013405 - 2.370214687336322 - 2.9740236358278804 - 2.631483773589872 - 2.340748059991844 - 0.6150420591540998'\n",
      "1056 - random_58 - lwr_k=200 - 3.6075097795197277 - 2.6056962000141146 - 1.3724153403848947 - 1.6806347775528023 - 2.5217519263518273 - 2.3577553722426043 - 0.6122450473717216'\n",
      "1057 - random_58 - lwr_k=100 - 3.6312968482429397 - 2.655654622385815 - 1.3753000378637452 - 1.6620266586924093 - 2.487449310731561 - 2.362505859007587 - 0.6114637853323248'\n",
      "1058 - random_88 - deep - 1.771517517751397 - 0.8613212999470604 - 1.8926825550302588 - 5.862979450264995 - 1.4642912849508516 - 2.370342013982906 - 0.6101750578260905'\n",
      "1059 - random_58 - lwr_k=500 - 3.6351439509410555 - 2.6064295832054305 - 1.3743113221347658 - 1.737848555272405 - 2.570679188034423 - 2.3850335985969746 - 0.6077588875723012'\n",
      "1060 - random_62 - knn_k=1 - 1.4963464264984376 - 1.2943492739883795 - 1.73521051379728 - 3.711597857799828 - 3.7021279944246506 - 2.3877226402442195 - 0.6073166494890725'\n",
      "1061 - random_58 - lwr_k=50 - 3.765412047047239 - 2.7166347058608196 - 1.3794212594705588 - 1.5970899497132052 - 2.4798568374391676 - 2.3878581478381515 - 0.6072943639961479'\n",
      "1062 - random_7 - knn_k=1 - 2.1874827405011987 - 1.3254980914704906 - 3.4798330474520918 - 2.813464368854762 - 2.201386596863078 - 2.401400543950713 - 0.605067190123523'\n",
      "1063 - random_83 - knn_k=100 - 4.750342666669228 - 2.517430117159726 - 1.3329225282730788 - 2.311502211598201 - 1.144551106131565 - 2.411600708652861 - 0.6033896775081579'\n",
      "1064 - random_58 - lwr_k=1000 - 3.6861652845318593 - 2.6543428445533435 - 1.3808177904214163 - 1.7524003426128487 - 2.590920140474107 - 2.4130847567626126 - 0.6031456118975905'\n",
      "1065 - random_21 - deep - 1.6515150431060008 - 0.7335952843929817 - 2.6643459040526247 - 5.6379432022204385 - 1.407188903379734 - 2.4186659009270537 - 0.6022277420706028'\n",
      "1066 - random_62 - knn_k=100 - 1.2264576188112226 - 0.7604364326342995 - 1.4142224393874656 - 4.321785174670124 - 4.457572822559385 - 2.435798726831984 - 0.5994100867909837'\n",
      "1067 - random_26 - knn_k=1 - 2.555863147039443 - 1.304054744706277 - 3.167550260208463 - 3.113364056540925 - 2.089817032266808 - 2.446023879993426 - 0.5977284645894572'\n",
      "1068 - random_71 - knn_k=50 - 3.3306372107287636 - 0.8137274657672006 - 1.0885676591283542 - 3.577737120505762 - 3.422210329104945 - 2.4464990952899126 - 0.5976503109832999'\n",
      "1069 - random_55 - lr - 2.5294370469207537 - 2.324026642462596 - 2.421410874670482 - 2.5527146092952466 - 2.525403323094244 - 2.4705894936112682 - 0.5936884193596542'\n",
      "1070 - random_63 - knn_k=1 - 2.2734353821164404 - 1.4473290919610724 - 2.4297690008223882 - 4.242167020650008 - 2.0288709643631586 - 2.4841862008196194 - 0.5914523135186738'\n",
      "1071 - random_3 - knn_k=50 - 4.3943754317190775 - 4.330764716675875 - 1.444778185627855 - 1.2165553900532393 - 1.0469711375402324 - 2.4870740844361428 - 0.5909773740113338'\n",
      "1072 - random_69 - knn_k=1 - 2.199327232921343 - 1.3252877635224216 - 3.637691127611023 - 2.9809996679281374 - 2.384643835657687 - 2.5054373321330687 - 0.5879573659457599'\n",
      "1073 - random_58 - knn_k=20 - 4.032381156487236 - 2.9402027316640376 - 1.4456080311386545 - 1.753654821636879 - 2.632139261749615 - 2.5609872015091173 - 0.5788216696720923'\n",
      "1074 - random_58 - knn_k=50 - 3.9754630215991513 - 2.944193478618878 - 1.431882332285074 - 1.8722066656375753 - 2.6385127050580492 - 2.57263381608821 - 0.5769062748276726'\n",
      "1075 - random_58 - lwr_k=20 - 3.965757534349956 - 2.8156323233940994 - 1.3966734590054037 - 2.1347723436938724 - 2.551727963999325 - 2.573080612838435 - 0.5768327949176033'\n",
      "1076 - random_58 - knn_k=10 - 4.243815346268595 - 2.992115753582745 - 1.4587758459819968 - 1.7073982296003616 - 2.612544970482121 - 2.603138412578923 - 0.5718895082426174'\n",
      "1077 - random_58 - knn_k=100 - 3.970919388604783 - 2.952364640506062 - 1.4307676476693387 - 2.038229954860933 - 2.6660147496423843 - 2.6118337748685456 - 0.5704594744772861'\n",
      "1078 - random_64 - knn_k=1 - 2.8006570589613147 - 1.2701204471125633 - 2.6435609566377405 - 4.114692925611286 - 2.2897017703136266 - 2.623625843823654 - 0.5685201582984712'\n",
      "1079 - random_3 - knn_k=100 - 4.594317428506501 - 4.556449638484942 - 1.4785724994561376 - 1.296631536195991 - 1.1930803349868315 - 2.6242109389828596 - 0.5684239339198052'\n",
      "1080 - random_55 - knn_k=1 - 2.532261272943012 - 2.53623485796151 - 2.6630567272019103 - 2.8993634473674605 - 2.490243369336125 - 2.6242134615747097 - 0.56842351905595'\n",
      "1081 - random_44 - knn_k=1 - 2.246134979228649 - 1.417160556967922 - 2.212807871903947 - 3.3887500610183205 - 3.904395520870888 - 2.633685108605644 - 0.5668658179945807'\n",
      "1082 - random_19 - knn_k=1 - 2.538657002303999 - 1.6633977335340937 - 2.846037208301624 - 4.204940280172762 - 1.9404468979187288 - 2.6385854429113356 - 0.5660599121237103'\n",
      "1083 - random_28 - knn_k=1 - 2.527275005733898 - 1.575169329446827 - 2.548407875346338 - 4.56828151240232 - 2.0549292760178393 - 2.65468868469353 - 0.5634115831970001'\n",
      "1084 - random_71 - knn_k=100 - 3.6682612706272533 - 0.8197639081151135 - 1.1650185875604675 - 3.961976076181283 - 3.7784559684451646 - 2.6786059233082518 - 0.5594781693088453'\n",
      "1085 - random_83 - knn_k=1 - 5.953510342678775 - 2.5888373852440805 - 1.7444206774530422 - 1.8101387239276165 - 1.4639532524507757 - 2.7124921342009114 - 0.5539052645647295'\n",
      "1086 - random_67 - lwr_k=1000 - 6.376560190082502 - 0.7788466904625669 - 1.9004216414169302 - 3.2735541840040714 - 1.2709375518155337 - 2.7202401220528754 - 0.5526310353983487'\n",
      "1087 - random_67 - lwr_k=500 - 6.3791854873719185 - 0.7803179635603477 - 1.8977896156102843 - 3.2720273574440366 - 1.2766823840630088 - 2.7213768192908585 - 0.5524440948917737'\n",
      "1088 - random_67 - lwr_k=100 - 6.376243941559878 - 0.7845935968882649 - 1.9023489007423227 - 3.256539578006819 - 1.2878597424438722 - 2.7216934815560894 - 0.5523920168165419'\n",
      "1089 - random_67 - lwr_k=200 - 6.38136139563315 - 0.785027181331112 - 1.8960886386588194 - 3.267364101173776 - 1.2800990504936822 - 2.7221648762121675 - 0.5523144915504823'\n",
      "1090 - random_67 - knn_k=100 - 6.376244001260474 - 0.7857163721978975 - 1.9053682867055202 - 3.2673104437998615 - 1.2919949529099326 - 2.7255024741493936 - 0.5517655923112833'\n",
      "1091 - random_67 - lr - 6.3796425170401925 - 0.7844519745983133 - 1.913805516011661 - 3.286656475652775 - 1.2774056543563157 - 2.7285676800094305 - 0.5512614905002782'\n",
      "1092 - random_94 - deep - 1.7156518376625887 - 0.7901952065462452 - 2.1870154171753713 - 7.6829874980621025 - 1.3655802625895037 - 2.7479790479210293 - 0.5480691110685196'\n",
      "1093 - random_58 - lr - 3.8012949789438553 - 2.8809248080613648 - 1.2665374083659455 - 3.2012406333624708 - 2.5894922859715876 - 2.7480198073529856 - 0.5480624059788652'\n",
      "1094 - random_6 - lwr_k=500 - 2.8759448085746606 - 2.699910631636055 - 2.632099430505905 - 2.778586289171148 - 2.7549473963708975 - 2.7483058471599353 - 0.5480153640536938'\n",
      "1095 - random_58 - knn_k=5 - 4.6185160051994405 - 3.173881307054938 - 1.5420640606326699 - 1.7600735252655602 - 2.7149039171927534 - 2.7621206332996326 - 0.5457433930900255'\n",
      "1096 - random_67 - lwr_k=50 - 6.534872880433508 - 0.7993640506684834 - 1.9234698887417498 - 3.2719840864736707 - 1.2961427081084158 - 2.765351890559702 - 0.5452119825711234'\n",
      "1097 - random_67 - knn_k=50 - 6.534873661330036 - 0.7994053199788439 - 1.9241612761420863 - 3.279515458958515 - 1.299803910737063 - 2.767736607746128 - 0.5448197934956405'\n",
      "1098 - random_16 - knn_k=1 - 2.8758465272847578 - 1.484615561241565 - 2.9997472685413635 - 4.185085325377396 - 2.3285659572969837 - 2.7746500706534665 - 0.5436828097721838'\n",
      "1099 - random_67 - lwr_k=20 - 6.410994372089644 - 0.8174064661038221 - 1.9699672990596484 - 3.3898309868407845 - 1.3469900406703197 - 2.787207646663816 - 0.5416175987887444'\n",
      "1100 - random_67 - knn_k=20 - 6.4109942454384745 - 0.8163144187243894 - 1.9679037371136112 - 3.39319852297967 - 1.350619175959169 - 2.787975563937959 - 0.541491307601048'\n",
      "1101 - random_6 - lwr_k=1000 - 2.9303086890510004 - 2.710975925074856 - 2.6642569065679518 - 2.8760344410061047 - 2.8253661412180042 - 2.801392373342048 - 0.5392847876388194'\n",
      "1102 - random_55 - knn_k=5 - 2.8233630578946114 - 2.7162207695851968 - 2.7983435950198547 - 2.938144177425681 - 2.840345876852703 - 2.8232725137129044 - 0.5356863936354025'\n",
      "1103 - random_35 - deep - 1.43165734947003 - 0.9170898670964268 - 6.162661981288902 - 4.14163494746543 - 1.4775916844667596 - 2.825788044488441 - 0.5352726929108993'\n",
      "1104 - random_3 - lr - 5.257086289404227 - 5.076543191228168 - 1.482550231165246 - 1.3676421324351322 - 0.9699827245518049 - 2.831240497790288 - 0.5343759840293669'\n",
      "1105 - random_55 - lwr_k=1000 - 2.8804566198639807 - 2.752011421008978 - 2.867914486020572 - 2.882947458322395 - 2.828695716900408 - 2.8423997675799106 - 0.532540737599825'\n",
      "1106 - random_24 - knn_k=1 - 2.7995944204991 - 1.3757324354798806 - 2.9561422441250644 - 5.003577476309707 - 2.1538251196110663 - 2.85761623801194 - 0.5300382465267461'\n",
      "1107 - random_72 - knn_k=1 - 2.674020133984803 - 1.3356014890261614 - 3.1218212161142738 - 5.071201166316798 - 2.273091638411239 - 2.894964345704085 - 0.5238960004314064'\n",
      "1108 - random_55 - knn_k=10 - 2.985493533366559 - 2.879752769143431 - 2.9180534627628307 - 2.989690353698928 - 2.8897850310218107 - 2.9325550439837778 - 0.5177138580419514'\n",
      "1109 - random_6 - lwr_k=200 - 3.046210447864138 - 2.95862313238665 - 2.8462535972485026 - 2.9624541869406156 - 2.9661121283604377 - 2.9559402419991088 - 0.5138679432132163'\n",
      "1110 - random_33 - lr - 3.0847803727978476 - 3.016907719503518 - 2.9648179346133774 - 2.7149295240337254 - 3.0229661548024986 - 2.960898810397781 - 0.5130524602003614'\n",
      "1111 - random_81 - knn_k=1 - 2.505682476881064 - 1.9517721997271806 - 2.822570154938113 - 5.051063299061031 - 2.630810176656027 - 2.9922228861861777 - 0.5079009225699322'\n",
      "1112 - random_55 - lwr_k=500 - 3.0309259837455245 - 2.9351863485063774 - 3.04016580124039 - 3.0292479022720973 - 2.9424126927842167 - 2.995585173018367 - 0.5073479630107316'\n",
      "1113 - random_67 - knn_k=10 - 7.172810169641005 - 0.8538093815859139 - 2.0434165512332605 - 3.5877478617808802 - 1.3997267718768878 - 3.0117078149773135 - 0.5046964435432613'\n",
      "1114 - random_55 - lwr_k=20 - 3.099190684231596 - 3.0309902933065542 - 3.069131498565139 - 3.100623099271315 - 2.9683075224625113 - 3.053650968544882 - 0.4977984991186012'\n",
      "1115 - random_6 - knn_k=1 - 3.066063685827233 - 3.0991645325069617 - 2.8668687641350967 - 3.318373868895324 - 2.964422517290544 - 3.0629827048202203 - 0.49626380769133005'\n",
      "1116 - random_67 - knn_k=5 - 6.943363814868382 - 0.9262042399642428 - 2.212185006326705 - 3.7206129066194387 - 1.525601726414228 - 3.0657719807373014 - 0.49580508514367816'\n",
      "1117 - random_67 - deep - 6.38784473623723 - 0.8051880656174356 - 2.1365350565626393 - 4.742817783747365 - 1.3069180490055123 - 3.0759676302548256 - 0.49412831712919547'\n",
      "1118 - random_70 - knn_k=1 - 3.002904387895308 - 1.4468799635421623 - 3.066902727692198 - 5.510728568590008 - 2.434949391575913 - 3.092294896417496 - 0.4914431432585217'\n",
      "1119 - random_55 - knn_k=20 - 3.153082496713927 - 3.0882474750375453 - 3.1304021269794013 - 3.175611637096962 - 3.032283077668046 - 3.1159263357279543 - 0.48755673174261904'\n",
      "1120 - random_6 - lwr_k=100 - 3.2243161958604034 - 3.1864782455692104 - 3.0739003798877462 - 3.1657830645484206 - 3.203445739514924 - 3.1707918309056704 - 0.4785335872154042'\n",
      "1121 - random_33 - knn_k=1 - 3.048933188102653 - 3.184096727011483 - 2.9421481912055905 - 3.3117256760786877 - 3.3786274592209824 - 3.173094630321258 - 0.4781548702845403'\n",
      "1122 - random_55 - lwr_k=200 - 3.295533826345317 - 3.19496456497772 - 3.289770488687654 - 3.2662120330534137 - 3.19093503546761 - 3.2474827310748413 - 0.46592105043054177'\n",
      "1123 - random_55 - lwr_k=50 - 3.2657353115733327 - 3.2139962437894027 - 3.3106777017135998 - 3.2980683105701685 - 3.191425518010708 - 3.255977308808829 - 0.46452403756584126'\n",
      "1124 - random_6 - knn_k=5 - 3.302463689423301 - 3.268788142912761 - 3.073814490996091 - 3.3218906498940406 - 3.3755065846450476 - 3.268496228963818 - 0.4624651838998488'\n",
      "1125 - random_6 - lwr_k=50 - 3.3533393470697166 - 3.317106565662417 - 3.208326910686921 - 3.2895264754186933 - 3.380248210802348 - 3.3097147397548388 - 0.45568641376646635'\n",
      "1126 - random_55 - lwr_k=100 - 3.3380672412663674 - 3.2757583970531865 - 3.3772178587690234 - 3.350481048520845 - 3.2675371105563933 - 3.3218092724131933 - 0.45369735459891547'\n",
      "1127 - random_6 - lwr_k=20 - 3.3387860814377337 - 3.3455124370980376 - 3.2477649497889445 - 3.3356252287196373 - 3.429395591057782 - 3.339417418573342 - 0.4508015300530017'\n",
      "1128 - random_33 - knn_k=5 - 3.2837058654798525 - 3.4469272751596605 - 3.2111208488597027 - 3.432640605711147 - 3.359799383829662 - 3.346842589233279 - 0.4495803911972084'\n",
      "1129 - random_33 - lwr_k=1000 - 3.4623837682627494 - 3.4156857543745978 - 3.2252354929746194 - 3.3109241745540667 - 3.33372802151279 - 3.3496098047498446 - 0.449125296689029'\n",
      "1130 - random_6 - knn_k=10 - 3.464269954046172 - 3.4472495058444257 - 3.2546253116526946 - 3.504463628963389 - 3.5512497402162833 - 3.4443739660837838 - 0.43354044283968785'\n",
      "1131 - random_55 - knn_k=50 - 3.4522729787068958 - 3.4080136213931693 - 3.525820293180846 - 3.5115127549720437 - 3.394519881002697 - 3.4584220991162087 - 0.43123009579408966'\n",
      "1132 - random_33 - lwr_k=500 - 3.591719931714242 - 3.5127237524143355 - 3.3697587418956596 - 3.4249115186496057 - 3.444583126308911 - 3.4687565528596322 - 0.42953049808819677'\n",
      "1133 - random_33 - knn_k=10 - 3.5451394267119998 - 3.560888649538611 - 3.2879942253449546 - 3.517467389901629 - 3.484239245264676 - 3.47916095225707 - 0.42781939716442197'\n",
      "1134 - random_6 - lr - 3.851386811107871 - 3.5869768883806485 - 3.208507099839956 - 3.433949970454358 - 3.5226354390030172 - 3.520731991214774 - 0.42098265047241024'\n",
      "1135 - random_21 - knn_k=1 - 3.140044302083168 - 1.4201867859448418 - 3.6542052971155057 - 7.252701954481957 - 2.4100301697751223 - 3.575167777396878 - 0.41203017561398236'\n",
      "1136 - random_33 - lwr_k=20 - 3.791751029633325 - 3.66963158177963 - 3.4039155571609476 - 3.5505106776126505 - 3.5901569005542298 - 3.6012197348863126 - 0.40774568721407634'\n",
      "1137 - random_6 - knn_k=20 - 3.6126509957577984 - 3.5989182187909803 - 3.5432780588374744 - 3.6323577643494356 - 3.7039879295776115 - 3.618236036700971 - 0.40494719701372306'\n",
      "1138 - random_33 - knn_k=20 - 3.8790688236057886 - 3.7464714517528224 - 3.4663174030965784 - 3.641856407573917 - 3.6835120406844095 - 3.6834717753144424 - 0.3942185688305213'\n",
      "1139 - random_33 - lwr_k=200 - 3.837873719951464 - 3.7385637039509954 - 3.5763950395289705 - 3.616276096303746 - 3.6689390447125936 - 3.6876301756198067 - 0.39353468095462074'\n",
      "1140 - random_33 - lwr_k=50 - 3.898619464738409 - 3.791609668213876 - 3.5589549657066235 - 3.6771868517346165 - 3.7175729286750125 - 3.7288126571092652 - 0.3867618361773141'\n",
      "1141 - random_33 - lwr_k=100 - 3.925599919965116 - 3.8234697860098974 - 3.6202153765524847 - 3.6756486633507857 - 3.744862181197182 - 3.7579831180095447 - 0.381964480685012'\n",
      "1142 - random_87 - lwr_k=500 - 3.869973586521293 - 3.6236143273228008 - 3.4025645863305622 - 4.775083398624604 - 3.1695788001045115 - 3.768158552800081 - 0.38029103513522056'\n",
      "1143 - random_55 - knn_k=100 - 3.78919230223704 - 3.7230299127284288 - 3.8514031978918015 - 3.77983596832507 - 3.7384266378184603 - 3.7763734431562845 - 0.3789400194792212'\n",
      "1144 - random_87 - lwr_k=200 - 3.9758999108590243 - 3.6319545873149313 - 3.382282476675903 - 4.719402646139366 - 3.2241075223624183 - 3.78673295932531 - 0.3772363000227147'\n",
      "1145 - random_87 - lwr_k=100 - 4.082288152031857 - 3.6280800232692734 - 3.385007234949528 - 4.733464741475187 - 3.2433532232026154 - 3.8144470398825643 - 0.37267845991761805'\n",
      "1146 - random_87 - lwr_k=1000 - 3.7925077752627376 - 3.6410078500530023 - 3.4829456172920534 - 5.110458911381826 - 3.146002690936056 - 3.834560379546349 - 0.3693706328375299'\n",
      "1147 - random_87 - lwr_k=50 - 4.153767734913445 - 3.6605531065536265 - 3.3819222314252397 - 4.735102714609148 - 3.2642606542067263 - 3.8391352565478356 - 0.3686182514684211'\n",
      "1148 - random_87 - lwr_k=20 - 4.267523009128198 - 3.746174972324919 - 3.4659129701860425 - 4.960090059206984 - 3.3099675598264056 - 3.949945398650337 - 0.3503944858023421'\n",
      "1149 - random_33 - knn_k=50 - 4.129656287675445 - 4.017101268269016 - 3.7514281671586867 - 3.916388254812597 - 3.9487575591408643 - 3.9526910892775837 - 0.3499429312638035'\n",
      "1150 - random_6 - knn_k=50 - 3.973855613092204 - 3.9054699750596344 - 3.905769486407707 - 3.9314871143508388 - 4.050577970338934 - 3.9534292050714255 - 0.34982154120864983'\n",
      "1151 - random_87 - knn_k=50 - 4.214124362416804 - 3.6538679476306273 - 3.691032822818661 - 5.035153051505306 - 3.361993002860907 - 3.991222486659678 - 0.3436060820967992'\n",
      "1152 - random_87 - knn_k=20 - 4.288456771197525 - 3.7082064033097435 - 3.5870485003176276 - 5.0056611926014085 - 3.3670048316773844 - 3.991276988403664 - 0.3435971187745622'\n",
      "1153 - random_92 - deep - 2.477423333583458 - 0.7852017467238463 - 6.538485253860818 - 8.522117276945643 - 1.6461957247595034 - 3.993399647976198 - 0.34324803017187777'\n",
      "1154 - random_87 - lr - 4.106616746313888 - 3.6707594878331924 - 3.677002719190055 - 5.421553965702486 - 3.211183837230607 - 4.01739692234126 - 0.3393014510111195'\n",
      "1155 - random_87 - knn_k=100 - 4.197556953564489 - 3.6509399555967406 - 3.7541621625390844 - 5.09473534884457 - 3.4105860620235395 - 4.021576111368554 - 0.3386141442352'\n",
      "1156 - random_67 - knn_k=1 - 6.446605094091744 - 1.5248532209614816 - 3.632696992374729 - 6.03289440771491 - 2.5101423274790515 - 4.029429435161418 - 0.33732259158680955'\n",
      "1157 - random_45 - knn_k=20 - 4.951510111717612 - 0.8042429730480783 - 5.01559203641483 - 4.655315142830218 - 4.914287997866023 - 4.067945285077057 - 0.3309882993462744'\n",
      "1158 - random_45 - lwr_k=20 - 4.949494684359949 - 0.8211693727590725 - 5.013052826445245 - 4.653835545097316 - 4.911816854589895 - 4.069630674176862 - 0.33071112132422475'\n",
      "1159 - random_45 - knn_k=10 - 4.958544142891634 - 0.828272387409069 - 4.981654893579923 - 4.601173219248254 - 4.990456836439661 - 4.071778330807824 - 0.3303579190772893'\n",
      "1160 - random_45 - lr - 4.894220682590446 - 0.776928704925105 - 4.960687500970057 - 4.91269870780829 - 4.877190257879343 - 4.0840888024345094 - 0.3283333467240104'\n",
      "1161 - random_83 - deep - 10.724978046945695 - 3.6134780731612195 - 1.9312715341912647 - 3.1342220800858014 - 1.1997366077601297 - 4.12136312159466 - 0.3222032385724284'\n",
      "1162 - random_87 - knn_k=10 - 4.399333691473971 - 3.863255797527175 - 3.6775050539651297 - 5.239982537346097 - 3.429267109893459 - 4.1218707731482205 - 0.3221197477914106'\n",
      "1163 - random_45 - lwr_k=50 - 5.096058824229894 - 0.7905181078169982 - 5.08046743336383 - 4.844220400909916 - 4.97390615338018 - 4.156785006005875 - 0.3163777752071659'\n",
      "1164 - random_45 - knn_k=50 - 5.108423193556737 - 0.7881097328084962 - 5.087712326850191 - 4.848720319101229 - 4.980690893664679 - 4.162481967630671 - 0.3154408565128203'\n",
      "1165 - random_45 - knn_k=5 - 5.09536391215879 - 0.9031568986008076 - 5.105876270625732 - 4.762408097594549 - 4.976405600305758 - 4.168402085696897 - 0.3144672376516999'\n",
      "1166 - random_33 - knn_k=100 - 4.3387564633103874 - 4.273734479840186 - 4.0264695968911415 - 4.046006511192121 - 4.194270711988888 - 4.175874322900946 - 0.3132383582619237'\n",
      "1167 - random_45 - lwr_k=100 - 5.174115425506394 - 0.7781022417398815 - 5.205591978476615 - 4.99923287086755 - 5.011232405309694 - 4.233396814363447 - 0.30377824581145885'\n",
      "1168 - random_45 - knn_k=100 - 5.2040799840011935 - 0.7895023343540997 - 5.22247208099084 - 5.011539824706745 - 5.0303399325892055 - 4.2513292259758915 - 0.3008290927749925'\n",
      "1169 - random_6 - knn_k=100 - 4.3404199518620965 - 4.2144897901343175 - 4.250650335488168 - 4.1840567193459055 - 4.3478504583008055 - 4.267495496072444 - 0.29817039825169156'\n",
      "1170 - random_58 - knn_k=1 - 7.452191390784286 - 4.714723051106041 - 2.487901475267892 - 2.73925168515249 - 3.964894260644695 - 4.27216430132201 - 0.2974025695024969'\n",
      "1171 - random_45 - lwr_k=200 - 5.307566847377659 - 0.7745691972282216 - 5.34863166776539 - 5.16565875064366 - 5.132180439101044 - 4.3454535394545815 - 0.28534946789797055'\n",
      "1172 - random_87 - knn_k=5 - 4.77207835571703 - 4.295618826765849 - 3.9406742947996194 - 5.5894076256523775 - 3.687214319744918 - 4.45701446156464 - 0.2670022294281852'\n",
      "1173 - random_45 - lwr_k=500 - 5.483817634380465 - 0.7658010993232272 - 5.480241320278563 - 5.325824541693548 - 5.26976298494607 - 4.464814361094756 - 0.265719462900151'\n",
      "1174 - random_45 - lwr_k=1000 - 5.560760112847336 - 0.7708593123131368 - 5.556482513532923 - 5.358824697154214 - 5.343948667719904 - 4.5178974246329995 - 0.2569894559494904'\n",
      "1175 - random_38 - lwr_k=1000 - 6.376560190082502 - 0.6888066129605009 - 6.161921442268553 - 3.542089285031953 - 5.905006382724211 - 4.53467103566608 - 0.2542308785210987'\n",
      "1176 - random_38 - lwr_k=500 - 6.3791854873719185 - 0.6907654336250793 - 6.1728821818732715 - 3.5383138514527825 - 5.920384054507838 - 4.540099810729169 - 0.2533380656185391'\n",
      "1177 - random_38 - lwr_k=200 - 6.38136139563315 - 0.6879886275968757 - 6.167948899924199 - 3.5586981015462933 - 5.911529994114458 - 4.54129870485268 - 0.2531408962516315'\n",
      "1178 - random_38 - lwr_k=100 - 6.376243941559878 - 0.6930246927619269 - 6.191821162485071 - 3.5578990907834753 - 5.9211413125626855 - 4.547817994101051 - 0.252068738078043'\n",
      "1179 - random_38 - knn_k=100 - 6.376244001260474 - 0.702000309947112 - 6.19182190714994 - 3.5631768229916703 - 5.921140806080239 - 4.550669059649327 - 0.25159985364684745'\n",
      "1180 - random_38 - knn_k=50 - 6.534873661330036 - 0.6986905306615764 - 6.242852203614283 - 3.5988870266291637 - 5.923798187260375 - 4.599618507440884 - 0.24354965851929167'\n",
      "1181 - random_38 - lwr_k=50 - 6.534872880433508 - 0.7135298299351501 - 6.2428524976329784 - 3.5988435604224094 - 5.9237984501939405 - 4.602578544916671 - 0.24306285263403582'\n",
      "1182 - random_38 - knn_k=20 - 6.4109942454384745 - 0.7122329275678003 - 6.301486607324462 - 3.704951036557078 - 5.904964089792113 - 4.606711182240352 - 0.24238320172175742'\n",
      "1183 - random_38 - lwr_k=20 - 6.410994372089644 - 0.8305247285371488 - 6.301484121893587 - 3.706667420273305 - 5.904964094631818 - 4.63071956349882 - 0.23843479857223815'\n",
      "1184 - random_38 - deep - 6.387074367763936 - 0.7223883730867326 - 6.162342597326949 - 4.253641998009026 - 5.905457276338424 - 4.685948649284568 - 0.22935186126670093'\n",
      "1185 - random_45 - knn_k=1 - 5.901445556219796 - 1.4265871225334277 - 6.355792615345644 - 5.370686637884185 - 5.862680045564738 - 4.983167522576663 - 0.18047143083482375'\n",
      "1186 - random_38 - knn_k=10 - 7.172810169641005 - 0.7298963214889619 - 7.4220055524996535 - 4.06749577738407 - 5.91051328659929 - 5.060316508326958 - 0.16778355758592467'\n",
      "1187 - random_38 - knn_k=5 - 6.943363814868382 - 0.768824877807808 - 7.484300313055575 - 4.1896360457085065 - 6.260097641200401 - 5.128983165054065 - 0.1564906827865189'\n",
      "1188 - random_87 - deep - 5.330579200605664 - 3.958075586008744 - 5.153442398968174 - 8.54001353947289 - 4.554669142258975 - 5.507178799961846 - 0.09429287226396477'\n",
      "1189 - random_47 - lwr_k=1000 - 6.162656691356333 - 6.093086073290388 - 6.161921442268553 - 5.715933466449311 - 5.905006382724211 - 6.007745477727943 - 0.011969990379709472'\n",
      "1190 - random_47 - lwr_k=500 - 6.171697272146623 - 6.109102572963855 - 6.1728821818732715 - 5.73224760418363 - 5.920384054507838 - 6.021287195600538 - 0.009742928049999322'\n",
      "1191 - random_47 - lwr_k=200 - 6.17373924421489 - 6.105296827231455 - 6.167948899924199 - 5.791504896620431 - 5.911529994114458 - 6.030026455291812 - 0.008305674945843222'\n",
      "1192 - random_47 - knn_k=100 - 6.162145791489569 - 6.144776882615169 - 6.19182190714994 - 5.852323316286935 - 5.921140806080239 - 6.054462069116143 - 0.004287009399602026'\n",
      "1193 - random_47 - lwr_k=100 - 6.1625767908070355 - 6.144776674500061 - 6.191821162485071 - 5.858849474377996 - 5.9211413125626855 - 6.055853169920437 - 0.004058229843919348'\n",
      "1194 - random_86 - lwr_k=1000 - 6.376560190082502 - 6.093086073290388 - 6.161921442268553 - 5.864482083524555 - 5.90493429481561 - 6.080228561061337 - 4.946848198661424e-05'\n",
      "1195 - random_14 - lwr_k=1000 - 6.376560190082502 - 6.093086073290388 - 6.161921442268553 - 5.864482083524555 - 5.905006382724211 - 6.080242975683175 - 4.7097862424516634e-05'\n",
      "1196 - random_14 - deep - 6.377360093403988 - 6.091894046534875 - 6.162663342282023 - 5.862979701901853 - 5.907958895274011 - 6.08060288224079 - -1.2088115954433931e-05'\n",
      "1197 - random_14 - lr - 6.3796425170401925 - 6.09411446467585 - 6.162065407832034 - 5.872109960157973 - 5.90505507139898 - 6.082629157595392 - -0.0003453321009325716'\n",
      "1198 - random_86 - deep - 6.386593793709502 - 6.103030481969717 - 6.162311877068553 - 5.86620441060781 - 5.90585544417771 - 6.084832054779673 - -0.0007076151456777424'\n",
      "1199 - random_14 - lwr_k=200 - 6.38136139563315 - 6.105296827231455 - 6.167948899924199 - 5.857947583664328 - 5.911529994114458 - 6.084849482131855 - -0.0007104852655022142'\n",
      "1200 - random_86 - lwr_k=200 - 6.38136139563315 - 6.105296827231455 - 6.167948899924199 - 5.857947583664328 - 5.911529994114458 - 6.084849482131855 - -0.0007104852655022142'\n",
      "1201 - random_14 - lwr_k=500 - 6.3791854873719185 - 6.109102572963855 - 6.1728821818732715 - 5.856816518779601 - 5.920384054507838 - 6.087706285839404 - -0.0011803133907311025'\n",
      "1202 - random_86 - lwr_k=500 - 6.3791854873719185 - 6.109102572963855 - 6.1728821818732715 - 5.856816518779601 - 5.923328487266349 - 6.0882950514946685 - -0.0012771414168504247'\n",
      "1203 - random_86 - lwr_k=100 - 6.376243941559878 - 6.144776674500061 - 6.191821162485071 - 5.859454980148711 - 5.9211413125626855 - 6.098720835908802 - -0.0029917593069028747'\n",
      "1204 - random_14 - lwr_k=100 - 6.376243941559878 - 6.144776674500061 - 6.191821162485071 - 5.859454980148711 - 5.9211413125626855 - 6.098720835908802 - -0.0029917593069028747'\n",
      "1205 - random_86 - knn_k=100 - 6.376244001260474 - 6.144776882615169 - 6.19182190714994 - 5.859455100149075 - 5.921140806080239 - 6.0987209611102875 - -0.00299177989745969'\n",
      "1206 - random_14 - knn_k=100 - 6.376244001260474 - 6.144776882615169 - 6.19182190714994 - 5.859455100149075 - 5.921140806080239 - 6.0987209611102875 - -0.00299177989745969'\n",
      "1207 - random_47 - deep - 6.186588783273947 - 6.1030700829409525 - 6.549066234173472 - 5.824099817804732 - 5.906939129565041 - 6.113959167511824 - -0.005497841606467935'\n",
      "1208 - random_47 - knn_k=50 - 6.29562124788092 - 6.235901641286987 - 6.242852203614283 - 6.036248684286965 - 5.923798187260375 - 6.146908797926821 - -0.010916720967271365'\n",
      "1209 - random_47 - lwr_k=50 - 6.2986829425645015 - 6.235901703681936 - 6.2428524976329784 - 6.043475929903769 - 5.9237984501939405 - 6.14896660165815 - -0.01125514606334077'\n",
      "1210 - random_14 - lwr_k=50 - 6.534872880433508 - 6.235901703681936 - 6.2428524976329784 - 5.877725245059973 - 5.9237984501939405 - 6.1630758045765415 - -0.013575536623638751'\n",
      "1211 - random_86 - lwr_k=50 - 6.534872880433508 - 6.235901703681936 - 6.2428524976329784 - 5.877725245059973 - 5.9237984501939405 - 6.1630758045765415 - -0.013575536623638751'\n",
      "1212 - random_14 - knn_k=50 - 6.534873661330036 - 6.235901641286987 - 6.242852203614283 - 5.877725084593729 - 5.923798187260375 - 6.163075804866866 - -0.013575536671385446'\n",
      "1213 - random_86 - knn_k=50 - 6.534873661330036 - 6.235901641286987 - 6.242852203614283 - 5.877725084593729 - 5.923798187260375 - 6.163075804866866 - -0.013575536671385446'\n",
      "1214 - random_47 - knn_k=20 - 6.163271868175667 - 6.430965413719734 - 6.301486607324462 - 6.117793607567792 - 5.904964089792113 - 6.183719602539446 - -0.01697060253904814'\n",
      "1215 - random_14 - lwr_k=20 - 6.410994372089644 - 6.430962501076351 - 6.301484121893587 - 5.889101655988783 - 5.904964094631818 - 6.187549281200797 - -0.017600429061933376'\n",
      "1216 - random_86 - lwr_k=20 - 6.410994372089644 - 6.430962501076351 - 6.301484121893587 - 5.889101655988783 - 5.904964094631818 - 6.187549281200797 - -0.017600429061933376'\n",
      "1217 - random_14 - knn_k=20 - 6.4109942454384745 - 6.430965413719734 - 6.301486607324462 - 5.889102472007728 - 5.904964089792113 - 6.187550497757492 - -0.01760062913607574'\n",
      "1218 - random_86 - knn_k=20 - 6.4109942454384745 - 6.430965413719734 - 6.301486607324462 - 5.889102472007728 - 5.904964089792113 - 6.187550497757492 - -0.01760062913607574'\n",
      "1219 - random_47 - lwr_k=20 - 6.177415975898373 - 6.430962501076351 - 6.301484121893587 - 6.125491027974091 - 5.904964094631818 - 6.188087384511266 - -0.01768892519097065'\n",
      "1220 - random_38 - knn_k=1 - 6.446605094091744 - 1.1905054473298915 - 6.239869201229517 - 8.551930399968649 - 9.716406178718696 - 6.428527335712258 - -0.05723152701704892'\n",
      "1221 - random_47 - knn_k=10 - 6.6924753196146645 - 8.404026551313887 - 7.4220055524996535 - 5.807528582836774 - 5.91051328659929 - 6.847453759430356 - -0.12612790087157544'\n",
      "1222 - random_14 - knn_k=1 - 6.446605094091744 - 6.180856216390306 - 6.239869201229517 - 5.887523156601586 - 9.716406178718696 - 6.89413279032319 - -0.13380470467644567'\n",
      "1223 - random_86 - knn_k=1 - 6.446605094091744 - 6.180856216390306 - 6.239869201229517 - 5.887523156601586 - 9.716406178718696 - 6.89413279032319 - -0.13380470467644567'\n",
      "1224 - random_87 - knn_k=1 - 7.556701670150778 - 6.336487732353349 - 5.587363070071762 - 9.227244377374861 - 5.848011431809741 - 6.911168930637646 - -0.136606457503889'\n",
      "1225 - random_14 - knn_k=5 - 6.943363814868382 - 7.459049411198213 - 7.484300313055575 - 6.949924585796849 - 6.260097641200401 - 7.0193844883624195 - -0.15440351946935515'\n",
      "1226 - random_86 - knn_k=5 - 6.943363814868382 - 7.459049411198213 - 7.484300313055575 - 6.949924585796849 - 6.260097641200401 - 7.0193844883624195 - -0.15440351946935515'\n",
      "1227 - random_47 - knn_k=5 - 7.193271099266448 - 7.459049411198213 - 7.484300313055575 - 6.965912207600528 - 6.260097641200401 - 7.072578204700481 - -0.1631517243092695'\n",
      "1228 - random_14 - knn_k=10 - 7.172810169641005 - 8.404026551313887 - 7.4220055524996535 - 6.559967979065029 - 5.91051328659929 - 7.094007297364454 - -0.16667593929298197'\n",
      "1229 - random_86 - knn_k=10 - 7.172810169641005 - 8.404026551313887 - 7.4220055524996535 - 6.559967979065029 - 5.91051328659929 - 7.094007297364454 - -0.16667593929298197'\n",
      "1230 - random_47 - knn_k=1 - 34.65093305986067 - 6.180856216390306 - 6.239869201229517 - 10.798641795563357 - 9.716406178718696 - 13.518757540269933 - -1.223286288023425'\n",
      "1231 - random_38 - lr - 6.3796288276955995 - 0.6931455223868036 - 6.162065407832034 - 3.6592728385714874 - 65.70837215526048 - 16.517831356061592 - -1.716512064989801'\n",
      "1232 - random_58 - deep - 6.392638463861457 - 3.1459787441192986 - 1.4890843331201855 - 143.41081965557115 - 3.038719854805259 - 31.489959963631296 - -4.178818815793821'\n",
      "1233 - random_86 - lr - 6.37901800720696 - 270.25129529062394 - 6.235767517579386 - 5.872114206662025 - 5.905056440139388 - 58.94494807654343 - -8.694048762724908'\n",
      "1234 - random_3 - deep - 261.2037156537106 - 261.2597224557014 - 1.7503904882642523 - 4.550660153923583 - 1.3508817177778396 - 106.0549377761447 - -16.441727709316687'\n",
      "1235 - random_62 - deep - 1.7701360092461569 - 0.7797527471953872 - 1.8808898705476609 - 277.53670819730974 - 274.63073799399626 - 111.2970535901248 - -17.30384274672431'\n",
      "1236 - random_90 - deep - 266.79853048075034 - 6.091877244447304 - 267.4759948855798 - 270.74492518368197 - 1.1968245711904286 - 162.45628995789164 - -25.7174582676404'\n",
      "1237 - random_71 - deep - 269.57165494461805 - 0.8416537160503981 - 1.4173382011527154 - 273.3335670925509 - 270.00316718569525 - 163.0277636233853 - -25.811442463714553'\n",
      "1238 - random_45 - deep - 276.54425268041103 - 0.8302551010989605 - 277.4388794947943 - 280.5970297310142 - 276.99421857955275 - 222.46372347570917 - -35.586242672208876'\n",
      "1239 - random_89 - deep - 260.8698555411529 - 261.09620446508023 - 261.80141679266393 - 264.7035737399938 - 261.34261859368985 - 261.9625317673559 - -42.0821915974683'\n",
      "1240 - random_6 - deep - 268.1199177976386 - 268.32631556910695 - 269.0526436995677 - 272.08102147535135 - 268.60469240035854 - 269.23670958100814 - -43.278498260743845'\n",
      "1241 - random_55 - deep - 269.7293678154512 - 269.9019175999711 - 270.60159533616206 - 273.71554740890093 - 270.15693034773244 - 270.82086372183943 - -43.53902724462092'\n",
      "1242 - random_33 - deep - 270.1993585765637 - 270.37032237084725 - 271.1008661101731 - 274.1765252021304 - 270.65334349833967 - 271.2998746189997 - -43.61780507253969'\n",
      "1243 - random_47 - lr - 6.163772353689557 - 2284.842530642201 - 1012.8024115507621 - 5.726873794488253 - 594.779152260394 - 780.9378075338519 - -127.43253635677095'\n"
     ]
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(all_scores)\n",
    "scores_df.to_csv(log_dir/f\"scores.csv\",index=False)\n",
    "scores_df_final = pd.DataFrame(all_scores_final)\n",
    "scores_df_final.to_csv(log_dir/f\"test_scores.csv\",index=False)\n",
    "\n",
    "scores_df_sorted = pd.DataFrame(scores_df).sort_values(by='MSE')\n",
    "\n",
    "best_5 = []\n",
    "summary_logger.info(f\"Rank - \" +\" - \".join(list(scores_df_sorted.columns)))\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    if i < 5:\n",
    "        best_5.append((row[\"model_num\"],row[\"predictor\"],row[\"MSE\"],row[\"R2\"]))\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    summary_logger.info(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save scores\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      " Best 5 on Test Sest \n",
      " ---------------------'\n",
      "Rank -  Deep Model - Predictor - Val Set - Test Set'\n",
      "0 - random_11 - lwr_k=100 - 0.6045804574149457 - 0.9005710815529029 - 0.5069184558749 - 0.9138593334639022'\n",
      "1 - random_11 - lwr_k=200 - 0.6095786916208898 - 0.8997490751265502 - 0.5109400588281845 - 0.9131759423683038'\n",
      "2 - random_9 - lwr_k=100 - 0.6145718497698474 - 0.898927903505309 - 0.549707226006311 - 0.9065882366303532'\n",
      "3 - random_11 - lwr_k=50 - 0.6164516765545218 - 0.8986187483849678 - 0.5155683159755551 - 0.9123894625095523'\n",
      "4 - random_9 - lwr_k=200 - 0.6230353395911254 - 0.8975360033390088 - 0.5918220664313395 - 0.8994316606895304'\n"
     ]
    }
   ],
   "source": [
    "summary_logger.info(\"-----------------------\\n Best 5 on Test Sest \\n ---------------------\")\n",
    "summary_logger.info(f\"Rank -  Deep Model - Predictor - Val Set - Test Set\")\n",
    "for i, (j,k,v1,v2) in enumerate(best_5):\n",
    "\n",
    "    row = scores_df_final.loc[(scores_df_final['model_num']==j) & (scores_df_final['predictor'] == k)].iloc[0]\n",
    "    #print(row)\n",
    "    s = f\"{i} - {j} - {k} - {v1} - {v2} - {row['MSE']} - {row['R2']}\"\n",
    "    summary_logger.info(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote Summary Graph'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#take 1 is a scatter plot - lets, for each dataset\n",
    "#graph our deep models by rank - plot - then overlay our knn moels\n",
    "#plot points\n",
    "\n",
    "deep_set = scores_df[scores_df[\"predictor\"]==\"deep\"].sort_values(\"MSE\")\n",
    "deep_set[\"order\"] = [i for i in range(0,100)]\n",
    "deep_ordering = {row[\"model_num\"]:row[\"order\"] for index, row in deep_set.iterrows()}\n",
    "\n",
    "def order_models(x):\n",
    "    x = [deep_ordering[i] for i in x]\n",
    "    return x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df[scores_df[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    if knn_model == \"deep\":\n",
    "        s=10\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"MSE\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,10)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"MSE Loss\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot_mse.png\", bbox_inches='tight')\n",
    "logging.getLogger().info(\"Wrote Summary Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote Summary Graph'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#take 1 is a scatter plot - lets, for each dataset\n",
    "#graph our deep models by rank - plot - then overlay our knn moels\n",
    "#plot points\n",
    "\n",
    "deep_set = scores_df[scores_df[\"predictor\"]==\"deep\"].sort_values(\"R2\")\n",
    "deep_set[\"order\"] = [i for i in range(0,100)]\n",
    "deep_ordering = {row[\"model_num\"]:row[\"order\"] for index, row in deep_set.iterrows()}\n",
    "\n",
    "def order_models(x):\n",
    "    x = [deep_ordering[i] for i in x]\n",
    "    return x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df[scores_df[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    if knn_model == \"deep\":\n",
    "        s=10\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot_r2.png\", bbox_inches='tight')\n",
    "logging.getLogger().info(\"Wrote Summary Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (lazydeep)",
   "language": "python",
   "name": "pycharm-12fcba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
