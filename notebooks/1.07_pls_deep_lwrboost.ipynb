{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# set seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import utils as ut\n",
    "import experiment as exp\n",
    "from evaluation import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import random\n",
    "#define fixed_hyperparams and create a config gen\n",
    "from configurations import RandomConfigGen, Configuration\n",
    "from torch import nn\n",
    "from deep_net import RandomNet\n",
    "from experiment import run_experiment\n",
    "import regex as re\n",
    "from pathlib import *\n",
    "from plot import *\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sk_models import setup_pls_models_exh, StandardScaler, PLSRegression, CustomWrapper, LWRBoost\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "random_state = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up some stuff to manage metadata for each dataset\n",
    "id_col_db = {'A_C_OF_ALPHA':[\"sample_id\"],\n",
    "             'A_C_OF_SIWARE':[],\n",
    "             'A_AL_RT':[],\n",
    "             'PLN7':[\"db_id\", \"sample_id\"],\n",
    "             'mango_684_990': ['Set','Season','Region','Date','Type','Cultivar','Pop','Temp',\"FruitID\"]\n",
    "            }\n",
    "\n",
    "output_col_db= {'A_C_OF_ALPHA':None,\n",
    "             'A_C_OF_SIWARE':None,\n",
    "             'A_AL_RT':None,\n",
    "             'PLN7':None,\n",
    "             'mango_684_990': ['DM']\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\workspace\\lazydeep\\experiments\\1.07\\PLN7\n"
     ]
    }
   ],
   "source": [
    "#setup input and output formats, load data\n",
    "\n",
    "file_name = \"PLN7.csv\"\n",
    "dataset_name = re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "\n",
    "\n",
    "\n",
    "data_path = Path('D:/workspace/lazydeep/data/soil_data/')\n",
    "model_path = Path('D:/workspace/lazydeep/experiments/1.01/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/1.07\")\n",
    "n_components = 34\n",
    "\n",
    "data_file = data_path / file_name\n",
    "log_dir = log_path / dataset_name\n",
    "model_dir = model_path / dataset_name\n",
    "\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "print(log_dir)\n",
    "\n",
    "id_cols =id_col_db[dataset_name]\n",
    "output_cols = output_col_db[dataset_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% load data\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "if not file_name == 'mango_684_990.csv': \n",
    "    data = data.sample(frac=1)\n",
    "nrow, ncol = data.shape\n",
    "data = ut.sample_data(data,random_state)\n",
    "n_features = ncol - 1-len(id_cols)\n",
    "dataset = TabularDataset(data,id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "#dataset = TabularDataset(data,id_cols = id_cols, cat_cols=None, output_cols=None, ignore_cols= None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% load models\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 models\n"
     ]
    }
   ],
   "source": [
    "n_models = 100\n",
    "\n",
    "model_names = [f\"random_{i}\" for i in range(0,n_models)]\n",
    "deep_models = {name:torch.load(model_dir/\"models\"/name/\"_model\") for name in model_names}\n",
    "#for each model, load state\n",
    "print(f\"Loaded {len(deep_models)} models\")\n",
    "\n",
    "#print(deep_models)\n",
    "for name in model_names:\n",
    "    sub_path = log_dir / name\n",
    "    if not sub_path.exists():\n",
    "        sub_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup logging and tensorboard outputs\n"
    }
   },
   "outputs": [],
   "source": [
    "# set logging, in this case the root logger\n",
    "ut.setup_logger(logger_name=\"\",file_name=log_dir/\"log.txt\")\n",
    "ut.setup_logger(logger_name=\"summary\",file_name=log_dir/\"summary.txt\")\n",
    "summary_logger = logging.getLogger(\"summary\")\n",
    "tb = SummaryWriter(log_dir/\"tb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup experiment\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is (10000, 129)\n"
     ]
    }
   ],
   "source": [
    "fixed_hyperparams = {'bs': 32,'loss': nn.MSELoss(),'epochs': 100}\n",
    "preprocessing = PLSRegression(n_components=n_components)\n",
    "\n",
    "if dataset_name == 'mango_684_990':\n",
    "    eval_ = MangoesSplitter(preprocessing=preprocessing,tensorboard=None,time=True,random_state=random_state)\n",
    "else:\n",
    "    eval_ = CrossValEvaluation(preprocessing=preprocessing,tensorboard=None,time=True,random_state=random_state)\n",
    "    \n",
    "print(f\"Dataset shape is {data.shape}\")\n",
    "scores={} #->model->knn:{fold_0:number,...,fold_n:number,mean:number,median:number\n",
    "preds={} #model-> foldsxknn_models\n",
    "deep_scores_dict={}\n",
    "deep_preds_dict={}\n",
    "actual_y = None\n",
    "\n",
    "device = \"cpu\" #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_fun_cv = lambda name,model, fold : model.load_state(model_dir/'models'/name/f\"_fold_{fold}\")\n",
    "load_fun_pp_cv = None #lambda fold : preprocessing.from_state(preprocessing.load_state(model_dir/'preprocessing'/f\"_fold_{fold}\"))\n",
    "load_fun_build = lambda name,model : model.load_state(model_dir/'models'/name/f\"_final\")\n",
    "load_fun_pp_build = None #lambda : preprocessing.from_state(preprocessing.load_state(model_dir/'preprocessing'/f\"_final\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% deep experiment\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Tested (test) on 1667 instances with mean losses of: random_0:147.1446,random_1:161.1235,random_2:148.0153,random_3:2762.2158,random_4:149.5205,random_5:134.669,random_6:466.0829,random_7:151.6422,random_8:151.2387,random_9:310.3846,random_10:146.2283,random_11:152.8767,random_12:166.4905,random_13:684.0451,random_14:137.7049,random_15:156.9714,random_16:169.3578,random_17:144.9467,random_18:159.2038,random_19:166.2787,random_20:152.0457,random_21:182.3562,random_22:175.5737,random_23:181.1456,random_24:144.4135,random_25:155.3511,random_26:466.1744,random_27:224.4122,random_28:142.8462,random_29:154.4464,random_30:173.3534,random_31:1270.8496,random_32:152.9794,random_33:160.7083,random_34:154.5682,random_35:465.9934,random_36:142.6404,random_37:166.6472,random_38:162.0285,random_39:164.3657,random_40:153.9292,random_41:155.9942,random_42:251.2476,random_43:339.4361,random_44:148.3971,random_45:161.8606,random_46:152.1294,random_47:154.4685,random_48:1020.6516,random_49:395.3792,random_50:160.3652,random_51:325.7392,random_52:1543.3301,random_53:152.0561,random_54:143.337,random_55:146.6807,random_56:145.7448,random_57:149.1403,random_58:152.5084,random_59:160.1906,random_60:162.2731,random_61:143.138,random_62:163.0945,random_63:191.5376,random_64:162.2601,random_65:148.3225,random_66:156.1508,random_67:205.2405,random_68:466.593,random_69:184.2796,random_70:187.4995,random_71:147.4211,random_72:205.1887,random_73:143.3698,random_74:153.4553,random_75:152.5712,random_76:152.16,random_77:148.7748,random_78:158.8913,random_79:145.9491,random_80:159.3029,random_81:176.8159,random_82:137.5075,random_83:145.0249,random_84:160.862,random_85:189.6642,random_86:157.523,random_87:152.8857,random_88:162.0142,random_89:466.1002,random_90:139.4601,random_91:153.6203,random_92:2781.881,random_93:155.2179,random_94:147.7485,random_95:466.0357,random_96:156.7473,random_97:665.7362,random_98:186.2882,random_99:158.5273'\n",
      "Testing (test) took 0:00:02.119002'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Tested (test) on 1667 instances with mean losses of: random_0:148.0008,random_1:144.2612,random_2:145.0499,random_3:152.0345,random_4:139.5041,random_5:142.3263,random_6:141.6708,random_7:155.104,random_8:152.0488,random_9:143.1419,random_10:131.2531,random_11:498.9816,random_12:149.8912,random_13:513.7776,random_14:143.5664,random_15:148.1501,random_16:185.4176,random_17:183.6008,random_18:150.7018,random_19:156.4546,random_20:155.5693,random_21:153.0119,random_22:154.8608,random_23:514.9816,random_24:132.8159,random_25:148.612,random_26:514.5891,random_27:271.9099,random_28:513.7774,random_29:146.686,random_30:185.5018,random_31:159.0032,random_32:139.3803,random_33:158.3283,random_34:154.392,random_35:142.5927,random_36:465.0108,random_37:139.1235,random_38:177.5098,random_39:142.6209,random_40:145.4948,random_41:192.3752,random_42:153.0581,random_43:2904.6899,random_44:163.6855,random_45:164.5139,random_46:159.3647,random_47:150.39,random_48:1222.5734,random_49:602.405,random_50:157.4969,random_51:385.0494,random_52:164.7968,random_53:326.8645,random_54:153.0258,random_55:152.2478,random_56:149.7551,random_57:156.1512,random_58:146.709,random_59:188.0667,random_60:149.2189,random_61:231.3234,random_62:156.1511,random_63:200.617,random_64:158.2461,random_65:137.4342,random_66:149.8862,random_67:213.7093,random_68:516.1761,random_69:137.7548,random_70:160.1036,random_71:145.4025,random_72:243.9084,random_73:138.5785,random_74:145.833,random_75:149.313,random_76:144.8256,random_77:136.9131,random_78:146.8002,random_79:143.5927,random_80:146.6703,random_81:140.4785,random_82:130.4421,random_83:147.3903,random_84:145.3098,random_85:2002.3053,random_86:157.0982,random_87:163.5835,random_88:155.0942,random_89:513.9314,random_90:514.673,random_91:150.3186,random_92:160.8836,random_93:299.1196,random_94:133.9411,random_95:127.0093,random_96:152.7334,random_97:2592.0743,random_98:159.6562,random_99:145.0231'\n",
      "Testing (test) took 0:00:02.137999'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Tested (test) on 1667 instances with mean losses of: random_0:159.2522,random_1:165.968,random_2:1801.2777,random_3:477.6612,random_4:143.9305,random_5:147.2763,random_6:387.9102,random_7:165.9713,random_8:153.7772,random_9:154.4154,random_10:142.5462,random_11:156.2559,random_12:158.2287,random_13:663.1099,random_14:148.2283,random_15:172.834,random_16:166.8948,random_17:151.1486,random_18:154.3236,random_19:188.3211,random_20:162.4378,random_21:164.307,random_22:167.8061,random_23:170.0383,random_24:145.4006,random_25:160.5468,random_26:477.6822,random_27:276.7694,random_28:150.7173,random_29:152.7773,random_30:186.086,random_31:162.183,random_32:163.8631,random_33:161.4014,random_34:156.477,random_35:176.4314,random_36:149.5971,random_37:159.6392,random_38:2554.7328,random_39:152.7702,random_40:154.5902,random_41:477.6775,random_42:152.6498,random_43:2874.17,random_44:172.8528,random_45:174.2463,random_46:162.3512,random_47:161.257,random_48:183.7435,random_49:2530.0331,random_50:2884.4274,random_51:170.6085,random_52:3121.022,random_53:421.224,random_54:146.232,random_55:157.9174,random_56:151.7304,random_57:154.7122,random_58:2853.6657,random_59:147.9642,random_60:156.3865,random_61:146.7111,random_62:162.8552,random_63:153.1518,random_64:164.6062,random_65:164.6585,random_66:169.2091,random_67:161.0262,random_68:477.6964,random_69:157.2185,random_70:152.4009,random_71:150.0015,random_72:635.4183,random_73:150.1126,random_74:151.3223,random_75:156.1372,random_76:174.7629,random_77:150.0817,random_78:152.97,random_79:157.209,random_80:161.2426,random_81:148.8484,random_82:144.0645,random_83:156.1235,random_84:160.1145,random_85:172.6342,random_86:157.4279,random_87:170.4553,random_88:169.8041,random_89:477.6978,random_90:169.365,random_91:162.8963,random_92:161.8216,random_93:160.0911,random_94:150.2785,random_95:145.07,random_96:161.6327,random_97:2368.4496,random_98:157.957,random_99:154.3858'\n",
      "Testing (test) took 0:00:02.054000'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Tested (test) on 1666 instances with mean losses of: random_0:133.357,random_1:192.2467,random_2:1415.5633,random_3:134.9737,random_4:124.7036,random_5:123.8185,random_6:157.0571,random_7:176.8107,random_8:135.3755,random_9:245.6379,random_10:119.5908,random_11:472.5846,random_12:134.675,random_13:713.0095,random_14:157.7538,random_15:136.3398,random_16:145.303,random_17:133.2364,random_18:133.1141,random_19:161.8239,random_20:133.3432,random_21:138.4661,random_22:169.4892,random_23:472.5129,random_24:121.6522,random_25:131.5783,random_26:1624.6619,random_27:216.848,random_28:136.6674,random_29:133.7198,random_30:164.806,random_31:1935.45,random_32:136.4928,random_33:135.5115,random_34:133.8875,random_35:146.5755,random_36:144.2897,random_37:131.683,random_38:2431.4706,random_39:132.3304,random_40:136.8123,random_41:181.3128,random_42:174.2485,random_43:2686.9451,random_44:138.8564,random_45:142.5028,random_46:144.239,random_47:138.7671,random_48:1977.4979,random_49:495.7517,random_50:152.9357,random_51:145.659,random_52:2846.5281,random_53:200.3157,random_54:126.7564,random_55:259.1991,random_56:132.3274,random_57:128.3768,random_58:471.6211,random_59:125.6756,random_60:137.3581,random_61:119.7391,random_62:127.3378,random_63:210.6187,random_64:132.9177,random_65:176.9314,random_66:141.4423,random_67:134.8516,random_68:472.3926,random_69:136.2145,random_70:472.4526,random_71:132.4932,random_72:232.6625,random_73:130.9746,random_74:135.8892,random_75:139.1481,random_76:407.2409,random_77:139.1033,random_78:132.9269,random_79:260.4291,random_80:137.2758,random_81:127.8606,random_82:127.6599,random_83:130.1486,random_84:145.5172,random_85:142.5383,random_86:138.7751,random_87:139.3711,random_88:142.9177,random_89:472.3927,random_90:125.1426,random_91:127.1109,random_92:474.5244,random_93:132.6615,random_94:128.0873,random_95:143.1267,random_96:140.311,random_97:471.79,random_98:164.9911,random_99:135.9104'\n",
      "Testing (test) took 0:00:02.156000'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Tested (test) on 1666 instances with mean losses of: random_0:148.6053,random_1:168.7185,random_2:208.2626,random_3:163.9045,random_4:135.6274,random_5:212.8488,random_6:215.8807,random_7:153.8888,random_8:151.5435,random_9:147.4957,random_10:137.4024,random_11:150.7574,random_12:157.272,random_13:490.8967,random_14:142.8191,random_15:157.8033,random_16:160.2569,random_17:188.5516,random_18:149.9715,random_19:162.3633,random_20:159.013,random_21:215.3753,random_22:162.1375,random_23:173.2692,random_24:130.3835,random_25:151.0191,random_26:468.0707,random_27:348.3353,random_28:133.5176,random_29:142.78,random_30:170.1586,random_31:1409.3124,random_32:148.1136,random_33:154.7793,random_34:155.3584,random_35:158.8298,random_36:151.4864,random_37:157.3666,random_38:2674.5696,random_39:147.9702,random_40:157.8587,random_41:2854.7169,random_42:214.2356,random_43:2789.4853,random_44:170.6055,random_45:166.7587,random_46:157.81,random_47:154.4264,random_48:2254.8898,random_49:1791.4051,random_50:159.3631,random_51:157.0975,random_52:2159.3965,random_53:2693.7183,random_54:144.3304,random_55:194.3157,random_56:218.6769,random_57:162.0064,random_58:152.6066,random_59:240.8172,random_60:155.0633,random_61:141.8397,random_62:265.379,random_63:143.0361,random_64:161.859,random_65:165.5859,random_66:151.4811,random_67:151.5285,random_68:467.8714,random_69:160.299,random_70:467.8797,random_71:149.4263,random_72:149.3267,random_73:134.5115,random_74:151.2776,random_75:145.9744,random_76:154.5654,random_77:157.0348,random_78:145.2294,random_79:138.5148,random_80:155.5301,random_81:146.1472,random_82:131.8439,random_83:147.7245,random_84:155.1951,random_85:162.4605,random_86:157.9949,random_87:148.0234,random_88:157.7004,random_89:467.8628,random_90:135.3262,random_91:156.4463,random_92:153.8961,random_93:140.3847,random_94:142.8339,random_95:182.9616,random_96:153.3846,random_97:1080.9239,random_98:163.7234,random_99:144.5762'\n",
      "Testing (test) took 0:00:02.070002'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Tested (test) on 1667 instances with mean losses of: random_0:148.8265,random_1:149.872,random_2:376.3356,random_3:146.5714,random_4:146.598,random_5:133.5081,random_6:698.0153,random_7:168.8136,random_8:159.7339,random_9:144.5003,random_10:142.4375,random_11:156.7136,random_12:150.6126,random_13:485.2733,random_14:138.6782,random_15:160.192,random_16:153.3117,random_17:135.5052,random_18:143.0904,random_19:143.4403,random_20:158.8435,random_21:155.4229,random_22:170.3754,random_23:152.8703,random_24:130.7422,random_25:155.2039,random_26:481.204,random_27:192.29,random_28:142.5244,random_29:144.5691,random_30:189.5855,random_31:160.682,random_32:142.8227,random_33:151.4686,random_34:158.0551,random_35:173.876,random_36:137.4498,random_37:154.1287,random_38:2078.1625,random_39:139.0234,random_40:158.3656,random_41:2901.9386,random_42:145.6764,random_43:2885.6209,random_44:177.5122,random_45:161.4243,random_46:150.4457,random_47:153.572,random_48:407989.7919,random_49:2612.8249,random_50:154.9875,random_51:228.4547,random_52:2798.9508,random_53:2715.1806,random_54:158.0454,random_55:156.7729,random_56:225.8742,random_57:157.9843,random_58:153.4846,random_59:172.9738,random_60:166.1266,random_61:136.6601,random_62:187.1484,random_63:203.4299,random_64:160.6635,random_65:139.607,random_66:157.085,random_67:137.5318,random_68:481.2553,random_69:146.0202,random_70:481.2521,random_71:146.3163,random_72:375.6847,random_73:138.23,random_74:151.9656,random_75:147.5415,random_76:144.0803,random_77:142.0133,random_78:138.2711,random_79:147.4801,random_80:151.5035,random_81:143.7027,random_82:133.6739,random_83:147.4844,random_84:154.461,random_85:155.8948,random_86:150.1848,random_87:138.2064,random_88:166.3994,random_89:481.2561,random_90:138.8256,random_91:154.4019,random_92:156.2352,random_93:158.8351,random_94:144.6764,random_95:147.8741,random_96:166.669,random_97:138.3341,random_98:178.8772,random_99:153.2657'\n",
      "Testing (test) took 0:00:02.136000'\n"
     ]
    }
   ],
   "source": [
    "deep_scheme = DeepScheme(None, fixed_hyperparams=fixed_hyperparams,loss_eval=loss_target,device=device,tensorboard=tb,adaptive_lr=True,update=False)\n",
    "deep_scores, deep_preds, _ , _, _,_ = eval_.evaluate(deep_models,dataset,deep_scheme,logger_name=\"log\",load_fun=load_fun_cv,load_fun_pp = load_fun_pp_cv)\n",
    "deep_scores_final, deep_preds_final, _ ,_, _,_ = eval_.build(deep_models,dataset,deep_scheme,logger_name=\"test_log\",load_fun=load_fun_build,load_fun_pp = load_fun_pp_build)\n",
    "\n",
    "all_scores = []\n",
    "for k,v in ut.flip_dicts(deep_scores).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores.append({**dict1,**v})\n",
    "    \n",
    "all_scores_final = []\n",
    "for k,v in ut.flip_dicts(deep_scores_final).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores_final.append({**dict1,**v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - random_82 - deep - 137.5075182648712 - 130.4421176006498 - 144.06449480977827 - 127.65992345271849 - 131.84387805109836 - 134.30467871071176 - 0.7199893993454223\n",
      "1 - random_24 - deep - 144.41353603516356 - 132.81591498472767 - 145.4006378800839 - 121.6521948073663 - 130.38346345313028 - 134.9352893915091 - 0.7186746448841157\n",
      "2 - random_10 - deep - 146.22829733827405 - 131.2531475577443 - 142.54620770487017 - 119.59081962557973 - 137.4023663176208 - 135.40582546692042 - 0.7176936285087342\n",
      "3 - random_4 - deep - 149.52052070283574 - 139.50407097535572 - 143.93053564656333 - 124.70355024944548 - 135.62736985663406 - 138.6592477281742 - 0.7109105980863994\n",
      "4 - random_73 - deep - 143.369752692833 - 138.57852169190184 - 150.11264153991405 - 130.9745516782763 - 134.5115186226468 - 139.51102111677213 - 0.7091347435111719\n",
      "5 - random_94 - deep - 147.74845175007968 - 133.9410871426789 - 150.27850711595963 - 128.0872647581982 - 142.83391092032517 - 140.57907244776365 - 0.7069079730249028\n",
      "6 - random_54 - deep - 143.3369931162083 - 153.02575410821157 - 146.23201375502487 - 126.75642759545224 - 144.33043288726623 - 142.73805122060224 - 0.7024067378573241\n",
      "7 - random_71 - deep - 147.42106379444326 - 145.40249613651488 - 150.00145401522724 - 132.49321839331435 - 149.42633086865118 - 144.94986936347323 - 0.6977953383687179\n",
      "8 - random_83 - deep - 145.02487304357976 - 147.3902957506643 - 156.12350985041334 - 130.14863648706552 - 147.72448534467497 - 145.28388368452516 - 0.6970989549548054\n",
      "9 - random_14 - deep - 137.70490223702086 - 143.56642867593473 - 148.22834771195787 - 157.75380246092578 - 142.81907055730008 - 146.01348448413944 - 0.6955778168969267\n",
      "10 - random_29 - deep - 154.446354651494 - 146.6859692697691 - 152.77725805089227 - 133.71976552461805 - 142.77998224741557 - 146.08374610812191 - 0.6954313290774168\n",
      "11 - random_77 - deep - 148.77480655754835 - 136.91305230775134 - 150.08172788660042 - 139.1033063982429 - 157.03478088928443 - 146.38112929019692 - 0.6948113175913184\n",
      "12 - random_0 - deep - 147.1445725308826 - 148.0008328900626 - 159.25217494953156 - 133.35702390544841 - 148.6052618496129 - 147.27348410121905 - 0.6929508551783186\n",
      "13 - random_78 - deep - 158.89134197086364 - 146.8002499292622 - 152.97004405652683 - 132.92693485475246 - 145.22940014018303 - 147.3655830805905 - 0.6927588388555735\n",
      "14 - random_74 - deep - 153.45526117669226 - 145.8329661643355 - 151.3222925590053 - 135.88923227372004 - 151.27763947375826 - 147.55643185984212 - 0.6923609399750175\n",
      "15 - random_99 - deep - 158.52725067779411 - 145.02305100503338 - 154.38577592136906 - 135.91042533956943 - 144.576222038498 - 147.68633145297855 - 0.6920901134971309\n",
      "16 - random_39 - deep - 164.36570207473397 - 142.62089369235528 - 152.7702025360309 - 132.3304426506931 - 147.9701933385659 - 148.01337385772723 - 0.6914082657679803\n",
      "17 - random_81 - deep - 176.8159001927642 - 140.4785398633164 - 148.84839134010357 - 127.860574765795 - 146.1472452262155 - 148.03277671218763 - 0.6913678129335442\n",
      "18 - random_32 - deep - 152.97942731705123 - 139.38026185656423 - 163.863112735119 - 136.49283807761387 - 148.11364142061853 - 148.16726493576093 - 0.6910874196618784\n",
      "19 - random_75 - deep - 152.5712334255866 - 149.3129566561053 - 156.1371806041166 - 139.14811772487315 - 145.9744149170288 - 148.63023752479896 - 0.6901221723303064\n",
      "20 - random_8 - deep - 151.23871260141283 - 152.04883586881257 - 153.77720893809519 - 135.3754873653563 - 151.5434860559214 - 148.7980271650407 - 0.6897723492385219\n",
      "21 - random_25 - deep - 155.35112474689817 - 148.6119859463166 - 160.54683642167134 - 131.57825921506299 - 151.01910835440134 - 149.4234122263752 - 0.6884684896236095\n",
      "22 - random_18 - deep - 159.2038448130076 - 150.7018404241515 - 154.32362722706924 - 133.1140560411176 - 149.97153083645568 - 149.46488185862907 - 0.6883820299652581\n",
      "23 - random_40 - deep - 153.92921740664073 - 145.49475220312382 - 154.59019869304947 - 136.81229081903757 - 157.85874189763797 - 149.73761682867652 - 0.6878134073117839\n",
      "24 - random_57 - deep - 149.14027304097286 - 156.1511642007536 - 154.7122040538639 - 128.37676139181258 - 162.0063626585888 - 150.07852621532834 - 0.6871026484384406\n",
      "25 - random_91 - deep - 153.620345600222 - 150.31857823381614 - 162.8963279952957 - 127.11086940879868 - 156.4462514879609 - 150.08046612553136 - 0.6870986039373377\n",
      "26 - random_37 - deep - 166.647212444413 - 139.12350676227058 - 159.6392497581569 - 131.68301010589784 - 157.36661104566338 - 150.8934462727633 - 0.6854036290374907\n",
      "27 - random_34 - deep - 154.56817166077283 - 154.3920279847839 - 156.47700864566465 - 133.88745565975412 - 155.35841047234322 - 150.93813077537928 - 0.6853104667252201\n",
      "28 - random_47 - deep - 154.46845284721132 - 150.39001206716665 - 161.25703940937888 - 138.767085484096 - 154.42642385933866 - 151.86306536051902 - 0.6833820790380791\n",
      "29 - random_80 - deep - 159.3029143866051 - 146.6703013218157 - 161.24257640918717 - 137.27580574466114 - 155.53014179609832 - 152.0056930065216 - 0.6830847159587694\n",
      "30 - random_60 - deep - 162.27312153917484 - 149.2188880888373 - 156.38646359091828 - 137.35813310309476 - 155.0632761466403 - 152.06138062313747 - 0.6829686133543975\n",
      "31 - random_5 - deep - 134.66904243510427 - 142.32630676013235 - 147.27630952081068 - 123.81846252294864 - 212.8487847226293 - 152.18390586583163 - 0.6827131615925416\n",
      "32 - random_20 - deep - 152.0456795123214 - 155.5693030491802 - 162.43784279643094 - 133.34324928091354 - 159.01298762913368 - 152.4833254194813 - 0.6820889044939058\n",
      "33 - random_96 - deep - 156.74727865172204 - 152.73341804417436 - 161.63271283502698 - 140.3110226085063 - 153.38456757214604 - 152.9632668004845 - 0.6810882790826112\n",
      "34 - random_12 - deep - 166.49045075780987 - 149.89121054573266 - 158.2286906720066 - 134.67502651695443 - 157.2720019282127 - 153.31323775183708 - 0.6803586278356061\n",
      "35 - random_84 - deep - 160.86198042907898 - 145.30979812338313 - 160.11448720120782 - 145.51721045779152 - 155.1951267384395 - 153.40045155720236 - 0.6801767965676254\n",
      "36 - random_66 - deep - 156.15075935313425 - 149.8862396771134 - 169.2090683418187 - 141.4422553200968 - 151.481117706482 - 153.63560923805974 - 0.6796865184619219\n",
      "37 - random_86 - deep - 157.52297369505592 - 157.09822286641304 - 157.42790203288993 - 138.77506606890802 - 157.9949466389339 - 153.76511409923057 - 0.679416514957113\n",
      "38 - random_33 - deep - 160.70834340974824 - 158.32827788080078 - 161.40144821148687 - 135.51153196263857 - 154.7793091754524 - 154.14794262294382 - 0.6786183592569415\n",
      "39 - random_15 - deep - 156.9714350754727 - 148.15011470362177 - 172.83399741636757 - 136.3397816157713 - 157.8032911879962 - 154.42148773746416 - 0.678048047540639\n",
      "40 - random_87 - deep - 152.88574119892817 - 163.5835175677267 - 170.45526103767438 - 139.37112779376886 - 148.0233774173732 - 154.8664841480599 - 0.6771202785796749\n",
      "41 - random_69 - deep - 184.2796111630335 - 137.754818061046 - 157.21845980726036 - 136.21446411206085 - 160.2989878568615 - 155.1549236684153 - 0.6765189136523875\n",
      "42 - random_46 - deep - 152.12944892100683 - 159.36474299988635 - 162.35117764292752 - 144.2390072606191 - 157.81001028035726 - 155.1798754199314 - 0.6764668919730501\n",
      "43 - random_64 - deep - 162.2600555236853 - 158.24614114652655 - 164.60620457352317 - 132.91768263396668 - 161.85900162677376 - 155.97987831429353 - 0.6747989732294428\n",
      "44 - random_61 - deep - 143.13800560963247 - 231.3233687979201 - 146.7110830511815 - 119.73905226763557 - 141.83969843888482 - 156.55642390768728 - 0.6735969385761402\n",
      "45 - random_88 - deep - 162.0142171089708 - 155.0941768250354 - 169.8041499514886 - 142.91770699673913 - 157.7003786286243 - 157.50785300003724 - 0.6716133127323751\n",
      "46 - random_65 - deep - 148.32248614058926 - 137.43423286167962 - 164.65849010373705 - 176.9313974735402 - 165.58588623742955 - 158.5834580233449 - 0.6693707936218369\n",
      "47 - random_44 - deep - 148.39711365359375 - 163.68551773043828 - 172.85278245711942 - 138.85642161832996 - 170.60551890433908 - 158.8804664285704 - 0.6687515635045765\n",
      "48 - random_56 - deep - 145.7448183184408 - 149.75511053184871 - 151.73036057003688 - 132.3274281880721 - 218.6768508856179 - 159.64310852601199 - 0.6671615379459803\n",
      "49 - random_17 - deep - 144.94666282045105 - 183.60079701588978 - 151.14859541977103 - 133.23641724145713 - 188.5515621501286 - 160.29666370621445 - 0.6657989467069694\n",
      "50 - random_7 - deep - 151.64223659632088 - 155.10397609809093 - 165.97125007066458 - 176.81070711976196 - 153.88882547953264 - 160.6822792508325 - 0.664994980372313\n",
      "51 - random_45 - deep - 161.86059964139375 - 164.5138501291441 - 174.24633187338057 - 142.50278724771158 - 166.75869967127477 - 161.97821719709586 - 0.6622930911587146\n",
      "52 - random_16 - deep - 169.35776610852145 - 185.41757143566403 - 166.89483514429926 - 145.3030489203738 - 160.2569451257676 - 165.44907279212296 - 0.6550567359603807\n",
      "53 - random_22 - deep - 175.57371266072713 - 154.86078630526336 - 167.8061403939305 - 169.48919913119056 - 162.1374607246463 - 165.97349783560256 - 0.6539633669665921\n",
      "54 - random_1 - deep - 161.12350827258865 - 144.26118596471136 - 165.96799771973096 - 192.24671431377726 - 168.71851978095927 - 166.4602206410644 - 0.6529486030252463\n",
      "55 - random_98 - deep - 186.28815338921962 - 159.65621146400602 - 157.9569506539366 - 164.99110850394845 - 163.72338969309646 - 166.52368093492535 - 0.6528162952369228\n",
      "56 - random_19 - deep - 166.27871105924078 - 156.45464102980185 - 188.3210877165082 - 161.82390342611654 - 162.3632909035196 - 167.04951569928306 - 0.651719987128923\n",
      "57 - random_79 - deep - 145.949127256763 - 143.59269041577426 - 157.20897991269666 - 260.42908010677417 - 138.51477217473902 - 169.13165067791914 - 0.6473789628875591\n",
      "58 - random_21 - deep - 182.35615583029633 - 153.01192431801726 - 164.3069572242778 - 138.46614069211668 - 215.37528136254502 - 170.70180058761753 - 0.6441053716504334\n",
      "59 - random_59 - deep - 160.19059733738067 - 188.06666404756157 - 147.96422720155675 - 125.67558226293447 - 240.817212831788 - 172.5402877785584 - 0.6402723264611443\n",
      "60 - random_67 - deep - 205.24045169603775 - 213.70926477241173 - 161.0261890615041 - 134.85159571030562 - 151.52847057402062 - 173.27841316296212 - 0.638733415574127\n",
      "61 - random_62 - deep - 163.09446299826948 - 156.1511381866693 - 162.85520207588732 - 127.33779319222806 - 265.3790267083396 - 174.95838932791807 - 0.6352308485783194\n",
      "62 - random_30 - deep - 173.3533757192043 - 185.50183336135507 - 186.08602185812836 - 164.8059586871858 - 170.15860179521027 - 175.98319842292648 - 0.6330942334357622\n",
      "63 - random_93 - deep - 155.2179052699592 - 299.11956988485116 - 160.09105209368892 - 132.66151291754494 - 140.3846710223396 - 177.50477686591913 - 0.6299219084069139\n",
      "64 - random_63 - deep - 191.53762106617984 - 200.61696854964944 - 153.1517904083673 - 210.61870356052577 - 143.03606591562405 - 179.79294112922187 - 0.6251513355876019\n",
      "65 - random_55 - deep - 146.68073118240733 - 152.2477806562711 - 157.91743109279145 - 259.19905293660435 - 194.31572880922388 - 182.0614203569256 - 0.6204218039196103\n",
      "66 - random_42 - deep - 251.2475656430451 - 153.05805732164114 - 152.6498317661297 - 174.24853471662104 - 214.23556274011068 - 189.08667258193154 - 0.6057749195805249\n",
      "67 - random_9 - deep - 310.38463308314897 - 143.14187168059553 - 154.41544005880831 - 245.6378944644264 - 147.49568408906532 - 200.21598038757668 - 0.5825715271637883\n",
      "68 - random_76 - deep - 152.16003187301993 - 144.8255891851415 - 174.76287267418343 - 407.24086128592063 - 154.56537553070544 - 206.69313749800142 - 0.5690673613340134\n",
      "69 - random_36 - deep - 142.64040199925103 - 465.0107623983016 - 149.59706328082527 - 144.28972853789952 - 151.4863744921186 - 210.61991914337602 - 0.5608804500684044\n",
      "70 - random_95 - deep - 466.0357204590576 - 127.00927894560247 - 145.0699664243482 - 143.12668319280837 - 182.96160533305118 - 212.85260281028292 - 0.5562255482388943\n",
      "71 - random_28 - deep - 142.84624130166642 - 513.7774482640093 - 150.717256714215 - 136.66736076144326 - 133.51756206480394 - 215.52447263281496 - 0.5506549911960563\n",
      "72 - random_90 - deep - 139.46011549566919 - 514.6729708501659 - 169.36498542195247 - 125.14263848239491 - 135.32623114019168 - 216.81416396538575 - 0.5479661254904169\n",
      "73 - random_35 - deep - 465.99340326941933 - 142.59268921667328 - 176.4314055828971 - 146.57553641879116 - 158.82982911182052 - 218.10026291658392 - 0.545284749507962\n",
      "74 - random_51 - deep - 325.73920026938214 - 385.0494466963541 - 170.60847450947432 - 145.6590373209831 - 157.09753128546342 - 236.85125326279024 - 0.5061909806228231\n",
      "75 - random_27 - deep - 224.41219365074738 - 271.90993467261137 - 276.769445029146 - 216.84801762501877 - 348.33531820931495 - 267.6513971490468 - 0.4419760413323257\n",
      "76 - random_6 - deep - 466.0828696321283 - 141.67080462386528 - 387.9102466539773 - 157.05710355431236 - 215.88066088251708 - 273.7412787156305 - 0.4292793027544586\n",
      "77 - random_11 - deep - 152.87669865929158 - 498.9816036487527 - 156.25594332808853 - 472.58464118069105 - 150.75741988842657 - 286.285171241492 - 0.4031266555463996\n",
      "78 - random_70 - deep - 187.49950451499055 - 160.10357839931038 - 152.40089890881077 - 472.4525561201043 - 467.87971077102713 - 288.0235480358472 - 0.3995023296105932\n",
      "79 - random_72 - deep - 205.18874024114854 - 243.90843077112117 - 635.4182856421879 - 232.66252412830366 - 149.32667355577485 - 293.3254871819242 - 0.3884483650043056\n",
      "80 - random_23 - deep - 181.14561097866488 - 514.9816022025087 - 170.038321487619 - 472.512864423113 - 173.26917229294062 - 302.384593748075 - 0.3695611162849547\n",
      "81 - random_89 - deep - 466.10016369833943 - 513.9313962097717 - 477.69780327076677 - 472.3927264265081 - 467.86279575306685 - 479.5992494363184 - 8.789569117728657e-05\n",
      "82 - random_68 - deep - 466.5929696415453 - 516.1761393326803 - 477.69639091285745 - 472.39263967305675 - 467.87135232510974 - 480.14830461973656 - -0.0010568244569015839\n",
      "83 - random_85 - deep - 189.664187206504 - 2002.3053440581416 - 172.63422487621617 - 142.53825361931882 - 162.46052386408664 - 534.0120498519592 - -0.11335685600283818\n",
      "84 - random_13 - deep - 684.0451448894792 - 513.7775837898827 - 663.1098745216777 - 713.0094548073135 - 490.8966737818174 - 612.9703903896211 - -0.2779763806008002\n",
      "85 - random_50 - deep - 160.36521464017744 - 157.49689449317168 - 2884.4273858851275 - 152.93569041386087 - 159.3630966424656 - 703.0488874300769 - -0.46578021814758475\n",
      "86 - random_26 - deep - 466.1744460647665 - 514.5890979640986 - 477.68216640790496 - 1624.6619264893457 - 468.0707411382522 - 710.1549983181146 - -0.48059568397631747\n",
      "87 - random_3 - deep - 2762.2157660508915 - 152.03450223651558 - 477.6611929963861 - 134.97366123268154 - 163.90448042925667 - 738.2992173620416 - -0.5392733097678863\n",
      "88 - random_2 - deep - 148.015276594797 - 145.04986391027458 - 1801.2777444511098 - 1415.5632643682472 - 208.26263287602637 - 743.6173708804092 - -0.5503610795711924\n",
      "89 - random_92 - deep - 2781.880973683193 - 160.88361652010417 - 161.82161745942133 - 474.5243501697554 - 153.89610513089514 - 746.7051138217261 - -0.5567986866893138\n",
      "90 - random_58 - deep - 152.50841684804823 - 146.70903570750693 - 2853.6657045544016 - 471.6211347820378 - 152.60657100059262 - 755.5285603548361 - -0.5751946099534722\n",
      "91 - random_53 - deep - 152.05613927949884 - 326.86451718445375 - 421.2239868402052 - 200.31568483716728 - 2693.718315793114 - 758.6705613181265 - -0.5817453391271239\n",
      "92 - random_41 - deep - 155.9941819882636 - 192.3752413579784 - 477.6774804310378 - 181.3127581721165 - 2854.716855418925 - 772.2363557107115 - -0.6100285402239836\n",
      "93 - random_31 - deep - 1270.8496071781738 - 159.0032286206333 - 162.1829776523638 - 1935.4499854629353 - 1409.312398518978 - 987.1952277860047 - -1.0581943335801665\n",
      "94 - random_49 - deep - 395.3791950651465 - 602.4050220473483 - 2530.0331304832785 - 495.751736607729 - 1791.4050561142426 - 1162.9994843727166 - -1.424727025940872\n",
      "95 - random_48 - deep - 1020.651579016472 - 1222.5734120753975 - 183.74350586349405 - 1977.4979138139631 - 2254.889812785466 - 1331.6829908161287 - -1.7764137312229638\n",
      "96 - random_97 - deep - 665.7361578801183 - 2592.074283776057 - 2368.449622599894 - 471.79004052792993 - 1080.923870585832 - 1435.9530618911933 - -1.993805452139204\n",
      "97 - random_38 - deep - 162.02848151835698 - 177.5097919869151 - 2554.732763701166 - 2431.4705829597465 - 2674.5695529676714 - 1599.8335232421664 - -2.3354783324807538\n",
      "98 - random_52 - deep - 1543.3301443593118 - 164.7967505131786 - 3121.0219840797467 - 2846.5280823266808 - 2159.3965115587253 - 1966.8860678431233 - -3.1007428375758224\n",
      "99 - random_43 - deep - 339.4360802735693 - 2904.689921634814 - 2874.169992539578 - 2686.9450581013657 - 2789.4853359556714 - 2318.8446419293336 - -3.8345380611040127\n"
     ]
    }
   ],
   "source": [
    "scores_df_sorted = pd.DataFrame(all_scores).sort_values(by='MSE')\n",
    "n = 30\n",
    "best_n = []\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    print(s)\n",
    "    if i < n:\n",
    "        best_n.append(row['model_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% lwr part\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3116d768b7f448669e1152fea56840a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_0'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:124.1964,knn_ttm_n=100:116.1614,knn_tta_r_n=100:138.6778,knn_ttm_r_n=100:138.1299,knn_tta_n=500:198.6792,knn_ttm_n=500:208.1391,knn_tta_r_n=500:205.8835,knn_ttm_r_n=500:200.6888,knn_tta_n=1000:217.6973,knn_ttm_n=1000:230.605,knn_tta_r_n=1000:223.2779,knn_ttm_r_n=1000:219.0237'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1333604.3491,knn_ttm_n=100:2703754.5602,knn_tta_r_n=100:1225055.8844,knn_ttm_r_n=100:8473619.1789,knn_tta_n=500:250309.4263,knn_ttm_n=500:376125.1873,knn_tta_r_n=500:189048.9805,knn_ttm_r_n=500:182232.2327,knn_tta_n=1000:584.5302,knn_ttm_n=1000:735.9487,knn_tta_r_n=1000:414.1572,knn_ttm_r_n=1000:848.3392'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:125.0426,knn_ttm_n=100:132.4075,knn_tta_r_n=100:141.5843,knn_ttm_r_n=100:135.6195,knn_tta_n=500:206.0445,knn_ttm_n=500:236.3408,knn_tta_r_n=500:217.2328,knn_ttm_r_n=500:208.5492,knn_tta_n=1000:230.791,knn_ttm_n=1000:271.6026,knn_tta_r_n=1000:237.5398,knn_ttm_r_n=1000:231.6885'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:217547.4996,knn_ttm_n=100:1351599.2462,knn_tta_r_n=100:134091.9635,knn_ttm_r_n=100:533905.0185,knn_tta_n=500:10323.6033,knn_ttm_n=500:6728.1013,knn_tta_r_n=500:5143.1348,knn_ttm_r_n=500:576.0118,knn_tta_n=1000:19444.2368,knn_ttm_n=1000:9948.9733,knn_tta_r_n=1000:10475.1846,knn_ttm_r_n=1000:4468.4841'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:136.3487,knn_ttm_n=100:140.1276,knn_tta_r_n=100:149.814,knn_ttm_r_n=100:138.6844,knn_tta_n=500:219.5684,knn_ttm_n=500:247.1578,knn_tta_r_n=500:226.2459,knn_ttm_r_n=500:218.8741,knn_tta_n=1000:241.8446,knn_ttm_n=1000:274.0426,knn_tta_r_n=1000:248.3073,knn_ttm_r_n=1000:242.3981'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:38791.6796,knn_ttm_n=100:45471.6956,knn_tta_r_n=100:22449.5655,knn_ttm_r_n=100:20132.9981,knn_tta_n=500:283.0149,knn_ttm_n=500:328.3446,knn_tta_r_n=500:266.3124,knn_ttm_r_n=500:271.1794,knn_tta_n=1000:263.1793,knn_ttm_n=1000:311.8316,knn_tta_r_n=1000:263.053,knn_ttm_r_n=1000:265.2778'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:114.7449,knn_ttm_n=100:105.389,knn_tta_r_n=100:126.8505,knn_ttm_r_n=100:116.6071,knn_tta_n=500:166.2915,knn_ttm_n=500:167.5817,knn_tta_r_n=500:172.5846,knn_ttm_r_n=500:165.9758,knn_tta_n=1000:178.0501,knn_ttm_n=1000:180.3325,knn_tta_r_n=1000:181.9812,knn_ttm_r_n=1000:177.073'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:8070.8065,knn_ttm_n=100:21703.3991,knn_tta_r_n=100:2304.4561,knn_ttm_r_n=100:3827.391,knn_tta_n=500:215.0671,knn_ttm_n=500:301.7304,knn_tta_r_n=500:222.5152,knn_ttm_r_n=500:241.8061,knn_tta_n=1000:189.5819,knn_ttm_n=1000:202.6411,knn_tta_r_n=1000:188.1139,knn_ttm_r_n=1000:187.0534'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:110.6577,knn_ttm_n=100:103.6086,knn_tta_r_n=100:122.9214,knn_ttm_r_n=100:109.1338,knn_tta_n=500:170.9319,knn_ttm_n=500:176.2398,knn_tta_r_n=500:176.2728,knn_ttm_r_n=500:166.3976,knn_tta_n=1000:184.5735,knn_ttm_n=1000:194.6811,knn_tta_r_n=1000:187.8326,knn_ttm_r_n=1000:181.7614'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:24700.7393,knn_ttm_n=100:48496.8292,knn_tta_r_n=100:5542.2019,knn_ttm_r_n=100:36749.4806,knn_tta_n=500:210.1782,knn_ttm_n=500:247.5215,knn_tta_r_n=500:196.9057,knn_ttm_r_n=500:197.832,knn_tta_n=1000:204.9888,knn_ttm_n=1000:235.0712,knn_tta_r_n=1000:196.0974,knn_ttm_r_n=1000:196.7897'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:78.1148,knn_ttm_n=100:70.8472,knn_tta_r_n=100:85.9967,knn_ttm_r_n=100:719.6388,knn_tta_n=500:112.0885,knn_ttm_n=500:110.6902,knn_tta_r_n=500:115.9922,knn_ttm_r_n=500:145.2712,knn_tta_n=1000:118.5488,knn_ttm_n=1000:119.9577,knn_tta_r_n=1000:120.8157,knn_ttm_r_n=1000:299.4081'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1641229.8765,knn_ttm_n=100:2230286.8689,knn_tta_r_n=100:38222.4459,knn_ttm_r_n=100:52795.7298,knn_tta_n=500:153.4722,knn_ttm_n=500:173.1019,knn_tta_r_n=500:143.3875,knn_ttm_r_n=500:143.473,knn_tta_n=1000:146.1354,knn_ttm_n=1000:159.0273,knn_tta_r_n=1000:141.4078,knn_ttm_r_n=1000:140.8738'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_4'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:72.7425,knn_ttm_n=100:67.3145,knn_tta_r_n=100:87.8826,knn_ttm_r_n=100:95.1033,knn_tta_n=500:157.7717,knn_ttm_n=500:162.5598,knn_tta_r_n=500:165.9128,knn_ttm_r_n=500:156.3374,knn_tta_n=1000:176.8232,knn_ttm_n=1000:190.4279,knn_tta_r_n=1000:180.8135,knn_ttm_r_n=1000:178.2719'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:520.3509,knn_ttm_n=100:621.576,knn_tta_r_n=100:350.335,knn_ttm_r_n=100:399.0087,knn_tta_n=500:230.0105,knn_ttm_n=500:266.2484,knn_tta_r_n=500:216.9917,knn_ttm_r_n=500:221.4987,knn_tta_n=1000:218.8333,knn_ttm_n=1000:244.9171,knn_tta_r_n=1000:214.0827,knn_ttm_r_n=1000:217.8792'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:66.5868,knn_ttm_n=100:59.4713,knn_tta_r_n=100:86.1932,knn_ttm_r_n=100:67.6224,knn_tta_n=500:157.877,knn_ttm_n=500:175.3499,knn_tta_r_n=500:166.4866,knn_ttm_r_n=500:157.4428,knn_tta_n=1000:180.6097,knn_ttm_n=1000:210.5121,knn_tta_r_n=1000:185.7277,knn_ttm_r_n=1000:182.1461'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:405.7632,knn_ttm_n=100:491.7657,knn_tta_r_n=100:277.8752,knn_ttm_r_n=100:335.891,knn_tta_n=500:249.0271,knn_ttm_n=500:273.1764,knn_tta_r_n=500:252.5155,knn_ttm_r_n=500:241.2287,knn_tta_n=1000:267.5508,knn_ttm_n=1000:280.5122,knn_tta_r_n=1000:256.3544,knn_ttm_r_n=1000:250.3286'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:72.0546,knn_ttm_n=100:62.3711,knn_tta_r_n=100:88.5487,knn_ttm_r_n=100:73.8099,knn_tta_n=500:163.0164,knn_ttm_n=500:182.4762,knn_tta_r_n=500:170.6822,knn_ttm_r_n=500:163.4188,knn_tta_n=1000:183.794,knn_ttm_n=1000:211.6203,knn_tta_r_n=1000:187.6279,knn_ttm_r_n=1000:184.4127'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:514.4146,knn_ttm_n=100:520.0082,knn_tta_r_n=100:311.7329,knn_ttm_r_n=100:476.458,knn_tta_n=500:246.4694,knn_ttm_n=500:290.9623,knn_tta_r_n=500:231.5397,knn_ttm_r_n=500:235.3057,knn_tta_n=1000:232.4014,knn_ttm_n=1000:269.5695,knn_tta_r_n=1000:227.2025,knn_ttm_r_n=1000:229.3351'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:65.6141,knn_ttm_n=100:56.6451,knn_tta_r_n=100:83.6815,knn_ttm_r_n=100:82.7118,knn_tta_n=500:147.9959,knn_ttm_n=500:152.9603,knn_tta_r_n=500:156.4468,knn_ttm_r_n=500:143.9761,knn_tta_n=1000:166.569,knn_ttm_n=1000:178.9638,knn_tta_r_n=1000:171.3208,knn_ttm_r_n=1000:165.3523'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:678.398,knn_ttm_n=100:1073.1237,knn_tta_r_n=100:280.0828,knn_ttm_r_n=100:405.832,knn_tta_n=500:221.2624,knn_ttm_n=500:284.2207,knn_tta_r_n=500:200.6092,knn_ttm_r_n=500:202.6774,knn_tta_n=1000:192.7415,knn_ttm_n=1000:233.7924,knn_tta_r_n=1000:184.4218,knn_ttm_r_n=1000:188.5423'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:66.2274,knn_ttm_n=100:60.9746,knn_tta_r_n=100:84.4174,knn_ttm_r_n=100:66.2916,knn_tta_n=500:153.6664,knn_ttm_n=500:163.3875,knn_tta_r_n=500:163.0226,knn_ttm_r_n=500:151.3269,knn_tta_n=1000:173.6007,knn_ttm_n=1000:191.7207,knn_tta_r_n=1000:177.6609,knn_ttm_r_n=1000:171.5732'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:619.6771,knn_ttm_n=100:701.2383,knn_tta_r_n=100:352.9676,knn_ttm_r_n=100:351.9925,knn_tta_n=500:223.9005,knn_ttm_n=500:287.2765,knn_tta_r_n=500:200.2622,knn_ttm_r_n=500:202.5208,knn_tta_n=1000:210.7327,knn_ttm_n=1000:260.0748,knn_tta_r_n=1000:197.7702,knn_ttm_r_n=1000:197.5785'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:53.9363,knn_ttm_n=100:44.6143,knn_tta_r_n=100:66.8699,knn_ttm_r_n=100:53.8374,knn_tta_n=500:111.5302,knn_ttm_n=500:109.4364,knn_tta_r_n=500:117.872,knn_ttm_r_n=500:109.5064,knn_tta_n=1000:123.5159,knn_ttm_n=1000:124.7684,knn_tta_r_n=1000:127.2463,knn_ttm_r_n=1000:122.6769'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:301.0715,knn_ttm_n=100:644.693,knn_tta_r_n=100:217.8609,knn_ttm_r_n=100:286.7238,knn_tta_n=500:157.837,knn_ttm_n=500:192.1244,knn_tta_r_n=500:145.1948,knn_ttm_r_n=500:147.4866,knn_tta_n=1000:148.0297,knn_ttm_n=1000:172.1151,knn_tta_r_n=1000:144.778,knn_ttm_r_n=1000:145.2332'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_8'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:232.1807,knn_ttm_n=100:240.6178,knn_tta_r_n=100:234.725,knn_ttm_r_n=100:268.3134,knn_tta_n=500:253.5245,knn_ttm_n=500:268.8097,knn_tta_r_n=500:255.5569,knn_ttm_r_n=500:255.3094,knn_tta_n=1000:257.3748,knn_ttm_n=1000:274.1111,knn_tta_r_n=1000:259.6885,knn_ttm_r_n=1000:259.0429'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:324.4585,knn_ttm_n=100:615.778,knn_tta_r_n=100:334.3331,knn_ttm_r_n=100:301.5312,knn_tta_n=500:277.2918,knn_ttm_n=500:297.3798,knn_tta_r_n=500:278.6674,knn_ttm_r_n=500:280.5094,knn_tta_n=1000:279.9174,knn_ttm_n=1000:298.1805,knn_tta_r_n=1000:282.2892,knn_ttm_r_n=1000:282.2632'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:363.2746,knn_ttm_n=100:434.4959,knn_tta_r_n=100:363.0992,knn_ttm_r_n=100:367.3613,knn_tta_n=500:387.2061,knn_ttm_n=500:473.575,knn_tta_r_n=500:383.6348,knn_ttm_r_n=500:388.8314,knn_tta_n=1000:390.2977,knn_ttm_n=1000:484.192,knn_tta_r_n=1000:387.883,knn_ttm_r_n=1000:392.9297'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1190460.002,knn_ttm_n=100:1646417.8089,knn_tta_r_n=100:287846.3827,knn_ttm_r_n=100:161360.8074,knn_tta_n=500:430.2778,knn_ttm_n=500:527.3166,knn_tta_r_n=500:423.4315,knn_ttm_r_n=500:429.658,knn_tta_n=1000:431.9109,knn_ttm_n=1000:531.227,knn_tta_r_n=1000:421.9573,knn_ttm_r_n=1000:426.5315'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:365.122,knn_ttm_n=100:443.612,knn_tta_r_n=100:366.8089,knn_ttm_r_n=100:372.3117,knn_tta_n=500:394.597,knn_ttm_n=500:506.7911,knn_tta_r_n=500:391.727,knn_ttm_r_n=500:398.3077,knn_tta_n=1000:403.0485,knn_ttm_n=1000:519.6579,knn_tta_r_n=1000:401.2421,knn_ttm_r_n=1000:407.9942'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1405.1939,knn_ttm_n=100:2466.7623,knn_tta_r_n=100:607.3299,knn_ttm_r_n=100:568.251,knn_tta_n=500:427.5862,knn_ttm_n=500:544.4913,knn_tta_r_n=500:418.5054,knn_ttm_r_n=500:429.4268,knn_tta_n=1000:434.2627,knn_ttm_n=1000:554.0729,knn_tta_r_n=1000:426.4415,knn_ttm_r_n=1000:435.1697'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:188.5981,knn_ttm_n=100:190.5688,knn_tta_r_n=100:192.3335,knn_ttm_r_n=100:194.7844,knn_tta_n=500:203.0794,knn_ttm_n=500:208.9308,knn_tta_r_n=500:205.1369,knn_ttm_r_n=500:204.0673,knn_tta_n=1000:206.712,knn_ttm_n=1000:211.7872,knn_tta_r_n=1000:207.8555,knn_ttm_r_n=1000:206.9596'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:359.5784,knn_ttm_n=100:692.4229,knn_tta_r_n=100:219.3971,knn_ttm_r_n=100:217.6792,knn_tta_n=500:205.5948,knn_ttm_n=500:218.2329,knn_tta_r_n=500:204.2957,knn_ttm_r_n=500:205.2447,knn_tta_n=1000:203.6287,knn_ttm_n=1000:212.875,knn_tta_r_n=1000:203.5531,knn_ttm_r_n=1000:204.2134'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:196.3399,knn_ttm_n=100:209.1611,knn_tta_r_n=100:199.1492,knn_ttm_r_n=100:197.1775,knn_tta_n=500:212.1084,knn_ttm_n=500:226.2499,knn_tta_r_n=500:213.0313,knn_ttm_r_n=500:212.7544,knn_tta_n=1000:215.9502,knn_ttm_n=1000:228.8703,knn_tta_r_n=1000:217.3676,knn_ttm_r_n=1000:216.343'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:522.9258,knn_ttm_n=100:606.9898,knn_tta_r_n=100:288.6884,knn_ttm_r_n=100:264.4462,knn_tta_n=500:220.4638,knn_ttm_n=500:246.8136,knn_tta_r_n=500:215.202,knn_ttm_r_n=500:215.2413,knn_tta_n=1000:218.7601,knn_ttm_n=1000:240.745,knn_tta_r_n=1000:215.6181,knn_ttm_r_n=1000:215.4684'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:116.4782,knn_ttm_n=100:118.6922,knn_tta_r_n=100:117.8694,knn_ttm_r_n=100:118.8607,knn_tta_n=500:125.4846,knn_ttm_n=500:132.9997,knn_tta_r_n=500:125.785,knn_ttm_r_n=500:125.4312,knn_tta_n=1000:127.1448,knn_ttm_n=1000:134.3662,knn_tta_r_n=1000:127.0487,knn_ttm_r_n=1000:126.8588'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:32399.5944,knn_ttm_n=100:62383.7126,knn_tta_r_n=100:5741.8967,knn_ttm_r_n=100:3767.6024,knn_tta_n=500:319.0194,knn_ttm_n=500:472.4183,knn_tta_r_n=500:217.1696,knn_ttm_r_n=500:222.9577,knn_tta_n=1000:235.7699,knn_ttm_n=1000:341.9975,knn_tta_r_n=1000:183.5245,knn_ttm_r_n=1000:197.7632'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_10'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:174.1281,knn_ttm_n=100:167.5205,knn_tta_r_n=100:185.922,knn_ttm_r_n=100:175.2998,knn_tta_n=500:237.5072,knn_ttm_n=500:259.3698,knn_tta_r_n=500:241.1026,knn_ttm_r_n=500:238.4506,knn_tta_n=1000:250.4873,knn_ttm_n=1000:280.8861,knn_tta_r_n=1000:251.7809,knn_ttm_r_n=1000:251.152'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:322.5988,knn_ttm_n=100:388.6524,knn_tta_r_n=100:283.226,knn_ttm_r_n=100:291.6085,knn_tta_n=500:299.1263,knn_ttm_n=500:336.3594,knn_tta_r_n=500:280.9305,knn_ttm_r_n=500:280.6803,knn_tta_n=1000:302.0341,knn_ttm_n=1000:345.731,knn_tta_r_n=1000:289.2623,knn_ttm_r_n=1000:286.9294'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:227.197,knn_ttm_n=100:258.6447,knn_tta_r_n=100:242.9573,knn_ttm_r_n=100:219.6318,knn_tta_n=500:306.4218,knn_ttm_n=500:400.8836,knn_tta_r_n=500:305.4889,knn_ttm_r_n=500:301.1468,knn_tta_n=1000:321.916,knn_ttm_n=1000:430.9384,knn_tta_r_n=1000:317.3217,knn_ttm_r_n=1000:317.4234'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:389.0631,knn_ttm_n=100:513.0496,knn_tta_r_n=100:354.4986,knn_ttm_r_n=100:363.0339,knn_tta_n=500:362.9958,knn_ttm_n=500:467.0548,knn_tta_r_n=500:352.2787,knn_ttm_r_n=500:352.9983,knn_tta_n=1000:358.4886,knn_ttm_n=1000:473.952,knn_tta_r_n=1000:348.7377,knn_ttm_r_n=1000:353.6419'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:227.5143,knn_ttm_n=100:261.3458,knn_tta_r_n=100:238.4066,knn_ttm_r_n=100:218.4894,knn_tta_n=500:300.3034,knn_ttm_n=500:382.0713,knn_tta_r_n=500:300.2267,knn_ttm_r_n=500:296.5691,knn_tta_n=1000:315.0048,knn_ttm_n=1000:406.9336,knn_tta_r_n=1000:315.0585,knn_ttm_r_n=1000:312.9638'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:401.8447,knn_ttm_n=100:559.1626,knn_tta_r_n=100:345.3196,knn_ttm_r_n=100:364.6817,knn_tta_n=500:334.0273,knn_ttm_n=500:426.331,knn_tta_r_n=500:324.9231,knn_ttm_r_n=500:331.5161,knn_tta_n=1000:331.7963,knn_ttm_n=1000:427.0236,knn_tta_r_n=1000:328.5411,knn_ttm_r_n=1000:331.286'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:141.3554,knn_ttm_n=100:133.5606,knn_tta_r_n=100:150.19,knn_ttm_r_n=100:139.576,knn_tta_n=500:182.2382,knn_ttm_n=500:195.5575,knn_tta_r_n=500:183.6849,knn_ttm_r_n=500:182.0924,knn_tta_n=1000:187.8344,knn_ttm_n=1000:204.8268,knn_tta_r_n=1000:188.0774,knn_ttm_r_n=1000:187.9352'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:258.7589,knn_ttm_n=100:329.8636,knn_tta_r_n=100:219.6115,knn_ttm_r_n=100:216.7502,knn_tta_n=500:211.5943,knn_ttm_n=500:246.5604,knn_tta_r_n=500:199.0202,knn_ttm_r_n=500:207.753,knn_tta_n=1000:198.1818,knn_ttm_n=1000:226.6858,knn_tta_r_n=1000:194.9251,knn_ttm_r_n=1000:197.0719'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:140.2615,knn_ttm_n=100:134.38,knn_tta_r_n=100:150.056,knn_ttm_r_n=100:137.8501,knn_tta_n=500:189.3253,knn_ttm_n=500:206.9825,knn_tta_r_n=500:192.8495,knn_ttm_r_n=500:189.267,knn_tta_n=1000:197.295,knn_ttm_n=1000:221.4137,knn_tta_r_n=1000:199.3836,knn_ttm_r_n=1000:196.949'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:264.8197,knn_ttm_n=100:320.6179,knn_tta_r_n=100:212.8772,knn_ttm_r_n=100:222.0971,knn_tta_n=500:208.1824,knn_ttm_n=500:244.6478,knn_tta_r_n=500:199.1204,knn_ttm_r_n=500:199.7846,knn_tta_n=1000:199.6783,knn_ttm_n=1000:231.358,knn_tta_r_n=1000:196.9666,knn_ttm_r_n=1000:197.8732'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:81.3022,knn_ttm_n=100:72.7746,knn_tta_r_n=100:86.2173,knn_ttm_r_n=100:77.8814,knn_tta_n=500:102.5818,knn_ttm_n=500:103.0246,knn_tta_r_n=500:103.7269,knn_ttm_r_n=500:101.6658,knn_tta_n=1000:105.2838,knn_ttm_n=1000:107.7723,knn_tta_r_n=1000:106.0295,knn_ttm_r_n=1000:105.3825'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:174.7204,knn_ttm_n=100:200.1529,knn_tta_r_n=100:140.1912,knn_ttm_r_n=100:141.4772,knn_tta_n=500:145.1592,knn_ttm_n=500:154.5239,knn_tta_r_n=500:141.1151,knn_ttm_r_n=500:139.754,knn_tta_n=1000:143.2565,knn_ttm_n=1000:151.7225,knn_tta_r_n=1000:141.3625,knn_ttm_r_n=1000:140.9081'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_14'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:53.5949,knn_ttm_n=100:41.34,knn_tta_r_n=100:70.3487,knn_ttm_r_n=100:47.2375,knn_tta_n=500:129.6445,knn_ttm_n=500:118.6824,knn_tta_r_n=500:143.9069,knn_ttm_r_n=500:121.3565,knn_tta_n=1000:150.9739,knn_ttm_n=1000:146.0585,knn_tta_r_n=1000:162.5054,knn_ttm_r_n=1000:145.8759'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:255.3146,knn_ttm_n=100:329.5147,knn_tta_r_n=100:204.2617,knn_ttm_r_n=100:217.9668,knn_tta_n=500:189.8609,knn_ttm_n=500:216.1223,knn_tta_r_n=500:187.7145,knn_ttm_r_n=500:189.4621,knn_tta_n=1000:193.1247,knn_ttm_n=1000:209.6567,knn_tta_r_n=1000:195.6459,knn_ttm_r_n=1000:191.6257'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:59.8745,knn_ttm_n=100:48.8885,knn_tta_r_n=100:79.8907,knn_ttm_r_n=100:53.0557,knn_tta_n=500:145.3872,knn_ttm_n=500:148.034,knn_tta_r_n=500:157.836,knn_ttm_r_n=500:131.2831,knn_tta_n=1000:166.4007,knn_ttm_n=1000:180.1631,knn_tta_r_n=1000:176.8874,knn_ttm_r_n=1000:158.8515'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:279.2042,knn_ttm_n=100:330.5571,knn_tta_r_n=100:238.5737,knn_ttm_r_n=100:264.3412,knn_tta_n=500:221.076,knn_ttm_n=500:256.3253,knn_tta_r_n=500:206.0613,knn_ttm_r_n=500:208.6282,knn_tta_n=1000:217.8623,knn_ttm_n=1000:252.8793,knn_tta_r_n=1000:212.9737,knn_ttm_r_n=1000:210.1947'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:60.4847,knn_ttm_n=100:43.4055,knn_tta_r_n=100:77.5139,knn_ttm_r_n=100:48.1316,knn_tta_n=500:142.3983,knn_ttm_n=500:140.6077,knn_tta_r_n=500:153.9972,knn_ttm_r_n=500:127.0178,knn_tta_n=1000:166.7239,knn_ttm_n=1000:175.5776,knn_tta_r_n=1000:176.6116,knn_ttm_r_n=1000:156.9478'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:291.8109,knn_ttm_n=100:353.6177,knn_tta_r_n=100:255.7298,knn_ttm_r_n=100:280.7009,knn_tta_n=500:222.6768,knn_ttm_n=500:242.3782,knn_tta_r_n=500:212.2021,knn_ttm_r_n=500:213.1001,knn_tta_n=1000:219.2175,knn_ttm_n=1000:241.6758,knn_tta_r_n=1000:213.879,knn_ttm_r_n=1000:211.9181'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:51.9526,knn_ttm_n=100:41.9576,knn_tta_r_n=100:68.8114,knn_ttm_r_n=100:82.6572,knn_tta_n=500:115.875,knn_ttm_n=500:108.3247,knn_tta_r_n=500:128.6613,knn_ttm_r_n=500:115.7876,knn_tta_n=1000:132.0563,knn_ttm_n=1000:129.9833,knn_tta_r_n=1000:142.5232,knn_ttm_r_n=1000:138.04'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:267.3242,knn_ttm_n=100:303.5114,knn_tta_r_n=100:195.8543,knn_ttm_r_n=100:193.8336,knn_tta_n=500:165.6597,knn_ttm_n=500:196.8586,knn_tta_r_n=500:145.4755,knn_ttm_r_n=500:149.8004,knn_tta_n=1000:159.0683,knn_ttm_n=1000:182.9791,knn_tta_r_n=1000:149.4966,knn_ttm_r_n=1000:150.2395'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:51.6229,knn_ttm_n=100:40.7601,knn_tta_r_n=100:69.6143,knn_ttm_r_n=100:51.5454,knn_tta_n=500:122.2189,knn_ttm_n=500:113.5851,knn_tta_r_n=500:136.369,knn_ttm_r_n=500:116.5231,knn_tta_n=1000:139.9008,knn_ttm_n=1000:138.4448,knn_tta_r_n=1000:150.9001,knn_ttm_r_n=1000:137.3371'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:260.7188,knn_ttm_n=100:324.904,knn_tta_r_n=100:188.4471,knn_ttm_r_n=100:209.2673,knn_tta_n=500:170.8215,knn_ttm_n=500:200.5092,knn_tta_r_n=500:157.9009,knn_ttm_r_n=500:159.0434,knn_tta_n=1000:165.5058,knn_ttm_n=1000:188.3384,knn_tta_r_n=1000:160.0032,knn_ttm_r_n=1000:158.2684'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:40.7072,knn_ttm_n=100:26.4046,knn_tta_r_n=100:54.2502,knn_ttm_r_n=100:35.8446,knn_tta_n=500:91.5883,knn_ttm_n=500:75.8458,knn_tta_r_n=500:100.5698,knn_ttm_r_n=500:85.0915,knn_tta_n=1000:102.7322,knn_ttm_n=1000:92.2842,knn_tta_r_n=1000:108.7684,knn_ttm_r_n=1000:99.6035'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:243.2758,knn_ttm_n=100:310.7244,knn_tta_r_n=100:157.1075,knn_ttm_r_n=100:172.1229,knn_tta_n=500:145.84,knn_ttm_n=500:168.918,knn_tta_r_n=500:136.4024,knn_ttm_r_n=500:138.0001,knn_tta_n=1000:143.1957,knn_ttm_n=1000:153.7567,knn_tta_r_n=1000:137.3382,knn_ttm_r_n=1000:135.9298'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_18'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:97.4675,knn_ttm_n=100:75.6139,knn_tta_r_n=100:114.9171,knn_ttm_r_n=100:91.3316,knn_tta_n=500:159.3347,knn_ttm_n=500:148.9428,knn_tta_r_n=500:170.4991,knn_ttm_r_n=500:156.4121,knn_tta_n=1000:175.384,knn_ttm_n=1000:171.6472,knn_tta_r_n=1000:185.8242,knn_ttm_r_n=1000:175.6569'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:224.6736,knn_ttm_n=100:269.6321,knn_tta_r_n=100:205.2817,knn_ttm_r_n=100:209.7761,knn_tta_n=500:209.1736,knn_ttm_n=500:229.7086,knn_tta_r_n=500:208.0399,knn_ttm_r_n=500:208.7956,knn_tta_n=1000:208.7963,knn_ttm_n=1000:225.8515,knn_tta_r_n=1000:214.2584,knn_ttm_r_n=1000:214.0781'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:108.6285,knn_ttm_n=100:97.8032,knn_tta_r_n=100:128.381,knn_ttm_r_n=100:143.5141,knn_tta_n=500:181.3214,knn_ttm_n=500:192.3002,knn_tta_r_n=500:192.7787,knn_ttm_r_n=500:175.5106,knn_tta_n=1000:202.6297,knn_ttm_n=1000:226.848,knn_tta_r_n=1000:212.9762,knn_ttm_r_n=1000:200.1684'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:244.7358,knn_ttm_n=100:292.6008,knn_tta_r_n=100:237.0572,knn_ttm_r_n=100:238.5899,knn_tta_n=500:226.2678,knn_ttm_n=500:253.5604,knn_tta_r_n=500:223.8008,knn_ttm_r_n=500:229.4173,knn_tta_n=1000:230.325,knn_ttm_n=1000:263.5004,knn_tta_r_n=1000:232.3757,knn_ttm_r_n=1000:236.3477'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:111.2641,knn_ttm_n=100:99.3516,knn_tta_r_n=100:127.6551,knn_ttm_r_n=100:97.6461,knn_tta_n=500:183.7496,knn_ttm_n=500:196.0035,knn_tta_r_n=500:194.7028,knn_ttm_r_n=500:173.202,knn_tta_n=1000:210.3001,knn_ttm_n=1000:235.0609,knn_tta_r_n=1000:224.0416,knn_ttm_r_n=1000:206.2103'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:262.7097,knn_ttm_n=100:308.682,knn_tta_r_n=100:227.8788,knn_ttm_r_n=100:240.5603,knn_tta_n=500:236.1165,knn_ttm_n=500:268.762,knn_tta_r_n=500:227.4782,knn_ttm_r_n=500:225.3433,knn_tta_n=1000:243.9337,knn_ttm_n=1000:280.6426,knn_tta_r_n=1000:243.1281,knn_ttm_r_n=1000:238.7294'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:95.257,knn_ttm_n=100:72.1699,knn_tta_r_n=100:112.0106,knn_ttm_r_n=100:90.6247,knn_tta_n=500:146.0567,knn_ttm_n=500:137.8199,knn_tta_r_n=500:155.9635,knn_ttm_r_n=500:143.5011,knn_tta_n=1000:158.6194,knn_ttm_n=1000:155.5688,knn_tta_r_n=1000:165.8677,knn_ttm_r_n=1000:157.4541'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:198.8443,knn_ttm_n=100:256.0658,knn_tta_r_n=100:167.6588,knn_ttm_r_n=100:179.5527,knn_tta_n=500:160.0281,knn_ttm_n=500:180.3593,knn_tta_r_n=500:161.5864,knn_ttm_r_n=500:161.2272,knn_tta_n=1000:159.8344,knn_ttm_n=1000:169.4497,knn_tta_r_n=1000:163.6907,knn_ttm_r_n=1000:162.6461'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:95.218,knn_ttm_n=100:75.8755,knn_tta_r_n=100:112.2715,knn_ttm_r_n=100:89.3546,knn_tta_n=500:152.3722,knn_ttm_n=500:147.5726,knn_tta_r_n=500:161.4003,knn_ttm_r_n=500:149.3675,knn_tta_n=1000:167.9698,knn_ttm_n=1000:171.7472,knn_tta_r_n=1000:173.1607,knn_ttm_r_n=1000:164.3582'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:226.0122,knn_ttm_n=100:284.8576,knn_tta_r_n=100:189.8636,knn_ttm_r_n=100:195.2504,knn_tta_n=500:186.5042,knn_ttm_n=500:211.2422,knn_tta_r_n=500:175.0064,knn_ttm_r_n=500:175.1799,knn_tta_n=1000:193.1151,knn_ttm_n=1000:215.6459,knn_tta_r_n=1000:180.4031,knn_ttm_r_n=1000:176.9347'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:73.6298,knn_ttm_n=100:52.6984,knn_tta_r_n=100:86.187,knn_ttm_r_n=100:68.1622,knn_tta_n=500:113.2419,knn_ttm_n=500:102.4605,knn_tta_r_n=500:119.2069,knn_ttm_r_n=500:109.5382,knn_tta_n=1000:121.4064,knn_ttm_n=1000:116.4794,knn_tta_r_n=1000:125.1092,knn_ttm_r_n=1000:119.4388'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:186.6321,knn_ttm_n=100:228.2449,knn_tta_r_n=100:151.4831,knn_ttm_r_n=100:157.8892,knn_tta_n=500:146.8165,knn_ttm_n=500:164.4183,knn_tta_r_n=500:137.7038,knn_ttm_r_n=500:137.2264,knn_tta_n=1000:142.1071,knn_ttm_n=1000:154.8289,knn_tta_r_n=1000:136.6827,knn_ttm_r_n=1000:136.7446'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_24'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:128.6433,knn_ttm_n=100:122.2185,knn_tta_r_n=100:142.4218,knn_ttm_r_n=100:143.7717,knn_tta_n=500:210.8188,knn_ttm_n=500:229.4676,knn_tta_r_n=500:214.5114,knn_ttm_r_n=500:210.9733,knn_tta_n=1000:223.1517,knn_ttm_n=1000:243.964,knn_tta_r_n=1000:226.5384,knn_ttm_r_n=1000:246.0735'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:614.472,knn_ttm_n=100:575.3651,knn_tta_r_n=100:527.9105,knn_ttm_r_n=100:600.6154,knn_tta_n=500:296.9736,knn_ttm_n=500:338.7356,knn_tta_r_n=500:278.73,knn_ttm_r_n=500:273.6061,knn_tta_n=1000:283.9284,knn_ttm_n=1000:322.7446,knn_tta_r_n=1000:273.7349,knn_ttm_r_n=1000:273.4479'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:155.6526,knn_ttm_n=100:183.9463,knn_tta_r_n=100:176.696,knn_ttm_r_n=100:160.1666,knn_tta_n=500:249.6787,knn_ttm_n=500:313.9196,knn_tta_r_n=500:253.8001,knn_ttm_r_n=500:253.8892,knn_tta_n=1000:270.1336,knn_ttm_n=1000:340.7514,knn_tta_r_n=1000:272.6961,knn_ttm_r_n=1000:272.864'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:598.1052,knn_ttm_n=100:9167.9928,knn_tta_r_n=100:4805.9092,knn_ttm_r_n=100:74447.6118,knn_tta_n=500:340.5217,knn_ttm_n=500:421.4311,knn_tta_r_n=500:352.1285,knn_ttm_r_n=500:336.5433,knn_tta_n=1000:357.6467,knn_ttm_n=1000:432.1734,knn_tta_r_n=1000:350.0941,knn_ttm_r_n=1000:361.302'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:222.1728,knn_ttm_n=100:275.8466,knn_tta_r_n=100:201.1408,knn_ttm_r_n=100:192.1156,knn_tta_n=500:270.5204,knn_ttm_n=500:334.8285,knn_tta_r_n=500:274.7391,knn_ttm_r_n=500:271.448,knn_tta_n=1000:293.8893,knn_ttm_n=1000:369.8732,knn_tta_r_n=1000:295.7223,knn_ttm_r_n=1000:294.8679'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:170177476.5255,knn_ttm_n=100:5847035234.9675,knn_tta_r_n=100:19693928269.9379,knn_ttm_r_n=100:1547154862.0646,knn_tta_n=500:394.3762,knn_ttm_n=500:521.1306,knn_tta_r_n=500:342.4012,knn_ttm_r_n=500:351.4828,knn_tta_n=1000:343.2371,knn_ttm_n=1000:443.3613,knn_tta_r_n=1000:324.9551,knn_ttm_r_n=1000:331.2744'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:107.0913,knn_ttm_n=100:107.1197,knn_tta_r_n=100:119.3444,knn_ttm_r_n=100:113.416,knn_tta_n=500:171.111,knn_ttm_n=500:186.926,knn_tta_r_n=500:174.4231,knn_ttm_r_n=500:171.3425,knn_tta_n=1000:180.8413,knn_ttm_n=1000:196.829,knn_tta_r_n=1000:183.4512,knn_ttm_r_n=1000:181.4385'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:1134.0453,knn_ttm_n=100:821.3354,knn_tta_r_n=100:310.452,knn_ttm_r_n=100:669.1908,knn_tta_n=500:224.9983,knn_ttm_n=500:272.9892,knn_tta_r_n=500:206.218,knn_ttm_r_n=500:207.4857,knn_tta_n=1000:208.0872,knn_ttm_n=1000:241.4532,knn_tta_r_n=1000:201.3809,knn_ttm_r_n=1000:201.5495'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:107.6922,knn_ttm_n=100:109.356,knn_tta_r_n=100:121.2792,knn_ttm_r_n=100:113.8757,knn_tta_n=500:175.0236,knn_ttm_n=500:199.1396,knn_tta_r_n=500:178.7461,knn_ttm_r_n=500:176.3602,knn_tta_n=1000:185.816,knn_ttm_n=1000:213.0106,knn_tta_r_n=1000:187.4521,knn_ttm_r_n=1000:185.2227'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:312.4984,knn_ttm_n=100:441.8199,knn_tta_r_n=100:233.73,knn_ttm_r_n=100:242.6076,knn_tta_n=500:209.1602,knn_ttm_n=500:274.3355,knn_tta_r_n=500:195.9161,knn_ttm_r_n=500:197.2176,knn_tta_n=1000:229.8635,knn_ttm_n=1000:283.2322,knn_tta_r_n=1000:228.8898,knn_ttm_r_n=1000:227.5645'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:63.1865,knn_ttm_n=100:57.4583,knn_tta_r_n=100:70.8491,knn_ttm_r_n=100:63.0002,knn_tta_n=500:99.0324,knn_ttm_n=500:101.4734,knn_tta_r_n=500:101.5698,knn_ttm_r_n=500:99.3399,knn_tta_n=1000:104.0186,knn_ttm_n=1000:107.2183,knn_tta_r_n=1000:105.5106,knn_ttm_r_n=1000:104.5426'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:305.2856,knn_ttm_n=100:765.5733,knn_tta_r_n=100:152.1112,knn_ttm_r_n=100:162.2739,knn_tta_n=500:189.2598,knn_ttm_n=500:195.9503,knn_tta_r_n=500:168.8233,knn_ttm_r_n=500:159.9555,knn_tta_n=1000:168.0812,knn_ttm_n=1000:198.126,knn_tta_r_n=1000:158.9071,knn_ttm_r_n=1000:160.8043'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_25'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:209.258,knn_ttm_n=100:254.9808,knn_tta_r_n=100:204.3597,knn_ttm_r_n=100:203.8794,knn_tta_n=500:242.6632,knn_ttm_n=500:275.1742,knn_tta_r_n=500:242.9072,knn_ttm_r_n=500:242.5602,knn_tta_n=1000:251.9478,knn_ttm_n=1000:279.4853,knn_tta_r_n=1000:252.3396,knn_ttm_r_n=1000:252.4282'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:114581.0278,knn_ttm_n=100:7648.2433,knn_tta_r_n=100:236219.4271,knn_ttm_r_n=100:1580301.3079,knn_tta_n=500:443.3044,knn_ttm_n=500:562.2334,knn_tta_r_n=500:341.9879,knn_ttm_r_n=500:330.5884,knn_tta_n=1000:441.9194,knn_ttm_n=1000:545.6744,knn_tta_r_n=1000:346.2857,knn_ttm_r_n=1000:334.0097'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:288.5793,knn_ttm_n=100:361.6171,knn_tta_r_n=100:286.013,knn_ttm_r_n=100:298.5554,knn_tta_n=500:339.1618,knn_ttm_n=500:422.2438,knn_tta_r_n=500:343.1316,knn_ttm_r_n=500:354.2128,knn_tta_n=1000:359.5416,knn_ttm_n=1000:449.0333,knn_tta_r_n=1000:360.3288,knn_ttm_r_n=1000:370.6947'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:6532255497.5576,knn_ttm_n=100:229078615.0716,knn_tta_r_n=100:1070998133.4798,knn_ttm_r_n=100:5579934120.3801,knn_tta_n=500:679.5891,knn_ttm_n=500:831.9745,knn_tta_r_n=500:780.4001,knn_ttm_r_n=500:439.5882,knn_tta_n=1000:783.4044,knn_ttm_n=1000:759.2117,knn_tta_r_n=1000:628.4002,knn_ttm_r_n=1000:405.0133'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:302.0996,knn_ttm_n=100:379.8683,knn_tta_r_n=100:302.3015,knn_ttm_r_n=100:309.1743,knn_tta_n=500:362.4649,knn_ttm_n=500:459.4222,knn_tta_r_n=500:366.2149,knn_ttm_r_n=500:368.23,knn_tta_n=1000:382.7174,knn_ttm_n=1000:485.1204,knn_tta_r_n=1000:385.1588,knn_ttm_r_n=1000:387.8528'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:93985648.7553,knn_ttm_n=100:168731964.2953,knn_tta_r_n=100:195300309.5578,knn_ttm_r_n=100:214375103.6729,knn_tta_n=500:460.1372,knn_ttm_n=500:594.7349,knn_tta_r_n=500:426.7582,knn_ttm_r_n=500:427.4129,knn_tta_n=1000:450.9899,knn_ttm_n=1000:594.4676,knn_tta_r_n=1000:424.3465,knn_ttm_r_n=1000:426.6525'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:163.324,knn_ttm_n=100:208.1685,knn_tta_r_n=100:163.5107,knn_ttm_r_n=100:79872071.6848,knn_tta_n=500:190.8397,knn_ttm_n=500:215.0717,knn_tta_r_n=500:192.9441,knn_ttm_r_n=500:192.2868,knn_tta_n=1000:196.4824,knn_ttm_n=1000:215.1748,knn_tta_r_n=1000:197.4863,knn_ttm_r_n=1000:197.4947'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:4660567.3673,knn_ttm_n=100:2158530.5953,knn_tta_r_n=100:268467.8203,knn_ttm_r_n=100:766791.8913,knn_tta_n=500:305.726,knn_ttm_n=500:440.1572,knn_tta_r_n=500:218.3873,knn_ttm_r_n=500:232.0514,knn_tta_n=1000:218.9143,knn_ttm_n=1000:256.6725,knn_tta_r_n=1000:200.0404,knn_ttm_r_n=1000:197.0143'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:165.7532,knn_ttm_n=100:206.1369,knn_tta_r_n=100:166.856,knn_ttm_r_n=100:172636.2519,knn_tta_n=500:198.7563,knn_ttm_n=500:215.9508,knn_tta_r_n=500:200.7318,knn_ttm_r_n=500:200.9254,knn_tta_n=1000:204.7586,knn_ttm_n=1000:220.5743,knn_tta_r_n=1000:206.4205,knn_ttm_r_n=1000:205.6638'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:98072933.7899,knn_ttm_n=100:94462902.757,knn_tta_r_n=100:3902229.5141,knn_ttm_r_n=100:2024561.2211,knn_tta_n=500:353.4526,knn_ttm_n=500:354.0768,knn_tta_r_n=500:397.7212,knn_ttm_r_n=500:408.38,knn_tta_n=1000:347.38,knn_ttm_n=1000:323.2463,knn_tta_r_n=1000:391.9172,knn_ttm_r_n=1000:405.017'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:104.2633,knn_ttm_n=100:128.9803,knn_tta_r_n=100:100.5082,knn_ttm_r_n=100:106.5043,knn_tta_n=500:115.2776,knn_ttm_n=500:124.6647,knn_tta_r_n=500:115.9984,knn_ttm_r_n=500:115.3746,knn_tta_n=1000:117.953,knn_ttm_n=1000:126.4653,knn_tta_r_n=1000:118.3371,knn_ttm_r_n=1000:117.991'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:2024241.8758,knn_ttm_n=100:1196948.065,knn_tta_r_n=100:451809.9657,knn_ttm_r_n=100:2507706.2564,knn_tta_n=500:146.9589,knn_ttm_n=500:161.1701,knn_tta_r_n=500:144.3225,knn_ttm_r_n=500:146.852,knn_tta_n=1000:143.5883,knn_ttm_n=1000:153.0104,knn_tta_r_n=1000:143.7731,knn_ttm_r_n=1000:144.4985'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_29'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:143.759,knn_ttm_n=100:117.4291,knn_tta_r_n=100:157.4858,knn_ttm_r_n=100:138.236,knn_tta_n=500:189.7588,knn_ttm_n=500:186.3409,knn_tta_r_n=500:195.6565,knn_ttm_r_n=500:184.6221,knn_tta_n=1000:202.3321,knn_ttm_n=1000:207.4674,knn_tta_r_n=1000:207.101,knn_ttm_r_n=1000:197.5733'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:245.3034,knn_ttm_n=100:288.2721,knn_tta_r_n=100:226.1996,knn_ttm_r_n=100:235.0094,knn_tta_n=500:234.7541,knn_ttm_n=500:255.8778,knn_tta_r_n=500:228.5251,knn_ttm_r_n=500:226.8898,knn_tta_n=1000:235.7786,knn_ttm_n=1000:253.9017,knn_tta_r_n=1000:233.0724,knn_ttm_r_n=1000:230.1709'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:167.4347,knn_ttm_n=100:139.94,knn_tta_r_n=100:184.1167,knn_ttm_r_n=100:156.4448,knn_tta_n=500:223.9564,knn_ttm_n=500:227.2309,knn_tta_r_n=500:233.8545,knn_ttm_r_n=500:219.1203,knn_tta_n=1000:243.1256,knn_ttm_n=1000:255.1639,knn_tta_r_n=1000:248.8636,knn_ttm_r_n=1000:236.8548'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:255.9013,knn_ttm_n=100:285.7133,knn_tta_r_n=100:244.7828,knn_ttm_r_n=100:251.7589,knn_tta_n=500:254.8289,knn_ttm_n=500:276.9643,knn_tta_r_n=500:254.9533,knn_ttm_r_n=500:251.444,knn_tta_n=1000:264.0011,knn_ttm_n=1000:283.9358,knn_tta_r_n=1000:261.7216,knn_ttm_r_n=1000:256.4712'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:162.3876,knn_ttm_n=100:140.9363,knn_tta_r_n=100:177.4585,knn_ttm_r_n=100:150.5356,knn_tta_n=500:213.2013,knn_ttm_n=500:219.9849,knn_tta_r_n=500:224.2623,knn_ttm_r_n=500:208.8327,knn_tta_n=1000:231.7948,knn_ttm_n=1000:242.9095,knn_tta_r_n=1000:239.6672,knn_ttm_r_n=1000:227.1626'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:251.275,knn_ttm_n=100:280.3698,knn_tta_r_n=100:242.9333,knn_ttm_r_n=100:257.7865,knn_tta_n=500:242.0771,knn_ttm_n=500:260.4738,knn_tta_r_n=500:246.9382,knn_ttm_r_n=500:245.2379,knn_tta_n=1000:250.2269,knn_ttm_n=1000:263.9382,knn_tta_r_n=1000:255.038,knn_ttm_r_n=1000:249.9487'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:127.453,knn_ttm_n=100:105.3784,knn_tta_r_n=100:139.7569,knn_ttm_r_n=100:121.0155,knn_tta_n=500:162.7473,knn_ttm_n=500:164.1945,knn_tta_r_n=500:168.7495,knn_ttm_r_n=500:160.0423,knn_tta_n=1000:170.2808,knn_ttm_n=1000:177.6364,knn_tta_r_n=1000:175.1742,knn_ttm_r_n=1000:169.2043'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:188.4787,knn_ttm_n=100:226.2491,knn_tta_r_n=100:174.746,knn_ttm_r_n=100:179.9961,knn_tta_n=500:171.6415,knn_ttm_n=500:194.741,knn_tta_r_n=500:173.6703,knn_ttm_r_n=500:173.4073,knn_tta_n=1000:173.2876,knn_ttm_n=1000:191.5095,knn_tta_r_n=1000:176.1775,knn_ttm_r_n=1000:175.0802'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:125.7049,knn_ttm_n=100:102.5188,knn_tta_r_n=100:140.2149,knn_ttm_r_n=100:122.8271,knn_tta_n=500:165.1239,knn_ttm_n=500:165.8594,knn_tta_r_n=500:173.4698,knn_ttm_r_n=500:162.9436,knn_tta_n=1000:176.3088,knn_ttm_n=1000:183.9158,knn_tta_r_n=1000:182.9606,knn_ttm_r_n=1000:174.3378'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:199.1444,knn_ttm_n=100:234.7945,knn_tta_r_n=100:181.9677,knn_ttm_r_n=100:188.08,knn_tta_n=500:187.7595,knn_ttm_n=500:212.6213,knn_tta_r_n=500:182.1653,knn_ttm_r_n=500:181.1048,knn_tta_n=1000:189.0389,knn_ttm_n=1000:211.5095,knn_tta_r_n=1000:185.7157,knn_ttm_r_n=1000:182.1401'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:90.9358,knn_ttm_n=100:72.521,knn_tta_r_n=100:97.8782,knn_ttm_r_n=100:85.2564,knn_tta_n=500:112.3513,knn_ttm_n=500:112.3761,knn_tta_r_n=500:115.872,knn_ttm_r_n=500:110.1119,knn_tta_n=1000:116.9715,knn_ttm_n=1000:121.1918,knn_tta_r_n=1000:119.1573,knn_ttm_r_n=1000:115.6312'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:153.6282,knn_ttm_n=100:182.5824,knn_tta_r_n=100:134.9166,knn_ttm_r_n=100:137.0465,knn_tta_n=500:138.9274,knn_ttm_n=500:151.3095,knn_tta_r_n=500:134.6582,knn_ttm_r_n=500:133.5518,knn_tta_n=1000:138.2527,knn_ttm_n=1000:147.3028,knn_tta_r_n=1000:135.6533,knn_ttm_r_n=1000:134.4182'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_32'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:291.7509,knn_ttm_n=100:295.8908,knn_tta_r_n=100:278.5365,knn_ttm_r_n=100:278.0275,knn_tta_n=500:296.7792,knn_ttm_n=500:5672994.8877,knn_tta_r_n=500:284.7369,knn_ttm_r_n=500:5672981.501,knn_tta_n=1000:284.0935,knn_ttm_n=1000:313.1623,knn_tta_r_n=1000:286.1727,knn_ttm_r_n=1000:287.5656'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:344.5164,knn_ttm_n=100:357.8928,knn_tta_r_n=100:321.4963,knn_ttm_r_n=100:327.1978,knn_tta_n=500:328.1636,knn_ttm_n=500:5084352.2526,knn_tta_r_n=500:316.5501,knn_ttm_r_n=500:5084345.7538,knn_tta_n=1000:312.8336,knn_ttm_n=1000:337.3494,knn_tta_r_n=1000:316.7021,knn_ttm_r_n=1000:318.8743'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:458.2303,knn_ttm_n=100:530.361,knn_tta_r_n=100:434.2682,knn_ttm_r_n=100:436.4223,knn_tta_n=500:636.5971,knn_ttm_n=500:38378576.1212,knn_tta_r_n=500:433.6527,knn_ttm_r_n=500:38378490.1992,knn_tta_n=1000:435.2985,knn_ttm_n=1000:577.2739,knn_tta_r_n=1000:432.8806,knn_ttm_r_n=1000:438.5217'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:518.9695,knn_ttm_n=100:620.8641,knn_tta_r_n=100:481.3395,knn_ttm_r_n=100:484.4547,knn_tta_n=500:677.4807,knn_ttm_n=500:39112937.1471,knn_tta_r_n=500:472.8448,knn_ttm_r_n=500:39112846.1064,knn_tta_n=1000:471.6574,knn_ttm_n=1000:618.8751,knn_tta_r_n=1000:466.727,knn_ttm_r_n=1000:471.1021'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:531.4192,knn_ttm_n=100:514.2816,knn_tta_r_n=100:459.1978,knn_ttm_r_n=100:454.9497,knn_tta_n=500:567.7682,knn_ttm_n=500:1365181.7603,knn_tta_r_n=500:456.5286,knn_ttm_r_n=500:1365120.7541,knn_tta_n=1000:454.1865,knn_ttm_n=1000:611.6586,knn_tta_r_n=1000:452.216,knn_ttm_r_n=1000:457.4227'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:545.4184,knn_ttm_n=100:557.8468,knn_tta_r_n=100:478.4466,knn_ttm_r_n=100:476.2655,knn_tta_n=500:569.6655,knn_ttm_n=500:1370414.4497,knn_tta_r_n=500:463.1616,knn_ttm_r_n=500:1370354.5525,knn_tta_n=1000:463.1318,knn_ttm_n=1000:611.058,knn_tta_r_n=1000:461.4007,knn_ttm_r_n=1000:466.7946'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:226.537,knn_ttm_n=100:235.385,knn_tta_r_n=100:231.9517,knn_ttm_r_n=100:221.3876,knn_tta_n=500:224.5859,knn_ttm_n=500:231.8719,knn_tta_r_n=500:224.3163,knn_ttm_r_n=500:224.4644,knn_tta_n=1000:225.1308,knn_ttm_n=1000:231.8441,knn_tta_r_n=1000:225.009,knn_ttm_r_n=1000:225.0618'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:242.146,knn_ttm_n=100:261.3124,knn_tta_r_n=100:230.8019,knn_ttm_r_n=100:229.9172,knn_tta_n=500:227.9872,knn_ttm_n=500:238.2384,knn_tta_r_n=500:226.7546,knn_ttm_r_n=500:227.4138,knn_tta_n=1000:226.6483,knn_ttm_n=1000:233.9985,knn_tta_r_n=1000:226.4315,knn_ttm_r_n=1000:226.6749'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:242.5998,knn_ttm_n=100:254.0461,knn_tta_r_n=100:237.6579,knn_ttm_r_n=100:237.3891,knn_tta_n=500:240.8946,knn_ttm_n=500:258.3217,knn_tta_r_n=500:240.7723,knn_ttm_r_n=500:241.4452,knn_tta_n=1000:241.2415,knn_ttm_n=1000:258.8002,knn_tta_r_n=1000:241.0881,knn_ttm_r_n=1000:241.8225'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:1462581026.3436,knn_ttm_n=100:105155.8653,knn_tta_r_n=100:48443155.4011,knn_ttm_r_n=100:855728.7404,knn_tta_n=500:234.7506,knn_ttm_n=500:253.9469,knn_tta_r_n=500:234.814,knn_ttm_r_n=500:235.9039,knn_tta_n=1000:233.8951,knn_ttm_n=1000:251.5574,knn_tta_r_n=1000:234.4895,knn_ttm_r_n=1000:235.5091'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:18072542703113.598,knn_ttm_n=100:119.9251,knn_tta_r_n=100:115.2352,knn_ttm_r_n=100:114.7415,knn_tta_n=500:117.2923,knn_ttm_n=500:119.422,knn_tta_r_n=500:117.4765,knn_ttm_r_n=500:117.2998,knn_tta_n=1000:117.7089,knn_ttm_n=1000:119.5982,knn_tta_r_n=1000:117.6498,knn_ttm_r_n=1000:117.6064'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:13001574802136.703,knn_ttm_n=100:1286038.3032,knn_tta_r_n=100:413206.5375,knn_ttm_r_n=100:421813.2296,knn_tta_n=500:141.7731,knn_ttm_n=500:143.4155,knn_tta_r_n=500:141.9983,knn_ttm_r_n=500:142.4829,knn_tta_n=1000:141.3518,knn_ttm_n=1000:141.7189,knn_tta_r_n=1000:141.8018,knn_ttm_r_n=1000:141.8696'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_34'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:136.5888,knn_ttm_n=100:115.9961,knn_tta_r_n=100:151.1797,knn_ttm_r_n=100:130.3946,knn_tta_n=500:185.8459,knn_ttm_n=500:189.7075,knn_tta_r_n=500:193.8351,knn_ttm_r_n=500:182.6834,knn_tta_n=1000:199.3686,knn_ttm_n=1000:209.9173,knn_tta_r_n=1000:205.7686,knn_ttm_r_n=1000:197.741'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:263.9354,knn_ttm_n=100:322.2798,knn_tta_r_n=100:225.2945,knn_ttm_r_n=100:234.0893,knn_tta_n=500:438.8118,knn_ttm_n=500:450.5375,knn_tta_r_n=500:267.2711,knn_ttm_r_n=500:249.0383,knn_tta_n=1000:233.5556,knn_ttm_n=1000:263.9707,knn_tta_r_n=1000:227.6757,knn_ttm_r_n=1000:225.4999'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:147.3248,knn_ttm_n=100:145.6581,knn_tta_r_n=100:163.9265,knn_ttm_r_n=100:138.1552,knn_tta_n=500:200.1266,knn_ttm_n=500:230.8855,knn_tta_r_n=500:208.5116,knn_ttm_r_n=500:196.1916,knn_tta_n=1000:212.3559,knn_ttm_n=1000:250.2338,knn_tta_r_n=1000:219.163,knn_ttm_r_n=1000:211.3925'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:282.7005,knn_ttm_n=100:319.8086,knn_tta_r_n=100:250.2281,knn_ttm_r_n=100:265.9683,knn_tta_n=500:254.8341,knn_ttm_n=500:304.0669,knn_tta_r_n=500:253.6279,knn_ttm_r_n=500:250.9005,knn_tta_n=1000:252.7823,knn_ttm_n=1000:304.1852,knn_tta_r_n=1000:249.5087,knn_ttm_r_n=1000:253.2695'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:164.3227,knn_ttm_n=100:162.5155,knn_tta_r_n=100:178.9161,knn_ttm_r_n=100:152.674,knn_tta_n=500:215.7536,knn_ttm_n=500:250.9427,knn_tta_r_n=500:225.5936,knn_ttm_r_n=500:213.0645,knn_tta_n=1000:229.0033,knn_ttm_n=1000:272.1894,knn_tta_r_n=1000:236.4265,knn_ttm_r_n=1000:228.1144'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:282.4889,knn_ttm_n=100:344.432,knn_tta_r_n=100:266.9652,knn_ttm_r_n=100:285.7045,knn_tta_n=500:258.4164,knn_ttm_n=500:306.5184,knn_tta_r_n=500:256.0356,knn_ttm_r_n=500:263.8353,knn_tta_n=1000:263.9037,knn_ttm_n=1000:312.0805,knn_tta_r_n=1000:261.7266,knn_ttm_r_n=1000:259.5834'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:124.06,knn_ttm_n=100:97.2451,knn_tta_r_n=100:139.0371,knn_ttm_r_n=100:118.539,knn_tta_n=500:169.6065,knn_ttm_n=500:163.7136,knn_tta_r_n=500:176.3246,knn_ttm_r_n=500:165.8285,knn_tta_n=1000:179.8927,knn_ttm_n=1000:182.3213,knn_tta_r_n=1000:184.1325,knn_ttm_r_n=1000:176.9714'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:227.7375,knn_ttm_n=100:267.3073,knn_tta_r_n=100:200.4146,knn_ttm_r_n=100:209.1503,knn_tta_n=500:195.3264,knn_ttm_n=500:217.6638,knn_tta_r_n=500:188.618,knn_ttm_r_n=500:190.4079,knn_tta_n=1000:192.6237,knn_ttm_n=1000:208.4553,knn_tta_r_n=1000:189.6499,knn_ttm_r_n=1000:189.0643'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:123.3269,knn_ttm_n=100:101.4131,knn_tta_r_n=100:139.8256,knn_ttm_r_n=100:116.1845,knn_tta_n=500:171.2455,knn_ttm_n=500:167.7911,knn_tta_r_n=500:180.2417,knn_ttm_r_n=500:168.4697,knn_tta_n=1000:183.6461,knn_ttm_n=1000:186.7682,knn_tta_r_n=1000:189.79,knn_ttm_r_n=1000:180.3219'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:220.2321,knn_ttm_n=100:264.6801,knn_tta_r_n=100:192.9192,knn_ttm_r_n=100:202.0222,knn_tta_n=500:193.4032,knn_ttm_n=500:212.0083,knn_tta_r_n=500:188.1242,knn_ttm_r_n=500:187.3333,knn_tta_n=1000:192.8867,knn_ttm_n=1000:210.7191,knn_tta_r_n=1000:190.2892,knn_ttm_r_n=1000:187.9661'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:78.1285,knn_ttm_n=100:62.4729,knn_tta_r_n=100:87.6454,knn_ttm_r_n=100:72.8422,knn_tta_n=500:106.9341,knn_ttm_n=500:103.5712,knn_tta_r_n=500:110.9051,knn_ttm_r_n=500:104.0614,knn_tta_n=1000:112.6332,knn_ttm_n=1000:114.05,knn_tta_r_n=1000:114.6881,knn_ttm_r_n=1000:110.6899'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:174.6625,knn_ttm_n=100:197.3419,knn_tta_r_n=100:147.8539,knn_ttm_r_n=100:152.1463,knn_tta_n=500:144.8767,knn_ttm_n=500:156.6437,knn_tta_r_n=500:140.2617,knn_ttm_r_n=500:141.8177,knn_tta_n=1000:141.9212,knn_ttm_n=1000:150.7976,knn_tta_r_n=1000:139.3447,knn_ttm_r_n=1000:140.3719'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_37'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:256.747,knn_ttm_n=100:275.5548,knn_tta_r_n=100:258.1693,knn_ttm_r_n=100:261.4506,knn_tta_n=500:270.5036,knn_ttm_n=500:289.8135,knn_tta_r_n=500:270.1378,knn_ttm_r_n=500:270.8844,knn_tta_n=1000:272.4437,knn_ttm_n=1000:293.2128,knn_tta_r_n=1000:272.0243,knn_ttm_r_n=1000:273.0061'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:310.1287,knn_ttm_n=100:348.207,knn_tta_r_n=100:298.9954,knn_ttm_r_n=100:298.8502,knn_tta_n=500:299.0404,knn_ttm_n=500:325.014,knn_tta_r_n=500:296.3432,knn_ttm_r_n=500:297.1968,knn_tta_n=1000:298.7965,knn_ttm_n=1000:322.4027,knn_tta_r_n=1000:296.8731,knn_ttm_r_n=1000:297.8445'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:408.483,knn_ttm_n=100:488.9837,knn_tta_r_n=100:406.5129,knn_ttm_r_n=100:413.1318,knn_tta_n=500:424.85,knn_ttm_n=500:516.0337,knn_tta_r_n=500:422.1441,knn_ttm_r_n=500:426.4552,knn_tta_n=1000:431.5121,knn_ttm_n=1000:523.6378,knn_tta_r_n=1000:428.5372,knn_ttm_r_n=1000:432.1817'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:482.6392,knn_ttm_n=100:606.6074,knn_tta_r_n=100:461.9475,knn_ttm_r_n=100:467.8147,knn_tta_n=500:470.1962,knn_ttm_n=500:577.5309,knn_tta_r_n=500:458.7519,knn_ttm_r_n=500:461.047,knn_tta_n=1000:473.4458,knn_ttm_n=1000:581.438,knn_tta_r_n=1000:462.1386,knn_ttm_r_n=1000:464.1069'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:405.9085,knn_ttm_n=100:492.2488,knn_tta_r_n=100:403.4264,knn_ttm_r_n=100:415.1817,knn_tta_n=500:427.4836,knn_ttm_n=500:530.0664,knn_tta_r_n=500:426.9847,knn_ttm_r_n=500:431.9778,knn_tta_n=1000:442.1379,knn_ttm_n=1000:562.9913,knn_tta_r_n=1000:438.3041,knn_ttm_r_n=1000:442.9909'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:470.8525,knn_ttm_n=100:574.8095,knn_tta_r_n=100:454.0049,knn_ttm_r_n=100:467.5926,knn_tta_n=500:449.0855,knn_ttm_n=500:549.2304,knn_tta_r_n=500:446.9575,knn_ttm_r_n=500:455.0137,knn_tta_n=1000:461.1519,knn_ttm_n=1000:573.1337,knn_tta_r_n=1000:457.8353,knn_ttm_r_n=1000:462.5366'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:190.2614,knn_ttm_n=100:198.2382,knn_tta_r_n=100:191.3457,knn_ttm_r_n=100:192.2964,knn_tta_n=500:197.9452,knn_ttm_n=500:207.5271,knn_tta_r_n=500:197.7541,knn_ttm_r_n=500:198.0983,knn_tta_n=1000:198.7913,knn_ttm_n=1000:208.0115,knn_tta_r_n=1000:198.6365,knn_ttm_r_n=1000:198.7744'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:205.1576,knn_ttm_n=100:230.1945,knn_tta_r_n=100:197.1385,knn_ttm_r_n=100:196.7469,knn_tta_n=500:195.944,knn_ttm_n=500:210.0669,knn_tta_r_n=500:194.417,knn_ttm_r_n=500:194.4858,knn_tta_n=1000:194.7113,knn_ttm_n=1000:206.464,knn_tta_r_n=1000:193.6694,knn_ttm_r_n=1000:193.9359'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:217.2654,knn_ttm_n=100:239.4346,knn_tta_r_n=100:217.4547,knn_ttm_r_n=100:218.1233,knn_tta_n=500:224.1193,knn_ttm_n=500:244.3061,knn_tta_r_n=500:223.8011,knn_ttm_r_n=500:224.1452,knn_tta_n=1000:224.9107,knn_ttm_n=1000:242.5964,knn_tta_r_n=1000:224.8117,knn_ttm_r_n=1000:224.8801'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:234.9741,knn_ttm_n=100:286.3238,knn_tta_r_n=100:224.3544,knn_ttm_r_n=100:224.0224,knn_tta_n=500:225.9296,knn_ttm_n=500:259.7992,knn_tta_r_n=500:220.9112,knn_ttm_r_n=500:221.2878,knn_tta_n=1000:223.8257,knn_ttm_n=1000:249.9284,knn_tta_r_n=1000:220.2086,knn_ttm_r_n=1000:220.4032'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:136.599,knn_ttm_n=100:144.5539,knn_tta_r_n=100:136.9357,knn_ttm_r_n=100:137.1468,knn_tta_n=500:140.6649,knn_ttm_n=500:147.8211,knn_tta_r_n=500:140.7984,knn_ttm_r_n=500:140.6473,knn_tta_n=1000:141.4488,knn_ttm_n=1000:149.305,knn_tta_r_n=1000:141.4151,knn_ttm_r_n=1000:141.3724'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:150.9335,knn_ttm_n=100:164.9794,knn_tta_r_n=100:150.2235,knn_ttm_r_n=100:151.8214,knn_tta_n=500:147.4954,knn_ttm_n=500:150.3619,knn_tta_r_n=500:148.5666,knn_ttm_r_n=500:148.8735,knn_tta_n=1000:147.2172,knn_ttm_n=1000:149.9787,knn_tta_r_n=1000:148.3019,knn_ttm_r_n=1000:148.8945'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_39'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:123.7022,knn_ttm_n=100:107.5254,knn_tta_r_n=100:139.0404,knn_ttm_r_n=100:120.712,knn_tta_n=500:185.4839,knn_ttm_n=500:184.9839,knn_tta_r_n=500:194.5146,knn_ttm_r_n=500:182.23,knn_tta_n=1000:200.2559,knn_ttm_n=1000:205.2153,knn_tta_r_n=1000:207.4111,knn_ttm_r_n=1000:199.1771'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:289.1916,knn_ttm_n=100:470.8966,knn_tta_r_n=100:252.2545,knn_ttm_r_n=100:293.1889,knn_tta_n=500:252.4221,knn_ttm_n=500:286.4807,knn_tta_r_n=500:248.8395,knn_ttm_r_n=500:249.1583,knn_tta_n=1000:238.7887,knn_ttm_n=1000:267.1716,knn_tta_r_n=1000:235.5954,knn_ttm_r_n=1000:236.6849'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:152.069,knn_ttm_n=100:141.8149,knn_tta_r_n=100:173.5048,knn_ttm_r_n=100:145.1305,knn_tta_n=500:246.5578,knn_ttm_n=500:266.8335,knn_tta_r_n=500:257.8994,knn_ttm_r_n=500:239.6383,knn_tta_n=1000:274.257,knn_ttm_n=1000:302.4915,knn_tta_r_n=1000:281.7523,knn_ttm_r_n=1000:266.7432'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:365.7598,knn_ttm_n=100:444.8379,knn_tta_r_n=100:324.7937,knn_ttm_r_n=100:354.4754,knn_tta_n=500:309.7117,knn_ttm_n=500:365.9915,knn_tta_r_n=500:299.648,knn_ttm_r_n=500:302.6161,knn_tta_n=1000:317.9988,knn_ttm_n=1000:370.3862,knn_tta_r_n=1000:317.6218,knn_ttm_r_n=1000:311.6244'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:151.9552,knn_ttm_n=100:135.7534,knn_tta_r_n=100:174.406,knn_ttm_r_n=100:139.6131,knn_tta_n=500:248.9299,knn_ttm_n=500:262.901,knn_tta_r_n=500:257.2386,knn_ttm_r_n=500:233.7069,knn_tta_n=1000:272.6172,knn_ttm_n=1000:295.2595,knn_tta_r_n=1000:279.7308,knn_ttm_r_n=1000:261.0149'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:420.4842,knn_ttm_n=100:477.2519,knn_tta_r_n=100:346.5952,knn_ttm_r_n=100:340.4675,knn_tta_n=500:364.876,knn_ttm_n=500:420.5418,knn_tta_r_n=500:328.1206,knn_ttm_r_n=500:317.121,knn_tta_n=1000:356.3812,knn_ttm_n=1000:398.0185,knn_tta_r_n=1000:337.0387,knn_ttm_r_n=1000:322.3355'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:117.7171,knn_ttm_n=100:96.9936,knn_tta_r_n=100:134.0345,knn_ttm_r_n=100:329.0769,knn_tta_n=500:172.1111,knn_ttm_n=500:168.9204,knn_tta_r_n=500:179.5821,knn_ttm_r_n=500:173.7332,knn_tta_n=1000:183.1422,knn_ttm_n=1000:185.3906,knn_tta_r_n=1000:188.6429,knn_ttm_r_n=1000:180.8966'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:271.4976,knn_ttm_n=100:346.3151,knn_tta_r_n=100:212.6176,knn_ttm_r_n=100:219.0336,knn_tta_n=500:202.3806,knn_ttm_n=500:235.0697,knn_tta_r_n=500:198.497,knn_ttm_r_n=500:201.3625,knn_tta_n=1000:195.9814,knn_ttm_n=1000:217.1518,knn_tta_r_n=1000:199.8812,knn_ttm_r_n=1000:200.3536'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:115.8425,knn_ttm_n=100:101.4774,knn_tta_r_n=100:132.881,knn_ttm_r_n=100:413.2289,knn_tta_n=500:173.0555,knn_ttm_n=500:177.034,knn_tta_r_n=500:182.2761,knn_ttm_r_n=500:346.3353,knn_tta_n=1000:185.6613,knn_ttm_n=1000:196.5879,knn_tta_r_n=1000:193.0404,knn_ttm_r_n=1000:340.1748'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:489.4078,knn_ttm_n=100:978.0006,knn_tta_r_n=100:481.9007,knn_ttm_r_n=100:508.7147,knn_tta_n=500:292.3956,knn_ttm_n=500:425.2476,knn_tta_r_n=500:229.1575,knn_ttm_r_n=500:235.7019,knn_tta_n=1000:317.7866,knn_ttm_n=1000:372.5162,knn_tta_r_n=1000:211.1435,knn_ttm_r_n=1000:221.8146'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:65.3209,knn_ttm_n=100:52.3664,knn_tta_r_n=100:73.5232,knn_ttm_r_n=100:59.2367,knn_tta_n=500:92.5238,knn_ttm_n=500:87.8285,knn_tta_r_n=500:96.3135,knn_ttm_r_n=500:89.9162,knn_tta_n=1000:97.7044,knn_ttm_n=1000:97.2792,knn_tta_r_n=1000:100.144,knn_ttm_r_n=1000:96.4281'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:169.9519,knn_ttm_n=100:208.0253,knn_tta_r_n=100:146.606,knn_ttm_r_n=100:153.163,knn_tta_n=500:147.9181,knn_ttm_n=500:162.1241,knn_tta_r_n=500:140.6601,knn_ttm_r_n=500:140.3494,knn_tta_n=1000:145.4043,knn_ttm_n=1000:157.4818,knn_tta_r_n=1000:140.584,knn_ttm_r_n=1000:139.8765'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_40'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:168.8975,knn_ttm_n=100:194.6244,knn_tta_r_n=100:157.5783,knn_ttm_r_n=100:198.6873,knn_tta_n=500:190.4317,knn_ttm_n=500:221.2152,knn_tta_r_n=500:187.8912,knn_ttm_r_n=500:979.0134,knn_tta_n=1000:198.2262,knn_ttm_n=1000:223.2108,knn_tta_r_n=1000:196.9801,knn_ttm_r_n=1000:251.8594'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1141.0554,knn_ttm_n=100:2871.721,knn_tta_r_n=100:670.4125,knn_ttm_r_n=100:757.6708,knn_tta_n=500:270.4014,knn_ttm_n=500:345.6993,knn_tta_r_n=500:242.7539,knn_ttm_r_n=500:260.088,knn_tta_n=1000:276.9828,knn_ttm_n=1000:305.1904,knn_tta_r_n=1000:238.4317,knn_ttm_r_n=1000:260.3207'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:237.9654,knn_ttm_n=100:249.8867,knn_tta_r_n=100:216.1163,knn_ttm_r_n=100:175.5003,knn_tta_n=500:280.5267,knn_ttm_n=500:315.9007,knn_tta_r_n=500:263.8877,knn_ttm_r_n=500:229.216,knn_tta_n=1000:287.0924,knn_ttm_n=1000:336.0574,knn_tta_r_n=1000:265.168,knn_ttm_r_n=1000:253.2948'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:220761.6519,knn_ttm_n=100:294771.3944,knn_tta_r_n=100:66731.7279,knn_ttm_r_n=100:259284.9827,knn_tta_n=500:90646.5107,knn_ttm_n=500:101163.9832,knn_tta_r_n=500:69182.4892,knn_ttm_r_n=500:75947.8337,knn_tta_n=1000:97220.0796,knn_ttm_n=1000:78984.4051,knn_tta_r_n=1000:89514.5679,knn_ttm_r_n=1000:74224.6971'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:198.4417,knn_ttm_n=100:230.972,knn_tta_r_n=100:183.6601,knn_ttm_r_n=100:151.1847,knn_tta_n=500:277.663,knn_ttm_n=500:309.7671,knn_tta_r_n=500:261.8914,knn_ttm_r_n=500:229.8717,knn_tta_n=1000:240.5724,knn_ttm_n=1000:298.883,knn_tta_r_n=1000:235.2644,knn_ttm_r_n=1000:222.1721'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1150.1478,knn_ttm_n=100:2067.5453,knn_tta_r_n=100:545.4465,knn_ttm_r_n=100:827.1705,knn_tta_n=500:454.6866,knn_ttm_n=500:513.987,knn_tta_r_n=500:348.1109,knn_ttm_r_n=500:348.8557,knn_tta_n=1000:301.9291,knn_ttm_n=1000:363.1419,knn_tta_r_n=1000:289.2907,knn_ttm_r_n=1000:286.6578'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:170.5825,knn_ttm_n=100:225.3202,knn_tta_r_n=100:150.2045,knn_ttm_r_n=100:146.6044,knn_tta_n=500:181.4373,knn_ttm_n=500:200.3877,knn_tta_r_n=500:179.5681,knn_ttm_r_n=500:172.1917,knn_tta_n=1000:190.2421,knn_ttm_n=1000:208.9266,knn_tta_r_n=1000:188.1089,knn_ttm_r_n=1000:180.2479'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:24490.1994,knn_ttm_n=100:28835.1184,knn_tta_r_n=100:5692.6275,knn_ttm_r_n=100:4400.9133,knn_tta_n=500:314.0683,knn_ttm_n=500:327.9232,knn_tta_r_n=500:239.4948,knn_ttm_r_n=500:256.5891,knn_tta_n=1000:327.0653,knn_ttm_n=1000:531.633,knn_tta_r_n=1000:217.0351,knn_ttm_r_n=1000:232.291'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:207.5741,knn_ttm_n=100:247.2113,knn_tta_r_n=100:174.3989,knn_ttm_r_n=100:398.6507,knn_tta_n=500:194.7039,knn_ttm_n=500:220.4363,knn_tta_r_n=500:188.6904,knn_ttm_r_n=500:171.5035,knn_tta_n=1000:198.8197,knn_ttm_n=1000:218.3268,knn_tta_r_n=1000:191.6775,knn_ttm_r_n=1000:185.4224'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:2716.7244,knn_ttm_n=100:6826.82,knn_tta_r_n=100:1510.7638,knn_ttm_r_n=100:1243.9138,knn_tta_n=500:605.8908,knn_ttm_n=500:1487.9637,knn_tta_r_n=500:246.5802,knn_ttm_r_n=500:215.8606,knn_tta_n=1000:324.4009,knn_ttm_n=1000:265.8884,knn_tta_r_n=1000:208.7669,knn_ttm_r_n=1000:208.9792'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:107.0994,knn_ttm_n=100:125.9528,knn_tta_r_n=100:90.3413,knn_ttm_r_n=100:122.3685,knn_tta_n=500:117.6171,knn_ttm_n=500:131.7725,knn_tta_r_n=500:112.1439,knn_ttm_r_n=500:106.0719,knn_tta_n=1000:115.6616,knn_ttm_n=1000:128.4722,knn_tta_r_n=1000:114.3064,knn_ttm_r_n=1000:110.7023'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:10959.4254,knn_ttm_n=100:20732.9646,knn_tta_r_n=100:4707.3654,knn_ttm_r_n=100:8076.7816,knn_tta_n=500:874.8831,knn_ttm_n=500:758.803,knn_tta_r_n=500:597.7324,knn_ttm_r_n=500:1083.8643,knn_tta_n=1000:195.1484,knn_ttm_n=1000:643.047,knn_tta_r_n=1000:158.9667,knn_ttm_r_n=1000:167.6639'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_47'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:296.1422,knn_ttm_n=100:304.5391,knn_tta_r_n=100:288.5327,knn_ttm_r_n=100:303.1133,knn_tta_n=500:291.921,knn_ttm_n=500:319.0673,knn_tta_r_n=500:290.792,knn_ttm_r_n=500:302.1243,knn_tta_n=1000:291.5801,knn_ttm_n=1000:318.717,knn_tta_r_n=1000:291.2523,knn_ttm_r_n=1000:302.3366'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:335.6214,knn_ttm_n=100:340.8823,knn_tta_r_n=100:318.5239,knn_ttm_r_n=100:319.6725,knn_tta_n=500:320.2362,knn_ttm_n=500:350.806,knn_tta_r_n=500:317.7276,knn_ttm_r_n=500:319.2912,knn_tta_n=1000:315.536,knn_ttm_n=1000:345.3256,knn_tta_r_n=1000:314.7534,knn_ttm_r_n=1000:315.6401'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:453.0175,knn_ttm_n=100:489.5221,knn_tta_r_n=100:432.119,knn_ttm_r_n=100:436.1739,knn_tta_n=500:484.3518,knn_ttm_n=500:498.001,knn_tta_r_n=500:434.6888,knn_ttm_r_n=500:439.069,knn_tta_n=1000:438.798,knn_ttm_n=1000:543.1215,knn_tta_r_n=1000:435.6432,knn_ttm_r_n=1000:440.9763'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1692.2198,knn_ttm_n=100:1948.9337,knn_tta_r_n=100:1273.8931,knn_ttm_r_n=100:657.6334,knn_tta_n=500:1689.1986,knn_ttm_n=500:1817.3505,knn_tta_r_n=500:1312.1526,knn_ttm_r_n=500:665.3324,knn_tta_n=1000:1713.5309,knn_ttm_n=1000:1870.2892,knn_tta_r_n=1000:1200.0824,knn_ttm_r_n=1000:648.9219'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:522.6535,knn_ttm_n=100:509.9671,knn_tta_r_n=100:465.2491,knn_ttm_r_n=100:464.265,knn_tta_n=500:556.7107,knn_ttm_n=500:516.4588,knn_tta_r_n=500:457.6378,knn_ttm_r_n=500:461.97,knn_tta_n=1000:462.3653,knn_ttm_n=1000:611.3624,knn_tta_r_n=1000:458.2118,knn_ttm_r_n=1000:464.5496'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:549.6207,knn_ttm_n=100:558.701,knn_tta_r_n=100:495.2578,knn_ttm_r_n=100:487.6458,knn_tta_n=500:571.3674,knn_ttm_n=500:540.077,knn_tta_r_n=500:478.8711,knn_ttm_r_n=500:479.8135,knn_tta_n=1000:479.8809,knn_ttm_n=1000:621.5991,knn_tta_r_n=1000:476.2015,knn_ttm_r_n=1000:481.5451'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:212.6802,knn_ttm_n=100:214.2929,knn_tta_r_n=100:212.14,knn_ttm_r_n=100:212.3658,knn_tta_n=500:215.2593,knn_ttm_n=500:217.265,knn_tta_r_n=500:215.4278,knn_ttm_r_n=500:215.1321,knn_tta_n=1000:215.9436,knn_ttm_n=1000:218.0687,knn_tta_r_n=1000:216.26,knn_ttm_r_n=1000:215.9328'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:217.7886,knn_ttm_n=100:226.0223,knn_tta_r_n=100:214.8353,knn_ttm_r_n=100:214.7452,knn_tta_n=500:213.3209,knn_ttm_n=500:215.842,knn_tta_r_n=500:214.0098,knn_ttm_r_n=500:214.3088,knn_tta_n=1000:213.5814,knn_ttm_n=1000:215.272,knn_tta_r_n=1000:214.2835,knn_ttm_r_n=1000:214.2972'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:236.1818,knn_ttm_n=100:244.2256,knn_tta_r_n=100:236.8193,knn_ttm_r_n=100:236.9097,knn_tta_n=500:239.9604,knn_ttm_n=500:246.3656,knn_tta_r_n=500:239.6135,knn_ttm_r_n=500:239.7369,knn_tta_n=1000:240.3275,knn_ttm_n=1000:246.6897,knn_tta_r_n=1000:240.2517,knn_ttm_r_n=1000:240.2054'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:230.5477,knn_ttm_n=100:252.8295,knn_tta_r_n=100:224.9104,knn_ttm_r_n=100:224.5425,knn_tta_n=500:226.2082,knn_ttm_n=500:237.7327,knn_tta_r_n=500:223.8569,knn_ttm_r_n=500:223.732,knn_tta_n=1000:225.0944,knn_ttm_n=1000:235.2749,knn_tta_r_n=1000:223.4988,knn_ttm_r_n=1000:223.4364'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:120.6656,knn_ttm_n=100:125.9203,knn_tta_r_n=100:121.195,knn_ttm_r_n=100:121.1108,knn_tta_n=500:122.8241,knn_ttm_n=500:129.8358,knn_tta_r_n=500:122.5671,knn_ttm_r_n=500:122.8913,knn_tta_n=1000:123.036,knn_ttm_n=1000:129.8822,knn_tta_r_n=1000:122.8285,knn_ttm_r_n=1000:123.0458'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:142.4466,knn_ttm_n=100:151.4583,knn_tta_r_n=100:142.2526,knn_ttm_r_n=100:143.2632,knn_tta_n=500:140.6463,knn_ttm_n=500:145.6368,knn_tta_r_n=500:141.3074,knn_ttm_r_n=500:141.9359,knn_tta_n=1000:140.028,knn_ttm_n=1000:144.1373,knn_tta_r_n=1000:141.0689,knn_ttm_r_n=1000:141.6472'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_54'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:396.2995,knn_ttm_n=100:558.0814,knn_tta_r_n=100:254.384,knn_ttm_r_n=100:23769333.3718,knn_tta_n=500:249.276,knn_ttm_n=500:273.836,knn_tta_r_n=500:248.4355,knn_ttm_r_n=500:1897.5731,knn_tta_n=1000:252.4653,knn_ttm_n=1000:273.0348,knn_tta_r_n=1000:254.2219,knn_ttm_r_n=1000:254.7912'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:128506349.2331,knn_ttm_n=100:518189765.8877,knn_tta_r_n=100:202811090.4642,knn_ttm_r_n=100:262489080.9235,knn_tta_n=500:355.0845,knn_ttm_n=500:533.6998,knn_tta_r_n=500:316.5764,knn_ttm_r_n=500:316.4149,knn_tta_n=1000:318.4159,knn_ttm_n=1000:422.1568,knn_tta_r_n=1000:305.7998,knn_ttm_r_n=1000:303.5252'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:564.3762,knn_ttm_n=100:1089.8194,knn_tta_r_n=100:400.8892,knn_ttm_r_n=100:421.5,knn_tta_n=500:361.655,knn_ttm_n=500:449.4385,knn_tta_r_n=500:363.6373,knn_ttm_r_n=500:365.8015,knn_tta_n=1000:370.1533,knn_ttm_n=1000:447.7901,knn_tta_r_n=1000:371.5452,knn_ttm_r_n=1000:373.3739'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:3803288017.5204,knn_ttm_n=100:2380425990.0133,knn_tta_r_n=100:114087471.8876,knn_ttm_r_n=100:1533982545.2494,knn_tta_n=500:432.0432,knn_ttm_n=500:549.2977,knn_tta_r_n=500:416.3992,knn_ttm_r_n=500:424.3609,knn_tta_n=1000:428.6157,knn_ttm_n=1000:511.8785,knn_tta_r_n=1000:423.0359,knn_ttm_r_n=1000:423.8077'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:525.26,knn_ttm_n=100:968.9219,knn_tta_r_n=100:381.6955,knn_ttm_r_n=100:387.2102,knn_tta_n=500:352.768,knn_ttm_n=500:436.7287,knn_tta_r_n=500:349.9976,knn_ttm_r_n=500:352.2146,knn_tta_n=1000:356.3466,knn_ttm_n=1000:430.6764,knn_tta_r_n=1000:357.1385,knn_ttm_r_n=1000:357.9529'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:198485482002.2982,knn_ttm_n=100:280532490455.9886,knn_tta_r_n=100:15149370595.6988,knn_ttm_r_n=100:15970944167.5439,knn_tta_n=500:321914.4576,knn_ttm_n=500:926949.049,knn_tta_r_n=500:7753.6563,knn_ttm_r_n=500:93018.6939,knn_tta_n=1000:383.2548,knn_ttm_n=1000:449.3572,knn_tta_r_n=1000:384.1541,knn_ttm_r_n=1000:389.9035'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:286.9105,knn_ttm_n=100:492.9969,knn_tta_r_n=100:201.7422,knn_ttm_r_n=100:28618796235.8148,knn_tta_n=500:199.5802,knn_ttm_n=500:219.0651,knn_tta_r_n=500:195.1221,knn_ttm_r_n=500:212.9076,knn_tta_n=1000:194.9527,knn_ttm_n=1000:203.875,knn_tta_r_n=1000:196.1019,knn_ttm_r_n=1000:195.6125'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:866942580176.6171,knn_ttm_n=100:357749858040.8208,knn_tta_r_n=100:36129427080.8676,knn_ttm_r_n=100:62598984720.6077,knn_tta_n=500:493611782.3999,knn_ttm_n=500:177060358.7469,knn_tta_r_n=500:116505401.5188,knn_ttm_r_n=500:60042453.584,knn_tta_n=1000:212.9926,knn_ttm_n=1000:321.4136,knn_tta_r_n=1000:203.6765,knn_ttm_r_n=1000:218.6711'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:285.8608,knn_ttm_n=100:591.2654,knn_tta_r_n=100:224.7155,knn_ttm_r_n=100:24086555.1039,knn_tta_n=500:205.891,knn_ttm_n=500:236.0454,knn_tta_r_n=500:204.1689,knn_ttm_r_n=500:205.8708,knn_tta_n=1000:206.0783,knn_ttm_n=1000:217.4668,knn_tta_r_n=1000:207.2248,knn_ttm_r_n=1000:207.2806'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:1332239451.9103,knn_ttm_n=100:14061274970.2643,knn_tta_r_n=100:287827397.419,knn_ttm_r_n=100:899453110.79,knn_tta_n=500:3264.8914,knn_ttm_n=500:5068.0564,knn_tta_r_n=500:1863.0624,knn_ttm_r_n=500:1715.8513,knn_tta_n=1000:2757.2291,knn_ttm_n=1000:4686.3007,knn_tta_r_n=1000:1838.6997,knn_ttm_r_n=1000:1737.7014'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:219.2651,knn_ttm_n=100:366.7503,knn_tta_r_n=100:154.7687,knn_ttm_r_n=100:272387.1237,knn_tta_n=500:141.8715,knn_ttm_n=500:159.0157,knn_tta_r_n=500:139.0188,knn_ttm_r_n=500:138.8109,knn_tta_n=1000:139.6427,knn_ttm_n=1000:152.1134,knn_tta_r_n=1000:139.2445,knn_ttm_r_n=1000:139.1154'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1316902151.7217,knn_ttm_n=100:504041322.7308,knn_tta_r_n=100:117381976.2759,knn_ttm_r_n=100:132257969.6986,knn_tta_n=500:12813493.1208,knn_ttm_n=500:21002970.0802,knn_tta_r_n=500:6774533.5577,knn_ttm_r_n=500:1066045.0996,knn_tta_n=1000:6339836.5765,knn_ttm_n=1000:5566269.9215,knn_tta_r_n=1000:153.2055,knn_ttm_r_n=1000:1069203.9726'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_57'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:227.2763,knn_ttm_n=100:212.149,knn_tta_r_n=100:145.286,knn_ttm_r_n=100:902.0256,knn_tta_n=500:247.4974,knn_ttm_n=500:291.0668,knn_tta_r_n=500:218.5908,knn_ttm_r_n=500:199.4818,knn_tta_n=1000:296.5695,knn_ttm_n=1000:373.6415,knn_tta_r_n=1000:238.9464,knn_ttm_r_n=1000:228.0204'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:2894538.4187,knn_ttm_n=100:4535024.3453,knn_tta_r_n=100:1601758.6561,knn_ttm_r_n=100:1160878.891,knn_tta_n=500:436.7776,knn_ttm_n=500:499.5798,knn_tta_r_n=500:258.2355,knn_ttm_r_n=500:247.892,knn_tta_n=1000:348.0028,knn_ttm_n=1000:377.3691,knn_tta_r_n=1000:288.1555,knn_ttm_r_n=1000:269.4977'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:244.7456,knn_ttm_n=100:337.3497,knn_tta_r_n=100:217.2195,knn_ttm_r_n=100:3611.4737,knn_tta_n=500:416.201,knn_ttm_n=500:463.603,knn_tta_r_n=500:322.2232,knn_ttm_r_n=500:813.9904,knn_tta_n=1000:392.2606,knn_ttm_n=1000:405.449,knn_tta_r_n=1000:368.6173,knn_ttm_r_n=1000:373.4893'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:12569663.6512,knn_ttm_n=100:15115057.4355,knn_tta_r_n=100:6199466.8855,knn_ttm_r_n=100:90712.894,knn_tta_n=500:2973165.7543,knn_ttm_n=500:36960.9916,knn_tta_r_n=500:1860406.3446,knn_ttm_r_n=500:1418683.6257,knn_tta_n=1000:1637055.7404,knn_ttm_n=1000:2047277.0813,knn_tta_r_n=1000:428900.2349,knn_ttm_r_n=1000:1685507.8486'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:261.2503,knn_ttm_n=100:267.349,knn_tta_r_n=100:222.8445,knn_ttm_r_n=100:185.3641,knn_tta_n=500:366.8049,knn_ttm_n=500:358.8435,knn_tta_r_n=500:307.4022,knn_ttm_r_n=500:293.0172,knn_tta_n=1000:422.2626,knn_ttm_n=1000:413.3753,knn_tta_r_n=1000:403.2218,knn_ttm_r_n=1000:414.4501'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1669170.8365,knn_ttm_n=100:1593438.2109,knn_tta_r_n=100:333471.2831,knn_ttm_r_n=100:11947602.4961,knn_tta_n=500:31735.6315,knn_ttm_n=500:867.1547,knn_tta_r_n=500:3321.863,knn_ttm_r_n=500:13646.2553,knn_tta_n=1000:5614.2124,knn_ttm_n=1000:11190.402,knn_tta_r_n=1000:1082.1831,knn_ttm_r_n=1000:1660.9265'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:165.7496,knn_ttm_n=100:229.2046,knn_tta_r_n=100:140.3306,knn_ttm_r_n=100:136.5008,knn_tta_n=500:219.0845,knn_ttm_n=500:262.3394,knn_tta_r_n=500:196.5094,knn_ttm_r_n=500:177.0403,knn_tta_n=1000:226.2338,knn_ttm_n=1000:249.2559,knn_tta_r_n=1000:195.5184,knn_ttm_r_n=1000:185.0921'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:390076.955,knn_ttm_n=100:13718995.5094,knn_tta_r_n=100:4946569.422,knn_ttm_r_n=100:10488552.5468,knn_tta_n=500:1505334.2716,knn_ttm_n=500:5941023.0359,knn_tta_r_n=500:650523.5146,knn_ttm_r_n=500:1514748.2223,knn_tta_n=1000:325080.0009,knn_ttm_n=1000:242112.0678,knn_tta_r_n=1000:91230.6205,knn_ttm_r_n=1000:59146.6757'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:161.0742,knn_ttm_n=100:211.0834,knn_tta_r_n=100:137.5416,knn_ttm_r_n=100:122.9573,knn_tta_n=500:208.0511,knn_ttm_n=500:271.9122,knn_tta_r_n=500:188.7991,knn_ttm_r_n=500:174.0323,knn_tta_n=1000:215.7309,knn_ttm_n=1000:264.5461,knn_tta_r_n=1000:199.5696,knn_ttm_r_n=1000:188.591'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:423.6069,knn_ttm_n=100:784.4562,knn_tta_r_n=100:293.3785,knn_ttm_r_n=100:300.0551,knn_tta_n=500:253.6345,knn_ttm_n=500:370.5776,knn_tta_r_n=500:216.8897,knn_ttm_r_n=500:210.9728,knn_tta_n=1000:237.8789,knn_ttm_n=1000:327.2977,knn_tta_r_n=1000:203.8917,knn_ttm_r_n=1000:202.0092'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:124.239,knn_ttm_n=100:141.5231,knn_tta_r_n=100:100.1028,knn_ttm_r_n=100:88.0494,knn_tta_n=500:143.4509,knn_ttm_n=500:175.5873,knn_tta_r_n=500:134.8141,knn_ttm_r_n=500:126.3672,knn_tta_n=1000:142.6699,knn_ttm_n=1000:159.1995,knn_tta_r_n=1000:137.6735,knn_ttm_r_n=1000:131.7371'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:80602.9487,knn_ttm_n=100:29933.5468,knn_tta_r_n=100:5268.1526,knn_ttm_r_n=100:195086.4051,knn_tta_n=500:1522.4418,knn_ttm_n=500:3350.9015,knn_tta_r_n=500:708.2877,knn_ttm_r_n=500:395.4162,knn_tta_n=1000:205.1145,knn_ttm_n=1000:303.3761,knn_tta_r_n=1000:160.3347,knn_ttm_r_n=1000:166.1541'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_71'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:181.4653,knn_ttm_n=100:159.1421,knn_tta_r_n=100:194.6336,knn_ttm_r_n=100:177.2383,knn_tta_n=500:218.5805,knn_ttm_n=500:225.0958,knn_tta_r_n=500:229.0634,knn_ttm_r_n=500:219.0558,knn_tta_n=1000:232.3504,knn_ttm_n=1000:243.45,knn_tta_r_n=1000:241.0553,knn_ttm_r_n=1000:233.3665'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:300.1763,knn_ttm_n=100:1139.704,knn_tta_r_n=100:271.3467,knn_ttm_r_n=100:1053.9784,knn_tta_n=500:264.686,knn_ttm_n=500:293.8603,knn_tta_r_n=500:262.0203,knn_ttm_r_n=500:262.1209,knn_tta_n=1000:269.8846,knn_ttm_n=1000:295.7251,knn_tta_r_n=1000:269.609,knn_ttm_r_n=1000:266.3592'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:230.5143,knn_ttm_n=100:202.2807,knn_tta_r_n=100:218.1367,knn_ttm_r_n=100:198.6516,knn_tta_n=500:275.1921,knn_ttm_n=500:258.3165,knn_tta_r_n=500:247.2781,knn_ttm_r_n=500:237.2217,knn_tta_n=1000:259.5895,knn_ttm_n=1000:323.179,knn_tta_r_n=1000:260.3511,knn_ttm_r_n=1000:254.7999'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:309.1418,knn_ttm_n=100:325.2383,knn_tta_r_n=100:273.5061,knn_ttm_r_n=100:290.8871,knn_tta_n=500:309.207,knn_ttm_n=500:309.6983,knn_tta_r_n=500:270.7938,knn_ttm_r_n=500:275.0352,knn_tta_n=1000:279.4019,knn_ttm_n=1000:356.2782,knn_tta_r_n=1000:279.0735,knn_ttm_r_n=1000:279.2235'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:326.8074,knn_ttm_n=100:255.106,knn_tta_r_n=100:264.5619,knn_ttm_r_n=100:243.8803,knn_tta_n=500:365.4097,knn_ttm_n=500:308.1523,knn_tta_r_n=500:286.477,knn_ttm_r_n=500:277.9424,knn_tta_n=1000:299.8773,knn_ttm_n=1000:407.3108,knn_tta_r_n=1000:300.4675,knn_ttm_r_n=1000:293.6938'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:413.2971,knn_ttm_n=100:385.0925,knn_tta_r_n=100:336.5887,knn_ttm_r_n=100:336.4843,knn_tta_n=500:414.0301,knn_ttm_n=500:372.2406,knn_tta_r_n=500:328.4568,knn_ttm_r_n=500:329.6404,knn_tta_n=1000:339.5741,knn_ttm_n=1000:447.8374,knn_tta_r_n=1000:335.483,knn_ttm_r_n=1000:335.1911'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:142.9123,knn_ttm_n=100:128.3218,knn_tta_r_n=100:153.4639,knn_ttm_r_n=100:137.1578,knn_tta_n=500:173.9764,knn_ttm_n=500:177.5803,knn_tta_r_n=500:177.1,knn_ttm_r_n=500:169.9929,knn_tta_n=1000:179.915,knn_ttm_n=1000:188.5716,knn_tta_r_n=1000:182.0969,knn_ttm_r_n=1000:177.279'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:210.9116,knn_ttm_n=100:256.5624,knn_tta_r_n=100:191.2316,knn_ttm_r_n=100:200.0371,knn_tta_n=500:186.5671,knn_ttm_n=500:206.1163,knn_tta_r_n=500:184.6354,knn_ttm_r_n=500:185.0187,knn_tta_n=1000:186.5567,knn_ttm_n=1000:202.3083,knn_tta_r_n=1000:185.8998,knn_ttm_r_n=1000:185.3776'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:146.5581,knn_ttm_n=100:131.6944,knn_tta_r_n=100:156.5326,knn_ttm_r_n=100:138.7869,knn_tta_n=500:177.8595,knn_ttm_n=500:180.5269,knn_tta_r_n=500:183.7733,knn_ttm_r_n=500:175.3861,knn_tta_n=1000:186.0638,knn_ttm_n=1000:191.1624,knn_tta_r_n=1000:191.2588,knn_ttm_r_n=1000:184.6476'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:210.9218,knn_ttm_n=100:312.4554,knn_tta_r_n=100:432.7544,knn_ttm_r_n=100:486.4383,knn_tta_n=500:185.9265,knn_ttm_n=500:205.4833,knn_tta_r_n=500:185.424,knn_ttm_r_n=500:184.2577,knn_tta_n=1000:187.454,knn_ttm_n=1000:202.8486,knn_tta_r_n=1000:188.3514,knn_ttm_r_n=1000:186.2489'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:98.4059,knn_ttm_n=100:86.03,knn_tta_r_n=100:102.8762,knn_ttm_r_n=100:91.9943,knn_tta_n=500:113.3228,knn_ttm_n=500:115.0105,knn_tta_r_n=500:115.414,knn_ttm_r_n=500:111.2212,knn_tta_n=1000:116.1802,knn_ttm_n=1000:120.9955,knn_tta_r_n=1000:117.497,knn_ttm_r_n=1000:115.1736'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:158.8967,knn_ttm_n=100:183.2208,knn_tta_r_n=100:140.9989,knn_ttm_r_n=100:144.0294,knn_tta_n=500:141.5146,knn_ttm_n=500:155.118,knn_tta_r_n=500:139.0268,knn_ttm_r_n=500:139.6678,knn_tta_n=1000:140.8935,knn_ttm_n=1000:149.8889,knn_tta_r_n=1000:140.0925,knn_ttm_r_n=1000:139.8282'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_73'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:99.9885,knn_ttm_n=100:82.8572,knn_tta_r_n=100:116.2095,knn_ttm_r_n=100:94.9633,knn_tta_n=500:183.0945,knn_ttm_n=500:188.3857,knn_tta_r_n=500:190.2859,knn_ttm_r_n=500:176.535,knn_tta_n=1000:203.6531,knn_ttm_n=1000:220.2192,knn_tta_r_n=1000:208.2865,knn_ttm_r_n=1000:202.3761'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:508.936,knn_ttm_n=100:628.0877,knn_tta_r_n=100:330.9703,knn_ttm_r_n=100:342.5767,knn_tta_n=500:270.4439,knn_ttm_n=500:307.2008,knn_tta_r_n=500:248.4235,knn_ttm_r_n=500:255.3264,knn_tta_n=1000:251.7291,knn_ttm_n=1000:283.7052,knn_tta_r_n=1000:246.4116,knn_ttm_r_n=1000:247.4561'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:109.4965,knn_ttm_n=100:107.1328,knn_tta_r_n=100:133.5148,knn_ttm_r_n=100:102.154,knn_tta_n=500:203.5332,knn_ttm_n=500:241.9517,knn_tta_r_n=500:213.173,knn_ttm_r_n=500:197.7381,knn_tta_n=1000:228.476,knn_ttm_n=1000:281.2817,knn_tta_r_n=1000:233.8169,knn_ttm_r_n=1000:227.2937'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:391733.8307,knn_ttm_n=100:966748.5485,knn_tta_r_n=100:107030.6602,knn_ttm_r_n=100:299576.8779,knn_tta_n=500:433.0009,knn_ttm_n=500:461.8969,knn_tta_r_n=500:353.1081,knn_ttm_r_n=500:350.9333,knn_tta_n=1000:426.1333,knn_ttm_n=1000:471.2132,knn_tta_r_n=1000:360.1545,knn_ttm_r_n=1000:358.9155'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:115.6304,knn_ttm_n=100:113.0166,knn_tta_r_n=100:136.1936,knn_ttm_r_n=100:103.8802,knn_tta_n=500:207.4458,knn_ttm_n=500:240.6325,knn_tta_r_n=500:217.1631,knn_ttm_r_n=500:202.3473,knn_tta_n=1000:232.3131,knn_ttm_n=1000:277.1531,knn_tta_r_n=1000:238.6438,knn_ttm_r_n=1000:231.0886'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:20073.164,knn_ttm_n=100:650.2355,knn_tta_r_n=100:3117.6247,knn_ttm_r_n=100:65207.3279,knn_tta_n=500:295.395,knn_ttm_n=500:348.7584,knn_tta_r_n=500:279.2536,knn_ttm_r_n=500:280.7658,knn_tta_n=1000:288.1164,knn_ttm_n=1000:338.8832,knn_tta_r_n=1000:280.213,knn_ttm_r_n=1000:280.7613'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:90.6196,knn_ttm_n=100:76.9896,knn_tta_r_n=100:106.9803,knn_ttm_r_n=100:83.6316,knn_tta_n=500:157.4079,knn_ttm_n=500:159.8106,knn_tta_r_n=500:165.0892,knn_ttm_r_n=500:154.8361,knn_tta_n=1000:173.3457,knn_ttm_n=1000:181.1202,knn_tta_r_n=1000:177.4248,knn_ttm_r_n=1000:172.3072'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:285.8161,knn_ttm_n=100:28692.8015,knn_tta_r_n=100:214.2451,knn_ttm_r_n=100:231.8631,knn_tta_n=500:209.9511,knn_ttm_n=500:237.5976,knn_tta_r_n=500:194.5787,knn_ttm_r_n=500:189.2476,knn_tta_n=1000:3466.8516,knn_ttm_n=1000:6252.7386,knn_tta_r_n=1000:276.1273,knn_ttm_r_n=1000:187.7979'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:89.1266,knn_ttm_n=100:79.8925,knn_tta_r_n=100:107.6431,knn_ttm_r_n=100:87.946,knn_tta_n=500:160.0873,knn_ttm_n=500:165.1045,knn_tta_r_n=500:168.8255,knn_ttm_r_n=500:157.7413,knn_tta_n=1000:177.1547,knn_ttm_n=1000:193.3865,knn_tta_r_n=1000:182.0902,knn_ttm_r_n=1000:175.9855'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:407.9022,knn_ttm_n=100:495.8946,knn_tta_r_n=100:276.8637,knn_ttm_r_n=100:261.4491,knn_tta_n=500:194680.8217,knn_ttm_n=500:285411.2451,knn_tta_r_n=500:82871.2394,knn_ttm_r_n=500:96145.3351,knn_tta_n=1000:207.2552,knn_ttm_n=1000:245.0357,knn_tta_r_n=1000:198.6486,knn_ttm_r_n=1000:198.7837'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:60.8897,knn_ttm_n=100:48.8809,knn_tta_r_n=100:70.404,knn_ttm_r_n=100:56.9443,knn_tta_n=500:100.1416,knn_ttm_n=500:95.9877,knn_tta_r_n=500:104.6669,knn_ttm_r_n=500:97.3674,knn_tta_n=1000:108.3582,knn_ttm_n=1000:108.6093,knn_tta_r_n=1000:110.5228,knn_ttm_r_n=1000:107.1534'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:244.7147,knn_ttm_n=100:300.263,knn_tta_r_n=100:184.5011,knn_ttm_r_n=100:202.1913,knn_tta_n=500:158.4276,knn_ttm_n=500:181.4377,knn_tta_r_n=500:142.7332,knn_ttm_r_n=500:140.1682,knn_tta_n=1000:145.2548,knn_ttm_n=1000:159.0023,knn_tta_r_n=1000:138.1566,knn_ttm_r_n=1000:136.436'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_74'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:120.5988,knn_ttm_n=100:113.1024,knn_tta_r_n=100:135.1086,knn_ttm_r_n=100:137.9645,knn_tta_n=500:183.8137,knn_ttm_n=500:191.0834,knn_tta_r_n=500:191.1908,knn_ttm_r_n=500:196.5195,knn_tta_n=1000:199.3644,knn_ttm_n=1000:211.8954,knn_tta_r_n=1000:204.7046,knn_ttm_r_n=1000:201.2486'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:319.4578,knn_ttm_n=100:457.2342,knn_tta_r_n=100:277.4381,knn_ttm_r_n=100:372.5107,knn_tta_n=500:230.1355,knn_ttm_n=500:262.6251,knn_tta_r_n=500:222.033,knn_ttm_r_n=500:225.2397,knn_tta_n=1000:228.0577,knn_ttm_n=1000:257.0719,knn_tta_r_n=1000:227.6117,knn_ttm_r_n=1000:227.4133'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:156.0572,knn_ttm_n=100:158.0699,knn_tta_r_n=100:173.9242,knn_ttm_r_n=100:161.2664,knn_tta_n=500:234.237,knn_ttm_n=500:256.4004,knn_tta_r_n=500:243.2317,knn_ttm_r_n=500:237.7138,knn_tta_n=1000:250.05,knn_ttm_n=1000:279.6926,knn_tta_r_n=1000:257.3679,knn_ttm_r_n=1000:256.0901'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:147422.0298,knn_ttm_n=100:265273.9451,knn_tta_r_n=100:161538.7178,knn_ttm_r_n=100:146687.5561,knn_tta_n=500:35169.9319,knn_ttm_n=500:87874.0073,knn_tta_r_n=500:2477.8746,knn_ttm_r_n=500:24059.4723,knn_tta_n=1000:14579.9867,knn_ttm_n=1000:68365.8792,knn_tta_r_n=1000:294.5679,knn_ttm_r_n=1000:13981.1121'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:143.4212,knn_ttm_n=100:143.1718,knn_tta_r_n=100:157.9162,knn_ttm_r_n=100:1530.8606,knn_tta_n=500:216.1378,knn_ttm_n=500:240.0141,knn_tta_r_n=500:226.278,knn_ttm_r_n=500:224.9945,knn_tta_n=1000:234.9184,knn_ttm_n=1000:261.999,knn_tta_r_n=1000:244.8048,knn_ttm_r_n=1000:256.6964'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:522.6456,knn_ttm_n=100:500.3016,knn_tta_r_n=100:342.7084,knn_ttm_r_n=100:5600.6451,knn_tta_n=500:286.6656,knn_ttm_n=500:329.6437,knn_tta_r_n=500:291.8452,knn_ttm_r_n=500:291.9709,knn_tta_n=1000:299.2666,knn_ttm_n=1000:316.6304,knn_tta_r_n=1000:323.2967,knn_ttm_r_n=1000:299.2314'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:112.6625,knn_ttm_n=100:99.0628,knn_tta_r_n=100:127.7858,knn_ttm_r_n=100:117.2921,knn_tta_n=500:168.8899,knn_ttm_n=500:168.7569,knn_tta_r_n=500:176.5878,knn_ttm_r_n=500:170.521,knn_tta_n=1000:180.124,knn_ttm_n=1000:186.7621,knn_tta_r_n=1000:184.9272,knn_ttm_r_n=1000:182.0972'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:226.7656,knn_ttm_n=100:319.5237,knn_tta_r_n=100:188.859,knn_ttm_r_n=100:205.9038,knn_tta_n=500:178.6292,knn_ttm_n=500:203.5458,knn_tta_r_n=500:176.6324,knn_ttm_r_n=500:179.5355,knn_tta_n=1000:180.8967,knn_ttm_n=1000:195.889,knn_tta_r_n=1000:182.1519,knn_ttm_r_n=1000:183.8379'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:114.8595,knn_ttm_n=100:104.4257,knn_tta_r_n=100:128.6145,knn_ttm_r_n=100:250.0579,knn_tta_n=500:167.8841,knn_ttm_n=500:174.4513,knn_tta_r_n=500:174.3874,knn_ttm_r_n=500:167.663,knn_tta_n=1000:180.0803,knn_ttm_n=1000:189.0728,knn_tta_r_n=1000:184.8731,knn_ttm_r_n=1000:179.3194'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:265.5661,knn_ttm_n=100:348.1934,knn_tta_r_n=100:205.8635,knn_ttm_r_n=100:215.6991,knn_tta_n=500:201.0354,knn_ttm_n=500:235.0728,knn_tta_r_n=500:190.8718,knn_ttm_r_n=500:192.4143,knn_tta_n=1000:196.1256,knn_ttm_n=1000:223.4722,knn_tta_r_n=1000:191.2149,knn_ttm_r_n=1000:189.6563'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:81.5025,knn_ttm_n=100:72.5706,knn_tta_r_n=100:90.097,knn_ttm_r_n=100:79.1517,knn_tta_n=500:115.1076,knn_ttm_n=500:116.4058,knn_tta_r_n=500:118.8606,knn_ttm_r_n=500:114.1327,knn_tta_n=1000:121.3818,knn_ttm_n=1000:124.1648,knn_tta_r_n=1000:123.5123,knn_ttm_r_n=1000:120.4768'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:3796.7935,knn_ttm_n=100:1892.2589,knn_tta_r_n=100:1426.8889,knn_ttm_r_n=100:1515.8275,knn_tta_n=500:292.3982,knn_ttm_n=500:1341.0097,knn_tta_r_n=500:145.2039,knn_ttm_r_n=500:150.845,knn_tta_n=1000:147.1596,knn_ttm_n=1000:243.924,knn_tta_r_n=1000:144.3016,knn_ttm_r_n=1000:148.6583'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_75'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:133.3673,knn_ttm_n=100:105.1808,knn_tta_r_n=100:153.054,knn_ttm_r_n=100:131.1846,knn_tta_n=500:202.6021,knn_ttm_n=500:198.6864,knn_tta_r_n=500:215.3381,knn_ttm_r_n=500:201.8935,knn_tta_n=1000:221.8512,knn_ttm_n=1000:227.4901,knn_tta_r_n=1000:232.4949,knn_ttm_r_n=1000:221.3672'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:293.0261,knn_ttm_n=100:355.6661,knn_tta_r_n=100:245.8741,knn_ttm_r_n=100:248.8129,knn_tta_n=500:254.8186,knn_ttm_n=500:278.6458,knn_tta_r_n=500:243.6875,knn_ttm_r_n=500:241.9608,knn_tta_n=1000:251.5635,knn_ttm_n=1000:279.6348,knn_tta_r_n=1000:250.4995,knn_ttm_r_n=1000:247.6124'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:149.2735,knn_ttm_n=100:134.8136,knn_tta_r_n=100:174.7666,knn_ttm_r_n=100:146.9908,knn_tta_n=500:230.4643,knn_ttm_n=500:252.1368,knn_tta_r_n=500:241.8159,knn_ttm_r_n=500:226.6761,knn_tta_n=1000:250.7176,knn_ttm_n=1000:283.7772,knn_tta_r_n=1000:260.0669,knn_ttm_r_n=1000:248.9109'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:326.3793,knn_ttm_n=100:395.2671,knn_tta_r_n=100:296.8244,knn_ttm_r_n=100:322.4595,knn_tta_n=500:281.6531,knn_ttm_n=500:332.0452,knn_tta_r_n=500:272.898,knn_ttm_r_n=500:282.9478,knn_tta_n=1000:285.3383,knn_ttm_n=1000:335.9743,knn_tta_r_n=1000:279.2715,knn_ttm_r_n=1000:279.6244'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:153.4692,knn_ttm_n=100:138.4661,knn_tta_r_n=100:173.2095,knn_ttm_r_n=100:144.7265,knn_tta_n=500:228.7036,knn_ttm_n=500:247.3793,knn_tta_r_n=500:239.4134,knn_ttm_r_n=500:222.3303,knn_tta_n=1000:252.4656,knn_ttm_n=1000:279.8847,knn_tta_r_n=1000:260.4757,knn_ttm_r_n=1000:245.6228'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:292.1731,knn_ttm_n=100:340.2141,knn_tta_r_n=100:268.2553,knn_ttm_r_n=100:276.5536,knn_tta_n=500:264.3314,knn_ttm_n=500:301.6334,knn_tta_r_n=500:265.6148,knn_ttm_r_n=500:267.6673,knn_tta_n=1000:269.2166,knn_ttm_n=1000:299.9988,knn_tta_r_n=1000:271.2604,knn_ttm_r_n=1000:269.7791'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:114.737,knn_ttm_n=100:94.6144,knn_tta_r_n=100:131.33,knn_ttm_r_n=100:111.8597,knn_tta_n=500:163.3233,knn_ttm_n=500:165.7073,knn_tta_r_n=500:170.9722,knn_ttm_r_n=500:162.218,knn_tta_n=1000:173.7617,knn_ttm_n=1000:180.3419,knn_tta_r_n=1000:179.2196,knn_ttm_r_n=1000:174.0221'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:221.3372,knn_ttm_n=100:286.0534,knn_tta_r_n=100:187.131,knn_ttm_r_n=100:193.9741,knn_tta_n=500:185.4307,knn_ttm_n=500:210.6993,knn_tta_r_n=500:184.2862,knn_ttm_r_n=500:182.7864,knn_tta_n=1000:187.8351,knn_ttm_n=1000:205.4095,knn_tta_r_n=1000:187.6874,knn_ttm_r_n=1000:185.7651'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:121.1339,knn_ttm_n=100:101.3688,knn_tta_r_n=100:140.0021,knn_ttm_r_n=100:117.2762,knn_tta_n=500:180.6542,knn_ttm_n=500:181.6193,knn_tta_r_n=500:190.6651,knn_ttm_r_n=500:179.1708,knn_tta_n=1000:194.4803,knn_ttm_n=1000:203.0234,knn_tta_r_n=1000:201.4242,knn_ttm_r_n=1000:193.5921'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:249.5643,knn_ttm_n=100:317.4563,knn_tta_r_n=100:204.7828,knn_ttm_r_n=100:208.6367,knn_tta_n=500:203.2464,knn_ttm_n=500:242.7056,knn_tta_r_n=500:192.955,knn_ttm_r_n=500:194.3891,knn_tta_n=1000:198.1595,knn_ttm_n=1000:229.6841,knn_tta_r_n=1000:194.2135,knn_ttm_r_n=1000:192.6775'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:77.6448,knn_ttm_n=100:65.3326,knn_tta_r_n=100:86.9141,knn_ttm_r_n=100:72.5237,knn_tta_n=500:108.2981,knn_ttm_n=500:109.7554,knn_tta_r_n=500:111.5423,knn_ttm_r_n=500:105.4449,knn_tta_n=1000:113.4544,knn_ttm_n=1000:120.416,knn_tta_r_n=1000:114.8991,knn_ttm_r_n=1000:111.7489'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:187.1236,knn_ttm_n=100:249.4537,knn_tta_r_n=100:147.9068,knn_ttm_r_n=100:155.4771,knn_tta_n=500:143.9582,knn_ttm_n=500:165.0042,knn_tta_r_n=500:138.5649,knn_ttm_r_n=500:139.2864,knn_tta_n=1000:139.0162,knn_ttm_n=1000:154.4644,knn_tta_r_n=1000:137.5536,knn_ttm_r_n=1000:138.2017'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_77'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:106.1026,knn_ttm_n=100:87.4209,knn_tta_r_n=100:120.2677,knn_ttm_r_n=100:98.8091,knn_tta_n=500:176.4026,knn_ttm_n=500:181.9133,knn_tta_r_n=500:179.3285,knn_ttm_r_n=500:168.3872,knn_tta_n=1000:192.2165,knn_ttm_n=1000:206.4332,knn_tta_r_n=1000:193.6495,knn_ttm_r_n=1000:187.3013'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:332.2067,knn_ttm_n=100:423.7463,knn_tta_r_n=100:264.0136,knn_ttm_r_n=100:299.4413,knn_tta_n=500:236.4876,knn_ttm_n=500:262.2427,knn_tta_r_n=500:227.4981,knn_ttm_r_n=500:225.493,knn_tta_n=1000:235.803,knn_ttm_n=1000:262.2926,knn_tta_r_n=1000:229.9557,knn_ttm_r_n=1000:229.6633'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:115.828,knn_ttm_n=100:102.6289,knn_tta_r_n=100:134.5534,knn_ttm_r_n=100:107.5456,knn_tta_n=500:200.4352,knn_ttm_n=500:214.8356,knn_tta_r_n=500:210.7469,knn_ttm_r_n=500:197.6336,knn_tta_n=1000:227.2194,knn_ttm_n=1000:252.9736,knn_tta_r_n=1000:232.9942,knn_ttm_r_n=1000:225.8952'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:430.4445,knn_ttm_n=100:445.5726,knn_tta_r_n=100:376.4207,knn_ttm_r_n=100:485.197,knn_tta_n=500:580.3315,knn_ttm_n=500:906.3828,knn_tta_r_n=500:358.2463,knn_ttm_r_n=500:356.078,knn_tta_n=1000:400.7601,knn_ttm_n=1000:592.4669,knn_tta_r_n=1000:295.1057,knn_ttm_r_n=1000:302.1056'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:122.1876,knn_ttm_n=100:105.4127,knn_tta_r_n=100:136.1409,knn_ttm_r_n=100:109.1413,knn_tta_n=500:201.6158,knn_ttm_n=500:211.8197,knn_tta_r_n=500:210.2307,knn_ttm_r_n=500:198.4218,knn_tta_n=1000:225.3931,knn_ttm_n=1000:247.6197,knn_tta_r_n=1000:233.456,knn_ttm_r_n=1000:227.0366'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:286.6899,knn_ttm_n=100:326.9383,knn_tta_r_n=100:252.3952,knn_ttm_r_n=100:286.4949,knn_tta_n=500:263.1484,knn_ttm_n=500:292.1201,knn_tta_r_n=500:254.64,knn_ttm_r_n=500:252.3634,knn_tta_n=1000:273.4404,knn_ttm_n=1000:310.3989,knn_tta_r_n=1000:266.7229,knn_ttm_r_n=1000:263.7031'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:103.742,knn_ttm_n=100:83.3835,knn_tta_r_n=100:120.3729,knn_ttm_r_n=100:176.3414,knn_tta_n=500:163.31,knn_ttm_n=500:164.0474,knn_tta_r_n=500:170.6906,knn_ttm_r_n=500:159.6278,knn_tta_n=1000:177.2611,knn_ttm_n=1000:183.7366,knn_tta_r_n=1000:181.7635,knn_ttm_r_n=1000:175.7745'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:353.8379,knn_ttm_n=100:294.9994,knn_tta_r_n=100:281.9419,knn_ttm_r_n=100:304.1958,knn_tta_n=500:187.345,knn_ttm_n=500:213.8997,knn_tta_r_n=500:177.7332,knn_ttm_r_n=500:179.1004,knn_tta_n=1000:178.9289,knn_ttm_n=1000:197.8466,knn_tta_r_n=1000:177.0884,knn_ttm_r_n=1000:177.2335'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:105.9105,knn_ttm_n=100:89.0339,knn_tta_r_n=100:120.9308,knn_ttm_r_n=100:109.4285,knn_tta_n=500:175.0861,knn_ttm_n=500:185.5812,knn_tta_r_n=500:180.5351,knn_ttm_r_n=500:167.9158,knn_tta_n=1000:191.8003,knn_ttm_n=1000:209.2422,knn_tta_r_n=1000:194.7889,knn_ttm_r_n=1000:187.6696'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:761.1522,knn_ttm_n=100:1294.4141,knn_tta_r_n=100:424.2436,knn_ttm_r_n=100:328.301,knn_tta_n=500:255.2862,knn_ttm_n=500:352.8097,knn_tta_r_n=500:202.1286,knn_ttm_r_n=500:197.3706,knn_tta_n=1000:210.3452,knn_ttm_n=1000:246.9898,knn_tta_r_n=1000:199.9856,knn_ttm_r_n=1000:197.2787'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:78.095,knn_ttm_n=100:59.0063,knn_tta_r_n=100:89.6518,knn_ttm_r_n=100:70.8231,knn_tta_n=500:118.376,knn_ttm_n=500:113.0418,knn_tta_r_n=500:122.655,knn_ttm_r_n=500:115.4217,knn_tta_n=1000:125.6355,knn_ttm_n=1000:124.786,knn_tta_r_n=1000:128.9389,knn_ttm_r_n=1000:124.9018'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:581.0696,knn_ttm_n=100:2043.2975,knn_tta_r_n=100:1395.5891,knn_ttm_r_n=100:1077.8994,knn_tta_n=500:153.3407,knn_ttm_n=500:180.6707,knn_tta_r_n=500:142.1692,knn_ttm_r_n=500:143.7333,knn_tta_n=1000:147.1987,knn_ttm_n=1000:164.3816,knn_tta_r_n=1000:141.2736,knn_ttm_r_n=1000:141.928'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_78'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:146.6022,knn_ttm_n=100:129.3252,knn_tta_r_n=100:159.213,knn_ttm_r_n=100:216.8509,knn_tta_n=500:206.5101,knn_ttm_n=500:220.9052,knn_tta_r_n=500:209.8034,knn_ttm_r_n=500:204.5406,knn_tta_n=1000:221.1294,knn_ttm_n=1000:243.2057,knn_tta_r_n=1000:223.1227,knn_ttm_r_n=1000:220.8997'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:686.1702,knn_ttm_n=100:882.1532,knn_tta_r_n=100:428.3721,knn_ttm_r_n=100:501.266,knn_tta_n=500:255.5987,knn_ttm_n=500:286.7365,knn_tta_r_n=500:244.1108,knn_ttm_r_n=500:243.8415,knn_tta_n=1000:252.7562,knn_ttm_n=1000:278.8653,knn_tta_r_n=1000:249.987,knn_ttm_r_n=1000:249.333'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:182.5539,knn_ttm_n=100:198.2698,knn_tta_r_n=100:203.8913,knn_ttm_r_n=100:179.0182,knn_tta_n=500:282.9783,knn_ttm_n=500:359.2853,knn_tta_r_n=500:285.915,knn_ttm_r_n=500:279.9837,knn_tta_n=1000:311.8951,knn_ttm_n=1000:416.6372,knn_tta_r_n=1000:311.7176,knn_ttm_r_n=1000:310.2125'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:880.7387,knn_ttm_n=100:5930.1094,knn_tta_r_n=100:602.7646,knn_ttm_r_n=100:33595.5547,knn_tta_n=500:390.513,knn_ttm_n=500:464.1263,knn_tta_r_n=500:360.4,knn_ttm_r_n=500:346.671,knn_tta_n=1000:760.5505,knn_ttm_n=1000:992.8468,knn_tta_r_n=1000:481.6595,knn_ttm_r_n=1000:442.8707'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:190.042,knn_ttm_n=100:204.536,knn_tta_r_n=100:208.1863,knn_ttm_r_n=100:190.1056,knn_tta_n=500:282.7835,knn_ttm_n=500:342.6798,knn_tta_r_n=500:287.0588,knn_ttm_r_n=500:280.7347,knn_tta_n=1000:314.7267,knn_ttm_n=1000:394.9957,knn_tta_r_n=1000:317.0515,knn_ttm_r_n=1000:312.353'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:10124.3876,knn_ttm_n=100:11457.8872,knn_tta_r_n=100:5066.875,knn_ttm_r_n=100:5268.483,knn_tta_n=500:4767.8067,knn_ttm_n=500:7135.1821,knn_tta_r_n=500:2448.3965,knn_ttm_r_n=500:1879.905,knn_tta_n=1000:1469.8365,knn_ttm_n=1000:2396.2827,knn_tta_r_n=1000:957.8291,knn_ttm_r_n=1000:896.0635'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:132.5285,knn_ttm_n=100:118.3831,knn_tta_r_n=100:146.2906,knn_ttm_r_n=100:130.5019,knn_tta_n=500:187.5628,knn_ttm_n=500:189.6276,knn_tta_r_n=500:192.3965,knn_ttm_r_n=500:186.9023,knn_tta_n=1000:198.7691,knn_ttm_n=1000:207.421,knn_tta_r_n=1000:201.3464,knn_ttm_r_n=1000:199.2266'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:1984.7876,knn_ttm_n=100:4673.4485,knn_tta_r_n=100:355.5733,knn_ttm_r_n=100:692.6436,knn_tta_n=500:214.8459,knn_ttm_n=500:688.8182,knn_tta_r_n=500:208.2697,knn_ttm_r_n=500:215.7982,knn_tta_n=1000:219.739,knn_ttm_n=1000:227.07,knn_tta_r_n=1000:227.7283,knn_ttm_r_n=1000:218.3838'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:129.9579,knn_ttm_n=100:121.8071,knn_tta_r_n=100:141.6401,knn_ttm_r_n=100:139.2328,knn_tta_n=500:182.6097,knn_ttm_n=500:195.2605,knn_tta_r_n=500:185.8713,knn_ttm_r_n=500:182.392,knn_tta_n=1000:194.1824,knn_ttm_n=1000:212.0586,knn_tta_r_n=1000:195.1572,knn_ttm_r_n=1000:193.0151'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:716.2313,knn_ttm_n=100:332.9564,knn_tta_r_n=100:311.2786,knn_ttm_r_n=100:221.8032,knn_tta_n=500:445.7683,knn_ttm_n=500:767.7578,knn_tta_r_n=500:255.5612,knn_ttm_r_n=500:260.9077,knn_tta_n=1000:212.9334,knn_ttm_n=1000:252.6319,knn_tta_r_n=1000:203.773,knn_ttm_r_n=1000:203.3184'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:82.9891,knn_ttm_n=100:71.0688,knn_tta_r_n=100:89.7343,knn_ttm_r_n=100:78.7815,knn_tta_n=500:110.9503,knn_ttm_n=500:109.8188,knn_tta_r_n=500:113.5395,knn_ttm_r_n=500:110.3535,knn_tta_n=1000:115.6748,knn_ttm_n=1000:117.2366,knn_tta_r_n=1000:117.6922,knn_ttm_r_n=1000:116.0938'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:211.3569,knn_ttm_n=100:384.4024,knn_tta_r_n=100:189.2852,knn_ttm_r_n=100:204.8974,knn_tta_n=500:268.4864,knn_ttm_n=500:464.6638,knn_tta_r_n=500:149.1127,knn_ttm_r_n=500:148.3316,knn_tta_n=1000:154.2631,knn_ttm_n=1000:153.25,knn_tta_r_n=1000:137.8698,knn_ttm_r_n=1000:140.2708'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_80'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:240.5972,knn_ttm_n=100:262.9296,knn_tta_r_n=100:242.8676,knn_ttm_r_n=100:246.7374,knn_tta_n=500:262.8673,knn_ttm_n=500:286.3165,knn_tta_r_n=500:263.4357,knn_ttm_r_n=500:264.6267,knn_tta_n=1000:266.7348,knn_ttm_n=1000:290.7922,knn_tta_r_n=1000:268.33,knn_ttm_r_n=1000:268.4017'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:309.1336,knn_ttm_n=100:368.4312,knn_tta_r_n=100:293.7362,knn_ttm_r_n=100:295.6631,knn_tta_n=500:286.4611,knn_ttm_n=500:315.3385,knn_tta_r_n=500:286.5283,knn_ttm_r_n=500:289.3675,knn_tta_n=1000:286.3663,knn_ttm_n=1000:308.4463,knn_tta_r_n=1000:289.7552,knn_ttm_r_n=1000:291.0632'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:375.3511,knn_ttm_n=100:456.6129,knn_tta_r_n=100:377.4687,knn_ttm_r_n=100:381.7696,knn_tta_n=500:420.4572,knn_ttm_n=500:517.8419,knn_tta_r_n=500:418.6821,knn_ttm_r_n=500:421.9686,knn_tta_n=1000:426.6957,knn_ttm_n=1000:527.0273,knn_tta_r_n=1000:425.6091,knn_ttm_r_n=1000:429.2759'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:516.1592,knn_ttm_n=100:728.4507,knn_tta_r_n=100:476.6754,knn_ttm_r_n=100:473.9034,knn_tta_n=500:481.0832,knn_ttm_n=500:603.0071,knn_tta_r_n=500:473.2378,knn_ttm_r_n=500:473.6938,knn_tta_n=1000:473.0396,knn_ttm_n=1000:585.6964,knn_tta_r_n=1000:466.2644,knn_ttm_r_n=1000:473.0735'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:380.2504,knn_ttm_n=100:502.8293,knn_tta_r_n=100:378.6557,knn_ttm_r_n=100:394.643,knn_tta_n=500:435.2093,knn_ttm_n=500:563.0089,knn_tta_r_n=500:432.2296,knn_ttm_r_n=500:438.4291,knn_tta_n=1000:442.1432,knn_ttm_n=1000:575.2174,knn_tta_r_n=1000:439.3214,knn_ttm_r_n=1000:444.5927'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:750.5459,knn_ttm_n=100:5731.7489,knn_tta_r_n=100:536.4711,knn_ttm_r_n=100:488.1096,knn_tta_n=500:459.1062,knn_ttm_n=500:585.7777,knn_tta_r_n=500:454.6259,knn_ttm_r_n=500:463.7815,knn_tta_n=1000:459.6647,knn_ttm_n=1000:587.6798,knn_tta_r_n=1000:454.0903,knn_ttm_r_n=1000:460.1549'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:180.1492,knn_ttm_n=100:187.6609,knn_tta_r_n=100:181.6706,knn_ttm_r_n=100:187.6124,knn_tta_n=500:196.1974,knn_ttm_n=500:201.7047,knn_tta_r_n=500:196.6771,knn_ttm_r_n=500:196.525,knn_tta_n=1000:198.0648,knn_ttm_n=1000:203.6555,knn_tta_r_n=1000:198.6642,knn_ttm_r_n=1000:198.7483'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:209.2494,knn_ttm_n=100:249.6214,knn_tta_r_n=100:196.4612,knn_ttm_r_n=100:201.3504,knn_tta_n=500:188.6352,knn_ttm_n=500:199.1606,knn_tta_r_n=500:190.2842,knn_ttm_r_n=500:192.0635,knn_tta_n=1000:188.0806,knn_ttm_n=1000:193.7796,knn_tta_r_n=1000:190.4123,knn_ttm_r_n=1000:192.0438'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:193.8398,knn_ttm_n=100:211.1662,knn_tta_r_n=100:194.699,knn_ttm_r_n=100:196.9906,knn_tta_n=500:209.9125,knn_ttm_n=500:228.3886,knn_tta_r_n=500:210.4142,knn_ttm_r_n=500:210.8717,knn_tta_n=1000:212.9072,knn_ttm_n=1000:232.6027,knn_tta_r_n=1000:212.4851,knn_ttm_r_n=1000:213.0986'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:237.437,knn_ttm_n=100:300.7975,knn_tta_r_n=100:215.4545,knn_ttm_r_n=100:215.4751,knn_tta_n=500:215.5164,knn_ttm_n=500:249.3884,knn_tta_r_n=500:209.0338,knn_ttm_r_n=500:209.5017,knn_tta_n=1000:212.2131,knn_ttm_n=1000:240.8696,knn_tta_r_n=1000:206.835,knn_ttm_r_n=1000:207.568'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:122.0348,knn_ttm_n=100:129.157,knn_tta_r_n=100:123.142,knn_ttm_r_n=100:123.2751,knn_tta_n=500:131.9005,knn_ttm_n=500:136.9049,knn_tta_r_n=500:132.1196,knn_ttm_r_n=500:131.9003,knn_tta_n=1000:133.178,knn_ttm_n=1000:138.5322,knn_tta_r_n=1000:133.3249,knn_ttm_r_n=1000:133.1953'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:159.6238,knn_ttm_n=100:188.8129,knn_tta_r_n=100:150.8539,knn_ttm_r_n=100:151.0024,knn_tta_n=500:143.9815,knn_ttm_n=500:148.49,knn_tta_r_n=500:144.5822,knn_ttm_r_n=500:145.3388,knn_tta_n=1000:143.5017,knn_ttm_n=1000:145.8953,knn_tta_r_n=1000:144.4812,knn_ttm_r_n=1000:144.9434'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_81'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:197.7954,knn_ttm_n=100:279.9599,knn_tta_r_n=100:188.3159,knn_ttm_r_n=100:10066.9965,knn_tta_n=500:232.5142,knn_ttm_n=500:345.7973,knn_tta_r_n=500:217.8966,knn_ttm_r_n=500:219.3281,knn_tta_n=1000:329.3743,knn_ttm_n=1000:283.8919,knn_tta_r_n=1000:246.4457,knn_ttm_r_n=1000:301.1113'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1008261.277,knn_ttm_n=100:2381189.3803,knn_tta_r_n=100:5728891.776,knn_ttm_r_n=100:858458.5201,knn_tta_n=500:1406.5817,knn_ttm_n=500:3810.6561,knn_tta_r_n=500:692.6834,knn_ttm_r_n=500:799.5021,knn_tta_n=1000:436.1207,knn_ttm_n=1000:528.4797,knn_tta_r_n=1000:610.7455,knn_ttm_r_n=1000:374.9964'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:143.2957,knn_ttm_n=100:204.5242,knn_tta_r_n=100:148.8075,knn_ttm_r_n=100:149.106,knn_tta_n=500:254.5245,knn_ttm_n=500:320.7276,knn_tta_r_n=500:268.3931,knn_ttm_r_n=500:259.7056,knn_tta_n=1000:464.8092,knn_ttm_n=1000:491.3924,knn_tta_r_n=1000:351.2721,knn_ttm_r_n=1000:294.4693'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1244099.4076,knn_ttm_n=100:275302.4202,knn_tta_r_n=100:358124.1766,knn_ttm_r_n=100:589970.438,knn_tta_n=500:13754.2857,knn_ttm_n=500:28150.383,knn_tta_r_n=500:6935.3382,knn_ttm_r_n=500:8904.8136,knn_tta_n=1000:1424.3858,knn_ttm_n=1000:1938.3697,knn_tta_r_n=1000:673.0109,knn_ttm_r_n=1000:1324.0752'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:136.8888,knn_ttm_n=100:201.245,knn_tta_r_n=100:141.0441,knn_ttm_r_n=100:459503.7295,knn_tta_n=500:246.6374,knn_ttm_n=500:353.8481,knn_tta_r_n=500:254.494,knn_ttm_r_n=500:243.4261,knn_tta_n=1000:248.3342,knn_ttm_n=1000:334.2968,knn_tta_r_n=1000:251.3707,knn_ttm_r_n=1000:247.2681'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:199956514.0742,knn_ttm_n=100:28874792.4974,knn_tta_r_n=100:103886203.2816,knn_ttm_r_n=100:59782854.7902,knn_tta_n=500:10876.1178,knn_ttm_n=500:7167.6121,knn_tta_r_n=500:14199.1963,knn_ttm_r_n=500:3207.5682,knn_tta_n=1000:1031.264,knn_ttm_n=1000:1730.4578,knn_tta_r_n=1000:538.9431,knn_ttm_r_n=1000:890.3201'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:183.8415,knn_ttm_n=100:310.8772,knn_tta_r_n=100:144.8488,knn_ttm_r_n=100:520039.9407,knn_tta_n=500:178.2172,knn_ttm_n=500:213.576,knn_tta_r_n=500:184.8333,knn_ttm_r_n=500:172.0787,knn_tta_n=1000:176.7626,knn_ttm_n=1000:225.161,knn_tta_r_n=1000:180.0437,knn_ttm_r_n=1000:187.8621'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:682462.4962,knn_ttm_n=100:1189183.6385,knn_tta_r_n=100:551536.9687,knn_ttm_r_n=100:1025395.3667,knn_tta_n=500:24724.0565,knn_ttm_n=500:158650.936,knn_tta_r_n=500:15502.9073,knn_ttm_r_n=500:30931.5377,knn_tta_n=1000:246.4324,knn_ttm_n=1000:421.9985,knn_tta_r_n=1000:195.3386,knn_ttm_r_n=1000:228.103'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:206.7413,knn_ttm_n=100:291.7071,knn_tta_r_n=100:183.3202,knn_ttm_r_n=100:222.9959,knn_tta_n=500:324.0349,knn_ttm_n=500:597.3646,knn_tta_r_n=500:238.3262,knn_ttm_r_n=500:211.872,knn_tta_n=1000:337.4078,knn_ttm_n=1000:542.4675,knn_tta_r_n=1000:249.1539,knn_ttm_r_n=1000:257.677'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:4814197.9673,knn_ttm_n=100:9242761.9776,knn_tta_r_n=100:4050621.2252,knn_ttm_r_n=100:3619089.4976,knn_tta_n=500:412.0154,knn_ttm_n=500:753.9124,knn_tta_r_n=500:334.1444,knn_ttm_r_n=500:335.9956,knn_tta_n=1000:344.067,knn_ttm_n=1000:611.2888,knn_tta_r_n=1000:242.9703,knn_ttm_r_n=1000:268.6813'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:114.363,knn_ttm_n=100:155.7912,knn_tta_r_n=100:106.3334,knn_ttm_r_n=100:100.2005,knn_tta_n=500:126.3224,knn_ttm_n=500:160.5815,knn_tta_r_n=500:124.1363,knn_ttm_r_n=500:122.4733,knn_tta_n=1000:133.2959,knn_ttm_n=1000:174.9432,knn_tta_r_n=1000:131.4455,knn_ttm_r_n=1000:126.0094'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:150668.6317,knn_ttm_n=100:647191.5604,knn_tta_r_n=100:149632.2239,knn_ttm_r_n=100:135952.4443,knn_tta_n=500:1427.9151,knn_ttm_n=500:3103.3624,knn_tta_r_n=500:387.5505,knn_ttm_r_n=500:400.3415,knn_tta_n=1000:541.1525,knn_ttm_n=1000:1040.5192,knn_tta_r_n=1000:181.979,knn_ttm_r_n=1000:188.1283'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_82'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:93.2314,knn_ttm_n=100:90.6181,knn_tta_r_n=100:108.4879,knn_ttm_r_n=100:101.8747,knn_tta_n=500:192.8736,knn_ttm_n=500:208.4394,knn_tta_r_n=500:199.6381,knn_ttm_r_n=500:195.8187,knn_tta_n=1000:211.7051,knn_ttm_n=1000:237.3248,knn_tta_r_n=1000:215.3573,knn_ttm_r_n=1000:213.5082'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:592.2378,knn_ttm_n=100:830.1077,knn_tta_r_n=100:415.4047,knn_ttm_r_n=100:476.4727,knn_tta_n=500:288.4632,knn_ttm_n=500:350.7095,knn_tta_r_n=500:278.6433,knn_ttm_r_n=500:284.2539,knn_tta_n=1000:284.7125,knn_ttm_n=1000:313.443,knn_tta_r_n=1000:263.1934,knn_ttm_r_n=1000:265.0969'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:107.0871,knn_ttm_n=100:113.1892,knn_tta_r_n=100:128.0045,knn_ttm_r_n=100:2456.503,knn_tta_n=500:222.6013,knn_ttm_n=500:259.6291,knn_tta_r_n=500:233.8369,knn_ttm_r_n=500:228.0107,knn_tta_n=1000:250.5976,knn_ttm_n=1000:297.9585,knn_tta_r_n=1000:257.5053,knn_ttm_r_n=1000:257.1946'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1873.8643,knn_ttm_n=100:1824.5901,knn_tta_r_n=100:2725.7754,knn_ttm_r_n=100:1856.1396,knn_tta_n=500:506.4409,knn_ttm_n=500:605.6472,knn_tta_r_n=500:448.3185,knn_ttm_r_n=500:373.3162,knn_tta_n=1000:358.7667,knn_ttm_n=1000:447.5019,knn_tta_r_n=1000:350.3715,knn_ttm_r_n=1000:344.235'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:112.9773,knn_ttm_n=100:117.6224,knn_tta_r_n=100:131.4467,knn_ttm_r_n=100:124.0808,knn_tta_n=500:229.938,knn_ttm_n=500:268.2232,knn_tta_r_n=500:240.3564,knn_ttm_r_n=500:233.1022,knn_tta_n=1000:262.2606,knn_ttm_n=1000:308.6423,knn_tta_r_n=1000:269.8808,knn_ttm_r_n=1000:266.1449'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:942.6272,knn_ttm_n=100:1248.737,knn_tta_r_n=100:529.7191,knn_ttm_r_n=100:753.018,knn_tta_n=500:372.4366,knn_ttm_n=500:476.134,knn_tta_r_n=500:318.8017,knn_ttm_r_n=500:316.3874,knn_tta_n=1000:321.8962,knn_ttm_n=1000:390.7436,knn_tta_r_n=1000:308.1364,knn_ttm_r_n=1000:311.7911'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:84.3144,knn_ttm_n=100:82.9083,knn_tta_r_n=100:99.7243,knn_ttm_r_n=100:90.8275,knn_tta_n=500:161.4918,knn_ttm_n=500:177.3314,knn_tta_r_n=500:167.094,knn_ttm_r_n=500:163.2133,knn_tta_n=1000:175.9928,knn_ttm_n=1000:196.3631,knn_tta_r_n=1000:178.722,knn_ttm_r_n=1000:177.6413'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:325.9517,knn_ttm_n=100:452.4357,knn_tta_r_n=100:249.101,knn_ttm_r_n=100:257.301,knn_tta_n=500:210.9508,knn_ttm_n=500:252.3163,knn_tta_r_n=500:199.4326,knn_ttm_r_n=500:202.0435,knn_tta_n=1000:194.6231,knn_ttm_n=1000:223.2053,knn_tta_r_n=1000:193.4505,knn_ttm_r_n=1000:196.039'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:82.5953,knn_ttm_n=100:85.1238,knn_tta_r_n=100:97.9584,knn_ttm_r_n=100:123.2082,knn_tta_n=500:164.3538,knn_ttm_n=500:184.7866,knn_tta_r_n=500:170.1787,knn_ttm_r_n=500:165.0751,knn_tta_n=1000:178.9805,knn_ttm_n=1000:202.7184,knn_tta_r_n=1000:183.1384,knn_ttm_r_n=1000:178.749'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:680.1444,knn_ttm_n=100:1175.2798,knn_tta_r_n=100:489.8317,knn_ttm_r_n=100:405.4711,knn_tta_n=500:290.7916,knn_ttm_n=500:414.2836,knn_tta_r_n=500:219.5526,knn_ttm_r_n=500:214.599,knn_tta_n=1000:222.1862,knn_ttm_n=1000:297.3882,knn_tta_r_n=1000:199.9603,knn_ttm_r_n=1000:203.7062'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:49.3441,knn_ttm_n=100:45.8725,knn_tta_r_n=100:56.3126,knn_ttm_r_n=100:48.3863,knn_tta_n=500:87.0877,knn_ttm_n=500:86.4038,knn_tta_r_n=500:90.1863,knn_ttm_r_n=500:86.7664,knn_tta_n=1000:93.6111,knn_ttm_n=1000:93.9457,knn_tta_r_n=1000:95.0694,knn_ttm_r_n=1000:93.4488'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:327.5908,knn_ttm_n=100:422.1083,knn_tta_r_n=100:186.1611,knn_ttm_r_n=100:184.8547,knn_tta_n=500:140.1981,knn_ttm_n=500:162.4389,knn_tta_r_n=500:133.5466,knn_ttm_r_n=500:133.5224,knn_tta_n=1000:140.5548,knn_ttm_n=1000:151.6837,knn_tta_r_n=1000:136.4144,knn_ttm_r_n=1000:135.2448'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_83'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:73.2236,knn_ttm_n=100:52.3221,knn_tta_r_n=100:90.8378,knn_ttm_r_n=100:63.4587,knn_tta_n=500:143.1738,knn_ttm_n=500:131.4191,knn_tta_r_n=500:155.1487,knn_ttm_r_n=500:134.6195,knn_tta_n=1000:161.1987,knn_ttm_n=1000:158.3795,knn_tta_r_n=1000:171.6003,knn_ttm_r_n=1000:157.6068'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:236.7437,knn_ttm_n=100:307.4043,knn_tta_r_n=100:209.6108,knn_ttm_r_n=100:216.2811,knn_tta_n=500:193.0481,knn_ttm_n=500:217.5623,knn_tta_r_n=500:190.1096,knn_ttm_r_n=500:189.188,knn_tta_n=1000:197.29,knn_ttm_n=1000:213.082,knn_tta_r_n=1000:196.5321,knn_ttm_r_n=1000:193.1134'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:76.7318,knn_ttm_n=100:57.4568,knn_tta_r_n=100:97.7679,knn_ttm_r_n=100:63.2319,knn_tta_n=500:153.1653,knn_ttm_n=500:147.273,knn_tta_r_n=500:167.2424,knn_ttm_r_n=500:141.358,knn_tta_n=1000:176.0763,knn_ttm_n=1000:179.9631,knn_tta_r_n=1000:186.3755,knn_ttm_r_n=1000:166.7404'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:244.144,knn_ttm_n=100:299.1929,knn_tta_r_n=100:213.8862,knn_ttm_r_n=100:242.3213,knn_tta_n=500:197.1733,knn_ttm_n=500:223.4213,knn_tta_r_n=500:194.4905,knn_ttm_r_n=500:191.5799,knn_tta_n=1000:200.8302,knn_ttm_n=1000:222.161,knn_tta_r_n=1000:198.9409,knn_ttm_r_n=1000:194.025'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:75.8044,knn_ttm_n=100:56.6647,knn_tta_r_n=100:95.6853,knn_ttm_r_n=100:60.5281,knn_tta_n=500:150.5471,knn_ttm_n=500:145.7108,knn_tta_r_n=500:163.5069,knn_ttm_r_n=500:137.3333,knn_tta_n=1000:172.1466,knn_ttm_n=1000:177.6611,knn_tta_r_n=1000:181.6132,knn_ttm_r_n=1000:162.6001'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:258.5213,knn_ttm_n=100:305.6812,knn_tta_r_n=100:232.7496,knn_ttm_r_n=100:254.2923,knn_tta_n=500:218.3514,knn_ttm_n=500:237.4178,knn_tta_r_n=500:213.4793,knn_ttm_r_n=500:213.2884,knn_tta_n=1000:221.877,knn_ttm_n=1000:239.7051,knn_tta_r_n=1000:217.3932,knn_ttm_r_n=1000:214.5693'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:72.6413,knn_ttm_n=100:49.4421,knn_tta_r_n=100:93.2177,knn_ttm_r_n=100:65.2697,knn_tta_n=500:138.2123,knn_ttm_n=500:122.1884,knn_tta_r_n=500:150.9999,knn_ttm_r_n=500:131.1175,knn_tta_n=1000:156.2026,knn_ttm_n=1000:147.1316,knn_tta_r_n=1000:165.0247,knn_ttm_r_n=1000:151.6572'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:222.823,knn_ttm_n=100:287.7508,knn_tta_r_n=100:171.4858,knn_ttm_r_n=100:183.1031,knn_tta_n=500:163.471,knn_ttm_n=500:186.1863,knn_tta_r_n=500:163.7648,knn_ttm_r_n=500:161.1054,knn_tta_n=1000:164.1226,knn_ttm_n=1000:178.0569,knn_tta_r_n=1000:167.9999,knn_ttm_r_n=1000:165.0373'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:69.6409,knn_ttm_n=100:51.6146,knn_tta_r_n=100:89.5247,knn_ttm_r_n=100:60.9804,knn_tta_n=500:135.676,knn_ttm_n=500:128.6864,knn_tta_r_n=500:146.9572,knn_ttm_r_n=500:127.712,knn_tta_n=1000:152.7152,knn_ttm_n=1000:155.4734,knn_tta_r_n=1000:159.5722,knn_ttm_r_n=1000:146.4079'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:238.042,knn_ttm_n=100:301.5118,knn_tta_r_n=100:182.8715,knn_ttm_r_n=100:194.5181,knn_tta_n=500:175.8027,knn_ttm_n=500:206.1746,knn_tta_r_n=500:167.7426,knn_ttm_r_n=500:168.7475,knn_tta_n=1000:174.4846,knn_ttm_n=1000:199.4763,knn_tta_r_n=1000:170.1341,knn_ttm_r_n=1000:168.3292'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:51.8493,knn_ttm_n=100:34.101,knn_tta_r_n=100:66.183,knn_ttm_r_n=100:46.0667,knn_tta_n=500:96.2266,knn_ttm_n=500:86.7371,knn_tta_r_n=500:103.24,knn_ttm_r_n=500:89.8276,knn_tta_n=1000:104.7755,knn_ttm_n=1000:103.6032,knn_tta_r_n=1000:109.1652,knn_ttm_r_n=1000:101.5163'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:180.8871,knn_ttm_n=100:231.6941,knn_tta_r_n=100:146.2673,knn_ttm_r_n=100:155.8746,knn_tta_n=500:142.8995,knn_ttm_n=500:159.8067,knn_tta_r_n=500:136.7938,knn_ttm_r_n=500:137.2914,knn_tta_n=1000:141.0465,knn_ttm_n=1000:152.1127,knn_tta_r_n=1000:136.7942,knn_ttm_r_n=1000:136.3617'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_91'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:226.1742,knn_ttm_n=100:275.1794,knn_tta_r_n=100:204.8166,knn_ttm_r_n=100:256.4825,knn_tta_n=500:221.0399,knn_ttm_n=500:238.7645,knn_tta_r_n=500:225.7424,knn_ttm_r_n=500:217.5508,knn_tta_n=1000:231.0876,knn_ttm_n=1000:250.0922,knn_tta_r_n=1000:234.5745,knn_ttm_r_n=1000:229.067'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:2120719643.3793,knn_ttm_n=100:7980359365.7793,knn_tta_r_n=100:4661020799.4513,knn_ttm_r_n=100:5320877357.7753,knn_tta_n=500:12458327.5285,knn_ttm_n=500:24942068.1083,knn_tta_r_n=500:308190142.136,knn_ttm_r_n=500:198611863.7656,knn_tta_n=1000:257.4283,knn_ttm_n=1000:280.5835,knn_tta_r_n=1000:258.104,knn_ttm_r_n=1000:257.9661'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:256.4185,knn_ttm_n=100:303.203,knn_tta_r_n=100:245.1619,knn_ttm_r_n=100:237.2485,knn_tta_n=500:276.1904,knn_ttm_n=500:326.0996,knn_tta_r_n=500:284.6919,knn_ttm_r_n=500:277.2979,knn_tta_n=1000:289.9026,knn_ttm_n=1000:345.7897,knn_tta_r_n=1000:295.3205,knn_ttm_r_n=1000:290.1624'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:422870384.2292,knn_ttm_n=100:798097718.8703,knn_tta_r_n=100:168803110.5454,knn_ttm_r_n=100:15546659.9967,knn_tta_n=500:390.0152,knn_ttm_n=500:485.6472,knn_tta_r_n=500:348.4122,knn_ttm_r_n=500:342.8818,knn_tta_n=1000:354.407,knn_ttm_n=1000:437.4188,knn_tta_r_n=1000:340.8782,knn_ttm_r_n=1000:337.1852'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:249.5842,knn_ttm_n=100:299.1067,knn_tta_r_n=100:254.8055,knn_ttm_r_n=100:245.2368,knn_tta_n=500:284.5004,knn_ttm_n=500:348.6806,knn_tta_r_n=500:290.2574,knn_ttm_r_n=500:283.1995,knn_tta_n=1000:301.1624,knn_ttm_n=1000:373.0463,knn_tta_r_n=1000:305.5651,knn_ttm_r_n=1000:299.3574'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:2735698638.0133,knn_ttm_n=100:1747933271.132,knn_tta_r_n=100:2264934047.7465,knn_ttm_r_n=100:617448832.9068,knn_tta_n=500:326.5051,knn_ttm_n=500:409.5133,knn_tta_r_n=500:319.899,knn_ttm_r_n=500:321.8188,knn_tta_n=1000:323.6752,knn_ttm_n=1000:398.9099,knn_tta_r_n=1000:326.7978,knn_ttm_r_n=1000:324.1305'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:177.8207,knn_ttm_n=100:210.0635,knn_tta_r_n=100:164.5954,knn_ttm_r_n=100:155.603,knn_tta_n=500:184.8937,knn_ttm_n=500:186.8816,knn_tta_r_n=500:188.7305,knn_ttm_r_n=500:183.7473,knn_tta_n=1000:192.2686,knn_ttm_n=1000:196.6202,knn_tta_r_n=1000:194.4828,knn_ttm_r_n=1000:191.132'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:4401634115.7792,knn_ttm_n=100:16922224916.8005,knn_tta_r_n=100:12689568796.8817,knn_ttm_r_n=100:1317096371.3334,knn_tta_n=500:209.5911,knn_ttm_n=500:245.5127,knn_tta_r_n=500:192.4655,knn_ttm_r_n=500:192.2714,knn_tta_n=1000:198.2617,knn_ttm_n=1000:226.3684,knn_tta_r_n=1000:191.2837,knn_ttm_r_n=1000:191.4879'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:177.0322,knn_ttm_n=100:214.1505,knn_tta_r_n=100:161.1893,knn_ttm_r_n=100:13722786.1008,knn_tta_n=500:183.3705,knn_ttm_n=500:196.7335,knn_tta_r_n=500:187.1477,knn_ttm_r_n=500:181.7028,knn_tta_n=1000:193.2088,knn_ttm_n=1000:210.4195,knn_tta_r_n=1000:195.1103,knn_ttm_r_n=1000:190.5585'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:13993798353.6296,knn_ttm_n=100:13470906498.3398,knn_tta_r_n=100:3077489055.9982,knn_ttm_r_n=100:1322185596.0327,knn_tta_n=500:203.6852,knn_ttm_n=500:238.4898,knn_tta_r_n=500:194.2285,knn_ttm_r_n=500:194.3537,knn_tta_n=1000:201.8954,knn_ttm_n=1000:231.5818,knn_tta_r_n=1000:197.3538,knn_ttm_r_n=1000:195.4555'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:111.4792,knn_ttm_n=100:135.5952,knn_tta_r_n=100:101.0241,knn_ttm_r_n=100:837722.2253,knn_tta_n=500:113.5505,knn_ttm_n=500:119.9044,knn_tta_r_n=500:114.5004,knn_ttm_r_n=500:111.4905,knn_tta_n=1000:116.2099,knn_ttm_n=1000:124.5439,knn_tta_r_n=1000:117.3088,knn_ttm_r_n=1000:115.2182'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:10706943711.4607,knn_ttm_n=100:269834439501.9174,knn_tta_r_n=100:2873844569.3139,knn_ttm_r_n=100:1060416111.227,knn_tta_n=500:1149113.8469,knn_ttm_n=500:258301.6985,knn_tta_r_n=500:1073734.9194,knn_ttm_r_n=500:565760.666,knn_tta_n=1000:143.2007,knn_ttm_n=1000:154.2892,knn_tta_r_n=1000:141.474,knn_ttm_r_n=1000:141.8424'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_94'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:169.9722,knn_ttm_n=100:158.3596,knn_tta_r_n=100:179.8585,knn_ttm_r_n=100:168.3403,knn_tta_n=500:231.7402,knn_ttm_n=500:248.1267,knn_tta_r_n=500:233.6244,knn_ttm_r_n=500:228.4558,knn_tta_n=1000:243.4792,knn_ttm_n=1000:267.7466,knn_tta_r_n=1000:244.8444,knn_ttm_r_n=1000:243.0602'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:21806.2786,knn_ttm_n=100:21527.2452,knn_tta_r_n=100:8435.1797,knn_ttm_r_n=100:4799.9781,knn_tta_n=500:393.9694,knn_ttm_n=500:397.8903,knn_tta_r_n=500:341.7994,knn_ttm_r_n=500:310.9798,knn_tta_n=1000:305.3968,knn_ttm_n=1000:389.088,knn_tta_r_n=1000:280.0337,knn_ttm_r_n=1000:295.4149'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:233.0718,knn_ttm_n=100:248.5479,knn_tta_r_n=100:249.7896,knn_ttm_r_n=100:3847.8138,knn_tta_n=500:318.0855,knn_ttm_n=500:390.879,knn_tta_r_n=500:323.4819,knn_ttm_r_n=500:441.184,knn_tta_n=1000:341.2699,knn_ttm_n=1000:427.052,knn_tta_r_n=1000:344.9774,knn_ttm_r_n=1000:341.0251'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1931.5456,knn_ttm_n=100:3251.7994,knn_tta_r_n=100:601.7096,knn_ttm_r_n=100:821.7991,knn_tta_n=500:408.9981,knn_ttm_n=500:624.9781,knn_tta_r_n=500:365.272,knn_ttm_r_n=500:372.1414,knn_tta_n=1000:379.3147,knn_ttm_n=1000:493.7758,knn_tta_r_n=1000:368.4736,knn_ttm_r_n=1000:369.4961'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:240.0136,knn_ttm_n=100:253.355,knn_tta_r_n=100:253.1481,knn_ttm_r_n=100:227.402,knn_tta_n=500:329.4095,knn_ttm_n=500:402.8781,knn_tta_r_n=500:334.646,knn_ttm_r_n=500:323.6769,knn_tta_n=1000:352.57,knn_ttm_n=1000:433.3259,knn_tta_r_n=1000:359.4551,knn_ttm_r_n=1000:352.1273'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1004.1712,knn_ttm_n=100:941.9544,knn_tta_r_n=100:546.8685,knn_ttm_r_n=100:635.836,knn_tta_n=500:379.0277,knn_ttm_n=500:520.089,knn_tta_r_n=500:367.1186,knn_ttm_r_n=500:363.9302,knn_tta_n=1000:383.3811,knn_ttm_n=1000:488.8616,knn_tta_r_n=1000:382.1822,knn_ttm_r_n=1000:378.1237'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:140.8063,knn_ttm_n=100:126.8753,knn_tta_r_n=100:149.8101,knn_ttm_r_n=100:156.4141,knn_tta_n=500:183.6517,knn_ttm_n=500:185.2246,knn_tta_r_n=500:187.1745,knn_ttm_r_n=500:182.1321,knn_tta_n=1000:193.2228,knn_ttm_n=1000:200.4274,knn_tta_r_n=1000:195.1923,knn_ttm_r_n=1000:193.1682'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:1594.6641,knn_ttm_n=100:1618.7496,knn_tta_r_n=100:559.7521,knn_ttm_r_n=100:1092.4075,knn_tta_n=500:200.613,knn_ttm_n=500:218.0978,knn_tta_r_n=500:196.6642,knn_ttm_r_n=500:197.7578,knn_tta_n=1000:199.2025,knn_ttm_n=1000:210.58,knn_tta_r_n=1000:198.5397,knn_ttm_r_n=1000:198.9117'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:145.9738,knn_ttm_n=100:136.5322,knn_tta_r_n=100:157.333,knn_ttm_r_n=100:141.6045,knn_tta_n=500:198.8592,knn_ttm_n=500:211.3569,knn_tta_r_n=500:202.1396,knn_ttm_r_n=500:196.2846,knn_tta_n=1000:210.6636,knn_ttm_n=1000:223.5722,knn_tta_r_n=1000:213.4771,knn_ttm_r_n=1000:209.7402'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:8093.6635,knn_ttm_n=100:6060.9953,knn_tta_r_n=100:3210.1984,knn_ttm_r_n=100:2438.4131,knn_tta_n=500:239.192,knn_ttm_n=500:284.6484,knn_tta_r_n=500:219.1768,knn_ttm_r_n=500:216.5114,knn_tta_n=1000:223.7192,knn_ttm_n=1000:252.3914,knn_tta_r_n=1000:216.5873,knn_ttm_r_n=1000:216.1944'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:84.4831,knn_ttm_n=100:70.4815,knn_tta_r_n=100:90.0707,knn_ttm_r_n=100:80.6388,knn_tta_n=500:109.0022,knn_ttm_n=500:108.2834,knn_tta_r_n=500:111.4759,knn_ttm_r_n=500:108.4629,knn_tta_n=1000:113.2545,knn_ttm_n=1000:114.8359,knn_tta_r_n=1000:114.4211,knn_ttm_r_n=1000:112.9165'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:300.5254,knn_ttm_n=100:342.8153,knn_tta_r_n=100:170.3881,knn_ttm_r_n=100:187.2136,knn_tta_n=500:148.8342,knn_ttm_n=500:176.5093,knn_tta_r_n=500:142.9926,knn_ttm_r_n=500:139.7998,knn_tta_n=1000:139.9343,knn_ttm_n=1000:151.4995,knn_tta_r_n=1000:142.7195,knn_ttm_r_n=1000:141.4164'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_99'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:135.6541,knn_ttm_n=100:129.4731,knn_tta_r_n=100:148.6894,knn_ttm_r_n=100:171.4765,knn_tta_n=500:210.9289,knn_ttm_n=500:219.4874,knn_tta_r_n=500:216.2079,knn_ttm_r_n=500:210.3827,knn_tta_n=1000:228.2107,knn_ttm_n=1000:240.4789,knn_tta_r_n=1000:232.9969,knn_ttm_r_n=1000:228.0697'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:485.0428,knn_ttm_n=100:624.9451,knn_tta_r_n=100:328.4691,knn_ttm_r_n=100:410.4115,knn_tta_n=500:269.8796,knn_ttm_n=500:296.278,knn_tta_r_n=500:263.2302,knn_ttm_r_n=500:257.122,knn_tta_n=1000:279.1435,knn_ttm_n=1000:289.1254,knn_tta_r_n=1000:271.2478,knn_ttm_r_n=1000:264.0796'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:170.5779,knn_ttm_n=100:182.7259,knn_tta_r_n=100:189.5557,knn_ttm_r_n=100:312.6111,knn_tta_n=500:277.6968,knn_ttm_n=500:331.4282,knn_tta_r_n=500:284.6581,knn_ttm_r_n=500:281.8888,knn_tta_n=1000:305.41,knn_ttm_n=1000:372.5426,knn_tta_r_n=1000:308.8191,knn_ttm_r_n=1000:305.4633'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:6606.9544,knn_ttm_n=100:9820.7474,knn_tta_r_n=100:3505.2603,knn_ttm_r_n=100:5905.3081,knn_tta_n=500:341.2335,knn_ttm_n=500:418.6712,knn_tta_r_n=500:337.5917,knn_ttm_r_n=500:345.9583,knn_tta_n=1000:344.3222,knn_ttm_n=1000:420.9198,knn_tta_r_n=1000:341.8357,knn_ttm_r_n=1000:347.4097'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:177.208,knn_ttm_n=100:193.6371,knn_tta_r_n=100:193.4127,knn_ttm_r_n=100:209.6655,knn_tta_n=500:284.8363,knn_ttm_n=500:337.6882,knn_tta_r_n=500:287.8997,knn_ttm_r_n=500:282.1965,knn_tta_n=1000:309.7684,knn_ttm_n=1000:369.8309,knn_tta_r_n=1000:315.9538,knn_ttm_r_n=1000:308.9498'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1510.4398,knn_ttm_n=100:1560.2393,knn_tta_r_n=100:823.7729,knn_ttm_r_n=100:602.265,knn_tta_n=500:365.2837,knn_ttm_n=500:504.2596,knn_tta_r_n=500:335.1625,knn_ttm_r_n=500:337.0511,knn_tta_n=1000:347.821,knn_ttm_n=1000:417.6731,knn_tta_r_n=1000:345.8788,knn_ttm_r_n=1000:344.7444'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:123.4285,knn_ttm_n=100:119.0643,knn_tta_r_n=100:136.1389,knn_ttm_r_n=100:161.9186,knn_tta_n=500:181.3683,knn_ttm_n=500:195.6684,knn_tta_r_n=500:184.8992,knn_ttm_r_n=500:181.2878,knn_tta_n=1000:191.0288,knn_ttm_n=1000:207.0955,knn_tta_r_n=1000:193.0579,knn_ttm_r_n=1000:191.578'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:47818.4333,knn_ttm_n=100:6315.4469,knn_tta_r_n=100:316.3732,knn_ttm_r_n=100:1743.4193,knn_tta_n=500:216.4676,knn_ttm_n=500:253.4751,knn_tta_r_n=500:202.5256,knn_ttm_r_n=500:224.4626,knn_tta_n=1000:192.3368,knn_ttm_n=1000:218.6113,knn_tta_r_n=1000:197.4685,knn_ttm_r_n=1000:208.2272'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:120.0696,knn_ttm_n=100:122.5041,knn_tta_r_n=100:130.8903,knn_ttm_r_n=100:123.1356,knn_tta_n=500:178.4546,knn_ttm_n=500:197.6271,knn_tta_r_n=500:181.4445,knn_ttm_r_n=500:177.2357,knn_tta_n=1000:189.9284,knn_ttm_n=1000:216.3326,knn_tta_r_n=1000:190.9778,knn_ttm_r_n=1000:187.8079'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:321.4468,knn_ttm_n=100:528.8045,knn_tta_r_n=100:242.0827,knn_ttm_r_n=100:279.221,knn_tta_n=500:193.9839,knn_ttm_n=500:235.8442,knn_tta_r_n=500:186.8157,knn_ttm_r_n=500:187.4325,knn_tta_n=1000:195.1115,knn_ttm_n=1000:236.0452,knn_tta_r_n=1000:190.3874,knn_ttm_r_n=1000:188.1608'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:77.9,knn_ttm_n=100:76.479,knn_tta_r_n=100:84.9784,knn_ttm_r_n=100:75.8781,knn_tta_n=500:111.4686,knn_ttm_n=500:124.4301,knn_tta_r_n=500:113.3323,knn_ttm_r_n=500:110.601,knn_tta_n=1000:115.9469,knn_ttm_n=1000:130.8963,knn_tta_r_n=1000:116.6424,knn_ttm_r_n=1000:115.5766'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1073.0152,knn_ttm_n=100:1206.2309,knn_tta_r_n=100:233.1703,knn_ttm_r_n=100:246.5852,knn_tta_n=500:142.9633,knn_ttm_n=500:165.0519,knn_tta_r_n=500:139.0504,knn_ttm_r_n=500:140.7366,knn_tta_n=1000:139.503,knn_ttm_n=1000:155.7427,knn_tta_r_n=1000:137.3983,knn_ttm_r_n=1000:138.7889'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "def build_predictors(n,deep):\n",
    "    predictors = {}\n",
    "    for i in [100,500,1000]:\n",
    "        if i* 2 < n:\n",
    "            predictors[f'knn_tta_n={i}'] = LWRBoost(deep,n_neighbors=i, weights='triangle',errors='triangle',convolution='additive',reverse=True)\n",
    "            predictors[f'knn_ttm_n={i}'] = LWRBoost(deep,n_neighbors=i, weights='triangle',errors='triangle',convolution='multiplicative',reverse=True)\n",
    "            predictors[f'knn_tta_r_n={i}'] = LWRBoost(deep,n_neighbors=i, weights='triangle',errors='triangle',convolution='additive',reverse=False)\n",
    "            predictors[f'knn_ttm_r_n={i}'] = LWRBoost(deep,n_neighbors=i, weights='triangle',errors='triangle',convolution='multiplicative',reverse=False)\n",
    "    return predictors\n",
    "\n",
    "\n",
    "deep_models = {k:v for k,v in deep_models.items() if k in best_n}\n",
    "for deep_name,deep_model in tqdm(deep_models.items()):\n",
    "    #if #int(deep_name.replace(\"random_\",\"\")) >=34 :\n",
    "        logging.getLogger().info(f\"Running model {deep_name}\")\n",
    "        temp_dict = {deep_name:deep_model}\n",
    "\n",
    "        lwr_scheme = BoostScheme(boost_models = build_predictors(nrow,deep_model),loss_fun_sk = mean_squared_error)\n",
    "        lwr_scores, lwr_preds, _ , _, _,_= eval_.evaluate(temp_dict,dataset,lwr_scheme,logger_name=\"log\")\n",
    "        lwr_scores_final, lwr_preds_final, _ , _, _,_= eval_.build(temp_dict,dataset,lwr_scheme,logger_name=\"test_log\")\n",
    "\n",
    "        #scores\n",
    "        for k,v in ut.flip_dicts(lwr_scores).items(): \n",
    "            dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "            all_scores.append({**dict1,**v})\n",
    "\n",
    "        for k,v in ut.flip_dicts(lwr_scores_final).items():\n",
    "            dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "            all_scores_final.append({**dict1,**v})\n",
    "\n",
    "        lwr_preds['deep'] = deep_preds[deep_name]\n",
    "        lwr_preds_final['deep'] = deep_preds_final[deep_name]\n",
    "\n",
    "        lwr_preds.to_csv(log_dir/deep_name/ f\"predictions.csv\",index=False)\n",
    "        lwr_preds_final.to_csv(log_dir/deep_name/ f\"predictions_test.csv\",index=False)\n",
    "\n",
    "        #preds\n",
    "        # todo save predictions - appending solns\n",
    "        plot_preds_and_res(lwr_preds,name_lambda=lambda x:f\"{deep_name} with {x} predictor\",save_lambda= lambda x:f\"deep_lwr{x}\",save_loc=log_dir/deep_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save scores\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank - model_num - predictor - fold_0 - fold_1 - fold_2 - fold_3 - fold_4 - MSE - R2'\n",
      "0 - random_82 - deep - 137.5075182648712 - 130.4421176006498 - 144.06449480977827 - 127.65992345271849 - 131.84387805109836 - 134.30467871071176 - 0.7199893993454223'\n",
      "1 - random_24 - deep - 144.41353603516356 - 132.81591498472767 - 145.4006378800839 - 121.6521948073663 - 130.38346345313028 - 134.9352893915091 - 0.7186746448841157'\n",
      "2 - random_10 - deep - 146.22829733827405 - 131.2531475577443 - 142.54620770487017 - 119.59081962557973 - 137.4023663176208 - 135.40582546692042 - 0.7176936285087342'\n",
      "3 - random_4 - deep - 149.52052070283574 - 139.50407097535572 - 143.93053564656333 - 124.70355024944548 - 135.62736985663406 - 138.6592477281742 - 0.7109105980863994'\n",
      "4 - random_73 - deep - 143.369752692833 - 138.57852169190184 - 150.11264153991405 - 130.9745516782763 - 134.5115186226468 - 139.51102111677213 - 0.7091347435111719'\n",
      "5 - random_94 - deep - 147.74845175007968 - 133.9410871426789 - 150.27850711595963 - 128.0872647581982 - 142.83391092032517 - 140.57907244776365 - 0.7069079730249028'\n",
      "6 - random_54 - deep - 143.3369931162083 - 153.02575410821157 - 146.23201375502487 - 126.75642759545224 - 144.33043288726623 - 142.73805122060224 - 0.7024067378573241'\n",
      "7 - random_71 - deep - 147.42106379444326 - 145.40249613651488 - 150.00145401522724 - 132.49321839331435 - 149.42633086865118 - 144.94986936347323 - 0.6977953383687179'\n",
      "8 - random_83 - deep - 145.02487304357976 - 147.3902957506643 - 156.12350985041334 - 130.14863648706552 - 147.72448534467497 - 145.28388368452516 - 0.6970989549548054'\n",
      "9 - random_14 - deep - 137.70490223702086 - 143.56642867593473 - 148.22834771195787 - 157.75380246092578 - 142.81907055730008 - 146.01348448413944 - 0.6955778168969267'\n",
      "10 - random_29 - deep - 154.446354651494 - 146.6859692697691 - 152.77725805089227 - 133.71976552461805 - 142.77998224741557 - 146.08374610812191 - 0.6954313290774168'\n",
      "11 - random_77 - deep - 148.77480655754835 - 136.91305230775134 - 150.08172788660042 - 139.1033063982429 - 157.03478088928443 - 146.38112929019692 - 0.6948113175913184'\n",
      "12 - random_0 - deep - 147.1445725308826 - 148.0008328900626 - 159.25217494953156 - 133.35702390544841 - 148.6052618496129 - 147.27348410121905 - 0.6929508551783186'\n",
      "13 - random_78 - deep - 158.89134197086364 - 146.8002499292622 - 152.97004405652683 - 132.92693485475246 - 145.22940014018303 - 147.3655830805905 - 0.6927588388555735'\n",
      "14 - random_74 - deep - 153.45526117669226 - 145.8329661643355 - 151.3222925590053 - 135.88923227372004 - 151.27763947375826 - 147.55643185984212 - 0.6923609399750175'\n",
      "15 - random_99 - deep - 158.52725067779411 - 145.02305100503338 - 154.38577592136906 - 135.91042533956943 - 144.576222038498 - 147.68633145297855 - 0.6920901134971309'\n",
      "16 - random_39 - deep - 164.36570207473397 - 142.62089369235528 - 152.7702025360309 - 132.3304426506931 - 147.9701933385659 - 148.01337385772723 - 0.6914082657679803'\n",
      "17 - random_81 - deep - 176.8159001927642 - 140.4785398633164 - 148.84839134010357 - 127.860574765795 - 146.1472452262155 - 148.03277671218763 - 0.6913678129335442'\n",
      "18 - random_32 - deep - 152.97942731705123 - 139.38026185656423 - 163.863112735119 - 136.49283807761387 - 148.11364142061853 - 148.16726493576093 - 0.6910874196618784'\n",
      "19 - random_75 - deep - 152.5712334255866 - 149.3129566561053 - 156.1371806041166 - 139.14811772487315 - 145.9744149170288 - 148.63023752479896 - 0.6901221723303064'\n",
      "20 - random_8 - deep - 151.23871260141283 - 152.04883586881257 - 153.77720893809519 - 135.3754873653563 - 151.5434860559214 - 148.7980271650407 - 0.6897723492385219'\n",
      "21 - random_25 - deep - 155.35112474689817 - 148.6119859463166 - 160.54683642167134 - 131.57825921506299 - 151.01910835440134 - 149.4234122263752 - 0.6884684896236095'\n",
      "22 - random_18 - deep - 159.2038448130076 - 150.7018404241515 - 154.32362722706924 - 133.1140560411176 - 149.97153083645568 - 149.46488185862907 - 0.6883820299652581'\n",
      "23 - random_40 - deep - 153.92921740664073 - 145.49475220312382 - 154.59019869304947 - 136.81229081903757 - 157.85874189763797 - 149.73761682867652 - 0.6878134073117839'\n",
      "24 - random_57 - deep - 149.14027304097286 - 156.1511642007536 - 154.7122040538639 - 128.37676139181258 - 162.0063626585888 - 150.07852621532834 - 0.6871026484384406'\n",
      "25 - random_91 - deep - 153.620345600222 - 150.31857823381614 - 162.8963279952957 - 127.11086940879868 - 156.4462514879609 - 150.08046612553136 - 0.6870986039373377'\n",
      "26 - random_37 - deep - 166.647212444413 - 139.12350676227058 - 159.6392497581569 - 131.68301010589784 - 157.36661104566338 - 150.8934462727633 - 0.6854036290374907'\n",
      "27 - random_34 - deep - 154.56817166077283 - 154.3920279847839 - 156.47700864566465 - 133.88745565975412 - 155.35841047234322 - 150.93813077537928 - 0.6853104667252201'\n",
      "28 - random_47 - deep - 154.46845284721132 - 150.39001206716665 - 161.25703940937888 - 138.767085484096 - 154.42642385933866 - 151.86306536051902 - 0.6833820790380791'\n",
      "29 - random_80 - deep - 159.3029143866051 - 146.6703013218157 - 161.24257640918717 - 137.27580574466114 - 155.53014179609832 - 152.0056930065216 - 0.6830847159587694'\n",
      "30 - random_60 - deep - 162.27312153917484 - 149.2188880888373 - 156.38646359091828 - 137.35813310309476 - 155.0632761466403 - 152.06138062313747 - 0.6829686133543975'\n",
      "31 - random_5 - deep - 134.66904243510427 - 142.32630676013235 - 147.27630952081068 - 123.81846252294864 - 212.8487847226293 - 152.18390586583163 - 0.6827131615925416'\n",
      "32 - random_20 - deep - 152.0456795123214 - 155.5693030491802 - 162.43784279643094 - 133.34324928091354 - 159.01298762913368 - 152.4833254194813 - 0.6820889044939058'\n",
      "33 - random_96 - deep - 156.74727865172204 - 152.73341804417436 - 161.63271283502698 - 140.3110226085063 - 153.38456757214604 - 152.9632668004845 - 0.6810882790826112'\n",
      "34 - random_12 - deep - 166.49045075780987 - 149.89121054573266 - 158.2286906720066 - 134.67502651695443 - 157.2720019282127 - 153.31323775183708 - 0.6803586278356061'\n",
      "35 - random_84 - deep - 160.86198042907898 - 145.30979812338313 - 160.11448720120782 - 145.51721045779152 - 155.1951267384395 - 153.40045155720236 - 0.6801767965676254'\n",
      "36 - random_66 - deep - 156.15075935313425 - 149.8862396771134 - 169.2090683418187 - 141.4422553200968 - 151.481117706482 - 153.63560923805974 - 0.6796865184619219'\n",
      "37 - random_86 - deep - 157.52297369505592 - 157.09822286641304 - 157.42790203288993 - 138.77506606890802 - 157.9949466389339 - 153.76511409923057 - 0.679416514957113'\n",
      "38 - random_33 - deep - 160.70834340974824 - 158.32827788080078 - 161.40144821148687 - 135.51153196263857 - 154.7793091754524 - 154.14794262294382 - 0.6786183592569415'\n",
      "39 - random_15 - deep - 156.9714350754727 - 148.15011470362177 - 172.83399741636757 - 136.3397816157713 - 157.8032911879962 - 154.42148773746416 - 0.678048047540639'\n",
      "40 - random_87 - deep - 152.88574119892817 - 163.5835175677267 - 170.45526103767438 - 139.37112779376886 - 148.0233774173732 - 154.8664841480599 - 0.6771202785796749'\n",
      "41 - random_69 - deep - 184.2796111630335 - 137.754818061046 - 157.21845980726036 - 136.21446411206085 - 160.2989878568615 - 155.1549236684153 - 0.6765189136523875'\n",
      "42 - random_46 - deep - 152.12944892100683 - 159.36474299988635 - 162.35117764292752 - 144.2390072606191 - 157.81001028035726 - 155.1798754199314 - 0.6764668919730501'\n",
      "43 - random_64 - deep - 162.2600555236853 - 158.24614114652655 - 164.60620457352317 - 132.91768263396668 - 161.85900162677376 - 155.97987831429353 - 0.6747989732294428'\n",
      "44 - random_61 - deep - 143.13800560963247 - 231.3233687979201 - 146.7110830511815 - 119.73905226763557 - 141.83969843888482 - 156.55642390768728 - 0.6735969385761402'\n",
      "45 - random_88 - deep - 162.0142171089708 - 155.0941768250354 - 169.8041499514886 - 142.91770699673913 - 157.7003786286243 - 157.50785300003724 - 0.6716133127323751'\n",
      "46 - random_65 - deep - 148.32248614058926 - 137.43423286167962 - 164.65849010373705 - 176.9313974735402 - 165.58588623742955 - 158.5834580233449 - 0.6693707936218369'\n",
      "47 - random_44 - deep - 148.39711365359375 - 163.68551773043828 - 172.85278245711942 - 138.85642161832996 - 170.60551890433908 - 158.8804664285704 - 0.6687515635045765'\n",
      "48 - random_56 - deep - 145.7448183184408 - 149.75511053184871 - 151.73036057003688 - 132.3274281880721 - 218.6768508856179 - 159.64310852601199 - 0.6671615379459803'\n",
      "49 - random_17 - deep - 144.94666282045105 - 183.60079701588978 - 151.14859541977103 - 133.23641724145713 - 188.5515621501286 - 160.29666370621445 - 0.6657989467069694'\n",
      "50 - random_7 - deep - 151.64223659632088 - 155.10397609809093 - 165.97125007066458 - 176.81070711976196 - 153.88882547953264 - 160.6822792508325 - 0.664994980372313'\n",
      "51 - random_45 - deep - 161.86059964139375 - 164.5138501291441 - 174.24633187338057 - 142.50278724771158 - 166.75869967127477 - 161.97821719709586 - 0.6622930911587146'\n",
      "52 - random_16 - deep - 169.35776610852145 - 185.41757143566403 - 166.89483514429926 - 145.3030489203738 - 160.2569451257676 - 165.44907279212296 - 0.6550567359603807'\n",
      "53 - random_22 - deep - 175.57371266072713 - 154.86078630526336 - 167.8061403939305 - 169.48919913119056 - 162.1374607246463 - 165.97349783560256 - 0.6539633669665921'\n",
      "54 - random_1 - deep - 161.12350827258865 - 144.26118596471136 - 165.96799771973096 - 192.24671431377726 - 168.71851978095927 - 166.4602206410644 - 0.6529486030252463'\n",
      "55 - random_98 - deep - 186.28815338921962 - 159.65621146400602 - 157.9569506539366 - 164.99110850394845 - 163.72338969309646 - 166.52368093492535 - 0.6528162952369228'\n",
      "56 - random_19 - deep - 166.27871105924078 - 156.45464102980185 - 188.3210877165082 - 161.82390342611654 - 162.3632909035196 - 167.04951569928306 - 0.651719987128923'\n",
      "57 - random_79 - deep - 145.949127256763 - 143.59269041577426 - 157.20897991269666 - 260.42908010677417 - 138.51477217473902 - 169.13165067791914 - 0.6473789628875591'\n",
      "58 - random_21 - deep - 182.35615583029633 - 153.01192431801726 - 164.3069572242778 - 138.46614069211668 - 215.37528136254502 - 170.70180058761753 - 0.6441053716504334'\n",
      "59 - random_59 - deep - 160.19059733738067 - 188.06666404756157 - 147.96422720155675 - 125.67558226293447 - 240.817212831788 - 172.5402877785584 - 0.6402723264611443'\n",
      "60 - random_67 - deep - 205.24045169603775 - 213.70926477241173 - 161.0261890615041 - 134.85159571030562 - 151.52847057402062 - 173.27841316296212 - 0.638733415574127'\n",
      "61 - random_62 - deep - 163.09446299826948 - 156.1511381866693 - 162.85520207588732 - 127.33779319222806 - 265.3790267083396 - 174.95838932791807 - 0.6352308485783194'\n",
      "62 - random_30 - deep - 173.3533757192043 - 185.50183336135507 - 186.08602185812836 - 164.8059586871858 - 170.15860179521027 - 175.98319842292648 - 0.6330942334357622'\n",
      "63 - random_93 - deep - 155.2179052699592 - 299.11956988485116 - 160.09105209368892 - 132.66151291754494 - 140.3846710223396 - 177.50477686591913 - 0.6299219084069139'\n",
      "64 - random_63 - deep - 191.53762106617984 - 200.61696854964944 - 153.1517904083673 - 210.61870356052577 - 143.03606591562405 - 179.79294112922187 - 0.6251513355876019'\n",
      "65 - random_14 - knn_tta_r_n=500 - 187.71453983524384 - 206.06129853338672 - 212.20214917195315 - 145.47545007832045 - 157.90090873146693 - 181.87811340540728 - 0.620803978829336'\n",
      "66 - random_55 - deep - 146.68073118240733 - 152.2477806562711 - 157.91743109279145 - 259.19905293660435 - 194.31572880922388 - 182.0614203569256 - 0.6204218039196103'\n",
      "67 - random_14 - knn_ttm_r_n=500 - 189.46214001552408 - 208.6281826395261 - 213.10010137885894 - 149.80042389492525 - 159.04336984380464 - 184.0139442257591 - 0.6163510046159637'\n",
      "68 - random_14 - knn_ttm_r_n=1000 - 191.6256516468028 - 210.1946975474986 - 211.91810744475575 - 150.2395177716682 - 158.26844151197892 - 184.4565303472776 - 0.6154282608445287'\n",
      "69 - random_83 - knn_ttm_r_n=500 - 189.18802985991798 - 191.5799269794626 - 213.28841999494298 - 161.10537939429128 - 168.7474809931745 - 184.78661293511763 - 0.6147400746652073'\n",
      "70 - random_83 - knn_tta_r_n=500 - 190.1096032036395 - 194.49048980986203 - 213.4792739038009 - 163.76484935603037 - 167.74263359887445 - 185.9222094388593 - 0.6123724798633285'\n",
      "71 - random_14 - knn_tta_r_n=1000 - 195.64592752621365 - 212.97374419297563 - 213.87902888121025 - 149.49662951853352 - 160.00319696643285 - 186.40730167104525 - 0.6113611154891243'\n",
      "72 - random_83 - knn_ttm_r_n=1000 - 193.11344651157802 - 194.02498483325476 - 214.5692628275438 - 165.03732790933853 - 168.3292081303025 - 187.0197258163199 - 0.6100842779697063'\n",
      "73 - random_42 - deep - 251.2475656430451 - 153.05805732164114 - 152.6498317661297 - 174.24853471662104 - 214.23556274011068 - 189.08667258193154 - 0.6057749195805249'\n",
      "74 - random_83 - knn_tta_n=500 - 193.0480937612258 - 197.17332588953283 - 218.35136023739497 - 163.47095376559406 - 175.8027387962533 - 189.57407846892949 - 0.6047587314022791'\n",
      "75 - random_83 - knn_tta_r_n=1000 - 196.53207914282643 - 198.94094806849355 - 217.3931751074081 - 167.9999468156086 - 170.134139468088 - 190.20512984686886 - 0.6034430581352297'\n",
      "76 - random_14 - knn_tta_n=1000 - 193.1246761114278 - 217.86231572496948 - 219.21747971038232 - 159.06826434658458 - 165.50578204330742 - 190.96258434585883 - 0.6018638481530226'\n",
      "77 - random_83 - knn_tta_n=1000 - 197.28995267479215 - 200.8302001660019 - 221.87697203156083 - 164.1226121203858 - 174.48456082348082 - 191.72623992400068 - 0.6002717095974026'\n",
      "78 - random_14 - knn_tta_n=500 - 189.860903002901 - 221.07604980702828 - 222.67681266643882 - 165.65965577461 - 170.82148908671743 - 194.02516913333457 - 0.5954786930391689'\n",
      "79 - random_18 - knn_tta_r_n=500 - 208.0399305338146 - 223.8007767328044 - 227.47823333960355 - 161.5864310715255 - 175.00642292604675 - 199.18977184093708 - 0.5847110599194827'\n",
      "80 - random_18 - knn_ttm_r_n=500 - 208.79559801783677 - 229.41726953692717 - 225.34326099277226 - 161.22724186648108 - 175.17985229937776 - 200.00027423125692 - 0.5830212508720711'\n",
      "81 - random_9 - deep - 310.38463308314897 - 143.14187168059553 - 154.41544005880831 - 245.6378944644264 - 147.49568408906532 - 200.21598038757668 - 0.5825715271637883'\n",
      "82 - random_83 - knn_tta_r_n=100 - 209.61076435456718 - 213.88620385019084 - 232.74962298827577 - 171.48581588449605 - 182.8714946313296 - 202.126766691246 - 0.578587746121118'\n",
      "83 - random_18 - knn_tta_n=500 - 209.17356567927868 - 226.2677571371609 - 236.11650228065045 - 160.02808532827527 - 186.50424071854454 - 203.62531496830084 - 0.575463436474664'\n",
      "84 - random_18 - knn_tta_r_n=100 - 205.28173427940965 - 237.05724805930677 - 227.87877318379466 - 167.65879967751647 - 189.863585978221 - 205.5544573333115 - 0.5714413851382658'\n",
      "85 - random_18 - knn_ttm_r_n=1000 - 214.0781292178369 - 236.34774083914488 - 238.72943422015135 - 162.6460694013519 - 176.93471561190773 - 205.75584784136223 - 0.571021507903317'\n",
      "86 - random_76 - deep - 152.16003187301993 - 144.8255891851415 - 174.76287267418343 - 407.24086128592063 - 154.56537553070544 - 206.69313749800142 - 0.5690673613340134'\n",
      "87 - random_18 - knn_tta_r_n=1000 - 214.25840013566702 - 232.37574631010017 - 243.1281410125599 - 163.6907233337789 - 180.40307218991572 - 206.7795507662914 - 0.5688871990042101'\n",
      "88 - random_18 - knn_tta_n=1000 - 208.79625834212453 - 230.32500948850037 - 243.93374464949105 - 159.83439106716844 - 193.11507358712637 - 207.20827000100908 - 0.5679933661786964'\n",
      "89 - random_83 - knn_ttm_n=1000 - 213.08196650813468 - 222.16103052601522 - 239.70511740759784 - 178.05694804780617 - 199.4762833213139 - 210.5014844876212 - 0.5611273733068581'\n",
      "90 - random_36 - deep - 142.64040199925103 - 465.0107623983016 - 149.59706328082527 - 144.28972853789952 - 151.4863744921186 - 210.61991914337602 - 0.5608804500684044'\n",
      "91 - random_18 - knn_ttm_r_n=100 - 209.7760721433845 - 238.58985284747433 - 240.5603252576465 - 179.5526618748993 - 195.25042956114993 - 212.75195121765466 - 0.5564353957300758'\n",
      "92 - random_95 - deep - 466.0357204590576 - 127.00927894560247 - 145.0699664243482 - 143.12668319280837 - 182.96160533305118 - 212.85260281028292 - 0.5562255482388943'\n",
      "93 - random_29 - knn_tta_r_n=100 - 226.19955297700685 - 244.78276584845776 - 242.93332876531656 - 174.74598223120188 - 181.9676911205726 - 214.13444909851057 - 0.5535530384970816'\n",
      "94 - random_83 - knn_ttm_n=500 - 217.562265442442 - 223.42132161238348 - 237.41776404076197 - 186.18630872218077 - 206.17463087054745 - 214.15677158740306 - 0.553506498543416'\n",
      "95 - random_14 - knn_ttm_n=1000 - 209.65670051060107 - 252.87927021909698 - 241.6757632697134 - 182.97912774952675 - 188.33844742750958 - 215.112929415812 - 0.551513013800501'\n",
      "96 - random_28 - deep - 142.84624130166642 - 513.7774482640093 - 150.717256714215 - 136.66736076144326 - 133.51756206480394 - 215.52447263281496 - 0.5506549911960563'\n",
      "97 - random_29 - knn_ttm_r_n=500 - 226.8897806239536 - 251.44404401972005 - 245.23786289417254 - 173.40733453240802 - 181.10480579961032 - 215.62597250914826 - 0.5504433749306027'\n",
      "98 - random_4 - knn_tta_r_n=1000 - 214.08271018378005 - 256.35438567498056 - 227.20252108073308 - 184.42177906852032 - 197.77015355779497 - 215.97227903439065 - 0.549721363612041'\n",
      "99 - random_14 - knn_tta_r_n=100 - 204.26174549338654 - 238.57373070575343 - 255.7297951945063 - 195.85425907321527 - 188.44712227253217 - 216.57919221591547 - 0.5484560158507232'\n",
      "100 - random_4 - knn_ttm_r_n=1000 - 217.87923506693338 - 250.3286125566725 - 229.33511405039107 - 188.5422756838926 - 197.57851142820974 - 216.73843134997188 - 0.5481240196312867'\n",
      "101 - random_90 - deep - 139.46011549566919 - 514.6729708501659 - 169.36498542195247 - 125.14263848239491 - 135.32623114019168 - 216.81416396538575 - 0.5479661254904169'\n",
      "102 - random_29 - knn_tta_r_n=500 - 228.52513838060702 - 254.9533336464781 - 246.93817730145773 - 173.670268093957 - 182.16533031231444 - 217.25988976065392 - 0.5470368357429434'\n",
      "103 - random_35 - deep - 465.99340326941933 - 142.59268921667328 - 176.4314055828971 - 146.57553641879116 - 158.82982911182052 - 218.10026291658392 - 0.545284749507962'\n",
      "104 - random_83 - knn_ttm_r_n=100 - 216.28114348563295 - 242.32129497822874 - 254.2922592654765 - 183.10314562732594 - 194.5181022290964 - 218.1102196140173 - 0.545263990780783'\n",
      "105 - random_29 - knn_tta_n=500 - 234.7541222888168 - 254.82894599849624 - 242.0770653795927 - 171.6415286786909 - 187.7595186946758 - 218.22147938878686 - 0.5450320262902841'\n",
      "106 - random_29 - knn_ttm_r_n=1000 - 230.17091505800104 - 256.47121594667834 - 249.9486609271306 - 175.08016053095935 - 182.14012830225934 - 218.77185303569777 - 0.5438845572894341'\n",
      "107 - random_4 - knn_tta_r_n=500 - 216.9916503919941 - 252.51545864654327 - 231.53966333456628 - 200.6091747686446 - 200.26219154935265 - 220.38841543642712 - 0.5405142010720023'\n",
      "108 - random_4 - knn_ttm_r_n=500 - 221.49866787148022 - 241.22865187071784 - 235.30566223456512 - 202.67741385371934 - 202.52080750683078 - 220.65057215191896 - 0.5399676329249263'\n",
      "109 - random_29 - knn_tta_r_n=1000 - 233.0724346841363 - 261.721647007979 - 255.0380184691766 - 176.17745001776086 - 185.7156983676025 - 222.35498574089632 - 0.5364141165657106'\n",
      "110 - random_14 - knn_ttm_n=500 - 216.12231273700704 - 256.32532584307626 - 242.37820964789134 - 196.8585889190796 - 200.50921756384034 - 222.44443232888253 - 0.5362276301895512'\n",
      "111 - random_29 - knn_tta_n=1000 - 235.77857916022717 - 264.0010784109145 - 250.22687770156895 - 173.28762699014956 - 189.0388830859857 - 222.47652227126483 - 0.5361607261611163'\n",
      "112 - random_29 - knn_ttm_r_n=100 - 235.00938852884175 - 251.758915194335 - 257.7865200203972 - 179.99612655873577 - 188.08002661141467 - 222.53543290075703 - 0.5360379039265448'\n",
      "113 - random_34 - knn_ttm_r_n=1000 - 225.4999041346448 - 253.2695354775592 - 259.58336206605856 - 189.0643342129082 - 187.96605521539368 - 223.08493329955772 - 0.5348922555527218'\n",
      "114 - random_34 - knn_tta_r_n=1000 - 227.6757174761676 - 249.50873671317956 - 261.7266267564397 - 189.64993939265727 - 190.28922720727667 - 223.77816194553182 - 0.5334469494661727'\n",
      "115 - random_4 - knn_tta_n=1000 - 218.83326696108935 - 267.55084218352454 - 232.40136010005253 - 192.74145788510253 - 210.7327415561331 - 224.4573855154155 - 0.5320308424351352'\n",
      "116 - random_34 - knn_tta_n=1000 - 233.55557915953588 - 252.7822572337298 - 263.90367061498335 - 192.62373269399015 - 192.88668150251075 - 227.15863941367112 - 0.5263990227993822'\n",
      "117 - random_34 - knn_tta_r_n=100 - 225.2945176000911 - 250.22814316894886 - 266.96522929949305 - 200.41461858880163 - 192.91922114218514 - 227.17166563495363 - 0.5263718645493392'\n",
      "118 - random_29 - knn_tta_n=100 - 245.30341102581917 - 255.90127424140192 - 251.27498065018344 - 188.4786875587858 - 199.14443944981642 - 228.02876907244027 - 0.5245848974033682'\n",
      "119 - random_34 - knn_ttm_r_n=500 - 249.0383327580696 - 250.90048573177117 - 263.83528299465445 - 190.4078728453053 - 187.33325524842925 - 228.31251008986143 - 0.5239933283418992'\n",
      "120 - random_18 - knn_ttm_n=500 - 229.70857394530634 - 253.56038266326513 - 268.76204584364626 - 180.35928195239995 - 211.24222579280828 - 228.73440453514502 - 0.5231137244576816'\n",
      "121 - random_34 - knn_tta_r_n=500 - 267.2711143994914 - 253.6278731143023 - 256.03560489486443 - 188.61800734666343 - 188.12424141436384 - 230.74553605917492 - 0.5189207346708173'\n",
      "122 - random_18 - knn_ttm_n=1000 - 225.85145713408417 - 263.50037214470365 - 280.64256697562234 - 169.4496659056724 - 215.64590313476367 - 231.0272262783473 - 0.5183334412999279'\n",
      "123 - random_18 - knn_tta_n=100 - 224.67358167394778 - 244.73579597064972 - 262.70971059789696 - 198.84433772776922 - 226.01220605314404 - 231.39967863185402 - 0.5175569187822867'\n",
      "124 - random_75 - knn_tta_r_n=500 - 243.68747095333967 - 272.8979613378985 - 265.6148008026111 - 184.2861891267186 - 192.95496123937272 - 231.8986613557368 - 0.5165165942485288'\n",
      "125 - random_14 - knn_ttm_r_n=100 - 217.96680038594036 - 264.34119866439437 - 280.70094207025 - 193.83362034307888 - 209.26728250943182 - 233.22957026284624 - 0.5137417943967645'\n",
      "126 - random_77 - knn_tta_r_n=1000 - 229.955658313192 - 295.1057126284699 - 266.72286539854946 - 177.08842706359877 - 199.98562110117018 - 233.78251364714237 - 0.5125889677738582'\n",
      "127 - random_75 - knn_ttm_r_n=500 - 241.96075242893266 - 282.94783004230095 - 267.6672622729363 - 182.7864295465074 - 194.38912732966494 - 233.96116776001855 - 0.5122164934420104'\n",
      "128 - random_77 - knn_ttm_r_n=1000 - 229.6632682842589 - 302.10563599484726 - 263.7031140102812 - 177.23348129308573 - 197.2786679129096 - 234.00805172994083 - 0.5121187454803763'\n",
      "129 - random_4 - knn_tta_n=500 - 230.0105339793437 - 249.02710579681653 - 246.46937203778901 - 221.2623646869877 - 223.90049283059037 - 234.1367465880401 - 0.5118504307435305'\n",
      "130 - random_75 - knn_ttm_r_n=1000 - 247.612370275324 - 279.6244325297912 - 269.7790912693826 - 185.76511307134908 - 192.67747916860614 - 235.10270659953835 - 0.5098365095184206'\n",
      "131 - random_75 - knn_tta_r_n=1000 - 250.49946883331182 - 279.2714950841362 - 271.2603935968833 - 187.68737735389243 - 194.2134792721954 - 236.59739590969068 - 0.5067202453968948'\n",
      "132 - random_51 - deep - 325.73920026938214 - 385.0494466963541 - 170.60847450947432 - 145.6590373209831 - 157.09753128546342 - 236.85125326279024 - 0.5061909806228231'\n",
      "133 - random_75 - knn_tta_n=500 - 254.81858680277006 - 281.65314018522963 - 264.3314185382252 - 185.43066149673712 - 203.2464152714561 - 237.90649867851033 - 0.5039909089641299'\n",
      "134 - random_75 - knn_tta_n=1000 - 251.56350051535534 - 285.33832865556343 - 269.2166274552497 - 187.83512131048911 - 198.15950453755656 - 238.43351900380014 - 0.5028921290907071'\n",
      "135 - random_34 - knn_ttm_r_n=100 - 234.08932361884936 - 265.9682804377369 - 285.70450234039595 - 209.15031980983574 - 202.02219449308532 - 239.39503662455726 - 0.5008874697655695'\n",
      "136 - random_83 - knn_tta_n=100 - 236.7436696916658 - 244.14404067949633 - 258.52129654470264 - 222.8229880556616 - 238.0420296034597 - 240.05711435843546 - 0.4995071099317687'\n",
      "137 - random_29 - knn_ttm_n=500 - 255.87779410980787 - 276.96433362476705 - 260.473793865401 - 194.74095349212857 - 212.62129734875745 - 240.14438392032596 - 0.49932516241747693'\n",
      "138 - random_75 - knn_tta_r_n=100 - 245.87406418832734 - 296.82438861950067 - 268.25525112869065 - 187.13102791659264 - 204.78281085901216 - 240.58421695215816 - 0.49840815853763987'\n",
      "139 - random_29 - knn_ttm_n=1000 - 253.90173410049036 - 283.9357908916115 - 263.93821745643487 - 191.5095160823402 - 211.50949874279218 - 240.96841970003373 - 0.4976071377298613'\n",
      "140 - random_77 - knn_ttm_r_n=500 - 225.49301341677668 - 356.0779943843683 - 252.3634070572419 - 179.10043763384513 - 197.370632260474 - 242.0940204023601 - 0.4952603830832609'\n",
      "141 - random_74 - knn_tta_r_n=1000 - 227.6117127247814 - 294.5679026380533 - 323.2967049246506 - 182.15187394275574 - 191.2149462472975 - 243.78232909586785 - 0.4917404436738445'\n",
      "142 - random_77 - knn_tta_r_n=500 - 227.4981060581614 - 358.2463473710903 - 254.6399511294259 - 177.73324987110288 - 202.12858017745793 - 244.06223584065978 - 0.491156868652438'\n",
      "143 - random_71 - knn_tta_r_n=500 - 262.02025474731306 - 270.79384116531344 - 328.45683447448806 - 184.6354188607036 - 185.42396248179654 - 246.28075966301753 - 0.48653148855277084'\n",
      "144 - random_71 - knn_ttm_r_n=500 - 262.1208768497714 - 275.03522921932745 - 329.64041270617963 - 185.01867052652787 - 184.25770227384538 - 247.22959724994732 - 0.4845532657146058'\n",
      "145 - random_75 - knn_ttm_r_n=100 - 248.81292120303857 - 322.459487904225 - 276.5535986733165 - 193.97412457043603 - 208.63666195229348 - 250.09906700073134 - 0.4785707343808794'\n",
      "146 - random_71 - knn_ttm_r_n=1000 - 266.35917770309993 - 279.22345798436544 - 335.1910608351806 - 185.37759248224953 - 186.24893130832842 - 250.49556471119087 - 0.47774407991765433'\n",
      "147 - random_71 - knn_tta_r_n=1000 - 269.60902697904174 - 279.0734652342308 - 335.4830069318886 - 185.89976596833483 - 188.35141246273008 - 251.69882999413628 - 0.47523540309468415'\n",
      "148 - random_71 - knn_tta_n=1000 - 269.8845815065126 - 279.401860027333 - 339.57411656472823 - 186.556707744335 - 187.453962199139 - 252.5899827764491 - 0.4733774467799793'\n",
      "149 - random_73 - knn_ttm_r_n=1000 - 247.4561296253413 - 358.91553268550956 - 280.76128874530684 - 187.79785349418978 - 198.78372501776542 - 254.75765501158432 - 0.4688580866910982'\n",
      "150 - random_34 - knn_tta_n=100 - 263.93537326229205 - 282.7005012296638 - 282.4888794649999 - 227.7375020806243 - 220.23213040353974 - 255.4264217646541 - 0.46746378098214225'\n",
      "151 - random_4 - knn_ttm_n=1000 - 244.91713037880618 - 280.5122230589261 - 269.5695324839102 - 233.7923851290128 - 260.0748484779057 - 257.77582551548113 - 0.4625655305123275'\n",
      "152 - random_39 - knn_ttm_r_n=1000 - 236.68488052201388 - 311.62444055048144 - 322.3355003768998 - 200.35356963102168 - 221.81461597790505 - 258.57399670954203 - 0.4609014306636213'\n",
      "153 - random_77 - knn_tta_n=1000 - 235.80302031698494 - 400.7600872155384 - 273.4403579098581 - 178.92892431515597 - 210.34515553535672 - 259.8711621172932 - 0.4581969823261621'\n",
      "154 - random_34 - knn_ttm_n=1000 - 263.9707331173197 - 304.1851798739939 - 312.0804582010333 - 208.4552630491353 - 210.71910416271194 - 259.89421895506786 - 0.4581489113352043'\n",
      "155 - random_39 - knn_tta_r_n=1000 - 235.5953799177511 - 317.6217646387703 - 337.0386807826898 - 199.88115940767756 - 211.14352140252646 - 260.26924025804215 - 0.4573670328382291'\n",
      "156 - random_39 - knn_tta_r_n=500 - 248.83954199368375 - 299.6480036497851 - 328.1205930527767 - 198.49700478622876 - 229.1574563598824 - 260.8638064893871 - 0.45612742712082277'\n",
      "157 - random_39 - knn_ttm_r_n=500 - 249.15828533736268 - 302.6160854568904 - 317.1210487545441 - 201.36249886171152 - 235.70188633972722 - 261.20219970400126 - 0.45542191419147526'\n",
      "158 - random_91 - knn_ttm_r_n=1000 - 257.9660583852562 - 337.1852132896841 - 324.1304685993219 - 191.48789252893067 - 195.4554722997083 - 261.26128727249585 - 0.45529872305839014'\n",
      "159 - random_91 - knn_tta_r_n=1000 - 258.104047603575 - 340.878177534841 - 326.79778145121867 - 191.28367568384922 - 197.3538350707127 - 262.89995966662923 - 0.4518822699172004'\n",
      "160 - random_82 - knn_tta_r_n=1000 - 263.1933966023805 - 350.3715367286042 - 308.13642447616235 - 193.45052845968263 - 199.96027474955545 - 263.03834892728975 - 0.45159374340880054'\n",
      "161 - random_29 - knn_ttm_n=100 - 288.27210072307867 - 285.71329508234106 - 280.3698292656951 - 226.2490995973874 - 234.79453156191488 - 263.0875854680122 - 0.45149109059374426'\n",
      "162 - random_82 - knn_ttm_r_n=1000 - 265.09690701582514 - 344.23501177508194 - 311.79111167282656 - 196.03896292643051 - 203.70618929675447 - 264.1890694092008 - 0.44919461676266226'\n",
      "163 - random_99 - knn_tta_r_n=500 - 263.230155208942 - 337.59173597517514 - 335.162485616775 - 202.5255647697597 - 186.81572485730788 - 265.0820286386393 - 0.4473328942028072'\n",
      "164 - random_91 - knn_tta_n=1000 - 257.4282713275391 - 354.4070257819995 - 323.6752283331261 - 198.26170949173206 - 201.89542637971707 - 267.14962609801466 - 0.4430221791019192'\n",
      "165 - random_27 - deep - 224.41219365074738 - 271.90993467261137 - 276.769445029146 - 216.84801762501877 - 348.33531820931495 - 267.6513971490468 - 0.4419760413323257'\n",
      "166 - random_34 - knn_tta_n=500 - 438.8117973075395 - 254.83410365956144 - 258.41638679792277 - 195.32637240368197 - 193.40322258173404 - 268.1760877175084 - 0.4408821186256551'\n",
      "167 - random_99 - knn_tta_r_n=1000 - 271.24776273618295 - 341.83566193999894 - 345.878772985818 - 197.46853480189324 - 190.38743051830824 - 269.3817378766361 - 0.4383684695960658'\n",
      "168 - random_75 - knn_ttm_n=1000 - 279.63475895629057 - 335.9742726914214 - 299.9988328130643 - 205.40951638459066 - 229.68409727419655 - 270.15291856614107 - 0.43676064200434184'\n",
      "169 - random_99 - knn_ttm_r_n=500 - 257.12200945578314 - 345.95828084417906 - 337.0510582093592 - 224.46257795541052 - 187.43253597734855 - 270.4207629637604 - 0.43620221566063044'\n",
      "170 - random_99 - knn_ttm_r_n=1000 - 264.07962115980985 - 347.4097383146263 - 344.7443792514424 - 208.22724147990252 - 188.1607989647713 - 270.5417158090563 - 0.43595004217572497'\n",
      "171 - random_14 - knn_tta_n=100 - 255.3145844729762 - 279.20423186264804 - 291.8109116470141 - 267.3241745608758 - 260.7188135562656 - 270.87618801754655 - 0.4352527041163128'\n",
      "172 - random_10 - knn_tta_r_n=500 - 280.9305360017904 - 352.27873487355777 - 324.9231029241454 - 199.02017856925292 - 199.12044950702148 - 271.2719252968714 - 0.4344276350690306'\n",
      "173 - random_10 - knn_tta_r_n=1000 - 289.2623108106743 - 348.73772350620476 - 328.5410794605765 - 194.9251405273615 - 196.9666054905118 - 271.70475045395364 - 0.43352524184339647'\n",
      "174 - random_99 - knn_tta_n=1000 - 279.1435485716598 - 344.32218414309597 - 347.8210107388872 - 192.3367651741181 - 195.11151613103888 - 271.76573118824126 - 0.433398103666202'\n",
      "175 - random_71 - knn_tta_n=500 - 264.68598913645695 - 309.2070043811392 - 414.03011769156046 - 186.5670586337819 - 185.92646350683216 - 272.10392826976204 - 0.4326929996529536'\n",
      "176 - random_73 - knn_tta_r_n=1000 - 246.41159306560905 - 360.1544745084409 - 280.21300560104555 - 276.1272634922361 - 198.6486484316218 - 272.3193788849192 - 0.4322438086288293'\n",
      "177 - random_75 - knn_ttm_n=500 - 278.64582933289216 - 332.04516232824045 - 301.63339918827387 - 210.69926614599788 - 242.70559963951402 - 273.15699819328256 - 0.4304974637661073'\n",
      "178 - random_24 - knn_ttm_r_n=500 - 273.60607716839326 - 336.54328687072325 - 351.48283232758814 - 207.48568964121867 - 197.2176239791331 - 273.2841223850717 - 0.4302324236971379'\n",
      "179 - random_10 - knn_ttm_r_n=1000 - 286.9293913447842 - 353.6418593073849 - 331.2860490329943 - 197.0719214540474 - 197.87320188625478 - 273.37869843515074 - 0.4300352429522065'\n",
      "180 - random_6 - deep - 466.0828696321283 - 141.67080462386528 - 387.9102466539773 - 157.05710355431236 - 215.88066088251708 - 273.7412787156305 - 0.4292793027544586'\n",
      "181 - random_10 - knn_ttm_r_n=500 - 280.68025841302733 - 352.99829263643926 - 331.5160656547889 - 207.75296937369248 - 199.78455666308056 - 274.56341586742565 - 0.4275652363740713'\n",
      "182 - random_24 - knn_tta_r_n=500 - 278.73000342558515 - 352.1285332345076 - 342.4011783522212 - 206.2179837515963 - 195.91614797706538 - 275.096532867572 - 0.42645374559879956'\n",
      "183 - random_24 - knn_tta_r_n=1000 - 273.7349460100691 - 350.09408541615835 - 324.9551378202189 - 201.380878743828 - 228.88977533798325 - 275.82552740119087 - 0.42493387153903694'\n",
      "184 - random_82 - knn_tta_n=1000 - 284.71245255266365 - 358.7666772052579 - 321.89624367006434 - 194.623061858108 - 222.18618433686677 - 276.45325232992684 - 0.4236251335556175'\n",
      "185 - random_75 - knn_tta_n=100 - 293.0260947481369 - 326.37932885664026 - 292.17305755141376 - 221.3372434358871 - 249.56433875781966 - 276.5058639172069 - 0.4235154441367506'\n",
      "186 - random_99 - knn_tta_n=500 - 269.8795847849422 - 341.23347281927556 - 365.28365114585364 - 216.4675712453452 - 193.9839035793165 - 277.3869519433884 - 0.421678471740383'\n",
      "187 - random_71 - knn_ttm_n=500 - 293.8603074025684 - 309.69828862104674 - 372.2406190493108 - 206.11629054610592 - 205.48327662373816 - 277.4969603301966 - 0.4214491162572409'\n",
      "188 - random_10 - knn_tta_n=1000 - 302.034052518448 - 358.4886482373253 - 331.79632637255605 - 198.1817618059117 - 199.6783050161543 - 278.05480493801593 - 0.42028607111807614'\n",
      "189 - random_82 - knn_ttm_r_n=500 - 284.253856602578 - 373.31621595001826 - 316.38737574344793 - 202.04354632611566 - 214.59902014291012 - 278.13675531584096 - 0.4201152135221684'\n",
      "190 - random_24 - knn_ttm_r_n=1000 - 273.44794720557917 - 361.3019512767756 - 331.274429526896 - 201.5495308110134 - 227.56445062984832 - 279.0431354700464 - 0.41822550979857265'\n",
      "191 - random_4 - knn_ttm_n=500 - 266.24839605969055 - 273.1763907569212 - 290.9623016075356 - 284.2206570375801 - 287.27649524411544 - 280.37555887487804 - 0.4154475523843092'\n",
      "192 - random_18 - knn_ttm_n=100 - 269.6320916482481 - 292.6008123587981 - 308.68195342278256 - 256.0658331018579 - 284.85762148465585 - 282.3705199419965 - 0.41128827623569686'\n",
      "193 - random_10 - knn_tta_r_n=100 - 283.22599137337886 - 354.4986290393138 - 345.31955097080106 - 219.61145521530273 - 212.87719017914714 - 283.1226109352499 - 0.40972024857772193'\n",
      "194 - random_10 - knn_tta_n=500 - 299.12629911752845 - 362.9957971715887 - 334.0273038526479 - 211.59428304685625 - 208.18242162882007 - 283.2028129156365 - 0.4095530361997004'\n",
      "195 - random_39 - knn_tta_n=500 - 252.422056976029 - 309.7116683859139 - 364.8760358697304 - 202.38064279700333 - 292.3955653776772 - 284.3660668177388 - 0.40712777874002337'\n",
      "196 - random_24 - knn_tta_n=1000 - 283.92844997474634 - 357.64672617896264 - 343.2371360291699 - 208.0872406677408 - 229.86352917981355 - 284.568355571209 - 0.4067060287613853'\n",
      "197 - random_39 - knn_tta_n=1000 - 238.78870902649015 - 317.9988194913677 - 356.38122927330215 - 195.981438677582 - 317.7866107156379 - 285.3942025113366 - 0.40498422800191547'\n",
      "198 - random_11 - deep - 152.87669865929158 - 498.9816036487527 - 156.25594332808853 - 472.58464118069105 - 150.75741988842657 - 286.285171241492 - 0.4031266555463996'\n",
      "199 - random_70 - deep - 187.49950451499055 - 160.10357839931038 - 152.40089890881077 - 472.4525561201043 - 467.87971077102713 - 288.0235480358472 - 0.3995023296105932'\n",
      "200 - random_71 - knn_tta_n=100 - 300.1762732485038 - 309.1418003929666 - 413.297107673363 - 210.91163286651306 - 210.92176881586946 - 288.9084308717961 - 0.39765744531860814'\n",
      "201 - random_94 - knn_tta_r_n=1000 - 280.03372969078436 - 368.4735860848467 - 382.1822269046894 - 198.53972515725965 - 216.58728444250832 - 289.1828951927647 - 0.3970852171570337'\n",
      "202 - random_94 - knn_ttm_r_n=1000 - 295.4148698488621 - 369.49607130384265 - 378.1237418398865 - 198.9116547138857 - 216.1944491172436 - 291.6483361972052 - 0.3919450416746161'\n",
      "203 - random_10 - knn_ttm_r_n=100 - 291.60846539714964 - 363.0338554528446 - 364.6817175124828 - 216.7501641997311 - 222.0971300018211 - 291.65159775471443 - 0.391938241683088'\n",
      "204 - random_94 - knn_ttm_r_n=500 - 310.97978488925935 - 372.14144833528235 - 363.93023370179077 - 197.75781849737854 - 216.51135242483076 - 292.28455947709074 - 0.390618585556331'\n",
      "205 - random_82 - knn_tta_r_n=500 - 278.643330617946 - 448.31849704057066 - 318.8016806616206 - 199.43258291691404 - 219.55255959915996 - 292.96976068660126 - 0.3891900157989102'\n",
      "206 - random_24 - knn_tta_n=500 - 296.9736437878641 - 340.5217404260566 - 394.37615700217395 - 224.99827116294915 - 209.16018949369325 - 293.2242715302047 - 0.3886593884604569'\n",
      "207 - random_72 - deep - 205.18874024114854 - 243.90843077112117 - 635.4182856421879 - 232.66252412830366 - 149.32667355577485 - 293.3254871819242 - 0.3884483650043056'\n",
      "208 - random_94 - knn_tta_r_n=500 - 341.7994038767918 - 365.27203933079056 - 367.11861718889946 - 196.66422738756842 - 219.17675532121717 - 298.0278300580549 - 0.37864449306091486'\n",
      "209 - random_34 - knn_ttm_n=500 - 450.5375463025518 - 304.06687576674193 - 306.5183556608649 - 217.6637928776446 - 212.00828309856962 - 298.17896904506745 - 0.37832938476423283'\n",
      "210 - random_94 - knn_tta_n=1000 - 305.39680135551356 - 379.31471344967366 - 383.3811096285867 - 199.202473400576 - 223.71921781439127 - 298.2236820467103 - 0.3782361630345805'\n",
      "211 - random_83 - knn_ttm_n=100 - 307.40429865906765 - 299.1929464562063 - 305.6812208956119 - 287.7507759139222 - 301.5118495402137 - 300.30958080484066 - 0.3738872917226992'\n",
      "212 - random_71 - knn_ttm_n=1000 - 295.7251197571107 - 356.2781970858691 - 447.8374238040658 - 202.3082716116631 - 202.84858700582006 - 301.0231418595166 - 0.37239959478253826'\n",
      "213 - random_71 - knn_tta_r_n=100 - 271.34668387178914 - 273.506082227993 - 336.5886695646545 - 191.231635277488 - 432.754430122364 - 301.08288230034435 - 0.3722750424818755'\n",
      "214 - random_23 - deep - 181.14561097866488 - 514.9816022025087 - 170.038321487619 - 472.512864423113 - 173.26917229294062 - 302.384593748075 - 0.3695611162849547'\n",
      "215 - random_34 - knn_ttm_n=100 - 322.2798234886833 - 319.8086166020743 - 344.43196495556316 - 267.30727307098175 - 264.6801067658691 - 303.71060722673826 - 0.36679652272948216'\n",
      "216 - random_77 - knn_tta_n=500 - 236.48762913666204 - 580.3314755017387 - 263.14838092400186 - 187.3449883952348 - 255.2861784609689 - 304.53970027780633 - 0.3650679541828946'\n",
      "217 - random_8 - knn_tta_r_n=500 - 278.667369217526 - 423.4314840900156 - 418.50535344795975 - 204.29568048460192 - 215.20202457594317 - 308.04396847381366 - 0.35776193735568607'\n",
      "218 - random_8 - knn_tta_r_n=1000 - 282.2891716277767 - 421.95726969608336 - 426.44145591465707 - 203.55305469794004 - 215.6181331605324 - 309.99591067668587 - 0.35369235084510675'\n",
      "219 - random_8 - knn_ttm_r_n=500 - 280.50937980771045 - 429.65795887195287 - 429.4268157347122 - 205.24471781418964 - 215.2413472260034 - 312.0404703907027 - 0.3494296669295721'\n",
      "220 - random_8 - knn_tta_n=500 - 277.29179725818904 - 430.27779324198445 - 427.58623903889537 - 205.5947739823254 - 220.46380904254505 - 312.26669472711654 - 0.3489580138721815'\n",
      "221 - random_8 - knn_ttm_r_n=1000 - 282.26316409921816 - 426.53146691114074 - 435.16972476979777 - 204.21336867410187 - 215.46843070177948 - 312.7539252184975 - 0.3479421914608677'\n",
      "222 - random_8 - knn_tta_n=1000 - 279.9173598200028 - 431.9108953658907 - 434.26267571602045 - 203.6286930394734 - 218.76006412050586 - 313.7205389706007 - 0.34592690725792796'\n",
      "223 - random_4 - knn_tta_r_n=100 - 350.33504079836007 - 277.8752187558624 - 311.73292422740974 - 280.08277413905 - 352.9676133534437 - 314.59825188125234 - 0.34409697160917097'\n",
      "224 - random_91 - knn_ttm_n=1000 - 280.5834596164442 - 437.4187774090183 - 398.9099380396232 - 226.36844698622886 - 231.58181417435125 - 314.9931274363404 - 0.3432736991628972'\n",
      "225 - random_99 - knn_ttm_n=1000 - 289.1254038451597 - 420.9197803719122 - 417.67313300843557 - 218.6112573617339 - 236.045209438324 - 316.49635287457306 - 0.340139638145727'\n",
      "226 - random_77 - knn_tta_r_n=100 - 264.0135607672219 - 376.42070518373265 - 252.3951523773669 - 281.94190244741014 - 424.2436473431015 - 319.79500375666674 - 0.3332623109824915'\n",
      "227 - random_80 - knn_tta_r_n=1000 - 289.75522676246624 - 466.26437060312236 - 454.090320312375 - 190.41234645779295 - 206.83495574718975 - 321.5009286262651 - 0.3297056437680814'\n",
      "228 - random_77 - knn_ttm_n=1000 - 262.29259845961093 - 592.4668689727762 - 310.39892456208423 - 197.84656673753273 - 246.98980587925345 - 322.02285326225245 - 0.3286174878508479'\n",
      "229 - random_80 - knn_tta_r_n=500 - 286.528288836429 - 473.2378240004815 - 454.6259164677085 - 190.28416398732008 - 209.03379998262068 - 322.771539760557 - 0.32705655819336643'\n",
      "230 - random_37 - knn_tta_r_n=500 - 296.3431604530362 - 458.75185099541505 - 446.95749595379203 - 194.4169913818554 - 220.9112141976636 - 323.5039385977461 - 0.32552958653211383'\n",
      "231 - random_39 - knn_tta_r_n=100 - 252.25451594387613 - 324.7937201184207 - 346.5952453627984 - 212.6176012181227 - 481.90073748642067 - 323.626693365823 - 0.3252736562348233'\n",
      "232 - random_80 - knn_tta_n=1000 - 286.36629867650976 - 473.03957004767375 - 459.66468962282653 - 188.0805891907023 - 212.21308102187916 - 323.9025411422809 - 0.3246985437195068'\n",
      "233 - random_94 - knn_tta_n=500 - 393.96942542548646 - 408.9981313133009 - 379.02765096826784 - 200.61298813246322 - 239.1919817536586 - 324.3851063336061 - 0.32369244794976404'\n",
      "234 - random_80 - knn_ttm_r_n=1000 - 291.0631834565118 - 473.07352888089025 - 460.1548811962384 - 192.04379659341825 - 207.5680132762338 - 324.8106758266433 - 0.32280518199197594'\n",
      "235 - random_39 - knn_ttm_n=1000 - 267.17162367946617 - 370.3861918034069 - 398.01852649736327 - 217.15177598386157 - 372.51621552081036 - 325.0561185560827 - 0.32229346068210496'\n",
      "236 - random_80 - knn_ttm_r_n=500 - 289.3674817218505 - 473.6938314986278 - 463.78149913467263 - 192.06345718958696 - 209.50166452148864 - 325.71156377855374 - 0.32092692891089436'\n",
      "237 - random_37 - knn_ttm_r_n=500 - 297.19683772524337 - 461.0469648939932 - 455.0136776234552 - 194.48576890342358 - 221.28777484003732 - 325.8345065932045 - 0.3206706065570156'\n",
      "238 - random_37 - knn_tta_r_n=1000 - 296.8730976602831 - 462.1386050749432 - 457.8353281107873 - 193.66936435475725 - 220.20857466813695 - 326.17360456407613 - 0.3199636242877695'\n",
      "239 - random_80 - knn_tta_n=500 - 286.4610806516091 - 481.0832312797585 - 459.10622580149607 - 188.6352254603088 - 215.51637408782943 - 326.19020895810417 - 0.31992900593797746'\n",
      "240 - random_37 - knn_tta_r_n=100 - 298.9953962445912 - 461.9474701108643 - 454.004924524127 - 197.13845170903616 - 224.35435468715028 - 327.3160905859007 - 0.3175816655924243'\n",
      "241 - random_10 - knn_tta_n=100 - 322.59880322292105 - 389.0630604475178 - 401.844682360404 - 258.7588552186116 - 264.81970748681 - 327.43277303499906 - 0.31733839541763464'\n",
      "242 - random_37 - knn_ttm_r_n=1000 - 297.8445270714339 - 464.1068825860669 - 462.53655953266747 - 193.9359366614212 - 220.40315943350225 - 327.79435722238725 - 0.31658453184049173'\n",
      "243 - random_37 - knn_tta_n=500 - 299.0404470893362 - 470.19621727915336 - 449.0854968971713 - 195.94403530079987 - 225.92957494993715 - 328.0672599913098 - 0.3160155593445475'\n",
      "244 - random_14 - knn_ttm_n=100 - 329.51465358136744 - 330.55707492694273 - 353.61769716080437 - 303.5113762058603 - 324.9040389345543 - 328.42437948090065 - 0.31527100417515497'\n",
      "245 - random_37 - knn_tta_n=1000 - 298.7965064481012 - 473.44576303516106 - 461.1518609465442 - 194.71129306926514 - 223.82569664030234 - 330.41529344565305 - 0.3111201657933843'\n",
      "246 - random_37 - knn_ttm_r_n=100 - 298.8501958228238 - 467.8146673100593 - 467.59259833454706 - 196.746858460353 - 224.02240926224775 - 331.03429596688574 - 0.3098296130778805'\n",
      "247 - random_82 - knn_tta_n=500 - 288.4631865277943 - 506.44093086187945 - 372.4366074046899 - 210.95079077100866 - 290.7915938088877 - 333.83652957426034 - 0.30398726176682067'\n",
      "248 - random_82 - knn_ttm_n=1000 - 313.44301653256656 - 447.5019091676026 - 390.7436067103389 - 223.2053009496213 - 297.3882267144893 - 334.4742110424487 - 0.30265776548503165'\n",
      "249 - random_80 - knn_ttm_r_n=100 - 295.66308793265443 - 473.90335900466056 - 488.10956534651876 - 201.35037282480351 - 215.47513584328243 - 334.93066241667856 - 0.30170611417457394'\n",
      "250 - random_75 - knn_ttm_n=100 - 355.66613456347477 - 395.2670680035973 - 340.21409928984997 - 286.0534477002329 - 317.4562577034983 - 338.9403241807398 - 0.2933464069030173'\n",
      "251 - random_77 - knn_ttm_r_n=100 - 299.4412870071954 - 485.19698447396394 - 286.4949114905934 - 304.195848471615 - 328.30102548422974 - 340.73188623837143 - 0.2896111954956945'\n",
      "252 - random_37 - knn_tta_n=100 - 310.1286608274764 - 482.6391849106522 - 470.85253655461725 - 205.15762372417265 - 234.97412573718006 - 340.7793918018266 - 0.2895121515793684'\n",
      "253 - random_10 - knn_ttm_n=1000 - 345.73101727566996 - 473.9519771213547 - 427.0235943187357 - 226.68579260799476 - 231.35797682807967 - 340.97693546977945 - 0.28910029458628306'\n",
      "254 - random_32 - knn_tta_r_n=1000 - 316.70208002996594 - 466.7269924629301 - 461.4006846176774 - 226.43152093436723 - 234.4895330786638 - 341.17672879983627 - 0.28868374729317847'\n",
      "255 - random_32 - knn_tta_n=1000 - 312.83356784516855 - 471.65741813833023 - 463.1318335240447 - 226.64832766962516 - 233.8950872439934 - 341.6599747228085 - 0.2876762322722284'\n",
      "256 - random_99 - knn_ttm_n=500 - 296.27801234553624 - 418.67122792096455 - 504.25956404917247 - 253.47513384198695 - 235.84415804084156 - 341.72891120497053 - 0.28753250722879187'\n",
      "257 - random_32 - knn_tta_r_n=500 - 316.55014378115163 - 472.8448088100359 - 463.1616126653463 - 226.75464387570372 - 234.8139914390109 - 342.85193096327333 - 0.28519113356886594'\n",
      "258 - random_39 - knn_ttm_r_n=100 - 293.1888555270752 - 354.4753783541097 - 340.46745557895593 - 219.03362909079354 - 508.7146634007813 - 343.1710286356677 - 0.2845258497396508'\n",
      "259 - random_80 - knn_tta_r_n=100 - 293.73619705800184 - 476.675425368527 - 536.4710550575921 - 196.46121085736723 - 215.45449183763932 - 343.7927497967012 - 0.2832296289568016'\n",
      "260 - random_32 - knn_ttm_r_n=1000 - 318.8742667927167 - 471.1020926638748 - 466.79462703253415 - 226.6749130032989 - 235.50905131371678 - 343.8180390051027 - 0.2831769037166675'\n",
      "261 - random_10 - knn_ttm_n=500 - 336.35940507573974 - 467.054760636502 - 426.3309802319222 - 246.56039397078777 - 244.64778314766434 - 344.214326337245 - 0.28235068786927897'\n",
      "262 - random_24 - knn_ttm_n=1000 - 322.74455160080714 - 432.17336294850867 - 443.36125938322266 - 241.45318227568862 - 283.23222779854393 - 344.61265764181127 - 0.2815202105624104'\n",
      "263 - random_39 - knn_ttm_n=500 - 286.48069782747933 - 365.9914787625792 - 420.54183246776626 - 235.069720999817 - 425.24757419535695 - 346.67022283625994 - 0.27723041163924333'\n",
      "264 - random_25 - knn_ttm_r_n=1000 - 334.00972251432785 - 405.01326009279705 - 426.65251979819743 - 197.01428055947684 - 405.01703557219054 - 353.55397038101887 - 0.26287854911525965'\n",
      "265 - random_24 - knn_ttm_n=500 - 338.7355861347108 - 421.4311310049711 - 521.1305991116956 - 272.9892286087448 - 274.33545739536856 - 365.74649622871704 - 0.23745846308675478'\n",
      "266 - random_8 - knn_ttm_n=500 - 297.37984267976407 - 527.3165901100981 - 544.4912701316917 - 218.23290502553502 - 246.81364027066584 - 366.87908859158773 - 0.2350971315908008'\n",
      "267 - random_94 - knn_ttm_n=1000 - 389.08803344549904 - 493.7757788832927 - 488.86155813259313 - 210.5800044879389 - 252.39138631852407 - 366.9718624316207 - 0.23490370825717077'\n",
      "268 - random_39 - knn_tta_n=100 - 289.1915517326122 - 365.75983869196597 - 420.4841865247736 - 271.4976443138042 - 489.40775643412 - 367.2650311317186 - 0.23429248350600407'\n",
      "269 - random_8 - knn_ttm_n=1000 - 298.18052256209114 - 531.2269957404694 - 554.0729176835266 - 212.87502628475258 - 240.74498089969663 - 367.45383640442816 - 0.23389884511352788'\n",
      "270 - random_25 - knn_ttm_r_n=500 - 330.5883515778722 - 439.588222447992 - 427.4128863126895 - 232.05137659944867 - 408.3800140812828 - 367.6155438927718 - 0.23356170264473208'\n",
      "271 - random_47 - knn_ttm_r_n=1000 - 315.64006648874783 - 648.9219470734536 - 481.5450729108056 - 214.29715656367964 - 223.43637276818552 - 376.8060210029269 - 0.2144005606712457'\n",
      "272 - random_47 - knn_ttm_r_n=500 - 319.2912440819119 - 665.3324387103071 - 479.81350104883893 - 214.30881202358785 - 223.73201794341225 - 380.53435835690215 - 0.20662738409854797'\n",
      "273 - random_47 - knn_ttm_r_n=100 - 319.67245497677544 - 657.6333811787993 - 487.64580817270803 - 214.7452182741756 - 224.54246451840453 - 380.88655593755976 - 0.2058930905722366'\n",
      "274 - random_80 - knn_ttm_n=1000 - 308.44631604194035 - 585.6963528883468 - 587.6798280264519 - 193.77964920627753 - 240.86961046616827 - 383.3341856523675 - 0.2007900496852587'\n",
      "275 - random_37 - knn_ttm_n=500 - 325.0140483544063 - 577.5308774386091 - 549.2303821243289 - 210.06690923947264 - 259.79917547296736 - 384.36413481688925 - 0.19864271805814793'\n",
      "276 - random_37 - knn_ttm_n=1000 - 322.4027321905675 - 581.4380260854696 - 573.1337032288814 - 206.4639932988906 - 249.92842130285464 - 386.7114112630753 - 0.193748902786393'\n",
      "277 - random_80 - knn_ttm_n=500 - 315.33850464913627 - 603.0071495979086 - 585.7776640373244 - 199.16063365614403 - 249.38836891765203 - 390.57436815888485 - 0.18569505915772244'\n",
      "278 - random_4 - knn_ttm_r_n=100 - 399.0086899719572 - 335.8909681399868 - 476.45803770214667 - 405.8320351123982 - 351.9924524760673 - 393.84001863008194 - 0.17888653425043022'\n",
      "279 - random_25 - knn_tta_r_n=1000 - 346.2856960356394 - 628.4001709298363 - 424.3465395696706 - 200.04036641695143 - 391.9172399778321 - 398.22253617518277 - 0.16974946335884566'\n",
      "280 - random_78 - knn_ttm_r_n=1000 - 249.33301827245415 - 442.8707373726608 - 896.0634953204737 - 218.38383072162907 - 203.3183888834468 - 402.03977021741184 - 0.16179094689092932'\n",
      "281 - random_80 - knn_tta_n=100 - 309.1335982949071 - 516.1592197985849 - 750.5459254430565 - 209.24936728625815 - 237.43704512243062 - 404.54851176626687 - 0.15656049449806286'\n",
      "282 - random_77 - knn_ttm_n=500 - 262.24269758359725 - 906.3827588899535 - 292.1200712306195 - 213.8997200917236 - 352.80965949875537 - 405.5202953414845 - 0.15453443177802484'\n",
      "283 - random_32 - knn_tta_n=500 - 328.1635518329993 - 677.4806713502894 - 569.6655317535849 - 227.9871571977735 - 234.75062145423072 - 407.6518061579272 - 0.15009046430143425'\n",
      "284 - random_94 - knn_ttm_n=500 - 397.8902999711237 - 624.9780654244979 - 520.0890387214648 - 218.0978057010472 - 284.6483796958197 - 409.17858364746945 - 0.14690729982712014'\n",
      "285 - random_37 - knn_ttm_n=100 - 348.20700590827 - 606.6074311477277 - 574.8095244337253 - 230.1945210827601 - 286.32376441553896 - 409.26468348056335 - 0.14672779106973666'\n",
      "286 - random_32 - knn_ttm_n=1000 - 337.3493567359218 - 618.8751106584825 - 611.0579536839148 - 233.99849684733383 - 251.55742705516545 - 410.60794013670005 - 0.14392724750855135'\n",
      "287 - random_82 - knn_ttm_n=500 - 350.70945984432564 - 605.6472391024545 - 476.13401470923094 - 252.31630163705455 - 414.2836098145478 - 419.83889021276127 - 0.12468172381728027'\n",
      "288 - random_10 - knn_ttm_n=100 - 388.65244315332876 - 513.0496348362481 - 559.1625795641728 - 329.86357105468073 - 320.6179095337037 - 422.2925153968978 - 0.11956618303093602'\n",
      "289 - random_78 - knn_tta_r_n=1000 - 249.98701312288338 - 481.6595173276427 - 957.8290867212734 - 227.7283110562679 - 203.77300684412225 - 424.2454157503228 - 0.11549459888100089'\n",
      "290 - random_77 - knn_tta_n=100 - 332.20673520476663 - 430.4444852813405 - 286.6898571036596 - 353.8378791289107 - 761.1521950703302 - 432.83631824769907 - 0.09758350455373066'\n",
      "291 - random_25 - knn_tta_r_n=500 - 341.9878628025277 - 780.4000546634004 - 426.75815669825886 - 218.38725048225325 - 397.7211852544172 - 433.08090238437444 - 0.09707357331608901'\n",
      "292 - random_25 - knn_tta_n=500 - 443.30440000466194 - 679.5890658257181 - 460.137164872991 - 305.7260187964122 - 353.45258652697345 - 448.47037295707185 - 0.06498820636441927'\n",
      "293 - random_25 - knn_tta_n=1000 - 441.91940021829987 - 783.4043906041614 - 450.9899186008054 - 218.91429493242688 - 347.37998683437917 - 448.56128969543795 - 0.06479865488513059'\n",
      "294 - random_81 - knn_tta_r_n=1000 - 610.7455030350105 - 673.0108515513554 - 538.9430823789393 - 195.33857443738304 - 242.97032293710046 - 452.2576004376638 - 0.057092250303408254'\n",
      "295 - random_71 - knn_ttm_r_n=100 - 1053.9784476490522 - 290.88706791206243 - 336.4843428398826 - 200.03713347399102 - 486.4383206057986 - 473.59634230785935 - 0.012603301839720138'\n",
      "296 - random_89 - deep - 466.10016369833943 - 513.9313962097717 - 477.69780327076677 - 472.3927264265081 - 467.86279575306685 - 479.5992494363184 - 8.789569117728657e-05'\n",
      "297 - random_68 - deep - 466.5929696415453 - 516.1761393326803 - 477.69639091285745 - 472.39263967305675 - 467.87135232510974 - 480.14830461973656 - -0.0010568244569015839'\n",
      "298 - random_71 - knn_ttm_n=100 - 1139.7039753141141 - 325.23828309690487 - 385.0924905973223 - 256.5623652500062 - 312.45541315429807 - 483.8583397838084 - -0.008791843179568382'\n",
      "299 - random_47 - knn_tta_r_n=1000 - 314.75342892321 - 1200.0823690379991 - 476.20153746791004 - 214.28351001878985 - 223.4987780664073 - 485.82797673230294 - -0.012898321304042115'\n",
      "300 - random_25 - knn_ttm_n=1000 - 545.6743985560349 - 759.2116586399501 - 594.4675534392455 - 256.67254548243824 - 323.2463198939855 - 495.90391199400585 - -0.03390554690844705'\n",
      "301 - random_47 - knn_tta_r_n=100 - 318.5238681879846 - 1273.8931402952994 - 495.25777504077433 - 214.83533681186086 - 224.9103738784209 - 505.55264828328507 - -0.05402210926834061'\n",
      "302 - random_47 - knn_tta_r_n=500 - 317.7275992540822 - 1312.152613667071 - 478.871115348964 - 214.00984803917493 - 223.8569239332324 - 509.3933164925378 - -0.06202948341752723'\n",
      "303 - random_85 - deep - 189.664187206504 - 2002.3053440581416 - 172.63422487621617 - 142.53825361931882 - 162.46052386408664 - 534.0120498519592 - -0.11335685600283818'\n",
      "304 - random_39 - knn_ttm_n=100 - 470.8965749586339 - 444.83786637533467 - 477.2519350049848 - 346.3150526346707 - 978.0005965070644 - 543.431916575923 - -0.13299625053517738'\n",
      "305 - random_4 - knn_tta_n=100 - 520.3508806126711 - 405.76322532203716 - 514.4145959041166 - 678.3980250243488 - 619.6770668171267 - 547.6964417344558 - -0.14188732017527927'\n",
      "306 - random_25 - knn_ttm_n=500 - 562.2333753917943 - 831.9744617306183 - 594.7349285292087 - 440.1571732221855 - 354.07675246565753 - 556.6736242094323 - -0.16060376610765115'\n",
      "307 - random_77 - knn_ttm_n=100 - 423.7462686150508 - 445.57263455093766 - 326.93831680296296 - 294.9993596465835 - 1294.414143154869 - 557.0771248476493 - -0.16144502091113955'\n",
      "308 - random_78 - knn_tta_n=1000 - 252.7561872596452 - 760.5505149673062 - 1469.8365028779488 - 219.73901849624727 - 212.93335070690847 - 583.251156846553 - -0.21601502169982623'\n",
      "309 - random_78 - knn_ttm_r_n=500 - 243.841545267204 - 346.670994384854 - 1879.9049731358616 - 215.79815465429098 - 260.9077287698738 - 589.5089398298477 - -0.22906181641407297'\n",
      "310 - random_47 - knn_tta_n=1000 - 315.5359679304806 - 1713.5308746810874 - 479.8809008910262 - 213.58143788950179 - 225.09439410059204 - 589.613563484258 - -0.22927994531771012'\n",
      "311 - random_47 - knn_tta_n=500 - 320.2362410875237 - 1689.1985841472808 - 571.3673647341062 - 213.32093549027064 - 226.2082342031848 - 604.1585080268177 - -0.259604567645372'\n",
      "312 - random_47 - knn_tta_n=100 - 335.62138911743625 - 1692.219806834362 - 549.620676834691 - 217.78856542976368 - 230.5476646562422 - 605.2510621934913 - -0.2618824238709454'\n",
      "313 - random_13 - deep - 684.0451448894792 - 513.7775837898827 - 663.1098745216777 - 713.0094548073135 - 490.8966737818174 - 612.9703903896211 - -0.2779763806008002'\n",
      "314 - random_54 - knn_ttm_r_n=1000 - 303.5252217997267 - 423.8077427631087 - 389.9035172522849 - 218.67108114882672 - 1737.7014175859347 - 614.6345611517962 - -0.2814459953366175'\n",
      "315 - random_81 - knn_ttm_r_n=1000 - 374.9964448195554 - 1324.0751531291726 - 890.3200865249084 - 228.10300310014208 - 268.6813126537712 - 617.3237259166652 - -0.28705261044834174'\n",
      "316 - random_54 - knn_tta_r_n=1000 - 305.7997971360942 - 423.0358755159823 - 384.1541163903314 - 203.67647237483712 - 1838.6996955502482 - 630.9795600740292 - -0.31552353463643557'\n",
      "317 - random_47 - knn_ttm_n=500 - 350.80595037385854 - 1817.350534226912 - 540.0769789241399 - 215.8420162058532 - 237.73270710831338 - 632.4589790876548 - -0.31860796185589235'\n",
      "318 - random_47 - knn_ttm_n=1000 - 345.3256021821261 - 1870.2892132163176 - 621.5991489471708 - 215.27200771320736 - 235.27488673100675 - 657.655922801896 - -0.3711408401841616'\n",
      "319 - random_47 - knn_ttm_n=100 - 340.8823239258576 - 1948.9336633447795 - 558.7009813485793 - 226.02227207459035 - 252.8294648125 - 665.5759966809222 - -0.3876533300383431'\n",
      "320 - random_74 - knn_tta_r_n=500 - 222.03300967299313 - 2477.87459744435 - 291.8452367906244 - 176.6324447662271 - 190.87177143031118 - 671.9685605397834 - -0.40098112817179055'\n",
      "321 - random_4 - knn_ttm_n=100 - 621.5760377946793 - 491.76573515265545 - 520.0082259920441 - 1073.1237346953455 - 701.2383416518952 - 681.4930598135663 - -0.42083866991025687'\n",
      "322 - random_81 - knn_tta_n=1000 - 436.12074426011407 - 1424.385786647133 - 1031.2640304489098 - 246.43237943269634 - 344.06702653051036 - 696.5502863453036 - -0.45223134428869227'\n",
      "323 - random_50 - deep - 160.36521464017744 - 157.49689449317168 - 2884.4273858851275 - 152.93569041386087 - 159.3630966424656 - 703.0488874300769 - -0.46578021814758475'\n",
      "324 - random_78 - knn_tta_r_n=500 - 244.11078952543653 - 360.4000045079114 - 2448.3964878471174 - 208.26965459554165 - 255.56116056662063 - 703.4607676652943 - -0.46663894381702997'\n",
      "325 - random_26 - deep - 466.1744460647665 - 514.5890979640986 - 477.68216640790496 - 1624.6619264893457 - 468.0707411382522 - 710.1549983181146 - -0.48059568397631747'\n",
      "326 - random_3 - deep - 2762.2157660508915 - 152.03450223651558 - 477.6611929963861 - 134.97366123268154 - 163.90448042925667 - 738.2992173620416 - -0.5392733097678863'\n",
      "327 - random_2 - deep - 148.015276594797 - 145.04986391027458 - 1801.2777444511098 - 1415.5632643682472 - 208.26263287602637 - 743.6173708804092 - -0.5503610795711924'\n",
      "328 - random_92 - deep - 2781.880973683193 - 160.88361652010417 - 161.82161745942133 - 474.5243501697554 - 153.89610513089514 - 746.7051138217261 - -0.5567986866893138'\n",
      "329 - random_82 - knn_ttm_r_n=100 - 476.4726830329933 - 1856.1396113312726 - 753.0180416969421 - 257.30100737746204 - 405.4711006268042 - 749.7808834932366 - -0.563211331188175'\n",
      "330 - random_58 - deep - 152.50841684804823 - 146.70903570750693 - 2853.6657045544016 - 471.6211347820378 - 152.60657100059262 - 755.5285603548361 - -0.5751946099534722'\n",
      "331 - random_53 - deep - 152.05613927949884 - 326.86451718445375 - 421.2239868402052 - 200.31568483716728 - 2693.718315793114 - 758.6705613181265 - -0.5817453391271239'\n",
      "332 - random_41 - deep - 155.9941819882636 - 192.3752413579784 - 477.6774804310378 - 181.3127581721165 - 2854.716855418925 - 772.2363557107115 - -0.6100285402239836'\n",
      "333 - random_54 - knn_tta_n=1000 - 318.41590155492224 - 428.61568695970743 - 383.25480599322344 - 212.9926056362985 - 2757.2291282184315 - 819.9420170702713 - -0.7094896391995007'\n",
      "334 - random_78 - knn_ttm_n=1000 - 278.865319407091 - 992.8468300913793 - 2396.282704290679 - 227.07003185856618 - 252.6318780374437 - 829.6808836137361 - -0.7297941133049826'\n",
      "335 - random_82 - knn_tta_r_n=100 - 415.4046925724351 - 2725.7754366633503 - 529.7190748384206 - 249.10103767369165 - 489.83165467570296 - 882.0893842128636 - -0.8390601186016851'\n",
      "336 - random_82 - knn_tta_n=100 - 592.2378190943161 - 1873.864290106345 - 942.6271630494297 - 325.95169406666014 - 680.1444286821265 - 883.0562627313548 - -0.8410759548136542'\n",
      "337 - random_73 - knn_tta_n=1000 - 251.7291114510016 - 426.1332806725852 - 288.1164120114735 - 3466.8515715504377 - 207.25524780562858 - 927.798947262733 - -0.934359570049837'\n",
      "338 - random_31 - deep - 1270.8496071781738 - 159.0032286206333 - 162.1829776523638 - 1935.4499854629353 - 1409.312398518978 - 987.1952277860047 - -1.0581943335801665'\n",
      "339 - random_99 - knn_tta_r_n=100 - 328.4691017916917 - 3505.2603038075363 - 823.7728511453979 - 316.3732100296594 - 242.0827118631988 - 1043.374994343789 - -1.1753230173563387'\n",
      "340 - random_81 - knn_ttm_n=1000 - 528.479660799639 - 1938.3697219581238 - 1730.4577692589655 - 421.9984525179621 - 611.2888091230423 - 1046.245961875171 - -1.1813086713991843'\n",
      "341 - random_82 - knn_ttm_n=100 - 830.1076723567483 - 1824.5900509043176 - 1248.7370496744645 - 452.43565177777504 - 1175.2797918081906 - 1106.3002154683486 - -1.3065152374368876'\n",
      "342 - random_49 - deep - 395.3791950651465 - 602.4050220473483 - 2530.0331304832785 - 495.751736607729 - 1791.4050561142426 - 1162.9994843727166 - -1.424727025940872'\n",
      "343 - random_0 - knn_ttm_r_n=1000 - 848.3392201404259 - 4468.484051120744 - 265.27777866809436 - 187.0533725539522 - 196.78972443445255 - 1193.4291431434976 - -1.4881695447346495'\n",
      "344 - random_78 - knn_tta_n=500 - 255.59867766760837 - 390.51299982761975 - 4767.806660598036 - 214.84589335614106 - 445.76831230119296 - 1215.118821100035 - -1.5333901566466457'\n",
      "345 - random_54 - knn_ttm_n=1000 - 422.15676274958815 - 511.8785368447126 - 449.3572173878689 - 321.4135714744079 - 4686.300697692263 - 1277.927192876629 - -1.664338758586478'\n",
      "346 - random_48 - deep - 1020.651579016472 - 1222.5734120753975 - 183.74350586349405 - 1977.4979138139631 - 2254.889812785466 - 1331.6829908161287 - -1.7764137312229638'\n",
      "347 - random_78 - knn_tta_r_n=100 - 428.37210389752954 - 602.7645613038931 - 5066.875035665786 - 355.57330049804716 - 311.2786396703658 - 1353.2174292171142 - -1.821310686207441'\n",
      "348 - random_97 - deep - 665.7361578801183 - 2592.074283776057 - 2368.449622599894 - 471.79004052792993 - 1080.923870585832 - 1435.9530618911933 - -1.993805452139204'\n",
      "349 - random_80 - knn_ttm_n=100 - 368.4312405955533 - 728.4506833976307 - 5731.748854836086 - 249.6213956316791 - 300.79749328828416 - 1476.0980891934541 - -2.07750345437186'\n",
      "350 - random_73 - knn_ttm_n=1000 - 283.7052488351162 - 471.21316515752653 - 338.88323240759655 - 6252.738571626387 - 245.03572655339264 - 1517.8998350314068 - -2.164655533327105'\n",
      "351 - random_38 - deep - 162.02848151835698 - 177.5097919869151 - 2554.732763701166 - 2431.4705829597465 - 2674.5695529676714 - 1599.8335232421664 - -2.3354783324807538'\n",
      "352 - random_99 - knn_ttm_r_n=100 - 410.4115323591909 - 5905.3081291506505 - 602.2650316271306 - 1743.419254040664 - 279.22096660686196 - 1788.3114233839087 - -2.72843418960307'\n",
      "353 - random_78 - knn_ttm_n=500 - 286.7365339336387 - 464.12633872830133 - 7135.182064405353 - 688.8182254157346 - 767.7577672061675 - 1868.7978535700552 - -2.8962396144195663'\n",
      "354 - random_94 - knn_ttm_r_n=100 - 4799.978146507585 - 821.7990916297418 - 635.8360449442264 - 1092.407513254775 - 2438.413066681719 - 1957.73292080537 - -3.081659525626839'\n",
      "355 - random_52 - deep - 1543.3301443593118 - 164.7967505131786 - 3121.0219840797467 - 2846.5280823266808 - 2159.3965115587253 - 1966.8860678431233 - -3.1007428375758224'\n",
      "356 - random_0 - knn_ttm_n=1000 - 735.9486743098655 - 9948.973291316262 - 311.8316046875738 - 202.6411075635994 - 235.07115475001842 - 2287.389515267902 - -3.7689575552376233'\n",
      "357 - random_0 - knn_tta_r_n=1000 - 414.1572091997497 - 10475.18455999163 - 263.05298559564454 - 188.113902104128 - 196.0974014405411 - 2307.8288837075943 - -3.81157140823211'\n",
      "358 - random_43 - deep - 339.4360802735693 - 2904.689921634814 - 2874.169992539578 - 2686.9450581013657 - 2789.4853359556714 - 2318.8446419293336 - -3.8345380611040127'\n",
      "359 - random_94 - knn_tta_r_n=100 - 8435.17968404788 - 601.7095860816964 - 546.8685308330587 - 559.7521270922867 - 3210.1983843608296 - 2670.9302539644314 - -4.568598146111804'\n",
      "360 - random_78 - knn_tta_n=100 - 686.1702394575339 - 880.73869431096 - 10124.387589845208 - 1984.7875991673243 - 716.2312981871672 - 2878.829807735104 - -5.002046031164762'\n",
      "361 - random_74 - knn_ttm_r_n=1000 - 227.41328508156298 - 13981.112117104192 - 299.23139942032054 - 183.8378622705595 - 189.65633714637426 - 2976.9197077290232 - -5.206552769761802'\n",
      "362 - random_74 - knn_tta_n=1000 - 228.05765436790577 - 14579.986728129354 - 299.26660760961744 - 180.89668525858397 - 196.12556803397194 - 3097.564681926505 - -5.458084377019844'\n",
      "363 - random_99 - knn_ttm_n=100 - 624.9450742054455 - 9820.74742327163 - 1560.2393031395015 - 6315.446915267174 - 528.8045450836383 - 3770.1201541548407 - -6.8602891520225295'\n",
      "364 - random_0 - knn_tta_n=1000 - 584.5302280605334 - 19444.236809441973 - 263.17925507861946 - 189.581895785896 - 204.9888195123478 - 4138.249043732102 - -7.627797719117233'\n",
      "365 - random_78 - knn_ttm_n=100 - 882.1531815681524 - 5930.10937537845 - 11457.887198168159 - 4673.448508290053 - 332.95637445863645 - 4655.827454270445 - -8.706892230519513'\n",
      "366 - random_74 - knn_ttm_r_n=500 - 225.23967203065533 - 24059.472339757427 - 291.97087475005924 - 179.53552412045372 - 192.41430451353907 - 4990.879489543178 - -9.405439165506447'\n",
      "367 - random_94 - knn_ttm_n=100 - 21527.245249591724 - 3251.7994063914884 - 941.9544466423107 - 1618.7495539937597 - 6060.995322505593 - 6680.830489418536 - -12.92880260450212'\n",
      "368 - random_94 - knn_tta_n=100 - 21806.278631091103 - 1931.5456473023012 - 1004.1711840416741 - 1594.6640847019041 - 8093.663529687439 - 6886.554691161877 - -13.357715117937431'\n",
      "369 - random_74 - knn_tta_n=500 - 230.1354515684867 - 35169.93188631747 - 286.6655901585888 - 178.6291738614494 - 201.03537684134514 - 7214.965190510155 - -14.042415175200263'\n",
      "370 - random_81 - knn_tta_r_n=500 - 692.6833850486937 - 6935.338201543851 - 14199.19631894554 - 15502.90725475504 - 334.144377936847 - 7532.761342685309 - -14.704985476771153'\n",
      "371 - random_78 - knn_ttm_r_n=100 - 501.26596301930675 - 33595.55472392367 - 5268.483030017469 - 692.6435927890648 - 221.8032380660636 - 8057.773876920403 - -15.799579324921087'\n",
      "372 - random_81 - knn_ttm_r_n=500 - 799.5021398215464 - 8904.813587370663 - 3207.568220586658 - 30931.537680064936 - 335.9955982744353 - 8834.251887994815 - -17.418451254110416'\n",
      "373 - random_81 - knn_tta_n=500 - 1406.581670335105 - 13754.28569271847 - 10876.11783402141 - 24724.05651521974 - 412.0154230719922 - 10234.051382781476 - -20.336880464318106'\n",
      "374 - random_99 - knn_tta_n=100 - 485.0427506562849 - 6606.95436498292 - 1510.4398449373107 - 47818.433342598895 - 321.44684705239194 - 11345.410153514948 - -22.653942237528277'\n",
      "375 - random_74 - knn_ttm_n=1000 - 257.0718682804112 - 68365.87918225945 - 316.63043404629065 - 195.88904270079416 - 223.47217038048598 - 13875.067576598887 - -27.928001945966766'\n",
      "376 - random_40 - knn_tta_r_n=500 - 242.7538928699519 - 69182.4891989751 - 348.11090230756355 - 239.49482702351517 - 246.5802238156182 - 14055.200065156658 - -28.303558529800597'\n",
      "377 - random_40 - knn_tta_r_n=100 - 670.4124758403995 - 66731.72790383888 - 545.4465121194112 - 5692.627507520821 - 1510.7637714078205 - 15032.938583862175 - -30.342036657248602'\n",
      "378 - random_40 - knn_ttm_r_n=1000 - 260.3207105472213 - 74224.6971367048 - 286.6578487623962 - 232.2910225354959 - 208.97924448057893 - 15046.146603876727 - -30.36957393781131'\n",
      "379 - random_40 - knn_ttm_r_n=500 - 260.08797676138806 - 75947.8337065313 - 348.8557411540486 - 256.589108692855 - 215.8605895331137 - 15409.48627910683 - -31.127097515558077'\n",
      "380 - random_40 - knn_ttm_n=1000 - 305.19042061028733 - 78984.40511885981 - 363.14188894409835 - 531.6329883819279 - 265.88839992574515 - 16093.817823843397 - -32.553854116816986'\n",
      "381 - random_73 - knn_tta_r_n=500 - 248.4234927844173 - 353.10806368319885 - 279.2536257434624 - 194.57874653970194 - 82871.23937244434 - 16783.38196147526 - -33.9915201033183'\n",
      "382 - random_74 - knn_ttm_n=500 - 262.625121024179 - 87874.00727203878 - 329.6437404718327 - 203.5458458662757 - 235.0727641284365 - 17785.193918019162 - -36.080188721932586'\n",
      "383 - random_40 - knn_tta_r_n=1000 - 238.4316763315072 - 89514.56794454007 - 289.2906810877697 - 217.03506667252785 - 208.7668960395673 - 18097.90999678923 - -36.732167624756286'\n",
      "384 - random_40 - knn_tta_n=500 - 270.4014049322068 - 90646.51072139008 - 454.6865529736633 - 314.0682810314611 - 605.890834505373 - 18462.631331437748 - -37.49257181163335'\n",
      "385 - random_73 - knn_ttm_r_n=500 - 255.32635441258535 - 350.93329917165255 - 280.7658454305069 - 189.24764215352775 - 96145.3351265692 - 19437.427865060563 - -39.524916221192946'\n",
      "386 - random_40 - knn_tta_n=1000 - 276.9828156538596 - 97220.07960272131 - 301.92905261694324 - 327.0653068427011 - 324.40093713024817 - 19694.739174919327 - -40.0613822262211'\n",
      "387 - random_40 - knn_ttm_n=500 - 345.6993312938868 - 101163.98324651107 - 513.9870454581408 - 327.92322099935274 - 1487.963727997359 - 20772.67789739687 - -42.30876684538177'\n",
      "388 - random_32 - knn_ttm_n=100 - 357.8927648849059 - 620.8640826956198 - 557.8467758881025 - 261.3123681777332 - 105155.86530973949 - 21383.239679795068 - -43.58172154141053'\n",
      "389 - random_73 - knn_tta_r_n=100 - 330.97031041086245 - 107030.6602209128 - 3117.6246947524864 - 214.24506316909833 - 276.86370898467055 - 22199.34065477945 - -45.283203026968856'\n",
      "390 - random_74 - knn_tta_n=100 - 319.4577693612581 - 147422.02975154063 - 522.6456266847938 - 226.76557126645733 - 265.56606090173926 - 29758.374469725095 - -61.04296374173267'\n",
      "391 - random_74 - knn_ttm_r_n=100 - 372.5107138451217 - 146687.55607698936 - 5600.645085057433 - 205.903797641308 - 215.69910635965869 - 30623.760606645566 - -62.847199412272325'\n",
      "392 - random_74 - knn_tta_r_n=100 - 277.4380590513392 - 161538.71780683091 - 342.7083728488155 - 188.85900607355723 - 205.8635291026453 - 32518.472870463 - -66.79746774445678'\n",
      "393 - random_8 - knn_ttm_r_n=100 - 301.531222211102 - 161360.80741757102 - 568.2509524797695 - 217.67922460065049 - 264.446178603931 - 32550.2956644713 - -66.86381479768129'\n",
      "394 - random_0 - knn_ttm_r_n=500 - 182232.23272665046 - 576.0117610592501 - 271.17938876248235 - 241.80613228515955 - 197.83198866263973 - 36712.568908145695 - -75.54170035232394'\n",
      "395 - random_0 - knn_tta_r_n=500 - 189048.9805277958 - 5143.134762568383 - 266.31242532408135 - 222.51518090055967 - 196.90566245880152 - 38984.8738902063 - -80.2792083017441'\n",
      "396 - random_73 - knn_tta_n=500 - 270.4438541060606 - 433.0008777566699 - 295.39498214949066 - 209.95108413868354 - 194680.82167774942 - 39163.93774445746 - -80.65253689965061'\n",
      "397 - random_81 - knn_ttm_n=500 - 3810.6561408642992 - 28150.38299753695 - 7167.612059053468 - 158650.9359999157 - 753.912414949442 - 39697.10056466128 - -81.76412320474262'\n",
      "398 - random_40 - knn_tta_n=100 - 1141.0553934867821 - 220761.65194466957 - 1150.147814252567 - 24490.199415317915 - 2716.7243832208583 - 50060.70377864291 - -103.3711051013148'\n",
      "399 - random_0 - knn_tta_n=500 - 250309.42628244116 - 10323.603283054548 - 283.0148697304137 - 215.06707881637178 - 210.17815377423423 - 52280.75178579358 - -107.99966295996681'\n",
      "400 - random_40 - knn_ttm_r_n=100 - 757.6708068452984 - 259284.98274691447 - 827.1704942532497 - 4400.9133133116475 - 1243.9137888249954 - 53315.04603866523 - -110.15605362218132'\n",
      "401 - random_74 - knn_ttm_n=100 - 457.2341796932159 - 265273.9450895472 - 500.3015603098301 - 319.5236785761121 - 348.19342141897386 - 53392.57113061948 - -110.31768497990502'\n",
      "402 - random_73 - knn_ttm_n=500 - 307.2008179702566 - 461.8969248190436 - 348.7583849852896 - 237.59762982650025 - 285411.24507745495 - 57332.825886875195 - -118.53268621339886'\n",
      "403 - random_8 - knn_tta_r_n=100 - 334.3330760326422 - 287846.38270962186 - 607.3298640978096 - 219.3970616697064 - 288.6884002950957 - 57873.05201941324 - -119.65899875400801'\n",
      "404 - random_40 - knn_ttm_n=100 - 2871.7210239681817 - 294771.39444210887 - 2067.5452849052244 - 28835.118369221953 - 6826.819961496988 - 67086.33874125346 - -138.86769627903115'\n",
      "405 - random_73 - knn_ttm_r_n=100 - 342.5767055346484 - 299576.8778566624 - 65207.32792510428 - 231.86311288351996 - 261.44909576069665 - 73141.51020592016 - -151.49206808450364'\n",
      "406 - random_0 - knn_ttm_n=500 - 376125.18730017863 - 6728.101343373674 - 328.3445765548616 - 301.7303553712319 - 247.52154147528753 - 76764.53092980504 - -159.04567097488396'\n",
      "407 - random_73 - knn_tta_n=100 - 508.93601083352263 - 391733.8307290457 - 20073.164020801625 - 285.8161244297279 - 407.90221492638585 - 82621.67182664372 - -171.2571706541586'\n",
      "408 - random_57 - knn_tta_r_n=1000 - 288.1555005937242 - 428900.2348589103 - 1082.1831239388894 - 91230.6205250412 - 203.8916697902741 - 104355.08740111468 - -216.56897072720088'\n",
      "409 - random_32 - knn_ttm_r_n=100 - 327.1977881568279 - 484.45469658943796 - 476.26551903844376 - 229.9172339991761 - 855728.7403912509 - 171387.74545973548 - -356.3247486402071'\n",
      "410 - random_73 - knn_ttm_n=100 - 628.0877474691002 - 966748.548506158 - 650.2355077567398 - 28692.801467050744 - 495.8946483521301 - 199487.4790537007 - -414.909627135381'\n",
      "411 - random_8 - knn_tta_n=100 - 324.4585050885492 - 1190460.00200804 - 1405.193914430483 - 359.57837940589127 - 522.9257527744355 - 238671.59556161682 - -496.6042345550761'\n",
      "412 - random_0 - knn_tta_r_n=100 - 1225055.8844290297 - 134091.96346134445 - 22449.565460302856 - 2304.45611872783 - 5542.201867930467 - 277954.5686141067 - -578.5049470836663'\n",
      "413 - random_0 - knn_tta_n=100 - 1333604.34914616 - 217547.49964031612 - 38791.67962821171 - 8070.806485097864 - 24700.739342411878 - 324616.9755449317 - -675.7909740558881'\n",
      "414 - random_8 - knn_ttm_n=100 - 615.7780010531762 - 1646417.8089139683 - 2466.7623377774785 - 692.42291197469 - 606.9898355481093 - 330239.03802253556 - -687.5123608811864'\n",
      "415 - random_57 - knn_ttm_r_n=1000 - 269.4977265165427 - 1685507.8486149888 - 1660.926488746983 - 59146.6756960201 - 202.00923903774284 - 349434.11855392274 - -727.5320093549324'\n",
      "416 - random_57 - knn_tta_n=1000 - 348.002778023787 - 1637055.7403906959 - 5614.212437514554 - 325080.00087244285 - 237.87891272490253 - 393722.61127057264 - -819.8686842156707'\n",
      "417 - random_57 - knn_ttm_n=1000 - 377.36907299361667 - 2047277.0812772543 - 11190.402017449967 - 242112.06775142887 - 327.29765486517306 - 460338.2157282897 - -958.7549508767919'\n",
      "418 - random_57 - knn_tta_r_n=500 - 258.2355075942549 - 1860406.344649125 - 3321.86303210629 - 650523.5145718091 - 216.8897247727382 - 502987.9892420349 - -1047.6750750051597'\n",
      "419 - random_57 - knn_ttm_r_n=500 - 247.89197679916998 - 1418683.6256547917 - 13646.255252973133 - 1514748.222343231 - 210.97275586519874 - 589467.0786551858 - -1227.9745404325045'\n",
      "420 - random_0 - knn_ttm_n=100 - 2703754.560167436 - 1351599.2462416133 - 45471.69560069577 - 21703.399098334066 - 48496.82917782971 - 834396.9389365575 - -1738.626574069783'\n",
      "421 - random_57 - knn_tta_n=500 - 436.77758539219604 - 2973165.754255871 - 31735.631528434445 - 1505334.271605236 - 253.6345033231959 - 902221.0692324671 - -1880.0324852375695'\n",
      "422 - random_57 - knn_ttm_n=500 - 499.57975572725485 - 36960.99161582144 - 867.1546624157648 - 5941023.035889854 - 370.5775708263666 - 1195518.3102513037 - -2491.525230198985'\n",
      "423 - random_0 - knn_ttm_r_n=100 - 8473619.178862372 - 533905.0185407724 - 20132.998095944215 - 3827.3909936511614 - 36749.48063069076 - 1814077.2366522418 - -3781.1530988805166'\n",
      "424 - random_91 - knn_tta_n=500 - 12458327.528498959 - 390.0151966993851 - 326.5050788956706 - 209.59109579305263 - 203.68519536414124 - 2492489.4932927215 - -5195.568630330786'\n",
      "425 - random_57 - knn_tta_r_n=100 - 1601758.6561429196 - 6199466.8854573965 - 333471.28312074253 - 4946569.422036312 - 293.37850756443606 - 2616346.2177506424 - -5453.796386437906'\n",
      "426 - random_57 - knn_tta_n=100 - 2894538.418698224 - 12569663.651234753 - 1669170.8365497165 - 390076.9549951905 - 423.60691292175306 - 3505569.01130992 - -7307.72888517866'\n",
      "427 - random_57 - knn_ttm_r_n=100 - 1160878.8909982236 - 90712.89401575188 - 11947602.496079179 - 10488552.546842247 - 300.055070374958 - 4737487.735673674 - -9876.145007041114'\n",
      "428 - random_91 - knn_ttm_n=500 - 24942068.108331192 - 485.6472325697851 - 409.51334606383296 - 245.51272398956593 - 238.48978235190705 - 4989886.72956297 - -10402.369369270802'\n",
      "429 - random_57 - knn_ttm_n=100 - 4535024.345330357 - 15115057.435548967 - 1593438.2109406104 - 13718995.509400172 - 784.4562265631922 - 6992691.857566058 - -14577.999528937913'\n",
      "430 - random_81 - knn_ttm_n=100 - 2381189.3803007817 - 275302.4202273907 - 28874792.497354407 - 1189183.638541189 - 9242761.977626927 - 8393408.414869357 - -17498.340714429287'\n",
      "431 - random_32 - knn_ttm_r_n=500 - 5084345.753830511 - 39112846.10637592 - 1370354.5525049705 - 227.41378325954352 - 235.90390940954825 - 9115789.242441604 - -19004.42591872646'\n",
      "432 - random_32 - knn_ttm_n=500 - 5084352.252552577 - 39112937.14708208 - 1370414.4497107468 - 238.23838186964318 - 253.94688870890948 - 9115826.5087627 - -19004.503614939702'\n",
      "433 - random_32 - knn_tta_r_n=100 - 321.4962933294924 - 481.3395423852997 - 478.4466019857977 - 230.80186877131962 - 48443155.40105483 - 9685445.495247131 - -20192.097048882486'\n",
      "434 - random_54 - knn_ttm_r_n=500 - 316.4148656784165 - 424.36085463357324 - 93018.69388008119 - 60042453.5840034 - 1715.8512998820045 - 12023266.928481832 - -25066.199650299408'\n",
      "435 - random_81 - knn_ttm_r_n=100 - 858458.5201201352 - 589970.4379679442 - 59782854.790204674 - 1025395.3666846884 - 3619089.4975670986 - 13177758.52541072 - -27473.188659771866'\n",
      "436 - random_81 - knn_tta_r_n=100 - 5728891.776011947 - 358124.17663673346 - 103886203.28158328 - 551536.9687148127 - 4050621.225214466 - 22920023.042667814 - -47784.74716984711'\n",
      "437 - random_54 - knn_tta_r_n=500 - 316.5764492412135 - 416.39916260204075 - 7753.656332443787 - 116505401.5187669 - 1863.062444574471 - 23294761.79140159 - -48566.03657206111'\n",
      "438 - random_24 - knn_tta_n=100 - 614.4720469293947 - 598.1052374536828 - 170177476.52548525 - 1134.0452752734986 - 312.49841168004593 - 34044195.928969085 - -70977.43384511264'\n",
      "439 - random_54 - knn_ttm_n=500 - 533.6997996458119 - 549.2977089572898 - 926949.0490357914 - 177060358.74694127 - 5068.05637485006 - 35585987.09659355 - -74191.9002000396'\n",
      "440 - random_91 - knn_ttm_r_n=500 - 198611863.7656163 - 342.88176886796737 - 321.81884525406974 - 192.27141815188074 - 194.3536984562983 - 39732116.77314896 - -82836.12817871336'\n",
      "441 - random_81 - knn_tta_n=100 - 1008261.2770179075 - 1244099.4076008238 - 199956514.0741772 - 682462.496182353 - 4814197.967280852 - 41550417.683312446 - -86627.08717600684'\n",
      "442 - random_91 - knn_tta_r_n=500 - 308190142.13603896 - 348.41223084523557 - 319.8990352584593 - 192.46550162705742 - 194.22854622603714 - 61653033.151079 - -128538.84696817925'\n",
      "443 - random_54 - knn_tta_n=500 - 355.0844688706539 - 432.04315414404743 - 321914.45764467085 - 493611782.39987594 - 3264.8913768862226 - 98752023.56052665 - -205886.19398708086'\n",
      "444 - random_25 - knn_ttm_n=100 - 7648.243321987443 - 229078615.07155755 - 168731964.2952708 - 2158530.595281865 - 94462902.7569579 - 98900071.20976263 - -206194.8571818041'\n",
      "445 - random_25 - knn_tta_r_n=100 - 236219.42711324382 - 1070998133.4797903 - 195300309.5578243 - 268467.8203498507 - 3902229.5140910726 - 254201567.75325572 - -529981.5320516756'\n",
      "446 - random_32 - knn_tta_n=100 - 344.5164292645922 - 518.9694806995478 - 545.4183756948405 - 242.14601241530372 - 1462581026.343589 - 292411225.48267365 - -609644.4992443924'\n",
      "447 - random_24 - knn_ttm_r_n=100 - 600.615437209999 - 74447.6118134258 - 1547154862.0646455 - 669.1908331051081 - 242.60756919555362 - 309520434.3589021 - -645315.3329129955'\n",
      "448 - random_25 - knn_ttm_r_n=100 - 1580301.3078749813 - 5579934120.38011 - 214375103.6728974 - 766791.8912855898 - 2024561.2211432608 - 1160014188.5349693 - -2418502.010384203'\n",
      "449 - random_24 - knn_ttm_n=100 - 575.3650986104515 - 9167.99277401648 - 5847035234.967457 - 821.3354175229332 - 441.8199006356015 - 1169689917.590914 - -2438674.8497173297'\n",
      "450 - random_25 - knn_tta_n=100 - 114581.0277872555 - 6532255497.557598 - 93985648.75528269 - 4660567.367272465 - 98072933.78992257 - 1346128526.3896298 - -2806530.097304098'\n",
      "451 - random_91 - knn_ttm_r_n=100 - 5320877357.775344 - 15546659.996730812 - 617448832.9068406 - 1317096371.333356 - 1322185596.0327313 - 1718726725.0346396 - -3583356.6861450174'\n",
      "452 - random_24 - knn_tta_r_n=100 - 527.9104899964133 - 4805.909247955985 - 19693928269.937878 - 310.45198357565715 - 233.73003419583497 - 3939732176.175588 - -8213910.711047085'\n",
      "453 - random_91 - knn_tta_r_n=100 - 4661020799.45132 - 168803110.54543996 - 2264934047.7465262 - 12689568796.881687 - 3077489055.998234 - 4571568450.552743 - -9531220.401526809'\n",
      "454 - random_91 - knn_tta_n=100 - 2120719643.3793147 - 422870384.229157 - 2735698638.01327 - 4401634115.77925 - 13993798353.629635 - 4733873118.879954 - -9869607.925428146'\n",
      "455 - random_91 - knn_ttm_n=100 - 7980359365.779296 - 798097718.870287 - 1747933271.1319573 - 16922224916.800503 - 13470906498.33976 - 8182221248.135306 - -17059037.515069235'\n",
      "456 - random_54 - knn_tta_r_n=100 - 202811090.46420538 - 114087471.88764405 - 15149370595.698797 - 36129427080.86764 - 287827397.41896904 - 10374824990.675137 - -21630377.07653563'\n",
      "457 - random_54 - knn_ttm_r_n=100 - 262489080.9234692 - 1533982545.2493532 - 15970944167.543945 - 62598984720.60767 - 899453110.7900136 - 16249451524.689116 - -33878332.401409164'\n",
      "458 - random_54 - knn_ttm_n=100 - 518189765.8877091 - 2380425990.01331 - 280532490455.98865 - 357749858040.8208 - 14061274970.264313 - 131035281609.46692 - -273194263.4936744'\n",
      "459 - random_54 - knn_tta_n=100 - 128506349.23313993 - 3803288017.520401 - 198485482002.2982 - 866942580176.6171 - 1332239451.910255 - 214085617329.69348 - -446345151.5931191'\n"
     ]
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(all_scores)\n",
    "scores_df.to_csv(log_dir/f\"scores.csv\",index=False)\n",
    "\n",
    "scores_df_sorted = pd.DataFrame(scores_df).sort_values(by='MSE')\n",
    "\n",
    "best_5 = []\n",
    "summary_logger.info(f\"Rank - \" +\" - \".join(list(scores_df_sorted.columns)))\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    if i < 5:\n",
    "        best_5.append((row[\"model_num\"],row[\"predictor\"],row[\"MSE\"],row[\"R2\"]))\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    summary_logger.info(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save scores\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      " Best 5 on Test Sest \n",
      " ---------------------'\n",
      "Rank -  Deep Model - Predictor - Val Set - Test Set'\n",
      "0 - random_82 - deep - 134.30467871071176 - 0.7199893993454223 - 133.67391071679515 - 0.722209097820552'\n",
      "1 - random_24 - deep - 134.9352893915091 - 0.7186746448841157 - 130.74223126740614 - 0.7283014899319201'\n",
      "2 - random_10 - deep - 135.40582546692042 - 0.7176936285087342 - 142.43745544334988 - 0.7039973691232655'\n",
      "3 - random_4 - deep - 138.6592477281742 - 0.7109105980863994 - 146.59803687853068 - 0.6953511668518396'\n",
      "4 - random_73 - deep - 139.51102111677213 - 0.7091347435111719 - 138.22997518795154 - 0.7127410329375573'\n"
     ]
    }
   ],
   "source": [
    "scores_df_final = pd.DataFrame(all_scores_final)\n",
    "scores_df_final.to_csv(log_dir/f\"test_scores.csv\",index=False)\n",
    "\n",
    "summary_logger.info(\"-----------------------\\n Best 5 on Test Sest \\n ---------------------\")\n",
    "summary_logger.info(f\"Rank -  Deep Model - Predictor - Val Set - Test Set\")\n",
    "for i, (j,k,v,x) in enumerate(best_5):\n",
    "\n",
    "    row = scores_df_final.loc[(scores_df_final['model_num']==j) & (scores_df_final['predictor'] == k)].iloc[0]\n",
    "    #print(row)\n",
    "    s = f\"{i} - {j} - {k} - {v} - {x} - {row['MSE']} - {row['R2']}\"\n",
    "    summary_logger.info(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote Summary Graph'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#take 1 is a scatter plot - lets, for each dataset\n",
    "#graph our deep models by rank - plot - then overlay our knn moels\n",
    "#plot points\n",
    "\n",
    "deep_set = scores_df[scores_df[\"predictor\"]==\"deep\"].sort_values(\"R2\")\n",
    "deep_set[\"order\"] = [i for i in range(0,100)]\n",
    "deep_ordering = {row[\"model_num\"]:row[\"order\"] for index, row in deep_set.iterrows()}\n",
    "\n",
    "def order_models(x):\n",
    "    x = [deep_ordering[i] for i in x]\n",
    "    return x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df[scores_df[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    if knn_model == \"deep\":\n",
    "        s=10\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot.png\", bbox_inches='tight')\n",
    "logging.getLogger().info(\"Wrote Summary Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df_base = scores_df[scores_df[\"predictor\"]=='deep']\n",
    "scores_df_uu = scores_df[scores_df[\"predictor\"].str.contains('_uu')]   #val_eq_list(scores_df[\"predictor\"],'dist')] #np.logical_or(scores_df[\"predictor\"]==\"deep\",'dist' in scores_df[\"predictor\"])]\n",
    "scores_df_ut = scores_df[scores_df[\"predictor\"].str.contains('_ut')] \n",
    "scores_df_tu = scores_df[scores_df[\"predictor\"].str.contains('_tu')]   #val_eq_list(scores_df[\"predictor\"],'dist')] #np.logical_or(scores_df[\"predictor\"]==\"deep\",'dist' in scores_df[\"predictor\"])]\n",
    "scores_df_tta = scores_df[scores_df[\"predictor\"].str.contains('_tta')] \n",
    "scores_df_ttm = scores_df[scores_df[\"predictor\"].str.contains('_ttm')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores_df_tt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_104860\\1430759390.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores_df_base\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model_num\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscores_df_base\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"R2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'deep'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mknn_model\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mknn_models\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0msubset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores_df_tt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscores_df_tt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"predictor\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mknn_model\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model_num\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"R2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mknn_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scores_df_tt' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "knn_models = scores_df_tta[\"predictor\"].unique()\n",
    "ax.scatter(x=order_models(scores_df_base[\"model_num\"].tolist()), y=scores_df_base[\"R2\"], s=10, label='deep')\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df_tt[scores_df_tt[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot_tta.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "knn_models = scores_df_ttm[\"predictor\"].unique()\n",
    "ax.scatter(x=order_models(scores_df_base[\"model_num\"].tolist()), y=scores_df_base[\"R2\"], s=10, label='deep')\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df_ttm[scores_df_ttm[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot_ttm.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (lazydeep)",
   "language": "python",
   "name": "pycharm-12fcba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
