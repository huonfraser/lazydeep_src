{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detected is GeForce GTX 970\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import logging\n",
    "# set seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils as ut\n",
    "import experiment as ex\n",
    "from evaluation import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import random\n",
    "#define fixed_hyperparams and create a config gen\n",
    "from configurations import RandomConfigGen, Configuration\n",
    "from torch import nn\n",
    "from deep_net import RandomNet\n",
    "from experiment import run_experiment\n",
    "import regex as re\n",
    "from pathlib import *\n",
    "from sk_models import PLSRegression, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from river_models import *\n",
    "\n",
    "from river import stream,linear_model,preprocessing, ensemble, metrics, optim\n",
    "from river.ensemble import SRPRegressor\n",
    "from river.neighbors import KNNRegressor \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from river.utils import dict2numpy, numpy2dict\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "random_state = np.random.RandomState(seed)\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"GPU detected is {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory is D:\\workspace\\lazydeep\\experiments\\6.02_v3\\PLN7\n"
     ]
    }
   ],
   "source": [
    "#setup input and output directories\n",
    "\n",
    "#setup input and outpu t formats, load data\n",
    "\n",
    "#we need to set parametesr\n",
    "file_name = \"PLN7.csv\" #\"mango_684_990.csv\" #\"mango_729_975.csv\" #fitlered=513-1050\n",
    "id_cols =[\"db_id\",\"sample_id\"] #\n",
    "output_cols = None\n",
    "data_path = Path('D:/workspace/lazydeep/data/soil_data/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/6.02_v3\") #1.01/\")\n",
    "if not log_path.exists():\n",
    "    log_path.mkdir()\n",
    "\n",
    "data_file = data_path / file_name\n",
    "log_dir = log_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "print(f\"Output directory is {log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 8333, test: 1667, stream: 100000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data=data.sample(frac=1,random_state=random_state)\n",
    "\n",
    "pre_ind =[i for i in range(0,10000)]\n",
    "pretrain_ind,pretest_ind = train_test_split(pre_ind,train_size=5/6,random_state=random_state,shuffle=False)\n",
    "stream_ind = [i for i in range(10000,110000)]\n",
    "\n",
    "pretrain_data =  ut.TabularDataset(data.iloc[pretrain_ind,:],id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "pretest_data = ut.TabularDataset(data.iloc[pretest_ind,:],id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "stream_data = ut.TabularDataset(data.iloc[stream_ind,:],id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "\n",
    "nrow, ncol = data.shape\n",
    "nrow_train = len(pretrain_data)\n",
    "nrow_test = len(pretest_data)\n",
    "nrow_stream = len(stream_data)\n",
    "\n",
    "print(f\"train: {nrow_train}, test: {nrow_test}, stream: {nrow_stream}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(dir_,id_,scaler_):\n",
    "    deep_ = torch.load(dir_/\"models\"/id_/\"_model\")\n",
    "    deep_.load_state(dir_/\"models\"/id_/\"_final\")\n",
    "    \n",
    "    return (StreamWrapper(scaler_)|StreamDeep(deep_))\n",
    "\n",
    "\n",
    "pls_model_dir = Path(\"D:/workspace/lazydeep/experiments/1.01/PLN7\")\n",
    "deep_model_dir = Path(\"D:/workspace/lazydeep/experiments/2.00/PLN7\")\n",
    "\n",
    "pls_scaler = PLSRegression(n_components=34).from_state(PLSRegression(n_components=34).load_state(pls_model_dir/'preprocessing'/f\"_final\"))      \n",
    "deep_scaler = StandardScaler().from_state(StandardScaler().load_state(deep_model_dir/'preprocessing'/f\"_final\"))      \n",
    "\n",
    "pls_nums = [\"random_82\",\"random_24\",\"random_10\",\"random_4\",\"random_73\"]\n",
    "deep_nums = [\"random_29\",\"random_60\",\"random_63\",\"random_41\",\"random_15\"]\n",
    "deep_num = 1\n",
    "pls_num = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup evaluation\n",
    "def setup_models(window_sizes=[1000,10000,20000],proportions =[0.01,0.05,0.1,0.5,0.8,1]):\n",
    "    model_dicts_ = {}\n",
    "    \n",
    "    for ws in window_sizes:\n",
    "        for p in proportions:\n",
    "            model_dicts_[f\"lwr_std_{ws}_{p}\"]= (build_model(deep_model_dir,deep_nums[deep_num],deep_scaler)|StreamLocalWeightedRegression(n_neighbors= int(ws*p), window_size=ws,floor=True))\n",
    "            model_dicts_[f\"lwr_pls_{ws}_{p}\"]= (build_model(pls_model_dir, pls_nums[pls_num],pls_scaler)  |StreamLocalWeightedRegression(n_neighbors= int(ws*p), window_size=ws,floor=True))\n",
    "    \n",
    "\n",
    "    return model_dicts_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup our metrics and stores of results\n",
    "river_models = setup_models()\n",
    "full_set = river_models.keys()\n",
    "metrics = {'R2':{name:metrics.R2() for name in full_set},\n",
    "           'R2_rolling': {name:RollingR2(window_size=1000) for name in full_set},\n",
    "           'MSE':{name:metrics.MSE() for name in river_models.keys()},\n",
    "           'MSE_rolling':{name:RollingMSE(window_size=1000) for name in full_set}\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so sofar we have establish our metrics and scores are correct\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take our pretrained models, now evaluate them on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5f2cbda9e44ce8baf60f75b8ffb780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17640\\3563026421.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mriver_models\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprequential_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mriver_models\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpretrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_its\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrain_data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\lazy_deep_v2\\lazydeep_src\\river_models.py\u001b[0m in \u001b[0;36mprequential_evaluate\u001b[1;34m(dataset, models, metrics_, pretrain, num_its)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m             \u001b[1;31m#learn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\lazydeep\\lib\\site-packages\\river\\compose\\pipeline.py\u001b[0m in \u001b[0;36mlearn_one\u001b[1;34m(self, x, y, **params)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mx_pre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[1;31m# The supervised transformers have to be updated.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lazy_deep_v2\\lazydeep_src\\river_models.py\u001b[0m in \u001b[0;36mtransform_one\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[0mx_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict2numpyordered\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[0mx_arr1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_arr1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy2dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lazy_deep_v2\\lazydeep_src\\sk_models.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\lazydeep\\lib\\site-packages\\sklearn\\cross_decomposition\\_pls.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, Y, copy)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x_std\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;31m# Apply rotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mx_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_rotations_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m             \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_,_,river_models,metrics = prequential_evaluate(pretrain_data,river_models,metrics,pretrain = len(pretrain_data),num_its= len(pretrain_data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test,scores_test,metrics = score_evaluate(pretest_data,river_models,metrics,num_its=len(pretest_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_stream, scores_stream,river_models,metrics = prequential_evaluate(stream_data,river_models,metrics,pretrain=0,num_its=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_dict(dict1,dict2):\n",
    "\n",
    "    dict12 = {k:dict1[k]+dict2[k] for k in dict1.keys()}   \n",
    "    return dict12b  \n",
    "\n",
    "def zip_nested_dict(dict1,dict2):\n",
    "    dict12 = {}\n",
    "    \n",
    "    for k in dict1.keys():\n",
    "        dict12[k] = {name:dict1[k][name]+dict2[k][name] for name in dict1[k].keys()}\n",
    "    return dict12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = zip_dict(preds_test,preds_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = zip_nested_dict(scores_test,scores_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(preds)\n",
    "preds_df.to_csv(log_dir/\"preds_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#findings\n",
    "#1) preprocessing works, random lr things for lr don't\n",
    "#) standardisation asks as regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_title(\"Streaming performance \")\n",
    "\n",
    "scores_df = pd.DataFrame(scores['R2'])\n",
    "scores_df.to_csv(log_dir/\"r2_scores.csv\")\n",
    "for (columnName, columnData) in scores_df.iteritems():\n",
    "\n",
    "    ax.plot(columnData.index,columnData,'-',label = f\"{columnName}\")\n",
    "\n",
    "ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0.4,0.8)\n",
    "#plt.savefig(log_dir / f\"r2_plot_v2.png\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_title(\"Streaming performance (rolling average) \")\n",
    "    \n",
    "scores_df = pd.DataFrame(scores['R2_rolling'])\n",
    "scores_df.to_csv(log_dir/\"r2_scores_rolling.csv\")\n",
    "for (columnName, columnData) in scores_df.iteritems():\n",
    "    columnData\n",
    "    ax.plot(columnData.index,columnData,label = f\"{columnName}\")\n",
    "ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling.png\",bbox_inches='tight')\n",
    "ax.set_ylim(-1,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling_v2.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.set_title(\"Streaming performance \")\n",
    "\n",
    "scores_df = pd.DataFrame(scores['MSE'])\n",
    "scores_df.to_csv(log_dir/\"MSE.csv\")\n",
    "for (columnName, columnData) in scores_df.iteritems():\n",
    "    ax.plot(columnData.index,columnData,'-',label = f\"{columnName}\")\n",
    "ax.plot([len(pretest_data),len(pretest_data)],[0,1000],c=\"black\",ls='--')\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"mse_plot.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,600)\n",
    "plt.savefig(log_dir / f\"mse_plot_v2.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.set_title(\"Streaming performance (rolling average) \")\n",
    "\n",
    "scores_df = pd.DataFrame(scores['MSE_rolling'])\n",
    "scores_df.to_csv(log_dir/\"MSE_rolling.csv\")\n",
    "for (columnName, columnData) in scores_df.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label = f\"{columnName}\")\n",
    "ax.plot([len(pretest_data),len(pretest_data)],[0,1000],c=\"black\",ls='--')\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"mse_plot_rolling.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1000)\n",
    "plt.savefig(log_dir / f\"mse_plot_rolling_v2.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores['R2_rolling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_subset_by_str(dataset,string):\n",
    "    col_names = dataset.columns.tolist()\n",
    "    encoding = [i for i in col_names if (string in i)]\n",
    "    return scores_df[encoding]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_opts = ['pls_','std_']\n",
    "ws_opts = ['1000_','10000_','20000_']\n",
    "\n",
    "for pp_opt in pp_opts:\n",
    "    subset1 = take_subset_by_str(scores_df,pp_opt)\n",
    "    for ws_opt in ws_opts:\n",
    "        subset2 = take_subset_by_str(subset1,ws_opt)\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        ax.set_xlabel(\"Stream Index\")\n",
    "        ax.set_ylabel(\"R2\")\n",
    "        ax.set_title(\"Streaming performance (rolling average) \")\n",
    "        \n",
    "        for (columnName, columnData) in subset2.iteritems():\n",
    "            ax.plot(columnData.index,columnData,label = f\"{columnName.replace(pp_opt,'').replace(ws_opt,'')}\")\n",
    "        ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "        ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "        plt.savefig(log_dir / f\"r2_plot_{pp_opt}{ws_opt}_.png\",bbox_inches='tight')\n",
    "        ax.set_ylim(-1,1)\n",
    "        plt.savefig(log_dir / f\"r2_plot_v2_{pp_opt}{ws_opt}_.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
