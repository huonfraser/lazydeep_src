{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%% imports\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# set seed\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import utils as ut\n",
    "import experiment as exp\n",
    "import evaluation as ev\n",
    "from pathlib import *\n",
    "import torch\n",
    "import random\n",
    "import regex as re\n",
    "import plot\n",
    "import matplotlib.pyplot as plt\n",
    "from sk_models import LocalWeightedRegression, PCR, setup_pls_models, PLSRegression, LinearRidge, CustomWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% seed\n"
    }
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "\n",
    "random_state = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% set these parametesr\n"
    }
   },
   "outputs": [],
   "source": [
    "#we need to set parametesr\n",
    "file_name = \"A_FE_RT.csv\"#\"PLN7.csv\" A_FE_RT  A_C_OF_alpha\n",
    "id_cols =[]#[\"sample_id\"] \"db_id\",\"sample_id\"\n",
    "n_comps = [i for i in range(1,101)]\n",
    "\n",
    "data_path = Path('D:/workspace/lazydeep/data/soil_data/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/0.00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup parametesr\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\workspace\\lazydeep\\experiments\\0.00\\A_FE_RT\n",
      "D:\\workspace\\lazydeep\\experiments\\0.00\\A_FE_RT\n"
     ]
    }
   ],
   "source": [
    "data_file = data_path / file_name\n",
    "log_dir = log_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "print(log_dir)\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "nrow, ncol = data.shape\n",
    "data = ut.sample_data(data,random_state)\n",
    "\n",
    "n_features = ncol - 1-len(id_cols)\n",
    "dataset = ut.TabularDataset(data,id_cols = id_cols, cat_cols=None, output_cols=None, ignore_cols= None)\n",
    "\n",
    "# todo write a summary\n",
    "#ut.setup_logger(logger_name=\"\",file_name=log_dir/\"log.txt\")\n",
    "ut.setup_logger(logger_name=\"summary\",file_name=log_dir/\"summary.txt\")\n",
    "#tb = SummaryWriter(log_dir/\"tb\")\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Setup summary logging and results datastructures\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#todo write a summary\n",
    "\n",
    "ut.setup_logger(logger_name=\"summary\",file_name=log_dir/\"summary.txt\")\n",
    "summary_logger = logging.getLogger(\"summary\")\n",
    "eval = ev.CrossValEvaluation(preprocessing=None,tensorboard=None,time=True,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Define helper models\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_preds_and_res(preds,save_loc = \"\", name_lambda = lambda x:x,save_lambda = lambda x:x):\n",
    "    for col_name in preds.columns:\n",
    "        # plot predictions\n",
    "        fig, ax = plot.scatter_plot(preds,col_name,\"y\",color_col=\"set_id\",title= f\"Predictions for {name_lambda(col_name)}\")\n",
    "        plt.savefig(save_loc/f\"predictions_{save_lambda(col_name)}.png\",bbox_inches='tight')\n",
    "        plt.close()\n",
    "        # plt.show()\n",
    "\n",
    "        fig, ax = plot.residual_plot(preds, col_name, \"y\", color_col=\"set_id\",title = f\"Residuals for {name_lambda(col_name)}\")\n",
    "        plt.savefig(save_loc/f\"residuals_{save_lambda(col_name)}.png\", bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass fit_intercept=0.01 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass fit_intercept=0.01 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "#PCR with and without whitening,scaling\n",
    "#PLSR with and without scaling\n",
    "lr_models = {\n",
    "    'lr':LinearRidge(scale=False,ridge=False),\n",
    "    'lr_norm':LinearRidge(scale=True,ridge=False),\n",
    "    'ridge':LinearRidge(scale=False,ridge=True,ridge_param=1e-2),\n",
    "    'ridge_norm':LinearRidge(scale=True,ridge=True,ridge_param=1e-2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% run LR Model\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LR'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of lr:1.7147,lr_norm:1.7147,ridge:1.7147,ridge_norm:1.7386'\n",
      "Tested (test) on 2003 instances with mean losses of: lr:2.8848,lr_norm:2.8848,ridge:2.8848,ridge_norm:2.8167'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of lr:1.7482,lr_norm:1.7482,ridge:1.7482,ridge_norm:1.7713'\n",
      "Tested (test) on 2003 instances with mean losses of: lr:3.1633,lr_norm:3.1633,ridge:3.1633,ridge_norm:3.1092'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of lr:1.8192,lr_norm:1.8192,ridge:1.8192,ridge_norm:1.8384'\n",
      "Tested (test) on 2002 instances with mean losses of: lr:2.7141,lr_norm:2.7141,ridge:2.7141,ridge_norm:2.6703'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of lr:1.8101,lr_norm:1.8101,ridge:1.8101,ridge_norm:1.8279'\n",
      "Tested (test) on 2002 instances with mean losses of: lr:3.2544,lr_norm:3.2544,ridge:3.2544,ridge_norm:3.2133'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of lr:1.6182,lr_norm:1.6182,ridge:1.6182,ridge_norm:1.639'\n",
      "Tested (test) on 2002 instances with mean losses of: lr:8.3716,lr_norm:8.3716,ridge:8.3717,ridge_norm:8.3605'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of lr:1.8517,lr_norm:1.8517,ridge:1.8517,ridge_norm:1.8652'\n",
      "Tested (test) on 2003 instances with mean losses of: lr:2.6484,lr_norm:2.6484,ridge:2.6484,ridge_norm:2.6187'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'lr': 2.8847916016061004, 'lr_norm': 2.8847916016059294, 'ridge': 2.8847869791343714, 'ridge_norm': 2.8166520932324572}, 'fold_1': {'lr': 3.1633414715432475, 'lr_norm': 3.1633414715432253, 'ridge': 3.163337537320763, 'ridge_norm': 3.109206138558866}, 'fold_2': {'lr': 2.714119657163784, 'lr_norm': 2.7141196571638715, 'ridge': 2.7141161994032292, 'ridge_norm': 2.670286307008039}, 'fold_3': {'lr': 3.2544210386931307, 'lr_norm': 3.2544210386927346, 'ridge': 3.2544181798868266, 'ridge_norm': 3.2133320299803128}, 'fold_4': {'lr': 8.37164852486796, 'lr_norm': 8.371648524869663, 'ridge': 8.371655429379814, 'ridge_norm': 8.360538423726583}, 'MSE': {'lr': 4.077453991750834, 'lr_norm': 4.0774539917510735, 'ridge': 4.077452397464714, 'ridge_norm': 4.033789040474363}, 'R2': {'lr': 0.9932155665365618, 'lr_norm': 0.9932155665365614, 'ridge': 0.993215569189278, 'ridge_norm': 0.9932882201967181}}'\n",
      "lr: {'fold_0': 2.8847916016061004, 'fold_1': 3.1633414715432475, 'fold_2': 2.714119657163784, 'fold_3': 3.2544210386931307, 'fold_4': 8.37164852486796, 'MSE': 4.077453991750834, 'R2': 0.9932155665365618}'\n",
      "lr_norm: {'fold_0': 2.8847916016059294, 'fold_1': 3.1633414715432253, 'fold_2': 2.7141196571638715, 'fold_3': 3.2544210386927346, 'fold_4': 8.371648524869663, 'MSE': 4.0774539917510735, 'R2': 0.9932155665365614}'\n",
      "ridge: {'fold_0': 2.8847869791343714, 'fold_1': 3.163337537320763, 'fold_2': 2.7141161994032292, 'fold_3': 3.2544181798868266, 'fold_4': 8.371655429379814, 'MSE': 4.077452397464714, 'R2': 0.993215569189278}'\n",
      "ridge_norm: {'fold_0': 2.8166520932324572, 'fold_1': 3.109206138558866, 'fold_2': 2.670286307008039, 'fold_3': 3.2133320299803128, 'fold_4': 8.360538423726583, 'MSE': 4.033789040474363, 'R2': 0.9932882201967181}'\n"
     ]
    }
   ],
   "source": [
    "local_logger_name = f\"lr\"\n",
    "\n",
    "save_loc = log_dir/f\"LR\"\n",
    "if not save_loc.exists():\n",
    "    save_loc.mkdir()\n",
    "ut.setup_logger(logger_name=local_logger_name,file_name=save_loc/f\"{local_logger_name}_log.txt\")\n",
    "local_logger=logging.getLogger(local_logger_name)\n",
    "scheme= ev.SKLearnScheme(logger=local_logger_name)\n",
    "\n",
    "local_logger.info(f\"Running LR\")\n",
    "scores_ls, preds_ls, model_states_ls ,train_time_ls, test_time_ls,_ = eval.evaluate(lr_models,dataset,scheme,logger_name=local_logger_name)\n",
    "scores_ls_final, _, model_states_ls_final , _, _,_= eval.build(lr_models,dataset,scheme,logger_name=local_logger_name)\n",
    "\n",
    "for fold,nested in model_states_ls.items():\n",
    "    for name,model in nested.items():\n",
    "        CustomWrapper(None).save_state(model,save_loc/(f\"{name}_{fold}\"))\n",
    "for name,model in model_states_ls_final.items():\n",
    "    model.save_state(model.state(),save_loc/(f\"{name}_final\"))\n",
    "\n",
    "local_logger.info(f\"Train times: {train_time_ls}\")\n",
    "local_logger.info(f\"Test times: {test_time_ls}\")\n",
    "local_logger.info(f\"Scores: {scores_ls}\")\n",
    "for key,value in ut.flip_dicts(scores_ls).items():\n",
    "    local_logger.info(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save LR Model\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "scores_df_lr = None\n",
    "scores_df_lr_final = None\n",
    "\n",
    "#write preds\n",
    "preds_ls.to_csv(save_loc/ (f\"predictions_lr\" + \".csv\"), index=False)\n",
    "#plot our figures\n",
    "plot_preds_and_res(preds_ls,name_lambda=lambda x:f\"{x}\",save_lambda= lambda x:f\"lr_{x}\",save_loc=save_loc)\n",
    "#save scores\n",
    "\n",
    "flipped = ut.flip_dicts(scores_ls)\n",
    "for name,record in flipped.items():\n",
    "    record1 = {'model':f\"{name}\",'n_comp':\"None\"}\n",
    "    if scores_df_lr is None:\n",
    "        scores_df_lr =pd.DataFrame([{**record1,**record}])\n",
    "    else:\n",
    "        scores_df_lr=scores_df_lr.append([{**record1,**record}],ignore_index=True)\n",
    "\n",
    "flipped = ut.flip_dicts(scores_ls_final)\n",
    "for name,record in flipped.items():\n",
    "    record1 = {'model':f\"{name}\",'n_comp':\"None\"}\n",
    "    if scores_df_lr_final is None:\n",
    "        scores_df_lr_final =pd.DataFrame([{**record1,**record}])\n",
    "    else:\n",
    "        scores_df_lr_final=scores_df_lr_final.append([{**record1,**record}],ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% run PCR models\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 1 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:31.5413,pcr_scale:77.1908,pcr_whiten:31.5413,pcr_s_w:77.1908'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:30.4766,pcr_scale:76.6031,pcr_whiten:30.4766,pcr_s_w:76.6031'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:31.5747,pcr_scale:78.72,pcr_whiten:31.5747,pcr_s_w:78.72'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:31.6382,pcr_scale:78.4232,pcr_whiten:31.6382,pcr_s_w:78.4232'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:31.4888,pcr_scale:78.2615,pcr_whiten:31.4888,pcr_s_w:78.2615'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:30.8056,pcr_scale:80.1885,pcr_whiten:30.8056,pcr_s_w:80.1885'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:31.335,pcr_scale:78.4693,pcr_whiten:31.335,pcr_s_w:78.4693'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:32.1734,pcr_scale:78.7734,pcr_whiten:32.1734,pcr_s_w:78.7734'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:30.9804,pcr_scale:77.3556,pcr_whiten:30.9804,pcr_s_w:77.3556'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:31.9806,pcr_scale:80.1423,pcr_whiten:31.9806,pcr_s_w:80.1423'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:31.2028,pcr_scale:78.7983,pcr_whiten:31.2028,pcr_s_w:78.7983'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:33.5884,pcr_scale:80.7105,pcr_whiten:33.5884,pcr_s_w:80.7105'\n",
      "Train times: {'fold_0': 6, 'fold_1': 6, 'fold_2': 6, 'fold_3': 6, 'fold_4': 6, 'mean': 6.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 30.47657908221457, 'pcr_scale': 76.60305816384424, 'pcr_whiten': 30.476579082214585, 'pcr_s_w': 76.60305816384715}, 'fold_1': {'pcr': 31.638222459809523, 'pcr_scale': 78.4231679806558, 'pcr_whiten': 31.638222459809516, 'pcr_s_w': 78.42316798066103}, 'fold_2': {'pcr': 30.805575081711993, 'pcr_scale': 80.18854728283789, 'pcr_whiten': 30.805575081712014, 'pcr_s_w': 80.18854728282963}, 'fold_3': {'pcr': 32.1734240935544, 'pcr_scale': 78.77341487721104, 'pcr_whiten': 32.173424093554395, 'pcr_s_w': 78.77341487720932}, 'fold_4': {'pcr': 31.980576384088604, 'pcr_scale': 80.14228786329245, 'pcr_whiten': 31.980576384088618, 'pcr_s_w': 80.14228786329915}, 'MSE': {'pcr': 31.414804011037052, 'pcr_scale': 78.82583295187405, 'pcr_whiten': 31.41480401103706, 'pcr_s_w': 78.82583295187504}, 'R2': {'pcr': 0.9477292329941623, 'pcr_scale': 0.8688425130132629, 'pcr_whiten': 0.9477292329941623, 'pcr_s_w': 0.8688425130132612}}'\n",
      "pcr: {'fold_0': 30.47657908221457, 'fold_1': 31.638222459809523, 'fold_2': 30.805575081711993, 'fold_3': 32.1734240935544, 'fold_4': 31.980576384088604, 'MSE': 31.414804011037052, 'R2': 0.9477292329941623}'\n",
      "pcr_scale: {'fold_0': 76.60305816384424, 'fold_1': 78.4231679806558, 'fold_2': 80.18854728283789, 'fold_3': 78.77341487721104, 'fold_4': 80.14228786329245, 'MSE': 78.82583295187405, 'R2': 0.8688425130132629}'\n",
      "pcr_whiten: {'fold_0': 30.476579082214585, 'fold_1': 31.638222459809516, 'fold_2': 30.805575081712014, 'fold_3': 32.173424093554395, 'fold_4': 31.980576384088618, 'MSE': 31.41480401103706, 'R2': 0.9477292329941623}'\n",
      "pcr_s_w: {'fold_0': 76.60305816384715, 'fold_1': 78.42316798066103, 'fold_2': 80.18854728282963, 'fold_3': 78.77341487720932, 'fold_4': 80.14228786329915, 'MSE': 78.82583295187504, 'R2': 0.8688425130132612}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 2 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:31.526,pcr_scale:56.6916,pcr_whiten:31.526,pcr_s_w:56.6916'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:30.435,pcr_scale:57.9875,pcr_whiten:30.435,pcr_s_w:57.9875'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:31.5281,pcr_scale:57.5562,pcr_whiten:31.5281,pcr_s_w:57.5562'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:31.6223,pcr_scale:57.8565,pcr_whiten:31.6223,pcr_s_w:57.8565'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:31.4283,pcr_scale:57.031,pcr_whiten:31.4283,pcr_s_w:57.031'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:30.772,pcr_scale:58.8136,pcr_whiten:30.772,pcr_s_w:58.8136'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:31.2739,pcr_scale:62.704,pcr_whiten:31.2739,pcr_s_w:62.704'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:32.1781,pcr_scale:58.679,pcr_whiten:32.1781,pcr_s_w:58.679'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:30.9479,pcr_scale:61.5171,pcr_whiten:30.9479,pcr_s_w:61.5171'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:31.8958,pcr_scale:71.1735,pcr_whiten:31.8958,pcr_s_w:71.1735'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:31.1494,pcr_scale:62.8118,pcr_whiten:31.1494,pcr_s_w:62.8118'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:33.4498,pcr_scale:60.3588,pcr_whiten:33.4498,pcr_s_w:60.3588'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 30.434994125122017, 'pcr_scale': 57.98749898459532, 'pcr_whiten': 30.43499412512203, 'pcr_s_w': 57.98749901035426}, 'fold_1': {'pcr': 31.62230875298492, 'pcr_scale': 57.85649767828005, 'pcr_whiten': 31.62230875298492, 'pcr_s_w': 57.85649750491954}, 'fold_2': {'pcr': 30.772024371142397, 'pcr_scale': 58.813598016198256, 'pcr_whiten': 30.772024371142408, 'pcr_s_w': 58.81359675310727}, 'fold_3': {'pcr': 32.17806251697134, 'pcr_scale': 58.67899436137093, 'pcr_whiten': 32.178062516971345, 'pcr_s_w': 58.67899439605261}, 'fold_4': {'pcr': 31.89575613377192, 'pcr_scale': 71.17354673620858, 'pcr_whiten': 31.895756133771883, 'pcr_s_w': 71.17354746764032}, 'MSE': {'pcr': 31.380558868823734, 'pcr_scale': 60.901431863915555, 'pcr_whiten': 31.380558868823734, 'pcr_s_w': 60.90143173501074}, 'R2': {'pcr': 0.9477862131315868, 'pcr_scale': 0.8986667383262296, 'pcr_whiten': 0.9477862131315868, 'pcr_s_w': 0.898666738540713}}'\n",
      "pcr: {'fold_0': 30.434994125122017, 'fold_1': 31.62230875298492, 'fold_2': 30.772024371142397, 'fold_3': 32.17806251697134, 'fold_4': 31.89575613377192, 'MSE': 31.380558868823734, 'R2': 0.9477862131315868}'\n",
      "pcr_scale: {'fold_0': 57.98749898459532, 'fold_1': 57.85649767828005, 'fold_2': 58.813598016198256, 'fold_3': 58.67899436137093, 'fold_4': 71.17354673620858, 'MSE': 60.901431863915555, 'R2': 0.8986667383262296}'\n",
      "pcr_whiten: {'fold_0': 30.43499412512203, 'fold_1': 31.62230875298492, 'fold_2': 30.772024371142408, 'fold_3': 32.178062516971345, 'fold_4': 31.895756133771883, 'MSE': 31.380558868823734, 'R2': 0.9477862131315868}'\n",
      "pcr_s_w: {'fold_0': 57.98749901035426, 'fold_1': 57.85649750491954, 'fold_2': 58.81359675310727, 'fold_3': 58.67899439605261, 'fold_4': 71.17354746764032, 'MSE': 60.90143173501074, 'R2': 0.898666738540713}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 3 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:13.7129,pcr_scale:32.3476,pcr_whiten:13.7129,pcr_s_w:32.3476'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:12.8372,pcr_scale:30.0306,pcr_whiten:12.8372,pcr_s_w:30.0306'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:13.3997,pcr_scale:32.0395,pcr_whiten:13.3997,pcr_s_w:32.0395'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:13.3388,pcr_scale:32.8115,pcr_whiten:13.3388,pcr_s_w:32.8115'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:13.0163,pcr_scale:31.5238,pcr_whiten:13.0163,pcr_s_w:31.5238'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.3188,pcr_scale:32.0412,pcr_whiten:12.3188,pcr_s_w:32.0412'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:12.8914,pcr_scale:32.1655,pcr_whiten:12.8914,pcr_s_w:32.1655'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:13.6924,pcr_scale:32.978,pcr_whiten:13.6924,pcr_s_w:32.978'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:12.9811,pcr_scale:30.7903,pcr_whiten:12.9811,pcr_s_w:30.7903'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:13.9976,pcr_scale:37.875,pcr_whiten:13.9976,pcr_s_w:37.875'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:12.976,pcr_scale:31.8055,pcr_whiten:12.976,pcr_s_w:31.8055'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:13.868,pcr_scale:34.3423,pcr_whiten:13.868,pcr_s_w:34.3423'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 12.83717053559811, 'pcr_scale': 30.030598625350432, 'pcr_whiten': 12.837170535598098, 'pcr_s_w': 30.03059873098187}, 'fold_1': {'pcr': 13.33879800115516, 'pcr_scale': 32.81152327076862, 'pcr_whiten': 13.338798001155157, 'pcr_s_w': 32.811523245137145}, 'fold_2': {'pcr': 12.318840419341148, 'pcr_scale': 32.041154697860335, 'pcr_whiten': 12.31884041934114, 'pcr_s_w': 32.04115133559899}, 'fold_3': {'pcr': 13.692357789075823, 'pcr_scale': 32.97796169507201, 'pcr_whiten': 13.692357789075793, 'pcr_s_w': 32.977961577906775}, 'fold_4': {'pcr': 13.99762292707595, 'pcr_scale': 37.87502059452096, 'pcr_whiten': 13.997622927075899, 'pcr_s_w': 37.8750216906645}, 'MSE': {'pcr': 13.23692817542685, 'pcr_scale': 33.14690695233799, 'pcr_whiten': 13.23692817542683, 'pcr_s_w': 33.14690649178139}, 'R2': {'pcr': 0.9779752123143071, 'pcr_scale': 0.9448472048509003, 'pcr_whiten': 0.9779752123143072, 'pcr_s_w': 0.9448472056172157}}'\n",
      "pcr: {'fold_0': 12.83717053559811, 'fold_1': 13.33879800115516, 'fold_2': 12.318840419341148, 'fold_3': 13.692357789075823, 'fold_4': 13.99762292707595, 'MSE': 13.23692817542685, 'R2': 0.9779752123143071}'\n",
      "pcr_scale: {'fold_0': 30.030598625350432, 'fold_1': 32.81152327076862, 'fold_2': 32.041154697860335, 'fold_3': 32.97796169507201, 'fold_4': 37.87502059452096, 'MSE': 33.14690695233799, 'R2': 0.9448472048509003}'\n",
      "pcr_whiten: {'fold_0': 12.837170535598098, 'fold_1': 13.338798001155157, 'fold_2': 12.31884041934114, 'fold_3': 13.692357789075793, 'fold_4': 13.997622927075899, 'MSE': 13.23692817542683, 'R2': 0.9779752123143072}'\n",
      "pcr_s_w: {'fold_0': 30.03059873098187, 'fold_1': 32.811523245137145, 'fold_2': 32.04115133559899, 'fold_3': 32.977961577906775, 'fold_4': 37.8750216906645, 'MSE': 33.14690649178139, 'R2': 0.9448472056172157}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 4 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:9.4491,pcr_scale:25.7096,pcr_whiten:9.4491,pcr_s_w:25.7096'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:8.9491,pcr_scale:23.2288,pcr_whiten:8.9491,pcr_s_w:23.2288'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:9.0637,pcr_scale:26.18,pcr_whiten:9.0637,pcr_s_w:26.18'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:9.1332,pcr_scale:25.0333,pcr_whiten:9.1332,pcr_s_w:25.0333'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:9.0768,pcr_scale:24.2738,pcr_whiten:9.0768,pcr_s_w:24.2738'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:8.611,pcr_scale:26.4927,pcr_whiten:8.611,pcr_s_w:26.4927'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:8.8897,pcr_scale:24.5836,pcr_whiten:8.8897,pcr_s_w:24.5836'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:9.7469,pcr_scale:25.1842,pcr_whiten:9.7469,pcr_s_w:25.1842'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:8.9239,pcr_scale:24.8794,pcr_whiten:8.9239,pcr_s_w:24.8794'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:9.1782,pcr_scale:34.7634,pcr_whiten:9.1782,pcr_s_w:34.7634'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:8.8036,pcr_scale:25.6107,pcr_whiten:8.8036,pcr_s_w:25.6107'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:9.8257,pcr_scale:25.82,pcr_whiten:9.8257,pcr_s_w:25.82'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 8.94909410109938, 'pcr_scale': 23.22877013301555, 'pcr_whiten': 8.949094101099382, 'pcr_s_w': 23.228766560628085}, 'fold_1': {'pcr': 9.133222488327787, 'pcr_scale': 25.033324659707457, 'pcr_whiten': 9.133222488327789, 'pcr_s_w': 25.033324190493186}, 'fold_2': {'pcr': 8.611012667738954, 'pcr_scale': 26.49269262746069, 'pcr_whiten': 8.611012667738954, 'pcr_s_w': 26.4926843510797}, 'fold_3': {'pcr': 9.746853628692556, 'pcr_scale': 25.184222676903392, 'pcr_whiten': 9.746853628692575, 'pcr_s_w': 25.184224122433744}, 'fold_4': {'pcr': 9.178222128182933, 'pcr_scale': 34.763435366371304, 'pcr_whiten': 9.178222128182963, 'pcr_s_w': 34.76343906124506}, 'MSE': {'pcr': 9.123664518048415, 'pcr_scale': 26.93992787781027, 'pcr_whiten': 9.123664518048427, 'pcr_s_w': 26.939926442177626}, 'R2': {'pcr': 0.9848192291094738, 'pcr_scale': 0.9551749330423849, 'pcr_whiten': 0.9848192291094737, 'pcr_s_w': 0.9551749354311192}}'\n",
      "pcr: {'fold_0': 8.94909410109938, 'fold_1': 9.133222488327787, 'fold_2': 8.611012667738954, 'fold_3': 9.746853628692556, 'fold_4': 9.178222128182933, 'MSE': 9.123664518048415, 'R2': 0.9848192291094738}'\n",
      "pcr_scale: {'fold_0': 23.22877013301555, 'fold_1': 25.033324659707457, 'fold_2': 26.49269262746069, 'fold_3': 25.184222676903392, 'fold_4': 34.763435366371304, 'MSE': 26.93992787781027, 'R2': 0.9551749330423849}'\n",
      "pcr_whiten: {'fold_0': 8.949094101099382, 'fold_1': 9.133222488327789, 'fold_2': 8.611012667738954, 'fold_3': 9.746853628692575, 'fold_4': 9.178222128182963, 'MSE': 9.123664518048427, 'R2': 0.9848192291094737}'\n",
      "pcr_s_w: {'fold_0': 23.228766560628085, 'fold_1': 25.033324190493186, 'fold_2': 26.4926843510797, 'fold_3': 25.184224122433744, 'fold_4': 34.76343906124506, 'MSE': 26.939926442177626, 'R2': 0.9551749354311192}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 5 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:8.5619,pcr_scale:19.2613,pcr_whiten:8.5619,pcr_s_w:19.2613'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:8.0709,pcr_scale:17.7221,pcr_whiten:8.0709,pcr_s_w:17.7221'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:8.1208,pcr_scale:20.1581,pcr_whiten:8.1208,pcr_s_w:20.1581'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:8.4687,pcr_scale:17.6346,pcr_whiten:8.4687,pcr_s_w:17.6346'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:8.174,pcr_scale:20.1471,pcr_whiten:8.174,pcr_s_w:20.1471'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:7.7522,pcr_scale:20.6207,pcr_whiten:7.7522,pcr_s_w:20.6207'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:8.0203,pcr_scale:21.1712,pcr_whiten:8.0203,pcr_s_w:21.1712'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:8.8567,pcr_scale:20.6218,pcr_whiten:8.8567,pcr_s_w:20.6218'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:8.1311,pcr_scale:20.0025,pcr_whiten:8.1311,pcr_s_w:20.0025'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:8.0668,pcr_scale:38.0492,pcr_whiten:8.0668,pcr_s_w:38.0492'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:7.9823,pcr_scale:20.9537,pcr_whiten:7.9823,pcr_s_w:20.9537'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:8.8453,pcr_scale:19.9954,pcr_whiten:8.8453,pcr_s_w:19.9954'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 8.070901015205102, 'pcr_scale': 17.72206940921658, 'pcr_whiten': 8.070901015205088, 'pcr_s_w': 17.722071507960166}, 'fold_1': {'pcr': 8.468715619629542, 'pcr_scale': 17.63459696152566, 'pcr_whiten': 8.468715619629542, 'pcr_s_w': 17.634591004186632}, 'fold_2': {'pcr': 7.752240405485085, 'pcr_scale': 20.620676683259067, 'pcr_whiten': 7.752240405485092, 'pcr_s_w': 20.620677547062723}, 'fold_3': {'pcr': 8.856722494956344, 'pcr_scale': 20.621847013154795, 'pcr_whiten': 8.856722494956347, 'pcr_s_w': 20.6218465090174}, 'fold_4': {'pcr': 8.066792554012027, 'pcr_scale': 38.049238520287176, 'pcr_whiten': 8.066792554012027, 'pcr_s_w': 38.049245096722395}, 'MSE': {'pcr': 8.243079758229086, 'pcr_scale': 22.928636705796265, 'pcr_whiten': 8.243079758229085, 'pcr_s_w': 22.928637320789115}, 'R2': {'pcr': 0.98628442497042, 'pcr_scale': 0.9618492788753639, 'pcr_whiten': 0.98628442497042, 'pcr_s_w': 0.9618492778520836}}'\n",
      "pcr: {'fold_0': 8.070901015205102, 'fold_1': 8.468715619629542, 'fold_2': 7.752240405485085, 'fold_3': 8.856722494956344, 'fold_4': 8.066792554012027, 'MSE': 8.243079758229086, 'R2': 0.98628442497042}'\n",
      "pcr_scale: {'fold_0': 17.72206940921658, 'fold_1': 17.63459696152566, 'fold_2': 20.620676683259067, 'fold_3': 20.621847013154795, 'fold_4': 38.049238520287176, 'MSE': 22.928636705796265, 'R2': 0.9618492788753639}'\n",
      "pcr_whiten: {'fold_0': 8.070901015205088, 'fold_1': 8.468715619629542, 'fold_2': 7.752240405485092, 'fold_3': 8.856722494956347, 'fold_4': 8.066792554012027, 'MSE': 8.243079758229085, 'R2': 0.98628442497042}'\n",
      "pcr_s_w: {'fold_0': 17.722071507960166, 'fold_1': 17.634591004186632, 'fold_2': 20.620677547062723, 'fold_3': 20.6218465090174, 'fold_4': 38.049245096722395, 'MSE': 22.928637320789115, 'R2': 0.9618492778520836}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 6 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:7.2119,pcr_scale:16.7297,pcr_whiten:7.2119,pcr_s_w:16.7297'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:7.002,pcr_scale:15.0646,pcr_whiten:7.002,pcr_s_w:15.0646'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:7.1823,pcr_scale:18.2941,pcr_whiten:7.1823,pcr_s_w:18.2941'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:7.2091,pcr_scale:16.3357,pcr_whiten:7.2091,pcr_s_w:16.3357'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:7.2386,pcr_scale:17.2796,pcr_whiten:7.2386,pcr_s_w:17.2796'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:6.4504,pcr_scale:17.4499,pcr_whiten:6.4504,pcr_s_w:17.4499'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:7.1464,pcr_scale:17.6274,pcr_whiten:7.1464,pcr_s_w:17.6274'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:7.7757,pcr_scale:15.8509,pcr_whiten:7.7757,pcr_s_w:15.8509'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.9091,pcr_scale:16.5306,pcr_whiten:6.9091,pcr_s_w:16.5306'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:6.8963,pcr_scale:36.8819,pcr_whiten:6.8963,pcr_s_w:36.8819'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:6.7668,pcr_scale:17.9274,pcr_whiten:6.7668,pcr_s_w:17.9274'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:7.1195,pcr_scale:16.327,pcr_whiten:7.1195,pcr_s_w:16.327'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 7.001961431877896, 'pcr_scale': 15.06464312846911, 'pcr_whiten': 7.001961431877877, 'pcr_s_w': 15.064643498824797}, 'fold_1': {'pcr': 7.2090511680403555, 'pcr_scale': 16.335746223030444, 'pcr_whiten': 7.209051168040363, 'pcr_s_w': 16.335745005182563}, 'fold_2': {'pcr': 6.450415526624994, 'pcr_scale': 17.44989279186883, 'pcr_whiten': 6.450415526624993, 'pcr_s_w': 17.449892044581947}, 'fold_3': {'pcr': 7.775702531079188, 'pcr_scale': 15.85089004995927, 'pcr_whiten': 7.775702531079177, 'pcr_s_w': 15.850889846638701}, 'fold_4': {'pcr': 6.896349766584353, 'pcr_scale': 36.88192913577328, 'pcr_whiten': 6.896349766584355, 'pcr_s_w': 36.88192708176947}, 'MSE': {'pcr': 7.066703837581094, 'pcr_scale': 20.315698087316377, 'pcr_whiten': 7.066703837581089, 'pcr_s_w': 20.315697316964936}, 'R2': {'pcr': 0.9882417846801246, 'pcr_scale': 0.9661969203783678, 'pcr_whiten': 0.9882417846801246, 'pcr_s_w': 0.9661969216601476}}'\n",
      "pcr: {'fold_0': 7.001961431877896, 'fold_1': 7.2090511680403555, 'fold_2': 6.450415526624994, 'fold_3': 7.775702531079188, 'fold_4': 6.896349766584353, 'MSE': 7.066703837581094, 'R2': 0.9882417846801246}'\n",
      "pcr_scale: {'fold_0': 15.06464312846911, 'fold_1': 16.335746223030444, 'fold_2': 17.44989279186883, 'fold_3': 15.85089004995927, 'fold_4': 36.88192913577328, 'MSE': 20.315698087316377, 'R2': 0.9661969203783678}'\n",
      "pcr_whiten: {'fold_0': 7.001961431877877, 'fold_1': 7.209051168040363, 'fold_2': 6.450415526624993, 'fold_3': 7.775702531079177, 'fold_4': 6.896349766584355, 'MSE': 7.066703837581089, 'R2': 0.9882417846801246}'\n",
      "pcr_s_w: {'fold_0': 15.064643498824797, 'fold_1': 16.335745005182563, 'fold_2': 17.449892044581947, 'fold_3': 15.850889846638701, 'fold_4': 36.88192708176947, 'MSE': 20.315697316964936, 'R2': 0.9661969216601476}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 7 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.8063,pcr_scale:16.0801,pcr_whiten:6.8063,pcr_s_w:16.0801'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:6.8235,pcr_scale:14.7823,pcr_whiten:6.8235,pcr_s_w:14.7823'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.9101,pcr_scale:16.8377,pcr_whiten:6.9101,pcr_s_w:16.8377'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:7.0311,pcr_scale:16.6143,pcr_whiten:7.0311,pcr_s_w:16.6143'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:7.0148,pcr_scale:16.0521,pcr_whiten:7.0148,pcr_s_w:16.0521'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:6.3593,pcr_scale:17.8781,pcr_whiten:6.3593,pcr_s_w:17.8781'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.8166,pcr_scale:16.0566,pcr_whiten:6.8166,pcr_s_w:16.0566'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:7.6034,pcr_scale:15.9343,pcr_whiten:7.6034,pcr_s_w:15.9343'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.6086,pcr_scale:15.9055,pcr_whiten:6.6086,pcr_s_w:15.9055'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:6.8347,pcr_scale:28.7419,pcr_whiten:6.8347,pcr_s_w:28.7419'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:6.7261,pcr_scale:16.5101,pcr_whiten:6.7261,pcr_s_w:16.5101'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:7.0764,pcr_scale:16.3409,pcr_whiten:7.0764,pcr_s_w:16.3409'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 6.823451075059412, 'pcr_scale': 14.782315631878738, 'pcr_whiten': 6.823451075059405, 'pcr_s_w': 14.782315682076227}, 'fold_1': {'pcr': 7.031056036697449, 'pcr_scale': 16.614344100298222, 'pcr_whiten': 7.031056036697437, 'pcr_s_w': 16.61434405751291}, 'fold_2': {'pcr': 6.359303115700182, 'pcr_scale': 17.87805625629894, 'pcr_whiten': 6.359303115700178, 'pcr_s_w': 17.878056320418366}, 'fold_3': {'pcr': 7.6033609163454425, 'pcr_scale': 15.934304279840482, 'pcr_whiten': 7.603360916345455, 'pcr_s_w': 15.934304470223097}, 'fold_4': {'pcr': 6.834653755295386, 'pcr_scale': 28.74194160244513, 'pcr_whiten': 6.834653755295388, 'pcr_s_w': 28.741943719529182}, 'MSE': {'pcr': 6.930364358280632, 'pcr_scale': 18.789574742808302, 'pcr_whiten': 6.930364358280632, 'pcr_s_w': 18.78957521851365}, 'R2': {'pcr': 0.9884686385275561, 'pcr_scale': 0.9687362212040207, 'pcr_whiten': 0.9884686385275561, 'pcr_s_w': 0.9687362204124995}}'\n",
      "pcr: {'fold_0': 6.823451075059412, 'fold_1': 7.031056036697449, 'fold_2': 6.359303115700182, 'fold_3': 7.6033609163454425, 'fold_4': 6.834653755295386, 'MSE': 6.930364358280632, 'R2': 0.9884686385275561}'\n",
      "pcr_scale: {'fold_0': 14.782315631878738, 'fold_1': 16.614344100298222, 'fold_2': 17.87805625629894, 'fold_3': 15.934304279840482, 'fold_4': 28.74194160244513, 'MSE': 18.789574742808302, 'R2': 0.9687362212040207}'\n",
      "pcr_whiten: {'fold_0': 6.823451075059405, 'fold_1': 7.031056036697437, 'fold_2': 6.359303115700178, 'fold_3': 7.603360916345455, 'fold_4': 6.834653755295388, 'MSE': 6.930364358280632, 'R2': 0.9884686385275561}'\n",
      "pcr_s_w: {'fold_0': 14.782315682076227, 'fold_1': 16.61434405751291, 'fold_2': 17.878056320418366, 'fold_3': 15.934304470223097, 'fold_4': 28.741943719529182, 'MSE': 18.78957521851365, 'R2': 0.9687362204124995}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 8 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.6338,pcr_scale:15.5533,pcr_whiten:6.6338,pcr_s_w:15.5533'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:6.6594,pcr_scale:14.1092,pcr_whiten:6.6594,pcr_s_w:14.1092'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.6695,pcr_scale:15.8746,pcr_whiten:6.6695,pcr_s_w:15.8746'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:6.5469,pcr_scale:15.8913,pcr_whiten:6.5469,pcr_s_w:15.8913'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.8045,pcr_scale:15.3504,pcr_whiten:6.8045,pcr_s_w:15.3504'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:6.1187,pcr_scale:16.7238,pcr_whiten:6.1187,pcr_s_w:16.7238'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.5735,pcr_scale:15.6079,pcr_whiten:6.5735,pcr_s_w:15.6079'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:7.2329,pcr_scale:15.3798,pcr_whiten:7.2329,pcr_s_w:15.3798'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.4325,pcr_scale:15.3947,pcr_whiten:6.4325,pcr_s_w:15.3947'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:6.7182,pcr_scale:27.93,pcr_whiten:6.7182,pcr_s_w:27.93'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:6.443,pcr_scale:15.8709,pcr_whiten:6.443,pcr_s_w:15.8709'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:6.7739,pcr_scale:15.5231,pcr_whiten:6.7739,pcr_s_w:15.5231'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 6.659444775379159, 'pcr_scale': 14.109195210986039, 'pcr_whiten': 6.6594447753791535, 'pcr_s_w': 14.109195243647616}, 'fold_1': {'pcr': 6.546929425429421, 'pcr_scale': 15.891265661577203, 'pcr_whiten': 6.54692942542941, 'pcr_s_w': 15.891264105813303}, 'fold_2': {'pcr': 6.118748416490256, 'pcr_scale': 16.72376327563654, 'pcr_whiten': 6.118748416490256, 'pcr_s_w': 16.723764827527418}, 'fold_3': {'pcr': 7.232899993205603, 'pcr_scale': 15.379800332209955, 'pcr_whiten': 7.23289999320561, 'pcr_s_w': 15.37980038956087}, 'fold_4': {'pcr': 6.7182364070814025, 'pcr_scale': 27.92998752051041, 'pcr_whiten': 6.7182364070813945, 'pcr_s_w': 27.92999139728261}, 'MSE': {'pcr': 6.655241403057097, 'pcr_scale': 18.00620180650366, 'pcr_whiten': 6.6552414030570946, 'pcr_s_w': 18.006202598775545}, 'R2': {'pcr': 0.9889264127630851, 'pcr_scale': 0.970039667318721, 'pcr_whiten': 0.9889264127630851, 'pcr_s_w': 0.9700396660004681}}'\n",
      "pcr: {'fold_0': 6.659444775379159, 'fold_1': 6.546929425429421, 'fold_2': 6.118748416490256, 'fold_3': 7.232899993205603, 'fold_4': 6.7182364070814025, 'MSE': 6.655241403057097, 'R2': 0.9889264127630851}'\n",
      "pcr_scale: {'fold_0': 14.109195210986039, 'fold_1': 15.891265661577203, 'fold_2': 16.72376327563654, 'fold_3': 15.379800332209955, 'fold_4': 27.92998752051041, 'MSE': 18.00620180650366, 'R2': 0.970039667318721}'\n",
      "pcr_whiten: {'fold_0': 6.6594447753791535, 'fold_1': 6.54692942542941, 'fold_2': 6.118748416490256, 'fold_3': 7.23289999320561, 'fold_4': 6.7182364070813945, 'MSE': 6.6552414030570946, 'R2': 0.9889264127630851}'\n",
      "pcr_s_w: {'fold_0': 14.109195243647616, 'fold_1': 15.891264105813303, 'fold_2': 16.723764827527418, 'fold_3': 15.37980038956087, 'fold_4': 27.92999139728261, 'MSE': 18.006202598775545, 'R2': 0.9700396660004681}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 9 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.1588,pcr_scale:15.5408,pcr_whiten:6.1588,pcr_s_w:15.5408'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:6.1931,pcr_scale:14.1317,pcr_whiten:6.1931,pcr_s_w:14.1317'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.5966,pcr_scale:15.6694,pcr_whiten:6.5966,pcr_s_w:15.6694'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:6.4853,pcr_scale:16.061,pcr_whiten:6.4853,pcr_s_w:16.061'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.7533,pcr_scale:15.2453,pcr_whiten:6.7533,pcr_s_w:15.2453'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:5.9915,pcr_scale:16.7384,pcr_whiten:5.9915,pcr_s_w:16.7384'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.5252,pcr_scale:15.4159,pcr_whiten:6.5252,pcr_s_w:15.4159'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:7.2137,pcr_scale:15.0999,pcr_whiten:7.2137,pcr_s_w:15.0999'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:5.9762,pcr_scale:15.2418,pcr_whiten:5.9762,pcr_s_w:15.2418'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:9.7377,pcr_scale:30.0278,pcr_whiten:9.7377,pcr_s_w:30.0278'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:6.3795,pcr_scale:15.748,pcr_whiten:6.3795,pcr_s_w:15.748'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:6.752,pcr_scale:15.3228,pcr_whiten:6.752,pcr_s_w:15.3228'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 6.19305246797006, 'pcr_scale': 14.131719074006055, 'pcr_whiten': 6.193052467970067, 'pcr_s_w': 14.131719162114065}, 'fold_1': {'pcr': 6.485270053132975, 'pcr_scale': 16.061035942313477, 'pcr_whiten': 6.4852700531329885, 'pcr_s_w': 16.061036223292888}, 'fold_2': {'pcr': 5.991531627899181, 'pcr_scale': 16.738360984137774, 'pcr_whiten': 5.9915316278991755, 'pcr_s_w': 16.738361061770338}, 'fold_3': {'pcr': 7.213745949709079, 'pcr_scale': 15.099888643563288, 'pcr_whiten': 7.213745949709094, 'pcr_s_w': 15.099888234076282}, 'fold_4': {'pcr': 9.737749971939847, 'pcr_scale': 30.027772242734166, 'pcr_whiten': 9.73774997193982, 'pcr_s_w': 30.027771270114222}, 'MSE': {'pcr': 7.124113180579772, 'pcr_scale': 18.411093096514122, 'pcr_whiten': 7.124113180579774, 'pcr_s_w': 18.411092909510963}, 'R2': {'pcr': 0.9881462618689433, 'pcr_scale': 0.969365972895054, 'pcr_whiten': 0.9881462618689433, 'pcr_s_w': 0.9693659732062065}}'\n",
      "pcr: {'fold_0': 6.19305246797006, 'fold_1': 6.485270053132975, 'fold_2': 5.991531627899181, 'fold_3': 7.213745949709079, 'fold_4': 9.737749971939847, 'MSE': 7.124113180579772, 'R2': 0.9881462618689433}'\n",
      "pcr_scale: {'fold_0': 14.131719074006055, 'fold_1': 16.061035942313477, 'fold_2': 16.738360984137774, 'fold_3': 15.099888643563288, 'fold_4': 30.027772242734166, 'MSE': 18.411093096514122, 'R2': 0.969365972895054}'\n",
      "pcr_whiten: {'fold_0': 6.193052467970067, 'fold_1': 6.4852700531329885, 'fold_2': 5.9915316278991755, 'fold_3': 7.213745949709094, 'fold_4': 9.73774997193982, 'MSE': 7.124113180579774, 'R2': 0.9881462618689433}'\n",
      "pcr_s_w: {'fold_0': 14.131719162114065, 'fold_1': 16.061036223292888, 'fold_2': 16.738361061770338, 'fold_3': 15.099888234076282, 'fold_4': 30.027771270114222, 'MSE': 18.411092909510963, 'R2': 0.9693659732062065}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 10 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:5.8349,pcr_scale:14.9702,pcr_whiten:5.8349,pcr_s_w:14.9702'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:5.9188,pcr_scale:13.6327,pcr_whiten:5.9188,pcr_s_w:13.6327'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.2112,pcr_scale:15.637,pcr_whiten:6.2112,pcr_s_w:15.637'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:6.1769,pcr_scale:16.0987,pcr_whiten:6.1769,pcr_s_w:16.0987'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.3343,pcr_scale:15.095,pcr_whiten:6.3343,pcr_s_w:15.095'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:5.7505,pcr_scale:16.5496,pcr_whiten:5.7505,pcr_s_w:16.5496'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.1833,pcr_scale:15.2531,pcr_whiten:6.1833,pcr_s_w:15.2531'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:6.6375,pcr_scale:14.9812,pcr_whiten:6.6375,pcr_s_w:14.9812'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:5.7084,pcr_scale:14.9317,pcr_whiten:5.7084,pcr_s_w:14.9317'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:9.1989,pcr_scale:33.9469,pcr_whiten:9.1989,pcr_s_w:33.9469'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:6.0657,pcr_scale:15.7212,pcr_whiten:6.0657,pcr_s_w:15.7212'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:6.2407,pcr_scale:15.3189,pcr_whiten:6.2407,pcr_s_w:15.3189'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 5.918801401024682, 'pcr_scale': 13.632710918873732, 'pcr_whiten': 5.918801401024666, 'pcr_s_w': 13.632710917209431}, 'fold_1': {'pcr': 6.1768794884391705, 'pcr_scale': 16.09874452353171, 'pcr_whiten': 6.176879488439202, 'pcr_s_w': 16.09874454261939}, 'fold_2': {'pcr': 5.750518707760471, 'pcr_scale': 16.549648046770663, 'pcr_whiten': 5.750518707760484, 'pcr_s_w': 16.549648228573073}, 'fold_3': {'pcr': 6.637528995248562, 'pcr_scale': 14.981164539333342, 'pcr_whiten': 6.637528995248654, 'pcr_s_w': 14.981164126317564}, 'fold_4': {'pcr': 9.19890909569919, 'pcr_scale': 33.94689114889297, 'pcr_whiten': 9.198909095699182, 'pcr_s_w': 33.946891851219476}, 'MSE': {'pcr': 6.7363899653026325, 'pcr_scale': 19.040997615721338, 'pcr_whiten': 6.7363899653026555, 'pcr_s_w': 19.04099771341086}, 'R2': {'pcr': 0.988791390510885, 'pcr_scale': 0.9683178812899675, 'pcr_whiten': 0.9887913905108849, 'pcr_s_w': 0.9683178811274229}}'\n",
      "pcr: {'fold_0': 5.918801401024682, 'fold_1': 6.1768794884391705, 'fold_2': 5.750518707760471, 'fold_3': 6.637528995248562, 'fold_4': 9.19890909569919, 'MSE': 6.7363899653026325, 'R2': 0.988791390510885}'\n",
      "pcr_scale: {'fold_0': 13.632710918873732, 'fold_1': 16.09874452353171, 'fold_2': 16.549648046770663, 'fold_3': 14.981164539333342, 'fold_4': 33.94689114889297, 'MSE': 19.040997615721338, 'R2': 0.9683178812899675}'\n",
      "pcr_whiten: {'fold_0': 5.918801401024666, 'fold_1': 6.176879488439202, 'fold_2': 5.750518707760484, 'fold_3': 6.637528995248654, 'fold_4': 9.198909095699182, 'MSE': 6.7363899653026555, 'R2': 0.9887913905108849}'\n",
      "pcr_s_w: {'fold_0': 13.632710917209431, 'fold_1': 16.09874454261939, 'fold_2': 16.549648228573073, 'fold_3': 14.981164126317564, 'fold_4': 33.946891851219476, 'MSE': 19.04099771341086, 'R2': 0.9683178811274229}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 11 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:5.6681,pcr_scale:13.895,pcr_whiten:5.6681,pcr_s_w:13.895'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:5.7191,pcr_scale:12.3588,pcr_whiten:5.7191,pcr_s_w:12.3588'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:5.9419,pcr_scale:15.4706,pcr_whiten:5.9419,pcr_s_w:15.4706'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:5.9016,pcr_scale:15.8491,pcr_whiten:5.9016,pcr_s_w:15.8491'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:6.0477,pcr_scale:15.0184,pcr_whiten:6.0477,pcr_s_w:15.0184'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:5.469,pcr_scale:16.6382,pcr_whiten:5.469,pcr_s_w:16.6382'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:5.8221,pcr_scale:14.9185,pcr_whiten:5.8221,pcr_s_w:14.9185'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:6.2948,pcr_scale:15.2652,pcr_whiten:6.2948,pcr_s_w:15.2652'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:5.4812,pcr_scale:13.2319,pcr_whiten:5.4812,pcr_s_w:13.2319'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:8.0505,pcr_scale:59.1941,pcr_whiten:8.0505,pcr_s_w:59.1942'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:5.7134,pcr_scale:15.4503,pcr_whiten:5.7134,pcr_s_w:15.4503'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:6.2274,pcr_scale:14.9168,pcr_whiten:6.2274,pcr_s_w:14.9168'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 5.719134525478846, 'pcr_scale': 12.358806757437993, 'pcr_whiten': 5.719134525479344, 'pcr_s_w': 12.358807217817331}, 'fold_1': {'pcr': 5.9015814861965055, 'pcr_scale': 15.849102136122603, 'pcr_whiten': 5.901581486194806, 'pcr_s_w': 15.849102244035018}, 'fold_2': {'pcr': 5.469032556501605, 'pcr_scale': 16.638185964454365, 'pcr_whiten': 5.469032556501172, 'pcr_s_w': 16.638185645157684}, 'fold_3': {'pcr': 6.294810486876256, 'pcr_scale': 15.265226343608683, 'pcr_whiten': 6.294810486875493, 'pcr_s_w': 15.265226138534347}, 'fold_4': {'pcr': 8.050547694953513, 'pcr_scale': 59.19412914768845, 'pcr_whiten': 8.050547694953423, 'pcr_s_w': 59.19418179329838}, 'MSE': {'pcr': 6.2869261315946, 'pcr_scale': 23.859140981643666, 'pcr_whiten': 6.286926131594103, 'pcr_s_w': 23.859151517501502}, 'R2': {'pcr': 0.9895392487283372, 'pcr_scale': 0.9603010224487547, 'pcr_whiten': 0.989539248728338, 'pcr_s_w': 0.96030100491825}}'\n",
      "pcr: {'fold_0': 5.719134525478846, 'fold_1': 5.9015814861965055, 'fold_2': 5.469032556501605, 'fold_3': 6.294810486876256, 'fold_4': 8.050547694953513, 'MSE': 6.2869261315946, 'R2': 0.9895392487283372}'\n",
      "pcr_scale: {'fold_0': 12.358806757437993, 'fold_1': 15.849102136122603, 'fold_2': 16.638185964454365, 'fold_3': 15.265226343608683, 'fold_4': 59.19412914768845, 'MSE': 23.859140981643666, 'R2': 0.9603010224487547}'\n",
      "pcr_whiten: {'fold_0': 5.719134525479344, 'fold_1': 5.901581486194806, 'fold_2': 5.469032556501172, 'fold_3': 6.294810486875493, 'fold_4': 8.050547694953423, 'MSE': 6.286926131594103, 'R2': 0.989539248728338}'\n",
      "pcr_s_w: {'fold_0': 12.358807217817331, 'fold_1': 15.849102244035018, 'fold_2': 16.638185645157684, 'fold_3': 15.265226138534347, 'fold_4': 59.19418179329838, 'MSE': 23.859151517501502, 'R2': 0.96030100491825}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 12 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:5.4784,pcr_scale:13.6978,pcr_whiten:5.4784,pcr_s_w:13.6978'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:5.5307,pcr_scale:12.0609,pcr_whiten:5.5307,pcr_s_w:12.0609'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:4.9372,pcr_scale:15.3938,pcr_whiten:4.9372,pcr_s_w:15.3938'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:5.0783,pcr_scale:15.8736,pcr_whiten:5.0783,pcr_s_w:15.8736'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:5.1341,pcr_scale:14.9351,pcr_whiten:5.1341,pcr_s_w:14.9351'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:4.5754,pcr_scale:16.5064,pcr_whiten:4.5754,pcr_s_w:16.5064'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:5.4632,pcr_scale:14.9161,pcr_whiten:5.4632,pcr_s_w:14.9161'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:5.9498,pcr_scale:15.2928,pcr_whiten:5.9498,pcr_s_w:15.2928'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:5.314,pcr_scale:13.2047,pcr_whiten:5.314,pcr_s_w:13.2047'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:6.9866,pcr_scale:58.1823,pcr_whiten:6.9866,pcr_s_w:58.1823'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:5.229,pcr_scale:15.4414,pcr_whiten:5.229,pcr_s_w:15.4414'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:5.6782,pcr_scale:14.9031,pcr_whiten:5.6782,pcr_s_w:14.9031'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 5.530661419667955, 'pcr_scale': 12.060949650353363, 'pcr_whiten': 5.5306614196473385, 'pcr_s_w': 12.060948365223314}, 'fold_1': {'pcr': 5.078295679088295, 'pcr_scale': 15.873569605798378, 'pcr_whiten': 5.078295679232194, 'pcr_s_w': 15.873569745239626}, 'fold_2': {'pcr': 4.575428565832294, 'pcr_scale': 16.506415246107405, 'pcr_whiten': 4.575428565950465, 'pcr_s_w': 16.506415429315357}, 'fold_3': {'pcr': 5.949791423469555, 'pcr_scale': 15.292771393635842, 'pcr_whiten': 5.949791423455335, 'pcr_s_w': 15.292770955663912}, 'fold_4': {'pcr': 6.986613083779649, 'pcr_scale': 58.18227141189031, 'pcr_whiten': 6.986613083786696, 'pcr_s_w': 58.18227381969008}, 'MSE': {'pcr': 5.624094175101671, 'pcr_scale': 23.581274579448895, 'pcr_whiten': 5.62409417514853, 'pcr_s_w': 23.581274780763618}, 'R2': {'pcr': 0.9906421279552677, 'pcr_scale': 0.9607633614772831, 'pcr_whiten': 0.9906421279551897, 'pcr_s_w': 0.9607633611423176}}'\n",
      "pcr: {'fold_0': 5.530661419667955, 'fold_1': 5.078295679088295, 'fold_2': 4.575428565832294, 'fold_3': 5.949791423469555, 'fold_4': 6.986613083779649, 'MSE': 5.624094175101671, 'R2': 0.9906421279552677}'\n",
      "pcr_scale: {'fold_0': 12.060949650353363, 'fold_1': 15.873569605798378, 'fold_2': 16.506415246107405, 'fold_3': 15.292771393635842, 'fold_4': 58.18227141189031, 'MSE': 23.581274579448895, 'R2': 0.9607633614772831}'\n",
      "pcr_whiten: {'fold_0': 5.5306614196473385, 'fold_1': 5.078295679232194, 'fold_2': 4.575428565950465, 'fold_3': 5.949791423455335, 'fold_4': 6.986613083786696, 'MSE': 5.62409417514853, 'R2': 0.9906421279551897}'\n",
      "pcr_s_w: {'fold_0': 12.060948365223314, 'fold_1': 15.873569745239626, 'fold_2': 16.506415429315357, 'fold_3': 15.292770955663912, 'fold_4': 58.18227381969008, 'MSE': 23.581274780763618, 'R2': 0.9607633611423176}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 13 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:5.3142,pcr_scale:10.5308,pcr_whiten:5.3142,pcr_s_w:10.5308'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:5.3904,pcr_scale:9.6703,pcr_whiten:5.3904,pcr_s_w:9.6703'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:4.8827,pcr_scale:7.6688,pcr_whiten:4.8827,pcr_s_w:7.6688'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:5.1722,pcr_scale:8.2324,pcr_whiten:5.1722,pcr_s_w:8.2323'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:5.1278,pcr_scale:7.5758,pcr_whiten:5.1278,pcr_s_w:7.5758'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:4.5707,pcr_scale:7.5495,pcr_whiten:4.5707,pcr_s_w:7.5495'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:4.8865,pcr_scale:7.7522,pcr_whiten:4.8865,pcr_s_w:7.7522'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:5.3198,pcr_scale:8.1064,pcr_whiten:5.3198,pcr_s_w:8.1064'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:4.8124,pcr_scale:9.4283,pcr_whiten:4.8124,pcr_s_w:9.4284'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:5.3532,pcr_scale:20.6433,pcr_whiten:5.3532,pcr_s_w:20.6434'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:4.8228,pcr_scale:7.332,pcr_whiten:4.8228,pcr_s_w:7.332'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:5.0402,pcr_scale:7.5499,pcr_whiten:5.0402,pcr_s_w:7.5499'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 5.390395962336606, 'pcr_scale': 9.670257112287134, 'pcr_whiten': 5.390395962473412, 'pcr_s_w': 9.670273489356752}, 'fold_1': {'pcr': 5.172200644716033, 'pcr_scale': 8.232367764393107, 'pcr_whiten': 5.172200644669933, 'pcr_s_w': 8.232334210532445}, 'fold_2': {'pcr': 4.570721605041432, 'pcr_scale': 7.549483279771231, 'pcr_whiten': 4.570721604990994, 'pcr_s_w': 7.549481899865761}, 'fold_3': {'pcr': 5.319848003707437, 'pcr_scale': 8.106380744411323, 'pcr_whiten': 5.319848003576041, 'pcr_s_w': 8.106387422018846}, 'fold_4': {'pcr': 5.353159049695341, 'pcr_scale': 20.643290511327645, 'pcr_whiten': 5.353159049720209, 'pcr_s_w': 20.643388343342266}, 'MSE': {'pcr': 5.161289030976003, 'pcr_scale': 10.839978526576303, 'pcr_whiten': 5.161289030962764, 'pcr_s_w': 10.839995712011811}, 'R2': {'pcr': 0.9914121846409372, 'pcr_scale': 0.9819634720079143, 'pcr_whiten': 0.9914121846409591, 'pcr_s_w': 0.9819634434132463}}'\n",
      "pcr: {'fold_0': 5.390395962336606, 'fold_1': 5.172200644716033, 'fold_2': 4.570721605041432, 'fold_3': 5.319848003707437, 'fold_4': 5.353159049695341, 'MSE': 5.161289030976003, 'R2': 0.9914121846409372}'\n",
      "pcr_scale: {'fold_0': 9.670257112287134, 'fold_1': 8.232367764393107, 'fold_2': 7.549483279771231, 'fold_3': 8.106380744411323, 'fold_4': 20.643290511327645, 'MSE': 10.839978526576303, 'R2': 0.9819634720079143}'\n",
      "pcr_whiten: {'fold_0': 5.390395962473412, 'fold_1': 5.172200644669933, 'fold_2': 4.570721604990994, 'fold_3': 5.319848003576041, 'fold_4': 5.353159049720209, 'MSE': 5.161289030962764, 'R2': 0.9914121846409591}'\n",
      "pcr_s_w: {'fold_0': 9.670273489356752, 'fold_1': 8.232334210532445, 'fold_2': 7.549481899865761, 'fold_3': 8.106387422018846, 'fold_4': 20.643388343342266, 'MSE': 10.839995712011811, 'R2': 0.9819634434132463}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 14 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:4.4273,pcr_scale:7.0938,pcr_whiten:4.4273,pcr_s_w:7.0938'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:4.3751,pcr_scale:6.7817,pcr_whiten:4.3751,pcr_s_w:6.7817'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:4.43,pcr_scale:7.5463,pcr_whiten:4.43,pcr_s_w:7.5463'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:4.4996,pcr_scale:8.0429,pcr_whiten:4.4996,pcr_s_w:8.0429'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:4.4629,pcr_scale:7.5739,pcr_whiten:4.4629,pcr_s_w:7.5739'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:4.0744,pcr_scale:7.5464,pcr_whiten:4.0744,pcr_s_w:7.5464'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:4.3038,pcr_scale:7.7484,pcr_whiten:4.3038,pcr_s_w:7.7484'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:4.6323,pcr_scale:8.0699,pcr_whiten:4.6323,pcr_s_w:8.0699'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:4.2076,pcr_scale:6.9406,pcr_whiten:4.2076,pcr_s_w:6.9406'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:4.4933,pcr_scale:9.6794,pcr_whiten:4.4933,pcr_s_w:9.6794'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:4.2364,pcr_scale:7.2766,pcr_whiten:4.2364,pcr_s_w:7.2766'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:4.2492,pcr_scale:7.4632,pcr_whiten:4.2492,pcr_s_w:7.4632'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 4.375146894115419, 'pcr_scale': 6.781740343700101, 'pcr_whiten': 4.375146893729534, 'pcr_s_w': 6.781736115304873}, 'fold_1': {'pcr': 4.49955436691785, 'pcr_scale': 8.042942334978294, 'pcr_whiten': 4.499554365305432, 'pcr_s_w': 8.042937647895151}, 'fold_2': {'pcr': 4.074443532538143, 'pcr_scale': 7.546373891985349, 'pcr_whiten': 4.07444353259602, 'pcr_s_w': 7.546376538683799}, 'fold_3': {'pcr': 4.6322538353815395, 'pcr_scale': 8.06985616308959, 'pcr_whiten': 4.6322538359269645, 'pcr_s_w': 8.069856412716225}, 'fold_4': {'pcr': 4.493251791386481, 'pcr_scale': 9.679435413417727, 'pcr_whiten': 4.4932517913099455, 'pcr_s_w': 9.679434604244307}, 'MSE': {'pcr': 4.414934562802695, 'pcr_scale': 8.023947430415017, 'pcr_whiten': 4.414934562508246, 'pcr_s_w': 8.023946064132002}, 'R2': {'pcr': 0.9926540361099435, 'pcr_scale': 0.9866490369809419, 'pcr_whiten': 0.9926540361104335, 'pcr_s_w': 0.986649039254286}}'\n",
      "pcr: {'fold_0': 4.375146894115419, 'fold_1': 4.49955436691785, 'fold_2': 4.074443532538143, 'fold_3': 4.6322538353815395, 'fold_4': 4.493251791386481, 'MSE': 4.414934562802695, 'R2': 0.9926540361099435}'\n",
      "pcr_scale: {'fold_0': 6.781740343700101, 'fold_1': 8.042942334978294, 'fold_2': 7.546373891985349, 'fold_3': 8.06985616308959, 'fold_4': 9.679435413417727, 'MSE': 8.023947430415017, 'R2': 0.9866490369809419}'\n",
      "pcr_whiten: {'fold_0': 4.375146893729534, 'fold_1': 4.499554365305432, 'fold_2': 4.07444353259602, 'fold_3': 4.6322538359269645, 'fold_4': 4.4932517913099455, 'MSE': 4.414934562508246, 'R2': 0.9926540361104335}'\n",
      "pcr_s_w: {'fold_0': 6.781736115304873, 'fold_1': 8.042937647895151, 'fold_2': 7.546376538683799, 'fold_3': 8.069856412716225, 'fold_4': 9.679434604244307, 'MSE': 8.023946064132002, 'R2': 0.986649039254286}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 15 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8555,pcr_scale:6.4652,pcr_whiten:3.8555,pcr_s_w:6.4652'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.868,pcr_scale:6.3023,pcr_whiten:3.868,pcr_s_w:6.3023'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8797,pcr_scale:6.6022,pcr_whiten:3.8797,pcr_s_w:6.6022'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.9985,pcr_scale:6.8515,pcr_whiten:3.9985,pcr_s_w:6.8515'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.9528,pcr_scale:6.7941,pcr_whiten:3.9528,pcr_s_w:6.7941'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.6514,pcr_scale:6.5142,pcr_whiten:3.6514,pcr_s_w:6.5142'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.9657,pcr_scale:6.6204,pcr_whiten:3.9657,pcr_s_w:6.6204'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:4.2472,pcr_scale:7.1184,pcr_whiten:4.2472,pcr_s_w:7.1184'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8344,pcr_scale:6.399,pcr_whiten:3.8344,pcr_s_w:6.399'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:4.1464,pcr_scale:7.9362,pcr_whiten:4.1464,pcr_s_w:7.9362'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.9016,pcr_scale:6.4733,pcr_whiten:3.9016,pcr_s_w:6.4733'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.8896,pcr_scale:6.8232,pcr_whiten:3.8896,pcr_s_w:6.8232'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.8680123819774193, 'pcr_scale': 6.302310735193374, 'pcr_whiten': 3.8680123800150747, 'pcr_s_w': 6.302311228820965}, 'fold_1': {'pcr': 3.998502668756031, 'pcr_scale': 6.851513164556428, 'pcr_whiten': 3.998502661251679, 'pcr_s_w': 6.851493162460278}, 'fold_2': {'pcr': 3.651415220867968, 'pcr_scale': 6.514244137049131, 'pcr_whiten': 3.6514151797073082, 'pcr_s_w': 6.514244356451207}, 'fold_3': {'pcr': 4.247177678671207, 'pcr_scale': 7.118414746187443, 'pcr_whiten': 4.247177656323814, 'pcr_s_w': 7.118410454780858}, 'fold_4': {'pcr': 4.1463915720554665, 'pcr_scale': 7.936248581809341, 'pcr_whiten': 4.146391577423763, 'pcr_s_w': 7.936243451909713}, 'MSE': {'pcr': 3.9822901077458623, 'pcr_scale': 6.9444728342210125, 'pcr_whiten': 3.982290094226327, 'pcr_s_w': 6.944467091345002}, 'R2': {'pcr': 0.9933739087374697, 'pcr_scale': 0.9884451635805717, 'pcr_whiten': 0.9933739087599647, 'pcr_s_w': 0.9884451731360835}}'\n",
      "pcr: {'fold_0': 3.8680123819774193, 'fold_1': 3.998502668756031, 'fold_2': 3.651415220867968, 'fold_3': 4.247177678671207, 'fold_4': 4.1463915720554665, 'MSE': 3.9822901077458623, 'R2': 0.9933739087374697}'\n",
      "pcr_scale: {'fold_0': 6.302310735193374, 'fold_1': 6.851513164556428, 'fold_2': 6.514244137049131, 'fold_3': 7.118414746187443, 'fold_4': 7.936248581809341, 'MSE': 6.9444728342210125, 'R2': 0.9884451635805717}'\n",
      "pcr_whiten: {'fold_0': 3.8680123800150747, 'fold_1': 3.998502661251679, 'fold_2': 3.6514151797073082, 'fold_3': 4.247177656323814, 'fold_4': 4.146391577423763, 'MSE': 3.982290094226327, 'R2': 0.9933739087599647}'\n",
      "pcr_s_w: {'fold_0': 6.302311228820965, 'fold_1': 6.851493162460278, 'fold_2': 6.514244356451207, 'fold_3': 7.118410454780858, 'fold_4': 7.936243451909713, 'MSE': 6.944467091345002, 'R2': 0.9884451731360835}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 16 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8039,pcr_scale:6.0679,pcr_whiten:3.8039,pcr_s_w:6.0679'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.8597,pcr_scale:5.9902,pcr_whiten:3.8597,pcr_s_w:5.9902'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8421,pcr_scale:6.2025,pcr_whiten:3.8421,pcr_s_w:6.2025'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:4.0041,pcr_scale:6.3829,pcr_whiten:4.0041,pcr_s_w:6.3829'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8993,pcr_scale:6.25,pcr_whiten:3.8993,pcr_s_w:6.2501'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.6172,pcr_scale:5.8874,pcr_whiten:3.6172,pcr_s_w:5.8875'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.9266,pcr_scale:6.0729,pcr_whiten:3.9266,pcr_s_w:6.073'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:4.1135,pcr_scale:6.2162,pcr_whiten:4.1135,pcr_s_w:6.2163'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7901,pcr_scale:5.7867,pcr_whiten:3.7901,pcr_s_w:5.7867'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:4.0484,pcr_scale:7.5393,pcr_whiten:4.0484,pcr_s_w:7.5393'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.8532,pcr_scale:5.9598,pcr_whiten:3.8532,pcr_s_w:5.9598'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.8096,pcr_scale:6.032,pcr_whiten:3.8096,pcr_s_w:6.032'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.859665442712867, 'pcr_scale': 5.9902416739146895, 'pcr_whiten': 3.859665449762231, 'pcr_s_w': 5.990240647455607}, 'fold_1': {'pcr': 4.004131139650648, 'pcr_scale': 6.382872969426697, 'pcr_whiten': 4.004131119839211, 'pcr_s_w': 6.382872430397183}, 'fold_2': {'pcr': 3.6172425515562407, 'pcr_scale': 5.887396369782689, 'pcr_whiten': 3.6172425965344996, 'pcr_s_w': 5.88746209681958}, 'fold_3': {'pcr': 4.113455641260559, 'pcr_scale': 6.2162427600242705, 'pcr_whiten': 4.11345562362237, 'pcr_s_w': 6.2162899362290585}, 'fold_4': {'pcr': 4.0483873292638926, 'pcr_scale': 7.539330678631194, 'pcr_whiten': 4.048387331513595, 'pcr_s_w': 7.539332721092284}, 'MSE': {'pcr': 3.928577084466607, 'pcr_scale': 6.403173610378144, 'pcr_whiten': 3.9285770878301993, 'pcr_s_w': 6.403196281734845}, 'R2': {'pcr': 0.9934632812805555, 'pcr_scale': 0.9893458257524569, 'pcr_whiten': 0.9934632812749589, 'pcr_s_w': 0.9893457880298213}}'\n",
      "pcr: {'fold_0': 3.859665442712867, 'fold_1': 4.004131139650648, 'fold_2': 3.6172425515562407, 'fold_3': 4.113455641260559, 'fold_4': 4.0483873292638926, 'MSE': 3.928577084466607, 'R2': 0.9934632812805555}'\n",
      "pcr_scale: {'fold_0': 5.9902416739146895, 'fold_1': 6.382872969426697, 'fold_2': 5.887396369782689, 'fold_3': 6.2162427600242705, 'fold_4': 7.539330678631194, 'MSE': 6.403173610378144, 'R2': 0.9893458257524569}'\n",
      "pcr_whiten: {'fold_0': 3.859665449762231, 'fold_1': 4.004131119839211, 'fold_2': 3.6172425965344996, 'fold_3': 4.11345562362237, 'fold_4': 4.048387331513595, 'MSE': 3.9285770878301993, 'R2': 0.9934632812749589}'\n",
      "pcr_s_w: {'fold_0': 5.990240647455607, 'fold_1': 6.382872430397183, 'fold_2': 5.88746209681958, 'fold_3': 6.2162899362290585, 'fold_4': 7.539332721092284, 'MSE': 6.403196281734845, 'R2': 0.9893457880298213}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 17 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7999,pcr_scale:5.7911,pcr_whiten:3.7999,pcr_s_w:5.7911'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.8538,pcr_scale:5.6466,pcr_whiten:3.8538,pcr_s_w:5.6465'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8318,pcr_scale:6.0814,pcr_whiten:3.8318,pcr_s_w:6.0814'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:4.0017,pcr_scale:6.3314,pcr_whiten:4.0017,pcr_s_w:6.3314'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8914,pcr_scale:6.112,pcr_whiten:3.8914,pcr_s_w:6.112'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.6248,pcr_scale:5.8563,pcr_whiten:3.6248,pcr_s_w:5.8563'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.9089,pcr_scale:6.0699,pcr_whiten:3.9089,pcr_s_w:6.0699'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:4.0497,pcr_scale:6.2239,pcr_whiten:4.0497,pcr_s_w:6.2239'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7609,pcr_scale:5.68,pcr_whiten:3.7609,pcr_s_w:5.68'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:4.0043,pcr_scale:6.9196,pcr_whiten:4.0043,pcr_s_w:6.9196'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.8295,pcr_scale:5.9581,pcr_whiten:3.8295,pcr_s_w:5.9581'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.7896,pcr_scale:6.0341,pcr_whiten:3.7896,pcr_s_w:6.0341'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.853819830121315, 'pcr_scale': 5.646553028721408, 'pcr_whiten': 3.8538198201156004, 'pcr_s_w': 5.646521188930549}, 'fold_1': {'pcr': 4.001693504274492, 'pcr_scale': 6.33137489874845, 'pcr_whiten': 4.00169352150415, 'pcr_s_w': 6.331366386948305}, 'fold_2': {'pcr': 3.624809503985633, 'pcr_scale': 5.856330641276295, 'pcr_whiten': 3.624809525465296, 'pcr_s_w': 5.85630541189906}, 'fold_3': {'pcr': 4.049743986922327, 'pcr_scale': 6.223934601444064, 'pcr_whiten': 4.049744273562227, 'pcr_s_w': 6.223930370401382}, 'fold_4': {'pcr': 4.004288313138742, 'pcr_scale': 6.919637427266962, 'pcr_whiten': 4.004288271685889, 'pcr_s_w': 6.919560315206662}, 'MSE': {'pcr': 3.9068751998098583, 'pcr_scale': 6.195524848585372, 'pcr_whiten': 3.906875254577767, 'pcr_s_w': 6.195495465610723}, 'R2': {'pcr': 0.9934993908216522, 'pcr_scale': 0.9896913303764204, 'pcr_whiten': 0.9934993907305244, 'pcr_s_w': 0.9896913792664476}}'\n",
      "pcr: {'fold_0': 3.853819830121315, 'fold_1': 4.001693504274492, 'fold_2': 3.624809503985633, 'fold_3': 4.049743986922327, 'fold_4': 4.004288313138742, 'MSE': 3.9068751998098583, 'R2': 0.9934993908216522}'\n",
      "pcr_scale: {'fold_0': 5.646553028721408, 'fold_1': 6.33137489874845, 'fold_2': 5.856330641276295, 'fold_3': 6.223934601444064, 'fold_4': 6.919637427266962, 'MSE': 6.195524848585372, 'R2': 0.9896913303764204}'\n",
      "pcr_whiten: {'fold_0': 3.8538198201156004, 'fold_1': 4.00169352150415, 'fold_2': 3.624809525465296, 'fold_3': 4.049744273562227, 'fold_4': 4.004288271685889, 'MSE': 3.906875254577767, 'R2': 0.9934993907305244}'\n",
      "pcr_s_w: {'fold_0': 5.646521188930549, 'fold_1': 6.331366386948305, 'fold_2': 5.85630541189906, 'fold_3': 6.223930370401382, 'fold_4': 6.919560315206662, 'MSE': 6.195495465610723, 'R2': 0.9896913792664476}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 18 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7666,pcr_scale:5.79,pcr_whiten:3.7666,pcr_s_w:5.79'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.8418,pcr_scale:5.6634,pcr_whiten:3.8418,pcr_s_w:5.6635'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8136,pcr_scale:5.9862,pcr_whiten:3.8136,pcr_s_w:5.9862'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.9937,pcr_scale:6.1845,pcr_whiten:3.9937,pcr_s_w:6.1845'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8892,pcr_scale:6.0432,pcr_whiten:3.8892,pcr_s_w:6.0432'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.6116,pcr_scale:5.7295,pcr_whiten:3.6116,pcr_s_w:5.7295'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.9068,pcr_scale:6.0338,pcr_whiten:3.9068,pcr_s_w:6.0338'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:4.0445,pcr_scale:6.172,pcr_whiten:4.0445,pcr_s_w:6.172'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7508,pcr_scale:5.6753,pcr_whiten:3.7508,pcr_s_w:5.6753'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:4.0201,pcr_scale:6.9242,pcr_whiten:4.0201,pcr_s_w:6.9242'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.8235,pcr_scale:5.9178,pcr_whiten:3.8235,pcr_s_w:5.9178'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.7854,pcr_scale:5.989,pcr_whiten:3.7854,pcr_s_w:5.989'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.8417729186538225, 'pcr_scale': 5.6634460481768505, 'pcr_whiten': 3.841772942068719, 'pcr_s_w': 5.663450507565795}, 'fold_1': {'pcr': 3.9936614841560485, 'pcr_scale': 6.1844526356104055, 'pcr_whiten': 3.9936615042340016, 'pcr_s_w': 6.184464564671885}, 'fold_2': {'pcr': 3.611601635809121, 'pcr_scale': 5.729472526907254, 'pcr_whiten': 3.6116015035989184, 'pcr_s_w': 5.729483377040065}, 'fold_3': {'pcr': 4.044454921878971, 'pcr_scale': 6.171982179077028, 'pcr_whiten': 4.044455056561007, 'pcr_s_w': 6.172006501233903}, 'fold_4': {'pcr': 4.02007360385149, 'pcr_scale': 6.924219684330411, 'pcr_whiten': 4.020073707645861, 'pcr_s_w': 6.924165619416945}, 'MSE': {'pcr': 3.902315990035, 'pcr_scale': 6.134672512288843, 'pcr_whiten': 3.902316019985171, 'pcr_s_w': 6.134672013191099}, 'R2': {'pcr': 0.9935069768435731, 'pcr_scale': 0.9897925819484882, 'pcr_whiten': 0.9935069767937393, 'pcr_s_w': 0.9897925827789317}}'\n",
      "pcr: {'fold_0': 3.8417729186538225, 'fold_1': 3.9936614841560485, 'fold_2': 3.611601635809121, 'fold_3': 4.044454921878971, 'fold_4': 4.02007360385149, 'MSE': 3.902315990035, 'R2': 0.9935069768435731}'\n",
      "pcr_scale: {'fold_0': 5.6634460481768505, 'fold_1': 6.1844526356104055, 'fold_2': 5.729472526907254, 'fold_3': 6.171982179077028, 'fold_4': 6.924219684330411, 'MSE': 6.134672512288843, 'R2': 0.9897925819484882}'\n",
      "pcr_whiten: {'fold_0': 3.841772942068719, 'fold_1': 3.9936615042340016, 'fold_2': 3.6116015035989184, 'fold_3': 4.044455056561007, 'fold_4': 4.020073707645861, 'MSE': 3.902316019985171, 'R2': 0.9935069767937393}'\n",
      "pcr_s_w: {'fold_0': 5.663450507565795, 'fold_1': 6.184464564671885, 'fold_2': 5.729483377040065, 'fold_3': 6.172006501233903, 'fold_4': 6.924165619416945, 'MSE': 6.134672013191099, 'R2': 0.9897925827789317}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 19 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7635,pcr_scale:5.6648,pcr_whiten:3.7635,pcr_s_w:5.6648'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.8415,pcr_scale:5.5088,pcr_whiten:3.8415,pcr_s_w:5.5088'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8131,pcr_scale:5.9724,pcr_whiten:3.8131,pcr_s_w:5.9724'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.999,pcr_scale:6.1672,pcr_whiten:3.999,pcr_s_w:6.1672'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8889,pcr_scale:5.962,pcr_whiten:3.8889,pcr_s_w:5.962'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.6129,pcr_scale:5.6796,pcr_whiten:3.6129,pcr_s_w:5.6796'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8948,pcr_scale:6.0039,pcr_whiten:3.8948,pcr_s_w:6.0039'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:4.0354,pcr_scale:6.1223,pcr_whiten:4.0354,pcr_s_w:6.1224'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7412,pcr_scale:5.5707,pcr_whiten:3.7412,pcr_s_w:5.5707'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.9949,pcr_scale:6.9435,pcr_whiten:3.9949,pcr_s_w:6.9435'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.8136,pcr_scale:5.8809,pcr_whiten:3.8136,pcr_s_w:5.8809'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.7761,pcr_scale:5.8981,pcr_whiten:3.7761,pcr_s_w:5.8981'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.8415071629908737, 'pcr_scale': 5.508759194186853, 'pcr_whiten': 3.84150718357863, 'pcr_s_w': 5.508769334503575}, 'fold_1': {'pcr': 3.9990372469855955, 'pcr_scale': 6.167157734890696, 'pcr_whiten': 3.9990373464553555, 'pcr_s_w': 6.167155269328543}, 'fold_2': {'pcr': 3.612867586977726, 'pcr_scale': 5.679633740308773, 'pcr_whiten': 3.6128676656669225, 'pcr_s_w': 5.679620616364381}, 'fold_3': {'pcr': 4.035355966912731, 'pcr_scale': 6.122338199158942, 'pcr_whiten': 4.035355942375712, 'pcr_s_w': 6.12235751410529}, 'fold_4': {'pcr': 3.994942033167549, 'pcr_scale': 6.9435389813656085, 'pcr_whiten': 3.994942060177944, 'pcr_s_w': 6.9435139253817635}, 'MSE': {'pcr': 3.896746699807531, 'pcr_scale': 6.084236363608733, 'pcr_whiten': 3.8967467400555007, 'pcr_s_w': 6.084234126776899}, 'R2': {'pcr': 0.993516243527897, 'pcr_scale': 0.9898765021338697, 'pcr_whiten': 0.9935162434609289, 'pcr_s_w': 0.989876505855711}}'\n",
      "pcr: {'fold_0': 3.8415071629908737, 'fold_1': 3.9990372469855955, 'fold_2': 3.612867586977726, 'fold_3': 4.035355966912731, 'fold_4': 3.994942033167549, 'MSE': 3.896746699807531, 'R2': 0.993516243527897}'\n",
      "pcr_scale: {'fold_0': 5.508759194186853, 'fold_1': 6.167157734890696, 'fold_2': 5.679633740308773, 'fold_3': 6.122338199158942, 'fold_4': 6.9435389813656085, 'MSE': 6.084236363608733, 'R2': 0.9898765021338697}'\n",
      "pcr_whiten: {'fold_0': 3.84150718357863, 'fold_1': 3.9990373464553555, 'fold_2': 3.6128676656669225, 'fold_3': 4.035355942375712, 'fold_4': 3.994942060177944, 'MSE': 3.8967467400555007, 'R2': 0.9935162434609289}'\n",
      "pcr_s_w: {'fold_0': 5.508769334503575, 'fold_1': 6.167155269328543, 'fold_2': 5.679620616364381, 'fold_3': 6.12235751410529, 'fold_4': 6.9435139253817635, 'MSE': 6.084234126776899, 'R2': 0.989876505855711}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 20 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7631,pcr_scale:5.6079,pcr_whiten:3.7631,pcr_s_w:5.6079'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.842,pcr_scale:5.4644,pcr_whiten:3.842,pcr_s_w:5.4644'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8123,pcr_scale:5.8489,pcr_whiten:3.8123,pcr_s_w:5.8489'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.9919,pcr_scale:6.0292,pcr_whiten:3.9919,pcr_s_w:6.0292'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8871,pcr_scale:5.8052,pcr_whiten:3.8871,pcr_s_w:5.8052'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.6134,pcr_scale:5.5765,pcr_whiten:3.6134,pcr_s_w:5.5765'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8935,pcr_scale:5.7432,pcr_whiten:3.8935,pcr_s_w:5.7433'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:4.0261,pcr_scale:5.8212,pcr_whiten:4.0261,pcr_s_w:5.8212'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7408,pcr_scale:5.4136,pcr_whiten:3.7408,pcr_s_w:5.4136'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.9954,pcr_scale:6.7831,pcr_whiten:3.9954,pcr_s_w:6.7831'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.8132,pcr_scale:5.6329,pcr_whiten:3.8132,pcr_s_w:5.633'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.7784,pcr_scale:5.708,pcr_whiten:3.7784,pcr_s_w:5.7081'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.841953858281984, 'pcr_scale': 5.4643599433910515, 'pcr_whiten': 3.8419537400985604, 'pcr_s_w': 5.4643599303254895}, 'fold_1': {'pcr': 3.9918532116833965, 'pcr_scale': 6.029244689572096, 'pcr_whiten': 3.9918523076418704, 'pcr_s_w': 6.029243897169741}, 'fold_2': {'pcr': 3.613421447994475, 'pcr_scale': 5.576519896640859, 'pcr_whiten': 3.6134213786514358, 'pcr_s_w': 5.576543226750167}, 'fold_3': {'pcr': 4.0261039137389165, 'pcr_scale': 5.821230222943697, 'pcr_whiten': 4.026103793993279, 'pcr_s_w': 5.8212471159128105}, 'fold_4': {'pcr': 3.995355612353662, 'pcr_scale': 6.783069563347375, 'pcr_whiten': 3.995355666776608, 'pcr_s_w': 6.783127709940888}, 'MSE': {'pcr': 3.893742236442563, 'pcr_scale': 5.934847291755386, 'pcr_whiten': 3.8937420050085465, 'pcr_s_w': 5.934866800617847}, 'R2': {'pcr': 0.9935212426233704, 'pcr_scale': 0.9901250690631849, 'pcr_whiten': 0.9935212430084511, 'pcr_s_w': 0.9901250366025908}}'\n",
      "pcr: {'fold_0': 3.841953858281984, 'fold_1': 3.9918532116833965, 'fold_2': 3.613421447994475, 'fold_3': 4.0261039137389165, 'fold_4': 3.995355612353662, 'MSE': 3.893742236442563, 'R2': 0.9935212426233704}'\n",
      "pcr_scale: {'fold_0': 5.4643599433910515, 'fold_1': 6.029244689572096, 'fold_2': 5.576519896640859, 'fold_3': 5.821230222943697, 'fold_4': 6.783069563347375, 'MSE': 5.934847291755386, 'R2': 0.9901250690631849}'\n",
      "pcr_whiten: {'fold_0': 3.8419537400985604, 'fold_1': 3.9918523076418704, 'fold_2': 3.6134213786514358, 'fold_3': 4.026103793993279, 'fold_4': 3.995355666776608, 'MSE': 3.8937420050085465, 'R2': 0.9935212430084511}'\n",
      "pcr_s_w: {'fold_0': 5.4643599303254895, 'fold_1': 6.029243897169741, 'fold_2': 5.576543226750167, 'fold_3': 5.8212471159128105, 'fold_4': 6.783127709940888, 'MSE': 5.934866800617847, 'R2': 0.9901250366025908}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 21 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7524,pcr_scale:5.4622,pcr_whiten:3.7524,pcr_s_w:5.4622'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.8323,pcr_scale:5.4029,pcr_whiten:3.8323,pcr_s_w:5.4029'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7783,pcr_scale:5.6951,pcr_whiten:3.7783,pcr_s_w:5.695'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.9514,pcr_scale:5.832,pcr_whiten:3.9514,pcr_s_w:5.832'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8479,pcr_scale:5.7679,pcr_whiten:3.8479,pcr_s_w:5.7679'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.5908,pcr_scale:5.4589,pcr_whiten:3.5908,pcr_s_w:5.459'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8544,pcr_scale:5.7342,pcr_whiten:3.8544,pcr_s_w:5.7342'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.9833,pcr_scale:5.8036,pcr_whiten:3.9833,pcr_s_w:5.8036'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7215,pcr_scale:5.3891,pcr_whiten:3.7214,pcr_s_w:5.389'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.9905,pcr_scale:7.181,pcr_whiten:3.9905,pcr_s_w:7.1809'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.779,pcr_scale:5.5842,pcr_whiten:3.779,pcr_s_w:5.5843'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.8242,pcr_scale:5.6336,pcr_whiten:3.8243,pcr_s_w:5.6336'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.8323342356015795, 'pcr_scale': 5.402912034501016, 'pcr_whiten': 3.8323458896993823, 'pcr_s_w': 5.40287785797021}, 'fold_1': {'pcr': 3.9514312190928127, 'pcr_scale': 5.831972845886646, 'pcr_whiten': 3.9514394244064492, 'pcr_s_w': 5.831969560704546}, 'fold_2': {'pcr': 3.5908165577125333, 'pcr_scale': 5.4589407930520455, 'pcr_whiten': 3.590834064715739, 'pcr_s_w': 5.458979631266924}, 'fold_3': {'pcr': 3.9833411223335293, 'pcr_scale': 5.803554748444285, 'pcr_whiten': 3.983333917742739, 'pcr_s_w': 5.803568057269151}, 'fold_4': {'pcr': 3.9905264920070325, 'pcr_scale': 7.180980827552696, 'pcr_whiten': 3.990521415684795, 'pcr_s_w': 7.180931756278096}, 'MSE': {'pcr': 3.8696943585900083, 'pcr_scale': 5.935608680209013, 'pcr_whiten': 3.8696993766716754, 'pcr_s_w': 5.935601800651568}, 'R2': {'pcr': 0.9935612556382463, 'pcr_scale': 0.9901238021968233, 'pcr_whiten': 0.9935612472887122, 'pcr_s_w': 0.9901238136436477}}'\n",
      "pcr: {'fold_0': 3.8323342356015795, 'fold_1': 3.9514312190928127, 'fold_2': 3.5908165577125333, 'fold_3': 3.9833411223335293, 'fold_4': 3.9905264920070325, 'MSE': 3.8696943585900083, 'R2': 0.9935612556382463}'\n",
      "pcr_scale: {'fold_0': 5.402912034501016, 'fold_1': 5.831972845886646, 'fold_2': 5.4589407930520455, 'fold_3': 5.803554748444285, 'fold_4': 7.180980827552696, 'MSE': 5.935608680209013, 'R2': 0.9901238021968233}'\n",
      "pcr_whiten: {'fold_0': 3.8323458896993823, 'fold_1': 3.9514394244064492, 'fold_2': 3.590834064715739, 'fold_3': 3.983333917742739, 'fold_4': 3.990521415684795, 'MSE': 3.8696993766716754, 'R2': 0.9935612472887122}'\n",
      "pcr_s_w: {'fold_0': 5.40287785797021, 'fold_1': 5.831969560704546, 'fold_2': 5.458979631266924, 'fold_3': 5.803568057269151, 'fold_4': 7.180931756278096, 'MSE': 5.935601800651568, 'R2': 0.9901238136436477}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 22 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7401,pcr_scale:5.4616,pcr_whiten:3.7401,pcr_s_w:5.4615'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.8288,pcr_scale:5.3933,pcr_whiten:3.8288,pcr_s_w:5.393'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7352,pcr_scale:5.68,pcr_whiten:3.7353,pcr_s_w:5.68'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.9346,pcr_scale:5.7893,pcr_whiten:3.9347,pcr_s_w:5.7893'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8145,pcr_scale:5.7542,pcr_whiten:3.8145,pcr_s_w:5.7542'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.5778,pcr_scale:5.4505,pcr_whiten:3.5778,pcr_s_w:5.4505'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.8413,pcr_scale:5.7184,pcr_whiten:3.8413,pcr_s_w:5.7184'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.9548,pcr_scale:5.8294,pcr_whiten:3.9548,pcr_s_w:5.8294'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7146,pcr_scale:5.3237,pcr_whiten:3.7146,pcr_s_w:5.3237'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.9674,pcr_scale:6.9752,pcr_whiten:3.9674,pcr_s_w:6.9751'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.7617,pcr_scale:5.5814,pcr_whiten:3.7618,pcr_s_w:5.5814'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.7818,pcr_scale:5.6378,pcr_whiten:3.7819,pcr_s_w:5.6377'\n",
      "Train times: {'fold_0': 3, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 3.8}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.828825923789613, 'pcr_scale': 5.393324830960617, 'pcr_whiten': 3.828820845520548, 'pcr_s_w': 5.392994409647557}, 'fold_1': {'pcr': 3.9345792826558843, 'pcr_scale': 5.78931209813145, 'pcr_whiten': 3.934651225986465, 'pcr_s_w': 5.789298795132328}, 'fold_2': {'pcr': 3.5777627489895645, 'pcr_scale': 5.450484923761532, 'pcr_whiten': 3.5777708868723948, 'pcr_s_w': 5.450508610520944}, 'fold_3': {'pcr': 3.9547644608410573, 'pcr_scale': 5.829407322730414, 'pcr_whiten': 3.9548287738505516, 'pcr_s_w': 5.829413868248861}, 'fold_4': {'pcr': 3.967418538120763, 'pcr_scale': 6.975185450069721, 'pcr_whiten': 3.9674296231166406, 'pcr_s_w': 6.975146349001271}, 'MSE': {'pcr': 3.8526759904024175, 'pcr_scale': 5.88748375124729, 'pcr_whiten': 3.8527060712620256, 'pcr_s_w': 5.887413212382321}, 'R2': {'pcr': 0.9935895723248008, 'pcr_scale': 0.9902038767676544, 'pcr_whiten': 0.9935895222735701, 'pcr_s_w': 0.9902039941365413}}'\n",
      "pcr: {'fold_0': 3.828825923789613, 'fold_1': 3.9345792826558843, 'fold_2': 3.5777627489895645, 'fold_3': 3.9547644608410573, 'fold_4': 3.967418538120763, 'MSE': 3.8526759904024175, 'R2': 0.9935895723248008}'\n",
      "pcr_scale: {'fold_0': 5.393324830960617, 'fold_1': 5.78931209813145, 'fold_2': 5.450484923761532, 'fold_3': 5.829407322730414, 'fold_4': 6.975185450069721, 'MSE': 5.88748375124729, 'R2': 0.9902038767676544}'\n",
      "pcr_whiten: {'fold_0': 3.828820845520548, 'fold_1': 3.934651225986465, 'fold_2': 3.5777708868723948, 'fold_3': 3.9548287738505516, 'fold_4': 3.9674296231166406, 'MSE': 3.8527060712620256, 'R2': 0.9935895222735701}'\n",
      "pcr_s_w: {'fold_0': 5.392994409647557, 'fold_1': 5.789298795132328, 'fold_2': 5.450508610520944, 'fold_3': 5.829413868248861, 'fold_4': 6.975146349001271, 'MSE': 5.887413212382321, 'R2': 0.9902039941365413}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 23 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6,pcr_scale:5.263,pcr_whiten:3.6,pcr_s_w:5.263'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.7084,pcr_scale:5.2426,pcr_whiten:3.7083,pcr_s_w:5.2424'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7337,pcr_scale:5.6683,pcr_whiten:3.7337,pcr_s_w:5.6683'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.9345,pcr_scale:5.7882,pcr_whiten:3.9345,pcr_s_w:5.7883'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7578,pcr_scale:5.714,pcr_whiten:3.7576,pcr_s_w:5.714'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.495,pcr_scale:5.371,pcr_whiten:3.4948,pcr_s_w:5.3711'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7007,pcr_scale:5.6702,pcr_whiten:3.7004,pcr_s_w:5.6702'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.8353,pcr_scale:5.8139,pcr_whiten:3.8351,pcr_s_w:5.8139'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5555,pcr_scale:5.2713,pcr_whiten:3.5554,pcr_s_w:5.2714'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.9173,pcr_scale:6.7213,pcr_whiten:3.9173,pcr_s_w:6.7215'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.7444,pcr_scale:5.5522,pcr_whiten:3.7445,pcr_s_w:5.5523'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.7158,pcr_scale:5.6701,pcr_whiten:3.7159,pcr_s_w:5.6701'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 3, 'mean': 3.8}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.7083662541224207, 'pcr_scale': 5.242568374967141, 'pcr_whiten': 3.708340353166657, 'pcr_s_w': 5.242411861683299}, 'fold_1': {'pcr': 3.934495617176783, 'pcr_scale': 5.788248756752716, 'pcr_whiten': 3.9344999241182177, 'pcr_s_w': 5.788257521498012}, 'fold_2': {'pcr': 3.494959487738772, 'pcr_scale': 5.371016033487789, 'pcr_whiten': 3.4947874038330506, 'pcr_s_w': 5.371057922989418}, 'fold_3': {'pcr': 3.8353203454043787, 'pcr_scale': 5.813865134994083, 'pcr_whiten': 3.8351341254371074, 'pcr_s_w': 5.8138550210349935}, 'fold_4': {'pcr': 3.91733194782623, 'pcr_scale': 6.721347730692901, 'pcr_whiten': 3.9173266304824437, 'pcr_s_w': 6.721544183267723}, 'MSE': {'pcr': 3.778103387306533, 'pcr_scale': 5.787354871252774, 'pcr_whiten': 3.7780263574936384, 'pcr_s_w': 5.787370949196067}, 'R2': {'pcr': 0.9937136529066842, 'pcr_scale': 0.9903704801739628, 'pcr_whiten': 0.9937137810757921, 'pcr_s_w': 0.9903704534220396}}'\n",
      "pcr: {'fold_0': 3.7083662541224207, 'fold_1': 3.934495617176783, 'fold_2': 3.494959487738772, 'fold_3': 3.8353203454043787, 'fold_4': 3.91733194782623, 'MSE': 3.778103387306533, 'R2': 0.9937136529066842}'\n",
      "pcr_scale: {'fold_0': 5.242568374967141, 'fold_1': 5.788248756752716, 'fold_2': 5.371016033487789, 'fold_3': 5.813865134994083, 'fold_4': 6.721347730692901, 'MSE': 5.787354871252774, 'R2': 0.9903704801739628}'\n",
      "pcr_whiten: {'fold_0': 3.708340353166657, 'fold_1': 3.9344999241182177, 'fold_2': 3.4947874038330506, 'fold_3': 3.8351341254371074, 'fold_4': 3.9173266304824437, 'MSE': 3.7780263574936384, 'R2': 0.9937137810757921}'\n",
      "pcr_s_w: {'fold_0': 5.242411861683299, 'fold_1': 5.788257521498012, 'fold_2': 5.371057922989418, 'fold_3': 5.8138550210349935, 'fold_4': 6.721544183267723, 'MSE': 5.787370949196067, 'R2': 0.9903704534220396}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 24 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5906,pcr_scale:5.2208,pcr_whiten:3.5905,pcr_s_w:5.2209'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.7084,pcr_scale:5.2322,pcr_whiten:3.7083,pcr_s_w:5.2321'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6266,pcr_scale:5.3726,pcr_whiten:3.6266,pcr_s_w:5.3724'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.7715,pcr_scale:5.6666,pcr_whiten:3.7715,pcr_s_w:5.6666'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7152,pcr_scale:5.5412,pcr_whiten:3.7154,pcr_s_w:5.5417'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.38,pcr_scale:5.2152,pcr_whiten:3.3804,pcr_s_w:5.2156'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7007,pcr_scale:5.624,pcr_whiten:3.7009,pcr_s_w:5.6242'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.8361,pcr_scale:5.7583,pcr_whiten:3.8361,pcr_s_w:5.7586'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5415,pcr_scale:5.271,pcr_whiten:3.5416,pcr_s_w:5.2711'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.9056,pcr_scale:6.7269,pcr_whiten:3.9055,pcr_s_w:6.7267'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.6046,pcr_scale:5.4954,pcr_whiten:3.6043,pcr_s_w:5.4955'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.5572,pcr_scale:5.6067,pcr_whiten:3.5568,pcr_s_w:5.6068'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 3, 'fold_4': 3, 'mean': 3.6}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.7083558830415164, 'pcr_scale': 5.232232361877974, 'pcr_whiten': 3.708305333983882, 'pcr_s_w': 5.232144001210381}, 'fold_1': {'pcr': 3.7715090877360153, 'pcr_scale': 5.666621501136174, 'pcr_whiten': 3.771514653215261, 'pcr_s_w': 5.666556971651962}, 'fold_2': {'pcr': 3.3799964572251664, 'pcr_scale': 5.215188707223484, 'pcr_whiten': 3.380434479573136, 'pcr_s_w': 5.215571322583753}, 'fold_3': {'pcr': 3.8361478998773473, 'pcr_scale': 5.758337048104395, 'pcr_whiten': 3.836145477914551, 'pcr_s_w': 5.7585922230688045}, 'fold_4': {'pcr': 3.9055948708821515, 'pcr_scale': 6.7268741160306424, 'pcr_whiten': 3.9055322885503267, 'pcr_s_w': 6.726716923587796}, 'MSE': {'pcr': 3.7203247573804132, 'pcr_scale': 5.719796726935387, 'pcr_whiten': 3.7203903466767865, 'pcr_s_w': 5.719862240118105}, 'R2': {'pcr': 0.9938097901705591, 'pcr_scale': 0.9904828894705391, 'pcr_whiten': 0.9938096810372082, 'pcr_s_w': 0.9904827804638329}}'\n",
      "pcr: {'fold_0': 3.7083558830415164, 'fold_1': 3.7715090877360153, 'fold_2': 3.3799964572251664, 'fold_3': 3.8361478998773473, 'fold_4': 3.9055948708821515, 'MSE': 3.7203247573804132, 'R2': 0.9938097901705591}'\n",
      "pcr_scale: {'fold_0': 5.232232361877974, 'fold_1': 5.666621501136174, 'fold_2': 5.215188707223484, 'fold_3': 5.758337048104395, 'fold_4': 6.7268741160306424, 'MSE': 5.719796726935387, 'R2': 0.9904828894705391}'\n",
      "pcr_whiten: {'fold_0': 3.708305333983882, 'fold_1': 3.771514653215261, 'fold_2': 3.380434479573136, 'fold_3': 3.836145477914551, 'fold_4': 3.9055322885503267, 'MSE': 3.7203903466767865, 'R2': 0.9938096810372082}'\n",
      "pcr_s_w: {'fold_0': 5.232144001210381, 'fold_1': 5.666556971651962, 'fold_2': 5.215571322583753, 'fold_3': 5.7585922230688045, 'fold_4': 6.726716923587796, 'MSE': 5.719862240118105, 'R2': 0.9904827804638329}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 25 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5892,pcr_scale:5.2083,pcr_whiten:3.5892,pcr_s_w:5.208'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.7116,pcr_scale:5.246,pcr_whiten:3.7117,pcr_s_w:5.2465'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6244,pcr_scale:5.3529,pcr_whiten:3.6245,pcr_s_w:5.353'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.7657,pcr_scale:5.6424,pcr_whiten:3.7658,pcr_s_w:5.6425'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7152,pcr_scale:5.4234,pcr_whiten:3.715,pcr_s_w:5.424'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3809,pcr_scale:5.1517,pcr_whiten:3.3807,pcr_s_w:5.1525'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6955,pcr_scale:5.5948,pcr_whiten:3.6955,pcr_s_w:5.5943'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.8345,pcr_scale:5.6552,pcr_whiten:3.8345,pcr_s_w:5.6545'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5385,pcr_scale:5.2549,pcr_whiten:3.5385,pcr_s_w:5.2542'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.8974,pcr_scale:6.7364,pcr_whiten:3.8973,pcr_s_w:6.7349'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.594,pcr_scale:5.4647,pcr_whiten:3.5941,pcr_s_w:5.4649'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.537,pcr_scale:5.5359,pcr_whiten:3.537,pcr_s_w:5.5363'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.7116370057412813, 'pcr_scale': 5.246038589612322, 'pcr_whiten': 3.7116575298953727, 'pcr_s_w': 5.24645966919224}, 'fold_1': {'pcr': 3.7656729554020774, 'pcr_scale': 5.642358567654683, 'pcr_whiten': 3.7657824975685394, 'pcr_s_w': 5.642536808542947}, 'fold_2': {'pcr': 3.380898308397261, 'pcr_scale': 5.151663990411331, 'pcr_whiten': 3.380699576698736, 'pcr_s_w': 5.15247290753823}, 'fold_3': {'pcr': 3.834523687264165, 'pcr_scale': 5.6552402039854215, 'pcr_whiten': 3.834542946184167, 'pcr_s_w': 5.654544545083872}, 'fold_4': {'pcr': 3.897407868168723, 'pcr_scale': 6.736362862266778, 'pcr_whiten': 3.8972917423053577, 'pcr_s_w': 6.734861534950066}, 'MSE': {'pcr': 3.718032085453267, 'pcr_scale': 5.686284473975849, 'pcr_whiten': 3.7179989985933988, 'pcr_s_w': 5.686126815623559}, 'R2': {'pcr': 0.9938136049236317, 'pcr_scale': 0.9905386501611254, 'pcr_whiten': 0.993813659976515, 'pcr_s_w': 0.9905389124872247}}'\n",
      "pcr: {'fold_0': 3.7116370057412813, 'fold_1': 3.7656729554020774, 'fold_2': 3.380898308397261, 'fold_3': 3.834523687264165, 'fold_4': 3.897407868168723, 'MSE': 3.718032085453267, 'R2': 0.9938136049236317}'\n",
      "pcr_scale: {'fold_0': 5.246038589612322, 'fold_1': 5.642358567654683, 'fold_2': 5.151663990411331, 'fold_3': 5.6552402039854215, 'fold_4': 6.736362862266778, 'MSE': 5.686284473975849, 'R2': 0.9905386501611254}'\n",
      "pcr_whiten: {'fold_0': 3.7116575298953727, 'fold_1': 3.7657824975685394, 'fold_2': 3.380699576698736, 'fold_3': 3.834542946184167, 'fold_4': 3.8972917423053577, 'MSE': 3.7179989985933988, 'R2': 0.993813659976515}'\n",
      "pcr_s_w: {'fold_0': 5.24645966919224, 'fold_1': 5.642536808542947, 'fold_2': 5.15247290753823, 'fold_3': 5.654544545083872, 'fold_4': 6.734861534950066, 'MSE': 5.686126815623559, 'R2': 0.9905389124872247}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 26 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5732,pcr_scale:5.109,pcr_whiten:3.5735,pcr_s_w:5.1058'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.6878,pcr_scale:5.1468,pcr_whiten:3.6881,pcr_s_w:5.1438'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6215,pcr_scale:5.0557,pcr_whiten:3.6214,pcr_s_w:5.0576'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.7625,pcr_scale:5.3348,pcr_whiten:3.7624,pcr_s_w:5.3372'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.7145,pcr_scale:5.1518,pcr_whiten:3.7146,pcr_s_w:5.1521'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.377,pcr_scale:4.8164,pcr_whiten:3.3771,pcr_s_w:4.8168'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6893,pcr_scale:5.4587,pcr_whiten:3.6893,pcr_s_w:5.4594'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.8362,pcr_scale:5.5899,pcr_whiten:3.8362,pcr_s_w:5.5894'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5377,pcr_scale:4.8529,pcr_whiten:3.5377,pcr_s_w:4.8524'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.8996,pcr_scale:6.1679,pcr_whiten:3.8995,pcr_s_w:6.1708'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.5863,pcr_scale:5.2285,pcr_whiten:3.5862,pcr_s_w:5.2241'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.5335,pcr_scale:5.219,pcr_whiten:3.5334,pcr_s_w:5.2149'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.687770669505507, 'pcr_scale': 5.146750102713522, 'pcr_whiten': 3.6880768160128894, 'pcr_s_w': 5.1438221632081955}, 'fold_1': {'pcr': 3.762488818392643, 'pcr_scale': 5.334842376422209, 'pcr_whiten': 3.7623521611640798, 'pcr_s_w': 5.337174190450291}, 'fold_2': {'pcr': 3.376983795227312, 'pcr_scale': 4.816420491383012, 'pcr_whiten': 3.3771461820601165, 'pcr_s_w': 4.816816295109084}, 'fold_3': {'pcr': 3.836195331309741, 'pcr_scale': 5.589886313140694, 'pcr_whiten': 3.8362166413007235, 'pcr_s_w': 5.589437390470433}, 'fold_4': {'pcr': 3.899550953668653, 'pcr_scale': 6.167913338032578, 'pcr_whiten': 3.8995387731862525, 'pcr_s_w': 6.170786794910981}, 'MSE': {'pcr': 3.7126004169828026, 'pcr_scale': 5.41112849192035, 'pcr_whiten': 3.7126686214115807, 'pcr_s_w': 5.411573186008782}, 'R2': {'pcr': 0.9938226426205395, 'pcr_scale': 0.990996479349658, 'pcr_whiten': 0.993822529135897, 'pcr_s_w': 0.9909957394277703}}'\n",
      "pcr: {'fold_0': 3.687770669505507, 'fold_1': 3.762488818392643, 'fold_2': 3.376983795227312, 'fold_3': 3.836195331309741, 'fold_4': 3.899550953668653, 'MSE': 3.7126004169828026, 'R2': 0.9938226426205395}'\n",
      "pcr_scale: {'fold_0': 5.146750102713522, 'fold_1': 5.334842376422209, 'fold_2': 4.816420491383012, 'fold_3': 5.589886313140694, 'fold_4': 6.167913338032578, 'MSE': 5.41112849192035, 'R2': 0.990996479349658}'\n",
      "pcr_whiten: {'fold_0': 3.6880768160128894, 'fold_1': 3.7623521611640798, 'fold_2': 3.3771461820601165, 'fold_3': 3.8362166413007235, 'fold_4': 3.8995387731862525, 'MSE': 3.7126686214115807, 'R2': 0.993822529135897}'\n",
      "pcr_s_w: {'fold_0': 5.1438221632081955, 'fold_1': 5.337174190450291, 'fold_2': 4.816816295109084, 'fold_3': 5.589437390470433, 'fold_4': 6.170786794910981, 'MSE': 5.411573186008782, 'R2': 0.9909957394277703}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 27 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5717,pcr_scale:4.6442,pcr_whiten:3.5716,pcr_s_w:4.6419'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.6796,pcr_scale:4.5879,pcr_whiten:3.6794,pcr_s_w:4.5861'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5897,pcr_scale:4.8071,pcr_whiten:3.5897,pcr_s_w:4.8068'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.7414,pcr_scale:5.0795,pcr_whiten:3.7414,pcr_s_w:5.0787'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6848,pcr_scale:4.8154,pcr_whiten:3.6847,pcr_s_w:4.8165'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3182,pcr_scale:4.5475,pcr_whiten:3.3181,pcr_s_w:4.5486'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6887,pcr_scale:4.8638,pcr_whiten:3.6887,pcr_s_w:4.8627'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.839,pcr_scale:4.9899,pcr_whiten:3.839,pcr_s_w:4.9838'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5284,pcr_scale:4.8438,pcr_whiten:3.5284,pcr_s_w:4.8434'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.8828,pcr_scale:6.1128,pcr_whiten:3.8827,pcr_s_w:6.1114'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.5782,pcr_scale:4.812,pcr_whiten:3.5783,pcr_s_w:4.8136'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.5515,pcr_scale:4.9477,pcr_whiten:3.5514,pcr_s_w:4.9463'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.679624733884881, 'pcr_scale': 4.587858011430393, 'pcr_whiten': 3.6794184931651612, 'pcr_s_w': 4.586081333723341}, 'fold_1': {'pcr': 3.741385126078089, 'pcr_scale': 5.07948803634165, 'pcr_whiten': 3.7413876946589233, 'pcr_s_w': 5.078655446120414}, 'fold_2': {'pcr': 3.3182304236584548, 'pcr_scale': 4.547508067088997, 'pcr_whiten': 3.3180975106339123, 'pcr_s_w': 4.548578961753149}, 'fold_3': {'pcr': 3.839024484598185, 'pcr_scale': 4.9899381699016025, 'pcr_whiten': 3.8390286092060126, 'pcr_s_w': 4.983793794188381}, 'fold_4': {'pcr': 3.8828267745035814, 'pcr_scale': 6.112839813647682, 'pcr_whiten': 3.8826827394572985, 'pcr_s_w': 6.11139731226013}, 'MSE': {'pcr': 3.692221961485397, 'pcr_scale': 5.063480504101602, 'pcr_whiten': 3.6921266610591967, 'pcr_s_w': 5.061655557987092}, 'R2': {'pcr': 0.9938565501215658, 'pcr_scale': 0.9915749272357227, 'pcr_whiten': 0.9938567086909579, 'pcr_s_w': 0.9915779637446602}}'\n",
      "pcr: {'fold_0': 3.679624733884881, 'fold_1': 3.741385126078089, 'fold_2': 3.3182304236584548, 'fold_3': 3.839024484598185, 'fold_4': 3.8828267745035814, 'MSE': 3.692221961485397, 'R2': 0.9938565501215658}'\n",
      "pcr_scale: {'fold_0': 4.587858011430393, 'fold_1': 5.07948803634165, 'fold_2': 4.547508067088997, 'fold_3': 4.9899381699016025, 'fold_4': 6.112839813647682, 'MSE': 5.063480504101602, 'R2': 0.9915749272357227}'\n",
      "pcr_whiten: {'fold_0': 3.6794184931651612, 'fold_1': 3.7413876946589233, 'fold_2': 3.3180975106339123, 'fold_3': 3.8390286092060126, 'fold_4': 3.8826827394572985, 'MSE': 3.6921266610591967, 'R2': 0.9938567086909579}'\n",
      "pcr_s_w: {'fold_0': 4.586081333723341, 'fold_1': 5.078655446120414, 'fold_2': 4.548578961753149, 'fold_3': 4.983793794188381, 'fold_4': 6.11139731226013, 'MSE': 5.061655557987092, 'R2': 0.9915779637446602}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 28 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5411,pcr_scale:4.6202,pcr_whiten:3.5411,pcr_s_w:4.6243'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.676,pcr_scale:4.5607,pcr_whiten:3.6763,pcr_s_w:4.5637'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5878,pcr_scale:4.7702,pcr_whiten:3.5879,pcr_s_w:4.7723'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.7365,pcr_scale:5.0001,pcr_whiten:3.7366,pcr_s_w:5.0022'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6847,pcr_scale:4.8124,pcr_whiten:3.6847,pcr_s_w:4.8088'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3179,pcr_scale:4.5221,pcr_whiten:3.3179,pcr_s_w:4.5181'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6642,pcr_scale:4.8367,pcr_whiten:3.6642,pcr_s_w:4.8444'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.8261,pcr_scale:5.0166,pcr_whiten:3.8261,pcr_s_w:5.0216'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5172,pcr_scale:4.5978,pcr_whiten:3.5172,pcr_s_w:4.5856'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.9021,pcr_scale:5.6338,pcr_whiten:3.9022,pcr_s_w:5.6133'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.5661,pcr_scale:4.7419,pcr_whiten:3.5661,pcr_s_w:4.743'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.5247,pcr_scale:5.0144,pcr_whiten:3.5248,pcr_s_w:5.007'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.6760005156437514, 'pcr_scale': 4.56074077701035, 'pcr_whiten': 3.6762615325916537, 'pcr_s_w': 4.563652011889995}, 'fold_1': {'pcr': 3.736454215684881, 'pcr_scale': 5.0001077562529375, 'pcr_whiten': 3.7365747221083616, 'pcr_s_w': 5.002173607923582}, 'fold_2': {'pcr': 3.3179204167988456, 'pcr_scale': 4.522080542706397, 'pcr_whiten': 3.317851648688199, 'pcr_s_w': 4.518095532437563}, 'fold_3': {'pcr': 3.8260673591045053, 'pcr_scale': 5.016634066053193, 'pcr_whiten': 3.8261208742238217, 'pcr_s_w': 5.021634680029731}, 'fold_4': {'pcr': 3.9020772383866116, 'pcr_scale': 5.633763187190552, 'pcr_whiten': 3.902150522568682, 'pcr_s_w': 5.613292612864988}, 'MSE': {'pcr': 3.6917068503255845, 'pcr_scale': 4.946632057492862, 'pcr_whiten': 3.6917947817835093, 'pcr_s_w': 4.943737556212726}, 'R2': {'pcr': 0.9938574072096892, 'pcr_scale': 0.9917693501557426, 'pcr_whiten': 0.9938572609014471, 'pcr_s_w': 0.991774166286442}}'\n",
      "pcr: {'fold_0': 3.6760005156437514, 'fold_1': 3.736454215684881, 'fold_2': 3.3179204167988456, 'fold_3': 3.8260673591045053, 'fold_4': 3.9020772383866116, 'MSE': 3.6917068503255845, 'R2': 0.9938574072096892}'\n",
      "pcr_scale: {'fold_0': 4.56074077701035, 'fold_1': 5.0001077562529375, 'fold_2': 4.522080542706397, 'fold_3': 5.016634066053193, 'fold_4': 5.633763187190552, 'MSE': 4.946632057492862, 'R2': 0.9917693501557426}'\n",
      "pcr_whiten: {'fold_0': 3.6762615325916537, 'fold_1': 3.7365747221083616, 'fold_2': 3.317851648688199, 'fold_3': 3.8261208742238217, 'fold_4': 3.902150522568682, 'MSE': 3.6917947817835093, 'R2': 0.9938572609014471}'\n",
      "pcr_s_w: {'fold_0': 4.563652011889995, 'fold_1': 5.002173607923582, 'fold_2': 4.518095532437563, 'fold_3': 5.021634680029731, 'fold_4': 5.613292612864988, 'MSE': 4.943737556212726, 'R2': 0.991774166286442}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 29 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5137,pcr_scale:4.5723,pcr_whiten:3.5139,pcr_s_w:4.5862'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.663,pcr_scale:4.4899,pcr_whiten:3.6631,pcr_s_w:4.5006'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5867,pcr_scale:4.6871,pcr_whiten:3.5867,pcr_s_w:4.6851'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.7262,pcr_scale:4.968,pcr_whiten:3.7263,pcr_s_w:4.9658'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6816,pcr_scale:4.7987,pcr_whiten:3.6816,pcr_s_w:4.7865'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3218,pcr_scale:4.5143,pcr_whiten:3.3217,pcr_s_w:4.5056'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6623,pcr_scale:4.8389,pcr_whiten:3.6624,pcr_s_w:4.8369'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.8196,pcr_scale:5.0183,pcr_whiten:3.8198,pcr_s_w:5.0209'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4662,pcr_scale:4.5739,pcr_whiten:3.4657,pcr_s_w:4.579'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.8285,pcr_scale:5.6822,pcr_whiten:3.8268,pcr_s_w:5.6685'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.5637,pcr_scale:4.7342,pcr_whiten:3.5637,pcr_s_w:4.7358'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.5218,pcr_scale:5.012,pcr_whiten:3.5218,pcr_s_w:5.0066'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.662973398437672, 'pcr_scale': 4.48987541410951, 'pcr_whiten': 3.6631261933346, 'pcr_s_w': 4.500635090100289}, 'fold_1': {'pcr': 3.726249955488119, 'pcr_scale': 4.967978775721029, 'pcr_whiten': 3.7263226241344225, 'pcr_s_w': 4.965777304193096}, 'fold_2': {'pcr': 3.321802380167558, 'pcr_scale': 4.5143119948555155, 'pcr_whiten': 3.3217253467008616, 'pcr_s_w': 4.505608519209292}, 'fold_3': {'pcr': 3.819610721567249, 'pcr_scale': 5.018327935963143, 'pcr_whiten': 3.819768531025644, 'pcr_s_w': 5.020938695482272}, 'fold_4': {'pcr': 3.828545248260347, 'pcr_scale': 5.682178952448857, 'pcr_whiten': 3.8267860811472914, 'pcr_s_w': 5.668479393023168}, 'MSE': {'pcr': 3.6718408903918958, 'pcr_scale': 4.934493542402331, 'pcr_whiten': 3.6715503854430476, 'pcr_s_w': 4.93224803180329}, 'R2': {'pcr': 0.9938904619746552, 'pcr_scale': 0.9917895473052736, 'pcr_whiten': 0.9938909453428307, 'pcr_s_w': 0.9917932835871007}}'\n",
      "pcr: {'fold_0': 3.662973398437672, 'fold_1': 3.726249955488119, 'fold_2': 3.321802380167558, 'fold_3': 3.819610721567249, 'fold_4': 3.828545248260347, 'MSE': 3.6718408903918958, 'R2': 0.9938904619746552}'\n",
      "pcr_scale: {'fold_0': 4.48987541410951, 'fold_1': 4.967978775721029, 'fold_2': 4.5143119948555155, 'fold_3': 5.018327935963143, 'fold_4': 5.682178952448857, 'MSE': 4.934493542402331, 'R2': 0.9917895473052736}'\n",
      "pcr_whiten: {'fold_0': 3.6631261933346, 'fold_1': 3.7263226241344225, 'fold_2': 3.3217253467008616, 'fold_3': 3.819768531025644, 'fold_4': 3.8267860811472914, 'MSE': 3.6715503854430476, 'R2': 0.9938909453428307}'\n",
      "pcr_s_w: {'fold_0': 4.500635090100289, 'fold_1': 4.965777304193096, 'fold_2': 4.505608519209292, 'fold_3': 5.020938695482272, 'fold_4': 5.668479393023168, 'MSE': 4.93224803180329, 'R2': 0.9917932835871007}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 30 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5117,pcr_scale:4.5731,pcr_whiten:3.5118,pcr_s_w:4.5763'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.6656,pcr_scale:4.4865,pcr_whiten:3.6657,pcr_s_w:4.4892'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5133,pcr_scale:4.6555,pcr_whiten:3.5135,pcr_s_w:4.6433'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.6566,pcr_scale:4.9544,pcr_whiten:3.6569,pcr_s_w:4.9426'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6629,pcr_scale:4.682,pcr_whiten:3.663,pcr_s_w:4.6768'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3035,pcr_scale:4.4569,pcr_whiten:3.3036,pcr_s_w:4.4591'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6572,pcr_scale:4.702,pcr_whiten:3.6573,pcr_s_w:4.7066'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.8003,pcr_scale:4.887,pcr_whiten:3.8004,pcr_s_w:4.8856'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4655,pcr_scale:4.4785,pcr_whiten:3.4661,pcr_s_w:4.4876'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.8271,pcr_scale:5.4221,pcr_whiten:3.8278,pcr_s_w:5.467'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.5634,pcr_scale:4.6106,pcr_whiten:3.5635,pcr_s_w:4.6115'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.5188,pcr_scale:4.8615,pcr_whiten:3.5191,pcr_s_w:4.8758'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 4, 'mean': 3.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.6656134496328994, 'pcr_scale': 4.48653914053559, 'pcr_whiten': 3.6657329975314874, 'pcr_s_w': 4.489214238248037}, 'fold_1': {'pcr': 3.6566473058008264, 'pcr_scale': 4.954371317161575, 'pcr_whiten': 3.656911314595389, 'pcr_s_w': 4.942610135382543}, 'fold_2': {'pcr': 3.3035381749589883, 'pcr_scale': 4.456872832041323, 'pcr_whiten': 3.303587974441177, 'pcr_s_w': 4.4591490139074335}, 'fold_3': {'pcr': 3.8002884547783324, 'pcr_scale': 4.887038050368209, 'pcr_whiten': 3.8003857023199847, 'pcr_s_w': 4.885604731182493}, 'fold_4': {'pcr': 3.8271153141582013, 'pcr_scale': 5.422108446444815, 'pcr_whiten': 3.8278125035003367, 'pcr_s_w': 5.466968220492462}, 'MSE': {'pcr': 3.6506426353188757, 'pcr_scale': 4.841361800153198, 'pcr_whiten': 3.6508881831875404, 'pcr_s_w': 4.848682740259488}, 'R2': {'pcr': 0.9939257335317041, 'pcr_scale': 0.9919445082465623, 'pcr_whiten': 0.9939253249671488, 'pcr_s_w': 0.9919323270101482}}'\n",
      "pcr: {'fold_0': 3.6656134496328994, 'fold_1': 3.6566473058008264, 'fold_2': 3.3035381749589883, 'fold_3': 3.8002884547783324, 'fold_4': 3.8271153141582013, 'MSE': 3.6506426353188757, 'R2': 0.9939257335317041}'\n",
      "pcr_scale: {'fold_0': 4.48653914053559, 'fold_1': 4.954371317161575, 'fold_2': 4.456872832041323, 'fold_3': 4.887038050368209, 'fold_4': 5.422108446444815, 'MSE': 4.841361800153198, 'R2': 0.9919445082465623}'\n",
      "pcr_whiten: {'fold_0': 3.6657329975314874, 'fold_1': 3.656911314595389, 'fold_2': 3.303587974441177, 'fold_3': 3.8003857023199847, 'fold_4': 3.8278125035003367, 'MSE': 3.6508881831875404, 'R2': 0.9939253249671488}'\n",
      "pcr_s_w: {'fold_0': 4.489214238248037, 'fold_1': 4.942610135382543, 'fold_2': 4.4591490139074335, 'fold_3': 4.885604731182493, 'fold_4': 5.466968220492462, 'MSE': 4.848682740259488, 'R2': 0.9919323270101482}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 31 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4634,pcr_scale:4.565,pcr_whiten:3.4634,pcr_s_w:4.5657'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.586,pcr_scale:4.5025,pcr_whiten:3.5859,pcr_s_w:4.4903'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5099,pcr_scale:4.5792,pcr_whiten:3.51,pcr_s_w:4.6051'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.654,pcr_scale:4.9069,pcr_whiten:3.6539,pcr_s_w:4.926'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6208,pcr_scale:4.6331,pcr_whiten:3.6207,pcr_s_w:4.6485'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.2372,pcr_scale:4.3829,pcr_whiten:3.2367,pcr_s_w:4.4053'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6134,pcr_scale:4.6561,pcr_whiten:3.6132,pcr_s_w:4.6895'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.7691,pcr_scale:4.8422,pcr_whiten:3.7691,pcr_s_w:4.8889'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4114,pcr_scale:4.4722,pcr_whiten:3.4114,pcr_s_w:4.4541'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.8087,pcr_scale:5.4225,pcr_whiten:3.8082,pcr_s_w:5.3387'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.4941,pcr_scale:4.5727,pcr_whiten:3.4942,pcr_s_w:4.5718'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3971,pcr_scale:4.8152,pcr_whiten:3.3973,pcr_s_w:4.7975'\n",
      "Train times: {'fold_0': 3, 'fold_1': 4, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.5859705779515556, 'pcr_scale': 4.502472652899369, 'pcr_whiten': 3.585891713517162, 'pcr_s_w': 4.490286730433227}, 'fold_1': {'pcr': 3.654038069605388, 'pcr_scale': 4.906884131846803, 'pcr_whiten': 3.6539218890159586, 'pcr_s_w': 4.926037734752956}, 'fold_2': {'pcr': 3.237169852039428, 'pcr_scale': 4.382861458940067, 'pcr_whiten': 3.236698077532007, 'pcr_s_w': 4.405330272673592}, 'fold_3': {'pcr': 3.769076424381019, 'pcr_scale': 4.842238403408904, 'pcr_whiten': 3.7690958367742033, 'pcr_s_w': 4.888924567804342}, 'fold_4': {'pcr': 3.8086708206387425, 'pcr_scale': 5.422493188682058, 'pcr_whiten': 3.808159195957647, 'pcr_s_w': 5.3387403760844405}, 'MSE': {'pcr': 3.6109869505961907, 'pcr_scale': 4.811368650420566, 'pcr_whiten': 3.61075517105694, 'pcr_s_w': 4.809843620388115}, 'R2': {'pcr': 0.9939917162147687, 'pcr_scale': 0.9919944135377395, 'pcr_whiten': 0.9939921018703433, 'pcr_s_w': 0.9919969510194145}}'\n",
      "pcr: {'fold_0': 3.5859705779515556, 'fold_1': 3.654038069605388, 'fold_2': 3.237169852039428, 'fold_3': 3.769076424381019, 'fold_4': 3.8086708206387425, 'MSE': 3.6109869505961907, 'R2': 0.9939917162147687}'\n",
      "pcr_scale: {'fold_0': 4.502472652899369, 'fold_1': 4.906884131846803, 'fold_2': 4.382861458940067, 'fold_3': 4.842238403408904, 'fold_4': 5.422493188682058, 'MSE': 4.811368650420566, 'R2': 0.9919944135377395}'\n",
      "pcr_whiten: {'fold_0': 3.585891713517162, 'fold_1': 3.6539218890159586, 'fold_2': 3.236698077532007, 'fold_3': 3.7690958367742033, 'fold_4': 3.808159195957647, 'MSE': 3.61075517105694, 'R2': 0.9939921018703433}'\n",
      "pcr_s_w: {'fold_0': 4.490286730433227, 'fold_1': 4.926037734752956, 'fold_2': 4.405330272673592, 'fold_3': 4.888924567804342, 'fold_4': 5.3387403760844405, 'MSE': 4.809843620388115, 'R2': 0.9919969510194145}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 32 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4631,pcr_scale:4.5374,pcr_whiten:3.4631,pcr_s_w:4.5449'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.5861,pcr_scale:4.496,pcr_whiten:3.5855,pcr_s_w:4.491'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5081,pcr_scale:4.5877,pcr_whiten:3.508,pcr_s_w:4.5964'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.6494,pcr_scale:4.904,pcr_whiten:3.6493,pcr_s_w:4.9241'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6201,pcr_scale:4.6248,pcr_whiten:3.6199,pcr_s_w:4.6217'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.2374,pcr_scale:4.3786,pcr_whiten:3.2371,pcr_s_w:4.3717'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6132,pcr_scale:4.6657,pcr_whiten:3.6131,pcr_s_w:4.6775'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.7691,pcr_scale:4.8566,pcr_whiten:3.769,pcr_s_w:4.8614'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4081,pcr_scale:4.4333,pcr_whiten:3.41,pcr_s_w:4.4442'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.8133,pcr_scale:5.2892,pcr_whiten:3.8147,pcr_s_w:5.2949'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.4913,pcr_scale:4.5667,pcr_whiten:3.4912,pcr_s_w:4.567'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3967,pcr_scale:4.8467,pcr_whiten:3.3966,pcr_s_w:4.8794'\n",
      "Train times: {'fold_0': 3, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 3.8}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.586139238484226, 'pcr_scale': 4.495964507137921, 'pcr_whiten': 3.5854531222504646, 'pcr_s_w': 4.490961800440612}, 'fold_1': {'pcr': 3.6494335980926906, 'pcr_scale': 4.904031817370439, 'pcr_whiten': 3.649329479491671, 'pcr_s_w': 4.924073446434774}, 'fold_2': {'pcr': 3.2373877503558144, 'pcr_scale': 4.3786053683016215, 'pcr_whiten': 3.237091601673036, 'pcr_s_w': 4.3716668803249865}, 'fold_3': {'pcr': 3.7690511932939375, 'pcr_scale': 4.8565730157347415, 'pcr_whiten': 3.769035216594211, 'pcr_s_w': 4.861350137600194}, 'fold_4': {'pcr': 3.8132903056533385, 'pcr_scale': 5.289150335675191, 'pcr_whiten': 3.81474569364168, 'pcr_s_w': 5.2949357646438395}, 'MSE': {'pcr': 3.611061760763918, 'pcr_scale': 4.784848055818295, 'pcr_whiten': 3.6111322732851745, 'pcr_s_w': 4.7885814093282635}, 'R2': {'pcr': 0.9939915917389055, 'pcr_scale': 0.9920385408804033, 'pcr_whiten': 0.9939914744138517, 'pcr_s_w': 0.9920323289921674}}'\n",
      "pcr: {'fold_0': 3.586139238484226, 'fold_1': 3.6494335980926906, 'fold_2': 3.2373877503558144, 'fold_3': 3.7690511932939375, 'fold_4': 3.8132903056533385, 'MSE': 3.611061760763918, 'R2': 0.9939915917389055}'\n",
      "pcr_scale: {'fold_0': 4.495964507137921, 'fold_1': 4.904031817370439, 'fold_2': 4.3786053683016215, 'fold_3': 4.8565730157347415, 'fold_4': 5.289150335675191, 'MSE': 4.784848055818295, 'R2': 0.9920385408804033}'\n",
      "pcr_whiten: {'fold_0': 3.5854531222504646, 'fold_1': 3.649329479491671, 'fold_2': 3.237091601673036, 'fold_3': 3.769035216594211, 'fold_4': 3.81474569364168, 'MSE': 3.6111322732851745, 'R2': 0.9939914744138517}'\n",
      "pcr_s_w: {'fold_0': 4.490961800440612, 'fold_1': 4.924073446434774, 'fold_2': 4.3716668803249865, 'fold_3': 4.861350137600194, 'fold_4': 5.2949357646438395, 'MSE': 4.7885814093282635, 'R2': 0.9920323289921674}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 33 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4534,pcr_scale:4.5043,pcr_whiten:3.4534,pcr_s_w:4.5355'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.5771,pcr_scale:4.5041,pcr_whiten:3.577,pcr_s_w:4.4897'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5079,pcr_scale:4.5758,pcr_whiten:3.508,pcr_s_w:4.5872'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.6499,pcr_scale:4.9127,pcr_whiten:3.65,pcr_s_w:4.8999'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6157,pcr_scale:4.5954,pcr_whiten:3.6155,pcr_s_w:4.6237'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.23,pcr_scale:4.3877,pcr_whiten:3.2298,pcr_s_w:4.3978'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.6107,pcr_scale:4.6779,pcr_whiten:3.6107,pcr_s_w:4.6531'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.7653,pcr_scale:4.8543,pcr_whiten:3.7654,pcr_s_w:4.8391'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4074,pcr_scale:4.4267,pcr_whiten:3.4074,pcr_s_w:4.4472'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.8111,pcr_scale:5.2933,pcr_whiten:3.8108,pcr_s_w:5.3403'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.4871,pcr_scale:4.5663,pcr_whiten:3.4868,pcr_s_w:4.5633'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3862,pcr_scale:4.8697,pcr_whiten:3.3858,pcr_s_w:4.8251'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.5771277904092087, 'pcr_scale': 4.5040943182584945, 'pcr_whiten': 3.5770212995960393, 'pcr_s_w': 4.489669700537763}, 'fold_1': {'pcr': 3.6499066110285017, 'pcr_scale': 4.912745064086047, 'pcr_whiten': 3.6500122197411757, 'pcr_s_w': 4.89988519893311}, 'fold_2': {'pcr': 3.229956367275253, 'pcr_scale': 4.387680808506413, 'pcr_whiten': 3.22982574278377, 'pcr_s_w': 4.3978283367159605}, 'fold_3': {'pcr': 3.7653009029559574, 'pcr_scale': 4.8543403207845275, 'pcr_whiten': 3.7653867851088103, 'pcr_s_w': 4.839147307121183}, 'fold_4': {'pcr': 3.8110572443177975, 'pcr_scale': 5.293331617254359, 'pcr_whiten': 3.810754561524343, 'pcr_s_w': 5.340261738932098}, 'MSE': {'pcr': 3.606671151039437, 'pcr_scale': 4.79042204169195, 'pcr_whiten': 3.6066015034204075, 'pcr_s_w': 4.793338763877765}, 'R2': {'pcr': 0.993998897228949, 'pcr_scale': 0.9920292663830423, 'pcr_whiten': 0.9939990131149009, 'pcr_s_w': 0.9920244132792082}}'\n",
      "pcr: {'fold_0': 3.5771277904092087, 'fold_1': 3.6499066110285017, 'fold_2': 3.229956367275253, 'fold_3': 3.7653009029559574, 'fold_4': 3.8110572443177975, 'MSE': 3.606671151039437, 'R2': 0.993998897228949}'\n",
      "pcr_scale: {'fold_0': 4.5040943182584945, 'fold_1': 4.912745064086047, 'fold_2': 4.387680808506413, 'fold_3': 4.8543403207845275, 'fold_4': 5.293331617254359, 'MSE': 4.79042204169195, 'R2': 0.9920292663830423}'\n",
      "pcr_whiten: {'fold_0': 3.5770212995960393, 'fold_1': 3.6500122197411757, 'fold_2': 3.22982574278377, 'fold_3': 3.7653867851088103, 'fold_4': 3.810754561524343, 'MSE': 3.6066015034204075, 'R2': 0.9939990131149009}'\n",
      "pcr_s_w: {'fold_0': 4.489669700537763, 'fold_1': 4.89988519893311, 'fold_2': 4.3978283367159605, 'fold_3': 4.839147307121183, 'fold_4': 5.340261738932098, 'MSE': 4.793338763877765, 'R2': 0.9920244132792082}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 34 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4513,pcr_scale:4.4996,pcr_whiten:3.4512,pcr_s_w:4.5126'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.5747,pcr_scale:4.4873,pcr_whiten:3.5746,pcr_s_w:4.4803'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4329,pcr_scale:4.5639,pcr_whiten:3.4331,pcr_s_w:4.5557'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.5538,pcr_scale:4.8979,pcr_whiten:3.5545,pcr_s_w:4.8908'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5938,pcr_scale:4.5885,pcr_whiten:3.5938,pcr_s_w:4.5917'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.1893,pcr_scale:4.3208,pcr_whiten:3.1894,pcr_s_w:4.3581'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5824,pcr_scale:4.6473,pcr_whiten:3.5829,pcr_s_w:4.6522'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.7529,pcr_scale:4.8214,pcr_whiten:3.7526,pcr_s_w:4.8402'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4044,pcr_scale:4.4349,pcr_whiten:3.4043,pcr_s_w:4.4044'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.811,pcr_scale:5.3127,pcr_whiten:3.8108,pcr_s_w:5.3411'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.4554,pcr_scale:4.5242,pcr_whiten:3.4553,pcr_s_w:4.53'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3514,pcr_scale:4.7775,pcr_whiten:3.3513,pcr_s_w:4.8172'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.5746612004875398, 'pcr_scale': 4.4872997431409285, 'pcr_whiten': 3.5745539554494776, 'pcr_s_w': 4.48028809421346}, 'fold_1': {'pcr': 3.5537964535573523, 'pcr_scale': 4.897899554943775, 'pcr_whiten': 3.554493152401633, 'pcr_s_w': 4.890761840950988}, 'fold_2': {'pcr': 3.18930162099085, 'pcr_scale': 4.320843277484181, 'pcr_whiten': 3.189411579231179, 'pcr_s_w': 4.358118717564929}, 'fold_3': {'pcr': 3.7529370303335843, 'pcr_scale': 4.821420473461734, 'pcr_whiten': 3.7526376672252053, 'pcr_s_w': 4.840243704976545}, 'fold_4': {'pcr': 3.8109865300223755, 'pcr_scale': 5.312721314643104, 'pcr_whiten': 3.810774845851406, 'pcr_s_w': 5.341071397768855}, 'MSE': {'pcr': 3.5763341484327036, 'pcr_scale': 4.768021803373239, 'pcr_whiten': 3.576371872735315, 'pcr_s_w': 4.782077459887701}, 'R2': {'pcr': 0.9940493746533619, 'pcr_scale': 0.9920665379075637, 'pcr_whiten': 0.9940493118842855, 'pcr_s_w': 0.9920431508462749}}'\n",
      "pcr: {'fold_0': 3.5746612004875398, 'fold_1': 3.5537964535573523, 'fold_2': 3.18930162099085, 'fold_3': 3.7529370303335843, 'fold_4': 3.8109865300223755, 'MSE': 3.5763341484327036, 'R2': 0.9940493746533619}'\n",
      "pcr_scale: {'fold_0': 4.4872997431409285, 'fold_1': 4.897899554943775, 'fold_2': 4.320843277484181, 'fold_3': 4.821420473461734, 'fold_4': 5.312721314643104, 'MSE': 4.768021803373239, 'R2': 0.9920665379075637}'\n",
      "pcr_whiten: {'fold_0': 3.5745539554494776, 'fold_1': 3.554493152401633, 'fold_2': 3.189411579231179, 'fold_3': 3.7526376672252053, 'fold_4': 3.810774845851406, 'MSE': 3.576371872735315, 'R2': 0.9940493118842855}'\n",
      "pcr_s_w: {'fold_0': 4.48028809421346, 'fold_1': 4.890761840950988, 'fold_2': 4.358118717564929, 'fold_3': 4.840243704976545, 'fold_4': 5.341071397768855, 'MSE': 4.782077459887701, 'R2': 0.9920431508462749}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 35 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4502,pcr_scale:4.5017,pcr_whiten:3.45,pcr_s_w:4.514'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.5706,pcr_scale:4.477,pcr_whiten:3.5703,pcr_s_w:4.4726'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4223,pcr_scale:4.5709,pcr_whiten:3.4222,pcr_s_w:4.5668'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.5506,pcr_scale:4.904,pcr_whiten:3.5504,pcr_s_w:4.8752'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5876,pcr_scale:4.602,pcr_whiten:3.5877,pcr_s_w:4.6109'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.1945,pcr_scale:4.3768,pcr_whiten:3.1946,pcr_s_w:4.3683'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.5735,pcr_scale:4.6127,pcr_whiten:3.5735,pcr_s_w:4.603'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.7512,pcr_scale:4.8092,pcr_whiten:3.7512,pcr_s_w:4.8016'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3742,pcr_scale:4.3942,pcr_whiten:3.374,pcr_s_w:4.3889'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.7501,pcr_scale:5.2988,pcr_whiten:3.7498,pcr_s_w:5.3313'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.4514,pcr_scale:4.5614,pcr_whiten:3.4514,pcr_s_w:4.5061'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3511,pcr_scale:4.8213,pcr_whiten:3.3511,pcr_s_w:4.7687'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.570583451313759, 'pcr_scale': 4.477002001789146, 'pcr_whiten': 3.570262630302021, 'pcr_s_w': 4.472555307579094}, 'fold_1': {'pcr': 3.5506416049618483, 'pcr_scale': 4.903990062980239, 'pcr_whiten': 3.550409744506352, 'pcr_s_w': 4.875204570535578}, 'fold_2': {'pcr': 3.1945270557368226, 'pcr_scale': 4.376763147561782, 'pcr_whiten': 3.1946172680209672, 'pcr_s_w': 4.368271142933669}, 'fold_3': {'pcr': 3.751213626217954, 'pcr_scale': 4.809207755251592, 'pcr_whiten': 3.751189788926855, 'pcr_s_w': 4.80163185058942}, 'fold_4': {'pcr': 3.750081933550629, 'pcr_scale': 5.298792961439466, 'pcr_whiten': 3.7497760649425196, 'pcr_s_w': 5.3313468011284755}, 'MSE': {'pcr': 3.563408975625435, 'pcr_scale': 4.773134674587222, 'pcr_whiten': 3.5632505170560957, 'pcr_s_w': 4.769782773147835}, 'R2': {'pcr': 0.9940708807145195, 'pcr_scale': 0.9920580306541089, 'pcr_whiten': 0.9940711443720918, 'pcr_s_w': 0.9920636078481956}}'\n",
      "pcr: {'fold_0': 3.570583451313759, 'fold_1': 3.5506416049618483, 'fold_2': 3.1945270557368226, 'fold_3': 3.751213626217954, 'fold_4': 3.750081933550629, 'MSE': 3.563408975625435, 'R2': 0.9940708807145195}'\n",
      "pcr_scale: {'fold_0': 4.477002001789146, 'fold_1': 4.903990062980239, 'fold_2': 4.376763147561782, 'fold_3': 4.809207755251592, 'fold_4': 5.298792961439466, 'MSE': 4.773134674587222, 'R2': 0.9920580306541089}'\n",
      "pcr_whiten: {'fold_0': 3.570262630302021, 'fold_1': 3.550409744506352, 'fold_2': 3.1946172680209672, 'fold_3': 3.751189788926855, 'fold_4': 3.7497760649425196, 'MSE': 3.5632505170560957, 'R2': 0.9940711443720918}'\n",
      "pcr_s_w: {'fold_0': 4.472555307579094, 'fold_1': 4.875204570535578, 'fold_2': 4.368271142933669, 'fold_3': 4.80163185058942, 'fold_4': 5.3313468011284755, 'MSE': 4.769782773147835, 'R2': 0.9920636078481956}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 36 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4445,pcr_scale:4.524,pcr_whiten:3.4438,pcr_s_w:4.4815'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.547,pcr_scale:4.5103,pcr_whiten:3.5442,pcr_s_w:4.448'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3688,pcr_scale:4.5202,pcr_whiten:3.3679,pcr_s_w:4.5554'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.5247,pcr_scale:4.8669,pcr_whiten:3.5252,pcr_s_w:4.8995'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4364,pcr_scale:4.5908,pcr_whiten:3.4361,pcr_s_w:4.5662'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.1069,pcr_scale:4.3462,pcr_whiten:3.1069,pcr_s_w:4.3297'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4491,pcr_scale:4.5972,pcr_whiten:3.4489,pcr_s_w:4.6227'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.7118,pcr_scale:4.8147,pcr_whiten:3.7116,pcr_s_w:4.821'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3741,pcr_scale:4.4036,pcr_whiten:3.3741,pcr_s_w:4.416'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.7491,pcr_scale:5.2754,pcr_whiten:3.7489,pcr_s_w:5.3031'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.3586,pcr_scale:4.5357,pcr_whiten:3.3585,pcr_s_w:4.5012'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2978,pcr_scale:4.8307,pcr_whiten:3.2977,pcr_s_w:4.788'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.5469563497023033, 'pcr_scale': 4.510274472223413, 'pcr_whiten': 3.544197983266485, 'pcr_s_w': 4.447987891550634}, 'fold_1': {'pcr': 3.5247056147377664, 'pcr_scale': 4.866855536195431, 'pcr_whiten': 3.5251610087452936, 'pcr_s_w': 4.899473564696926}, 'fold_2': {'pcr': 3.1069002804627055, 'pcr_scale': 4.346180790067726, 'pcr_whiten': 3.1069025746698613, 'pcr_s_w': 4.3296761866017555}, 'fold_3': {'pcr': 3.7117743302358304, 'pcr_scale': 4.814702447970137, 'pcr_whiten': 3.7116276814182294, 'pcr_s_w': 4.8209606443922}, 'fold_4': {'pcr': 3.7491311745974434, 'pcr_scale': 5.275377919001362, 'pcr_whiten': 3.7489183585934582, 'pcr_s_w': 5.303077107302716}, 'MSE': {'pcr': 3.5278951355309633, 'pcr_scale': 4.7626634282116935, 'pcr_whiten': 3.5273629831793905, 'pcr_s_w': 4.76021779877485}, 'R2': {'pcr': 0.9941299718252077, 'pcr_scale': 0.992075453652494, 'pcr_whiten': 0.9941308572679936, 'pcr_s_w': 0.9920795229099827}}'\n",
      "pcr: {'fold_0': 3.5469563497023033, 'fold_1': 3.5247056147377664, 'fold_2': 3.1069002804627055, 'fold_3': 3.7117743302358304, 'fold_4': 3.7491311745974434, 'MSE': 3.5278951355309633, 'R2': 0.9941299718252077}'\n",
      "pcr_scale: {'fold_0': 4.510274472223413, 'fold_1': 4.866855536195431, 'fold_2': 4.346180790067726, 'fold_3': 4.814702447970137, 'fold_4': 5.275377919001362, 'MSE': 4.7626634282116935, 'R2': 0.992075453652494}'\n",
      "pcr_whiten: {'fold_0': 3.544197983266485, 'fold_1': 3.5251610087452936, 'fold_2': 3.1069025746698613, 'fold_3': 3.7116276814182294, 'fold_4': 3.7489183585934582, 'MSE': 3.5273629831793905, 'R2': 0.9941308572679936}'\n",
      "pcr_s_w: {'fold_0': 4.447987891550634, 'fold_1': 4.899473564696926, 'fold_2': 4.3296761866017555, 'fold_3': 4.8209606443922, 'fold_4': 5.303077107302716, 'MSE': 4.76021779877485, 'R2': 0.9920795229099827}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 37 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3687,pcr_scale:4.4632,pcr_whiten:3.3722,pcr_s_w:4.4693'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4888,pcr_scale:4.4484,pcr_whiten:3.4945,pcr_s_w:4.451'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3599,pcr_scale:4.5349,pcr_whiten:3.3602,pcr_s_w:4.5214'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.5017,pcr_scale:4.8973,pcr_whiten:3.5023,pcr_s_w:4.8619'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4362,pcr_scale:4.5353,pcr_whiten:3.4358,pcr_s_w:4.5814'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.1051,pcr_scale:4.3073,pcr_whiten:3.105,pcr_s_w:4.3559'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.4373,pcr_scale:4.6009,pcr_whiten:3.4375,pcr_s_w:4.5587'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.6734,pcr_scale:4.8228,pcr_whiten:3.6741,pcr_s_w:4.772'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3389,pcr_scale:4.4137,pcr_whiten:3.3389,pcr_s_w:4.399'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.7273,pcr_scale:5.3122,pcr_whiten:3.7276,pcr_s_w:5.2769'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.348,pcr_scale:4.548,pcr_whiten:3.3489,pcr_s_w:4.5301'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2623,pcr_scale:4.8572,pcr_whiten:3.2641,pcr_s_w:4.8004'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.488789535760328, 'pcr_scale': 4.448356427276498, 'pcr_whiten': 3.4944966788855854, 'pcr_s_w': 4.450951895604809}, 'fold_1': {'pcr': 3.501748824732714, 'pcr_scale': 4.897347870180365, 'pcr_whiten': 3.502325816224239, 'pcr_s_w': 4.861878192071078}, 'fold_2': {'pcr': 3.1051236099075075, 'pcr_scale': 4.307280042876364, 'pcr_whiten': 3.1050057037551855, 'pcr_s_w': 4.355861717495376}, 'fold_3': {'pcr': 3.673449492179619, 'pcr_scale': 4.822821886664589, 'pcr_whiten': 3.674067653795543, 'pcr_s_w': 4.7720158008021984}, 'fold_4': {'pcr': 3.7272687103923454, 'pcr_scale': 5.312214423962719, 'pcr_whiten': 3.727641899741557, 'pcr_s_w': 5.276926663079478}, 'MSE': {'pcr': 3.4992752341841253, 'pcr_scale': 4.757587200111911, 'pcr_whiten': 3.5007070917702885, 'pcr_s_w': 4.74350945233037}, 'R2': {'pcr': 0.9941775921826196, 'pcr_scale': 0.9920838999358508, 'pcr_whiten': 0.9941752097296128, 'pcr_s_w': 0.99210732375457}}'\n",
      "pcr: {'fold_0': 3.488789535760328, 'fold_1': 3.501748824732714, 'fold_2': 3.1051236099075075, 'fold_3': 3.673449492179619, 'fold_4': 3.7272687103923454, 'MSE': 3.4992752341841253, 'R2': 0.9941775921826196}'\n",
      "pcr_scale: {'fold_0': 4.448356427276498, 'fold_1': 4.897347870180365, 'fold_2': 4.307280042876364, 'fold_3': 4.822821886664589, 'fold_4': 5.312214423962719, 'MSE': 4.757587200111911, 'R2': 0.9920838999358508}'\n",
      "pcr_whiten: {'fold_0': 3.4944966788855854, 'fold_1': 3.502325816224239, 'fold_2': 3.1050057037551855, 'fold_3': 3.674067653795543, 'fold_4': 3.727641899741557, 'MSE': 3.5007070917702885, 'R2': 0.9941752097296128}'\n",
      "pcr_s_w: {'fold_0': 4.450951895604809, 'fold_1': 4.861878192071078, 'fold_2': 4.355861717495376, 'fold_3': 4.7720158008021984, 'fold_4': 5.276926663079478, 'MSE': 4.74350945233037, 'R2': 0.99210732375457}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 38 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3726,pcr_scale:4.4698,pcr_whiten:3.3743,pcr_s_w:4.5085'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4971,pcr_scale:4.4043,pcr_whiten:3.4986,pcr_s_w:4.4899'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2802,pcr_scale:4.486,pcr_whiten:3.2795,pcr_s_w:4.5303'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4157,pcr_scale:4.8382,pcr_whiten:3.4159,pcr_s_w:4.8648'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3759,pcr_scale:4.5584,pcr_whiten:3.3746,pcr_s_w:4.5797'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.0377,pcr_scale:4.3508,pcr_whiten:3.0368,pcr_s_w:4.3217'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3536,pcr_scale:4.5847,pcr_whiten:3.3534,pcr_s_w:4.6223'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.5694,pcr_scale:4.7821,pcr_whiten:3.569,pcr_s_w:4.8231'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3102,pcr_scale:4.4024,pcr_whiten:3.3087,pcr_s_w:4.3759'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.7814,pcr_scale:5.3294,pcr_whiten:3.7921,pcr_s_w:5.3189'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.2499,pcr_scale:4.5065,pcr_whiten:3.2493,pcr_s_w:4.4799'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.1022,pcr_scale:4.8141,pcr_whiten:3.1018,pcr_s_w:4.7675'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.4970960881615922, 'pcr_scale': 4.404343302985489, 'pcr_whiten': 3.49858360307533, 'pcr_s_w': 4.48991755266092}, 'fold_1': {'pcr': 3.4156646089976594, 'pcr_scale': 4.838219989390428, 'pcr_whiten': 3.415854619002844, 'pcr_s_w': 4.864773696394853}, 'fold_2': {'pcr': 3.0377392839885293, 'pcr_scale': 4.350800293191768, 'pcr_whiten': 3.03682235516337, 'pcr_s_w': 4.321722405267714}, 'fold_3': {'pcr': 3.56941532729817, 'pcr_scale': 4.7821443277350655, 'pcr_whiten': 3.5689990436746872, 'pcr_s_w': 4.8231400360396135}, 'fold_4': {'pcr': 3.781400711084807, 'pcr_scale': 5.329381071062909, 'pcr_whiten': 3.7920773752840056, 'pcr_s_w': 5.318856151967133}, 'MSE': {'pcr': 3.4602624282658545, 'pcr_scale': 4.74095388633564, 'pcr_whiten': 3.4624663508404874, 'pcr_s_w': 4.7636647218931465}, 'R2': {'pcr': 0.9942425051863003, 'pcr_scale': 0.9921115759343586, 'pcr_whiten': 0.9942388381023561, 'pcr_s_w': 0.9920737876103087}}'\n",
      "pcr: {'fold_0': 3.4970960881615922, 'fold_1': 3.4156646089976594, 'fold_2': 3.0377392839885293, 'fold_3': 3.56941532729817, 'fold_4': 3.781400711084807, 'MSE': 3.4602624282658545, 'R2': 0.9942425051863003}'\n",
      "pcr_scale: {'fold_0': 4.404343302985489, 'fold_1': 4.838219989390428, 'fold_2': 4.350800293191768, 'fold_3': 4.7821443277350655, 'fold_4': 5.329381071062909, 'MSE': 4.74095388633564, 'R2': 0.9921115759343586}'\n",
      "pcr_whiten: {'fold_0': 3.49858360307533, 'fold_1': 3.415854619002844, 'fold_2': 3.03682235516337, 'fold_3': 3.5689990436746872, 'fold_4': 3.7920773752840056, 'MSE': 3.4624663508404874, 'R2': 0.9942388381023561}'\n",
      "pcr_s_w: {'fold_0': 4.48991755266092, 'fold_1': 4.864773696394853, 'fold_2': 4.321722405267714, 'fold_3': 4.8231400360396135, 'fold_4': 5.318856151967133, 'MSE': 4.7636647218931465, 'R2': 0.9920737876103087}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 39 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2063,pcr_scale:4.5075,pcr_whiten:3.2106,pcr_s_w:4.4934'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3187,pcr_scale:4.4539,pcr_whiten:3.3235,pcr_s_w:4.4818'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2751,pcr_scale:4.4935,pcr_whiten:3.2755,pcr_s_w:4.5709'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4331,pcr_scale:4.8459,pcr_whiten:3.4334,pcr_s_w:4.8998'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3749,pcr_scale:4.6011,pcr_whiten:3.3746,pcr_s_w:4.5363'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.0394,pcr_scale:4.408,pcr_whiten:3.0388,pcr_s_w:4.3007'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3436,pcr_scale:4.5776,pcr_whiten:3.3439,pcr_s_w:4.6084'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.5631,pcr_scale:4.7812,pcr_whiten:3.5632,pcr_s_w:4.7972'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0955,pcr_scale:4.3703,pcr_whiten:3.1031,pcr_s_w:4.403'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:6.9412,pcr_scale:5.2626,pcr_whiten:6.7584,pcr_s_w:5.3158'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.2418,pcr_scale:4.4735,pcr_whiten:3.2421,pcr_s_w:4.4808'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0889,pcr_scale:4.7583,pcr_whiten:3.0883,pcr_s_w:4.8079'\n",
      "Train times: {'fold_0': 4, 'fold_1': 3, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 3.8}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.3186600088218916, 'pcr_scale': 4.453943490076519, 'pcr_whiten': 3.323513011735848, 'pcr_s_w': 4.481828719063936}, 'fold_1': {'pcr': 3.433082375382432, 'pcr_scale': 4.845886521699226, 'pcr_whiten': 3.433356536723334, 'pcr_s_w': 4.899767184237262}, 'fold_2': {'pcr': 3.0393554865207264, 'pcr_scale': 4.407960527037493, 'pcr_whiten': 3.038829379989476, 'pcr_s_w': 4.3006538228419675}, 'fold_3': {'pcr': 3.563085606466513, 'pcr_scale': 4.78119495575785, 'pcr_whiten': 3.563189263542445, 'pcr_s_w': 4.797176180393338}, 'fold_4': {'pcr': 6.941178670536534, 'pcr_scale': 5.2626294228186135, 'pcr_whiten': 6.758350684788747, 'pcr_s_w': 5.315774821478611}, 'MSE': {'pcr': 4.058935953069901, 'pcr_scale': 4.750302925951454, 'pcr_whiten': 4.0233189273733245, 'pcr_s_w': 4.759026513522728}, 'R2': {'pcr': 0.993246378509317, 'pcr_scale': 0.9920960201641773, 'pcr_whiten': 0.9933056413094596, 'pcr_s_w': 0.9920815050771746}}'\n",
      "pcr: {'fold_0': 3.3186600088218916, 'fold_1': 3.433082375382432, 'fold_2': 3.0393554865207264, 'fold_3': 3.563085606466513, 'fold_4': 6.941178670536534, 'MSE': 4.058935953069901, 'R2': 0.993246378509317}'\n",
      "pcr_scale: {'fold_0': 4.453943490076519, 'fold_1': 4.845886521699226, 'fold_2': 4.407960527037493, 'fold_3': 4.78119495575785, 'fold_4': 5.2626294228186135, 'MSE': 4.750302925951454, 'R2': 0.9920960201641773}'\n",
      "pcr_whiten: {'fold_0': 3.323513011735848, 'fold_1': 3.433356536723334, 'fold_2': 3.038829379989476, 'fold_3': 3.563189263542445, 'fold_4': 6.758350684788747, 'MSE': 4.0233189273733245, 'R2': 0.9933056413094596}'\n",
      "pcr_s_w: {'fold_0': 4.481828719063936, 'fold_1': 4.899767184237262, 'fold_2': 4.3006538228419675, 'fold_3': 4.797176180393338, 'fold_4': 5.315774821478611, 'MSE': 4.759026513522728, 'R2': 0.9920815050771746}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 40 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1991,pcr_scale:4.4645,pcr_whiten:3.1998,pcr_s_w:4.4684'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3131,pcr_scale:4.4394,pcr_whiten:3.3134,pcr_s_w:4.4112'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2579,pcr_scale:4.4949,pcr_whiten:3.257,pcr_s_w:4.4627'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4344,pcr_scale:4.8526,pcr_whiten:3.434,pcr_s_w:4.8286'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3531,pcr_scale:4.5413,pcr_whiten:3.3528,pcr_s_w:4.5013'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.043,pcr_scale:4.3231,pcr_whiten:3.0426,pcr_s_w:4.2554'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.34,pcr_scale:4.598,pcr_whiten:3.3398,pcr_s_w:4.5869'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.552,pcr_scale:4.8146,pcr_whiten:3.5515,pcr_s_w:4.7687'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0723,pcr_scale:4.3755,pcr_whiten:3.075,pcr_s_w:4.3904'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:8.1007,pcr_scale:5.2644,pcr_whiten:7.978,pcr_s_w:5.3063'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.2383,pcr_scale:4.4946,pcr_whiten:3.2384,pcr_s_w:4.4714'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0905,pcr_scale:4.7531,pcr_whiten:3.0904,pcr_s_w:4.7375'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.3131148961446115, 'pcr_scale': 4.4394028403477, 'pcr_whiten': 3.3134290730927853, 'pcr_s_w': 4.411155594215743}, 'fold_1': {'pcr': 3.4343676704614876, 'pcr_scale': 4.852630219538826, 'pcr_whiten': 3.4339512773901477, 'pcr_s_w': 4.8285898300524925}, 'fold_2': {'pcr': 3.0429864316304, 'pcr_scale': 4.323135163034513, 'pcr_whiten': 3.0425725686121767, 'pcr_s_w': 4.255411733244691}, 'fold_3': {'pcr': 3.551983418021782, 'pcr_scale': 4.814610220074062, 'pcr_whiten': 3.5515079378678105, 'pcr_s_w': 4.7686560237013556}, 'fold_4': {'pcr': 8.100678652029703, 'pcr_scale': 5.264352350453703, 'pcr_whiten': 7.97804911690791, 'pcr_s_w': 5.3062913329246735}, 'MSE': {'pcr': 4.2884434559807385, 'pcr_scale': 4.7388076190116255, 'pcr_whiten': 4.263724165805023, 'pcr_s_w': 4.714002095758136}, 'R2': {'pcr': 0.9928645033524155, 'pcr_scale': 0.9921151470863285, 'pcr_whiten': 0.9929056335233015, 'pcr_s_w': 0.9921564207395395}}'\n",
      "pcr: {'fold_0': 3.3131148961446115, 'fold_1': 3.4343676704614876, 'fold_2': 3.0429864316304, 'fold_3': 3.551983418021782, 'fold_4': 8.100678652029703, 'MSE': 4.2884434559807385, 'R2': 0.9928645033524155}'\n",
      "pcr_scale: {'fold_0': 4.4394028403477, 'fold_1': 4.852630219538826, 'fold_2': 4.323135163034513, 'fold_3': 4.814610220074062, 'fold_4': 5.264352350453703, 'MSE': 4.7388076190116255, 'R2': 0.9921151470863285}'\n",
      "pcr_whiten: {'fold_0': 3.3134290730927853, 'fold_1': 3.4339512773901477, 'fold_2': 3.0425725686121767, 'fold_3': 3.5515079378678105, 'fold_4': 7.97804911690791, 'MSE': 4.263724165805023, 'R2': 0.9929056335233015}'\n",
      "pcr_s_w: {'fold_0': 4.411155594215743, 'fold_1': 4.8285898300524925, 'fold_2': 4.255411733244691, 'fold_3': 4.7686560237013556, 'fold_4': 5.3062913329246735, 'MSE': 4.714002095758136, 'R2': 0.9921564207395395}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 41 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1261,pcr_scale:4.4805,pcr_whiten:3.126,pcr_s_w:4.4606'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.1875,pcr_scale:4.4419,pcr_whiten:3.1875,pcr_s_w:4.4557'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2579,pcr_scale:4.5017,pcr_whiten:3.258,pcr_s_w:4.5233'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4337,pcr_scale:4.8666,pcr_whiten:3.4337,pcr_s_w:4.8615'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3481,pcr_scale:4.5389,pcr_whiten:3.3477,pcr_s_w:4.5073'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.036,pcr_scale:4.3196,pcr_whiten:3.0354,pcr_s_w:4.2711'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3394,pcr_scale:4.5873,pcr_whiten:3.3394,pcr_s_w:4.6127'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.5484,pcr_scale:4.7884,pcr_whiten:3.5489,pcr_s_w:4.8339'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0191,pcr_scale:4.3759,pcr_whiten:3.0239,pcr_s_w:4.3696'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:10.5127,pcr_scale:5.2883,pcr_whiten:10.3703,pcr_s_w:5.3306'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.2383,pcr_scale:4.4599,pcr_whiten:3.2384,pcr_s_w:4.4503'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0918,pcr_scale:4.7217,pcr_whiten:3.0917,pcr_s_w:4.7213'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.1874614287617145, 'pcr_scale': 4.441937682532246, 'pcr_whiten': 3.1875371780808748, 'pcr_s_w': 4.455699571505066}, 'fold_1': {'pcr': 3.433666586889335, 'pcr_scale': 4.866585352622174, 'pcr_whiten': 3.433746957374525, 'pcr_s_w': 4.861515360343637}, 'fold_2': {'pcr': 3.0359828829758655, 'pcr_scale': 4.319606120451228, 'pcr_whiten': 3.0354094039963755, 'pcr_s_w': 4.271133368728205}, 'fold_3': {'pcr': 3.5484335317726674, 'pcr_scale': 4.788362561005718, 'pcr_whiten': 3.548871120052905, 'pcr_s_w': 4.833886353320536}, 'fold_4': {'pcr': 10.512730457467503, 'pcr_scale': 5.2883208900516, 'pcr_whiten': 10.370321140763995, 'pcr_s_w': 5.330575932377745}, 'MSE': {'pcr': 4.743368702909065, 'pcr_scale': 4.7409452019151415, 'pcr_whiten': 4.714896589719671, 'pcr_s_w': 4.750543748367436}, 'R2': {'pcr': 0.9921075579460743, 'pcr_scale': 0.992111590384276, 'pcr_whiten': 0.9921549324003018, 'pcr_s_w': 0.9920956194622538}}'\n",
      "pcr: {'fold_0': 3.1874614287617145, 'fold_1': 3.433666586889335, 'fold_2': 3.0359828829758655, 'fold_3': 3.5484335317726674, 'fold_4': 10.512730457467503, 'MSE': 4.743368702909065, 'R2': 0.9921075579460743}'\n",
      "pcr_scale: {'fold_0': 4.441937682532246, 'fold_1': 4.866585352622174, 'fold_2': 4.319606120451228, 'fold_3': 4.788362561005718, 'fold_4': 5.2883208900516, 'MSE': 4.7409452019151415, 'R2': 0.992111590384276}'\n",
      "pcr_whiten: {'fold_0': 3.1875371780808748, 'fold_1': 3.433746957374525, 'fold_2': 3.0354094039963755, 'fold_3': 3.548871120052905, 'fold_4': 10.370321140763995, 'MSE': 4.714896589719671, 'R2': 0.9921549324003018}'\n",
      "pcr_s_w: {'fold_0': 4.455699571505066, 'fold_1': 4.861515360343637, 'fold_2': 4.271133368728205, 'fold_3': 4.833886353320536, 'fold_4': 5.330575932377745, 'MSE': 4.750543748367436, 'R2': 0.9920956194622538}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 42 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.125,pcr_scale:4.458,pcr_whiten:3.1267,pcr_s_w:4.4419'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.1846,pcr_scale:4.4404,pcr_whiten:3.1859,pcr_s_w:4.4408'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2458,pcr_scale:4.522,pcr_whiten:3.2456,pcr_s_w:4.4617'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4499,pcr_scale:4.8604,pcr_whiten:3.4499,pcr_s_w:4.832'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3359,pcr_scale:4.5392,pcr_whiten:3.3355,pcr_s_w:4.552'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.0164,pcr_scale:4.3131,pcr_whiten:3.016,pcr_s_w:4.2974'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3378,pcr_scale:4.5979,pcr_whiten:3.3377,pcr_s_w:4.5836'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.5451,pcr_scale:4.8184,pcr_whiten:3.5448,pcr_s_w:4.7889'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0041,pcr_scale:4.3752,pcr_whiten:3.0042,pcr_s_w:4.3816'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:10.896,pcr_scale:5.319,pcr_whiten:10.8836,pcr_s_w:5.2921'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.2361,pcr_scale:4.4826,pcr_whiten:3.2359,pcr_s_w:4.4597'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.089,pcr_scale:4.7588,pcr_whiten:3.0886,pcr_s_w:4.7067'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.184616052064113, 'pcr_scale': 4.4403617024547, 'pcr_whiten': 3.185936456482598, 'pcr_s_w': 4.440806250106012}, 'fold_1': {'pcr': 3.4499094696411503, 'pcr_scale': 4.860421407823831, 'pcr_whiten': 3.449863248055303, 'pcr_s_w': 4.831956084545378}, 'fold_2': {'pcr': 3.016448947155719, 'pcr_scale': 4.313105973475846, 'pcr_whiten': 3.0160133560063342, 'pcr_s_w': 4.29739809190006}, 'fold_3': {'pcr': 3.5451027822375933, 'pcr_scale': 4.818393321155686, 'pcr_whiten': 3.544835235650066, 'pcr_s_w': 4.788884641974189}, 'fold_4': {'pcr': 10.896007417522021, 'pcr_scale': 5.319024066690468, 'pcr_whiten': 10.883601940052728, 'pcr_s_w': 5.29205286937656}, 'MSE': {'pcr': 4.818117062734732, 'pcr_scale': 4.75024134431228, 'pcr_whiten': 4.8157507763355065, 'pcr_s_w': 4.730200842390617}, 'R2': {'pcr': 0.9919831849243886, 'pcr_scale': 0.992096122629229, 'pcr_whiten': 0.9919871221638188, 'pcr_s_w': 0.992129467812801}}'\n",
      "pcr: {'fold_0': 3.184616052064113, 'fold_1': 3.4499094696411503, 'fold_2': 3.016448947155719, 'fold_3': 3.5451027822375933, 'fold_4': 10.896007417522021, 'MSE': 4.818117062734732, 'R2': 0.9919831849243886}'\n",
      "pcr_scale: {'fold_0': 4.4403617024547, 'fold_1': 4.860421407823831, 'fold_2': 4.313105973475846, 'fold_3': 4.818393321155686, 'fold_4': 5.319024066690468, 'MSE': 4.75024134431228, 'R2': 0.992096122629229}'\n",
      "pcr_whiten: {'fold_0': 3.185936456482598, 'fold_1': 3.449863248055303, 'fold_2': 3.0160133560063342, 'fold_3': 3.544835235650066, 'fold_4': 10.883601940052728, 'MSE': 4.8157507763355065, 'R2': 0.9919871221638188}'\n",
      "pcr_s_w: {'fold_0': 4.440806250106012, 'fold_1': 4.831956084545378, 'fold_2': 4.29739809190006, 'fold_3': 4.788884641974189, 'fold_4': 5.29205286937656, 'MSE': 4.730200842390617, 'R2': 0.992129467812801}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 43 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0563,pcr_scale:4.4748,pcr_whiten:3.0558,pcr_s_w:4.4447'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.1587,pcr_scale:4.448,pcr_whiten:3.1578,pcr_s_w:4.4633'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2453,pcr_scale:4.4757,pcr_whiten:3.2453,pcr_s_w:4.5062'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4481,pcr_scale:4.8934,pcr_whiten:3.4479,pcr_s_w:4.8296'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3343,pcr_scale:4.5145,pcr_whiten:3.3344,pcr_s_w:4.516'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.0169,pcr_scale:4.2699,pcr_whiten:3.0172,pcr_s_w:4.3064'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3367,pcr_scale:4.6054,pcr_whiten:3.3368,pcr_s_w:4.5664'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.5518,pcr_scale:4.8103,pcr_whiten:3.5515,pcr_s_w:4.7724'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9966,pcr_scale:4.4189,pcr_whiten:2.9969,pcr_s_w:4.3631'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:11.5527,pcr_scale:5.2991,pcr_whiten:11.5347,pcr_s_w:5.3132'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.235,pcr_scale:4.4627,pcr_whiten:3.235,pcr_s_w:4.4311'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0817,pcr_scale:4.715,pcr_whiten:3.0816,pcr_s_w:4.6965'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.1586746869813545, 'pcr_scale': 4.448048431417024, 'pcr_whiten': 3.1577653876815996, 'pcr_s_w': 4.4633044940663735}, 'fold_1': {'pcr': 3.448099789638711, 'pcr_scale': 4.893396520734282, 'pcr_whiten': 3.4479472911544047, 'pcr_s_w': 4.82963926852042}, 'fold_2': {'pcr': 3.0169491724792796, 'pcr_scale': 4.269936415082036, 'pcr_whiten': 3.017205014197832, 'pcr_s_w': 4.306393156244764}, 'fold_3': {'pcr': 3.551763741287025, 'pcr_scale': 4.81028504064458, 'pcr_whiten': 3.551531851147109, 'pcr_s_w': 4.772357722524106}, 'fold_4': {'pcr': 11.552732027657843, 'pcr_scale': 5.299136053331157, 'pcr_whiten': 11.534748736851569, 'pcr_s_w': 5.313206670582795}, 'MSE': {'pcr': 4.945315825948975, 'pcr_scale': 4.744145822242583, 'pcr_whiten': 4.941512252427679, 'pcr_s_w': 4.73696218240745}, 'R2': {'pcr': 0.9917715402197753, 'pcr_scale': 0.9921062649052645, 'pcr_whiten': 0.9917778689463608, 'pcr_s_w': 0.9921182176891795}}'\n",
      "pcr: {'fold_0': 3.1586746869813545, 'fold_1': 3.448099789638711, 'fold_2': 3.0169491724792796, 'fold_3': 3.551763741287025, 'fold_4': 11.552732027657843, 'MSE': 4.945315825948975, 'R2': 0.9917715402197753}'\n",
      "pcr_scale: {'fold_0': 4.448048431417024, 'fold_1': 4.893396520734282, 'fold_2': 4.269936415082036, 'fold_3': 4.81028504064458, 'fold_4': 5.299136053331157, 'MSE': 4.744145822242583, 'R2': 0.9921062649052645}'\n",
      "pcr_whiten: {'fold_0': 3.1577653876815996, 'fold_1': 3.4479472911544047, 'fold_2': 3.017205014197832, 'fold_3': 3.551531851147109, 'fold_4': 11.534748736851569, 'MSE': 4.941512252427679, 'R2': 0.9917778689463608}'\n",
      "pcr_s_w: {'fold_0': 4.4633044940663735, 'fold_1': 4.82963926852042, 'fold_2': 4.306393156244764, 'fold_3': 4.772357722524106, 'fold_4': 5.313206670582795, 'MSE': 4.73696218240745, 'R2': 0.9921182176891795}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 44 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0397,pcr_scale:4.4364,pcr_whiten:3.0399,pcr_s_w:4.4457'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.129,pcr_scale:4.4201,pcr_whiten:3.1298,pcr_s_w:4.4548'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2444,pcr_scale:4.4665,pcr_whiten:3.2446,pcr_s_w:4.497'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4502,pcr_scale:4.8525,pcr_whiten:3.4501,pcr_s_w:4.8341'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3338,pcr_scale:4.4865,pcr_whiten:3.3338,pcr_s_w:4.5119'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.0149,pcr_scale:4.247,pcr_whiten:3.015,pcr_s_w:4.3126'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3337,pcr_scale:4.5592,pcr_whiten:3.3337,pcr_s_w:4.5783'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.5545,pcr_scale:4.7731,pcr_whiten:3.5541,pcr_s_w:4.7617'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.979,pcr_scale:4.4091,pcr_whiten:2.9781,pcr_s_w:4.3757'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.1964,pcr_scale:5.2984,pcr_whiten:12.2075,pcr_s_w:5.3344'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.2326,pcr_scale:4.4958,pcr_whiten:3.2326,pcr_s_w:4.4558'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0787,pcr_scale:4.7893,pcr_whiten:3.0788,pcr_s_w:4.7607'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.12897796428632, 'pcr_scale': 4.42006192945981, 'pcr_whiten': 3.1298156626103757, 'pcr_s_w': 4.4547804623751786}, 'fold_1': {'pcr': 3.4501562580790877, 'pcr_scale': 4.852511670124912, 'pcr_whiten': 3.450074257150369, 'pcr_s_w': 4.834115173999018}, 'fold_2': {'pcr': 3.0149445031681954, 'pcr_scale': 4.247007630743949, 'pcr_whiten': 3.015039800591177, 'pcr_s_w': 4.312562648493571}, 'fold_3': {'pcr': 3.554486018964996, 'pcr_scale': 4.773090730165824, 'pcr_whiten': 3.5540946809048295, 'pcr_s_w': 4.761719399873846}, 'fold_4': {'pcr': 12.196434136718484, 'pcr_scale': 5.298427220151642, 'pcr_whiten': 12.207464327992572, 'pcr_s_w': 5.334357735763151}, 'MSE': {'pcr': 5.068644316262382, 'pcr_scale': 4.71820346916232, 'pcr_whiten': 5.0709419023049245, 'pcr_s_w': 4.739488095034649}, 'R2': {'pcr': 0.9915663352221541, 'pcr_scale': 0.9921494301178492, 'pcr_whiten': 0.9915625122925359, 'pcr_s_w': 0.992114014849322}}'\n",
      "pcr: {'fold_0': 3.12897796428632, 'fold_1': 3.4501562580790877, 'fold_2': 3.0149445031681954, 'fold_3': 3.554486018964996, 'fold_4': 12.196434136718484, 'MSE': 5.068644316262382, 'R2': 0.9915663352221541}'\n",
      "pcr_scale: {'fold_0': 4.42006192945981, 'fold_1': 4.852511670124912, 'fold_2': 4.247007630743949, 'fold_3': 4.773090730165824, 'fold_4': 5.298427220151642, 'MSE': 4.71820346916232, 'R2': 0.9921494301178492}'\n",
      "pcr_whiten: {'fold_0': 3.1298156626103757, 'fold_1': 3.450074257150369, 'fold_2': 3.015039800591177, 'fold_3': 3.5540946809048295, 'fold_4': 12.207464327992572, 'MSE': 5.0709419023049245, 'R2': 0.9915625122925359}'\n",
      "pcr_s_w: {'fold_0': 4.4547804623751786, 'fold_1': 4.834115173999018, 'fold_2': 4.312562648493571, 'fold_3': 4.761719399873846, 'fold_4': 5.334357735763151, 'MSE': 4.739488095034649, 'R2': 0.992114014849322}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 45 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0398,pcr_scale:4.4424,pcr_whiten:3.0398,pcr_s_w:4.4546'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.1298,pcr_scale:4.4442,pcr_whiten:3.1306,pcr_s_w:4.4541'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2402,pcr_scale:4.4584,pcr_whiten:3.2403,pcr_s_w:4.4509'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4345,pcr_scale:4.8385,pcr_whiten:3.4346,pcr_s_w:4.8134'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3336,pcr_scale:4.5129,pcr_whiten:3.3337,pcr_s_w:4.5265'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.0144,pcr_scale:4.2628,pcr_whiten:3.0156,pcr_s_w:4.2818'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3331,pcr_scale:4.585,pcr_whiten:3.3333,pcr_s_w:4.5505'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.5531,pcr_scale:4.7969,pcr_whiten:3.5531,pcr_s_w:4.7661'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9778,pcr_scale:4.3466,pcr_whiten:2.9777,pcr_s_w:4.3783'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.2619,pcr_scale:5.2751,pcr_whiten:12.2544,pcr_s_w:5.2912'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.2327,pcr_scale:4.484,pcr_whiten:3.2327,pcr_s_w:4.4607'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.079,pcr_scale:4.7245,pcr_whiten:3.079,pcr_s_w:4.7183'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.1298298341493282, 'pcr_scale': 4.444158432288752, 'pcr_whiten': 3.1305652130222783, 'pcr_s_w': 4.454106326957424}, 'fold_1': {'pcr': 3.4344932824429364, 'pcr_scale': 4.838513994621884, 'pcr_whiten': 3.4346369629884452, 'pcr_s_w': 4.813359531686798}, 'fold_2': {'pcr': 3.01443919755424, 'pcr_scale': 4.262805734019838, 'pcr_whiten': 3.0156047826340044, 'pcr_s_w': 4.281750011096011}, 'fold_3': {'pcr': 3.5531000436244944, 'pcr_scale': 4.7968686451310845, 'pcr_whiten': 3.553093535269844, 'pcr_s_w': 4.766096083325637}, 'fold_4': {'pcr': 12.261943971802514, 'pcr_scale': 5.27508368594157, 'pcr_whiten': 12.254350194286843, 'pcr_s_w': 5.291202265785909}, 'MSE': {'pcr': 5.078402376640307, 'pcr_scale': 4.723469688115979, 'pcr_whiten': 5.077291558125774, 'pcr_s_w': 4.721285350779056}, 'R2': {'pcr': 0.9915500988865633, 'pcr_scale': 0.9921406677106785, 'pcr_whiten': 0.991551947165984, 'pcr_s_w': 0.9921443022069486}}'\n",
      "pcr: {'fold_0': 3.1298298341493282, 'fold_1': 3.4344932824429364, 'fold_2': 3.01443919755424, 'fold_3': 3.5531000436244944, 'fold_4': 12.261943971802514, 'MSE': 5.078402376640307, 'R2': 0.9915500988865633}'\n",
      "pcr_scale: {'fold_0': 4.444158432288752, 'fold_1': 4.838513994621884, 'fold_2': 4.262805734019838, 'fold_3': 4.7968686451310845, 'fold_4': 5.27508368594157, 'MSE': 4.723469688115979, 'R2': 0.9921406677106785}'\n",
      "pcr_whiten: {'fold_0': 3.1305652130222783, 'fold_1': 3.4346369629884452, 'fold_2': 3.0156047826340044, 'fold_3': 3.553093535269844, 'fold_4': 12.254350194286843, 'MSE': 5.077291558125774, 'R2': 0.991551947165984}'\n",
      "pcr_s_w: {'fold_0': 4.454106326957424, 'fold_1': 4.813359531686798, 'fold_2': 4.281750011096011, 'fold_3': 4.766096083325637, 'fold_4': 5.291202265785909, 'MSE': 4.721285350779056, 'R2': 0.9921443022069486}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 46 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0352,pcr_scale:4.4686,pcr_whiten:3.0353,pcr_s_w:4.4272'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.1334,pcr_scale:4.5011,pcr_whiten:3.1345,pcr_s_w:4.4066'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.238,pcr_scale:4.5038,pcr_whiten:3.2381,pcr_s_w:4.4692'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4377,pcr_scale:4.8444,pcr_whiten:3.4379,pcr_s_w:4.872'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3108,pcr_scale:4.5175,pcr_whiten:3.3109,pcr_s_w:4.5173'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.0164,pcr_scale:4.2705,pcr_whiten:3.0168,pcr_s_w:4.2851'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3211,pcr_scale:4.5703,pcr_whiten:3.3206,pcr_s_w:4.5699'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.5478,pcr_scale:4.8143,pcr_whiten:3.5479,pcr_s_w:4.7615'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9765,pcr_scale:4.3659,pcr_whiten:2.9777,pcr_s_w:4.3742'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.3168,pcr_scale:5.2784,pcr_whiten:12.2529,pcr_s_w:5.2655'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.2316,pcr_scale:4.445,pcr_whiten:3.2325,pcr_s_w:4.4573'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0811,pcr_scale:4.6983,pcr_whiten:3.0804,pcr_s_w:4.7337'\n",
      "Train times: {'fold_0': 5, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.133429366519955, 'pcr_scale': 4.501054063164411, 'pcr_whiten': 3.134512214996119, 'pcr_s_w': 4.406591532941189}, 'fold_1': {'pcr': 3.4377087539629603, 'pcr_scale': 4.844368305642887, 'pcr_whiten': 3.437921199521252, 'pcr_s_w': 4.871994444711097}, 'fold_2': {'pcr': 3.0164206724122478, 'pcr_scale': 4.270492693467381, 'pcr_whiten': 3.016791189792611, 'pcr_s_w': 4.285132518243832}, 'fold_3': {'pcr': 3.5478114387268063, 'pcr_scale': 4.814277551028795, 'pcr_whiten': 3.5478716366941, 'pcr_s_w': 4.761468757639942}, 'fold_4': {'pcr': 12.31680198945617, 'pcr_scale': 5.278416516123412, 'pcr_whiten': 12.252859872014096, 'pcr_s_w': 5.265509317580854}, 'MSE': {'pcr': 5.0900739037873475, 'pcr_scale': 4.741708040299784, 'pcr_whiten': 5.077633297211037, 'pcr_s_w': 4.71812356385874}, 'R2': {'pcr': 0.9915306787534346, 'pcr_scale': 0.9921103211053891, 'pcr_whiten': 0.9915513785498596, 'pcr_s_w': 0.9921495630714562}}'\n",
      "pcr: {'fold_0': 3.133429366519955, 'fold_1': 3.4377087539629603, 'fold_2': 3.0164206724122478, 'fold_3': 3.5478114387268063, 'fold_4': 12.31680198945617, 'MSE': 5.0900739037873475, 'R2': 0.9915306787534346}'\n",
      "pcr_scale: {'fold_0': 4.501054063164411, 'fold_1': 4.844368305642887, 'fold_2': 4.270492693467381, 'fold_3': 4.814277551028795, 'fold_4': 5.278416516123412, 'MSE': 4.741708040299784, 'R2': 0.9921103211053891}'\n",
      "pcr_whiten: {'fold_0': 3.134512214996119, 'fold_1': 3.437921199521252, 'fold_2': 3.016791189792611, 'fold_3': 3.5478716366941, 'fold_4': 12.252859872014096, 'MSE': 5.077633297211037, 'R2': 0.9915513785498596}'\n",
      "pcr_s_w: {'fold_0': 4.406591532941189, 'fold_1': 4.871994444711097, 'fold_2': 4.285132518243832, 'fold_3': 4.761468757639942, 'fold_4': 5.265509317580854, 'MSE': 4.71812356385874, 'R2': 0.9921495630714562}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 47 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0274,pcr_scale:4.4381,pcr_whiten:3.027,pcr_s_w:4.4434'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.1301,pcr_scale:4.4509,pcr_whiten:3.1289,pcr_s_w:4.4272'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2183,pcr_scale:4.4633,pcr_whiten:3.2182,pcr_s_w:4.4394'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4195,pcr_scale:4.846,pcr_whiten:3.4184,pcr_s_w:4.8329'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3053,pcr_scale:4.5224,pcr_whiten:3.3054,pcr_s_w:4.5344'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.0058,pcr_scale:4.3056,pcr_whiten:3.0061,pcr_s_w:4.3194'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.3097,pcr_scale:4.5863,pcr_whiten:3.3105,pcr_s_w:4.5743'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.5158,pcr_scale:4.8132,pcr_whiten:3.5162,pcr_s_w:4.7644'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.974,pcr_scale:4.3582,pcr_whiten:2.974,pcr_s_w:4.3563'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.4468,pcr_scale:5.3061,pcr_whiten:12.4482,pcr_s_w:5.3281'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.2182,pcr_scale:4.4711,pcr_whiten:3.2201,pcr_s_w:4.4727'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0642,pcr_scale:4.7205,pcr_whiten:3.0657,pcr_s_w:4.7366'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.1301364924990804, 'pcr_scale': 4.450878487275942, 'pcr_whiten': 3.128943610949237, 'pcr_s_w': 4.427155968534854}, 'fold_1': {'pcr': 3.4194934545562843, 'pcr_scale': 4.84602557723805, 'pcr_whiten': 3.4184261275886754, 'pcr_s_w': 4.8328812305677555}, 'fold_2': {'pcr': 3.0058161150269473, 'pcr_scale': 4.305577491280012, 'pcr_whiten': 3.0061303864649807, 'pcr_s_w': 4.319390100400569}, 'fold_3': {'pcr': 3.5157733720688404, 'pcr_scale': 4.813219219534952, 'pcr_whiten': 3.51618235451832, 'pcr_s_w': 4.764433750873827}, 'fold_4': {'pcr': 12.446813809229143, 'pcr_scale': 5.306116193315596, 'pcr_whiten': 12.448219210812027, 'pcr_s_w': 5.328115264606815}, 'MSE': {'pcr': 5.1032413287249705, 'pcr_scale': 4.744344234447753, 'pcr_whiten': 5.103214797621422, 'pcr_s_w': 4.734374412684449}, 'R2': {'pcr': 0.9915087696114664, 'pcr_scale': 0.9921059347692515, 'pcr_whiten': 0.9915088137562948, 'pcr_s_w': 0.992122523452418}}'\n",
      "pcr: {'fold_0': 3.1301364924990804, 'fold_1': 3.4194934545562843, 'fold_2': 3.0058161150269473, 'fold_3': 3.5157733720688404, 'fold_4': 12.446813809229143, 'MSE': 5.1032413287249705, 'R2': 0.9915087696114664}'\n",
      "pcr_scale: {'fold_0': 4.450878487275942, 'fold_1': 4.84602557723805, 'fold_2': 4.305577491280012, 'fold_3': 4.813219219534952, 'fold_4': 5.306116193315596, 'MSE': 4.744344234447753, 'R2': 0.9921059347692515}'\n",
      "pcr_whiten: {'fold_0': 3.128943610949237, 'fold_1': 3.4184261275886754, 'fold_2': 3.0061303864649807, 'fold_3': 3.51618235451832, 'fold_4': 12.448219210812027, 'MSE': 5.103214797621422, 'R2': 0.9915088137562948}'\n",
      "pcr_s_w: {'fold_0': 4.427155968534854, 'fold_1': 4.8328812305677555, 'fold_2': 4.319390100400569, 'fold_3': 4.764433750873827, 'fold_4': 5.328115264606815, 'MSE': 4.734374412684449, 'R2': 0.992122523452418}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 48 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0145,pcr_scale:4.4428,pcr_whiten:3.0143,pcr_s_w:4.3833'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.1016,pcr_scale:4.4152,pcr_whiten:3.1016,pcr_s_w:4.4304'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.203,pcr_scale:4.4337,pcr_whiten:3.2039,pcr_s_w:4.469'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4328,pcr_scale:4.8255,pcr_whiten:3.4336,pcr_s_w:4.8638'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2895,pcr_scale:4.5064,pcr_whiten:3.289,pcr_s_w:4.5186'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9952,pcr_scale:4.2759,pcr_whiten:2.9943,pcr_s_w:4.263'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2945,pcr_scale:4.575,pcr_whiten:3.2939,pcr_s_w:4.5495'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4951,pcr_scale:4.7956,pcr_whiten:3.4944,pcr_s_w:4.7566'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9734,pcr_scale:4.3129,pcr_whiten:2.9733,pcr_s_w:4.3569'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.441,pcr_scale:5.2799,pcr_whiten:12.4469,pcr_s_w:5.2778'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.1997,pcr_scale:4.4423,pcr_whiten:3.1987,pcr_s_w:4.4626'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0524,pcr_scale:4.6798,pcr_whiten:3.0518,pcr_s_w:4.7403'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.1015884350906777, 'pcr_scale': 4.415187209812081, 'pcr_whiten': 3.101621709813745, 'pcr_s_w': 4.430421819414225}, 'fold_1': {'pcr': 3.432769267253811, 'pcr_scale': 4.825459671534759, 'pcr_whiten': 3.4335620515277463, 'pcr_s_w': 4.863757174859581}, 'fold_2': {'pcr': 2.99521718986236, 'pcr_scale': 4.275916622558766, 'pcr_whiten': 2.9942930536884553, 'pcr_s_w': 4.262998260732709}, 'fold_3': {'pcr': 3.4950943295711276, 'pcr_scale': 4.795616003755508, 'pcr_whiten': 3.494391168413112, 'pcr_s_w': 4.756602820085168}, 'fold_4': {'pcr': 12.4409663614569, 'pcr_scale': 5.279901786494402, 'pcr_whiten': 12.446861287496798, 'pcr_s_w': 5.277790583315749}, 'MSE': {'pcr': 5.092762364696221, 'pcr_scale': 4.718396663781531, 'pcr_whiten': 5.093780981240805, 'pcr_s_w': 4.718299903828002}, 'R2': {'pcr': 0.9915262054511749, 'pcr_scale': 0.9921491086633233, 'pcr_whiten': 0.9915245105856569, 'pcr_s_w': 0.9921492696612078}}'\n",
      "pcr: {'fold_0': 3.1015884350906777, 'fold_1': 3.432769267253811, 'fold_2': 2.99521718986236, 'fold_3': 3.4950943295711276, 'fold_4': 12.4409663614569, 'MSE': 5.092762364696221, 'R2': 0.9915262054511749}'\n",
      "pcr_scale: {'fold_0': 4.415187209812081, 'fold_1': 4.825459671534759, 'fold_2': 4.275916622558766, 'fold_3': 4.795616003755508, 'fold_4': 5.279901786494402, 'MSE': 4.718396663781531, 'R2': 0.9921491086633233}'\n",
      "pcr_whiten: {'fold_0': 3.101621709813745, 'fold_1': 3.4335620515277463, 'fold_2': 2.9942930536884553, 'fold_3': 3.494391168413112, 'fold_4': 12.446861287496798, 'MSE': 5.093780981240805, 'R2': 0.9915245105856569}'\n",
      "pcr_s_w: {'fold_0': 4.430421819414225, 'fold_1': 4.863757174859581, 'fold_2': 4.262998260732709, 'fold_3': 4.756602820085168, 'fold_4': 5.277790583315749, 'MSE': 4.718299903828002, 'R2': 0.9921492696612078}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 49 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0112,pcr_scale:4.4427,pcr_whiten:3.0097,pcr_s_w:4.4112'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.1028,pcr_scale:4.466,pcr_whiten:3.1003,pcr_s_w:4.4309'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2029,pcr_scale:4.4811,pcr_whiten:3.2019,pcr_s_w:4.4441'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4269,pcr_scale:4.8688,pcr_whiten:3.4277,pcr_s_w:4.8337'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2828,pcr_scale:4.4964,pcr_whiten:3.283,pcr_s_w:4.5133'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9865,pcr_scale:4.2388,pcr_whiten:2.986,pcr_s_w:4.2771'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2929,pcr_scale:4.558,pcr_whiten:3.2918,pcr_s_w:4.5202'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4943,pcr_scale:4.7553,pcr_whiten:3.4931,pcr_s_w:4.7298'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9491,pcr_scale:4.3168,pcr_whiten:2.949,pcr_s_w:4.337'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.3471,pcr_scale:5.3068,pcr_whiten:12.3403,pcr_s_w:5.2644'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.1896,pcr_scale:4.4572,pcr_whiten:3.1883,pcr_s_w:4.4248'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0491,pcr_scale:4.7679,pcr_whiten:3.0509,pcr_s_w:4.7142'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.1028117473524643, 'pcr_scale': 4.46600467270784, 'pcr_whiten': 3.100349487214063, 'pcr_s_w': 4.430893653206028}, 'fold_1': {'pcr': 3.426933300711931, 'pcr_scale': 4.8688210755739805, 'pcr_whiten': 3.427667637441132, 'pcr_s_w': 4.833664977275076}, 'fold_2': {'pcr': 2.9865319294833386, 'pcr_scale': 4.238768233475156, 'pcr_whiten': 2.986034355303306, 'pcr_s_w': 4.277138934219083}, 'fold_3': {'pcr': 3.494328867246279, 'pcr_scale': 4.755290685701073, 'pcr_whiten': 3.4931010902970234, 'pcr_s_w': 4.729764683983076}, 'fold_4': {'pcr': 12.347088996369909, 'pcr_scale': 5.30677281177441, 'pcr_whiten': 12.340279271355154, 'pcr_s_w': 5.264447172171945}, 'MSE': {'pcr': 5.071178068024195, 'pcr_scale': 4.727119566437442, 'pcr_whiten': 5.069125705556256, 'pcr_s_w': 4.707166921612327}, 'R2': {'pcr': 0.9915621193388418, 'pcr_scale': 0.9921345947159442, 'pcr_whiten': 0.9915655342434941, 'pcr_s_w': 0.9921677937150033}}'\n",
      "pcr: {'fold_0': 3.1028117473524643, 'fold_1': 3.426933300711931, 'fold_2': 2.9865319294833386, 'fold_3': 3.494328867246279, 'fold_4': 12.347088996369909, 'MSE': 5.071178068024195, 'R2': 0.9915621193388418}'\n",
      "pcr_scale: {'fold_0': 4.46600467270784, 'fold_1': 4.8688210755739805, 'fold_2': 4.238768233475156, 'fold_3': 4.755290685701073, 'fold_4': 5.30677281177441, 'MSE': 4.727119566437442, 'R2': 0.9921345947159442}'\n",
      "pcr_whiten: {'fold_0': 3.100349487214063, 'fold_1': 3.427667637441132, 'fold_2': 2.986034355303306, 'fold_3': 3.4931010902970234, 'fold_4': 12.340279271355154, 'MSE': 5.069125705556256, 'R2': 0.9915655342434941}'\n",
      "pcr_s_w: {'fold_0': 4.430893653206028, 'fold_1': 4.833664977275076, 'fold_2': 4.277138934219083, 'fold_3': 4.729764683983076, 'fold_4': 5.264447172171945, 'MSE': 4.707166921612327, 'R2': 0.9921677937150033}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 50 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0044,pcr_scale:4.4306,pcr_whiten:3.0049,pcr_s_w:4.4524'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0998,pcr_scale:4.4323,pcr_whiten:3.1006,pcr_s_w:4.4267'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1915,pcr_scale:4.3893,pcr_whiten:3.1925,pcr_s_w:4.4587'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4034,pcr_scale:4.8164,pcr_whiten:3.4054,pcr_s_w:4.853'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.278,pcr_scale:4.4941,pcr_whiten:3.2784,pcr_s_w:4.484'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9894,pcr_scale:4.2614,pcr_whiten:2.9893,pcr_s_w:4.243'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2918,pcr_scale:4.5421,pcr_whiten:3.2917,pcr_s_w:4.5421'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4925,pcr_scale:4.7564,pcr_whiten:3.4923,pcr_s_w:4.7433'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9471,pcr_scale:4.3376,pcr_whiten:2.9474,pcr_s_w:4.3488'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.3269,pcr_scale:5.2266,pcr_whiten:12.3129,pcr_s_w:5.298'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.1878,pcr_scale:4.4438,pcr_whiten:3.1868,pcr_s_w:4.4611'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0486,pcr_scale:4.6664,pcr_whiten:3.0475,pcr_s_w:4.7251'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.099792192710219, 'pcr_scale': 4.432296987097908, 'pcr_whiten': 3.1006094821734376, 'pcr_s_w': 4.426746102374924}, 'fold_1': {'pcr': 3.403384090400223, 'pcr_scale': 4.8164158627454166, 'pcr_whiten': 3.405441863232236, 'pcr_s_w': 4.853017952300515}, 'fold_2': {'pcr': 2.989371053020288, 'pcr_scale': 4.2613522197895, 'pcr_whiten': 2.9893017910345816, 'pcr_s_w': 4.2430253745917454}, 'fold_3': {'pcr': 3.492489154368792, 'pcr_scale': 4.756436843528739, 'pcr_whiten': 3.4922538624176083, 'pcr_s_w': 4.7432655250937055}, 'fold_4': {'pcr': 12.326892667130963, 'pcr_scale': 5.226582002154579, 'pcr_whiten': 12.312867103063514, 'pcr_s_w': 5.298002264433633}, 'MSE': {'pcr': 5.062024106058664, 'pcr_scale': 4.698601948792724, 'pcr_whiten': 5.059733839731522, 'pcr_s_w': 4.712796875357701}, 'R2': {'pcr': 0.9915773505213413, 'pcr_scale': 0.9921820448845636, 'pcr_whiten': 0.9915811612717609, 'pcr_s_w': 0.9921584260932803}}'\n",
      "pcr: {'fold_0': 3.099792192710219, 'fold_1': 3.403384090400223, 'fold_2': 2.989371053020288, 'fold_3': 3.492489154368792, 'fold_4': 12.326892667130963, 'MSE': 5.062024106058664, 'R2': 0.9915773505213413}'\n",
      "pcr_scale: {'fold_0': 4.432296987097908, 'fold_1': 4.8164158627454166, 'fold_2': 4.2613522197895, 'fold_3': 4.756436843528739, 'fold_4': 5.226582002154579, 'MSE': 4.698601948792724, 'R2': 0.9921820448845636}'\n",
      "pcr_whiten: {'fold_0': 3.1006094821734376, 'fold_1': 3.405441863232236, 'fold_2': 2.9893017910345816, 'fold_3': 3.4922538624176083, 'fold_4': 12.312867103063514, 'MSE': 5.059733839731522, 'R2': 0.9915811612717609}'\n",
      "pcr_s_w: {'fold_0': 4.426746102374924, 'fold_1': 4.853017952300515, 'fold_2': 4.2430253745917454, 'fold_3': 4.7432655250937055, 'fold_4': 5.298002264433633, 'MSE': 4.712796875357701, 'R2': 0.9921584260932803}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 51 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0042,pcr_scale:4.4103,pcr_whiten:3.0039,pcr_s_w:4.4035'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0971,pcr_scale:4.4138,pcr_whiten:3.0971,pcr_s_w:4.4093'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1914,pcr_scale:4.4591,pcr_whiten:3.1917,pcr_s_w:4.4005'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4053,pcr_scale:4.8559,pcr_whiten:3.4056,pcr_s_w:4.8098'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2757,pcr_scale:4.5108,pcr_whiten:3.2743,pcr_s_w:4.5171'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9849,pcr_scale:4.2981,pcr_whiten:2.9844,pcr_s_w:4.2716'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2862,pcr_scale:4.5373,pcr_whiten:3.2879,pcr_s_w:4.5636'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4873,pcr_scale:4.7943,pcr_whiten:3.4875,pcr_s_w:4.7852'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9468,pcr_scale:4.3166,pcr_whiten:2.9473,pcr_s_w:4.3282'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.3554,pcr_scale:5.2468,pcr_whiten:12.378,pcr_s_w:5.2389'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.1865,pcr_scale:4.4486,pcr_whiten:3.1864,pcr_s_w:4.4393'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0503,pcr_scale:4.7493,pcr_whiten:3.0506,pcr_s_w:4.7184'\n",
      "Train times: {'fold_0': 3, 'fold_1': 4, 'fold_2': 3, 'fold_3': 4, 'fold_4': 4, 'mean': 3.6}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.097107931656047, 'pcr_scale': 4.413818499903005, 'pcr_whiten': 3.0970586448285173, 'pcr_s_w': 4.409335590497614}, 'fold_1': {'pcr': 3.405339049728547, 'pcr_scale': 4.855900490772727, 'pcr_whiten': 3.405597156585685, 'pcr_s_w': 4.809751914356637}, 'fold_2': {'pcr': 2.9848965782152015, 'pcr_scale': 4.298098080227657, 'pcr_whiten': 2.9844041427559382, 'pcr_s_w': 4.271554974836034}, 'fold_3': {'pcr': 3.48727015092319, 'pcr_scale': 4.794305086631502, 'pcr_whiten': 3.4875110549513453, 'pcr_s_w': 4.7852466118070085}, 'fold_4': {'pcr': 12.355403993904526, 'pcr_scale': 5.246755598523549, 'pcr_whiten': 12.377998412721261, 'pcr_s_w': 5.238885776517729}, 'MSE': {'pcr': 5.065641019900645, 'pcr_scale': 4.7217581888353655, 'pcr_whiten': 5.070150481253555, 'pcr_s_w': 4.702936313750593}, 'R2': {'pcr': 0.9915713323758629, 'pcr_scale': 0.9921435154566043, 'pcr_whiten': 0.9915638291298259, 'pcr_s_w': 0.9921748329796046}}'\n",
      "pcr: {'fold_0': 3.097107931656047, 'fold_1': 3.405339049728547, 'fold_2': 2.9848965782152015, 'fold_3': 3.48727015092319, 'fold_4': 12.355403993904526, 'MSE': 5.065641019900645, 'R2': 0.9915713323758629}'\n",
      "pcr_scale: {'fold_0': 4.413818499903005, 'fold_1': 4.855900490772727, 'fold_2': 4.298098080227657, 'fold_3': 4.794305086631502, 'fold_4': 5.246755598523549, 'MSE': 4.7217581888353655, 'R2': 0.9921435154566043}'\n",
      "pcr_whiten: {'fold_0': 3.0970586448285173, 'fold_1': 3.405597156585685, 'fold_2': 2.9844041427559382, 'fold_3': 3.4875110549513453, 'fold_4': 12.377998412721261, 'MSE': 5.070150481253555, 'R2': 0.9915638291298259}'\n",
      "pcr_s_w: {'fold_0': 4.409335590497614, 'fold_1': 4.809751914356637, 'fold_2': 4.271554974836034, 'fold_3': 4.7852466118070085, 'fold_4': 5.238885776517729, 'MSE': 4.702936313750593, 'R2': 0.9921748329796046}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 52 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0037,pcr_scale:4.4159,pcr_whiten:3.0035,pcr_s_w:4.3846'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0947,pcr_scale:4.4323,pcr_whiten:3.0946,pcr_s_w:4.4385'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1916,pcr_scale:4.4303,pcr_whiten:3.1915,pcr_s_w:4.4068'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4048,pcr_scale:4.8563,pcr_whiten:3.4059,pcr_s_w:4.8529'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2697,pcr_scale:4.5029,pcr_whiten:3.2713,pcr_s_w:4.4989'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9932,pcr_scale:4.2823,pcr_whiten:2.9916,pcr_s_w:4.2594'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2651,pcr_scale:4.5413,pcr_whiten:3.2736,pcr_s_w:4.5365'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4729,pcr_scale:4.7664,pcr_whiten:3.4766,pcr_s_w:4.7787'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9444,pcr_scale:4.3004,pcr_whiten:2.9447,pcr_s_w:4.3138'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.5611,pcr_scale:5.2148,pcr_whiten:12.5141,pcr_s_w:5.2949'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.1858,pcr_scale:4.4402,pcr_whiten:3.1851,pcr_s_w:4.4054'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0448,pcr_scale:4.7283,pcr_whiten:3.0444,pcr_s_w:4.6438'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.094688649022361, 'pcr_scale': 4.432330565442626, 'pcr_whiten': 3.0945512294864654, 'pcr_s_w': 4.438458673866586}, 'fold_1': {'pcr': 3.4048459647998097, 'pcr_scale': 4.856311213862186, 'pcr_whiten': 3.405911698083394, 'pcr_s_w': 4.852874817625478}, 'fold_2': {'pcr': 2.993181456966448, 'pcr_scale': 4.282306718045453, 'pcr_whiten': 2.9916250472803982, 'pcr_s_w': 4.2594499615224635}, 'fold_3': {'pcr': 3.472920383112924, 'pcr_scale': 4.766370175147668, 'pcr_whiten': 3.4766149825101413, 'pcr_s_w': 4.778689976276093}, 'fold_4': {'pcr': 12.561146085682635, 'pcr_scale': 5.214761910990445, 'pcr_whiten': 12.514081845993308, 'pcr_s_w': 5.294879986206804}, 'MSE': {'pcr': 5.104985834884274, 'pcr_scale': 4.710402913496109, 'pcr_whiten': 5.096188138158379, 'pcr_s_w': 4.724854861298176}, 'R2': {'pcr': 0.9915058669457372, 'pcr_scale': 0.9921624093816256, 'pcr_whiten': 0.9915205053421947, 'pcr_s_w': 0.9921383629353681}}'\n",
      "pcr: {'fold_0': 3.094688649022361, 'fold_1': 3.4048459647998097, 'fold_2': 2.993181456966448, 'fold_3': 3.472920383112924, 'fold_4': 12.561146085682635, 'MSE': 5.104985834884274, 'R2': 0.9915058669457372}'\n",
      "pcr_scale: {'fold_0': 4.432330565442626, 'fold_1': 4.856311213862186, 'fold_2': 4.282306718045453, 'fold_3': 4.766370175147668, 'fold_4': 5.214761910990445, 'MSE': 4.710402913496109, 'R2': 0.9921624093816256}'\n",
      "pcr_whiten: {'fold_0': 3.0945512294864654, 'fold_1': 3.405911698083394, 'fold_2': 2.9916250472803982, 'fold_3': 3.4766149825101413, 'fold_4': 12.514081845993308, 'MSE': 5.096188138158379, 'R2': 0.9915205053421947}'\n",
      "pcr_s_w: {'fold_0': 4.438458673866586, 'fold_1': 4.852874817625478, 'fold_2': 4.2594499615224635, 'fold_3': 4.778689976276093, 'fold_4': 5.294879986206804, 'MSE': 4.724854861298176, 'R2': 0.9921383629353681}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 53 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.002,pcr_scale:4.4179,pcr_whiten:3.0019,pcr_s_w:4.3942'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.094,pcr_scale:4.3996,pcr_whiten:3.0932,pcr_s_w:4.4474'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1872,pcr_scale:4.4458,pcr_whiten:3.1885,pcr_s_w:4.4063'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3961,pcr_scale:4.8657,pcr_whiten:3.3975,pcr_s_w:4.8481'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2692,pcr_scale:4.5174,pcr_whiten:3.2676,pcr_s_w:4.4922'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9826,pcr_scale:4.2904,pcr_whiten:2.9823,pcr_s_w:4.2657'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2483,pcr_scale:4.528,pcr_whiten:3.245,pcr_s_w:4.5266'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4658,pcr_scale:4.7259,pcr_whiten:3.4589,pcr_s_w:4.7321'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9442,pcr_scale:4.3264,pcr_whiten:2.9443,pcr_s_w:4.3216'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.5375,pcr_scale:5.2641,pcr_whiten:12.5188,pcr_s_w:5.2515'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.1853,pcr_scale:4.4352,pcr_whiten:3.1852,pcr_s_w:4.4034'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.045,pcr_scale:4.728,pcr_whiten:3.0475,pcr_s_w:4.7135'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.094017185898883, 'pcr_scale': 4.399624423472698, 'pcr_whiten': 3.0931758874524666, 'pcr_s_w': 4.447413790211579}, 'fold_1': {'pcr': 3.3961018999816335, 'pcr_scale': 4.865660500697153, 'pcr_whiten': 3.397537939489288, 'pcr_s_w': 4.848131648931552}, 'fold_2': {'pcr': 2.9826160517437335, 'pcr_scale': 4.290412217853389, 'pcr_whiten': 2.9823410962252512, 'pcr_s_w': 4.265734287667255}, 'fold_3': {'pcr': 3.465849176819544, 'pcr_scale': 4.725880038113956, 'pcr_whiten': 3.458911847648364, 'pcr_s_w': 4.732123046260573}, 'fold_4': {'pcr': 12.53747218590959, 'pcr_scale': 5.264111745415155, 'pcr_whiten': 12.518778425857947, 'pcr_s_w': 5.251520019139201}, 'MSE': {'pcr': 5.094841713223467, 'pcr_scale': 4.709122504382739, 'pcr_whiten': 5.089780523128937, 'pcr_s_w': 4.708972330747491}, 'R2': {'pcr': 0.9915227456446979, 'pcr_scale': 0.9921645398410871, 'pcr_whiten': 0.9915311669064734, 'pcr_s_w': 0.9921647897134434}}'\n",
      "pcr: {'fold_0': 3.094017185898883, 'fold_1': 3.3961018999816335, 'fold_2': 2.9826160517437335, 'fold_3': 3.465849176819544, 'fold_4': 12.53747218590959, 'MSE': 5.094841713223467, 'R2': 0.9915227456446979}'\n",
      "pcr_scale: {'fold_0': 4.399624423472698, 'fold_1': 4.865660500697153, 'fold_2': 4.290412217853389, 'fold_3': 4.725880038113956, 'fold_4': 5.264111745415155, 'MSE': 4.709122504382739, 'R2': 0.9921645398410871}'\n",
      "pcr_whiten: {'fold_0': 3.0931758874524666, 'fold_1': 3.397537939489288, 'fold_2': 2.9823410962252512, 'fold_3': 3.458911847648364, 'fold_4': 12.518778425857947, 'MSE': 5.089780523128937, 'R2': 0.9915311669064734}'\n",
      "pcr_s_w: {'fold_0': 4.447413790211579, 'fold_1': 4.848131648931552, 'fold_2': 4.265734287667255, 'fold_3': 4.732123046260573, 'fold_4': 5.251520019139201, 'MSE': 4.708972330747491, 'R2': 0.9921647897134434}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 54 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9949,pcr_scale:4.4378,pcr_whiten:2.9953,pcr_s_w:4.406'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.087,pcr_scale:4.3987,pcr_whiten:3.0861,pcr_s_w:4.4215'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1831,pcr_scale:4.4107,pcr_whiten:3.1832,pcr_s_w:4.387'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3998,pcr_scale:4.8268,pcr_whiten:3.4013,pcr_s_w:4.809'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.265,pcr_scale:4.4925,pcr_whiten:3.2638,pcr_s_w:4.5201'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9851,pcr_scale:4.2702,pcr_whiten:2.9858,pcr_s_w:4.3193'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2424,pcr_scale:4.5358,pcr_whiten:3.2452,pcr_s_w:4.5284'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4546,pcr_scale:4.7593,pcr_whiten:3.455,pcr_s_w:4.7312'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9395,pcr_scale:4.29,pcr_whiten:2.9387,pcr_s_w:4.327'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.6757,pcr_scale:5.2814,pcr_whiten:12.7327,pcr_s_w:5.2808'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.1835,pcr_scale:4.4054,pcr_whiten:3.1837,pcr_s_w:4.4171'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0383,pcr_scale:4.7217,pcr_whiten:3.0385,pcr_s_w:4.6685'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.0870034887556614, 'pcr_scale': 4.398666355410989, 'pcr_whiten': 3.086132206555833, 'pcr_s_w': 4.421454927092567}, 'fold_1': {'pcr': 3.399760633635602, 'pcr_scale': 4.826764020511645, 'pcr_whiten': 3.4012717023316448, 'pcr_s_w': 4.809035696900574}, 'fold_2': {'pcr': 2.9851347316553554, 'pcr_scale': 4.2702222139864885, 'pcr_whiten': 2.9857770690085363, 'pcr_s_w': 4.319303377693797}, 'fold_3': {'pcr': 3.4545718908657537, 'pcr_scale': 4.759252753518414, 'pcr_whiten': 3.4549630062008885, 'pcr_s_w': 4.731205840561936}, 'fold_4': {'pcr': 12.675651089014474, 'pcr_scale': 5.281424189910337, 'pcr_whiten': 12.73274470264869, 'pcr_s_w': 5.280821030825843}, 'MSE': {'pcr': 5.120049408274466, 'pcr_scale': 4.7072470191888085, 'pcr_whiten': 5.131800494883496, 'pcr_s_w': 4.71234477412301}, 'R2': {'pcr': 0.9914808028219987, 'pcr_scale': 0.9921676604414754, 'pcr_whiten': 0.9914612503107053, 'pcr_s_w': 0.9921591783398419}}'\n",
      "pcr: {'fold_0': 3.0870034887556614, 'fold_1': 3.399760633635602, 'fold_2': 2.9851347316553554, 'fold_3': 3.4545718908657537, 'fold_4': 12.675651089014474, 'MSE': 5.120049408274466, 'R2': 0.9914808028219987}'\n",
      "pcr_scale: {'fold_0': 4.398666355410989, 'fold_1': 4.826764020511645, 'fold_2': 4.2702222139864885, 'fold_3': 4.759252753518414, 'fold_4': 5.281424189910337, 'MSE': 4.7072470191888085, 'R2': 0.9921676604414754}'\n",
      "pcr_whiten: {'fold_0': 3.086132206555833, 'fold_1': 3.4012717023316448, 'fold_2': 2.9857770690085363, 'fold_3': 3.4549630062008885, 'fold_4': 12.73274470264869, 'MSE': 5.131800494883496, 'R2': 0.9914612503107053}'\n",
      "pcr_s_w: {'fold_0': 4.421454927092567, 'fold_1': 4.809035696900574, 'fold_2': 4.319303377693797, 'fold_3': 4.731205840561936, 'fold_4': 5.280821030825843, 'MSE': 4.71234477412301, 'R2': 0.9921591783398419}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 55 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9936,pcr_scale:4.3718,pcr_whiten:2.9934,pcr_s_w:4.3858'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0877,pcr_scale:4.4171,pcr_whiten:3.0849,pcr_s_w:4.4217'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1816,pcr_scale:4.3954,pcr_whiten:3.1806,pcr_s_w:4.3986'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4048,pcr_scale:4.8221,pcr_whiten:3.4047,pcr_s_w:4.8106'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2616,pcr_scale:4.4898,pcr_whiten:3.264,pcr_s_w:4.4993'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.983,pcr_scale:4.2857,pcr_whiten:2.9842,pcr_s_w:4.3032'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2418,pcr_scale:4.5096,pcr_whiten:3.2441,pcr_s_w:4.5546'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4488,pcr_scale:4.7342,pcr_whiten:3.4495,pcr_s_w:4.7615'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9356,pcr_scale:4.2776,pcr_whiten:2.9372,pcr_s_w:4.311'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.5555,pcr_scale:5.2056,pcr_whiten:12.5663,pcr_s_w:5.259'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.1681,pcr_scale:4.3927,pcr_whiten:3.1626,pcr_s_w:4.3861'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0281,pcr_scale:4.6928,pcr_whiten:3.0282,pcr_s_w:4.6508'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.0877296606207323, 'pcr_scale': 4.417084923382192, 'pcr_whiten': 3.084937607131631, 'pcr_s_w': 4.4217070041084865}, 'fold_1': {'pcr': 3.4047779646794862, 'pcr_scale': 4.822147264159305, 'pcr_whiten': 3.40473139185299, 'pcr_s_w': 4.810619340469382}, 'fold_2': {'pcr': 2.982986493296787, 'pcr_scale': 4.285734571879425, 'pcr_whiten': 2.984182882712247, 'pcr_s_w': 4.30322828023572}, 'fold_3': {'pcr': 3.4488142177960253, 'pcr_scale': 4.734168714944838, 'pcr_whiten': 3.4495283661656413, 'pcr_s_w': 4.761519540295}, 'fold_4': {'pcr': 12.555518788306683, 'pcr_scale': 5.20560698921009, 'pcr_whiten': 12.566332437547834, 'pcr_s_w': 5.258952711668708}, 'MSE': {'pcr': 5.095595926016194, 'pcr_scale': 4.692933843814062, 'pcr_whiten': 5.097572359687424, 'pcr_s_w': 4.711186389697635}, 'R2': {'pcr': 0.991521490717844, 'pcr_scale': 0.9921914759857285, 'pcr_whiten': 0.9915182021503299, 'pcr_s_w': 0.992161105763689}}'\n",
      "pcr: {'fold_0': 3.0877296606207323, 'fold_1': 3.4047779646794862, 'fold_2': 2.982986493296787, 'fold_3': 3.4488142177960253, 'fold_4': 12.555518788306683, 'MSE': 5.095595926016194, 'R2': 0.991521490717844}'\n",
      "pcr_scale: {'fold_0': 4.417084923382192, 'fold_1': 4.822147264159305, 'fold_2': 4.285734571879425, 'fold_3': 4.734168714944838, 'fold_4': 5.20560698921009, 'MSE': 4.692933843814062, 'R2': 0.9921914759857285}'\n",
      "pcr_whiten: {'fold_0': 3.084937607131631, 'fold_1': 3.40473139185299, 'fold_2': 2.984182882712247, 'fold_3': 3.4495283661656413, 'fold_4': 12.566332437547834, 'MSE': 5.097572359687424, 'R2': 0.9915182021503299}'\n",
      "pcr_s_w: {'fold_0': 4.4217070041084865, 'fold_1': 4.810619340469382, 'fold_2': 4.30322828023572, 'fold_3': 4.761519540295, 'fold_4': 5.258952711668708, 'MSE': 4.711186389697635, 'R2': 0.992161105763689}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 56 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9832,pcr_scale:4.3821,pcr_whiten:2.9841,pcr_s_w:4.3906'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0761,pcr_scale:4.418,pcr_whiten:3.0794,pcr_s_w:4.4422'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1762,pcr_scale:4.4174,pcr_whiten:3.1776,pcr_s_w:4.4152'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.4024,pcr_scale:4.8334,pcr_whiten:3.4019,pcr_s_w:4.8541'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2575,pcr_scale:4.4974,pcr_whiten:3.2563,pcr_s_w:4.4858'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9849,pcr_scale:4.2641,pcr_whiten:2.9877,pcr_s_w:4.2724'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2398,pcr_scale:4.5484,pcr_whiten:3.2398,pcr_s_w:4.498'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4564,pcr_scale:4.7809,pcr_whiten:3.4557,pcr_s_w:4.7124'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9355,pcr_scale:4.3166,pcr_whiten:2.936,pcr_s_w:4.287'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.5379,pcr_scale:5.2701,pcr_whiten:12.558,pcr_s_w:5.2444'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.1653,pcr_scale:4.403,pcr_whiten:3.162,pcr_s_w:4.3887'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0276,pcr_scale:4.6719,pcr_whiten:3.0248,pcr_s_w:4.697'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.076121819578043, 'pcr_scale': 4.418038862373876, 'pcr_whiten': 3.079384994018576, 'pcr_s_w': 4.442153101936713}, 'fold_1': {'pcr': 3.402409452033767, 'pcr_scale': 4.833431767314119, 'pcr_whiten': 3.401870358678821, 'pcr_s_w': 4.854117300496077}, 'fold_2': {'pcr': 2.9849033336841364, 'pcr_scale': 4.264123481224316, 'pcr_whiten': 2.9876686733558744, 'pcr_s_w': 4.272362477620567}, 'fold_3': {'pcr': 3.456354823857114, 'pcr_scale': 4.780934456144654, 'pcr_whiten': 3.455655418468882, 'pcr_s_w': 4.712403018799094}, 'fold_4': {'pcr': 12.537927350811515, 'pcr_scale': 5.270102851888556, 'pcr_whiten': 12.557951800893823, 'pcr_s_w': 5.244394059379158}, 'MSE': {'pcr': 5.091173344462713, 'pcr_scale': 4.713308786591952, 'pcr_whiten': 5.096135518245653, 'pcr_s_w': 4.7050746151400435}, 'R2': {'pcr': 0.9915288494054827, 'pcr_scale': 0.9921575743294799, 'pcr_whiten': 0.9915205928959224, 'pcr_s_w': 0.9921712750820708}}'\n",
      "pcr: {'fold_0': 3.076121819578043, 'fold_1': 3.402409452033767, 'fold_2': 2.9849033336841364, 'fold_3': 3.456354823857114, 'fold_4': 12.537927350811515, 'MSE': 5.091173344462713, 'R2': 0.9915288494054827}'\n",
      "pcr_scale: {'fold_0': 4.418038862373876, 'fold_1': 4.833431767314119, 'fold_2': 4.264123481224316, 'fold_3': 4.780934456144654, 'fold_4': 5.270102851888556, 'MSE': 4.713308786591952, 'R2': 0.9921575743294799}'\n",
      "pcr_whiten: {'fold_0': 3.079384994018576, 'fold_1': 3.401870358678821, 'fold_2': 2.9876686733558744, 'fold_3': 3.455655418468882, 'fold_4': 12.557951800893823, 'MSE': 5.096135518245653, 'R2': 0.9915205928959224}'\n",
      "pcr_s_w: {'fold_0': 4.442153101936713, 'fold_1': 4.854117300496077, 'fold_2': 4.272362477620567, 'fold_3': 4.712403018799094, 'fold_4': 5.244394059379158, 'MSE': 4.7050746151400435, 'R2': 0.9921712750820708}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 57 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.97,pcr_scale:4.3726,pcr_whiten:2.9693,pcr_s_w:4.3684'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0631,pcr_scale:4.398,pcr_whiten:3.0605,pcr_s_w:4.4114'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1739,pcr_scale:4.3885,pcr_whiten:3.1733,pcr_s_w:4.4083'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3907,pcr_scale:4.82,pcr_whiten:3.3886,pcr_s_w:4.8416'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2544,pcr_scale:4.4773,pcr_whiten:3.2546,pcr_s_w:4.4811'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9846,pcr_scale:4.2783,pcr_whiten:2.9858,pcr_s_w:4.2187'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2399,pcr_scale:4.5273,pcr_whiten:3.2402,pcr_s_w:4.5105'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4584,pcr_scale:4.7566,pcr_whiten:3.4577,pcr_s_w:4.7246'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9163,pcr_scale:4.2877,pcr_whiten:2.9209,pcr_s_w:4.3141'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.6921,pcr_scale:5.2945,pcr_whiten:12.6278,pcr_s_w:5.2402'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.1558,pcr_scale:4.4014,pcr_whiten:3.1537,pcr_s_w:4.3986'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0352,pcr_scale:4.6981,pcr_whiten:3.0345,pcr_s_w:4.6625'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.063090550712499, 'pcr_scale': 4.398048933683041, 'pcr_whiten': 3.060538226105482, 'pcr_s_w': 4.4114224305482646}, 'fold_1': {'pcr': 3.3907323636733366, 'pcr_scale': 4.820030307357247, 'pcr_whiten': 3.388592763538554, 'pcr_s_w': 4.841626575859235}, 'fold_2': {'pcr': 2.9846269410336284, 'pcr_scale': 4.278339679463129, 'pcr_whiten': 2.9857646602747328, 'pcr_s_w': 4.218688607196204}, 'fold_3': {'pcr': 3.458438644864891, 'pcr_scale': 4.756568257165336, 'pcr_whiten': 3.4576809455555324, 'pcr_s_w': 4.724558775800426}, 'fold_4': {'pcr': 12.692101796442559, 'pcr_scale': 5.2945064400318875, 'pcr_whiten': 12.627819690488867, 'pcr_s_w': 5.24016747637392}, 'MSE': {'pcr': 5.117420335293815, 'pcr_scale': 4.709478655800812, 'pcr_whiten': 5.103703804982811, 'pcr_s_w': 4.687280634068525}, 'R2': {'pcr': 0.9914851773092997, 'pcr_scale': 0.9921639472444316, 'pcr_whiten': 0.9915080001020112, 'pcr_s_w': 0.9922008823028693}}'\n",
      "pcr: {'fold_0': 3.063090550712499, 'fold_1': 3.3907323636733366, 'fold_2': 2.9846269410336284, 'fold_3': 3.458438644864891, 'fold_4': 12.692101796442559, 'MSE': 5.117420335293815, 'R2': 0.9914851773092997}'\n",
      "pcr_scale: {'fold_0': 4.398048933683041, 'fold_1': 4.820030307357247, 'fold_2': 4.278339679463129, 'fold_3': 4.756568257165336, 'fold_4': 5.2945064400318875, 'MSE': 4.709478655800812, 'R2': 0.9921639472444316}'\n",
      "pcr_whiten: {'fold_0': 3.060538226105482, 'fold_1': 3.388592763538554, 'fold_2': 2.9857646602747328, 'fold_3': 3.4576809455555324, 'fold_4': 12.627819690488867, 'MSE': 5.103703804982811, 'R2': 0.9915080001020112}'\n",
      "pcr_s_w: {'fold_0': 4.4114224305482646, 'fold_1': 4.841626575859235, 'fold_2': 4.218688607196204, 'fold_3': 4.724558775800426, 'fold_4': 5.24016747637392, 'MSE': 4.687280634068525, 'R2': 0.9922008823028693}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 58 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9658,pcr_scale:4.3606,pcr_whiten:2.9682,pcr_s_w:4.3835'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0412,pcr_scale:4.4132,pcr_whiten:3.0495,pcr_s_w:4.4228'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1742,pcr_scale:4.405,pcr_whiten:3.1757,pcr_s_w:4.3975'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3916,pcr_scale:4.8081,pcr_whiten:3.3938,pcr_s_w:4.8689'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2542,pcr_scale:4.4797,pcr_whiten:3.2541,pcr_s_w:4.4838'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.979,pcr_scale:4.2692,pcr_whiten:2.9855,pcr_s_w:4.2707'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2385,pcr_scale:4.5282,pcr_whiten:3.2398,pcr_s_w:4.5155'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.455,pcr_scale:4.7413,pcr_whiten:3.4576,pcr_s_w:4.7502'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9184,pcr_scale:4.319,pcr_whiten:2.9112,pcr_s_w:4.2812'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.6939,pcr_scale:5.274,pcr_whiten:12.6815,pcr_s_w:5.243'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.1559,pcr_scale:4.4224,pcr_whiten:3.153,pcr_s_w:4.4028'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0372,pcr_scale:4.7378,pcr_whiten:3.0365,pcr_s_w:4.6966'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.041208288442091, 'pcr_scale': 4.4131826627264905, 'pcr_whiten': 3.0494687669556897, 'pcr_s_w': 4.422795278251983}, 'fold_1': {'pcr': 3.39161962653377, 'pcr_scale': 4.808126947602772, 'pcr_whiten': 3.393832786703421, 'pcr_s_w': 4.868874462135774}, 'fold_2': {'pcr': 2.9789848560987564, 'pcr_scale': 4.269221238630345, 'pcr_whiten': 2.9855090076232904, 'pcr_s_w': 4.2707364901853575}, 'fold_3': {'pcr': 3.455021174585498, 'pcr_scale': 4.741322264110346, 'pcr_whiten': 3.457617341717782, 'pcr_s_w': 4.7502482025830375}, 'fold_4': {'pcr': 12.693907079383886, 'pcr_scale': 5.274019859205131, 'pcr_whiten': 12.68145552713211, 'pcr_s_w': 5.242979390796904}, 'MSE': {'pcr': 5.1117695125901985, 'pcr_scale': 4.70115651219587, 'pcr_whiten': 5.113198754362616, 'pcr_s_w': 4.711113722062964}, 'R2': {'pcr': 0.9914945796546663, 'pcr_scale': 0.9921777943729767, 'pcr_whiten': 0.9914922015540849, 'pcr_s_w': 0.9921612266746136}}'\n",
      "pcr: {'fold_0': 3.041208288442091, 'fold_1': 3.39161962653377, 'fold_2': 2.9789848560987564, 'fold_3': 3.455021174585498, 'fold_4': 12.693907079383886, 'MSE': 5.1117695125901985, 'R2': 0.9914945796546663}'\n",
      "pcr_scale: {'fold_0': 4.4131826627264905, 'fold_1': 4.808126947602772, 'fold_2': 4.269221238630345, 'fold_3': 4.741322264110346, 'fold_4': 5.274019859205131, 'MSE': 4.70115651219587, 'R2': 0.9921777943729767}'\n",
      "pcr_whiten: {'fold_0': 3.0494687669556897, 'fold_1': 3.393832786703421, 'fold_2': 2.9855090076232904, 'fold_3': 3.457617341717782, 'fold_4': 12.68145552713211, 'MSE': 5.113198754362616, 'R2': 0.9914922015540849}'\n",
      "pcr_s_w: {'fold_0': 4.422795278251983, 'fold_1': 4.868874462135774, 'fold_2': 4.2707364901853575, 'fold_3': 4.7502482025830375, 'fold_4': 5.242979390796904, 'MSE': 4.711113722062964, 'R2': 0.9921612266746136}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 59 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.969,pcr_scale:4.3611,pcr_whiten:2.9664,pcr_s_w:4.3653'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0498,pcr_scale:4.372,pcr_whiten:3.0454,pcr_s_w:4.4184'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1665,pcr_scale:4.4146,pcr_whiten:3.1732,pcr_s_w:4.3749'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3775,pcr_scale:4.8067,pcr_whiten:3.3903,pcr_s_w:4.8299'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2199,pcr_scale:4.478,pcr_whiten:3.2206,pcr_s_w:4.4886'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9879,pcr_scale:4.262,pcr_whiten:2.9834,pcr_s_w:4.2257'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2149,pcr_scale:4.5196,pcr_whiten:3.2153,pcr_s_w:4.5055'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4453,pcr_scale:4.7723,pcr_whiten:3.4465,pcr_s_w:4.7331'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8815,pcr_scale:4.2813,pcr_whiten:2.8673,pcr_s_w:4.2651'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.6136,pcr_scale:5.256,pcr_whiten:12.5506,pcr_s_w:5.2667'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.1505,pcr_scale:4.3893,pcr_whiten:3.1508,pcr_s_w:4.3792'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0297,pcr_scale:4.7332,pcr_whiten:3.0293,pcr_s_w:4.7139'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.0497830128057775, 'pcr_scale': 4.372010445093625, 'pcr_whiten': 3.045441638216407, 'pcr_s_w': 4.418400747729256}, 'fold_1': {'pcr': 3.3775432393929865, 'pcr_scale': 4.806723920939904, 'pcr_whiten': 3.390342095989968, 'pcr_s_w': 4.829876335020741}, 'fold_2': {'pcr': 2.987914189906418, 'pcr_scale': 4.262044148570671, 'pcr_whiten': 2.9833524945293215, 'pcr_s_w': 4.225656344554554}, 'fold_3': {'pcr': 3.4452659169945865, 'pcr_scale': 4.772284583318112, 'pcr_whiten': 3.446472033582859, 'pcr_s_w': 4.733143650031807}, 'fold_4': {'pcr': 12.613582839358806, 'pcr_scale': 5.255968260760861, 'pcr_whiten': 12.5505588691252, 'pcr_s_w': 5.2666667258182445}, 'MSE': {'pcr': 5.094442059685004, 'pcr_scale': 4.69378540895423, 'pcr_whiten': 5.082860805122313, 'pcr_s_w': 4.69473465551321}, 'R2': {'pcr': 0.991523410624081, 'pcr_scale': 0.9921900590753121, 'pcr_whiten': 0.9915426805535916, 'pcr_s_w': 0.9921884796337948}}'\n",
      "pcr: {'fold_0': 3.0497830128057775, 'fold_1': 3.3775432393929865, 'fold_2': 2.987914189906418, 'fold_3': 3.4452659169945865, 'fold_4': 12.613582839358806, 'MSE': 5.094442059685004, 'R2': 0.991523410624081}'\n",
      "pcr_scale: {'fold_0': 4.372010445093625, 'fold_1': 4.806723920939904, 'fold_2': 4.262044148570671, 'fold_3': 4.772284583318112, 'fold_4': 5.255968260760861, 'MSE': 4.69378540895423, 'R2': 0.9921900590753121}'\n",
      "pcr_whiten: {'fold_0': 3.045441638216407, 'fold_1': 3.390342095989968, 'fold_2': 2.9833524945293215, 'fold_3': 3.446472033582859, 'fold_4': 12.5505588691252, 'MSE': 5.082860805122313, 'R2': 0.9915426805535916}'\n",
      "pcr_s_w: {'fold_0': 4.418400747729256, 'fold_1': 4.829876335020741, 'fold_2': 4.225656344554554, 'fold_3': 4.733143650031807, 'fold_4': 5.2666667258182445, 'MSE': 4.69473465551321, 'R2': 0.9921884796337948}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 60 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9641,pcr_scale:4.358,pcr_whiten:2.9616,pcr_s_w:4.3473'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0519,pcr_scale:4.3979,pcr_whiten:3.0516,pcr_s_w:4.4023'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1672,pcr_scale:4.3642,pcr_whiten:3.1701,pcr_s_w:4.3622'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3785,pcr_scale:4.7682,pcr_whiten:3.3814,pcr_s_w:4.8183'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2192,pcr_scale:4.4842,pcr_whiten:3.2119,pcr_s_w:4.4849'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9845,pcr_scale:4.2822,pcr_whiten:2.9915,pcr_s_w:4.2285'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2156,pcr_scale:4.4901,pcr_whiten:3.22,pcr_s_w:4.5064'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4489,pcr_scale:4.7164,pcr_whiten:3.4508,pcr_s_w:4.6982'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8723,pcr_scale:4.2749,pcr_whiten:2.8773,pcr_s_w:4.2502'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.456,pcr_scale:5.1981,pcr_whiten:12.4762,pcr_s_w:5.2506'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.1417,pcr_scale:4.4003,pcr_whiten:3.1383,pcr_s_w:4.4126'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0306,pcr_scale:4.6507,pcr_whiten:3.0278,pcr_s_w:4.6647'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.0519334175223625, 'pcr_scale': 4.397908795265646, 'pcr_whiten': 3.0516206073897, 'pcr_s_w': 4.402279450418058}, 'fold_1': {'pcr': 3.378484236335645, 'pcr_scale': 4.768242329027221, 'pcr_whiten': 3.3814047564562197, 'pcr_s_w': 4.818336871548612}, 'fold_2': {'pcr': 2.9845189534795775, 'pcr_scale': 4.282191160504343, 'pcr_whiten': 2.9914676359932955, 'pcr_s_w': 4.228547510517174}, 'fold_3': {'pcr': 3.448937384744803, 'pcr_scale': 4.71638980316659, 'pcr_whiten': 3.4507904752184992, 'pcr_s_w': 4.698166188269679}, 'fold_4': {'pcr': 12.456033572168227, 'pcr_scale': 5.198100682339129, 'pcr_whiten': 12.476182847965207, 'pcr_s_w': 5.250645188142233}, 'MSE': {'pcr': 5.063612201486576, 'pcr_scale': 4.672548677314299, 'pcr_whiten': 5.06992295286214, 'pcr_s_w': 4.679581201011913}, 'R2': {'pcr': 0.991574708105808, 'pcr_scale': 0.9922253946531221, 'pcr_whiten': 0.9915642077119596, 'pcr_s_w': 0.992213693309783}}'\n",
      "pcr: {'fold_0': 3.0519334175223625, 'fold_1': 3.378484236335645, 'fold_2': 2.9845189534795775, 'fold_3': 3.448937384744803, 'fold_4': 12.456033572168227, 'MSE': 5.063612201486576, 'R2': 0.991574708105808}'\n",
      "pcr_scale: {'fold_0': 4.397908795265646, 'fold_1': 4.768242329027221, 'fold_2': 4.282191160504343, 'fold_3': 4.71638980316659, 'fold_4': 5.198100682339129, 'MSE': 4.672548677314299, 'R2': 0.9922253946531221}'\n",
      "pcr_whiten: {'fold_0': 3.0516206073897, 'fold_1': 3.3814047564562197, 'fold_2': 2.9914676359932955, 'fold_3': 3.4507904752184992, 'fold_4': 12.476182847965207, 'MSE': 5.06992295286214, 'R2': 0.9915642077119596}'\n",
      "pcr_s_w: {'fold_0': 4.402279450418058, 'fold_1': 4.818336871548612, 'fold_2': 4.228547510517174, 'fold_3': 4.698166188269679, 'fold_4': 5.250645188142233, 'MSE': 4.679581201011913, 'R2': 0.992213693309783}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 61 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9439,pcr_scale:4.3545,pcr_whiten:2.9357,pcr_s_w:4.3641'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0079,pcr_scale:4.3919,pcr_whiten:3.007,pcr_s_w:4.3945'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.157,pcr_scale:4.3792,pcr_whiten:3.1554,pcr_s_w:4.3772'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3793,pcr_scale:4.7377,pcr_whiten:3.3765,pcr_s_w:4.8076'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2158,pcr_scale:4.425,pcr_whiten:3.2049,pcr_s_w:4.4793'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9605,pcr_scale:4.265,pcr_whiten:2.9562,pcr_s_w:4.2622'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2169,pcr_scale:4.5035,pcr_whiten:3.2116,pcr_s_w:4.4844'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4573,pcr_scale:4.7415,pcr_whiten:3.4549,pcr_s_w:4.7021'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.87,pcr_scale:4.2728,pcr_whiten:2.8764,pcr_s_w:4.2731'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.5302,pcr_scale:5.2777,pcr_whiten:12.5026,pcr_s_w:5.2622'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.1324,pcr_scale:4.3833,pcr_whiten:3.1339,pcr_s_w:4.3956'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.016,pcr_scale:4.6575,pcr_whiten:3.0173,pcr_s_w:4.6758'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 3.007874018942019, 'pcr_scale': 4.391915276566372, 'pcr_whiten': 3.0069985240819217, 'pcr_s_w': 4.39450266366673}, 'fold_1': {'pcr': 3.3792934211985686, 'pcr_scale': 4.737741116192845, 'pcr_whiten': 3.3765419148165057, 'pcr_s_w': 4.807562260022051}, 'fold_2': {'pcr': 2.9604724487277965, 'pcr_scale': 4.265036816830935, 'pcr_whiten': 2.956200868689437, 'pcr_s_w': 4.262223282099598}, 'fold_3': {'pcr': 3.457283708417754, 'pcr_scale': 4.741471860831512, 'pcr_whiten': 3.454898938430782, 'pcr_s_w': 4.70207277462707}, 'fold_4': {'pcr': 12.530213350317247, 'pcr_scale': 5.277674688907699, 'pcr_whiten': 12.50264384513834, 'pcr_s_w': 5.262234228960415}, 'MSE': {'pcr': 5.066653149874362, 'pcr_scale': 4.682744392186391, 'pcr_whiten': 5.059083728619176, 'pcr_s_w': 4.685702124859586}, 'R2': {'pcr': 0.9915696483032831, 'pcr_scale': 0.9922084301087515, 'pcr_whiten': 0.991582242984907, 'pcr_s_w': 0.9922035087679922}}'\n",
      "pcr: {'fold_0': 3.007874018942019, 'fold_1': 3.3792934211985686, 'fold_2': 2.9604724487277965, 'fold_3': 3.457283708417754, 'fold_4': 12.530213350317247, 'MSE': 5.066653149874362, 'R2': 0.9915696483032831}'\n",
      "pcr_scale: {'fold_0': 4.391915276566372, 'fold_1': 4.737741116192845, 'fold_2': 4.265036816830935, 'fold_3': 4.741471860831512, 'fold_4': 5.277674688907699, 'MSE': 4.682744392186391, 'R2': 0.9922084301087515}'\n",
      "pcr_whiten: {'fold_0': 3.0069985240819217, 'fold_1': 3.3765419148165057, 'fold_2': 2.956200868689437, 'fold_3': 3.454898938430782, 'fold_4': 12.50264384513834, 'MSE': 5.059083728619176, 'R2': 0.991582242984907}'\n",
      "pcr_s_w: {'fold_0': 4.39450266366673, 'fold_1': 4.807562260022051, 'fold_2': 4.262223282099598, 'fold_3': 4.70207277462707, 'fold_4': 5.262234228960415, 'MSE': 4.685702124859586, 'R2': 0.9922035087679922}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 62 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9277,pcr_scale:4.3384,pcr_whiten:2.9274,pcr_s_w:4.3326'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9747,pcr_scale:4.3556,pcr_whiten:2.9691,pcr_s_w:4.4165'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1485,pcr_scale:4.3889,pcr_whiten:3.1477,pcr_s_w:4.3796'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.378,pcr_scale:4.8066,pcr_whiten:3.3762,pcr_s_w:4.7993'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1885,pcr_scale:4.4655,pcr_whiten:3.196,pcr_s_w:4.4663'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9563,pcr_scale:4.2585,pcr_whiten:2.9556,pcr_s_w:4.2915'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.2091,pcr_scale:4.5065,pcr_whiten:3.211,pcr_s_w:4.4928'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4271,pcr_scale:4.737,pcr_whiten:3.4333,pcr_s_w:4.7057'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8418,pcr_scale:4.2716,pcr_whiten:2.8264,pcr_s_w:4.2798'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.7316,pcr_scale:5.2108,pcr_whiten:13.0291,pcr_s_w:5.1937'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.1277,pcr_scale:4.3662,pcr_whiten:3.1288,pcr_s_w:4.4126'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.0292,pcr_scale:4.6568,pcr_whiten:3.019,pcr_s_w:4.7037'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.9746610813032555, 'pcr_scale': 4.355585614586933, 'pcr_whiten': 2.9691297135705246, 'pcr_s_w': 4.416540433358168}, 'fold_1': {'pcr': 3.377977952426071, 'pcr_scale': 4.806636970849181, 'pcr_whiten': 3.3761583573333303, 'pcr_s_w': 4.799321733449631}, 'fold_2': {'pcr': 2.9562806579709604, 'pcr_scale': 4.258456652457768, 'pcr_whiten': 2.955551558425997, 'pcr_s_w': 4.291513236881751}, 'fold_3': {'pcr': 3.427081244239827, 'pcr_scale': 4.736954463698425, 'pcr_whiten': 3.4333027212534932, 'pcr_s_w': 4.705668642659577}, 'fold_4': {'pcr': 12.73163306579584, 'pcr_scale': 5.210815727272558, 'pcr_whiten': 13.02907647007852, 'pcr_s_w': 5.193670889803105}, 'MSE': {'pcr': 5.093143818468747, 'pcr_scale': 4.673671392246593, 'pcr_whiten': 5.152248238817015, 'pcr_s_w': 4.681328322447421}, 'R2': {'pcr': 0.9915255707541938, 'pcr_scale': 0.9922235265793751, 'pcr_whiten': 0.9914272275213678, 'pcr_s_w': 0.9922107862925228}}'\n",
      "pcr: {'fold_0': 2.9746610813032555, 'fold_1': 3.377977952426071, 'fold_2': 2.9562806579709604, 'fold_3': 3.427081244239827, 'fold_4': 12.73163306579584, 'MSE': 5.093143818468747, 'R2': 0.9915255707541938}'\n",
      "pcr_scale: {'fold_0': 4.355585614586933, 'fold_1': 4.806636970849181, 'fold_2': 4.258456652457768, 'fold_3': 4.736954463698425, 'fold_4': 5.210815727272558, 'MSE': 4.673671392246593, 'R2': 0.9922235265793751}'\n",
      "pcr_whiten: {'fold_0': 2.9691297135705246, 'fold_1': 3.3761583573333303, 'fold_2': 2.955551558425997, 'fold_3': 3.4333027212534932, 'fold_4': 13.02907647007852, 'MSE': 5.152248238817015, 'R2': 0.9914272275213678}'\n",
      "pcr_s_w: {'fold_0': 4.416540433358168, 'fold_1': 4.799321733449631, 'fold_2': 4.291513236881751, 'fold_3': 4.705668642659577, 'fold_4': 5.193670889803105, 'MSE': 4.681328322447421, 'R2': 0.9922107862925228}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 63 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9209,pcr_scale:4.3483,pcr_whiten:2.9233,pcr_s_w:4.3435'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9539,pcr_scale:4.4048,pcr_whiten:2.951,pcr_s_w:4.3712'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.136,pcr_scale:4.3919,pcr_whiten:3.139,pcr_s_w:4.3972'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3419,pcr_scale:4.8029,pcr_whiten:3.3445,pcr_s_w:4.8153'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1655,pcr_scale:4.4595,pcr_whiten:3.1627,pcr_s_w:4.4686'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9403,pcr_scale:4.2716,pcr_whiten:2.9473,pcr_s_w:4.2714'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1648,pcr_scale:4.5065,pcr_whiten:3.175,pcr_s_w:4.4982'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4013,pcr_scale:4.7771,pcr_whiten:3.41,pcr_s_w:4.7227'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8322,pcr_scale:4.2733,pcr_whiten:2.8314,pcr_s_w:4.2501'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.9247,pcr_scale:5.2362,pcr_whiten:12.8272,pcr_s_w:5.2208'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.1054,pcr_scale:4.3777,pcr_whiten:3.1119,pcr_s_w:4.3788'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.977,pcr_scale:4.6662,pcr_whiten:2.9779,pcr_s_w:4.6405'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.953928528481968, 'pcr_scale': 4.40479463591277, 'pcr_whiten': 2.9510226371914174, 'pcr_s_w': 4.371248075989824}, 'fold_1': {'pcr': 3.3419020872771297, 'pcr_scale': 4.802924831507444, 'pcr_whiten': 3.34445691172356, 'pcr_s_w': 4.815325432079368}, 'fold_2': {'pcr': 2.9403421202610884, 'pcr_scale': 4.271644098630779, 'pcr_whiten': 2.9473163542630063, 'pcr_s_w': 4.27144820177654}, 'fold_3': {'pcr': 3.4012562276313756, 'pcr_scale': 4.777052919636735, 'pcr_whiten': 3.4100253284057747, 'pcr_s_w': 4.722736962339503}, 'fold_4': {'pcr': 12.924726063907922, 'pcr_scale': 5.2361679697245505, 'pcr_whiten': 12.827214470117154, 'pcr_s_w': 5.220812146563904}, 'MSE': {'pcr': 5.112038573291034, 'pcr_scale': 4.69849798234147, 'pcr_whiten': 5.095617953890745, 'pcr_s_w': 4.68029677912943}, 'R2': {'pcr': 0.991494131967353, 'pcr_scale': 0.992182217873265, 'pcr_whiten': 0.9915214540658918, 'pcr_s_w': 0.9922125026667651}}'\n",
      "pcr: {'fold_0': 2.953928528481968, 'fold_1': 3.3419020872771297, 'fold_2': 2.9403421202610884, 'fold_3': 3.4012562276313756, 'fold_4': 12.924726063907922, 'MSE': 5.112038573291034, 'R2': 0.991494131967353}'\n",
      "pcr_scale: {'fold_0': 4.40479463591277, 'fold_1': 4.802924831507444, 'fold_2': 4.271644098630779, 'fold_3': 4.777052919636735, 'fold_4': 5.2361679697245505, 'MSE': 4.69849798234147, 'R2': 0.992182217873265}'\n",
      "pcr_whiten: {'fold_0': 2.9510226371914174, 'fold_1': 3.34445691172356, 'fold_2': 2.9473163542630063, 'fold_3': 3.4100253284057747, 'fold_4': 12.827214470117154, 'MSE': 5.095617953890745, 'R2': 0.9915214540658918}'\n",
      "pcr_s_w: {'fold_0': 4.371248075989824, 'fold_1': 4.815325432079368, 'fold_2': 4.27144820177654, 'fold_3': 4.722736962339503, 'fold_4': 5.220812146563904, 'MSE': 4.68029677912943, 'R2': 0.9922125026667651}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 64 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9232,pcr_scale:4.3314,pcr_whiten:2.9134,pcr_s_w:4.358'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9572,pcr_scale:4.3696,pcr_whiten:2.9565,pcr_s_w:4.3918'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.13,pcr_scale:4.3553,pcr_whiten:3.1209,pcr_s_w:4.378'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3416,pcr_scale:4.7904,pcr_whiten:3.3336,pcr_s_w:4.8439'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1636,pcr_scale:4.45,pcr_whiten:3.1693,pcr_s_w:4.4676'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9536,pcr_scale:4.2421,pcr_whiten:2.9551,pcr_s_w:4.244'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1671,pcr_scale:4.5216,pcr_whiten:3.1732,pcr_s_w:4.5093'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4027,pcr_scale:4.7313,pcr_whiten:3.4022,pcr_s_w:4.7496'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8248,pcr_scale:4.2586,pcr_whiten:2.8313,pcr_s_w:4.2572'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.6433,pcr_scale:5.2275,pcr_whiten:12.6706,pcr_s_w:5.264'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.0918,pcr_scale:4.424,pcr_whiten:3.0908,pcr_s_w:4.3907'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9878,pcr_scale:4.6589,pcr_whiten:2.9793,pcr_s_w:4.6965'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.957196165187918, 'pcr_scale': 4.369616265654412, 'pcr_whiten': 2.956452285647473, 'pcr_s_w': 4.391785682587529}, 'fold_1': {'pcr': 3.341617349215766, 'pcr_scale': 4.790431811342017, 'pcr_whiten': 3.333632853410051, 'pcr_s_w': 4.843926725856652}, 'fold_2': {'pcr': 2.953580045468834, 'pcr_scale': 4.24205946320541, 'pcr_whiten': 2.9551344593952975, 'pcr_s_w': 4.244016908827778}, 'fold_3': {'pcr': 3.402688082548029, 'pcr_scale': 4.731341106061559, 'pcr_whiten': 3.4022175277480424, 'pcr_s_w': 4.749607066444793}, 'fold_4': {'pcr': 12.643307359203192, 'pcr_scale': 5.227504675178623, 'pcr_whiten': 12.670594368312333, 'pcr_s_w': 5.264000244845504}, 'MSE': {'pcr': 5.059296204031675, 'pcr_scale': 4.672172253056725, 'pcr_whiten': 5.063223046060175, 'pcr_s_w': 4.698651182859576}, 'R2': {'pcr': 0.991581889449269, 'pcr_scale': 0.9922260209815453, 'pcr_whiten': 0.9915753556174912, 'pcr_s_w': 0.9921819629645097}}'\n",
      "pcr: {'fold_0': 2.957196165187918, 'fold_1': 3.341617349215766, 'fold_2': 2.953580045468834, 'fold_3': 3.402688082548029, 'fold_4': 12.643307359203192, 'MSE': 5.059296204031675, 'R2': 0.991581889449269}'\n",
      "pcr_scale: {'fold_0': 4.369616265654412, 'fold_1': 4.790431811342017, 'fold_2': 4.24205946320541, 'fold_3': 4.731341106061559, 'fold_4': 5.227504675178623, 'MSE': 4.672172253056725, 'R2': 0.9922260209815453}'\n",
      "pcr_whiten: {'fold_0': 2.956452285647473, 'fold_1': 3.333632853410051, 'fold_2': 2.9551344593952975, 'fold_3': 3.4022175277480424, 'fold_4': 12.670594368312333, 'MSE': 5.063223046060175, 'R2': 0.9915753556174912}'\n",
      "pcr_s_w: {'fold_0': 4.391785682587529, 'fold_1': 4.843926725856652, 'fold_2': 4.244016908827778, 'fold_3': 4.749607066444793, 'fold_4': 5.264000244845504, 'MSE': 4.698651182859576, 'R2': 0.9921819629645097}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 65 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9179,pcr_scale:4.3125,pcr_whiten:2.9225,pcr_s_w:4.3772'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9536,pcr_scale:4.3849,pcr_whiten:2.9683,pcr_s_w:4.446'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1229,pcr_scale:4.3559,pcr_whiten:3.1284,pcr_s_w:4.3771'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3441,pcr_scale:4.7976,pcr_whiten:3.3503,pcr_s_w:4.7958'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.162,pcr_scale:4.4404,pcr_whiten:3.1628,pcr_s_w:4.4689'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.95,pcr_scale:4.2203,pcr_whiten:2.9566,pcr_s_w:4.2503'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.171,pcr_scale:4.4699,pcr_whiten:3.1647,pcr_s_w:4.5066'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4063,pcr_scale:4.7164,pcr_whiten:3.4073,pcr_s_w:4.7422'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8282,pcr_scale:4.2616,pcr_whiten:2.8335,pcr_s_w:4.2428'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:12.7287,pcr_scale:5.2191,pcr_whiten:12.7228,pcr_s_w:5.2307'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.0788,pcr_scale:4.3998,pcr_whiten:3.0921,pcr_s_w:4.3718'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.966,pcr_scale:4.7031,pcr_whiten:2.9903,pcr_s_w:4.6977'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 6, 'fold_4': 5, 'mean': 4.6}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.9536421391573118, 'pcr_scale': 4.384901629734933, 'pcr_whiten': 2.9683311822733556, 'pcr_s_w': 4.445993861894604}, 'fold_1': {'pcr': 3.344052606124531, 'pcr_scale': 4.797621227218475, 'pcr_whiten': 3.350323126639993, 'pcr_s_w': 4.795809411136598}, 'fold_2': {'pcr': 2.9499828574828806, 'pcr_scale': 4.220334302444641, 'pcr_whiten': 2.9566459158828833, 'pcr_s_w': 4.250317757231479}, 'fold_3': {'pcr': 3.406309055860253, 'pcr_scale': 4.7164212913521775, 'pcr_whiten': 3.4072721539224453, 'pcr_s_w': 4.742239443520806}, 'fold_4': {'pcr': 12.728724605738712, 'pcr_scale': 5.219148387026569, 'pcr_whiten': 12.722752385591694, 'pcr_s_w': 5.230747617532303}, 'MSE': {'pcr': 5.076157175988953, 'pcr_scale': 4.667670101087305, 'pcr_whiten': 5.080681065966668, 'pcr_s_w': 4.693007211554859}, 'R2': {'pcr': 0.9915538346526718, 'pcr_scale': 0.9922335120655749, 'pcr_whiten': 0.9915463073989954, 'pcr_s_w': 0.9921913539099045}}'\n",
      "pcr: {'fold_0': 2.9536421391573118, 'fold_1': 3.344052606124531, 'fold_2': 2.9499828574828806, 'fold_3': 3.406309055860253, 'fold_4': 12.728724605738712, 'MSE': 5.076157175988953, 'R2': 0.9915538346526718}'\n",
      "pcr_scale: {'fold_0': 4.384901629734933, 'fold_1': 4.797621227218475, 'fold_2': 4.220334302444641, 'fold_3': 4.7164212913521775, 'fold_4': 5.219148387026569, 'MSE': 4.667670101087305, 'R2': 0.9922335120655749}'\n",
      "pcr_whiten: {'fold_0': 2.9683311822733556, 'fold_1': 3.350323126639993, 'fold_2': 2.9566459158828833, 'fold_3': 3.4072721539224453, 'fold_4': 12.722752385591694, 'MSE': 5.080681065966668, 'R2': 0.9915463073989954}'\n",
      "pcr_s_w: {'fold_0': 4.445993861894604, 'fold_1': 4.795809411136598, 'fold_2': 4.250317757231479, 'fold_3': 4.742239443520806, 'fold_4': 5.230747617532303, 'MSE': 4.693007211554859, 'R2': 0.9921913539099045}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 66 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9148,pcr_scale:4.3436,pcr_whiten:2.9158,pcr_s_w:4.3465'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9618,pcr_scale:4.3803,pcr_whiten:2.963,pcr_s_w:4.3868'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1239,pcr_scale:4.3571,pcr_whiten:3.1218,pcr_s_w:4.3851'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3462,pcr_scale:4.8002,pcr_whiten:3.3433,pcr_s_w:4.8086'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.167,pcr_scale:4.4275,pcr_whiten:3.166,pcr_s_w:4.4207'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9493,pcr_scale:4.2034,pcr_whiten:2.9544,pcr_s_w:4.2409'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1626,pcr_scale:4.4862,pcr_whiten:3.1648,pcr_s_w:4.5158'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4035,pcr_scale:4.7041,pcr_whiten:3.3941,pcr_s_w:4.7562'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8106,pcr_scale:4.2655,pcr_whiten:2.8178,pcr_s_w:4.2283'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:13.3663,pcr_scale:5.1875,pcr_whiten:13.1234,pcr_s_w:5.238'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.0759,pcr_scale:4.3683,pcr_whiten:3.0819,pcr_s_w:4.352'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9607,pcr_scale:4.6711,pcr_whiten:2.9749,pcr_s_w:4.6581'\n",
      "Train times: {'fold_0': 4, 'fold_1': 5, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.961843813228264, 'pcr_scale': 4.380272489070187, 'pcr_whiten': 2.96301609929627, 'pcr_s_w': 4.386761110692521}, 'fold_1': {'pcr': 3.3461728814512495, 'pcr_scale': 4.80020882771651, 'pcr_whiten': 3.343277900901122, 'pcr_s_w': 4.808553818007257}, 'fold_2': {'pcr': 2.949328993894702, 'pcr_scale': 4.203353638481665, 'pcr_whiten': 2.9543538736793056, 'pcr_s_w': 4.24091746358932}, 'fold_3': {'pcr': 3.4034961806418056, 'pcr_scale': 4.704051265470669, 'pcr_whiten': 3.3940564223256215, 'pcr_s_w': 4.756223444633608}, 'fold_4': {'pcr': 13.36627735008485, 'pcr_scale': 5.187516722949966, 'pcr_whiten': 13.12337370131894, 'pcr_s_w': 5.238010888504086}, 'MSE': {'pcr': 5.2050140525104895, 'pcr_scale': 4.655067636294662, 'pcr_whiten': 5.155215585800815, 'pcr_s_w': 4.686075679108384}, 'R2': {'pcr': 0.9913394310305008, 'pcr_scale': 0.9922544811762096, 'pcr_whiten': 0.9914222901834566, 'pcr_s_w': 0.9922028872149469}}'\n",
      "pcr: {'fold_0': 2.961843813228264, 'fold_1': 3.3461728814512495, 'fold_2': 2.949328993894702, 'fold_3': 3.4034961806418056, 'fold_4': 13.36627735008485, 'MSE': 5.2050140525104895, 'R2': 0.9913394310305008}'\n",
      "pcr_scale: {'fold_0': 4.380272489070187, 'fold_1': 4.80020882771651, 'fold_2': 4.203353638481665, 'fold_3': 4.704051265470669, 'fold_4': 5.187516722949966, 'MSE': 4.655067636294662, 'R2': 0.9922544811762096}'\n",
      "pcr_whiten: {'fold_0': 2.96301609929627, 'fold_1': 3.343277900901122, 'fold_2': 2.9543538736793056, 'fold_3': 3.3940564223256215, 'fold_4': 13.12337370131894, 'MSE': 5.155215585800815, 'R2': 0.9914222901834566}'\n",
      "pcr_s_w: {'fold_0': 4.386761110692521, 'fold_1': 4.808553818007257, 'fold_2': 4.24091746358932, 'fold_3': 4.756223444633608, 'fold_4': 5.238010888504086, 'MSE': 4.686075679108384, 'R2': 0.9922028872149469}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 67 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.9193,pcr_scale:4.3383,pcr_whiten:2.903,pcr_s_w:4.3387'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.969,pcr_scale:4.4041,pcr_whiten:2.9377,pcr_s_w:4.4039'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1159,pcr_scale:4.3519,pcr_whiten:3.1055,pcr_s_w:4.3707'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3352,pcr_scale:4.7423,pcr_whiten:3.3351,pcr_s_w:4.7784'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1307,pcr_scale:4.4504,pcr_whiten:3.1562,pcr_s_w:4.4191'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.923,pcr_scale:4.2477,pcr_whiten:2.9322,pcr_s_w:4.2331'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.156,pcr_scale:4.5053,pcr_whiten:3.1613,pcr_s_w:4.5029'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3867,pcr_scale:4.7233,pcr_whiten:3.3951,pcr_s_w:4.736'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8006,pcr_scale:4.2443,pcr_whiten:2.7962,pcr_s_w:4.2673'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:13.0935,pcr_scale:5.1832,pcr_whiten:13.2198,pcr_s_w:5.2587'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.0756,pcr_scale:4.3605,pcr_whiten:3.0665,pcr_s_w:4.3994'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9584,pcr_scale:4.6326,pcr_whiten:2.9555,pcr_s_w:4.6732'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 5, 'fold_4': 4, 'mean': 4.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.9690006658994545, 'pcr_scale': 4.404130952215203, 'pcr_whiten': 2.937714023169441, 'pcr_s_w': 4.403877948150945}, 'fold_1': {'pcr': 3.335169018240064, 'pcr_scale': 4.742256453820184, 'pcr_whiten': 3.335052695267989, 'pcr_s_w': 4.778370991078707}, 'fold_2': {'pcr': 2.922972979101876, 'pcr_scale': 4.247659402095059, 'pcr_whiten': 2.9322331040956304, 'pcr_s_w': 4.233107735197169}, 'fold_3': {'pcr': 3.3866643656660558, 'pcr_scale': 4.723290328622107, 'pcr_whiten': 3.395063961569363, 'pcr_s_w': 4.735970909469228}, 'fold_4': {'pcr': 13.093491338673173, 'pcr_scale': 5.183178323894817, 'pcr_whiten': 13.219842923838113, 'pcr_s_w': 5.25869321347612}, 'MSE': {'pcr': 5.141062275427542, 'pcr_scale': 4.660085731084906, 'pcr_whiten': 5.1635763080319, 'pcr_s_w': 4.681986005321446}, 'R2': {'pcr': 0.9914458397299897, 'pcr_scale': 0.9922461316202645, 'pcr_whiten': 0.991408378864335, 'pcr_s_w': 0.9922096919808009}}'\n",
      "pcr: {'fold_0': 2.9690006658994545, 'fold_1': 3.335169018240064, 'fold_2': 2.922972979101876, 'fold_3': 3.3866643656660558, 'fold_4': 13.093491338673173, 'MSE': 5.141062275427542, 'R2': 0.9914458397299897}'\n",
      "pcr_scale: {'fold_0': 4.404130952215203, 'fold_1': 4.742256453820184, 'fold_2': 4.247659402095059, 'fold_3': 4.723290328622107, 'fold_4': 5.183178323894817, 'MSE': 4.660085731084906, 'R2': 0.9922461316202645}'\n",
      "pcr_whiten: {'fold_0': 2.937714023169441, 'fold_1': 3.335052695267989, 'fold_2': 2.9322331040956304, 'fold_3': 3.395063961569363, 'fold_4': 13.219842923838113, 'MSE': 5.1635763080319, 'R2': 0.991408378864335}'\n",
      "pcr_s_w: {'fold_0': 4.403877948150945, 'fold_1': 4.778370991078707, 'fold_2': 4.233107735197169, 'fold_3': 4.735970909469228, 'fold_4': 5.25869321347612, 'MSE': 4.681986005321446, 'R2': 0.9922096919808009}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 68 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8631,pcr_scale:4.324,pcr_whiten:2.8785,pcr_s_w:4.3501'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8775,pcr_scale:4.3526,pcr_whiten:2.893,pcr_s_w:4.3812'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1025,pcr_scale:4.3513,pcr_whiten:3.1,pcr_s_w:4.3298'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3305,pcr_scale:4.8025,pcr_whiten:3.3397,pcr_s_w:4.8009'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1477,pcr_scale:4.4339,pcr_whiten:3.1566,pcr_s_w:4.4529'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.942,pcr_scale:4.2083,pcr_whiten:2.9445,pcr_s_w:4.2518'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1533,pcr_scale:4.4869,pcr_whiten:3.1468,pcr_s_w:4.4884'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3823,pcr_scale:4.7307,pcr_whiten:3.3886,pcr_s_w:4.7555'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7912,pcr_scale:4.2622,pcr_whiten:2.7569,pcr_s_w:4.2598'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:13.2132,pcr_scale:5.2019,pcr_whiten:13.6928,pcr_s_w:5.2664'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.0647,pcr_scale:4.362,pcr_whiten:3.0682,pcr_s_w:4.3516'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.94,pcr_scale:4.7033,pcr_whiten:2.9515,pcr_s_w:4.6052'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 5, 'fold_3': 5, 'fold_4': 4, 'mean': 4.4}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.877467366794392, 'pcr_scale': 4.352620075477843, 'pcr_whiten': 2.892950988453877, 'pcr_s_w': 4.381213503979304}, 'fold_1': {'pcr': 3.3304954721910933, 'pcr_scale': 4.8024920236473, 'pcr_whiten': 3.339729467162462, 'pcr_s_w': 4.800881206180107}, 'fold_2': {'pcr': 2.94196684704046, 'pcr_scale': 4.208316683650718, 'pcr_whiten': 2.9445057214451427, 'pcr_s_w': 4.251835771123181}, 'fold_3': {'pcr': 3.3822983139732115, 'pcr_scale': 4.73069690527916, 'pcr_whiten': 3.388646808925148, 'pcr_s_w': 4.755528628078392}, 'fold_4': {'pcr': 13.213178398074934, 'pcr_scale': 5.201904199707296, 'pcr_whiten': 13.69279192187232, 'pcr_s_w': 5.2663837061361765}, 'MSE': {'pcr': 5.148672749878477, 'pcr_scale': 4.659189667139361, 'pcr_whiten': 5.251298416499124, 'pcr_s_w': 4.6911485628581175}, 'R2': {'pcr': 0.9914331767403785, 'pcr_scale': 0.9922476225717822, 'pcr_whiten': 0.9912624189566641, 'pcr_s_w': 0.9921944464962196}}'\n",
      "pcr: {'fold_0': 2.877467366794392, 'fold_1': 3.3304954721910933, 'fold_2': 2.94196684704046, 'fold_3': 3.3822983139732115, 'fold_4': 13.213178398074934, 'MSE': 5.148672749878477, 'R2': 0.9914331767403785}'\n",
      "pcr_scale: {'fold_0': 4.352620075477843, 'fold_1': 4.8024920236473, 'fold_2': 4.208316683650718, 'fold_3': 4.73069690527916, 'fold_4': 5.201904199707296, 'MSE': 4.659189667139361, 'R2': 0.9922476225717822}'\n",
      "pcr_whiten: {'fold_0': 2.892950988453877, 'fold_1': 3.339729467162462, 'fold_2': 2.9445057214451427, 'fold_3': 3.388646808925148, 'fold_4': 13.69279192187232, 'MSE': 5.251298416499124, 'R2': 0.9912624189566641}'\n",
      "pcr_s_w: {'fold_0': 4.381213503979304, 'fold_1': 4.800881206180107, 'fold_2': 4.251835771123181, 'fold_3': 4.755528628078392, 'fold_4': 5.2663837061361765, 'MSE': 4.6911485628581175, 'R2': 0.9921944464962196}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 69 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8801,pcr_scale:4.304,pcr_whiten:2.869,pcr_s_w:4.3428'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8985,pcr_scale:4.379,pcr_whiten:2.8917,pcr_s_w:4.3666'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0948,pcr_scale:4.3289,pcr_whiten:3.0915,pcr_s_w:4.367'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3392,pcr_scale:4.8061,pcr_whiten:3.3357,pcr_s_w:4.8116'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1313,pcr_scale:4.4267,pcr_whiten:3.1376,pcr_s_w:4.4267'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9198,pcr_scale:4.2489,pcr_whiten:2.9287,pcr_s_w:4.2465'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1526,pcr_scale:4.4633,pcr_whiten:3.1559,pcr_s_w:4.479'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3755,pcr_scale:4.7211,pcr_whiten:3.3802,pcr_s_w:4.7031'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7714,pcr_scale:4.2207,pcr_whiten:2.7407,pcr_s_w:4.2449'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:13.3251,pcr_scale:5.2381,pcr_whiten:14.1189,pcr_s_w:5.3126'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.0667,pcr_scale:4.3468,pcr_whiten:3.0553,pcr_s_w:4.3591'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9513,pcr_scale:4.6894,pcr_whiten:2.9375,pcr_s_w:4.6662'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.8984731686156224, 'pcr_scale': 4.379013228666576, 'pcr_whiten': 2.891692484268844, 'pcr_s_w': 4.366631912980587}, 'fold_1': {'pcr': 3.339190429842431, 'pcr_scale': 4.806111590210022, 'pcr_whiten': 3.3357177379016245, 'pcr_s_w': 4.8115704727064434}, 'fold_2': {'pcr': 2.919779722262143, 'pcr_scale': 4.248947569755735, 'pcr_whiten': 2.928674295989836, 'pcr_s_w': 4.24646387803363}, 'fold_3': {'pcr': 3.3754515142828185, 'pcr_scale': 4.721123738473172, 'pcr_whiten': 3.3802302854533233, 'pcr_s_w': 4.703149684265918}, 'fold_4': {'pcr': 13.3250881121289, 'pcr_scale': 5.238060256910901, 'pcr_whiten': 14.118928488156563, 'pcr_s_w': 5.312584363587898}, 'MSE': {'pcr': 5.171186528541406, 'pcr_scale': 4.678634079666373, 'pcr_whiten': 5.3306057211692055, 'pcr_s_w': 4.688060290267457}, 'R2': {'pcr': 0.9913957162972543, 'pcr_scale': 0.9922152692151798, 'pcr_whiten': 0.9911304603538724, 'pcr_s_w': 0.9921995850409955}}'\n",
      "pcr: {'fold_0': 2.8984731686156224, 'fold_1': 3.339190429842431, 'fold_2': 2.919779722262143, 'fold_3': 3.3754515142828185, 'fold_4': 13.3250881121289, 'MSE': 5.171186528541406, 'R2': 0.9913957162972543}'\n",
      "pcr_scale: {'fold_0': 4.379013228666576, 'fold_1': 4.806111590210022, 'fold_2': 4.248947569755735, 'fold_3': 4.721123738473172, 'fold_4': 5.238060256910901, 'MSE': 4.678634079666373, 'R2': 0.9922152692151798}'\n",
      "pcr_whiten: {'fold_0': 2.891692484268844, 'fold_1': 3.3357177379016245, 'fold_2': 2.928674295989836, 'fold_3': 3.3802302854533233, 'fold_4': 14.118928488156563, 'MSE': 5.3306057211692055, 'R2': 0.9911304603538724}'\n",
      "pcr_s_w: {'fold_0': 4.366631912980587, 'fold_1': 4.8115704727064434, 'fold_2': 4.24646387803363, 'fold_3': 4.703149684265918, 'fold_4': 5.312584363587898, 'MSE': 4.688060290267457, 'R2': 0.9921995850409955}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 70 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8523,pcr_scale:4.359,pcr_whiten:2.8509,pcr_s_w:4.2972'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8545,pcr_scale:4.3839,pcr_whiten:2.8517,pcr_s_w:4.3275'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1016,pcr_scale:4.3242,pcr_whiten:3.0948,pcr_s_w:4.3344'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3457,pcr_scale:4.802,pcr_whiten:3.3371,pcr_s_w:4.7994'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1284,pcr_scale:4.4437,pcr_whiten:3.1258,pcr_s_w:4.4589'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9197,pcr_scale:4.212,pcr_whiten:2.921,pcr_s_w:4.2708'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1505,pcr_scale:4.4645,pcr_whiten:3.1387,pcr_s_w:4.4507'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.389,pcr_scale:4.7035,pcr_whiten:3.3741,pcr_s_w:4.6943'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7289,pcr_scale:4.2243,pcr_whiten:2.7641,pcr_s_w:4.2559'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:13.6252,pcr_scale:5.2356,pcr_whiten:13.594,pcr_s_w:5.2524'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.0685,pcr_scale:4.348,pcr_whiten:3.0564,pcr_s_w:4.3534'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9487,pcr_scale:4.6099,pcr_whiten:2.9328,pcr_s_w:4.6762'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 5, 'mean': 4.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.85449796836943, 'pcr_scale': 4.383871934694118, 'pcr_whiten': 2.851737151606629, 'pcr_s_w': 4.327526686138549}, 'fold_1': {'pcr': 3.345693931872885, 'pcr_scale': 4.802033076175438, 'pcr_whiten': 3.3370634039871825, 'pcr_s_w': 4.799411207137842}, 'fold_2': {'pcr': 2.919667129085378, 'pcr_scale': 4.212040570098505, 'pcr_whiten': 2.9210253882245527, 'pcr_s_w': 4.270812643073505}, 'fold_3': {'pcr': 3.3889624617646015, 'pcr_scale': 4.703527608125811, 'pcr_whiten': 3.3740590152352836, 'pcr_s_w': 4.694274298212633}, 'fold_4': {'pcr': 13.625221650400535, 'pcr_scale': 5.235620025643148, 'pcr_whiten': 13.594016675921102, 'pcr_s_w': 5.252438426337501}, 'MSE': {'pcr': 5.226383795562214, 'pcr_scale': 4.667403767570354, 'pcr_whiten': 5.215156599458155, 'pcr_s_w': 4.668871592710261}, 'R2': {'pcr': 0.9913038741363804, 'pcr_scale': 0.9922339552151551, 'pcr_whiten': 0.991322554951689, 'pcr_s_w': 0.9922315129161082}}'\n",
      "pcr: {'fold_0': 2.85449796836943, 'fold_1': 3.345693931872885, 'fold_2': 2.919667129085378, 'fold_3': 3.3889624617646015, 'fold_4': 13.625221650400535, 'MSE': 5.226383795562214, 'R2': 0.9913038741363804}'\n",
      "pcr_scale: {'fold_0': 4.383871934694118, 'fold_1': 4.802033076175438, 'fold_2': 4.212040570098505, 'fold_3': 4.703527608125811, 'fold_4': 5.235620025643148, 'MSE': 4.667403767570354, 'R2': 0.9922339552151551}'\n",
      "pcr_whiten: {'fold_0': 2.851737151606629, 'fold_1': 3.3370634039871825, 'fold_2': 2.9210253882245527, 'fold_3': 3.3740590152352836, 'fold_4': 13.594016675921102, 'MSE': 5.215156599458155, 'R2': 0.991322554951689}'\n",
      "pcr_s_w: {'fold_0': 4.327526686138549, 'fold_1': 4.799411207137842, 'fold_2': 4.270812643073505, 'fold_3': 4.694274298212633, 'fold_4': 5.252438426337501, 'MSE': 4.668871592710261, 'R2': 0.9922315129161082}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 71 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8334,pcr_scale:4.3086,pcr_whiten:2.8373,pcr_s_w:4.3127'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8492,pcr_scale:4.3809,pcr_whiten:2.8549,pcr_s_w:4.3848'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0921,pcr_scale:4.3101,pcr_whiten:3.1007,pcr_s_w:4.3217'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3391,pcr_scale:4.7792,pcr_whiten:3.34,pcr_s_w:4.7768'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1241,pcr_scale:4.4163,pcr_whiten:3.1166,pcr_s_w:4.4112'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.9088,pcr_scale:4.2394,pcr_whiten:2.8878,pcr_s_w:4.2221'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1455,pcr_scale:4.4851,pcr_whiten:3.1307,pcr_s_w:4.4659'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3828,pcr_scale:4.7341,pcr_whiten:3.3871,pcr_s_w:4.7144'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7303,pcr_scale:4.2388,pcr_whiten:2.715,pcr_s_w:4.2416'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:13.5523,pcr_scale:5.1985,pcr_whiten:14.7403,pcr_s_w:5.2279'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.0528,pcr_scale:4.3588,pcr_whiten:3.0389,pcr_s_w:4.3723'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9423,pcr_scale:4.6492,pcr_whiten:2.9349,pcr_s_w:4.6484'\n",
      "Train times: {'fold_0': 4, 'fold_1': 5, 'fold_2': 5, 'fold_3': 5, 'fold_4': 5, 'mean': 4.8}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.8491802197503904, 'pcr_scale': 4.3809279511797845, 'pcr_whiten': 2.8548531459773097, 'pcr_s_w': 4.384789567034777}, 'fold_1': {'pcr': 3.3391222531970515, 'pcr_scale': 4.77921678936133, 'pcr_whiten': 3.3400286665154852, 'pcr_s_w': 4.7768149150958035}, 'fold_2': {'pcr': 2.908806843210366, 'pcr_scale': 4.2394372762250665, 'pcr_whiten': 2.887800600005997, 'pcr_s_w': 4.22213243934755}, 'fold_3': {'pcr': 3.382842308350338, 'pcr_scale': 4.734060620483084, 'pcr_whiten': 3.3871185404414375, 'pcr_s_w': 4.714379274819447}, 'fold_4': {'pcr': 13.552275905011049, 'pcr_scale': 5.198524103084147, 'pcr_whiten': 14.740253931462611, 'pcr_s_w': 5.227942451546864}, 'MSE': {'pcr': 5.206023553392965, 'pcr_scale': 4.666416096572916, 'pcr_whiten': 5.4415426248888314, 'pcr_s_w': 4.665194867905184}, 'R2': {'pcr': 0.9913377513324386, 'pcr_scale': 0.9922355985906977, 'pcr_whiten': 0.9909458735888351, 'pcr_s_w': 0.9922376305804287}}'\n",
      "pcr: {'fold_0': 2.8491802197503904, 'fold_1': 3.3391222531970515, 'fold_2': 2.908806843210366, 'fold_3': 3.382842308350338, 'fold_4': 13.552275905011049, 'MSE': 5.206023553392965, 'R2': 0.9913377513324386}'\n",
      "pcr_scale: {'fold_0': 4.3809279511797845, 'fold_1': 4.77921678936133, 'fold_2': 4.2394372762250665, 'fold_3': 4.734060620483084, 'fold_4': 5.198524103084147, 'MSE': 4.666416096572916, 'R2': 0.9922355985906977}'\n",
      "pcr_whiten: {'fold_0': 2.8548531459773097, 'fold_1': 3.3400286665154852, 'fold_2': 2.887800600005997, 'fold_3': 3.3871185404414375, 'fold_4': 14.740253931462611, 'MSE': 5.4415426248888314, 'R2': 0.9909458735888351}'\n",
      "pcr_s_w: {'fold_0': 4.384789567034777, 'fold_1': 4.7768149150958035, 'fold_2': 4.22213243934755, 'fold_3': 4.714379274819447, 'fold_4': 5.227942451546864, 'MSE': 4.665194867905184, 'R2': 0.9922376305804287}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 72 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.823,pcr_scale:4.3187,pcr_whiten:2.8359,pcr_s_w:4.3025'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8294,pcr_scale:4.3478,pcr_whiten:2.8377,pcr_s_w:4.3739'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0713,pcr_scale:4.3068,pcr_whiten:3.0869,pcr_s_w:4.308'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3014,pcr_scale:4.809,pcr_whiten:3.3195,pcr_s_w:4.787'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1179,pcr_scale:4.4395,pcr_whiten:3.1192,pcr_s_w:4.4382'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.898,pcr_scale:4.2595,pcr_whiten:2.898,pcr_s_w:4.2818'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.131,pcr_scale:4.4648,pcr_whiten:3.1094,pcr_s_w:4.4538'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3919,pcr_scale:4.7046,pcr_whiten:3.3858,pcr_s_w:4.7029'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7097,pcr_scale:4.2405,pcr_whiten:2.7502,pcr_s_w:4.2268'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:14.5076,pcr_scale:5.2334,pcr_whiten:13.8751,pcr_s_w:5.2548'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.0391,pcr_scale:4.3522,pcr_whiten:3.0425,pcr_s_w:4.3447'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9276,pcr_scale:4.6361,pcr_whiten:2.923,pcr_s_w:4.6615'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 5, 'mean': 4.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.829388448682214, 'pcr_scale': 4.347791425404146, 'pcr_whiten': 2.8377181062218284, 'pcr_s_w': 4.373915476434526}, 'fold_1': {'pcr': 3.30143338709357, 'pcr_scale': 4.809043577164385, 'pcr_whiten': 3.3194899662097614, 'pcr_s_w': 4.787017973640534}, 'fold_2': {'pcr': 2.8979859653182016, 'pcr_scale': 4.259507140338391, 'pcr_whiten': 2.897980392691827, 'pcr_s_w': 4.281830734624522}, 'fold_3': {'pcr': 3.391867973373978, 'pcr_scale': 4.704638068750396, 'pcr_whiten': 3.385762625609211, 'pcr_s_w': 4.7028643347401315}, 'fold_4': {'pcr': 14.507589692676671, 'pcr_scale': 5.233376022250804, 'pcr_whiten': 13.875075776684568, 'pcr_s_w': 5.254751070581297}, 'MSE': {'pcr': 5.3851896011845115, 'pcr_scale': 4.6708527781948295, 'pcr_whiten': 5.262768976891895, 'pcr_s_w': 4.680056020043162}, 'R2': {'pcr': 0.9910396388012837, 'pcr_scale': 0.9922282164421011, 'pcr_whiten': 0.9912433332100363, 'pcr_s_w': 0.992212903263315}}'\n",
      "pcr: {'fold_0': 2.829388448682214, 'fold_1': 3.30143338709357, 'fold_2': 2.8979859653182016, 'fold_3': 3.391867973373978, 'fold_4': 14.507589692676671, 'MSE': 5.3851896011845115, 'R2': 0.9910396388012837}'\n",
      "pcr_scale: {'fold_0': 4.347791425404146, 'fold_1': 4.809043577164385, 'fold_2': 4.259507140338391, 'fold_3': 4.704638068750396, 'fold_4': 5.233376022250804, 'MSE': 4.6708527781948295, 'R2': 0.9922282164421011}'\n",
      "pcr_whiten: {'fold_0': 2.8377181062218284, 'fold_1': 3.3194899662097614, 'fold_2': 2.897980392691827, 'fold_3': 3.385762625609211, 'fold_4': 13.875075776684568, 'MSE': 5.262768976891895, 'R2': 0.9912433332100363}'\n",
      "pcr_s_w: {'fold_0': 4.373915476434526, 'fold_1': 4.787017973640534, 'fold_2': 4.281830734624522, 'fold_3': 4.7028643347401315, 'fold_4': 5.254751070581297, 'MSE': 4.680056020043162, 'R2': 0.992212903263315}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 73 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8101,pcr_scale:4.2998,pcr_whiten:2.8307,pcr_s_w:4.3088'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8086,pcr_scale:4.383,pcr_whiten:2.8525,pcr_s_w:4.3544'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0729,pcr_scale:4.3008,pcr_whiten:3.0726,pcr_s_w:4.2958'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3066,pcr_scale:4.7902,pcr_whiten:3.2961,pcr_s_w:4.7725'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1151,pcr_scale:4.4121,pcr_whiten:3.1161,pcr_s_w:4.3857'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8936,pcr_scale:4.2309,pcr_whiten:2.8853,pcr_s_w:4.1941'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1276,pcr_scale:4.4647,pcr_whiten:3.127,pcr_s_w:4.4815'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.382,pcr_scale:4.7036,pcr_whiten:3.3915,pcr_s_w:4.7433'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7248,pcr_scale:4.2298,pcr_whiten:2.7083,pcr_s_w:4.2313'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:14.2482,pcr_scale:5.2454,pcr_whiten:14.569,pcr_s_w:5.2041'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.0223,pcr_scale:4.3383,pcr_whiten:3.0325,pcr_s_w:4.328'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9208,pcr_scale:4.6177,pcr_whiten:2.9212,pcr_s_w:4.6172'\n",
      "Train times: {'fold_0': 5, 'fold_1': 5, 'fold_2': 5, 'fold_3': 5, 'fold_4': 5, 'mean': 5.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.8085795374245963, 'pcr_scale': 4.383002652308217, 'pcr_whiten': 2.85249263290732, 'pcr_s_w': 4.354350600585811}, 'fold_1': {'pcr': 3.306635356075226, 'pcr_scale': 4.790248368909594, 'pcr_whiten': 3.2961113341862736, 'pcr_s_w': 4.772546899873968}, 'fold_2': {'pcr': 2.8935922098282356, 'pcr_scale': 4.230872152775115, 'pcr_whiten': 2.8852709637394054, 'pcr_s_w': 4.194147122005211}, 'fold_3': {'pcr': 3.382011837997499, 'pcr_scale': 4.703578116275557, 'pcr_whiten': 3.3915359742795737, 'pcr_s_w': 4.743312933891271}, 'fold_4': {'pcr': 14.248174824916699, 'pcr_scale': 5.245404581707247, 'pcr_whiten': 14.56897868571382, 'pcr_s_w': 5.20410974055235}, 'MSE': {'pcr': 5.327345259180033, 'pcr_scale': 4.670604395397187, 'pcr_whiten': 5.398413560207904, 'pcr_s_w': 4.653675432072663}, 'R2': {'pcr': 0.991135885402805, 'pcr_scale': 0.9922286297236654, 'pcr_whiten': 0.9910176355928357, 'pcr_s_w': 0.9922567976503944}}'\n",
      "pcr: {'fold_0': 2.8085795374245963, 'fold_1': 3.306635356075226, 'fold_2': 2.8935922098282356, 'fold_3': 3.382011837997499, 'fold_4': 14.248174824916699, 'MSE': 5.327345259180033, 'R2': 0.991135885402805}'\n",
      "pcr_scale: {'fold_0': 4.383002652308217, 'fold_1': 4.790248368909594, 'fold_2': 4.230872152775115, 'fold_3': 4.703578116275557, 'fold_4': 5.245404581707247, 'MSE': 4.670604395397187, 'R2': 0.9922286297236654}'\n",
      "pcr_whiten: {'fold_0': 2.85249263290732, 'fold_1': 3.2961113341862736, 'fold_2': 2.8852709637394054, 'fold_3': 3.3915359742795737, 'fold_4': 14.56897868571382, 'MSE': 5.398413560207904, 'R2': 0.9910176355928357}'\n",
      "pcr_s_w: {'fold_0': 4.354350600585811, 'fold_1': 4.772546899873968, 'fold_2': 4.194147122005211, 'fold_3': 4.743312933891271, 'fold_4': 5.20410974055235, 'MSE': 4.653675432072663, 'R2': 0.9922567976503944}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 74 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8213,pcr_scale:4.2666,pcr_whiten:2.8308,pcr_s_w:4.3002'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8212,pcr_scale:4.3521,pcr_whiten:2.8189,pcr_s_w:4.4049'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0707,pcr_scale:4.3111,pcr_whiten:3.0752,pcr_s_w:4.2815'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2994,pcr_scale:4.7581,pcr_whiten:3.3148,pcr_s_w:4.7451'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.118,pcr_scale:4.4019,pcr_whiten:3.1168,pcr_s_w:4.386'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8931,pcr_scale:4.2108,pcr_whiten:2.9013,pcr_s_w:4.2676'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1258,pcr_scale:4.4705,pcr_whiten:3.1123,pcr_s_w:4.4731'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3844,pcr_scale:4.7142,pcr_whiten:3.3776,pcr_s_w:4.7281'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6839,pcr_scale:4.2435,pcr_whiten:2.7041,pcr_s_w:4.2614'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:14.9441,pcr_scale:5.2451,pcr_whiten:15.3283,pcr_s_w:5.264'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.0351,pcr_scale:4.3269,pcr_whiten:3.0184,pcr_s_w:4.3496'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.925,pcr_scale:4.5939,pcr_whiten:2.9191,pcr_s_w:4.664'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.8212241047763142, 'pcr_scale': 4.352106144649106, 'pcr_whiten': 2.818857288237587, 'pcr_s_w': 4.404880140488574}, 'fold_1': {'pcr': 3.2993765844078204, 'pcr_scale': 4.758141795821787, 'pcr_whiten': 3.314831528239216, 'pcr_s_w': 4.745074092934411}, 'fold_2': {'pcr': 2.893095127573283, 'pcr_scale': 4.210822802294543, 'pcr_whiten': 2.9012504584876315, 'pcr_s_w': 4.267621355819817}, 'fold_3': {'pcr': 3.3844381796499454, 'pcr_scale': 4.714246712934368, 'pcr_whiten': 3.3776435299473557, 'pcr_s_w': 4.728073614203582}, 'fold_4': {'pcr': 14.94411454114349, 'pcr_scale': 5.2451335345981205, 'pcr_whiten': 15.328339823192985, 'pcr_s_w': 5.263973843153242}, 'MSE': {'pcr': 5.4679686549007185, 'pcr_scale': 4.656070029016871, 'pcr_whiten': 5.5476888524053365, 'pcr_s_w': 4.681903245458038}, 'R2': {'pcr': 0.9909019035912138, 'pcr_scale': 0.9922528133053417, 'pcr_whiten': 0.9907692579803113, 'pcr_s_w': 0.9922098296840804}}'\n",
      "pcr: {'fold_0': 2.8212241047763142, 'fold_1': 3.2993765844078204, 'fold_2': 2.893095127573283, 'fold_3': 3.3844381796499454, 'fold_4': 14.94411454114349, 'MSE': 5.4679686549007185, 'R2': 0.9909019035912138}'\n",
      "pcr_scale: {'fold_0': 4.352106144649106, 'fold_1': 4.758141795821787, 'fold_2': 4.210822802294543, 'fold_3': 4.714246712934368, 'fold_4': 5.2451335345981205, 'MSE': 4.656070029016871, 'R2': 0.9922528133053417}'\n",
      "pcr_whiten: {'fold_0': 2.818857288237587, 'fold_1': 3.314831528239216, 'fold_2': 2.9012504584876315, 'fold_3': 3.3776435299473557, 'fold_4': 15.328339823192985, 'MSE': 5.5476888524053365, 'R2': 0.9907692579803113}'\n",
      "pcr_s_w: {'fold_0': 4.404880140488574, 'fold_1': 4.745074092934411, 'fold_2': 4.267621355819817, 'fold_3': 4.728073614203582, 'fold_4': 5.263973843153242, 'MSE': 4.681903245458038, 'R2': 0.9922098296840804}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 75 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8302,pcr_scale:4.3174,pcr_whiten:2.8017,pcr_s_w:4.3214'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8274,pcr_scale:4.3784,pcr_whiten:2.8128,pcr_s_w:4.3483'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0706,pcr_scale:4.3012,pcr_whiten:3.0741,pcr_s_w:4.3396'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3088,pcr_scale:4.7778,pcr_whiten:3.3075,pcr_s_w:4.7798'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1105,pcr_scale:4.4255,pcr_whiten:3.1079,pcr_s_w:4.4152'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8828,pcr_scale:4.2556,pcr_whiten:2.8891,pcr_s_w:4.2779'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1224,pcr_scale:4.4537,pcr_whiten:3.1159,pcr_s_w:4.4549'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3856,pcr_scale:4.7338,pcr_whiten:3.3701,pcr_s_w:4.6817'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6981,pcr_scale:4.226,pcr_whiten:2.7122,pcr_s_w:4.2105'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:14.0575,pcr_scale:5.2469,pcr_whiten:14.2977,pcr_s_w:5.2727'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.0121,pcr_scale:4.3361,pcr_whiten:3.0291,pcr_s_w:4.3396'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9244,pcr_scale:4.6453,pcr_whiten:2.9225,pcr_s_w:4.7002'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 5, 'fold_4': 4, 'mean': 4.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.8274483549869274, 'pcr_scale': 4.378417575807408, 'pcr_whiten': 2.8127814557048048, 'pcr_s_w': 4.348309318681557}, 'fold_1': {'pcr': 3.3087672968552755, 'pcr_scale': 4.777834766886325, 'pcr_whiten': 3.3074869888010863, 'pcr_s_w': 4.779814907226796}, 'fold_2': {'pcr': 2.8827822707259423, 'pcr_scale': 4.255609876651353, 'pcr_whiten': 2.889143185260523, 'pcr_s_w': 4.2778939731387045}, 'fold_3': {'pcr': 3.385556825262888, 'pcr_scale': 4.733830125841339, 'pcr_whiten': 3.370114440328761, 'pcr_s_w': 4.681731645581447}, 'fold_4': {'pcr': 14.057465507114214, 'pcr_scale': 5.246875195914639, 'pcr_whiten': 14.297706889667978, 'pcr_s_w': 5.272686821593273}, 'MSE': {'pcr': 5.2919597249353, 'pcr_scale': 4.678493454816922, 'pcr_whiten': 5.334992074899155, 'pcr_s_w': 4.672065754095277}, 'R2': {'pcr': 0.9911947630267187, 'pcr_scale': 0.9922155031994102, 'pcr_whiten': 0.9911231619453341, 'pcr_s_w': 0.9922261981840642}}'\n",
      "pcr: {'fold_0': 2.8274483549869274, 'fold_1': 3.3087672968552755, 'fold_2': 2.8827822707259423, 'fold_3': 3.385556825262888, 'fold_4': 14.057465507114214, 'MSE': 5.2919597249353, 'R2': 0.9911947630267187}'\n",
      "pcr_scale: {'fold_0': 4.378417575807408, 'fold_1': 4.777834766886325, 'fold_2': 4.255609876651353, 'fold_3': 4.733830125841339, 'fold_4': 5.246875195914639, 'MSE': 4.678493454816922, 'R2': 0.9922155031994102}'\n",
      "pcr_whiten: {'fold_0': 2.8127814557048048, 'fold_1': 3.3074869888010863, 'fold_2': 2.889143185260523, 'fold_3': 3.370114440328761, 'fold_4': 14.297706889667978, 'MSE': 5.334992074899155, 'R2': 0.9911231619453341}'\n",
      "pcr_s_w: {'fold_0': 4.348309318681557, 'fold_1': 4.779814907226796, 'fold_2': 4.2778939731387045, 'fold_3': 4.681731645581447, 'fold_4': 5.272686821593273, 'MSE': 4.672065754095277, 'R2': 0.9922261981840642}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 76 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8172,pcr_scale:4.2686,pcr_whiten:2.8161,pcr_s_w:4.2604'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8164,pcr_scale:4.364,pcr_whiten:2.8238,pcr_s_w:4.3516'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0739,pcr_scale:4.3259,pcr_whiten:3.0784,pcr_s_w:4.3399'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3081,pcr_scale:4.8058,pcr_whiten:3.3081,pcr_s_w:4.7793'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1116,pcr_scale:4.3962,pcr_whiten:3.1056,pcr_s_w:4.4056'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8883,pcr_scale:4.2498,pcr_whiten:2.8851,pcr_s_w:4.2401'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0873,pcr_scale:4.496,pcr_whiten:3.111,pcr_s_w:4.4567'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3895,pcr_scale:4.6951,pcr_whiten:3.3761,pcr_s_w:4.7238'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6964,pcr_scale:4.2242,pcr_whiten:2.6787,pcr_s_w:4.2254'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:14.5639,pcr_scale:5.2479,pcr_whiten:15.2824,pcr_s_w:5.2504'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.0161,pcr_scale:4.3066,pcr_whiten:3.0112,pcr_s_w:4.3084'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9159,pcr_scale:4.6608,pcr_whiten:2.9149,pcr_s_w:4.6162'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.816440027418386, 'pcr_scale': 4.364048314662949, 'pcr_whiten': 2.8237979634802275, 'pcr_s_w': 4.351567450720377}, 'fold_1': {'pcr': 3.308071005616297, 'pcr_scale': 4.805847857786592, 'pcr_whiten': 3.3081022880657844, 'pcr_s_w': 4.77925758736343}, 'fold_2': {'pcr': 2.8883019639757435, 'pcr_scale': 4.249757391485085, 'pcr_whiten': 2.8850802401821074, 'pcr_s_w': 4.240145369119115}, 'fold_3': {'pcr': 3.389534040245997, 'pcr_scale': 4.695106717111714, 'pcr_whiten': 3.376148235461597, 'pcr_s_w': 4.723809686273131}, 'fold_4': {'pcr': 14.563928673788153, 'pcr_scale': 5.247905500586624, 'pcr_whiten': 15.282436110957098, 'pcr_s_w': 5.250369054185094}, 'MSE': {'pcr': 5.392789501053165, 'pcr_scale': 4.672515660307795, 'pcr_whiten': 5.534619726949807, 'pcr_s_w': 4.66900913090848}, 'R2': {'pcr': 0.9910269934066104, 'pcr_scale': 0.9922254495897772, 'pcr_whiten': 0.9907910035627895, 'pcr_s_w': 0.9922312840677249}}'\n",
      "pcr: {'fold_0': 2.816440027418386, 'fold_1': 3.308071005616297, 'fold_2': 2.8883019639757435, 'fold_3': 3.389534040245997, 'fold_4': 14.563928673788153, 'MSE': 5.392789501053165, 'R2': 0.9910269934066104}'\n",
      "pcr_scale: {'fold_0': 4.364048314662949, 'fold_1': 4.805847857786592, 'fold_2': 4.249757391485085, 'fold_3': 4.695106717111714, 'fold_4': 5.247905500586624, 'MSE': 4.672515660307795, 'R2': 0.9922254495897772}'\n",
      "pcr_whiten: {'fold_0': 2.8237979634802275, 'fold_1': 3.3081022880657844, 'fold_2': 2.8850802401821074, 'fold_3': 3.376148235461597, 'fold_4': 15.282436110957098, 'MSE': 5.534619726949807, 'R2': 0.9907910035627895}'\n",
      "pcr_s_w: {'fold_0': 4.351567450720377, 'fold_1': 4.77925758736343, 'fold_2': 4.240145369119115, 'fold_3': 4.723809686273131, 'fold_4': 5.250369054185094, 'MSE': 4.66900913090848, 'R2': 0.9922312840677249}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 77 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.818,pcr_scale:4.2902,pcr_whiten:2.8074,pcr_s_w:4.2681'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8146,pcr_scale:4.4023,pcr_whiten:2.7949,pcr_s_w:4.35'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0705,pcr_scale:4.2768,pcr_whiten:3.0663,pcr_s_w:4.2331'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3047,pcr_scale:4.7436,pcr_whiten:3.2947,pcr_s_w:4.709'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1148,pcr_scale:4.4148,pcr_whiten:3.1012,pcr_s_w:4.3499'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8993,pcr_scale:4.1708,pcr_whiten:2.8772,pcr_s_w:4.2097'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0899,pcr_scale:4.4627,pcr_whiten:3.1074,pcr_s_w:4.4527'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4055,pcr_scale:4.6776,pcr_whiten:3.3795,pcr_s_w:4.6998'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6743,pcr_scale:4.2355,pcr_whiten:2.6853,pcr_s_w:4.1962'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:15.6828,pcr_scale:5.242,pcr_whiten:15.04,pcr_s_w:5.2553'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.017,pcr_scale:4.3205,pcr_whiten:3.0109,pcr_s_w:4.348'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9174,pcr_scale:4.6305,pcr_whiten:2.8931,pcr_s_w:4.6406'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.8146107327540086, 'pcr_scale': 4.40228278162269, 'pcr_whiten': 2.794910274174708, 'pcr_s_w': 4.349954741132039}, 'fold_1': {'pcr': 3.3047303903629843, 'pcr_scale': 4.743601812914577, 'pcr_whiten': 3.2946500754738666, 'pcr_s_w': 4.709020673142941}, 'fold_2': {'pcr': 2.899262808241674, 'pcr_scale': 4.1707658021141185, 'pcr_whiten': 2.8772044564763064, 'pcr_s_w': 4.209673115543292}, 'fold_3': {'pcr': 3.4054835781104074, 'pcr_scale': 4.677577235786885, 'pcr_whiten': 3.3794879353096188, 'pcr_s_w': 4.69982184959768}, 'fold_4': {'pcr': 15.682778705466246, 'pcr_scale': 5.241982049219196, 'pcr_whiten': 15.0399675295301, 'pcr_s_w': 5.255294522352992}, 'MSE': {'pcr': 5.620861516522536, 'pcr_scale': 4.647227094214221, 'pcr_whiten': 5.4767581445086675, 'pcr_s_w': 4.644729954929655}, 'R2': {'pcr': 0.9906475067423943, 'pcr_scale': 0.9922675269729665, 'pcr_whiten': 0.9908872788504949, 'pcr_s_w': 0.9922716819371572}}'\n",
      "pcr: {'fold_0': 2.8146107327540086, 'fold_1': 3.3047303903629843, 'fold_2': 2.899262808241674, 'fold_3': 3.4054835781104074, 'fold_4': 15.682778705466246, 'MSE': 5.620861516522536, 'R2': 0.9906475067423943}'\n",
      "pcr_scale: {'fold_0': 4.40228278162269, 'fold_1': 4.743601812914577, 'fold_2': 4.1707658021141185, 'fold_3': 4.677577235786885, 'fold_4': 5.241982049219196, 'MSE': 4.647227094214221, 'R2': 0.9922675269729665}'\n",
      "pcr_whiten: {'fold_0': 2.794910274174708, 'fold_1': 3.2946500754738666, 'fold_2': 2.8772044564763064, 'fold_3': 3.3794879353096188, 'fold_4': 15.0399675295301, 'MSE': 5.4767581445086675, 'R2': 0.9908872788504949}'\n",
      "pcr_s_w: {'fold_0': 4.349954741132039, 'fold_1': 4.709020673142941, 'fold_2': 4.209673115543292, 'fold_3': 4.69982184959768, 'fold_4': 5.255294522352992, 'MSE': 4.644729954929655, 'R2': 0.9922716819371572}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 78 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7965,pcr_scale:4.2672,pcr_whiten:2.7902,pcr_s_w:4.2728'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7937,pcr_scale:4.3658,pcr_whiten:2.7895,pcr_s_w:4.3611'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0649,pcr_scale:4.3022,pcr_whiten:3.0671,pcr_s_w:4.2907'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2995,pcr_scale:4.7284,pcr_whiten:3.2865,pcr_s_w:4.7904'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1085,pcr_scale:4.387,pcr_whiten:3.1072,pcr_s_w:4.3721'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8948,pcr_scale:4.2087,pcr_whiten:2.8857,pcr_s_w:4.2165'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1059,pcr_scale:4.4296,pcr_whiten:3.1043,pcr_s_w:4.4645'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3997,pcr_scale:4.6962,pcr_whiten:3.3718,pcr_s_w:4.7364'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6904,pcr_scale:4.2101,pcr_whiten:2.6903,pcr_s_w:4.2175'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:15.3072,pcr_scale:5.2694,pcr_whiten:15.4,pcr_s_w:5.2495'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:3.0104,pcr_scale:4.3336,pcr_whiten:2.9803,pcr_s_w:4.3292'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.9027,pcr_scale:4.6622,pcr_whiten:2.8824,pcr_s_w:4.6366'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.7936890218107497, 'pcr_scale': 4.365792531145264, 'pcr_whiten': 2.7895420133122393, 'pcr_s_w': 4.361116871616475}, 'fold_1': {'pcr': 3.299512931020239, 'pcr_scale': 4.728419207367108, 'pcr_whiten': 3.2865174733228457, 'pcr_s_w': 4.790355477346725}, 'fold_2': {'pcr': 2.894786301833467, 'pcr_scale': 4.208738823456102, 'pcr_whiten': 2.8856875427167235, 'pcr_s_w': 4.216529648594713}, 'fold_3': {'pcr': 3.3997489804554366, 'pcr_scale': 4.696246909632389, 'pcr_whiten': 3.3717716960359505, 'pcr_s_w': 4.736442311557484}, 'fold_4': {'pcr': 15.307186756112014, 'pcr_scale': 5.2694376776827, 'pcr_whiten': 15.399993790866322, 'pcr_s_w': 5.249528438978781}, 'MSE': {'pcr': 5.5384869189371875, 'pcr_scale': 4.653705731183002, 'pcr_whiten': 5.54620137005866, 'pcr_s_w': 4.670775560730474}, 'R2': {'pcr': 0.9907845689820973, 'pcr_scale': 0.9922567472360185, 'pcr_whiten': 0.990771732986781, 'pcr_s_w': 0.9922283449234404}}'\n",
      "pcr: {'fold_0': 2.7936890218107497, 'fold_1': 3.299512931020239, 'fold_2': 2.894786301833467, 'fold_3': 3.3997489804554366, 'fold_4': 15.307186756112014, 'MSE': 5.5384869189371875, 'R2': 0.9907845689820973}'\n",
      "pcr_scale: {'fold_0': 4.365792531145264, 'fold_1': 4.728419207367108, 'fold_2': 4.208738823456102, 'fold_3': 4.696246909632389, 'fold_4': 5.2694376776827, 'MSE': 4.653705731183002, 'R2': 0.9922567472360185}'\n",
      "pcr_whiten: {'fold_0': 2.7895420133122393, 'fold_1': 3.2865174733228457, 'fold_2': 2.8856875427167235, 'fold_3': 3.3717716960359505, 'fold_4': 15.399993790866322, 'MSE': 5.54620137005866, 'R2': 0.990771732986781}'\n",
      "pcr_s_w: {'fold_0': 4.361116871616475, 'fold_1': 4.790355477346725, 'fold_2': 4.216529648594713, 'fold_3': 4.736442311557484, 'fold_4': 5.249528438978781, 'MSE': 4.670775560730474, 'R2': 0.9922283449234404}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 79 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.8091,pcr_scale:4.2893,pcr_whiten:2.8001,pcr_s_w:4.2533'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7972,pcr_scale:4.4161,pcr_whiten:2.7886,pcr_s_w:4.3807'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0739,pcr_scale:4.2894,pcr_whiten:3.0657,pcr_s_w:4.2624'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3124,pcr_scale:4.7625,pcr_whiten:3.2908,pcr_s_w:4.7398'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.1036,pcr_scale:4.3837,pcr_whiten:3.1006,pcr_s_w:4.3711'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8849,pcr_scale:4.2369,pcr_whiten:2.8921,pcr_s_w:4.2124'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0993,pcr_scale:4.3863,pcr_whiten:3.1132,pcr_s_w:4.4314'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4004,pcr_scale:4.6819,pcr_whiten:3.387,pcr_s_w:4.6725'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6905,pcr_scale:4.1968,pcr_whiten:2.6695,pcr_s_w:4.2176'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:15.1932,pcr_scale:5.2369,pcr_whiten:15.8886,pcr_s_w:5.2634'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9908,pcr_scale:4.3129,pcr_whiten:3.0004,pcr_s_w:4.3175'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8982,pcr_scale:4.6653,pcr_whiten:2.9009,pcr_s_w:4.6634'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.797152707979102, 'pcr_scale': 4.416107525172788, 'pcr_whiten': 2.788581992413416, 'pcr_s_w': 4.380725922816159}, 'fold_1': {'pcr': 3.312426597919143, 'pcr_scale': 4.762464612233237, 'pcr_whiten': 3.2907974403459606, 'pcr_s_w': 4.739830531698174}, 'fold_2': {'pcr': 2.88490359493414, 'pcr_scale': 4.236905798791482, 'pcr_whiten': 2.8920652114123317, 'pcr_s_w': 4.212355597334457}, 'fold_3': {'pcr': 3.4004254601036052, 'pcr_scale': 4.681935477833403, 'pcr_whiten': 3.386980365902059, 'pcr_s_w': 4.672450175493364}, 'fold_4': {'pcr': 15.193173619748102, 'pcr_scale': 5.236856856818242, 'pcr_whiten': 15.88855982881406, 'pcr_s_w': 5.263392738850494}, 'MSE': {'pcr': 5.517124421158156, 'pcr_scale': 4.666838559166741, 'pcr_whiten': 5.648875651906331, 'pcr_s_w': 4.65373232109191}, 'R2': {'pcr': 0.9908201138208834, 'pcr_scale': 0.9922348956595636, 'pcr_whiten': 0.9906008943126939, 'pcr_s_w': 0.9922567029933446}}'\n",
      "pcr: {'fold_0': 2.797152707979102, 'fold_1': 3.312426597919143, 'fold_2': 2.88490359493414, 'fold_3': 3.4004254601036052, 'fold_4': 15.193173619748102, 'MSE': 5.517124421158156, 'R2': 0.9908201138208834}'\n",
      "pcr_scale: {'fold_0': 4.416107525172788, 'fold_1': 4.762464612233237, 'fold_2': 4.236905798791482, 'fold_3': 4.681935477833403, 'fold_4': 5.236856856818242, 'MSE': 4.666838559166741, 'R2': 0.9922348956595636}'\n",
      "pcr_whiten: {'fold_0': 2.788581992413416, 'fold_1': 3.2907974403459606, 'fold_2': 2.8920652114123317, 'fold_3': 3.386980365902059, 'fold_4': 15.88855982881406, 'MSE': 5.648875651906331, 'R2': 0.9906008943126939}'\n",
      "pcr_s_w: {'fold_0': 4.380725922816159, 'fold_1': 4.739830531698174, 'fold_2': 4.212355597334457, 'fold_3': 4.672450175493364, 'fold_4': 5.263392738850494, 'MSE': 4.65373232109191, 'R2': 0.9922567029933446}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 80 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.804,pcr_scale:4.2821,pcr_whiten:2.7898,pcr_s_w:4.2527'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.805,pcr_scale:4.3955,pcr_whiten:2.8049,pcr_s_w:4.3549'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0647,pcr_scale:4.3063,pcr_whiten:3.0629,pcr_s_w:4.307'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.3005,pcr_scale:4.7763,pcr_whiten:3.2886,pcr_s_w:4.7574'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0866,pcr_scale:4.3871,pcr_whiten:3.0903,pcr_s_w:4.385'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8733,pcr_scale:4.2668,pcr_whiten:2.8909,pcr_s_w:4.2387'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0671,pcr_scale:4.4533,pcr_whiten:3.1004,pcr_s_w:4.414'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3833,pcr_scale:4.707,pcr_whiten:3.3841,pcr_s_w:4.6884'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.677,pcr_scale:4.2221,pcr_whiten:2.6766,pcr_s_w:4.2229'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:15.71,pcr_scale:5.2262,pcr_whiten:16.1442,pcr_s_w:5.2798'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9863,pcr_scale:4.3136,pcr_whiten:2.9927,pcr_s_w:4.3433'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.886,pcr_scale:4.6214,pcr_whiten:2.8807,pcr_s_w:4.6587'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.804986151763569, 'pcr_scale': 4.395459271135235, 'pcr_whiten': 2.8049279115467116, 'pcr_s_w': 4.354916078785717}, 'fold_1': {'pcr': 3.3005339148284323, 'pcr_scale': 4.776328504912455, 'pcr_whiten': 3.288583559687708, 'pcr_s_w': 4.757402510795934}, 'fold_2': {'pcr': 2.873265852901784, 'pcr_scale': 4.2667828176980285, 'pcr_whiten': 2.890887133691888, 'pcr_s_w': 4.238680537124236}, 'fold_3': {'pcr': 3.383311530892117, 'pcr_scale': 4.7069999351473, 'pcr_whiten': 3.3840743277179506, 'pcr_s_w': 4.688398557696082}, 'fold_4': {'pcr': 15.710024391527135, 'pcr_scale': 5.2262008799981325, 'pcr_whiten': 16.144247421038724, 'pcr_s_w': 5.279777122942739}, 'MSE': {'pcr': 5.613912649578155, 'pcr_scale': 4.674336610904527, 'pcr_whiten': 5.702013549694823, 'pcr_s_w': 4.663813452146791}, 'R2': {'pcr': 0.9906590688901281, 'pcr_scale': 0.9922224197289403, 'pcr_whiten': 0.9905124787149551, 'pcr_s_w': 0.9922399291038007}}'\n",
      "pcr: {'fold_0': 2.804986151763569, 'fold_1': 3.3005339148284323, 'fold_2': 2.873265852901784, 'fold_3': 3.383311530892117, 'fold_4': 15.710024391527135, 'MSE': 5.613912649578155, 'R2': 0.9906590688901281}'\n",
      "pcr_scale: {'fold_0': 4.395459271135235, 'fold_1': 4.776328504912455, 'fold_2': 4.2667828176980285, 'fold_3': 4.7069999351473, 'fold_4': 5.2262008799981325, 'MSE': 4.674336610904527, 'R2': 0.9922224197289403}'\n",
      "pcr_whiten: {'fold_0': 2.8049279115467116, 'fold_1': 3.288583559687708, 'fold_2': 2.890887133691888, 'fold_3': 3.3840743277179506, 'fold_4': 16.144247421038724, 'MSE': 5.702013549694823, 'R2': 0.9905124787149551}'\n",
      "pcr_s_w: {'fold_0': 4.354916078785717, 'fold_1': 4.757402510795934, 'fold_2': 4.238680537124236, 'fold_3': 4.688398557696082, 'fold_4': 5.279777122942739, 'MSE': 4.663813452146791, 'R2': 0.9922399291038007}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 81 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7882,pcr_scale:4.2797,pcr_whiten:2.7871,pcr_s_w:4.2577'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7968,pcr_scale:4.406,pcr_whiten:2.7727,pcr_s_w:4.351'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0613,pcr_scale:4.2745,pcr_whiten:3.0528,pcr_s_w:4.2796'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2978,pcr_scale:4.7613,pcr_whiten:3.2842,pcr_s_w:4.7601'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0963,pcr_scale:4.3605,pcr_whiten:3.0939,pcr_s_w:4.3828'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8924,pcr_scale:4.2031,pcr_whiten:2.8896,pcr_s_w:4.1875'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0694,pcr_scale:4.3985,pcr_whiten:3.0714,pcr_s_w:4.4274'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3782,pcr_scale:4.6616,pcr_whiten:3.3799,pcr_s_w:4.6985'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.672,pcr_scale:4.1976,pcr_whiten:2.673,pcr_s_w:4.2124'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:15.7172,pcr_scale:5.2439,pcr_whiten:16.0213,pcr_s_w:5.2294'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9899,pcr_scale:4.3286,pcr_whiten:2.9929,pcr_s_w:4.3037'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8793,pcr_scale:4.6202,pcr_whiten:2.8768,pcr_s_w:4.6506'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.7967626300496855, 'pcr_scale': 4.406018246247392, 'pcr_whiten': 2.7727067438779014, 'pcr_s_w': 4.3509955512006355}, 'fold_1': {'pcr': 3.297815859143678, 'pcr_scale': 4.761328338826867, 'pcr_whiten': 3.284162033173946, 'pcr_s_w': 4.7600868561795435}, 'fold_2': {'pcr': 2.8924176270957913, 'pcr_scale': 4.20307271504248, 'pcr_whiten': 2.8896173694924663, 'pcr_s_w': 4.187473566725909}, 'fold_3': {'pcr': 3.37818729215335, 'pcr_scale': 4.66159173140492, 'pcr_whiten': 3.379905783618802, 'pcr_s_w': 4.698481419859835}, 'fold_4': {'pcr': 15.717230320303957, 'pcr_scale': 5.243938372692959, 'pcr_whiten': 16.021264850644062, 'pcr_s_w': 5.229432524284916}, 'MSE': {'pcr': 5.615969522916461, 'pcr_scale': 4.6551755946686715, 'pcr_whiten': 5.669003769871456, 'pcr_s_w': 4.645276054609026}, 'R2': {'pcr': 0.9906556464798851, 'pcr_scale': 0.9922543015453893, 'pcr_whiten': 0.9905674033456946, 'pcr_s_w': 0.9922707732875571}}'\n",
      "pcr: {'fold_0': 2.7967626300496855, 'fold_1': 3.297815859143678, 'fold_2': 2.8924176270957913, 'fold_3': 3.37818729215335, 'fold_4': 15.717230320303957, 'MSE': 5.615969522916461, 'R2': 0.9906556464798851}'\n",
      "pcr_scale: {'fold_0': 4.406018246247392, 'fold_1': 4.761328338826867, 'fold_2': 4.20307271504248, 'fold_3': 4.66159173140492, 'fold_4': 5.243938372692959, 'MSE': 4.6551755946686715, 'R2': 0.9922543015453893}'\n",
      "pcr_whiten: {'fold_0': 2.7727067438779014, 'fold_1': 3.284162033173946, 'fold_2': 2.8896173694924663, 'fold_3': 3.379905783618802, 'fold_4': 16.021264850644062, 'MSE': 5.669003769871456, 'R2': 0.9905674033456946}'\n",
      "pcr_s_w: {'fold_0': 4.3509955512006355, 'fold_1': 4.7600868561795435, 'fold_2': 4.187473566725909, 'fold_3': 4.698481419859835, 'fold_4': 5.229432524284916, 'MSE': 4.645276054609026, 'R2': 0.9922707732875571}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 82 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7902,pcr_scale:4.2662,pcr_whiten:2.7919,pcr_s_w:4.2975'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7934,pcr_scale:4.3785,pcr_whiten:2.7872,pcr_s_w:4.3801'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0493,pcr_scale:4.2961,pcr_whiten:3.0526,pcr_s_w:4.2747'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2867,pcr_scale:4.7182,pcr_whiten:3.3013,pcr_s_w:4.7569'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0922,pcr_scale:4.353,pcr_whiten:3.0947,pcr_s_w:4.3422'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8752,pcr_scale:4.2185,pcr_whiten:2.881,pcr_s_w:4.2094'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0745,pcr_scale:4.4323,pcr_whiten:3.0881,pcr_s_w:4.4162'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3967,pcr_scale:4.6795,pcr_whiten:3.3698,pcr_s_w:4.6943'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6553,pcr_scale:4.208,pcr_whiten:2.6778,pcr_s_w:4.2068'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:16.9775,pcr_scale:5.2838,pcr_whiten:15.4406,pcr_s_w:5.279'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9894,pcr_scale:4.3188,pcr_whiten:2.9921,pcr_s_w:4.3328'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8989,pcr_scale:4.6419,pcr_whiten:2.8806,pcr_s_w:4.7059'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 5, 'fold_4': 4, 'mean': 4.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.7933744348539054, 'pcr_scale': 4.378485544364505, 'pcr_whiten': 2.7871566931652794, 'pcr_s_w': 4.380063423074936}, 'fold_1': {'pcr': 3.286688108217832, 'pcr_scale': 4.718243557867255, 'pcr_whiten': 3.3013495386069054, 'pcr_s_w': 4.756919924624099}, 'fold_2': {'pcr': 2.875230205238457, 'pcr_scale': 4.21849630083142, 'pcr_whiten': 2.8809633328876862, 'pcr_s_w': 4.209398308125189}, 'fold_3': {'pcr': 3.396663821416952, 'pcr_scale': 4.679491788923585, 'pcr_whiten': 3.3698309221365004, 'pcr_s_w': 4.6943323676860045}, 'fold_4': {'pcr': 16.97746863759574, 'pcr_scale': 5.283833229873857, 'pcr_whiten': 15.440615985030377, 'pcr_s_w': 5.278985860118895}, 'MSE': {'pcr': 5.865320548102625, 'pcr_scale': 4.655688640997522, 'pcr_whiten': 5.5554815504223845, 'pcr_s_w': 4.663920909945386}, 'R2': {'pcr': 0.9902407538918049, 'pcr_scale': 0.9922534478929167, 'pcr_whiten': 0.9907562917907959, 'pcr_s_w': 0.9922397503058825}}'\n",
      "pcr: {'fold_0': 2.7933744348539054, 'fold_1': 3.286688108217832, 'fold_2': 2.875230205238457, 'fold_3': 3.396663821416952, 'fold_4': 16.97746863759574, 'MSE': 5.865320548102625, 'R2': 0.9902407538918049}'\n",
      "pcr_scale: {'fold_0': 4.378485544364505, 'fold_1': 4.718243557867255, 'fold_2': 4.21849630083142, 'fold_3': 4.679491788923585, 'fold_4': 5.283833229873857, 'MSE': 4.655688640997522, 'R2': 0.9922534478929167}'\n",
      "pcr_whiten: {'fold_0': 2.7871566931652794, 'fold_1': 3.3013495386069054, 'fold_2': 2.8809633328876862, 'fold_3': 3.3698309221365004, 'fold_4': 15.440615985030377, 'MSE': 5.5554815504223845, 'R2': 0.9907562917907959}'\n",
      "pcr_s_w: {'fold_0': 4.380063423074936, 'fold_1': 4.756919924624099, 'fold_2': 4.209398308125189, 'fold_3': 4.6943323676860045, 'fold_4': 5.278985860118895, 'MSE': 4.663920909945386, 'R2': 0.9922397503058825}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 83 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7971,pcr_scale:4.2462,pcr_whiten:2.7887,pcr_s_w:4.2644'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.792,pcr_scale:4.357,pcr_whiten:2.7839,pcr_s_w:4.3818'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.031,pcr_scale:4.2585,pcr_whiten:3.0423,pcr_s_w:4.2767'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2861,pcr_scale:4.7337,pcr_whiten:3.2971,pcr_s_w:4.7211'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0915,pcr_scale:4.3623,pcr_whiten:3.0915,pcr_s_w:4.3657'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8827,pcr_scale:4.2345,pcr_whiten:2.8841,pcr_s_w:4.1947'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0745,pcr_scale:4.4286,pcr_whiten:3.0719,pcr_s_w:4.4413'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3957,pcr_scale:4.6859,pcr_whiten:3.3884,pcr_s_w:4.7005'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6543,pcr_scale:4.1884,pcr_whiten:2.6642,pcr_s_w:4.188'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:16.1338,pcr_scale:5.2744,pcr_whiten:16.4917,pcr_s_w:5.2876'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.991,pcr_scale:4.3005,pcr_whiten:2.9982,pcr_s_w:4.2883'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8754,pcr_scale:4.5933,pcr_whiten:2.9042,pcr_s_w:4.6161'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.792042085821202, 'pcr_scale': 4.3570339442746535, 'pcr_whiten': 2.7839408981657434, 'pcr_s_w': 4.381811034737735}, 'fold_1': {'pcr': 3.286107896542051, 'pcr_scale': 4.733721284292899, 'pcr_whiten': 3.297073201028389, 'pcr_s_w': 4.7211236023480705}, 'fold_2': {'pcr': 2.8826579933010987, 'pcr_scale': 4.234501289896084, 'pcr_whiten': 2.8841346534058343, 'pcr_s_w': 4.19471300931148}, 'fold_3': {'pcr': 3.3957474828996377, 'pcr_scale': 4.685942635857466, 'pcr_whiten': 3.3883600613197076, 'pcr_s_w': 4.700524971734792}, 'fold_4': {'pcr': 16.133830036692938, 'pcr_scale': 5.274417838928982, 'pcr_whiten': 16.491679148138783, 'pcr_s_w': 5.287571883624512}, 'MSE': {'pcr': 5.697545936025442, 'pcr_scale': 4.657101076279988, 'pcr_whiten': 5.768492540365585, 'pcr_s_w': 4.657127789368135}, 'R2': {'pcr': 0.990519912331065, 'pcr_scale': 0.99225109775648, 'pcr_whiten': 0.9904018650109538, 'pcr_s_w': 0.9922510533088493}}'\n",
      "pcr: {'fold_0': 2.792042085821202, 'fold_1': 3.286107896542051, 'fold_2': 2.8826579933010987, 'fold_3': 3.3957474828996377, 'fold_4': 16.133830036692938, 'MSE': 5.697545936025442, 'R2': 0.990519912331065}'\n",
      "pcr_scale: {'fold_0': 4.3570339442746535, 'fold_1': 4.733721284292899, 'fold_2': 4.234501289896084, 'fold_3': 4.685942635857466, 'fold_4': 5.274417838928982, 'MSE': 4.657101076279988, 'R2': 0.99225109775648}'\n",
      "pcr_whiten: {'fold_0': 2.7839408981657434, 'fold_1': 3.297073201028389, 'fold_2': 2.8841346534058343, 'fold_3': 3.3883600613197076, 'fold_4': 16.491679148138783, 'MSE': 5.768492540365585, 'R2': 0.9904018650109538}'\n",
      "pcr_s_w: {'fold_0': 4.381811034737735, 'fold_1': 4.7211236023480705, 'fold_2': 4.19471300931148, 'fold_3': 4.700524971734792, 'fold_4': 5.287571883624512, 'MSE': 4.657127789368135, 'R2': 0.9922510533088493}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 84 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7706,pcr_scale:4.2554,pcr_whiten:2.7997,pcr_s_w:4.2531'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7621,pcr_scale:4.3357,pcr_whiten:2.8039,pcr_s_w:4.3789'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0529,pcr_scale:4.2705,pcr_whiten:3.0462,pcr_s_w:4.2839'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2926,pcr_scale:4.74,pcr_whiten:3.2901,pcr_s_w:4.7583'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0959,pcr_scale:4.3611,pcr_whiten:3.093,pcr_s_w:4.3381'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8971,pcr_scale:4.2148,pcr_whiten:2.8776,pcr_s_w:4.1645'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0819,pcr_scale:4.4277,pcr_whiten:3.0755,pcr_s_w:4.4212'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3736,pcr_scale:4.7022,pcr_whiten:3.3727,pcr_s_w:4.6832'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.643,pcr_scale:4.2024,pcr_whiten:2.6441,pcr_s_w:4.205'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:16.626,pcr_scale:5.2537,pcr_whiten:16.9045,pcr_s_w:5.2237'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9763,pcr_scale:4.3235,pcr_whiten:2.9883,pcr_s_w:4.3092'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8607,pcr_scale:4.6308,pcr_whiten:2.8731,pcr_s_w:4.6327'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.7620878868936423, 'pcr_scale': 4.335701037485809, 'pcr_whiten': 2.803868436340324, 'pcr_s_w': 4.378947170939245}, 'fold_1': {'pcr': 3.2925791641453785, 'pcr_scale': 4.739988618253007, 'pcr_whiten': 3.2901348981968654, 'pcr_s_w': 4.758306588675729}, 'fold_2': {'pcr': 2.897064935113392, 'pcr_scale': 4.214848181114851, 'pcr_whiten': 2.8775820760385242, 'pcr_s_w': 4.164509069755404}, 'fold_3': {'pcr': 3.373553543795674, 'pcr_scale': 4.70216136244181, 'pcr_whiten': 3.3727028612704824, 'pcr_s_w': 4.683249392043082}, 'fold_4': {'pcr': 16.62600272316021, 'pcr_scale': 5.253689929851811, 'pcr_whiten': 16.904526013562755, 'pcr_s_w': 5.223689805096587}, 'MSE': {'pcr': 5.789705728103661, 'pcr_scale': 4.649255565941731, 'pcr_whiten': 5.849202976700284, 'pcr_s_w': 4.641725800123125}, 'R2': {'pcr': 0.9903665686075983, 'pcr_scale': 0.9922641518198696, 'pcr_whiten': 0.9902675717519187, 'pcr_s_w': 0.9922766805192234}}'\n",
      "pcr: {'fold_0': 2.7620878868936423, 'fold_1': 3.2925791641453785, 'fold_2': 2.897064935113392, 'fold_3': 3.373553543795674, 'fold_4': 16.62600272316021, 'MSE': 5.789705728103661, 'R2': 0.9903665686075983}'\n",
      "pcr_scale: {'fold_0': 4.335701037485809, 'fold_1': 4.739988618253007, 'fold_2': 4.214848181114851, 'fold_3': 4.70216136244181, 'fold_4': 5.253689929851811, 'MSE': 4.649255565941731, 'R2': 0.9922641518198696}'\n",
      "pcr_whiten: {'fold_0': 2.803868436340324, 'fold_1': 3.2901348981968654, 'fold_2': 2.8775820760385242, 'fold_3': 3.3727028612704824, 'fold_4': 16.904526013562755, 'MSE': 5.849202976700284, 'R2': 0.9902675717519187}'\n",
      "pcr_s_w: {'fold_0': 4.378947170939245, 'fold_1': 4.758306588675729, 'fold_2': 4.164509069755404, 'fold_3': 4.683249392043082, 'fold_4': 5.223689805096587, 'MSE': 4.641725800123125, 'R2': 0.9922766805192234}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 85 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7863,pcr_scale:4.254,pcr_whiten:2.7842,pcr_s_w:4.2693'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7863,pcr_scale:4.377,pcr_whiten:2.7819,pcr_s_w:4.3661'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.038,pcr_scale:4.2469,pcr_whiten:3.0302,pcr_s_w:4.2633'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2908,pcr_scale:4.6851,pcr_whiten:3.2855,pcr_s_w:4.7111'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0784,pcr_scale:4.3652,pcr_whiten:3.0859,pcr_s_w:4.3574'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8792,pcr_scale:4.1956,pcr_whiten:2.864,pcr_s_w:4.2206'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0697,pcr_scale:4.42,pcr_whiten:3.0745,pcr_s_w:4.4267'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3816,pcr_scale:4.696,pcr_whiten:3.3786,pcr_s_w:4.6959'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6747,pcr_scale:4.1739,pcr_whiten:2.6711,pcr_s_w:4.1889'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:15.8726,pcr_scale:5.2135,pcr_whiten:16.0732,pcr_s_w:5.2796'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9855,pcr_scale:4.3326,pcr_whiten:2.9772,pcr_s_w:4.3089'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.885,pcr_scale:4.6606,pcr_whiten:2.8897,pcr_s_w:4.626'\n",
      "Train times: {'fold_0': 5, 'fold_1': 4, 'fold_2': 5, 'fold_3': 5, 'fold_4': 5, 'mean': 4.8}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.7863397955866533, 'pcr_scale': 4.376978878987367, 'pcr_whiten': 2.7819231190953264, 'pcr_s_w': 4.366106929504328}, 'fold_1': {'pcr': 3.290756411702287, 'pcr_scale': 4.685144614931627, 'pcr_whiten': 3.28547112723857, 'pcr_s_w': 4.711122436882105}, 'fold_2': {'pcr': 2.87917779243724, 'pcr_scale': 4.195569482865083, 'pcr_whiten': 2.8640073329661364, 'pcr_s_w': 4.220579734636714}, 'fold_3': {'pcr': 3.381584519901575, 'pcr_scale': 4.695982522876962, 'pcr_whiten': 3.3785666194504045, 'pcr_s_w': 4.695883471960186}, 'fold_4': {'pcr': 15.872591558316572, 'pcr_scale': 5.213522657558033, 'pcr_whiten': 16.073187492190343, 'pcr_s_w': 5.279589007779727}, 'MSE': {'pcr': 5.641569931307615, 'pcr_scale': 4.63341918040816, 'pcr_whiten': 5.676103184929062, 'pcr_s_w': 4.654633135642633}, 'R2': {'pcr': 0.9906130502255269, 'pcr_scale': 0.9922905018177288, 'pcr_whiten': 0.9905555907025146, 'pcr_s_w': 0.992255204137344}}'\n",
      "pcr: {'fold_0': 2.7863397955866533, 'fold_1': 3.290756411702287, 'fold_2': 2.87917779243724, 'fold_3': 3.381584519901575, 'fold_4': 15.872591558316572, 'MSE': 5.641569931307615, 'R2': 0.9906130502255269}'\n",
      "pcr_scale: {'fold_0': 4.376978878987367, 'fold_1': 4.685144614931627, 'fold_2': 4.195569482865083, 'fold_3': 4.695982522876962, 'fold_4': 5.213522657558033, 'MSE': 4.63341918040816, 'R2': 0.9922905018177288}'\n",
      "pcr_whiten: {'fold_0': 2.7819231190953264, 'fold_1': 3.28547112723857, 'fold_2': 2.8640073329661364, 'fold_3': 3.3785666194504045, 'fold_4': 16.073187492190343, 'MSE': 5.676103184929062, 'R2': 0.9905555907025146}'\n",
      "pcr_s_w: {'fold_0': 4.366106929504328, 'fold_1': 4.711122436882105, 'fold_2': 4.220579734636714, 'fold_3': 4.695883471960186, 'fold_4': 5.279589007779727, 'MSE': 4.654633135642633, 'R2': 0.992255204137344}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 86 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7771,pcr_scale:4.2501,pcr_whiten:2.7844,pcr_s_w:4.2642'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7842,pcr_scale:4.3675,pcr_whiten:2.7814,pcr_s_w:4.3747'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0387,pcr_scale:4.2142,pcr_whiten:3.0304,pcr_s_w:4.2662'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2907,pcr_scale:4.6776,pcr_whiten:3.2634,pcr_s_w:4.7731'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0952,pcr_scale:4.2988,pcr_whiten:3.0846,pcr_s_w:4.3497'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8948,pcr_scale:4.1867,pcr_whiten:2.8847,pcr_s_w:4.1968'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0599,pcr_scale:4.4363,pcr_whiten:3.0706,pcr_s_w:4.4095'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3858,pcr_scale:4.6766,pcr_whiten:3.3897,pcr_s_w:4.6865'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6633,pcr_scale:4.1901,pcr_whiten:2.6614,pcr_s_w:4.1762'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:15.9035,pcr_scale:5.2666,pcr_whiten:16.1248,pcr_s_w:5.2503'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9798,pcr_scale:4.3,pcr_whiten:2.9861,pcr_s_w:4.3244'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8804,pcr_scale:4.6787,pcr_whiten:2.8873,pcr_s_w:4.6049'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.7841864400820246, 'pcr_scale': 4.367476582909645, 'pcr_whiten': 2.7813736531536066, 'pcr_s_w': 4.374732567442655}, 'fold_1': {'pcr': 3.290701467942102, 'pcr_scale': 4.677643620136995, 'pcr_whiten': 3.2633830450126062, 'pcr_s_w': 4.773090321209403}, 'fold_2': {'pcr': 2.8948470525565706, 'pcr_scale': 4.186650893253913, 'pcr_whiten': 2.884690464222405, 'pcr_s_w': 4.196845859019121}, 'fold_3': {'pcr': 3.3857634940265977, 'pcr_scale': 4.676566105526811, 'pcr_whiten': 3.389660300579595, 'pcr_s_w': 4.686519949021256}, 'fold_4': {'pcr': 15.903460860514945, 'pcr_scale': 5.266577260905122, 'pcr_whiten': 16.124782117216334, 'pcr_s_w': 5.250285045478045}, 'MSE': {'pcr': 5.651269620134114, 'pcr_scale': 4.634960434937423, 'pcr_whiten': 5.688245275292412, 'pcr_s_w': 4.65627829152157}, 'R2': {'pcr': 0.9905969110137559, 'pcr_scale': 0.9922879373402816, 'pcr_whiten': 0.9905353876041243, 'pcr_s_w': 0.9922524667795173}}'\n",
      "pcr: {'fold_0': 2.7841864400820246, 'fold_1': 3.290701467942102, 'fold_2': 2.8948470525565706, 'fold_3': 3.3857634940265977, 'fold_4': 15.903460860514945, 'MSE': 5.651269620134114, 'R2': 0.9905969110137559}'\n",
      "pcr_scale: {'fold_0': 4.367476582909645, 'fold_1': 4.677643620136995, 'fold_2': 4.186650893253913, 'fold_3': 4.676566105526811, 'fold_4': 5.266577260905122, 'MSE': 4.634960434937423, 'R2': 0.9922879373402816}'\n",
      "pcr_whiten: {'fold_0': 2.7813736531536066, 'fold_1': 3.2633830450126062, 'fold_2': 2.884690464222405, 'fold_3': 3.389660300579595, 'fold_4': 16.124782117216334, 'MSE': 5.688245275292412, 'R2': 0.9905353876041243}'\n",
      "pcr_s_w: {'fold_0': 4.374732567442655, 'fold_1': 4.773090321209403, 'fold_2': 4.196845859019121, 'fold_3': 4.686519949021256, 'fold_4': 5.250285045478045, 'MSE': 4.65627829152157, 'R2': 0.9922524667795173}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 87 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7771,pcr_scale:4.2074,pcr_whiten:2.7784,pcr_s_w:4.2578'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7804,pcr_scale:4.3748,pcr_whiten:2.7772,pcr_s_w:4.4141'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0455,pcr_scale:4.2722,pcr_whiten:3.035,pcr_s_w:4.2433'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2861,pcr_scale:4.708,pcr_whiten:3.2765,pcr_s_w:4.7055'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0923,pcr_scale:4.3494,pcr_whiten:3.0817,pcr_s_w:4.3155'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8803,pcr_scale:4.1652,pcr_whiten:2.878,pcr_s_w:4.1717'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0639,pcr_scale:4.3832,pcr_whiten:3.0563,pcr_s_w:4.3982'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3834,pcr_scale:4.672,pcr_whiten:3.3893,pcr_s_w:4.6887'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6479,pcr_scale:4.1719,pcr_whiten:2.6617,pcr_s_w:4.2071'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:16.612,pcr_scale:5.2572,pcr_whiten:16.2369,pcr_s_w:5.2593'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9765,pcr_scale:4.3054,pcr_whiten:2.9669,pcr_s_w:4.3008'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8776,pcr_scale:4.6272,pcr_whiten:2.8684,pcr_s_w:4.569'\n",
      "Train times: {'fold_0': 5, 'fold_1': 5, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.4}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.780413135231276, 'pcr_scale': 4.374839066880355, 'pcr_whiten': 2.777249589454582, 'pcr_s_w': 4.414133816919221}, 'fold_1': {'pcr': 3.286145204523235, 'pcr_scale': 4.708021271670438, 'pcr_whiten': 3.2765397579207898, 'pcr_s_w': 4.705453688173696}, 'fold_2': {'pcr': 2.8802605878038854, 'pcr_scale': 4.165246638428425, 'pcr_whiten': 2.8780336733823972, 'pcr_s_w': 4.171744841648583}, 'fold_3': {'pcr': 3.383422987927667, 'pcr_scale': 4.672040266447682, 'pcr_whiten': 3.3892579369755964, 'pcr_s_w': 4.688704612562158}, 'fold_4': {'pcr': 16.61202713390688, 'pcr_scale': 5.257236628478735, 'pcr_whiten': 16.236884375926532, 'pcr_s_w': 5.259259456692049}, 'MSE': {'pcr': 5.787903435399963, 'pcr_scale': 4.635457987604238, 'pcr_whiten': 5.711056770608718, 'pcr_s_w': 4.647841691203405}, 'R2': {'pcr': 0.9903695674237603, 'pcr_scale': 0.9922871094675528, 'pcr_whiten': 0.9904974317933443, 'pcr_s_w': 0.9922665043514021}}'\n",
      "pcr: {'fold_0': 2.780413135231276, 'fold_1': 3.286145204523235, 'fold_2': 2.8802605878038854, 'fold_3': 3.383422987927667, 'fold_4': 16.61202713390688, 'MSE': 5.787903435399963, 'R2': 0.9903695674237603}'\n",
      "pcr_scale: {'fold_0': 4.374839066880355, 'fold_1': 4.708021271670438, 'fold_2': 4.165246638428425, 'fold_3': 4.672040266447682, 'fold_4': 5.257236628478735, 'MSE': 4.635457987604238, 'R2': 0.9922871094675528}'\n",
      "pcr_whiten: {'fold_0': 2.777249589454582, 'fold_1': 3.2765397579207898, 'fold_2': 2.8780336733823972, 'fold_3': 3.3892579369755964, 'fold_4': 16.236884375926532, 'MSE': 5.711056770608718, 'R2': 0.9904974317933443}'\n",
      "pcr_s_w: {'fold_0': 4.414133816919221, 'fold_1': 4.705453688173696, 'fold_2': 4.171744841648583, 'fold_3': 4.688704612562158, 'fold_4': 5.259259456692049, 'MSE': 4.647841691203405, 'R2': 0.9922665043514021}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 88 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7769,pcr_scale:4.2216,pcr_whiten:2.779,pcr_s_w:4.2439'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7694,pcr_scale:4.3384,pcr_whiten:2.796,pcr_s_w:4.3537'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0337,pcr_scale:4.2217,pcr_whiten:3.0361,pcr_s_w:4.262'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2691,pcr_scale:4.686,pcr_whiten:3.2778,pcr_s_w:4.71'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.079,pcr_scale:4.3282,pcr_whiten:3.081,pcr_s_w:4.3488'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.866,pcr_scale:4.1867,pcr_whiten:2.872,pcr_s_w:4.1804'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0577,pcr_scale:4.3908,pcr_whiten:3.0764,pcr_s_w:4.4093'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3805,pcr_scale:4.6224,pcr_whiten:3.376,pcr_s_w:4.6715'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6406,pcr_scale:4.177,pcr_whiten:2.6407,pcr_s_w:4.1817'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:16.912,pcr_scale:5.2685,pcr_whiten:16.9612,pcr_s_w:5.3277'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9736,pcr_scale:4.3318,pcr_whiten:2.9647,pcr_s_w:4.2828'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8726,pcr_scale:4.633,pcr_whiten:2.8548,pcr_s_w:4.6279'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 5, 'fold_4': 4, 'mean': 4.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.7694363565364966, 'pcr_scale': 4.338419013683829, 'pcr_whiten': 2.7959956091176434, 'pcr_s_w': 4.353714512429063}, 'fold_1': {'pcr': 3.2691305398595247, 'pcr_scale': 4.686045449505415, 'pcr_whiten': 3.2777980807993394, 'pcr_s_w': 4.709976769316522}, 'fold_2': {'pcr': 2.866024381094056, 'pcr_scale': 4.18669800271009, 'pcr_whiten': 2.871954028452658, 'pcr_s_w': 4.180358739867761}, 'fold_3': {'pcr': 3.3804992730733963, 'pcr_scale': 4.622412466424355, 'pcr_whiten': 3.375987060634073, 'pcr_s_w': 4.671525154276215}, 'fold_4': {'pcr': 16.91196112334464, 'pcr_scale': 5.2685223549477005, 'pcr_whiten': 16.96121099634996, 'pcr_s_w': 5.327735530763512}, 'MSE': {'pcr': 5.838846985423536, 'pcr_scale': 4.62039784594292, 'pcr_whiten': 5.8560258925237685, 'pcr_s_w': 4.64863880603288}, 'R2': {'pcr': 0.9902848029785389, 'pcr_scale': 0.9923121678812733, 'pcr_whiten': 0.9902562191729505, 'pcr_s_w': 0.9922651780402937}}'\n",
      "pcr: {'fold_0': 2.7694363565364966, 'fold_1': 3.2691305398595247, 'fold_2': 2.866024381094056, 'fold_3': 3.3804992730733963, 'fold_4': 16.91196112334464, 'MSE': 5.838846985423536, 'R2': 0.9902848029785389}'\n",
      "pcr_scale: {'fold_0': 4.338419013683829, 'fold_1': 4.686045449505415, 'fold_2': 4.18669800271009, 'fold_3': 4.622412466424355, 'fold_4': 5.2685223549477005, 'MSE': 4.62039784594292, 'R2': 0.9923121678812733}'\n",
      "pcr_whiten: {'fold_0': 2.7959956091176434, 'fold_1': 3.2777980807993394, 'fold_2': 2.871954028452658, 'fold_3': 3.375987060634073, 'fold_4': 16.96121099634996, 'MSE': 5.8560258925237685, 'R2': 0.9902562191729505}'\n",
      "pcr_s_w: {'fold_0': 4.353714512429063, 'fold_1': 4.709976769316522, 'fold_2': 4.180358739867761, 'fold_3': 4.671525154276215, 'fold_4': 5.327735530763512, 'MSE': 4.64863880603288, 'R2': 0.9922651780402937}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 89 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7826,pcr_scale:4.2627,pcr_whiten:2.7745,pcr_s_w:4.2056'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7934,pcr_scale:4.3848,pcr_whiten:2.7751,pcr_s_w:4.3601'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0265,pcr_scale:4.2362,pcr_whiten:3.0324,pcr_s_w:4.2257'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2631,pcr_scale:4.7098,pcr_whiten:3.2771,pcr_s_w:4.7286'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0714,pcr_scale:4.3286,pcr_whiten:3.0894,pcr_s_w:4.3344'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8598,pcr_scale:4.1677,pcr_whiten:2.8805,pcr_s_w:4.1779'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0643,pcr_scale:4.3875,pcr_whiten:3.0548,pcr_s_w:4.4021'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3943,pcr_scale:4.6446,pcr_whiten:3.3868,pcr_s_w:4.6548'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6383,pcr_scale:4.1668,pcr_whiten:2.6432,pcr_s_w:4.1603'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:17.3197,pcr_scale:5.2061,pcr_whiten:17.259,pcr_s_w:5.2989'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9586,pcr_scale:4.2581,pcr_whiten:2.9667,pcr_s_w:4.2938'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8639,pcr_scale:4.6101,pcr_whiten:2.8836,pcr_s_w:4.6608'\n",
      "Train times: {'fold_0': 4, 'fold_1': 5, 'fold_2': 5, 'fold_3': 5, 'fold_4': 5, 'mean': 4.8}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.7934411509818213, 'pcr_scale': 4.384801275232435, 'pcr_whiten': 2.775069289137507, 'pcr_s_w': 4.360076540114168}, 'fold_1': {'pcr': 3.263064168075169, 'pcr_scale': 4.709837015357994, 'pcr_whiten': 3.2771331693031622, 'pcr_s_w': 4.728614250450425}, 'fold_2': {'pcr': 2.859798568365385, 'pcr_scale': 4.167721461539281, 'pcr_whiten': 2.880485276032562, 'pcr_s_w': 4.177943085720256}, 'fold_3': {'pcr': 3.3942755427269713, 'pcr_scale': 4.64459532542104, 'pcr_whiten': 3.3867959685855253, 'pcr_s_w': 4.654779629098524}, 'fold_4': {'pcr': 17.319735631978737, 'pcr_scale': 5.2061123140032315, 'pcr_whiten': 17.258996813573507, 'pcr_s_w': 5.298850768972244}, 'MSE': {'pcr': 5.925484144995953, 'pcr_scale': 4.622598437493174, 'pcr_whiten': 5.915118877023195, 'pcr_s_w': 4.644032937280315}, 'R2': {'pcr': 0.9901406483060964, 'pcr_scale': 0.9923085063397861, 'pcr_whiten': 0.9901578949681149, 'pcr_s_w': 0.9922728416976044}}'\n",
      "pcr: {'fold_0': 2.7934411509818213, 'fold_1': 3.263064168075169, 'fold_2': 2.859798568365385, 'fold_3': 3.3942755427269713, 'fold_4': 17.319735631978737, 'MSE': 5.925484144995953, 'R2': 0.9901406483060964}'\n",
      "pcr_scale: {'fold_0': 4.384801275232435, 'fold_1': 4.709837015357994, 'fold_2': 4.167721461539281, 'fold_3': 4.64459532542104, 'fold_4': 5.2061123140032315, 'MSE': 4.622598437493174, 'R2': 0.9923085063397861}'\n",
      "pcr_whiten: {'fold_0': 2.775069289137507, 'fold_1': 3.2771331693031622, 'fold_2': 2.880485276032562, 'fold_3': 3.3867959685855253, 'fold_4': 17.258996813573507, 'MSE': 5.915118877023195, 'R2': 0.9901578949681149}'\n",
      "pcr_s_w: {'fold_0': 4.360076540114168, 'fold_1': 4.728614250450425, 'fold_2': 4.177943085720256, 'fold_3': 4.654779629098524, 'fold_4': 5.298850768972244, 'MSE': 4.644032937280315, 'R2': 0.9922728416976044}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 90 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7706,pcr_scale:4.202,pcr_whiten:2.772,pcr_s_w:4.2348'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.774,pcr_scale:4.354,pcr_whiten:2.7776,pcr_s_w:4.3948'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.016,pcr_scale:4.22,pcr_whiten:3.0326,pcr_s_w:4.2268'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2488,pcr_scale:4.6924,pcr_whiten:3.2751,pcr_s_w:4.7123'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0885,pcr_scale:4.3643,pcr_whiten:3.0766,pcr_s_w:4.3447'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8804,pcr_scale:4.1943,pcr_whiten:2.8622,pcr_s_w:4.2209'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0452,pcr_scale:4.3958,pcr_whiten:3.0655,pcr_s_w:4.396'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3852,pcr_scale:4.6635,pcr_whiten:3.3979,pcr_s_w:4.6677'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6465,pcr_scale:4.1729,pcr_whiten:2.6539,pcr_s_w:4.1963'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:17.08,pcr_scale:5.3183,pcr_whiten:16.1279,pcr_s_w:5.2188'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9639,pcr_scale:4.2869,pcr_whiten:2.9692,pcr_s_w:4.2791'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8704,pcr_scale:4.5814,pcr_whiten:2.8597,pcr_s_w:4.601'\n",
      "Train times: {'fold_0': 4, 'fold_1': 5, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.774029937445448, 'pcr_scale': 4.3540490503920415, 'pcr_whiten': 2.7775803992338424, 'pcr_s_w': 4.394759520440211}, 'fold_1': {'pcr': 3.248790975005264, 'pcr_scale': 4.692408465139063, 'pcr_whiten': 3.27509070807573, 'pcr_s_w': 4.712319039880389}, 'fold_2': {'pcr': 2.8804191092000893, 'pcr_scale': 4.194289511474507, 'pcr_whiten': 2.8621517811149837, 'pcr_s_w': 4.220937748368516}, 'fold_3': {'pcr': 3.3852076861524134, 'pcr_scale': 4.663481135545473, 'pcr_whiten': 3.3978655410853174, 'pcr_s_w': 4.667669634316251}, 'fold_4': {'pcr': 17.08002371511552, 'pcr_scale': 5.318306428699977, 'pcr_whiten': 16.12792470824173, 'pcr_s_w': 5.218849236727294}, 'MSE': {'pcr': 5.873122513942844, 'pcr_scale': 4.644482691689987, 'pcr_whiten': 5.687590908198763, 'pcr_s_w': 4.64288918381793}, 'R2': {'pcr': 0.9902277722816546, 'pcr_scale': 0.9922720933559006, 'pcr_whiten': 0.9905364763987536, 'pcr_s_w': 0.9922747447771437}}'\n",
      "pcr: {'fold_0': 2.774029937445448, 'fold_1': 3.248790975005264, 'fold_2': 2.8804191092000893, 'fold_3': 3.3852076861524134, 'fold_4': 17.08002371511552, 'MSE': 5.873122513942844, 'R2': 0.9902277722816546}'\n",
      "pcr_scale: {'fold_0': 4.3540490503920415, 'fold_1': 4.692408465139063, 'fold_2': 4.194289511474507, 'fold_3': 4.663481135545473, 'fold_4': 5.318306428699977, 'MSE': 4.644482691689987, 'R2': 0.9922720933559006}'\n",
      "pcr_whiten: {'fold_0': 2.7775803992338424, 'fold_1': 3.27509070807573, 'fold_2': 2.8621517811149837, 'fold_3': 3.3978655410853174, 'fold_4': 16.12792470824173, 'MSE': 5.687590908198763, 'R2': 0.9905364763987536}'\n",
      "pcr_s_w: {'fold_0': 4.394759520440211, 'fold_1': 4.712319039880389, 'fold_2': 4.220937748368516, 'fold_3': 4.667669634316251, 'fold_4': 5.218849236727294, 'MSE': 4.64288918381793, 'R2': 0.9922747447771437}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 91 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.771,pcr_scale:4.2038,pcr_whiten:2.7704,pcr_s_w:4.1985'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7863,pcr_scale:4.3463,pcr_whiten:2.7845,pcr_s_w:4.3862'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0235,pcr_scale:4.2295,pcr_whiten:3.0178,pcr_s_w:4.2245'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2662,pcr_scale:4.6941,pcr_whiten:3.2528,pcr_s_w:4.665'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0792,pcr_scale:4.3378,pcr_whiten:3.0732,pcr_s_w:4.3501'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8587,pcr_scale:4.1812,pcr_whiten:2.8714,pcr_s_w:4.1599'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0416,pcr_scale:4.4028,pcr_whiten:3.0592,pcr_s_w:4.4015'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3923,pcr_scale:4.6844,pcr_whiten:3.3839,pcr_s_w:4.6256'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6386,pcr_scale:4.2005,pcr_whiten:2.6523,pcr_s_w:4.1756'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:17.1415,pcr_scale:5.2562,pcr_whiten:16.252,pcr_s_w:5.2493'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.976,pcr_scale:4.2814,pcr_whiten:2.9651,pcr_s_w:4.2637'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8707,pcr_scale:4.5773,pcr_whiten:2.8552,pcr_s_w:4.584'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.786253468423701, 'pcr_scale': 4.346316406436434, 'pcr_whiten': 2.784536156082546, 'pcr_s_w': 4.386222751948826}, 'fold_1': {'pcr': 3.2662072501188715, 'pcr_scale': 4.6941456787131814, 'pcr_whiten': 3.2528043663300146, 'pcr_s_w': 4.665016985421118}, 'fold_2': {'pcr': 2.8586814837603907, 'pcr_scale': 4.18120883086641, 'pcr_whiten': 2.8714499751826277, 'pcr_s_w': 4.159938981253088}, 'fold_3': {'pcr': 3.39225750909316, 'pcr_scale': 4.684375190581647, 'pcr_whiten': 3.3838914597286442, 'pcr_s_w': 4.625565473664834}, 'fold_4': {'pcr': 17.141541719322497, 'pcr_scale': 5.256237182719863, 'pcr_whiten': 16.252006104036795, 'pcr_s_w': 5.249289938572658}, 'MSE': {'pcr': 5.888416420796767, 'pcr_scale': 4.632434239642314, 'pcr_whiten': 5.708400203692207, 'pcr_s_w': 4.617188530735132}, 'R2': {'pcr': 0.9902023249084515, 'pcr_scale': 0.9922921406504673, 'pcr_whiten': 0.9905018520275205, 'pcr_s_w': 0.9923175078276061}}'\n",
      "pcr: {'fold_0': 2.786253468423701, 'fold_1': 3.2662072501188715, 'fold_2': 2.8586814837603907, 'fold_3': 3.39225750909316, 'fold_4': 17.141541719322497, 'MSE': 5.888416420796767, 'R2': 0.9902023249084515}'\n",
      "pcr_scale: {'fold_0': 4.346316406436434, 'fold_1': 4.6941456787131814, 'fold_2': 4.18120883086641, 'fold_3': 4.684375190581647, 'fold_4': 5.256237182719863, 'MSE': 4.632434239642314, 'R2': 0.9922921406504673}'\n",
      "pcr_whiten: {'fold_0': 2.784536156082546, 'fold_1': 3.2528043663300146, 'fold_2': 2.8714499751826277, 'fold_3': 3.3838914597286442, 'fold_4': 16.252006104036795, 'MSE': 5.708400203692207, 'R2': 0.9905018520275205}'\n",
      "pcr_s_w: {'fold_0': 4.386222751948826, 'fold_1': 4.665016985421118, 'fold_2': 4.159938981253088, 'fold_3': 4.625565473664834, 'fold_4': 5.249289938572658, 'MSE': 4.617188530735132, 'R2': 0.9923175078276061}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 92 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7762,pcr_scale:4.2513,pcr_whiten:2.7717,pcr_s_w:4.2014'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7824,pcr_scale:4.3824,pcr_whiten:2.774,pcr_s_w:4.3731'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0316,pcr_scale:4.2225,pcr_whiten:3.0238,pcr_s_w:4.2142'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2793,pcr_scale:4.7001,pcr_whiten:3.2668,pcr_s_w:4.6976'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0782,pcr_scale:4.3151,pcr_whiten:3.0674,pcr_s_w:4.2991'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8556,pcr_scale:4.1285,pcr_whiten:2.8483,pcr_s_w:4.1616'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0567,pcr_scale:4.4032,pcr_whiten:3.0482,pcr_s_w:4.3759'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3814,pcr_scale:4.6765,pcr_whiten:3.3904,pcr_s_w:4.6445'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.638,pcr_scale:4.178,pcr_whiten:2.6308,pcr_s_w:4.1582'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:17.3702,pcr_scale:5.2348,pcr_whiten:17.4658,pcr_s_w:5.2689'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9572,pcr_scale:4.2599,pcr_whiten:2.966,pcr_s_w:4.2951'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8638,pcr_scale:4.5882,pcr_whiten:2.8807,pcr_s_w:4.6708'\n",
      "Train times: {'fold_0': 7, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.6}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.7823536458639415, 'pcr_scale': 4.382439983745347, 'pcr_whiten': 2.773988663525142, 'pcr_s_w': 4.373104382110784}, 'fold_1': {'pcr': 3.2793072797962073, 'pcr_scale': 4.700127719115096, 'pcr_whiten': 3.2668191659265116, 'pcr_s_w': 4.697594140004734}, 'fold_2': {'pcr': 2.8556184938036964, 'pcr_scale': 4.128467972397021, 'pcr_whiten': 2.8482773840719706, 'pcr_s_w': 4.161599968552479}, 'fold_3': {'pcr': 3.3814108782508847, 'pcr_scale': 4.67653501421109, 'pcr_whiten': 3.3903571734571085, 'pcr_s_w': 4.6444547198746395}, 'fold_4': {'pcr': 17.370163502011483, 'pcr_scale': 5.2348350879729475, 'pcr_whiten': 17.465785211921347, 'pcr_s_w': 5.268906839769021}, 'MSE': {'pcr': 5.933190867756446, 'pcr_scale': 4.62446453597091, 'pcr_whiten': 5.948460493490953, 'pcr_s_w': 4.629113275993412}, 'R2': {'pcr': 0.9901278251699198, 'pcr_scale': 0.9923054013578576, 'pcr_whiten': 0.9901024181978199, 'pcr_s_w': 0.9922976663674848}}'\n",
      "pcr: {'fold_0': 2.7823536458639415, 'fold_1': 3.2793072797962073, 'fold_2': 2.8556184938036964, 'fold_3': 3.3814108782508847, 'fold_4': 17.370163502011483, 'MSE': 5.933190867756446, 'R2': 0.9901278251699198}'\n",
      "pcr_scale: {'fold_0': 4.382439983745347, 'fold_1': 4.700127719115096, 'fold_2': 4.128467972397021, 'fold_3': 4.67653501421109, 'fold_4': 5.2348350879729475, 'MSE': 4.62446453597091, 'R2': 0.9923054013578576}'\n",
      "pcr_whiten: {'fold_0': 2.773988663525142, 'fold_1': 3.2668191659265116, 'fold_2': 2.8482773840719706, 'fold_3': 3.3903571734571085, 'fold_4': 17.465785211921347, 'MSE': 5.948460493490953, 'R2': 0.9901024181978199}'\n",
      "pcr_s_w: {'fold_0': 4.373104382110784, 'fold_1': 4.697594140004734, 'fold_2': 4.161599968552479, 'fold_3': 4.6444547198746395, 'fold_4': 5.268906839769021, 'MSE': 4.629113275993412, 'R2': 0.9922976663674848}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 93 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7793,pcr_scale:4.205,pcr_whiten:2.7689,pcr_s_w:4.2214'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7788,pcr_scale:4.3523,pcr_whiten:2.7665,pcr_s_w:4.3918'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0214,pcr_scale:4.2179,pcr_whiten:3.014,pcr_s_w:4.2309'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2605,pcr_scale:4.683,pcr_whiten:3.2493,pcr_s_w:4.6804'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0735,pcr_scale:4.3093,pcr_whiten:3.0736,pcr_s_w:4.3086'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.856,pcr_scale:4.1729,pcr_whiten:2.8765,pcr_s_w:4.121'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0609,pcr_scale:4.4186,pcr_whiten:3.0423,pcr_s_w:4.3725'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.391,pcr_scale:4.6697,pcr_whiten:3.3774,pcr_s_w:4.6322'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6394,pcr_scale:4.1548,pcr_whiten:2.6202,pcr_s_w:4.1665'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:16.9856,pcr_scale:5.2613,pcr_whiten:17.7742,pcr_s_w:5.3202'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9633,pcr_scale:4.2594,pcr_whiten:2.9749,pcr_s_w:4.285'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.873,pcr_scale:4.5784,pcr_whiten:2.8652,pcr_s_w:4.6677'\n",
      "Train times: {'fold_0': 4, 'fold_1': 5, 'fold_2': 5, 'fold_3': 5, 'fold_4': 5, 'mean': 4.8}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.778778797160232, 'pcr_scale': 4.352252978379225, 'pcr_whiten': 2.7664714506963635, 'pcr_s_w': 4.391835403711129}, 'fold_1': {'pcr': 3.2605253156277443, 'pcr_scale': 4.683003478181801, 'pcr_whiten': 3.2493097314745576, 'pcr_s_w': 4.6803886344188}, 'fold_2': {'pcr': 2.8560181401785933, 'pcr_scale': 4.17291695539002, 'pcr_whiten': 2.876546287235846, 'pcr_s_w': 4.121030663185496}, 'fold_3': {'pcr': 3.3909877224259475, 'pcr_scale': 4.669666409718311, 'pcr_whiten': 3.3774482111420867, 'pcr_s_w': 4.632243265597351}, 'fold_4': {'pcr': 16.985592986498446, 'pcr_scale': 5.2612862187133995, 'pcr_whiten': 17.774233388828375, 'pcr_s_w': 5.32018617251649}, 'MSE': {'pcr': 5.85381432619042, 'pcr_scale': 4.6278031950961696, 'pcr_whiten': 6.0082023509863545, 'pcr_s_w': 4.629118245223284}, 'R2': {'pcr': 0.9902598989752656, 'pcr_scale': 0.9922998461975202, 'pcr_whiten': 0.9900030143399272, 'pcr_s_w': 0.9922976580992348}}'\n",
      "pcr: {'fold_0': 2.778778797160232, 'fold_1': 3.2605253156277443, 'fold_2': 2.8560181401785933, 'fold_3': 3.3909877224259475, 'fold_4': 16.985592986498446, 'MSE': 5.85381432619042, 'R2': 0.9902598989752656}'\n",
      "pcr_scale: {'fold_0': 4.352252978379225, 'fold_1': 4.683003478181801, 'fold_2': 4.17291695539002, 'fold_3': 4.669666409718311, 'fold_4': 5.2612862187133995, 'MSE': 4.6278031950961696, 'R2': 0.9922998461975202}'\n",
      "pcr_whiten: {'fold_0': 2.7664714506963635, 'fold_1': 3.2493097314745576, 'fold_2': 2.876546287235846, 'fold_3': 3.3774482111420867, 'fold_4': 17.774233388828375, 'MSE': 6.0082023509863545, 'R2': 0.9900030143399272}'\n",
      "pcr_s_w: {'fold_0': 4.391835403711129, 'fold_1': 4.6803886344188, 'fold_2': 4.121030663185496, 'fold_3': 4.632243265597351, 'fold_4': 5.32018617251649, 'MSE': 4.629118245223284, 'R2': 0.9922976580992348}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 94 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7705,pcr_scale:4.1799,pcr_whiten:2.7601,pcr_s_w:4.1993'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.774,pcr_scale:4.3642,pcr_whiten:2.7639,pcr_s_w:4.37'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0291,pcr_scale:4.2492,pcr_whiten:3.0228,pcr_s_w:4.209'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2671,pcr_scale:4.7013,pcr_whiten:3.259,pcr_s_w:4.6736'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0621,pcr_scale:4.2821,pcr_whiten:3.0517,pcr_s_w:4.2817'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.857,pcr_scale:4.129,pcr_whiten:2.8274,pcr_s_w:4.1685'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0504,pcr_scale:4.4004,pcr_whiten:3.0532,pcr_s_w:4.3778'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3826,pcr_scale:4.6721,pcr_whiten:3.3661,pcr_s_w:4.6482'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6328,pcr_scale:4.1625,pcr_whiten:2.6337,pcr_s_w:4.1622'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:17.7516,pcr_scale:5.2446,pcr_whiten:17.3405,pcr_s_w:5.2118'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9678,pcr_scale:4.2601,pcr_whiten:2.9627,pcr_s_w:4.252'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8858,pcr_scale:4.6318,pcr_whiten:2.872,pcr_s_w:4.6234'\n",
      "Train times: {'fold_0': 5, 'fold_1': 5, 'fold_2': 5, 'fold_3': 5, 'fold_4': 5, 'mean': 5.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.774006756145466, 'pcr_scale': 4.364226596060695, 'pcr_whiten': 2.7639126694824645, 'pcr_s_w': 4.369975904397865}, 'fold_1': {'pcr': 3.2670960371828675, 'pcr_scale': 4.701308279635273, 'pcr_whiten': 3.2589985297163295, 'pcr_s_w': 4.673579188717814}, 'fold_2': {'pcr': 2.856967019609719, 'pcr_scale': 4.129006298589943, 'pcr_whiten': 2.8273888465115444, 'pcr_s_w': 4.168475810462523}, 'fold_3': {'pcr': 3.3825924209389115, 'pcr_scale': 4.672124090661554, 'pcr_whiten': 3.366095461738399, 'pcr_s_w': 4.648163796137463}, 'fold_4': {'pcr': 17.751601165634494, 'pcr_scale': 5.2446065722811746, 'pcr_whiten': 17.34045670230504, 'pcr_s_w': 5.211765910786638}, 'MSE': {'pcr': 6.005856215403043, 'pcr_scale': 4.62223649151093, 'pcr_whiten': 5.910791154127672, 'pcr_s_w': 4.614373621386209}, 'R2': {'pcr': 0.9900069180506235, 'pcr_scale': 0.992309108577957, 'pcr_whiten': 0.9901650958214151, 'pcr_s_w': 0.9923221915261154}}'\n",
      "pcr: {'fold_0': 2.774006756145466, 'fold_1': 3.2670960371828675, 'fold_2': 2.856967019609719, 'fold_3': 3.3825924209389115, 'fold_4': 17.751601165634494, 'MSE': 6.005856215403043, 'R2': 0.9900069180506235}'\n",
      "pcr_scale: {'fold_0': 4.364226596060695, 'fold_1': 4.701308279635273, 'fold_2': 4.129006298589943, 'fold_3': 4.672124090661554, 'fold_4': 5.2446065722811746, 'MSE': 4.62223649151093, 'R2': 0.992309108577957}'\n",
      "pcr_whiten: {'fold_0': 2.7639126694824645, 'fold_1': 3.2589985297163295, 'fold_2': 2.8273888465115444, 'fold_3': 3.366095461738399, 'fold_4': 17.34045670230504, 'MSE': 5.910791154127672, 'R2': 0.9901650958214151}'\n",
      "pcr_s_w: {'fold_0': 4.369975904397865, 'fold_1': 4.673579188717814, 'fold_2': 4.168475810462523, 'fold_3': 4.648163796137463, 'fold_4': 5.211765910786638, 'MSE': 4.614373621386209, 'R2': 0.9923221915261154}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 95 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7671,pcr_scale:4.1927,pcr_whiten:2.7625,pcr_s_w:4.1827'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7597,pcr_scale:4.3652,pcr_whiten:2.76,pcr_s_w:4.3516'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0079,pcr_scale:4.2146,pcr_whiten:3.0065,pcr_s_w:4.1957'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2473,pcr_scale:4.7138,pcr_whiten:3.2374,pcr_s_w:4.6906'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.064,pcr_scale:4.2596,pcr_whiten:3.0645,pcr_s_w:4.3153'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8536,pcr_scale:4.1114,pcr_whiten:2.8425,pcr_s_w:4.1486'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0447,pcr_scale:4.3792,pcr_whiten:3.036,pcr_s_w:4.3659'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3858,pcr_scale:4.6096,pcr_whiten:3.3764,pcr_s_w:4.6405'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.633,pcr_scale:4.161,pcr_whiten:2.6329,pcr_s_w:4.1567'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:17.4441,pcr_scale:5.2385,pcr_whiten:17.4819,pcr_s_w:5.2661'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9475,pcr_scale:4.2594,pcr_whiten:2.9543,pcr_s_w:4.2323'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8495,pcr_scale:4.6576,pcr_whiten:2.8714,pcr_s_w:4.5965'\n",
      "Train times: {'fold_0': 5, 'fold_1': 5, 'fold_2': 5, 'fold_3': 5, 'fold_4': 5, 'mean': 5.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.7596834065235867, 'pcr_scale': 4.365194493212171, 'pcr_whiten': 2.7599804923311098, 'pcr_s_w': 4.351630163595458}, 'fold_1': {'pcr': 3.2473009187515, 'pcr_scale': 4.713836912941233, 'pcr_whiten': 3.2374135571687557, 'pcr_s_w': 4.690599400672627}, 'fold_2': {'pcr': 2.853597795166849, 'pcr_scale': 4.111355175739864, 'pcr_whiten': 2.84251840185545, 'pcr_s_w': 4.148587599376732}, 'fold_3': {'pcr': 3.385846391942414, 'pcr_scale': 4.609612906154908, 'pcr_whiten': 3.3764315184787845, 'pcr_s_w': 4.640477543137637}, 'fold_4': {'pcr': 17.44410681596656, 'pcr_scale': 5.23849995890227, 'pcr_whiten': 17.481920117687352, 'pcr_s_w': 5.266142282155929}, 'MSE': {'pcr': 5.937520846152998, 'pcr_scale': 4.607686268897418, 'pcr_whiten': 5.939065331329148, 'pcr_s_w': 4.619467746845677}, 'R2': {'pcr': 0.9901206205637149, 'pcr_scale': 0.9923333185426554, 'pcr_whiten': 0.9901180507108277, 'pcr_s_w': 0.9923137154635274}}'\n",
      "pcr: {'fold_0': 2.7596834065235867, 'fold_1': 3.2473009187515, 'fold_2': 2.853597795166849, 'fold_3': 3.385846391942414, 'fold_4': 17.44410681596656, 'MSE': 5.937520846152998, 'R2': 0.9901206205637149}'\n",
      "pcr_scale: {'fold_0': 4.365194493212171, 'fold_1': 4.713836912941233, 'fold_2': 4.111355175739864, 'fold_3': 4.609612906154908, 'fold_4': 5.23849995890227, 'MSE': 4.607686268897418, 'R2': 0.9923333185426554}'\n",
      "pcr_whiten: {'fold_0': 2.7599804923311098, 'fold_1': 3.2374135571687557, 'fold_2': 2.84251840185545, 'fold_3': 3.3764315184787845, 'fold_4': 17.481920117687352, 'MSE': 5.939065331329148, 'R2': 0.9901180507108277}'\n",
      "pcr_s_w: {'fold_0': 4.351630163595458, 'fold_1': 4.690599400672627, 'fold_2': 4.148587599376732, 'fold_3': 4.640477543137637, 'fold_4': 5.266142282155929, 'MSE': 4.619467746845677, 'R2': 0.9923137154635274}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 96 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.769,pcr_scale:4.2169,pcr_whiten:2.7597,pcr_s_w:4.1942'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7681,pcr_scale:4.3852,pcr_whiten:2.7575,pcr_s_w:4.3728'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0229,pcr_scale:4.2164,pcr_whiten:3.0136,pcr_s_w:4.2068'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2653,pcr_scale:4.6702,pcr_whiten:3.2516,pcr_s_w:4.6759'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0551,pcr_scale:4.2718,pcr_whiten:3.0612,pcr_s_w:4.2664'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8407,pcr_scale:4.0959,pcr_whiten:2.8355,pcr_s_w:4.1196'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0406,pcr_scale:4.3703,pcr_whiten:3.0412,pcr_s_w:4.3797'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3845,pcr_scale:4.627,pcr_whiten:3.389,pcr_s_w:4.6298'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6294,pcr_scale:4.1821,pcr_whiten:2.6452,pcr_s_w:4.1261'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:17.7568,pcr_scale:5.2957,pcr_whiten:17.0089,pcr_s_w:5.2523'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9449,pcr_scale:4.2633,pcr_whiten:2.9549,pcr_s_w:4.2366'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8722,pcr_scale:4.5336,pcr_whiten:2.88,pcr_s_w:4.5818'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 5, 'fold_3': 5, 'fold_4': 5, 'mean': 4.6}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.7681172110922607, 'pcr_scale': 4.385245199049733, 'pcr_whiten': 2.7575498580195976, 'pcr_s_w': 4.372837655769842}, 'fold_1': {'pcr': 3.2652728224825083, 'pcr_scale': 4.670187872005333, 'pcr_whiten': 3.2515504147788192, 'pcr_s_w': 4.675918250484166}, 'fold_2': {'pcr': 2.840661597404491, 'pcr_scale': 4.095911734959231, 'pcr_whiten': 2.8354537058829368, 'pcr_s_w': 4.119627844475517}, 'fold_3': {'pcr': 3.3844907654453085, 'pcr_scale': 4.626987591863463, 'pcr_whiten': 3.389049071645887, 'pcr_s_w': 4.629830856386101}, 'fold_4': {'pcr': 17.75675192557446, 'pcr_scale': 5.295745628823532, 'pcr_whiten': 17.008935467159453, 'pcr_s_w': 5.2523353205633665}, 'MSE': {'pcr': 6.002462307498565, 'pcr_scale': 4.614798206405019, 'pcr_whiten': 5.847939593715658, 'pcr_s_w': 4.610092859680343}, 'R2': {'pcr': 0.9900125651388324, 'pcr_scale': 0.9923214850635005, 'pcr_whiten': 0.990269673881781, 'pcr_s_w': 0.9923293142411787}}'\n",
      "pcr: {'fold_0': 2.7681172110922607, 'fold_1': 3.2652728224825083, 'fold_2': 2.840661597404491, 'fold_3': 3.3844907654453085, 'fold_4': 17.75675192557446, 'MSE': 6.002462307498565, 'R2': 0.9900125651388324}'\n",
      "pcr_scale: {'fold_0': 4.385245199049733, 'fold_1': 4.670187872005333, 'fold_2': 4.095911734959231, 'fold_3': 4.626987591863463, 'fold_4': 5.295745628823532, 'MSE': 4.614798206405019, 'R2': 0.9923214850635005}'\n",
      "pcr_whiten: {'fold_0': 2.7575498580195976, 'fold_1': 3.2515504147788192, 'fold_2': 2.8354537058829368, 'fold_3': 3.389049071645887, 'fold_4': 17.008935467159453, 'MSE': 5.847939593715658, 'R2': 0.990269673881781}'\n",
      "pcr_s_w: {'fold_0': 4.372837655769842, 'fold_1': 4.675918250484166, 'fold_2': 4.119627844475517, 'fold_3': 4.629830856386101, 'fold_4': 5.2523353205633665, 'MSE': 4.610092859680343, 'R2': 0.9923293142411787}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 97 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7715,pcr_scale:4.186,pcr_whiten:2.7559,pcr_s_w:4.1911'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7716,pcr_scale:4.3696,pcr_whiten:2.7564,pcr_s_w:4.3743'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0187,pcr_scale:4.2272,pcr_whiten:3.0162,pcr_s_w:4.2068'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2618,pcr_scale:4.6825,pcr_whiten:3.2565,pcr_s_w:4.6893'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0602,pcr_scale:4.2896,pcr_whiten:3.0614,pcr_s_w:4.2907'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8343,pcr_scale:4.139,pcr_whiten:2.8462,pcr_s_w:4.1158'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0407,pcr_scale:4.3747,pcr_whiten:3.0318,pcr_s_w:4.367'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3782,pcr_scale:4.5965,pcr_whiten:3.368,pcr_s_w:4.6431'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6261,pcr_scale:4.1257,pcr_whiten:2.6236,pcr_s_w:4.1231'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:17.5658,pcr_scale:5.2561,pcr_whiten:17.4651,pcr_s_w:5.3309'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9557,pcr_scale:4.2726,pcr_whiten:2.9504,pcr_s_w:4.2539'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8879,pcr_scale:4.6528,pcr_whiten:2.8782,pcr_s_w:4.6192'\n",
      "Train times: {'fold_0': 5, 'fold_1': 5, 'fold_2': 5, 'fold_3': 5, 'fold_4': 5, 'mean': 5.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.771638517425102, 'pcr_scale': 4.369595002101403, 'pcr_whiten': 2.7564455938080377, 'pcr_s_w': 4.374329119499023}, 'fold_1': {'pcr': 3.261796170547032, 'pcr_scale': 4.682517950614738, 'pcr_whiten': 3.2564855457606674, 'pcr_s_w': 4.689284857391232}, 'fold_2': {'pcr': 2.8342534574021907, 'pcr_scale': 4.1389771506851885, 'pcr_whiten': 2.84618503854093, 'pcr_s_w': 4.115761124250693}, 'fold_3': {'pcr': 3.3782167551358637, 'pcr_scale': 4.59653953859961, 'pcr_whiten': 3.368009244980546, 'pcr_s_w': 4.643075615674779}, 'fold_4': {'pcr': 17.565779201270665, 'pcr_scale': 5.256050732230297, 'pcr_whiten': 17.46509483557487, 'pcr_s_w': 5.330902916538856}, 'MSE': {'pcr': 5.961748402562249, 'pcr_scale': 4.608719558745871, 'pcr_whiten': 5.937858358868059, 'pcr_s_w': 4.630650977622129}, 'R2': {'pcr': 0.9900803085835496, 'pcr_scale': 0.9923315992623791, 'pcr_whiten': 0.9901200589798042, 'pcr_s_w': 0.9922951078016721}}'\n",
      "pcr: {'fold_0': 2.771638517425102, 'fold_1': 3.261796170547032, 'fold_2': 2.8342534574021907, 'fold_3': 3.3782167551358637, 'fold_4': 17.565779201270665, 'MSE': 5.961748402562249, 'R2': 0.9900803085835496}'\n",
      "pcr_scale: {'fold_0': 4.369595002101403, 'fold_1': 4.682517950614738, 'fold_2': 4.1389771506851885, 'fold_3': 4.59653953859961, 'fold_4': 5.256050732230297, 'MSE': 4.608719558745871, 'R2': 0.9923315992623791}'\n",
      "pcr_whiten: {'fold_0': 2.7564455938080377, 'fold_1': 3.2564855457606674, 'fold_2': 2.84618503854093, 'fold_3': 3.368009244980546, 'fold_4': 17.46509483557487, 'MSE': 5.937858358868059, 'R2': 0.9901200589798042}'\n",
      "pcr_s_w: {'fold_0': 4.374329119499023, 'fold_1': 4.689284857391232, 'fold_2': 4.115761124250693, 'fold_3': 4.643075615674779, 'fold_4': 5.330902916538856, 'MSE': 4.630650977622129, 'R2': 0.9922951078016721}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 98 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7667,pcr_scale:4.1798,pcr_whiten:2.7576,pcr_s_w:4.1867'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7819,pcr_scale:4.3858,pcr_whiten:2.7598,pcr_s_w:4.3619'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0119,pcr_scale:4.2409,pcr_whiten:3.0141,pcr_s_w:4.1894'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2321,pcr_scale:4.726,pcr_whiten:3.2537,pcr_s_w:4.6124'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0717,pcr_scale:4.3056,pcr_whiten:3.0626,pcr_s_w:4.2861'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8595,pcr_scale:4.164,pcr_whiten:2.8273,pcr_s_w:4.1768'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0071,pcr_scale:4.3547,pcr_whiten:3.0359,pcr_s_w:4.3619'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3784,pcr_scale:4.5908,pcr_whiten:3.3875,pcr_s_w:4.6152'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6315,pcr_scale:4.1443,pcr_whiten:2.6298,pcr_s_w:4.142'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:17.4508,pcr_scale:5.2032,pcr_whiten:17.3833,pcr_s_w:5.2356'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9485,pcr_scale:4.254,pcr_whiten:2.9425,pcr_s_w:4.2658'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8793,pcr_scale:4.6184,pcr_whiten:2.8725,pcr_s_w:4.6558'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.7819496485452486, 'pcr_scale': 4.385806648917716, 'pcr_whiten': 2.7598205303281667, 'pcr_s_w': 4.361892289326213}, 'fold_1': {'pcr': 3.2321089583886677, 'pcr_scale': 4.725956683754507, 'pcr_whiten': 3.2536549184861676, 'pcr_s_w': 4.61242400977456}, 'fold_2': {'pcr': 2.859523344765954, 'pcr_scale': 4.163958660176167, 'pcr_whiten': 2.8272813942042747, 'pcr_s_w': 4.176843119049437}, 'fold_3': {'pcr': 3.37844100000516, 'pcr_scale': 4.590819618586796, 'pcr_whiten': 3.387490507044896, 'pcr_s_w': 4.61517169261641}, 'fold_4': {'pcr': 17.450822862425568, 'pcr_scale': 5.203164618903953, 'pcr_whiten': 17.383347522991226, 'pcr_s_w': 5.235571478398748}, 'MSE': {'pcr': 5.939983158059966, 'pcr_scale': 4.6139296480694805, 'pcr_whiten': 5.921736557261723, 'pcr_s_w': 4.600357900500216}, 'R2': {'pcr': 0.9901165235484369, 'pcr_scale': 0.9923229302487185, 'pcr_whiten': 0.9901468838785106, 'pcr_s_w': 0.9923455121389257}}'\n",
      "pcr: {'fold_0': 2.7819496485452486, 'fold_1': 3.2321089583886677, 'fold_2': 2.859523344765954, 'fold_3': 3.37844100000516, 'fold_4': 17.450822862425568, 'MSE': 5.939983158059966, 'R2': 0.9901165235484369}'\n",
      "pcr_scale: {'fold_0': 4.385806648917716, 'fold_1': 4.725956683754507, 'fold_2': 4.163958660176167, 'fold_3': 4.590819618586796, 'fold_4': 5.203164618903953, 'MSE': 4.6139296480694805, 'R2': 0.9923229302487185}'\n",
      "pcr_whiten: {'fold_0': 2.7598205303281667, 'fold_1': 3.2536549184861676, 'fold_2': 2.8272813942042747, 'fold_3': 3.387490507044896, 'fold_4': 17.383347522991226, 'MSE': 5.921736557261723, 'R2': 0.9901468838785106}'\n",
      "pcr_s_w: {'fold_0': 4.361892289326213, 'fold_1': 4.61242400977456, 'fold_2': 4.176843119049437, 'fold_3': 4.61517169261641, 'fold_4': 5.235571478398748, 'MSE': 4.600357900500216, 'R2': 0.9923455121389257}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 99 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7526,pcr_scale:4.1454,pcr_whiten:2.7631,pcr_s_w:4.1573'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7528,pcr_scale:4.3564,pcr_whiten:2.7635,pcr_s_w:4.3272'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0061,pcr_scale:4.228,pcr_whiten:3.0106,pcr_s_w:4.1862'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2318,pcr_scale:4.6815,pcr_whiten:3.2295,pcr_s_w:4.6491'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0499,pcr_scale:4.2783,pcr_whiten:3.0703,pcr_s_w:4.2532'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8298,pcr_scale:4.138,pcr_whiten:2.8454,pcr_s_w:4.1173'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0121,pcr_scale:4.3646,pcr_whiten:3.037,pcr_s_w:4.3524'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.3757,pcr_scale:4.6286,pcr_whiten:3.3858,pcr_s_w:4.6148'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.6301,pcr_scale:4.1696,pcr_whiten:2.6336,pcr_s_w:4.1735'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:17.9037,pcr_scale:5.2755,pcr_whiten:17.6485,pcr_s_w:5.2571'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9452,pcr_scale:4.2578,pcr_whiten:2.9471,pcr_s_w:4.254'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.8502,pcr_scale:4.6012,pcr_whiten:2.8561,pcr_s_w:4.6312'\n",
      "Train times: {'fold_0': 5, 'fold_1': 4, 'fold_2': 4, 'fold_3': 5, 'fold_4': 5, 'mean': 4.6}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.7528237209027258, 'pcr_scale': 4.356398097732031, 'pcr_whiten': 2.7635160106015433, 'pcr_s_w': 4.327177843344238}, 'fold_1': {'pcr': 3.2318033811473232, 'pcr_scale': 4.681458414001417, 'pcr_whiten': 3.2295496258848218, 'pcr_s_w': 4.64910174580337}, 'fold_2': {'pcr': 2.8298142414959666, 'pcr_scale': 4.138002689892184, 'pcr_whiten': 2.845398292453448, 'pcr_s_w': 4.1172519761296105}, 'fold_3': {'pcr': 3.375703441367005, 'pcr_scale': 4.628580701112026, 'pcr_whiten': 3.385836041200861, 'pcr_s_w': 4.614781980280495}, 'fold_4': {'pcr': 17.903729335123018, 'pcr_scale': 5.27550129114188, 'pcr_whiten': 17.64846810797684, 'pcr_s_w': 5.257134970289659}, 'MSE': {'pcr': 6.0181702572327405, 'pcr_scale': 4.615968850045801, 'pcr_whiten': 5.973958725332376, 'pcr_s_w': 4.5930687383455435}, 'R2': {'pcr': 0.9899864288439694, 'pcr_scale': 0.9923195372416719, 'pcr_whiten': 0.9900599919539644, 'pcr_s_w': 0.9923576405003353}}'\n",
      "pcr: {'fold_0': 2.7528237209027258, 'fold_1': 3.2318033811473232, 'fold_2': 2.8298142414959666, 'fold_3': 3.375703441367005, 'fold_4': 17.903729335123018, 'MSE': 6.0181702572327405, 'R2': 0.9899864288439694}'\n",
      "pcr_scale: {'fold_0': 4.356398097732031, 'fold_1': 4.681458414001417, 'fold_2': 4.138002689892184, 'fold_3': 4.628580701112026, 'fold_4': 5.27550129114188, 'MSE': 4.615968850045801, 'R2': 0.9923195372416719}'\n",
      "pcr_whiten: {'fold_0': 2.7635160106015433, 'fold_1': 3.2295496258848218, 'fold_2': 2.845398292453448, 'fold_3': 3.385836041200861, 'fold_4': 17.64846810797684, 'MSE': 5.973958725332376, 'R2': 0.9900599919539644}'\n",
      "pcr_s_w: {'fold_0': 4.327177843344238, 'fold_1': 4.64910174580337, 'fold_2': 4.1172519761296105, 'fold_3': 4.614781980280495, 'fold_4': 5.257134970289659, 'MSE': 4.5930687383455435, 'R2': 0.9923576405003353}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PCR with 100 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.7559,pcr_scale:4.1425,pcr_whiten:2.7662,pcr_s_w:4.1744'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.7552,pcr_scale:4.3584,pcr_whiten:2.7672,pcr_s_w:4.3557'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0088,pcr_scale:4.1604,pcr_whiten:3.0027,pcr_s_w:4.1829'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:3.2304,pcr_scale:4.6704,pcr_whiten:3.2478,pcr_s_w:4.6765'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0559,pcr_scale:4.2798,pcr_whiten:3.0546,pcr_s_w:4.2695'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:2.8306,pcr_scale:4.1431,pcr_whiten:2.8554,pcr_s_w:4.1097'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:3.0307,pcr_scale:4.3432,pcr_whiten:3.022,pcr_s_w:4.3885'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:3.4032,pcr_scale:4.5671,pcr_whiten:3.4028,pcr_s_w:4.6563'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of pcr:2.627,pcr_scale:4.1599,pcr_whiten:2.6261,pcr_s_w:4.1165'\n",
      "Tested (test) on 2002 instances with mean losses of: pcr:17.153,pcr_scale:5.2477,pcr_whiten:17.3326,pcr_s_w:5.1989'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of pcr:2.9417,pcr_scale:4.2579,pcr_whiten:2.9492,pcr_s_w:4.2553'\n",
      "Tested (test) on 2003 instances with mean losses of: pcr:2.869,pcr_scale:4.6047,pcr_whiten:2.8507,pcr_s_w:4.6451'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'pcr': 2.755212621713767, 'pcr_scale': 4.358358386082866, 'pcr_whiten': 2.7671510566462674, 'pcr_s_w': 4.355707605967643}, 'fold_1': {'pcr': 3.230405892508086, 'pcr_scale': 4.670390237937641, 'pcr_whiten': 3.2478448233751163, 'pcr_s_w': 4.676486038286927}, 'fold_2': {'pcr': 2.8305549854971956, 'pcr_scale': 4.143103136769382, 'pcr_whiten': 2.8553966601256526, 'pcr_s_w': 4.109662617006119}, 'fold_3': {'pcr': 3.403245988902947, 'pcr_scale': 4.567053685735951, 'pcr_whiten': 3.402771330511198, 'pcr_s_w': 4.6563301298923685}, 'fold_4': {'pcr': 17.15295651887073, 'pcr_scale': 5.247692767197579, 'pcr_whiten': 17.332638551565694, 'pcr_s_w': 5.198866436816614}, 'MSE': {'pcr': 5.873899559080569, 'pcr_scale': 4.597303073561556, 'pcr_whiten': 5.92057845037678, 'pcr_s_w': 4.599393922816573}, 'R2': {'pcr': 0.9902264793642984, 'pcr_scale': 0.9923505950338276, 'pcr_whiten': 0.9901488108405611, 'pcr_s_w': 0.9923471160914088}}'\n",
      "pcr: {'fold_0': 2.755212621713767, 'fold_1': 3.230405892508086, 'fold_2': 2.8305549854971956, 'fold_3': 3.403245988902947, 'fold_4': 17.15295651887073, 'MSE': 5.873899559080569, 'R2': 0.9902264793642984}'\n",
      "pcr_scale: {'fold_0': 4.358358386082866, 'fold_1': 4.670390237937641, 'fold_2': 4.143103136769382, 'fold_3': 4.567053685735951, 'fold_4': 5.247692767197579, 'MSE': 4.597303073561556, 'R2': 0.9923505950338276}'\n",
      "pcr_whiten: {'fold_0': 2.7671510566462674, 'fold_1': 3.2478448233751163, 'fold_2': 2.8553966601256526, 'fold_3': 3.402771330511198, 'fold_4': 17.332638551565694, 'MSE': 5.92057845037678, 'R2': 0.9901488108405611}'\n",
      "pcr_s_w: {'fold_0': 4.355707605967643, 'fold_1': 4.676486038286927, 'fold_2': 4.109662617006119, 'fold_3': 4.6563301298923685, 'fold_4': 5.198866436816614, 'MSE': 4.599393922816573, 'R2': 0.9923471160914088}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "scores_df_pcr = None\n",
    "scores_df_pcr_final = None\n",
    "\n",
    "for n_component in n_comps:\n",
    "    save_loc = log_dir/f\"PCR_{n_component}\"\n",
    "    if not save_loc.exists():\n",
    "        save_loc.mkdir()\n",
    "\n",
    "    pca_models = {\n",
    "    'pcr':PCR(n_component=n_component,scale=False,whiten=False),\n",
    "    'pcr_scale':PCR(n_component=n_component,scale=True,whiten=False),\n",
    "    'pcr_whiten':PCR(n_component=n_component,scale=False,whiten=True),\n",
    "    'pcr_s_w':PCR(n_component=n_component,scale=True,whiten=True),\n",
    "    }\n",
    "\n",
    "\n",
    "    local_logger_name = f\"pcr_{n_component}\"\n",
    "    ut.setup_logger(logger_name=local_logger_name,file_name=save_loc/f\"{local_logger_name}_log.txt\")\n",
    "    local_logger = logging.getLogger(local_logger_name)\n",
    "\n",
    "    scheme = ev.SKLearnScheme(logger=local_logger_name )\n",
    "\n",
    "    local_logger.info(f\"Running PCR with {n_component} components\")\n",
    "    scores_sk, preds_sk, model_states_sk , train_time_sk, test_time_sk,_ = eval.evaluate(pca_models,dataset,scheme,logger_name=local_logger_name)\n",
    "    scores_sk_final, _, model_states_sk_final , _, _,_= eval.build(pca_models,dataset,scheme,logger_name=local_logger_name)\n",
    "    \n",
    "    for fold,nested in model_states_sk.items():\n",
    "        for name,model in nested.items():\n",
    "            CustomWrapper(None).save_state(model,save_loc/(f\"{name}_{fold}\"))\n",
    "    for name,model in model_states_sk_final.items():\n",
    "        model.save_state(model.state(),save_loc/(f\"{name}_final\"))\n",
    "\n",
    "    local_logger.info(f\"Train times: {train_time_sk}\")\n",
    "    local_logger.info(f\"Test times: {test_time_sk}\")\n",
    "    local_logger.info(f\"Scores: {scores_sk}\")\n",
    "    for key,value in ut.flip_dicts(scores_sk).items():\n",
    "        local_logger.info(f\"{key}: {value}\")\n",
    "\n",
    "    preds_sk.to_csv(save_loc/ (f\"predictions_pcr\" + \".csv\"), index=False)\n",
    "    plot_preds_and_res(preds_sk,name_lambda=lambda x:f\"PCR with {x} components\",save_lambda= lambda x:f\"pcr_{x}\",save_loc=save_loc)\n",
    "\n",
    "    flipped = ut.flip_dicts(scores_sk)\n",
    "    #add to scores\n",
    "    for name,record in flipped.items():\n",
    "        record1 = {'model':f\"{name}\",'n_comp':n_component}\n",
    "        if scores_df_pcr is None:\n",
    "            scores_df_pcr =pd.DataFrame([{**record1,**record}])\n",
    "        else:\n",
    "           scores_df_pcr=scores_df_pcr.append([{**record1,**record}],ignore_index=True)\n",
    "        \n",
    "    flipped = ut.flip_dicts(scores_sk_final)\n",
    "    #add to scores\n",
    "    for name,record in flipped.items():\n",
    "        record1 = {'model':f\"{name}\",'n_comp':n_component}\n",
    "        if scores_df_pcr_final is None:\n",
    "            scores_df_pcr_final =pd.DataFrame([{**record1,**record}])\n",
    "        else:\n",
    "           scores_df_pcr_final=scores_df_pcr_final.append([{**record1,**record}],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% run PLS Models for each component\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1 components'\n",
      "Running PLSR with 1 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:31.0597,plsr_scale:60.8457'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:29.989,plsr_scale:60.2892'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:31.0783,plsr_scale:61.8702'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:31.1435,plsr_scale:62.0218'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:30.9892,plsr_scale:61.4804'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:30.3113,plsr_scale:63.2117'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:30.8249,plsr_scale:62.0865'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:31.6873,plsr_scale:61.8432'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:30.4859,plsr_scale:61.1269'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:31.4657,plsr_scale:65.4171'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:30.6972,plsr_scale:62.2889'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:33.0605,plsr_scale:63.9097'\n",
      "Train times: {'fold_0': 1, 'fold_1': 1, 'fold_2': 1, 'fold_3': 1, 'fold_4': 1, 'mean': 1.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 29.98899917203568, 'plsr_scale': 60.28923076084068}, 'fold_1': {'plsr': 31.143509922108578, 'plsr_scale': 62.02179566066535}, 'fold_2': {'plsr': 30.311268741765097, 'plsr_scale': 63.211701789643506}, 'fold_3': {'plsr': 31.687264644986186, 'plsr_scale': 61.84323686206212}, 'fold_4': {'plsr': 31.465722835927046, 'plsr_scale': 65.4171232157179}, 'MSE': {'plsr': 30.919282528303334, 'plsr_scale': 62.55633777275854}, 'R2': {'plsr': 0.9485537260567726, 'plsr_scale': 0.8959131575256833}}'\n",
      "plsr: {'fold_0': 29.98899917203568, 'fold_1': 31.143509922108578, 'fold_2': 30.311268741765097, 'fold_3': 31.687264644986186, 'fold_4': 31.465722835927046, 'MSE': 30.919282528303334, 'R2': 0.9485537260567726}'\n",
      "plsr_scale: {'fold_0': 60.28923076084068, 'fold_1': 62.02179566066535, 'fold_2': 63.211701789643506, 'fold_3': 61.84323686206212, 'fold_4': 65.4171232157179, 'MSE': 62.55633777275854, 'R2': 0.8959131575256833}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 2 components'\n",
      "Running PLSR with 2 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:9.5985,plsr_scale:16.8995'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:8.9736,plsr_scale:15.3192'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:9.6104,plsr_scale:16.9114'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:9.647,plsr_scale:16.8509'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:9.6975,plsr_scale:16.1098'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:9.2381,plsr_scale:17.2436'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:9.5985,plsr_scale:15.9613'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:10.743,plsr_scale:16.2357'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:9.4402,plsr_scale:16.2737'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:9.6749,plsr_scale:28.8487'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:9.5246,plsr_scale:16.4836'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:10.2746,plsr_scale:16.1405'\n",
      "Train times: {'fold_0': 1, 'fold_1': 1, 'fold_2': 1, 'fold_3': 1, 'fold_4': 1, 'mean': 1.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 8.97359510506624, 'plsr_scale': 15.319223596771787}, 'fold_1': {'plsr': 9.6469645013587, 'plsr_scale': 16.850873736169984}, 'fold_2': {'plsr': 9.23813025941362, 'plsr_scale': 17.24363015446805}, 'fold_3': {'plsr': 10.743029237662146, 'plsr_scale': 16.23572168772845}, 'fold_4': {'plsr': 9.674862413817277, 'plsr_scale': 28.848666308770316}, 'MSE': {'plsr': 9.655247378873055, 'plsr_scale': 18.89906085658389}, 'R2': {'plsr': 0.9839347338933744, 'plsr_scale': 0.9685540483933444}}'\n",
      "plsr: {'fold_0': 8.97359510506624, 'fold_1': 9.6469645013587, 'fold_2': 9.23813025941362, 'fold_3': 10.743029237662146, 'fold_4': 9.674862413817277, 'MSE': 9.655247378873055, 'R2': 0.9839347338933744}'\n",
      "plsr_scale: {'fold_0': 15.319223596771787, 'fold_1': 16.850873736169984, 'fold_2': 17.24363015446805, 'fold_3': 16.23572168772845, 'fold_4': 28.848666308770316, 'MSE': 18.89906085658389, 'R2': 0.9685540483933444}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 3 components'\n",
      "Running PLSR with 3 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:8.8707,plsr_scale:10.6787'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:8.2992,plsr_scale:9.74'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:8.5045,plsr_scale:10.5298'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:8.7603,plsr_scale:10.2374'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:8.4965,plsr_scale:10.2987'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.0193,plsr_scale:11.099'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:8.3863,plsr_scale:10.1703'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:9.2191,plsr_scale:10.3984'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:8.5396,plsr_scale:10.5036'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.702,plsr_scale:21.263'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:8.3762,plsr_scale:10.3927'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:9.0666,plsr_scale:10.5287'\n",
      "Train times: {'fold_0': 1, 'fold_1': 1, 'fold_2': 1, 'fold_3': 1, 'fold_4': 1, 'mean': 1.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 8.299170783598791, 'plsr_scale': 9.740009212316515}, 'fold_1': {'plsr': 8.760291090659022, 'plsr_scale': 10.237383566337018}, 'fold_2': {'plsr': 8.019336050104645, 'plsr_scale': 11.098995476399443}, 'fold_3': {'plsr': 9.219056658504153, 'plsr_scale': 10.398406486849115}, 'fold_4': {'plsr': 8.701970295227202, 'plsr_scale': 21.262981073938505}, 'MSE': {'plsr': 8.59995094564703, 'plsr_scale': 12.547044004803388}, 'R2': {'plsr': 0.9856906306980742, 'plsr_scale': 0.9791231034401281}}'\n",
      "plsr: {'fold_0': 8.299170783598791, 'fold_1': 8.760291090659022, 'fold_2': 8.019336050104645, 'fold_3': 9.219056658504153, 'fold_4': 8.701970295227202, 'MSE': 8.59995094564703, 'R2': 0.9856906306980742}'\n",
      "plsr_scale: {'fold_0': 9.740009212316515, 'fold_1': 10.237383566337018, 'fold_2': 11.098995476399443, 'fold_3': 10.398406486849115, 'fold_4': 21.262981073938505, 'MSE': 12.547044004803388, 'R2': 0.9791231034401281}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 4 components'\n",
      "Running PLSR with 4 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:6.9164,plsr_scale:7.4578'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:6.7864,plsr_scale:7.1418'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:6.7908,plsr_scale:7.3591'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:6.9362,plsr_scale:7.6838'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:6.9187,plsr_scale:7.3044'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:6.3351,plsr_scale:7.3871'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:6.744,plsr_scale:7.2941'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:7.4866,plsr_scale:7.4248'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:6.6644,plsr_scale:7.3318'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:6.6681,plsr_scale:16.8708'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:6.6365,plsr_scale:7.2866'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:7.2218,plsr_scale:7.1221'\n",
      "Train times: {'fold_0': 1, 'fold_1': 2, 'fold_2': 1, 'fold_3': 2, 'fold_4': 2, 'mean': 1.6}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 6.786406196458901, 'plsr_scale': 7.141759560305464}, 'fold_1': {'plsr': 6.936194732543566, 'plsr_scale': 7.683783624175332}, 'fold_2': {'plsr': 6.335091166107497, 'plsr_scale': 7.38709683115962}, 'fold_3': {'plsr': 7.4865757910697095, 'plsr_scale': 7.424794666546132}, 'fold_4': {'plsr': 6.668089049299173, 'plsr_scale': 16.8707616380919}, 'MSE': {'plsr': 6.842475148397687, 'plsr_scale': 9.301261943306226}, 'R2': {'plsr': 0.9886148764735418, 'plsr_scale': 0.9845237265931052}}'\n",
      "plsr: {'fold_0': 6.786406196458901, 'fold_1': 6.936194732543566, 'fold_2': 6.335091166107497, 'fold_3': 7.4865757910697095, 'fold_4': 6.668089049299173, 'MSE': 6.842475148397687, 'R2': 0.9886148764735418}'\n",
      "plsr_scale: {'fold_0': 7.141759560305464, 'fold_1': 7.683783624175332, 'fold_2': 7.38709683115962, 'fold_3': 7.424794666546132, 'fold_4': 16.8707616380919, 'MSE': 9.301261943306226, 'R2': 0.9845237265931052}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 5 components'\n",
      "Running PLSR with 5 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:6.0538,plsr_scale:5.4361'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:6.1907,plsr_scale:5.3374'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:6.2449,plsr_scale:5.526'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:6.1353,plsr_scale:6.0302'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:6.3831,plsr_scale:5.5851'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:5.6616,plsr_scale:5.3698'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:6.1959,plsr_scale:5.6293'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:6.7483,plsr_scale:5.6473'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:5.8825,plsr_scale:5.3587'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:6.705,plsr_scale:8.0838'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:6.0577,plsr_scale:5.5063'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:6.2535,plsr_scale:5.547'\n",
      "Train times: {'fold_0': 2, 'fold_1': 2, 'fold_2': 2, 'fold_3': 2, 'fold_4': 2, 'mean': 2.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 6.1907083983531574, 'plsr_scale': 5.337369594912462}, 'fold_1': {'plsr': 6.13527932139438, 'plsr_scale': 6.030202068338492}, 'fold_2': {'plsr': 5.661647462026362, 'plsr_scale': 5.369825607619889}, 'fold_3': {'plsr': 6.7482662689257715, 'plsr_scale': 5.647329248956136}, 'fold_4': {'plsr': 6.705009645922251, 'plsr_scale': 8.083844978254579}, 'MSE': {'plsr': 6.288157211661691, 'plsr_scale': 6.093632412187628}, 'R2': {'plsr': 0.9895372003469648, 'plsr_scale': 0.9898608681459615}}'\n",
      "plsr: {'fold_0': 6.1907083983531574, 'fold_1': 6.13527932139438, 'fold_2': 5.661647462026362, 'fold_3': 6.7482662689257715, 'fold_4': 6.705009645922251, 'MSE': 6.288157211661691, 'R2': 0.9895372003469648}'\n",
      "plsr_scale: {'fold_0': 5.337369594912462, 'fold_1': 6.030202068338492, 'fold_2': 5.369825607619889, 'fold_3': 5.647329248956136, 'fold_4': 8.083844978254579, 'MSE': 6.093632412187628, 'R2': 0.9898608681459615}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 6 components'\n",
      "Running PLSR with 6 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:5.6423,plsr_scale:4.9725'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:5.7815,plsr_scale:4.9536'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:5.8426,plsr_scale:5.0894'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:5.5939,plsr_scale:5.4418'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:5.9524,plsr_scale:5.1404'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:5.2736,plsr_scale:4.9084'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:5.8172,plsr_scale:5.182'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:6.3553,plsr_scale:5.4488'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:5.508,plsr_scale:4.9102'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:7.545,plsr_scale:6.6392'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:5.7229,plsr_scale:5.0869'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:5.9427,plsr_scale:5.2358'\n",
      "Train times: {'fold_0': 2, 'fold_1': 2, 'fold_2': 2, 'fold_3': 2, 'fold_4': 2, 'mean': 2.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 5.781513449726835, 'plsr_scale': 4.953584173960316}, 'fold_1': {'plsr': 5.593867938845555, 'plsr_scale': 5.441847797318303}, 'fold_2': {'plsr': 5.273567307189637, 'plsr_scale': 4.908375754381764}, 'fold_3': {'plsr': 6.355278699270272, 'plsr_scale': 5.448753858943966}, 'fold_4': {'plsr': 7.545028017835381, 'plsr_scale': 6.639195920190893}, 'MSE': {'plsr': 6.109766751692935, 'plsr_scale': 5.478295441127782}, 'R2': {'plsr': 0.9898340223855748, 'plsr_scale': 0.9908847209585733}}'\n",
      "plsr: {'fold_0': 5.781513449726835, 'fold_1': 5.593867938845555, 'fold_2': 5.273567307189637, 'fold_3': 6.355278699270272, 'fold_4': 7.545028017835381, 'MSE': 6.109766751692935, 'R2': 0.9898340223855748}'\n",
      "plsr_scale: {'fold_0': 4.953584173960316, 'fold_1': 5.441847797318303, 'fold_2': 4.908375754381764, 'fold_3': 5.448753858943966, 'fold_4': 6.639195920190893, 'MSE': 5.478295441127782, 'R2': 0.9908847209585733}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 7 components'\n",
      "Running PLSR with 7 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:5.1843,plsr_scale:4.636'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:5.234,plsr_scale:4.7463'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:5.2038,plsr_scale:4.7389'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:5.1451,plsr_scale:5.0072'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:5.282,plsr_scale:4.7828'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:4.8414,plsr_scale:4.4598'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:5.1936,plsr_scale:4.8264'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:5.5092,plsr_scale:5.0327'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:5.0768,plsr_scale:4.5638'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:9.077,plsr_scale:5.5735'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:5.0809,plsr_scale:4.7463'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:5.2657,plsr_scale:4.8456'\n",
      "Train times: {'fold_0': 2, 'fold_1': 2, 'fold_2': 2, 'fold_3': 2, 'fold_4': 2, 'mean': 2.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 5.234029201476464, 'plsr_scale': 4.746335273504132}, 'fold_1': {'plsr': 5.145096612203966, 'plsr_scale': 5.0072038893663855}, 'fold_2': {'plsr': 4.841440168474167, 'plsr_scale': 4.459757292198208}, 'fold_3': {'plsr': 5.509237388735012, 'plsr_scale': 5.032712662811895}, 'fold_4': {'plsr': 9.076960305600016, 'plsr_scale': 5.5735244774999035}, 'MSE': {'plsr': 5.961198562339783, 'plsr_scale': 4.963889312536424}, 'R2': {'plsr': 0.9900812234570006, 'plsr_scale': 0.9917406359878228}}'\n",
      "plsr: {'fold_0': 5.234029201476464, 'fold_1': 5.145096612203966, 'fold_2': 4.841440168474167, 'fold_3': 5.509237388735012, 'fold_4': 9.076960305600016, 'MSE': 5.961198562339783, 'R2': 0.9900812234570006}'\n",
      "plsr_scale: {'fold_0': 4.746335273504132, 'fold_1': 5.0072038893663855, 'fold_2': 4.459757292198208, 'fold_3': 5.032712662811895, 'fold_4': 5.5735244774999035, 'MSE': 4.963889312536424, 'R2': 0.9917406359878228}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 8 components'\n",
      "Running PLSR with 8 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:4.7465,plsr_scale:4.2286'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:4.7689,plsr_scale:4.3935'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:4.6886,plsr_scale:4.211'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:4.8308,plsr_scale:4.6478'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:4.7822,plsr_scale:4.3097'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:4.3182,plsr_scale:4.1631'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:4.6978,plsr_scale:4.3583'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:4.9358,plsr_scale:4.596'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:4.626,plsr_scale:4.1446'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:7.9608,plsr_scale:4.8481'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:4.5311,plsr_scale:4.241'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:4.6516,plsr_scale:4.5288'\n",
      "Train times: {'fold_0': 2, 'fold_1': 2, 'fold_2': 2, 'fold_3': 2, 'fold_4': 2, 'mean': 2.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 4.768937814831456, 'plsr_scale': 4.393522344997426}, 'fold_1': {'plsr': 4.8307881878920504, 'plsr_scale': 4.647777224305034}, 'fold_2': {'plsr': 4.3181991991314606, 'plsr_scale': 4.163118378696155}, 'fold_3': {'plsr': 4.935779592842635, 'plsr_scale': 4.595963539531947}, 'fold_4': {'plsr': 7.960765853191295, 'plsr_scale': 4.848085389185624}, 'MSE': {'plsr': 5.362781658317648, 'plsr_scale': 4.529691568792959}, 'R2': {'plsr': 0.9910769231453229, 'plsr_scale': 0.992463093116306}}'\n",
      "plsr: {'fold_0': 4.768937814831456, 'fold_1': 4.8307881878920504, 'fold_2': 4.3181991991314606, 'fold_3': 4.935779592842635, 'fold_4': 7.960765853191295, 'MSE': 5.362781658317648, 'R2': 0.9910769231453229}'\n",
      "plsr_scale: {'fold_0': 4.393522344997426, 'fold_1': 4.647777224305034, 'fold_2': 4.163118378696155, 'fold_3': 4.595963539531947, 'fold_4': 4.848085389185624, 'MSE': 4.529691568792959, 'R2': 0.992463093116306}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 9 components'\n",
      "Running PLSR with 9 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:4.205,plsr_scale:3.9795'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:4.2562,plsr_scale:4.1901'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:4.397,plsr_scale:3.9977'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:4.6226,plsr_scale:4.4262'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:4.4807,plsr_scale:4.1006'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:4.1113,plsr_scale:3.9527'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:4.4433,plsr_scale:4.131'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:4.6691,plsr_scale:4.4629'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:4.1381,plsr_scale:3.9155'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:4.4133,plsr_scale:4.9993'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:4.2179,plsr_scale:4.0492'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:4.2408,plsr_scale:4.3269'\n",
      "Train times: {'fold_0': 2, 'fold_1': 2, 'fold_2': 2, 'fold_3': 2, 'fold_4': 2, 'mean': 2.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 4.256192678086356, 'plsr_scale': 4.19013814017239}, 'fold_1': {'plsr': 4.622609742406996, 'plsr_scale': 4.426169271839418}, 'fold_2': {'plsr': 4.1112974222273895, 'plsr_scale': 3.952745117638546}, 'fold_3': {'plsr': 4.669138839818486, 'plsr_scale': 4.462940576578784}, 'fold_4': {'plsr': 4.413283078210447, 'plsr_scale': 4.999269339826623}, 'MSE': {'plsr': 4.414509325553471, 'plsr_scale': 4.40623289297}, 'R2': {'plsr': 0.9926547436577979, 'plsr_scale': 0.992668514728248}}'\n",
      "plsr: {'fold_0': 4.256192678086356, 'fold_1': 4.622609742406996, 'fold_2': 4.1112974222273895, 'fold_3': 4.669138839818486, 'fold_4': 4.413283078210447, 'MSE': 4.414509325553471, 'R2': 0.9926547436577979}'\n",
      "plsr_scale: {'fold_0': 4.19013814017239, 'fold_1': 4.426169271839418, 'fold_2': 3.952745117638546, 'fold_3': 4.462940576578784, 'fold_4': 4.999269339826623, 'MSE': 4.40623289297, 'R2': 0.992668514728248}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 10 components'\n",
      "Running PLSR with 10 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.9156,plsr_scale:3.7877'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.9254,plsr_scale:4.0279'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:4.0569,plsr_scale:3.7937'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:4.2142,plsr_scale:4.3514'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:4.0958,plsr_scale:3.8997'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.8305,plsr_scale:3.7792'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:4.1003,plsr_scale:3.9443'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:4.2598,plsr_scale:4.2387'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.888,plsr_scale:3.704'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:4.2132,plsr_scale:6.9935'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:4.005,plsr_scale:3.8529'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:4.0962,plsr_scale:4.3369'\n",
      "Train times: {'fold_0': 2, 'fold_1': 2, 'fold_2': 2, 'fold_3': 2, 'fold_4': 2, 'mean': 2.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 3.9254400556552147, 'plsr_scale': 4.027919403168943}, 'fold_1': {'plsr': 4.214215015948607, 'plsr_scale': 4.351387716080604}, 'fold_2': {'plsr': 3.830503810392608, 'plsr_scale': 3.7792072480954717}, 'fold_3': {'plsr': 4.259778985850518, 'plsr_scale': 4.238735586335731}, 'fold_4': {'plsr': 4.213203391291638, 'plsr_scale': 6.993456218169654}, 'MSE': {'plsr': 4.088624496191276, 'plsr_scale': 4.678043653931658}, 'R2': {'plsr': 0.9931969800499252, 'plsr_scale': 0.9922162516184443}}'\n",
      "plsr: {'fold_0': 3.9254400556552147, 'fold_1': 4.214215015948607, 'fold_2': 3.830503810392608, 'fold_3': 4.259778985850518, 'fold_4': 4.213203391291638, 'MSE': 4.088624496191276, 'R2': 0.9931969800499252}'\n",
      "plsr_scale: {'fold_0': 4.027919403168943, 'fold_1': 4.351387716080604, 'fold_2': 3.7792072480954717, 'fold_3': 4.238735586335731, 'fold_4': 6.993456218169654, 'MSE': 4.678043653931658, 'R2': 0.9922162516184443}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 11 components'\n",
      "Running PLSR with 11 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.782,plsr_scale:3.627'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.837,plsr_scale:3.9284'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.9129,plsr_scale:3.6714'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:4.0443,plsr_scale:4.2949'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.9796,plsr_scale:3.768'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.6727,plsr_scale:3.6737'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.9835,plsr_scale:3.7898'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:4.193,plsr_scale:4.2779'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.7462,plsr_scale:3.5442'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:4.0419,plsr_scale:5.6268'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:3.9001,plsr_scale:3.7142'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.9696,plsr_scale:4.2838'\n",
      "Train times: {'fold_0': 2, 'fold_1': 2, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 2.6}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 3.8370239108091164, 'plsr_scale': 3.9284134850588748}, 'fold_1': {'plsr': 4.044279222471675, 'plsr_scale': 4.294894517419298}, 'fold_2': {'plsr': 3.672681700932697, 'plsr_scale': 3.6737155169270883}, 'fold_3': {'plsr': 4.19304035340397, 'plsr_scale': 4.277946015578242}, 'fold_4': {'plsr': 4.04185882979958, 'plsr_scale': 5.626816239735314}, 'MSE': {'plsr': 3.9577733825411694, 'plsr_scale': 4.360307473930239}, 'R2': {'plsr': 0.9934147018625985, 'plsr_scale': 0.9927449295573022}}'\n",
      "plsr: {'fold_0': 3.8370239108091164, 'fold_1': 4.044279222471675, 'fold_2': 3.672681700932697, 'fold_3': 4.19304035340397, 'fold_4': 4.04185882979958, 'MSE': 3.9577733825411694, 'R2': 0.9934147018625985}'\n",
      "plsr_scale: {'fold_0': 3.9284134850588748, 'fold_1': 4.294894517419298, 'fold_2': 3.6737155169270883, 'fold_3': 4.277946015578242, 'fold_4': 5.626816239735314, 'MSE': 4.360307473930239, 'R2': 0.9927449295573022}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 12 components'\n",
      "Running PLSR with 12 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.6484,plsr_scale:3.4975'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.7085,plsr_scale:3.8447'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.7319,plsr_scale:3.5471'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.8699,plsr_scale:4.1981'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.8051,plsr_scale:3.6563'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.5094,plsr_scale:3.6045'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.803,plsr_scale:3.6896'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.9896,plsr_scale:4.241'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.6054,plsr_scale:3.4244'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.9513,plsr_scale:5.3257'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:3.7152,plsr_scale:3.6149'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.6203,plsr_scale:4.2224'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 3.7084533969863522, 'plsr_scale': 3.844703703431424}, 'fold_1': {'plsr': 3.8698880280910943, 'plsr_scale': 4.198071079643213}, 'fold_2': {'plsr': 3.509357817845344, 'plsr_scale': 3.604549036863748}, 'fold_3': {'plsr': 3.989623923886764, 'plsr_scale': 4.24103309467695}, 'fold_4': {'plsr': 3.951280414478863, 'plsr_scale': 5.325658580710868}, 'MSE': {'plsr': 3.8057174102241804, 'plsr_scale': 4.242758868999814}, 'R2': {'plsr': 0.993667706219972, 'plsr_scale': 0.9929405174635014}}'\n",
      "plsr: {'fold_0': 3.7084533969863522, 'fold_1': 3.8698880280910943, 'fold_2': 3.509357817845344, 'fold_3': 3.989623923886764, 'fold_4': 3.951280414478863, 'MSE': 3.8057174102241804, 'R2': 0.993667706219972}'\n",
      "plsr_scale: {'fold_0': 3.844703703431424, 'fold_1': 4.198071079643213, 'fold_2': 3.604549036863748, 'fold_3': 4.24103309467695, 'fold_4': 5.325658580710868, 'MSE': 4.242758868999814, 'R2': 0.9929405174635014}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 13 components'\n",
      "Running PLSR with 13 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.5072,plsr_scale:3.3761'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.5784,plsr_scale:3.8103'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.587,plsr_scale:3.4062'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.8279,plsr_scale:4.1012'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.6675,plsr_scale:3.5069'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.4161,plsr_scale:3.5165'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.6735,plsr_scale:3.5447'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.7895,plsr_scale:4.2235'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.4538,plsr_scale:3.3106'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:4.0832,plsr_scale:5.6934'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:3.5858,plsr_scale:3.4802'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.5563,plsr_scale:3.991'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 3.5784015985245086, 'plsr_scale': 3.8103475711186157}, 'fold_1': {'plsr': 3.8279228997302486, 'plsr_scale': 4.1012154226448905}, 'fold_2': {'plsr': 3.416091089506658, 'plsr_scale': 3.5164859343804107}, 'fold_3': {'plsr': 3.7894743894662613, 'plsr_scale': 4.22346441289129}, 'fold_4': {'plsr': 4.083173525130365, 'plsr_scale': 5.693429670495539}, 'MSE': {'plsr': 3.7390055389751353, 'plsr_scale': 4.2689260359646735}, 'R2': {'plsr': 0.9937787074115554, 'plsr_scale': 0.9928969781854228}}'\n",
      "plsr: {'fold_0': 3.5784015985245086, 'fold_1': 3.8279228997302486, 'fold_2': 3.416091089506658, 'fold_3': 3.7894743894662613, 'fold_4': 4.083173525130365, 'MSE': 3.7390055389751353, 'R2': 0.9937787074115554}'\n",
      "plsr_scale: {'fold_0': 3.8103475711186157, 'fold_1': 4.1012154226448905, 'fold_2': 3.5164859343804107, 'fold_3': 4.22346441289129, 'fold_4': 5.693429670495539, 'MSE': 4.2689260359646735, 'R2': 0.9928969781854228}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 14 components'\n",
      "Running PLSR with 14 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.3754,plsr_scale:3.2673'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.4968,plsr_scale:3.7943'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.4214,plsr_scale:3.2939'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.5789,plsr_scale:4.0662'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.5029,plsr_scale:3.3719'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.1845,plsr_scale:3.4768'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.5294,plsr_scale:3.4253'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.7256,plsr_scale:4.0984'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.2889,plsr_scale:3.1857'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:4.3483,plsr_scale:6.695'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:3.4266,plsr_scale:3.3449'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.4197,plsr_scale:3.8705'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 3, 'fold_4': 3, 'mean': 3.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 3.496765365206318, 'plsr_scale': 3.7942721501425907}, 'fold_1': {'plsr': 3.578866439079729, 'plsr_scale': 4.066195234491088}, 'fold_2': {'plsr': 3.1845191875148995, 'plsr_scale': 3.476835627623213}, 'fold_3': {'plsr': 3.7255789427006096, 'plsr_scale': 4.098412127929952}, 'fold_4': {'plsr': 4.3482861999708025, 'plsr_scale': 6.6949657913481575}, 'MSE': {'plsr': 3.6667774603493752, 'plsr_scale': 4.426037124682152}, 'R2': {'plsr': 0.9938988869634571, 'plsr_scale': 0.9926355626722304}}'\n",
      "plsr: {'fold_0': 3.496765365206318, 'fold_1': 3.578866439079729, 'fold_2': 3.1845191875148995, 'fold_3': 3.7255789427006096, 'fold_4': 4.3482861999708025, 'MSE': 3.6667774603493752, 'R2': 0.9938988869634571}'\n",
      "plsr_scale: {'fold_0': 3.7942721501425907, 'fold_1': 4.066195234491088, 'fold_2': 3.476835627623213, 'fold_3': 4.098412127929952, 'fold_4': 6.6949657913481575, 'MSE': 4.426037124682152, 'R2': 0.9926355626722304}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 15 components'\n",
      "Running PLSR with 15 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.0208,plsr_scale:3.1464'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1667,plsr_scale:3.7282'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.1757,plsr_scale:3.206'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.3854,plsr_scale:4.0872'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.2225,plsr_scale:3.2867'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.9422,plsr_scale:3.4351'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.3331,plsr_scale:3.3092'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.6741,plsr_scale:3.986'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.0239,plsr_scale:3.0412'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:5.6153,plsr_scale:7.1218'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:3.2338,plsr_scale:3.2706'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1855,plsr_scale:3.8285'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 4, 'fold_3': 3, 'fold_4': 3, 'mean': 3.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 3.166707917480144, 'plsr_scale': 3.7281597108298783}, 'fold_1': {'plsr': 3.385401185905249, 'plsr_scale': 4.087240899564641}, 'fold_2': {'plsr': 2.942191595664603, 'plsr_scale': 3.435075866667304}, 'fold_3': {'plsr': 3.674126417730456, 'plsr_scale': 3.9860100104810634}, 'fold_4': {'plsr': 5.6153417891657496, 'plsr_scale': 7.121832957476318}, 'MSE': {'plsr': 3.756657756572882, 'plsr_scale': 4.471551231476113}, 'R2': {'plsr': 0.9937493360695325, 'plsr_scale': 0.9925598322213617}}'\n",
      "plsr: {'fold_0': 3.166707917480144, 'fold_1': 3.385401185905249, 'fold_2': 2.942191595664603, 'fold_3': 3.674126417730456, 'fold_4': 5.6153417891657496, 'MSE': 3.756657756572882, 'R2': 0.9937493360695325}'\n",
      "plsr_scale: {'fold_0': 3.7281597108298783, 'fold_1': 4.087240899564641, 'fold_2': 3.435075866667304, 'fold_3': 3.9860100104810634, 'fold_4': 7.121832957476318, 'MSE': 4.471551231476113, 'R2': 0.9925598322213617}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 16 components'\n",
      "Running PLSR with 16 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.9444,plsr_scale:3.0622'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0704,plsr_scale:3.7358'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.1175,plsr_scale:3.1209'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.3508,plsr_scale:4.0287'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.1176,plsr_scale:3.2106'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.86,plsr_scale:3.3707'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.1992,plsr_scale:3.2326'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.4463,plsr_scale:3.983'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.8823,plsr_scale:2.9696'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:7.47,plsr_scale:7.5902'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:3.119,plsr_scale:3.1649'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0317,plsr_scale:3.7336'\n",
      "Train times: {'fold_0': 3, 'fold_1': 3, 'fold_2': 3, 'fold_3': 4, 'fold_4': 4, 'mean': 3.4}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 3.0703779311233057, 'plsr_scale': 3.735820628931863}, 'fold_1': {'plsr': 3.350769718730353, 'plsr_scale': 4.0286585566484785}, 'fold_2': {'plsr': 2.860003913823001, 'plsr_scale': 3.37069106469354}, 'fold_3': {'plsr': 3.4463183622303055, 'plsr_scale': 3.9830276373668503}, 'fold_4': {'plsr': 7.4700269893645554, 'plsr_scale': 7.590220501029208}, 'MSE': {'plsr': 4.0393337966463685, 'plsr_scale': 4.541551946993887}, 'R2': {'plsr': 0.993278994334355, 'plsr_scale': 0.9924433587558649}}'\n",
      "plsr: {'fold_0': 3.0703779311233057, 'fold_1': 3.350769718730353, 'fold_2': 2.860003913823001, 'fold_3': 3.4463183622303055, 'fold_4': 7.4700269893645554, 'MSE': 4.0393337966463685, 'R2': 0.993278994334355}'\n",
      "plsr_scale: {'fold_0': 3.735820628931863, 'fold_1': 4.0286585566484785, 'fold_2': 3.37069106469354, 'fold_3': 3.9830276373668503, 'fold_4': 7.590220501029208, 'MSE': 4.541551946993887, 'R2': 0.9924433587558649}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 17 components'\n",
      "Running PLSR with 17 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.8537,plsr_scale:2.9976'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.9677,plsr_scale:3.6893'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.0323,plsr_scale:3.0569'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.2391,plsr_scale:4.0247'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.0413,plsr_scale:3.1504'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.7832,plsr_scale:3.3366'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:3.0877,plsr_scale:3.1445'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.4566,plsr_scale:3.9463'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.7636,plsr_scale:2.8996'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:10.1225,plsr_scale:8.449'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:3.0246,plsr_scale:3.1237'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.92,plsr_scale:3.717'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.9677144989476556, 'plsr_scale': 3.689258756930435}, 'fold_1': {'plsr': 3.23907075923449, 'plsr_scale': 4.024717708253123}, 'fold_2': {'plsr': 2.783215537805106, 'plsr_scale': 3.336623213242257}, 'fold_3': {'plsr': 3.456568911158483, 'plsr_scale': 3.946287761367941}, 'fold_4': {'plsr': 10.12246599051052, 'plsr_scale': 8.449009411433565}, 'MSE': {'plsr': 4.513525394722933, 'plsr_scale': 4.689013131504423}, 'R2': {'plsr': 0.9924899918458951, 'plsr_scale': 0.9921979996183306}}'\n",
      "plsr: {'fold_0': 2.9677144989476556, 'fold_1': 3.23907075923449, 'fold_2': 2.783215537805106, 'fold_3': 3.456568911158483, 'fold_4': 10.12246599051052, 'MSE': 4.513525394722933, 'R2': 0.9924899918458951}'\n",
      "plsr_scale: {'fold_0': 3.689258756930435, 'fold_1': 4.024717708253123, 'fold_2': 3.336623213242257, 'fold_3': 3.946287761367941, 'fold_4': 8.449009411433565, 'MSE': 4.689013131504423, 'R2': 0.9921979996183306}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 18 components'\n",
      "Running PLSR with 18 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.717,plsr_scale:2.9113'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8025,plsr_scale:3.6088'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.9305,plsr_scale:2.9771'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.2472,plsr_scale:3.9759'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.9591,plsr_scale:3.0547'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.79,plsr_scale:3.2805'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.9555,plsr_scale:2.9385'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.3569,plsr_scale:3.8348'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.5964,plsr_scale:2.7815'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:16.3191,plsr_scale:8.6575'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.8918,plsr_scale:2.9865'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7752,plsr_scale:3.6372'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.802497083972449, 'plsr_scale': 3.608751836642751}, 'fold_1': {'plsr': 3.247216457378626, 'plsr_scale': 3.9759067132866135}, 'fold_2': {'plsr': 2.7900230040496035, 'plsr_scale': 3.2805438655489625}, 'fold_3': {'plsr': 3.3568955908144558, 'plsr_scale': 3.8347704896033803}, 'fold_4': {'plsr': 16.319090000719974, 'plsr_scale': 8.657450168805035}, 'MSE': {'plsr': 5.702609411874294, 'plsr_scale': 4.671308994453773}, 'R2': {'plsr': 0.9905114872660465, 'plsr_scale': 0.9922274573485933}}'\n",
      "plsr: {'fold_0': 2.802497083972449, 'fold_1': 3.247216457378626, 'fold_2': 2.7900230040496035, 'fold_3': 3.3568955908144558, 'fold_4': 16.319090000719974, 'MSE': 5.702609411874294, 'R2': 0.9905114872660465}'\n",
      "plsr_scale: {'fold_0': 3.608751836642751, 'fold_1': 3.9759067132866135, 'fold_2': 3.2805438655489625, 'fold_3': 3.8347704896033803, 'fold_4': 8.657450168805035, 'MSE': 4.671308994453773, 'R2': 0.9922274573485933}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 19 components'\n",
      "Running PLSR with 19 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.667,plsr_scale:2.8117'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7451,plsr_scale:3.494'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.8738,plsr_scale:2.8579'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1669,plsr_scale:3.9226'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.8874,plsr_scale:2.9302'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.792,plsr_scale:3.1987'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.872,plsr_scale:2.8681'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.3082,plsr_scale:3.8601'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.5422,plsr_scale:2.6881'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:18.7904,plsr_scale:9.4803'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.8234,plsr_scale:2.8852'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7525,plsr_scale:3.5329'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.7450698838421537, 'plsr_scale': 3.4940397501203364}, 'fold_1': {'plsr': 3.1668882613400586, 'plsr_scale': 3.9226261376551714}, 'fold_2': {'plsr': 2.792002370933062, 'plsr_scale': 3.1987258001564913}, 'fold_3': {'plsr': 3.3082223690617756, 'plsr_scale': 3.860122042138591}, 'fold_4': {'plsr': 18.79037768543734, 'plsr_scale': 9.48029803555321}, 'MSE': {'plsr': 6.159871975680702, 'plsr_scale': 4.79094604681049}, 'R2': {'plsr': 0.9897506528223613, 'plsr_scale': 0.9920283944963532}}'\n",
      "plsr: {'fold_0': 2.7450698838421537, 'fold_1': 3.1668882613400586, 'fold_2': 2.792002370933062, 'fold_3': 3.3082223690617756, 'fold_4': 18.79037768543734, 'MSE': 6.159871975680702, 'R2': 0.9897506528223613}'\n",
      "plsr_scale: {'fold_0': 3.4940397501203364, 'fold_1': 3.9226261376551714, 'fold_2': 3.1987258001564913, 'fold_3': 3.860122042138591, 'fold_4': 9.48029803555321, 'MSE': 4.79094604681049, 'R2': 0.9920283944963532}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 20 components'\n",
      "Running PLSR with 20 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.585,plsr_scale:2.7147'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6671,plsr_scale:3.4052'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.7736,plsr_scale:2.7634'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1243,plsr_scale:3.814'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.775,plsr_scale:2.8251'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.7698,plsr_scale:3.1729'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.7529,plsr_scale:2.7767'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2083,plsr_scale:3.8563'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.4375,plsr_scale:2.5991'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:22.2714,plsr_scale:9.1136'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.7043,plsr_scale:2.8035'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.71,plsr_scale:3.4388'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.6671366886039793, 'plsr_scale': 3.405212531987125}, 'fold_1': {'plsr': 3.1243438466173896, 'plsr_scale': 3.8140440648650484}, 'fold_2': {'plsr': 2.769827014649314, 'plsr_scale': 3.1729468324274475}, 'fold_3': {'plsr': 3.208312667732252, 'plsr_scale': 3.8563228181237017}, 'fold_4': {'plsr': 22.271350774247942, 'plsr_scale': 9.113586161523411}, 'MSE': {'plsr': 6.80741264544753, 'plsr_scale': 4.672210177713561}, 'R2': {'plsr': 0.9886732166090304, 'plsr_scale': 0.9922259578791016}}'\n",
      "plsr: {'fold_0': 2.6671366886039793, 'fold_1': 3.1243438466173896, 'fold_2': 2.769827014649314, 'fold_3': 3.208312667732252, 'fold_4': 22.271350774247942, 'MSE': 6.80741264544753, 'R2': 0.9886732166090304}'\n",
      "plsr_scale: {'fold_0': 3.405212531987125, 'fold_1': 3.8140440648650484, 'fold_2': 3.1729468324274475, 'fold_3': 3.8563228181237017, 'fold_4': 9.113586161523411, 'MSE': 4.672210177713561, 'R2': 0.9922259578791016}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 21 components'\n",
      "Running PLSR with 21 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.5183,plsr_scale:2.6576'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5996,plsr_scale:3.3307'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.7025,plsr_scale:2.7066'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.11,plsr_scale:3.7776'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.6795,plsr_scale:2.7149'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.791,plsr_scale:3.1261'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.654,plsr_scale:2.69'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.1632,plsr_scale:3.8388'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.3493,plsr_scale:2.5489'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:21.6929,plsr_scale:9.6089'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.6151,plsr_scale:2.7482'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6749,plsr_scale:3.3775'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.599563285911879, 'plsr_scale': 3.330669979720892}, 'fold_1': {'plsr': 3.1100431354335076, 'plsr_scale': 3.77764582681713}, 'fold_2': {'plsr': 2.7909566040104195, 'plsr_scale': 3.1260934586874396}, 'fold_3': {'plsr': 3.1631833618554643, 'plsr_scale': 3.8387562667287547}, 'fold_4': {'plsr': 21.69292074472178, 'plsr_scale': 9.608932544474273}, 'MSE': {'plsr': 6.670571035212874, 'plsr_scale': 4.736183446346022}, 'R2': {'plsr': 0.9889009059469224, 'plsr_scale': 0.9921195134200461}}'\n",
      "plsr: {'fold_0': 2.599563285911879, 'fold_1': 3.1100431354335076, 'fold_2': 2.7909566040104195, 'fold_3': 3.1631833618554643, 'fold_4': 21.69292074472178, 'MSE': 6.670571035212874, 'R2': 0.9889009059469224}'\n",
      "plsr_scale: {'fold_0': 3.330669979720892, 'fold_1': 3.77764582681713, 'fold_2': 3.1260934586874396, 'fold_3': 3.8387562667287547, 'fold_4': 9.608932544474273, 'MSE': 4.736183446346022, 'R2': 0.9921195134200461}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 22 components'\n",
      "Running PLSR with 22 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.4296,plsr_scale:2.586'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5772,plsr_scale:3.3036'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.5906,plsr_scale:2.609'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0838,plsr_scale:3.6509'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.5917,plsr_scale:2.6669'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.7009,plsr_scale:3.0999'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.5659,plsr_scale:2.6447'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.1257,plsr_scale:3.7548'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.2899,plsr_scale:2.4714'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:19.5252,plsr_scale:11.3287'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.5374,plsr_scale:2.6563'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.635,plsr_scale:3.2912'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 4, 'fold_3': 4, 'fold_4': 4, 'mean': 4.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.5772348998687, 'plsr_scale': 3.303583804120062}, 'fold_1': {'plsr': 3.0837705972369815, 'plsr_scale': 3.6509184889532746}, 'fold_2': {'plsr': 2.7008509048237386, 'plsr_scale': 3.0998931243224987}, 'fold_3': {'plsr': 3.1256749109080997, 'plsr_scale': 3.754836435432706}, 'fold_4': {'plsr': 19.52517756795832, 'plsr_scale': 11.328677987063699}, 'MSE': {'plsr': 6.20186817667303, 'plsr_scale': 5.027272273447596}, 'R2': {'plsr': 0.9896807757785182, 'plsr_scale': 0.9916351737356704}}'\n",
      "plsr: {'fold_0': 2.5772348998687, 'fold_1': 3.0837705972369815, 'fold_2': 2.7008509048237386, 'fold_3': 3.1256749109080997, 'fold_4': 19.52517756795832, 'MSE': 6.20186817667303, 'R2': 0.9896807757785182}'\n",
      "plsr_scale: {'fold_0': 3.303583804120062, 'fold_1': 3.6509184889532746, 'fold_2': 3.0998931243224987, 'fold_3': 3.754836435432706, 'fold_4': 11.328677987063699, 'MSE': 5.027272273447596, 'R2': 0.9916351737356704}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 23 components'\n",
      "Running PLSR with 23 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.3724,plsr_scale:2.4874'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5172,plsr_scale:3.19'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.5311,plsr_scale:2.5302'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0282,plsr_scale:3.6473'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.5424,plsr_scale:2.6051'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6796,plsr_scale:3.0585'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.5159,plsr_scale:2.5631'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.1419,plsr_scale:3.6898'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.232,plsr_scale:2.3918'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:16.1433,plsr_scale:10.9225'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.485,plsr_scale:2.571'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6744,plsr_scale:3.2277'\n",
      "Train times: {'fold_0': 5, 'fold_1': 5, 'fold_2': 5, 'fold_3': 4, 'fold_4': 4, 'mean': 4.6}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.5172086244467873, 'plsr_scale': 3.1900211433328254}, 'fold_1': {'plsr': 3.0282147841534632, 'plsr_scale': 3.647312502429547}, 'fold_2': {'plsr': 2.679611717688499, 'plsr_scale': 3.0585095590984857}, 'fold_3': {'plsr': 3.1419031975901435, 'plsr_scale': 3.6897933217112713}, 'fold_4': {'plsr': 16.143268964590057, 'plsr_scale': 10.922494740042593}, 'MSE': {'plsr': 5.5014962459971475, 'plsr_scale': 4.9013300169205385}, 'R2': {'plsr': 0.9908461173796603, 'plsr_scale': 0.9918447277518216}}'\n",
      "plsr: {'fold_0': 2.5172086244467873, 'fold_1': 3.0282147841534632, 'fold_2': 2.679611717688499, 'fold_3': 3.1419031975901435, 'fold_4': 16.143268964590057, 'MSE': 5.5014962459971475, 'R2': 0.9908461173796603}'\n",
      "plsr_scale: {'fold_0': 3.1900211433328254, 'fold_1': 3.647312502429547, 'fold_2': 3.0585095590984857, 'fold_3': 3.6897933217112713, 'fold_4': 10.922494740042593, 'MSE': 4.9013300169205385, 'R2': 0.9918447277518216}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 24 components'\n",
      "Running PLSR with 24 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.3281,plsr_scale:2.4261'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5143,plsr_scale:3.1511'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.4694,plsr_scale:2.4606'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.9652,plsr_scale:3.5908'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.4669,plsr_scale:2.5386'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6354,plsr_scale:2.9912'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.4599,plsr_scale:2.5004'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.1682,plsr_scale:3.6445'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.1987,plsr_scale:2.3316'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:14.6216,plsr_scale:10.6587'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.4449,plsr_scale:2.5175'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6762,plsr_scale:3.1609'\n",
      "Train times: {'fold_0': 4, 'fold_1': 4, 'fold_2': 5, 'fold_3': 5, 'fold_4': 5, 'mean': 4.6}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.514287116540102, 'plsr_scale': 3.151067604574485}, 'fold_1': {'plsr': 2.9651730837575943, 'plsr_scale': 3.5908373653243024}, 'fold_2': {'plsr': 2.635375995362839, 'plsr_scale': 2.9912374205569834}, 'fold_3': {'plsr': 3.1681872964844575, 'plsr_scale': 3.6444973919084958}, 'fold_4': {'plsr': 14.62160573820382, 'plsr_scale': 10.65872750405414}, 'MSE': {'plsr': 5.180438192105336, 'plsr_scale': 4.806986537393083}, 'R2': {'plsr': 0.9913803225500771, 'plsr_scale': 0.9920017048902169}}'\n",
      "plsr: {'fold_0': 2.514287116540102, 'fold_1': 2.9651730837575943, 'fold_2': 2.635375995362839, 'fold_3': 3.1681872964844575, 'fold_4': 14.62160573820382, 'MSE': 5.180438192105336, 'R2': 0.9913803225500771}'\n",
      "plsr_scale: {'fold_0': 3.151067604574485, 'fold_1': 3.5908373653243024, 'fold_2': 2.9912374205569834, 'fold_3': 3.6444973919084958, 'fold_4': 10.65872750405414, 'MSE': 4.806986537393083, 'R2': 0.9920017048902169}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 25 components'\n",
      "Running PLSR with 25 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.2989,plsr_scale:2.3607'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5204,plsr_scale:3.1217'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.4227,plsr_scale:2.4082'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.988,plsr_scale:3.5524'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.4095,plsr_scale:2.4791'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6734,plsr_scale:2.9893'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.4139,plsr_scale:2.4441'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.157,plsr_scale:3.634'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.1737,plsr_scale:2.2625'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:14.0036,plsr_scale:10.8735'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.4027,plsr_scale:2.459'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6082,plsr_scale:3.093'\n",
      "Train times: {'fold_0': 5, 'fold_1': 5, 'fold_2': 5, 'fold_3': 5, 'fold_4': 5, 'mean': 5.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.52036834500669, 'plsr_scale': 3.1216990147034576}, 'fold_1': {'plsr': 2.987952802533634, 'plsr_scale': 3.5524383970052313}, 'fold_2': {'plsr': 2.6734097712968086, 'plsr_scale': 2.9892578026317853}, 'fold_3': {'plsr': 3.1570408228614686, 'plsr_scale': 3.6339533667018946}, 'fold_4': {'plsr': 14.003600759921875, 'plsr_scale': 10.873542128352758}, 'MSE': {'plsr': 5.068012192308403, 'plsr_scale': 4.833879078867434}, 'R2': {'plsr': 0.9915673870066537, 'plsr_scale': 0.9919569586690051}}'\n",
      "plsr: {'fold_0': 2.52036834500669, 'fold_1': 2.987952802533634, 'fold_2': 2.6734097712968086, 'fold_3': 3.1570408228614686, 'fold_4': 14.003600759921875, 'MSE': 5.068012192308403, 'R2': 0.9915673870066537}'\n",
      "plsr_scale: {'fold_0': 3.1216990147034576, 'fold_1': 3.5524383970052313, 'fold_2': 2.9892578026317853, 'fold_3': 3.6339533667018946, 'fold_4': 10.873542128352758, 'MSE': 4.833879078867434, 'R2': 0.9919569586690051}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 26 components'\n",
      "Running PLSR with 26 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.2448,plsr_scale:2.3123'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5076,plsr_scale:3.1102'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.3813,plsr_scale:2.3479'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.9543,plsr_scale:3.4709'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.3718,plsr_scale:2.4295'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6649,plsr_scale:2.8949'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.3606,plsr_scale:2.3922'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.1182,plsr_scale:3.5706'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.1124,plsr_scale:2.2105'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:12.8989,plsr_scale:10.9228'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.3558,plsr_scale:2.4096'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5766,plsr_scale:3.0628'\n",
      "Train times: {'fold_0': 5, 'fold_1': 5, 'fold_2': 5, 'fold_3': 5, 'fold_4': 5, 'mean': 5.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.507615851204255, 'plsr_scale': 3.1102429758648724}, 'fold_1': {'plsr': 2.9543476182289092, 'plsr_scale': 3.4709460065175106}, 'fold_2': {'plsr': 2.6648608132078917, 'plsr_scale': 2.894869469734693}, 'fold_3': {'plsr': 3.1181605319290164, 'plsr_scale': 3.570629877198152}, 'fold_4': {'plsr': 12.898946920577988, 'plsr_scale': 10.922810898612646}, 'MSE': {'plsr': 4.8283672889768114, 'plsr_scale': 4.793599544875548}, 'R2': {'plsr': 0.9919661296791142, 'plsr_scale': 0.9920239793684071}}'\n",
      "plsr: {'fold_0': 2.507615851204255, 'fold_1': 2.9543476182289092, 'fold_2': 2.6648608132078917, 'fold_3': 3.1181605319290164, 'fold_4': 12.898946920577988, 'MSE': 4.8283672889768114, 'R2': 0.9919661296791142}'\n",
      "plsr_scale: {'fold_0': 3.1102429758648724, 'fold_1': 3.4709460065175106, 'fold_2': 2.894869469734693, 'fold_3': 3.570629877198152, 'fold_4': 10.922810898612646, 'MSE': 4.793599544875548, 'R2': 0.9920239793684071}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 27 components'\n",
      "Running PLSR with 27 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.1764,plsr_scale:2.2619'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5138,plsr_scale:3.0311'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.3067,plsr_scale:2.3023'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.9513,plsr_scale:3.4435'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.3118,plsr_scale:2.3856'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6507,plsr_scale:2.8659'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.306,plsr_scale:2.3508'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.0936,plsr_scale:3.5503'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0473,plsr_scale:2.1689'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:13.5914,plsr_scale:10.1711'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.2945,plsr_scale:2.3717'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5775,plsr_scale:3.041'\n",
      "Train times: {'fold_0': 5, 'fold_1': 5, 'fold_2': 5, 'fold_3': 5, 'fold_4': 5, 'mean': 5.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.513839647185926, 'plsr_scale': 3.031114635739566}, 'fold_1': {'plsr': 2.9513066672453125, 'plsr_scale': 3.4435473779867607}, 'fold_2': {'plsr': 2.6506909751518766, 'plsr_scale': 2.8658519745761595}, 'fold_3': {'plsr': 3.0935526965230347, 'plsr_scale': 3.550336740674095}, 'fold_4': {'plsr': 13.591432033587155, 'plsr_scale': 10.171084719463682}, 'MSE': {'plsr': 4.959719419670439, 'plsr_scale': 4.6121124080894065}, 'R2': {'plsr': 0.9917475742293717, 'plsr_scale': 0.9923259539354988}}'\n",
      "plsr: {'fold_0': 2.513839647185926, 'fold_1': 2.9513066672453125, 'fold_2': 2.6506909751518766, 'fold_3': 3.0935526965230347, 'fold_4': 13.591432033587155, 'MSE': 4.959719419670439, 'R2': 0.9917475742293717}'\n",
      "plsr_scale: {'fold_0': 3.031114635739566, 'fold_1': 3.4435473779867607, 'fold_2': 2.8658519745761595, 'fold_3': 3.550336740674095, 'fold_4': 10.171084719463682, 'MSE': 4.6121124080894065, 'R2': 0.9923259539354988}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 28 components'\n",
      "Running PLSR with 28 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.1229,plsr_scale:2.23'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.529,plsr_scale:3.0198'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.2434,plsr_scale:2.2605'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.998,plsr_scale:3.3989'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.2533,plsr_scale:2.3337'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6612,plsr_scale:2.8974'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.2499,plsr_scale:2.3086'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.0583,plsr_scale:3.5101'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0064,plsr_scale:2.13'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:14.1067,plsr_scale:9.1066'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.2437,plsr_scale:2.3295'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5508,plsr_scale:2.9719'\n",
      "Train times: {'fold_0': 5, 'fold_1': 5, 'fold_2': 6, 'fold_3': 6, 'fold_4': 6, 'mean': 5.6}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.528955558648803, 'plsr_scale': 3.019841448750421}, 'fold_1': {'plsr': 2.9979754261076894, 'plsr_scale': 3.3988973307278503}, 'fold_2': {'plsr': 2.6612494026881834, 'plsr_scale': 2.8973627267878617}, 'fold_3': {'plsr': 3.0582915127827706, 'plsr_scale': 3.5100578123510595}, 'fold_4': {'plsr': 14.106662550765371, 'plsr_scale': 9.106598435787644}, 'MSE': {'plsr': 5.070166010974069, 'plsr_scale': 4.386316396633836}, 'R2': {'plsr': 0.9915638032900848, 'plsr_scale': 0.9927016535802108}}'\n",
      "plsr: {'fold_0': 2.528955558648803, 'fold_1': 2.9979754261076894, 'fold_2': 2.6612494026881834, 'fold_3': 3.0582915127827706, 'fold_4': 14.106662550765371, 'MSE': 5.070166010974069, 'R2': 0.9915638032900848}'\n",
      "plsr_scale: {'fold_0': 3.019841448750421, 'fold_1': 3.3988973307278503, 'fold_2': 2.8973627267878617, 'fold_3': 3.5100578123510595, 'fold_4': 9.106598435787644, 'MSE': 4.386316396633836, 'R2': 0.9927016535802108}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 29 components'\n",
      "Running PLSR with 29 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0811,plsr_scale:2.1836'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5418,plsr_scale:3.0113'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.1904,plsr_scale:2.2244'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0121,plsr_scale:3.3677'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.2089,plsr_scale:2.2965'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6669,plsr_scale:2.8659'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.1901,plsr_scale:2.2738'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.0254,plsr_scale:3.4691'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9655,plsr_scale:2.0843'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:13.3418,plsr_scale:9.3277'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.1944,plsr_scale:2.2979'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5372,plsr_scale:2.9333'\n",
      "Train times: {'fold_0': 6, 'fold_1': 6, 'fold_2': 6, 'fold_3': 6, 'fold_4': 6, 'mean': 6.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.541812672993444, 'plsr_scale': 3.0112679789242613}, 'fold_1': {'plsr': 3.012070845807276, 'plsr_scale': 3.3676649151373454}, 'fold_2': {'plsr': 2.6668749957140703, 'plsr_scale': 2.8659023930090384}, 'fold_3': {'plsr': 3.02540858327028, 'plsr_scale': 3.469136234313414}, 'fold_4': {'plsr': 13.341813449200588, 'plsr_scale': 9.327681507576537}, 'MSE': {'plsr': 4.917168491668407, 'plsr_scale': 4.408087125137153}, 'R2': {'plsr': 0.9918183742777403, 'plsr_scale': 0.9926654294905508}}'\n",
      "plsr: {'fold_0': 2.541812672993444, 'fold_1': 3.012070845807276, 'fold_2': 2.6668749957140703, 'fold_3': 3.02540858327028, 'fold_4': 13.341813449200588, 'MSE': 4.917168491668407, 'R2': 0.9918183742777403}'\n",
      "plsr_scale: {'fold_0': 3.0112679789242613, 'fold_1': 3.3676649151373454, 'fold_2': 2.8659023930090384, 'fold_3': 3.469136234313414, 'fold_4': 9.327681507576537, 'MSE': 4.408087125137153, 'R2': 0.9926654294905508}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 30 components'\n",
      "Running PLSR with 30 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.052,plsr_scale:2.1407'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5398,plsr_scale:2.9856'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.1567,plsr_scale:2.1867'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.9868,plsr_scale:3.3694'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.1729,plsr_scale:2.2536'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6375,plsr_scale:2.8453'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.1503,plsr_scale:2.2343'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.0452,plsr_scale:3.447'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9306,plsr_scale:2.054'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:11.3997,plsr_scale:8.1783'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.1638,plsr_scale:2.2609'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5607,plsr_scale:2.8946'\n",
      "Train times: {'fold_0': 6, 'fold_1': 6, 'fold_2': 6, 'fold_3': 6, 'fold_4': 6, 'mean': 6.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.5398120694177453, 'plsr_scale': 2.9856379868974017}, 'fold_1': {'plsr': 2.9868049048175616, 'plsr_scale': 3.3693947240398923}, 'fold_2': {'plsr': 2.6374543436808855, 'plsr_scale': 2.845304602381825}, 'fold_3': {'plsr': 3.045208435258502, 'plsr_scale': 3.4469705564869413}, 'fold_4': {'plsr': 11.399661512727963, 'plsr_scale': 8.178309867735873}, 'MSE': {'plsr': 4.521436978756627, 'plsr_scale': 4.164926262811615}, 'R2': {'plsr': 0.992476827843168, 'plsr_scale': 0.9930700223307638}}'\n",
      "plsr: {'fold_0': 2.5398120694177453, 'fold_1': 2.9868049048175616, 'fold_2': 2.6374543436808855, 'fold_3': 3.045208435258502, 'fold_4': 11.399661512727963, 'MSE': 4.521436978756627, 'R2': 0.992476827843168}'\n",
      "plsr_scale: {'fold_0': 2.9856379868974017, 'fold_1': 3.3693947240398923, 'fold_2': 2.845304602381825, 'fold_3': 3.4469705564869413, 'fold_4': 8.178309867735873, 'MSE': 4.164926262811615, 'R2': 0.9930700223307638}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 31 components'\n",
      "Running PLSR with 31 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0233,plsr_scale:2.1036'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5139,plsr_scale:2.9892'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.1298,plsr_scale:2.1604'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.985,plsr_scale:3.3436'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.1406,plsr_scale:2.2259'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6202,plsr_scale:2.8436'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.1252,plsr_scale:2.211'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.0365,plsr_scale:3.4567'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9044,plsr_scale:2.0268'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:10.1358,plsr_scale:8.0529'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.1375,plsr_scale:2.2344'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5524,plsr_scale:2.875'\n",
      "Train times: {'fold_0': 6, 'fold_1': 6, 'fold_2': 6, 'fold_3': 6, 'fold_4': 6, 'mean': 6.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.5139417226225516, 'plsr_scale': 2.989210173232235}, 'fold_1': {'plsr': 2.985007652357787, 'plsr_scale': 3.343607533620112}, 'fold_2': {'plsr': 2.6202052521015244, 'plsr_scale': 2.8435620381308957}, 'fold_3': {'plsr': 3.0364606564017804, 'plsr_scale': 3.456706906197977}, 'fold_4': {'plsr': 10.13583434742091, 'plsr_scale': 8.05288536971946}, 'MSE': {'plsr': 4.257988524814811, 'plsr_scale': 4.137000479779266}, 'R2': {'plsr': 0.9929151769969365, 'plsr_scale': 0.9931164877519018}}'\n",
      "plsr: {'fold_0': 2.5139417226225516, 'fold_1': 2.985007652357787, 'fold_2': 2.6202052521015244, 'fold_3': 3.0364606564017804, 'fold_4': 10.13583434742091, 'MSE': 4.257988524814811, 'R2': 0.9929151769969365}'\n",
      "plsr_scale: {'fold_0': 2.989210173232235, 'fold_1': 3.343607533620112, 'fold_2': 2.8435620381308957, 'fold_3': 3.456706906197977, 'fold_4': 8.05288536971946, 'MSE': 4.137000479779266, 'R2': 0.9931164877519018}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 32 components'\n",
      "Running PLSR with 32 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0018,plsr_scale:2.0779'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5244,plsr_scale:2.9832'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0938,plsr_scale:2.132'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.96,plsr_scale:3.3155'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.1057,plsr_scale:2.2007'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6054,plsr_scale:2.8544'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0935,plsr_scale:2.1796'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.029,plsr_scale:3.4407'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8785,plsr_scale:1.9927'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:10.0175,plsr_scale:7.7721'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.1096,plsr_scale:2.2104'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5337,plsr_scale:2.8441'\n",
      "Train times: {'fold_0': 6, 'fold_1': 6, 'fold_2': 6, 'fold_3': 6, 'fold_4': 6, 'mean': 6.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.5243613385681227, 'plsr_scale': 2.983246158732634}, 'fold_1': {'plsr': 2.959950912897472, 'plsr_scale': 3.3154972434640495}, 'fold_2': {'plsr': 2.605429113431218, 'plsr_scale': 2.8543870269697393}, 'fold_3': {'plsr': 3.0289868017761203, 'plsr_scale': 3.440712195844975}, 'fold_4': {'plsr': 10.017491020069988, 'plsr_scale': 7.772120144519228}, 'MSE': {'plsr': 4.226947175800119, 'plsr_scale': 4.073008011186826}, 'R2': {'plsr': 0.9929668263760422, 'plsr_scale': 0.9932229641575717}}'\n",
      "plsr: {'fold_0': 2.5243613385681227, 'fold_1': 2.959950912897472, 'fold_2': 2.605429113431218, 'fold_3': 3.0289868017761203, 'fold_4': 10.017491020069988, 'MSE': 4.226947175800119, 'R2': 0.9929668263760422}'\n",
      "plsr_scale: {'fold_0': 2.983246158732634, 'fold_1': 3.3154972434640495, 'fold_2': 2.8543870269697393, 'fold_3': 3.440712195844975, 'fold_4': 7.772120144519228, 'MSE': 4.073008011186826, 'R2': 0.9932229641575717}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 33 components'\n",
      "Running PLSR with 33 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9807,plsr_scale:2.0532'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5328,plsr_scale:3.0153'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0733,plsr_scale:2.1022'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.9627,plsr_scale:3.3157'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0915,plsr_scale:2.1728'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.5846,plsr_scale:2.8279'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.077,plsr_scale:2.15'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.0496,plsr_scale:3.4297'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8601,plsr_scale:1.9663'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:10.4715,plsr_scale:7.34'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.0913,plsr_scale:2.1819'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.4971,plsr_scale:2.8304'\n",
      "Train times: {'fold_0': 6, 'fold_1': 6, 'fold_2': 6, 'fold_3': 6, 'fold_4': 6, 'mean': 6.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.5328000834934548, 'plsr_scale': 3.0153310136257723}, 'fold_1': {'plsr': 2.9626719315999903, 'plsr_scale': 3.3157269504749984}, 'fold_2': {'plsr': 2.584580716684515, 'plsr_scale': 2.827869324062168}, 'fold_3': {'plsr': 3.0495930021295394, 'plsr_scale': 3.4296963635016944}, 'fold_4': {'plsr': 10.471461415679803, 'plsr_scale': 7.340000295124679}, 'MSE': {'plsr': 4.319907309777155, 'plsr_scale': 3.985560946807461}, 'R2': {'plsr': 0.9928121509719798, 'plsr_scale': 0.9933684664222338}}'\n",
      "plsr: {'fold_0': 2.5328000834934548, 'fold_1': 2.9626719315999903, 'fold_2': 2.584580716684515, 'fold_3': 3.0495930021295394, 'fold_4': 10.471461415679803, 'MSE': 4.319907309777155, 'R2': 0.9928121509719798}'\n",
      "plsr_scale: {'fold_0': 3.0153310136257723, 'fold_1': 3.3157269504749984, 'fold_2': 2.827869324062168, 'fold_3': 3.4296963635016944, 'fold_4': 7.340000295124679, 'MSE': 3.985560946807461, 'R2': 0.9933684664222338}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 34 components'\n",
      "Running PLSR with 34 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9662,plsr_scale:2.0351'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5332,plsr_scale:2.9707'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0519,plsr_scale:2.0725'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.9615,plsr_scale:3.3111'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0711,plsr_scale:2.1404'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.575,plsr_scale:2.8167'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0557,plsr_scale:2.1215'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.0684,plsr_scale:3.4318'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8447,plsr_scale:1.9366'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:10.7261,plsr_scale:7.0864'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.0724,plsr_scale:2.1547'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5071,plsr_scale:2.8109'\n",
      "Train times: {'fold_0': 6, 'fold_1': 6, 'fold_2': 6, 'fold_3': 6, 'fold_4': 6, 'mean': 6.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.5332487625069002, 'plsr_scale': 2.970745195988395}, 'fold_1': {'plsr': 2.961516724240323, 'plsr_scale': 3.3110801332076347}, 'fold_2': {'plsr': 2.5749831503295155, 'plsr_scale': 2.8167289364425554}, 'fold_3': {'plsr': 3.0683629476916265, 'plsr_scale': 3.431750375860784}, 'fold_4': {'plsr': 10.726107937279536, 'plsr_scale': 7.086421728542899}, 'MSE': {'plsr': 4.37251920182048, 'plsr_scale': 3.9231889750453277}, 'R2': {'plsr': 0.9927246105897521, 'plsr_scale': 0.9934722465000126}}'\n",
      "plsr: {'fold_0': 2.5332487625069002, 'fold_1': 2.961516724240323, 'fold_2': 2.5749831503295155, 'fold_3': 3.0683629476916265, 'fold_4': 10.726107937279536, 'MSE': 4.37251920182048, 'R2': 0.9927246105897521}'\n",
      "plsr_scale: {'fold_0': 2.970745195988395, 'fold_1': 3.3110801332076347, 'fold_2': 2.8167289364425554, 'fold_3': 3.431750375860784, 'fold_4': 7.086421728542899, 'MSE': 3.9231889750453277, 'R2': 0.9934722465000126}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 35 components'\n",
      "Running PLSR with 35 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9485,plsr_scale:2.0116'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5516,plsr_scale:2.9889'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0327,plsr_scale:2.0522'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.9532,plsr_scale:3.2936'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0564,plsr_scale:2.1211'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.5624,plsr_scale:2.8127'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0408,plsr_scale:2.1021'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.0813,plsr_scale:3.4297'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8274,plsr_scale:1.9098'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:10.4657,plsr_scale:6.9523'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.0575,plsr_scale:2.1354'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.4933,plsr_scale:2.8017'\n",
      "Train times: {'fold_0': 6, 'fold_1': 6, 'fold_2': 6, 'fold_3': 6, 'fold_4': 6, 'mean': 6.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.5515682209510717, 'plsr_scale': 2.9888733297780266}, 'fold_1': {'plsr': 2.95323258670112, 'plsr_scale': 3.2935675581989408}, 'fold_2': {'plsr': 2.562386158277054, 'plsr_scale': 2.8126795949604015}, 'fold_3': {'plsr': 3.08126405063928, 'plsr_scale': 3.429710182363282}, 'fold_4': {'plsr': 10.465675357582386, 'plsr_scale': 6.952349355618659}, 'MSE': {'plsr': 4.32251156630621, 'plsr_scale': 3.8952853418666034}, 'R2': {'plsr': 0.9928078177765155, 'plsr_scale': 0.9935186750662386}}'\n",
      "plsr: {'fold_0': 2.5515682209510717, 'fold_1': 2.95323258670112, 'fold_2': 2.562386158277054, 'fold_3': 3.08126405063928, 'fold_4': 10.465675357582386, 'MSE': 4.32251156630621, 'R2': 0.9928078177765155}'\n",
      "plsr_scale: {'fold_0': 2.9888733297780266, 'fold_1': 3.2935675581989408, 'fold_2': 2.8126795949604015, 'fold_3': 3.429710182363282, 'fold_4': 6.952349355618659, 'MSE': 3.8952853418666034, 'R2': 0.9935186750662386}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 36 components'\n",
      "Running PLSR with 36 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9379,plsr_scale:1.9916'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5456,plsr_scale:2.9868'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0178,plsr_scale:2.0332'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.9594,plsr_scale:3.2938'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.044,plsr_scale:2.1013'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.5483,plsr_scale:2.821'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0272,plsr_scale:2.0816'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.0892,plsr_scale:3.432'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8158,plsr_scale:1.891'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:10.2666,plsr_scale:6.9511'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.0453,plsr_scale:2.1143'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.4906,plsr_scale:2.8039'\n",
      "Train times: {'fold_0': 6, 'fold_1': 6, 'fold_2': 6, 'fold_3': 6, 'fold_4': 6, 'mean': 6.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.5456395183166105, 'plsr_scale': 2.986842398662051}, 'fold_1': {'plsr': 2.959367598565298, 'plsr_scale': 3.293828707211721}, 'fold_2': {'plsr': 2.548309657846483, 'plsr_scale': 2.820967704803646}, 'fold_3': {'plsr': 3.0891860954805326, 'plsr_scale': 3.4319739934470266}, 'fold_4': {'plsr': 10.266635498835054, 'plsr_scale': 6.95108209874948}, 'MSE': {'plsr': 4.281522175583592, 'plsr_scale': 3.89678784125644}, 'R2': {'plsr': 0.9928760195991791, 'plsr_scale': 0.9935161750730663}}'\n",
      "plsr: {'fold_0': 2.5456395183166105, 'fold_1': 2.959367598565298, 'fold_2': 2.548309657846483, 'fold_3': 3.0891860954805326, 'fold_4': 10.266635498835054, 'MSE': 4.281522175583592, 'R2': 0.9928760195991791}'\n",
      "plsr_scale: {'fold_0': 2.986842398662051, 'fold_1': 3.293828707211721, 'fold_2': 2.820967704803646, 'fold_3': 3.4319739934470266, 'fold_4': 6.95108209874948, 'MSE': 3.89678784125644, 'R2': 0.9935161750730663}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 37 components'\n",
      "Running PLSR with 37 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9237,plsr_scale:1.9737'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5663,plsr_scale:2.9903'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0045,plsr_scale:2.015'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.9673,plsr_scale:3.2823'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0317,plsr_scale:2.0822'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.54,plsr_scale:2.845'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0145,plsr_scale:2.0648'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.1108,plsr_scale:3.3993'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8039,plsr_scale:1.8756'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:10.069,plsr_scale:6.7844'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.0326,plsr_scale:2.097'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.4874,plsr_scale:2.778'\n",
      "Train times: {'fold_0': 7, 'fold_1': 6, 'fold_2': 6, 'fold_3': 6, 'fold_4': 7, 'mean': 6.4}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.5662846691031036, 'plsr_scale': 2.9902650272204534}, 'fold_1': {'plsr': 2.9672519329668186, 'plsr_scale': 3.2822548920565806}, 'fold_2': {'plsr': 2.540046799002737, 'plsr_scale': 2.8450084209778983}, 'fold_3': {'plsr': 3.1107617208446823, 'plsr_scale': 3.3993076689960264}, 'fold_4': {'plsr': 10.069034598367832, 'plsr_scale': 6.784357578956614}, 'MSE': {'plsr': 4.250379518239411, 'plsr_scale': 3.86009409543656}, 'R2': {'plsr': 0.9929278375441648, 'plsr_scale': 0.9935772294166697}}'\n",
      "plsr: {'fold_0': 2.5662846691031036, 'fold_1': 2.9672519329668186, 'fold_2': 2.540046799002737, 'fold_3': 3.1107617208446823, 'fold_4': 10.069034598367832, 'MSE': 4.250379518239411, 'R2': 0.9929278375441648}'\n",
      "plsr_scale: {'fold_0': 2.9902650272204534, 'fold_1': 3.2822548920565806, 'fold_2': 2.8450084209778983, 'fold_3': 3.3993076689960264, 'fold_4': 6.784357578956614, 'MSE': 3.86009409543656, 'R2': 0.9935772294166697}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 38 components'\n",
      "Running PLSR with 38 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9086,plsr_scale:1.9558'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5955,plsr_scale:2.9772'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9893,plsr_scale:1.9988'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.97,plsr_scale:3.2603'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0209,plsr_scale:2.0661'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.541,plsr_scale:2.8097'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0037,plsr_scale:2.0481'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.1119,plsr_scale:3.393'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7873,plsr_scale:1.8599'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:9.7905,plsr_scale:7.0901'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.0218,plsr_scale:2.08'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.4867,plsr_scale:2.7765'\n",
      "Train times: {'fold_0': 7, 'fold_1': 6, 'fold_2': 7, 'fold_3': 6, 'fold_4': 7, 'mean': 6.6}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.5955163376580797, 'plsr_scale': 2.9772477191130635}, 'fold_1': {'plsr': 2.969990220839751, 'plsr_scale': 3.2603364305964506}, 'fold_2': {'plsr': 2.541009746593468, 'plsr_scale': 2.8096693095306327}, 'fold_3': {'plsr': 3.1118829956766523, 'plsr_scale': 3.3929517486795273}, 'fold_4': {'plsr': 9.790468743188853, 'plsr_scale': 7.090127313912072}, 'MSE': {'plsr': 4.2014901448821425, 'plsr_scale': 3.905909238199847}, 'R2': {'plsr': 0.9930091840661078, 'plsr_scale': 0.9935009980751698}}'\n",
      "plsr: {'fold_0': 2.5955163376580797, 'fold_1': 2.969990220839751, 'fold_2': 2.541009746593468, 'fold_3': 3.1118829956766523, 'fold_4': 9.790468743188853, 'MSE': 4.2014901448821425, 'R2': 0.9930091840661078}'\n",
      "plsr_scale: {'fold_0': 2.9772477191130635, 'fold_1': 3.2603364305964506, 'fold_2': 2.8096693095306327, 'fold_3': 3.3929517486795273, 'fold_4': 7.090127313912072, 'MSE': 3.905909238199847, 'R2': 0.9935009980751698}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 39 components'\n",
      "Running PLSR with 39 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8972,plsr_scale:1.9443'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5865,plsr_scale:2.9708'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.973,plsr_scale:1.9826'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.9975,plsr_scale:3.2489'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:2.0087,plsr_scale:2.0515'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.5596,plsr_scale:2.8161'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9926,plsr_scale:2.0302'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.1415,plsr_scale:3.3541'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7783,plsr_scale:1.8462'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:9.3428,plsr_scale:6.9816'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.0106,plsr_scale:2.063'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5031,plsr_scale:2.7471'\n",
      "Train times: {'fold_0': 7, 'fold_1': 7, 'fold_2': 7, 'fold_3': 7, 'fold_4': 7, 'mean': 7.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.5864668669463105, 'plsr_scale': 2.9708093536067124}, 'fold_1': {'plsr': 2.997483767136765, 'plsr_scale': 3.2488838530172046}, 'fold_2': {'plsr': 2.5596124051464235, 'plsr_scale': 2.8160811072810072}, 'fold_3': {'plsr': 3.141459717391003, 'plsr_scale': 3.3541369596440744}, 'fold_4': {'plsr': 9.342785978410822, 'plsr_scale': 6.981615764349888}, 'MSE': {'plsr': 4.125295349397402, 'plsr_scale': 3.8741526990691364}, 'R2': {'plsr': 0.9931359637971048, 'plsr_scale': 0.9935538374517017}}'\n",
      "plsr: {'fold_0': 2.5864668669463105, 'fold_1': 2.997483767136765, 'fold_2': 2.5596124051464235, 'fold_3': 3.141459717391003, 'fold_4': 9.342785978410822, 'MSE': 4.125295349397402, 'R2': 0.9931359637971048}'\n",
      "plsr_scale: {'fold_0': 2.9708093536067124, 'fold_1': 3.2488838530172046, 'fold_2': 2.8160811072810072, 'fold_3': 3.3541369596440744, 'fold_4': 6.981615764349888, 'MSE': 3.8741526990691364, 'R2': 0.9935538374517017}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 40 components'\n",
      "Running PLSR with 40 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8876,plsr_scale:1.9324'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6005,plsr_scale:2.9726'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9606,plsr_scale:1.9659'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0218,plsr_scale:3.2401'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9971,plsr_scale:2.0361'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.5579,plsr_scale:2.8239'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9781,plsr_scale:2.0143'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.1457,plsr_scale:3.3437'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7705,plsr_scale:1.8316'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.9042,plsr_scale:7.0132'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:2.0026,plsr_scale:2.0476'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5001,plsr_scale:2.7426'\n",
      "Train times: {'fold_0': 7, 'fold_1': 6, 'fold_2': 7, 'fold_3': 7, 'fold_4': 7, 'mean': 6.8}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.6005165212262438, 'plsr_scale': 2.9725560865161786}, 'fold_1': {'plsr': 3.0217760960927196, 'plsr_scale': 3.2401484194080425}, 'fold_2': {'plsr': 2.557939833348793, 'plsr_scale': 2.82386082890367}, 'fold_3': {'plsr': 3.145703408800354, 'plsr_scale': 3.343669775556334}, 'fold_4': {'plsr': 8.904188122459793, 'plsr_scale': 7.013222756514045}, 'MSE': {'plsr': 4.045778116703653, 'plsr_scale': 3.8785372906548403}, 'R2': {'plsr': 0.9932682716969606, 'plsr_scale': 0.9935465419751769}}'\n",
      "plsr: {'fold_0': 2.6005165212262438, 'fold_1': 3.0217760960927196, 'fold_2': 2.557939833348793, 'fold_3': 3.145703408800354, 'fold_4': 8.904188122459793, 'MSE': 4.045778116703653, 'R2': 0.9932682716969606}'\n",
      "plsr_scale: {'fold_0': 2.9725560865161786, 'fold_1': 3.2401484194080425, 'fold_2': 2.82386082890367, 'fold_3': 3.343669775556334, 'fold_4': 7.013222756514045, 'MSE': 3.8785372906548403, 'R2': 0.9935465419751769}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 41 components'\n",
      "Running PLSR with 41 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8758,plsr_scale:1.9192'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6115,plsr_scale:2.9662'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9475,plsr_scale:1.9544'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0306,plsr_scale:3.2256'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9854,plsr_scale:2.0219'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.5671,plsr_scale:2.8241'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9713,plsr_scale:2.001'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.1466,plsr_scale:3.3493'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.759,plsr_scale:1.819'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.5234,plsr_scale:7.1641'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.9915,plsr_scale:2.0352'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5095,plsr_scale:2.7447'\n",
      "Train times: {'fold_0': 7, 'fold_1': 7, 'fold_2': 7, 'fold_3': 7, 'fold_4': 7, 'mean': 7.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.6115427381953107, 'plsr_scale': 2.9661935526917422}, 'fold_1': {'plsr': 3.0306244235581072, 'plsr_scale': 3.2256385130200522}, 'fold_2': {'plsr': 2.5671342431175015, 'plsr_scale': 2.824070499744064}, 'fold_3': {'plsr': 3.1466105763037726, 'plsr_scale': 3.349292348994343}, 'fold_4': {'plsr': 8.523404270666283, 'plsr_scale': 7.164146873595909}, 'MSE': {'plsr': 3.9756325712492395, 'plsr_scale': 3.9057065612998425}, 'R2': {'plsr': 0.993384986143489, 'plsr_scale': 0.9935013353071644}}'\n",
      "plsr: {'fold_0': 2.6115427381953107, 'fold_1': 3.0306244235581072, 'fold_2': 2.5671342431175015, 'fold_3': 3.1466105763037726, 'fold_4': 8.523404270666283, 'MSE': 3.9756325712492395, 'R2': 0.993384986143489}'\n",
      "plsr_scale: {'fold_0': 2.9661935526917422, 'fold_1': 3.2256385130200522, 'fold_2': 2.824070499744064, 'fold_3': 3.349292348994343, 'fold_4': 7.164146873595909, 'MSE': 3.9057065612998425, 'R2': 0.9935013353071644}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 42 components'\n",
      "Running PLSR with 42 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8675,plsr_scale:1.9068'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6374,plsr_scale:2.9418'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9379,plsr_scale:1.944'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0619,plsr_scale:3.2285'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9721,plsr_scale:2.0098'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.5666,plsr_scale:2.8166'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9605,plsr_scale:1.9889'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.1527,plsr_scale:3.3207'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.749,plsr_scale:1.8074'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.3438,plsr_scale:7.0645'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.9816,plsr_scale:2.0247'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5241,plsr_scale:2.7269'\n",
      "Train times: {'fold_0': 8, 'fold_1': 7, 'fold_2': 7, 'fold_3': 7, 'fold_4': 7, 'mean': 7.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.6374074539095003, 'plsr_scale': 2.9418274613928506}, 'fold_1': {'plsr': 3.061885997930256, 'plsr_scale': 3.2285161573105308}, 'fold_2': {'plsr': 2.5666025557779166, 'plsr_scale': 2.816565379583131}, 'fold_3': {'plsr': 3.1526800168752405, 'plsr_scale': 3.3207180885447753}, 'fold_4': {'plsr': 8.343837722553387, 'plsr_scale': 7.064502210140384}, 'MSE': {'plsr': 3.9522624465679717, 'plsr_scale': 3.8742681977782647}, 'R2': {'plsr': 0.9934238714518832, 'plsr_scale': 0.9935536452745959}}'\n",
      "plsr: {'fold_0': 2.6374074539095003, 'fold_1': 3.061885997930256, 'fold_2': 2.5666025557779166, 'fold_3': 3.1526800168752405, 'fold_4': 8.343837722553387, 'MSE': 3.9522624465679717, 'R2': 0.9934238714518832}'\n",
      "plsr_scale: {'fold_0': 2.9418274613928506, 'fold_1': 3.2285161573105308, 'fold_2': 2.816565379583131, 'fold_3': 3.3207180885447753, 'fold_4': 7.064502210140384, 'MSE': 3.8742681977782647, 'R2': 0.9935536452745959}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 43 components'\n",
      "Running PLSR with 43 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8571,plsr_scale:1.897'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6319,plsr_scale:2.9312'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9251,plsr_scale:1.9333'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0655,plsr_scale:3.2324'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9647,plsr_scale:1.9987'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.58,plsr_scale:2.8082'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.951,plsr_scale:1.9784'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.1712,plsr_scale:3.3014'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7368,plsr_scale:1.7961'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.2827,plsr_scale:7.1077'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.9726,plsr_scale:2.0136'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5399,plsr_scale:2.6981'\n",
      "Train times: {'fold_0': 7, 'fold_1': 7, 'fold_2': 7, 'fold_3': 7, 'fold_4': 7, 'mean': 7.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.631859075382609, 'plsr_scale': 2.931232872908523}, 'fold_1': {'plsr': 3.0655449659166467, 'plsr_scale': 3.2324140280608593}, 'fold_2': {'plsr': 2.58004444962225, 'plsr_scale': 2.8082390695214583}, 'fold_3': {'plsr': 3.1712230441687903, 'plsr_scale': 3.30138166004445}, 'fold_4': {'plsr': 8.282727106940872, 'plsr_scale': 7.107745169579097}, 'MSE': {'plsr': 3.9460604759676086, 'plsr_scale': 3.8760438746234493}, 'R2': {'plsr': 0.9934341908465264, 'plsr_scale': 0.9935506907442853}}'\n",
      "plsr: {'fold_0': 2.631859075382609, 'fold_1': 3.0655449659166467, 'fold_2': 2.58004444962225, 'fold_3': 3.1712230441687903, 'fold_4': 8.282727106940872, 'MSE': 3.9460604759676086, 'R2': 0.9934341908465264}'\n",
      "plsr_scale: {'fold_0': 2.931232872908523, 'fold_1': 3.2324140280608593, 'fold_2': 2.8082390695214583, 'fold_3': 3.30138166004445, 'fold_4': 7.107745169579097, 'MSE': 3.8760438746234493, 'R2': 0.9935506907442853}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 44 components'\n",
      "Running PLSR with 44 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8477,plsr_scale:1.8878'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6581,plsr_scale:2.9127'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9119,plsr_scale:1.9236'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0683,plsr_scale:3.2261'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9565,plsr_scale:1.9904'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.579,plsr_scale:2.8045'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9413,plsr_scale:1.9694'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.1936,plsr_scale:3.2849'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7294,plsr_scale:1.7857'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4982,plsr_scale:7.0827'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.9626,plsr_scale:2.0043'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5567,plsr_scale:2.7055'\n",
      "Train times: {'fold_0': 7, 'fold_1': 7, 'fold_2': 7, 'fold_3': 7, 'fold_4': 7, 'mean': 7.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 1, 'fold_3': 0, 'fold_4': 0, 'mean': 0.2}'\n",
      "Scores: {'fold_0': {'plsr': 2.658136237543454, 'plsr_scale': 2.9127252251042925}, 'fold_1': {'plsr': 3.0683310124121976, 'plsr_scale': 3.226080956503221}, 'fold_2': {'plsr': 2.5790429814385325, 'plsr_scale': 2.8044793863022446}, 'fold_3': {'plsr': 3.193632055601616, 'plsr_scale': 3.284890533891846}, 'fold_4': {'plsr': 8.498208180771549, 'plsr_scale': 7.08267091653972}, 'MSE': {'plsr': 3.999243118629663, 'plsr_scale': 3.8620110404415637}, 'R2': {'plsr': 0.9933457007982559, 'plsr_scale': 0.9935740398317312}}'\n",
      "plsr: {'fold_0': 2.658136237543454, 'fold_1': 3.0683310124121976, 'fold_2': 2.5790429814385325, 'fold_3': 3.193632055601616, 'fold_4': 8.498208180771549, 'MSE': 3.999243118629663, 'R2': 0.9933457007982559}'\n",
      "plsr_scale: {'fold_0': 2.9127252251042925, 'fold_1': 3.226080956503221, 'fold_2': 2.8044793863022446, 'fold_3': 3.284890533891846, 'fold_4': 7.08267091653972, 'MSE': 3.8620110404415637, 'R2': 0.9935740398317312}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 45 components'\n",
      "Running PLSR with 45 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8394,plsr_scale:1.8793'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6714,plsr_scale:2.9064'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9018,plsr_scale:1.9157'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0772,plsr_scale:3.2186'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.948,plsr_scale:1.9821'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.5969,plsr_scale:2.8024'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9321,plsr_scale:1.9609'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2162,plsr_scale:3.2722'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7226,plsr_scale:1.7763'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.5199,plsr_scale:7.0989'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.9563,plsr_scale:1.9958'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5759,plsr_scale:2.6897'\n",
      "Train times: {'fold_0': 7, 'fold_1': 7, 'fold_2': 7, 'fold_3': 8, 'fold_4': 8, 'mean': 7.4}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.671364735223648, 'plsr_scale': 2.90643466414855}, 'fold_1': {'plsr': 3.077222697831523, 'plsr_scale': 3.2185902558266717}, 'fold_2': {'plsr': 2.5969295342760375, 'plsr_scale': 2.8024017584721994}, 'fold_3': {'plsr': 3.216224993085759, 'plsr_scale': 3.272178214748197}, 'fold_4': {'plsr': 8.519862693703361, 'plsr_scale': 7.0989455067195335}, 'MSE': {'plsr': 4.016092799139228, 'plsr_scale': 3.8595508315571427}, 'R2': {'plsr': 0.9933176647893815, 'plsr_scale': 0.9935781333478116}}'\n",
      "plsr: {'fold_0': 2.671364735223648, 'fold_1': 3.077222697831523, 'fold_2': 2.5969295342760375, 'fold_3': 3.216224993085759, 'fold_4': 8.519862693703361, 'MSE': 4.016092799139228, 'R2': 0.9933176647893815}'\n",
      "plsr_scale: {'fold_0': 2.90643466414855, 'fold_1': 3.2185902558266717, 'fold_2': 2.8024017584721994, 'fold_3': 3.272178214748197, 'fold_4': 7.0989455067195335, 'MSE': 3.8595508315571427, 'R2': 0.9935781333478116}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 46 components'\n",
      "Running PLSR with 46 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8299,plsr_scale:1.8719'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6789,plsr_scale:2.8923'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8918,plsr_scale:1.9081'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0868,plsr_scale:3.2131'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9379,plsr_scale:1.9746'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6211,plsr_scale:2.7888'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9241,plsr_scale:1.9528'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2084,plsr_scale:3.2756'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7152,plsr_scale:1.7669'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.3524,plsr_scale:7.1909'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.9497,plsr_scale:1.9873'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5866,plsr_scale:2.696'\n",
      "Train times: {'fold_0': 8, 'fold_1': 8, 'fold_2': 9, 'fold_3': 8, 'fold_4': 9, 'mean': 8.4}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.6788840172475608, 'plsr_scale': 2.892347489399446}, 'fold_1': {'plsr': 3.0867836380491713, 'plsr_scale': 3.2130554286265394}, 'fold_2': {'plsr': 2.6210695415951966, 'plsr_scale': 2.788839290885738}, 'fold_3': {'plsr': 3.208356472877454, 'plsr_scale': 3.2756242929443924}, 'fold_4': {'plsr': 8.352354989243148, 'plsr_scale': 7.190942336413059}, 'MSE': {'plsr': 3.989268665900757, 'plsr_scale': 3.871998072026859}, 'R2': {'plsr': 0.9933622971868382, 'plsr_scale': 0.9935574225133201}}'\n",
      "plsr: {'fold_0': 2.6788840172475608, 'fold_1': 3.0867836380491713, 'fold_2': 2.6210695415951966, 'fold_3': 3.208356472877454, 'fold_4': 8.352354989243148, 'MSE': 3.989268665900757, 'R2': 0.9933622971868382}'\n",
      "plsr_scale: {'fold_0': 2.892347489399446, 'fold_1': 3.2130554286265394, 'fold_2': 2.788839290885738, 'fold_3': 3.2756242929443924, 'fold_4': 7.190942336413059, 'MSE': 3.871998072026859, 'R2': 0.9935574225133201}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 47 components'\n",
      "Running PLSR with 47 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8208,plsr_scale:1.8639'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7003,plsr_scale:2.8887'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8822,plsr_scale:1.901'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.097,plsr_scale:3.2037'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9284,plsr_scale:1.9666'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6134,plsr_scale:2.7843'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9161,plsr_scale:1.9438'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2094,plsr_scale:3.2727'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7101,plsr_scale:1.7585'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.3848,plsr_scale:7.2616'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.9414,plsr_scale:1.9788'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5927,plsr_scale:2.6734'\n",
      "Train times: {'fold_0': 7, 'fold_1': 7, 'fold_2': 7, 'fold_3': 7, 'fold_4': 7, 'mean': 7.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.700282247032364, 'plsr_scale': 2.8886895698576005}, 'fold_1': {'plsr': 3.097030280272357, 'plsr_scale': 3.203694685903653}, 'fold_2': {'plsr': 2.613406051463184, 'plsr_scale': 2.784311683292986}, 'fold_3': {'plsr': 3.209436705432327, 'plsr_scale': 3.2726693672939686}, 'fold_4': {'plsr': 8.3847675148687, 'plsr_scale': 7.261640581550048}, 'MSE': {'plsr': 4.000764358396256, 'plsr_scale': 3.882034176171402}, 'R2': {'plsr': 0.9933431696231649, 'plsr_scale': 0.9935407235435859}}'\n",
      "plsr: {'fold_0': 2.700282247032364, 'fold_1': 3.097030280272357, 'fold_2': 2.613406051463184, 'fold_3': 3.209436705432327, 'fold_4': 8.3847675148687, 'MSE': 4.000764358396256, 'R2': 0.9933431696231649}'\n",
      "plsr_scale: {'fold_0': 2.8886895698576005, 'fold_1': 3.203694685903653, 'fold_2': 2.784311683292986, 'fold_3': 3.2726693672939686, 'fold_4': 7.261640581550048, 'MSE': 3.882034176171402, 'R2': 0.9935407235435859}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 48 components'\n",
      "Running PLSR with 48 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8104,plsr_scale:1.8569'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7134,plsr_scale:2.8717'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8732,plsr_scale:1.8942'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0915,plsr_scale:3.1933'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9222,plsr_scale:1.9596'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6242,plsr_scale:2.787'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9076,plsr_scale:1.9367'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2339,plsr_scale:3.2678'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7022,plsr_scale:1.7512'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.5115,plsr_scale:7.3052'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.9352,plsr_scale:1.9722'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6011,plsr_scale:2.6765'\n",
      "Train times: {'fold_0': 8, 'fold_1': 8, 'fold_2': 8, 'fold_3': 8, 'fold_4': 8, 'mean': 8.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.713399865648327, 'plsr_scale': 2.871672382480752}, 'fold_1': {'plsr': 3.091474244172989, 'plsr_scale': 3.193272082770921}, 'fold_2': {'plsr': 2.6241687569255117, 'plsr_scale': 2.7869528829984573}, 'fold_3': {'plsr': 3.2339380390491352, 'plsr_scale': 3.2677647440708872}, 'fold_4': {'plsr': 8.511469391234963, 'plsr_scale': 7.305203258211207}, 'MSE': {'plsr': 4.0346638402682515, 'plsr_scale': 3.8848027742939237}, 'R2': {'plsr': 0.9932867646264021, 'plsr_scale': 0.9935361169018464}}'\n",
      "plsr: {'fold_0': 2.713399865648327, 'fold_1': 3.091474244172989, 'fold_2': 2.6241687569255117, 'fold_3': 3.2339380390491352, 'fold_4': 8.511469391234963, 'MSE': 4.0346638402682515, 'R2': 0.9932867646264021}'\n",
      "plsr_scale: {'fold_0': 2.871672382480752, 'fold_1': 3.193272082770921, 'fold_2': 2.7869528829984573, 'fold_3': 3.2677647440708872, 'fold_4': 7.305203258211207, 'MSE': 3.8848027742939237, 'R2': 0.9935361169018464}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 49 components'\n",
      "Running PLSR with 49 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8024,plsr_scale:1.8506'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7267,plsr_scale:2.856'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8613,plsr_scale:1.8881'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0963,plsr_scale:3.1898'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9127,plsr_scale:1.953'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6479,plsr_scale:2.7947'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8995,plsr_scale:1.9299'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2361,plsr_scale:3.2566'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6959,plsr_scale:1.7441'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.3234,plsr_scale:7.2828'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.9286,plsr_scale:1.9655'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5879,plsr_scale:2.674'\n",
      "Train times: {'fold_0': 8, 'fold_1': 8, 'fold_2': 8, 'fold_3': 8, 'fold_4': 8, 'mean': 8.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.7267357312518046, 'plsr_scale': 2.855995282978433}, 'fold_1': {'plsr': 3.0962879566460773, 'plsr_scale': 3.189805698540803}, 'fold_2': {'plsr': 2.64787078933328, 'plsr_scale': 2.794732720295832}, 'fold_3': {'plsr': 3.2361057837028038, 'plsr_scale': 3.2566020745995896}, 'fold_4': {'plsr': 8.323437905874854, 'plsr_scale': 7.282811202013921}, 'MSE': {'plsr': 4.005868980587211, 'plsr_scale': 3.8758189824006726}, 'R2': {'plsr': 0.9933346760951741, 'plsr_scale': 0.9935510649401254}}'\n",
      "plsr: {'fold_0': 2.7267357312518046, 'fold_1': 3.0962879566460773, 'fold_2': 2.64787078933328, 'fold_3': 3.2361057837028038, 'fold_4': 8.323437905874854, 'MSE': 4.005868980587211, 'R2': 0.9933346760951741}'\n",
      "plsr_scale: {'fold_0': 2.855995282978433, 'fold_1': 3.189805698540803, 'fold_2': 2.794732720295832, 'fold_3': 3.2566020745995896, 'fold_4': 7.282811202013921, 'MSE': 3.8758189824006726, 'R2': 0.9935510649401254}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 50 components'\n",
      "Running PLSR with 50 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7972,plsr_scale:1.8445'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7344,plsr_scale:2.8518'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8537,plsr_scale:1.8819'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0891,plsr_scale:3.1771'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.9054,plsr_scale:1.9455'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6414,plsr_scale:2.7756'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8923,plsr_scale:1.9233'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2361,plsr_scale:3.2577'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6903,plsr_scale:1.7376'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.3524,plsr_scale:7.3145'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.922,plsr_scale:1.9596'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5949,plsr_scale:2.6683'\n",
      "Train times: {'fold_0': 8, 'fold_1': 8, 'fold_2': 8, 'fold_3': 8, 'fold_4': 8, 'mean': 8.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.734406447626324, 'plsr_scale': 2.851803802135314}, 'fold_1': {'plsr': 3.08910329301568, 'plsr_scale': 3.17711846825215}, 'fold_2': {'plsr': 2.641381249001373, 'plsr_scale': 2.7755727052850103}, 'fold_3': {'plsr': 3.236114539522222, 'plsr_scale': 3.257748527766525}, 'fold_4': {'plsr': 8.352389878955172, 'plsr_scale': 7.314532471421716}, 'MSE': {'plsr': 4.010459560207593, 'plsr_scale': 3.875183222527122}, 'R2': {'plsr': 0.993327037877292, 'plsr_scale': 0.9935521227743939}}'\n",
      "plsr: {'fold_0': 2.734406447626324, 'fold_1': 3.08910329301568, 'fold_2': 2.641381249001373, 'fold_3': 3.236114539522222, 'fold_4': 8.352389878955172, 'MSE': 4.010459560207593, 'R2': 0.993327037877292}'\n",
      "plsr_scale: {'fold_0': 2.851803802135314, 'fold_1': 3.17711846825215, 'fold_2': 2.7755727052850103, 'fold_3': 3.257748527766525, 'fold_4': 7.314532471421716, 'MSE': 3.875183222527122, 'R2': 0.9935521227743939}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 51 components'\n",
      "Running PLSR with 51 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7894,plsr_scale:1.838'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7448,plsr_scale:2.8584'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8456,plsr_scale:1.8756'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0995,plsr_scale:3.1733'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8997,plsr_scale:1.939'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.654,plsr_scale:2.7597'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8869,plsr_scale:1.9171'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2409,plsr_scale:3.2652'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6852,plsr_scale:1.7315'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.3845,plsr_scale:7.3012'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.9156,plsr_scale:1.9539'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5963,plsr_scale:2.6574'\n",
      "Train times: {'fold_0': 9, 'fold_1': 9, 'fold_2': 9, 'fold_3': 9, 'fold_4': 9, 'mean': 9.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.7447966123473377, 'plsr_scale': 2.858401877507126}, 'fold_1': {'plsr': 3.099465758251374, 'plsr_scale': 3.173312141080237}, 'fold_2': {'plsr': 2.6540102532724466, 'plsr_scale': 2.759662536584723}, 'fold_3': {'plsr': 3.2408792670364814, 'plsr_scale': 3.2651717216475538}, 'fold_4': {'plsr': 8.384505628535383, 'plsr_scale': 7.301229159659004}, 'MSE': {'plsr': 4.024511248131795, 'plsr_scale': 3.8713845527216177}, 'R2': {'plsr': 0.9933036574192995, 'plsr_scale': 0.9935584433417374}}'\n",
      "plsr: {'fold_0': 2.7447966123473377, 'fold_1': 3.099465758251374, 'fold_2': 2.6540102532724466, 'fold_3': 3.2408792670364814, 'fold_4': 8.384505628535383, 'MSE': 4.024511248131795, 'R2': 0.9933036574192995}'\n",
      "plsr_scale: {'fold_0': 2.858401877507126, 'fold_1': 3.173312141080237, 'fold_2': 2.759662536584723, 'fold_3': 3.2651717216475538, 'fold_4': 7.301229159659004, 'MSE': 3.8713845527216177, 'R2': 0.9935584433417374}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 52 components'\n",
      "Running PLSR with 52 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7828,plsr_scale:1.832'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7385,plsr_scale:2.852'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8384,plsr_scale:1.8698'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.109,plsr_scale:3.1596'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8923,plsr_scale:1.933'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6555,plsr_scale:2.7505'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8819,plsr_scale:1.9115'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2396,plsr_scale:3.258'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6792,plsr_scale:1.7256'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.3108,plsr_scale:7.247'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.9106,plsr_scale:1.9489'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6029,plsr_scale:2.6507'\n",
      "Train times: {'fold_0': 8, 'fold_1': 8, 'fold_2': 8, 'fold_3': 8, 'fold_4': 8, 'mean': 8.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.738462714136287, 'plsr_scale': 2.851987012066858}, 'fold_1': {'plsr': 3.1090280240721113, 'plsr_scale': 3.159620771991296}, 'fold_2': {'plsr': 2.655520274319874, 'plsr_scale': 2.7504959416261547}, 'fold_3': {'plsr': 3.2395795238374974, 'plsr_scale': 3.25802489973894}, 'fold_4': {'plsr': 8.310846000734943, 'plsr_scale': 7.247033740318592}, 'MSE': {'plsr': 4.01047017958588, 'plsr_scale': 3.8532631506191795}, 'R2': {'plsr': 0.9933270202078185, 'plsr_scale': 0.9935885953549979}}'\n",
      "plsr: {'fold_0': 2.738462714136287, 'fold_1': 3.1090280240721113, 'fold_2': 2.655520274319874, 'fold_3': 3.2395795238374974, 'fold_4': 8.310846000734943, 'MSE': 4.01047017958588, 'R2': 0.9933270202078185}'\n",
      "plsr_scale: {'fold_0': 2.851987012066858, 'fold_1': 3.159620771991296, 'fold_2': 2.7504959416261547, 'fold_3': 3.25802489973894, 'fold_4': 7.247033740318592, 'MSE': 3.8532631506191795, 'R2': 0.9935885953549979}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 53 components'\n",
      "Running PLSR with 53 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7772,plsr_scale:1.8261'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7594,plsr_scale:2.8513'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8302,plsr_scale:1.8639'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.101,plsr_scale:3.1628'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8863,plsr_scale:1.9269'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.654,plsr_scale:2.7397'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8743,plsr_scale:1.906'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2206,plsr_scale:3.2629'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6732,plsr_scale:1.7208'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.3518,plsr_scale:7.3405'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.9063,plsr_scale:1.9439'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5959,plsr_scale:2.6496'\n",
      "Train times: {'fold_0': 8, 'fold_1': 8, 'fold_2': 8, 'fold_3': 8, 'fold_4': 8, 'mean': 8.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.7594230384201532, 'plsr_scale': 2.8513142412301162}, 'fold_1': {'plsr': 3.1009999594893625, 'plsr_scale': 3.162788115820406}, 'fold_2': {'plsr': 2.6539567386745513, 'plsr_scale': 2.739695777940976}, 'fold_3': {'plsr': 3.22059145761308, 'plsr_scale': 3.262908034134454}, 'fold_4': {'plsr': 8.351797982624598, 'plsr_scale': 7.340531859818172}, 'MSE': {'plsr': 4.017136667498506, 'plsr_scale': 3.8712749337098664}, 'R2': {'plsr': 0.9933159279076308, 'plsr_scale': 0.9935586257356757}}'\n",
      "plsr: {'fold_0': 2.7594230384201532, 'fold_1': 3.1009999594893625, 'fold_2': 2.6539567386745513, 'fold_3': 3.22059145761308, 'fold_4': 8.351797982624598, 'MSE': 4.017136667498506, 'R2': 0.9933159279076308}'\n",
      "plsr_scale: {'fold_0': 2.8513142412301162, 'fold_1': 3.162788115820406, 'fold_2': 2.739695777940976, 'fold_3': 3.262908034134454, 'fold_4': 7.340531859818172, 'MSE': 3.8712749337098664, 'R2': 0.9935586257356757}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 54 components'\n",
      "Running PLSR with 54 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7717,plsr_scale:1.8205'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7612,plsr_scale:2.8502'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8221,plsr_scale:1.8581'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1036,plsr_scale:3.1555'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8803,plsr_scale:1.9211'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.659,plsr_scale:2.7302'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8707,plsr_scale:1.9011'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.22,plsr_scale:3.2593'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6681,plsr_scale:1.7157'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.689,plsr_scale:7.442'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.9002,plsr_scale:1.9394'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5949,plsr_scale:2.6488'\n",
      "Train times: {'fold_0': 9, 'fold_1': 9, 'fold_2': 9, 'fold_3': 9, 'fold_4': 9, 'mean': 9.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.761232812887876, 'plsr_scale': 2.850178424035136}, 'fold_1': {'plsr': 3.103566490125502, 'plsr_scale': 3.155471041927269}, 'fold_2': {'plsr': 2.658997144112395, 'plsr_scale': 2.730202823162093}, 'fold_3': {'plsr': 3.2200004293195064, 'plsr_scale': 3.2593313841696645}, 'fold_4': {'plsr': 8.688974563701123, 'plsr_scale': 7.441972009626719}, 'MSE': {'plsr': 4.08632373376709, 'plsr_scale': 3.887254427354531}, 'R2': {'plsr': 0.993200808264692, 'plsr_scale': 0.9935320376217126}}'\n",
      "plsr: {'fold_0': 2.761232812887876, 'fold_1': 3.103566490125502, 'fold_2': 2.658997144112395, 'fold_3': 3.2200004293195064, 'fold_4': 8.688974563701123, 'MSE': 4.08632373376709, 'R2': 0.993200808264692}'\n",
      "plsr_scale: {'fold_0': 2.850178424035136, 'fold_1': 3.155471041927269, 'fold_2': 2.730202823162093, 'fold_3': 3.2593313841696645, 'fold_4': 7.441972009626719, 'MSE': 3.887254427354531, 'R2': 0.9935320376217126}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 55 components'\n",
      "Running PLSR with 55 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7662,plsr_scale:1.8153'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7599,plsr_scale:2.8525'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8152,plsr_scale:1.8527'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1086,plsr_scale:3.1496'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8752,plsr_scale:1.9158'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6594,plsr_scale:2.7254'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8656,plsr_scale:1.8967'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2185,plsr_scale:3.2664'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6638,plsr_scale:1.711'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:7.9984,plsr_scale:7.6429'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8952,plsr_scale:1.9354'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.5876,plsr_scale:2.6507'\n",
      "Train times: {'fold_0': 9, 'fold_1': 9, 'fold_2': 9, 'fold_3': 9, 'fold_4': 8, 'mean': 8.8}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.75991705626298, 'plsr_scale': 2.8525119975095334}, 'fold_1': {'plsr': 3.1085980684391608, 'plsr_scale': 3.149614771589277}, 'fold_2': {'plsr': 2.659366738275536, 'plsr_scale': 2.7253999480179174}, 'fold_3': {'plsr': 3.218520311941759, 'plsr_scale': 3.2664316213444358}, 'fold_4': {'plsr': 7.998417249239891, 'plsr_scale': 7.6429490803926905}, 'MSE': {'plsr': 3.9487611868050014, 'plsr_scale': 3.9271964422008105}, 'R2': {'plsr': 0.9934296971617375, 'plsr_scale': 0.9934655785169211}}'\n",
      "plsr: {'fold_0': 2.75991705626298, 'fold_1': 3.1085980684391608, 'fold_2': 2.659366738275536, 'fold_3': 3.218520311941759, 'fold_4': 7.998417249239891, 'MSE': 3.9487611868050014, 'R2': 0.9934296971617375}'\n",
      "plsr_scale: {'fold_0': 2.8525119975095334, 'fold_1': 3.149614771589277, 'fold_2': 2.7253999480179174, 'fold_3': 3.2664316213444358, 'fold_4': 7.6429490803926905, 'MSE': 3.9271964422008105, 'R2': 0.9934655785169211}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 56 components'\n",
      "Running PLSR with 56 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7608,plsr_scale:1.8106'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7689,plsr_scale:2.8514'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8086,plsr_scale:1.8478'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.0956,plsr_scale:3.149'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8699,plsr_scale:1.9113'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6621,plsr_scale:2.727'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8609,plsr_scale:1.8928'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2215,plsr_scale:3.2704'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6597,plsr_scale:1.7069'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4147,plsr_scale:7.8754'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8912,plsr_scale:1.9318'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6015,plsr_scale:2.6384'\n",
      "Train times: {'fold_0': 9, 'fold_1': 9, 'fold_2': 9, 'fold_3': 9, 'fold_4': 9, 'mean': 9.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.768938271116904, 'plsr_scale': 2.8514244570662544}, 'fold_1': {'plsr': 3.095625855366141, 'plsr_scale': 3.1490112001454}, 'fold_2': {'plsr': 2.6620828809228825, 'plsr_scale': 2.7269786695278224}, 'fold_3': {'plsr': 3.2215158819041827, 'plsr_scale': 3.2703943790896903}, 'fold_4': {'plsr': 8.41471000396972, 'plsr_scale': 7.875434003051972}, 'MSE': {'plsr': 4.032354783906583, 'plsr_scale': 3.974453889216665}, 'R2': {'plsr': 0.9932906066413655, 'plsr_scale': 0.9933869473403144}}'\n",
      "plsr: {'fold_0': 2.768938271116904, 'fold_1': 3.095625855366141, 'fold_2': 2.6620828809228825, 'fold_3': 3.2215158819041827, 'fold_4': 8.41471000396972, 'MSE': 4.032354783906583, 'R2': 0.9932906066413655}'\n",
      "plsr_scale: {'fold_0': 2.8514244570662544, 'fold_1': 3.1490112001454, 'fold_2': 2.7269786695278224, 'fold_3': 3.2703943790896903, 'fold_4': 7.875434003051972, 'MSE': 3.974453889216665, 'R2': 0.9933869473403144}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 57 components'\n",
      "Running PLSR with 57 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7556,plsr_scale:1.8059'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7733,plsr_scale:2.8607'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8017,plsr_scale:1.8431'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1032,plsr_scale:3.1521'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8657,plsr_scale:1.9068'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6569,plsr_scale:2.7336'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8558,plsr_scale:1.8891'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2251,plsr_scale:3.2681'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6558,plsr_scale:1.703'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.3304,plsr_scale:8.114'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8868,plsr_scale:1.9283'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6034,plsr_scale:2.6425'\n",
      "Train times: {'fold_0': 9, 'fold_1': 9, 'fold_2': 9, 'fold_3': 9, 'fold_4': 9, 'mean': 9.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.7732843794426842, 'plsr_scale': 2.860670395694447}, 'fold_1': {'plsr': 3.103150434525503, 'plsr_scale': 3.1521089199841454}, 'fold_2': {'plsr': 2.656888499579214, 'plsr_scale': 2.733554912177295}, 'fold_3': {'plsr': 3.225061400196116, 'plsr_scale': 3.268139100963901}, 'fold_4': {'plsr': 8.330449386830058, 'plsr_scale': 8.114025316340294}, 'MSE': {'plsr': 4.0175511690134105, 'plsr_scale': 4.0254961113589856}, 'R2': {'plsr': 0.9933152382228534, 'plsr_scale': 0.9933020187155768}}'\n",
      "plsr: {'fold_0': 2.7732843794426842, 'fold_1': 3.103150434525503, 'fold_2': 2.656888499579214, 'fold_3': 3.225061400196116, 'fold_4': 8.330449386830058, 'MSE': 4.0175511690134105, 'R2': 0.9933152382228534}'\n",
      "plsr_scale: {'fold_0': 2.860670395694447, 'fold_1': 3.1521089199841454, 'fold_2': 2.733554912177295, 'fold_3': 3.268139100963901, 'fold_4': 8.114025316340294, 'MSE': 4.0254961113589856, 'R2': 0.9933020187155768}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 58 components'\n",
      "Running PLSR with 58 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7522,plsr_scale:1.8019'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7797,plsr_scale:2.8502'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7969,plsr_scale:1.8388'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1063,plsr_scale:3.1453'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8608,plsr_scale:1.9025'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6519,plsr_scale:2.7322'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8509,plsr_scale:1.8855'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2236,plsr_scale:3.2627'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6515,plsr_scale:1.6991'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4646,plsr_scale:8.2725'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.882,plsr_scale:1.9248'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6064,plsr_scale:2.6501'\n",
      "Train times: {'fold_0': 9, 'fold_1': 9, 'fold_2': 9, 'fold_3': 9, 'fold_4': 9, 'mean': 9.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 1, 'mean': 0.2}'\n",
      "Scores: {'fold_0': {'plsr': 2.7797391871444628, 'plsr_scale': 2.8501786679478114}, 'fold_1': {'plsr': 3.106275116157166, 'plsr_scale': 3.1453420409527832}, 'fold_2': {'plsr': 2.6518582010453335, 'plsr_scale': 2.7322495940119054}, 'fold_3': {'plsr': 3.2235759197099036, 'plsr_scale': 3.2627381014996595}, 'fold_4': {'plsr': 8.46463643185502, 'plsr_scale': 8.272461376341797}, 'MSE': {'plsr': 4.044996793431772, 'plsr_scale': 4.052383242287087}, 'R2': {'plsr': 0.99326957173266, 'plsr_scale': 0.9932572814969168}}'\n",
      "plsr: {'fold_0': 2.7797391871444628, 'fold_1': 3.106275116157166, 'fold_2': 2.6518582010453335, 'fold_3': 3.2235759197099036, 'fold_4': 8.46463643185502, 'MSE': 4.044996793431772, 'R2': 0.99326957173266}'\n",
      "plsr_scale: {'fold_0': 2.8501786679478114, 'fold_1': 3.1453420409527832, 'fold_2': 2.7322495940119054, 'fold_3': 3.2627381014996595, 'fold_4': 8.272461376341797, 'MSE': 4.052383242287087, 'R2': 0.9932572814969168}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 59 components'\n",
      "Running PLSR with 59 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7483,plsr_scale:1.7981'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.791,plsr_scale:2.8465'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7923,plsr_scale:1.8352'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1096,plsr_scale:3.1434'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.857,plsr_scale:1.8986'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6476,plsr_scale:2.7331'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.847,plsr_scale:1.8824'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2228,plsr_scale:3.2599'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6479,plsr_scale:1.6959'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.441,plsr_scale:8.3522'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.879,plsr_scale:1.9217'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6147,plsr_scale:2.6535'\n",
      "Train times: {'fold_0': 9, 'fold_1': 9, 'fold_2': 9, 'fold_3': 9, 'fold_4': 9, 'mean': 9.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.7910447016149953, 'plsr_scale': 2.8465164835003396}, 'fold_1': {'plsr': 3.1096170412493427, 'plsr_scale': 3.1433765713871744}, 'fold_2': {'plsr': 2.6475655139585483, 'plsr_scale': 2.733124827754558}, 'fold_3': {'plsr': 3.2227933512748135, 'plsr_scale': 3.259874509780305}, 'fold_4': {'plsr': 8.440971671971104, 'plsr_scale': 8.352212274864781}, 'MSE': {'plsr': 4.042180304278926, 'plsr_scale': 4.066806775565699}, 'R2': {'plsr': 0.9932742580597888, 'plsr_scale': 0.9932332823292906}}'\n",
      "plsr: {'fold_0': 2.7910447016149953, 'fold_1': 3.1096170412493427, 'fold_2': 2.6475655139585483, 'fold_3': 3.2227933512748135, 'fold_4': 8.440971671971104, 'MSE': 4.042180304278926, 'R2': 0.9932742580597888}'\n",
      "plsr_scale: {'fold_0': 2.8465164835003396, 'fold_1': 3.1433765713871744, 'fold_2': 2.733124827754558, 'fold_3': 3.259874509780305, 'fold_4': 8.352212274864781, 'MSE': 4.066806775565699, 'R2': 0.9932332823292906}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 60 components'\n",
      "Running PLSR with 60 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7449,plsr_scale:1.7946'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7907,plsr_scale:2.8561'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7881,plsr_scale:1.8315'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1105,plsr_scale:3.1429'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8534,plsr_scale:1.8954'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6512,plsr_scale:2.7291'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.843,plsr_scale:1.8795'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2303,plsr_scale:3.2635'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6449,plsr_scale:1.6926'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.692,plsr_scale:8.3668'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8759,plsr_scale:1.9187'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6146,plsr_scale:2.6529'\n",
      "Train times: {'fold_0': 10, 'fold_1': 9, 'fold_2': 9, 'fold_3': 9, 'fold_4': 9, 'mean': 9.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.790690034631912, 'plsr_scale': 2.8560678204498435}, 'fold_1': {'plsr': 3.110518538354102, 'plsr_scale': 3.1429160913129714}, 'fold_2': {'plsr': 2.6511903040606697, 'plsr_scale': 2.7291403770800127}, 'fold_3': {'plsr': 3.230265158755693, 'plsr_scale': 3.263463736872969}, 'fold_4': {'plsr': 8.69203454408259, 'plsr_scale': 8.366797436355979}, 'MSE': {'plsr': 4.094711123202426, 'plsr_scale': 4.071462912403062}, 'R2': {'plsr': 0.9931868525742854, 'plsr_scale': 0.9932255350314342}}'\n",
      "plsr: {'fold_0': 2.790690034631912, 'fold_1': 3.110518538354102, 'fold_2': 2.6511903040606697, 'fold_3': 3.230265158755693, 'fold_4': 8.69203454408259, 'MSE': 4.094711123202426, 'R2': 0.9931868525742854}'\n",
      "plsr_scale: {'fold_0': 2.8560678204498435, 'fold_1': 3.1429160913129714, 'fold_2': 2.7291403770800127, 'fold_3': 3.263463736872969, 'fold_4': 8.366797436355979, 'MSE': 4.071462912403062, 'R2': 0.9932255350314342}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 61 components'\n",
      "Running PLSR with 61 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7423,plsr_scale:1.7914'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.7865,plsr_scale:2.8587'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7839,plsr_scale:1.8279'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1203,plsr_scale:3.1433'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8501,plsr_scale:1.8924'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.657,plsr_scale:2.7228'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8395,plsr_scale:1.8766'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2249,plsr_scale:3.2693'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6424,plsr_scale:1.6895'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.57,plsr_scale:8.3221'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8729,plsr_scale:1.9161'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6209,plsr_scale:2.6591'\n",
      "Train times: {'fold_0': 9, 'fold_1': 9, 'fold_2': 9, 'fold_3': 9, 'fold_4': 9, 'mean': 9.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.7865378502246556, 'plsr_scale': 2.858729284543338}, 'fold_1': {'plsr': 3.120287133876798, 'plsr_scale': 3.1433275547809156}, 'fold_2': {'plsr': 2.6570292305847922, 'plsr_scale': 2.7227799678808196}, 'fold_3': {'plsr': 3.2249101603420876, 'plsr_scale': 3.2692968639483837}, 'fold_4': {'plsr': 8.570025951889765, 'plsr_scale': 8.322118755440279}, 'MSE': {'plsr': 4.071534664350193, 'plsr_scale': 4.063038295533358}, 'R2': {'plsr': 0.9932254156441126, 'plsr_scale': 0.9932395526641833}}'\n",
      "plsr: {'fold_0': 2.7865378502246556, 'fold_1': 3.120287133876798, 'fold_2': 2.6570292305847922, 'fold_3': 3.2249101603420876, 'fold_4': 8.570025951889765, 'MSE': 4.071534664350193, 'R2': 0.9932254156441126}'\n",
      "plsr_scale: {'fold_0': 2.858729284543338, 'fold_1': 3.1433275547809156, 'fold_2': 2.7227799678808196, 'fold_3': 3.2692968639483837, 'fold_4': 8.322118755440279, 'MSE': 4.063038295533358, 'R2': 0.9932395526641833}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 62 components'\n",
      "Running PLSR with 62 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7395,plsr_scale:1.7885'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8037,plsr_scale:2.8546'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7809,plsr_scale:1.8248'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1134,plsr_scale:3.1469'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8467,plsr_scale:1.8896'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6595,plsr_scale:2.7173'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8364,plsr_scale:1.8742'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2312,plsr_scale:3.2675'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6398,plsr_scale:1.6866'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.6342,plsr_scale:8.2673'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8701,plsr_scale:1.9136'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6177,plsr_scale:2.6656'\n",
      "Train times: {'fold_0': 10, 'fold_1': 9, 'fold_2': 9, 'fold_3': 10, 'fold_4': 10, 'mean': 9.6}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.803734164581553, 'plsr_scale': 2.8546352327226963}, 'fold_1': {'plsr': 3.1133546895219055, 'plsr_scale': 3.1468864261518736}, 'fold_2': {'plsr': 2.659465227848912, 'plsr_scale': 2.717271738778016}, 'fold_3': {'plsr': 3.2311817186262735, 'plsr_scale': 3.267503072940639}, 'fold_4': {'plsr': 8.63422371634556, 'plsr_scale': 8.267292828488534}, 'MSE': {'plsr': 4.088166204727963, 'plsr_scale': 4.050508120097938}, 'R2': {'plsr': 0.9931977425963441, 'plsr_scale': 0.9932604014933053}}'\n",
      "plsr: {'fold_0': 2.803734164581553, 'fold_1': 3.1133546895219055, 'fold_2': 2.659465227848912, 'fold_3': 3.2311817186262735, 'fold_4': 8.63422371634556, 'MSE': 4.088166204727963, 'R2': 0.9931977425963441}'\n",
      "plsr_scale: {'fold_0': 2.8546352327226963, 'fold_1': 3.1468864261518736, 'fold_2': 2.717271738778016, 'fold_3': 3.267503072940639, 'fold_4': 8.267292828488534, 'MSE': 4.050508120097938, 'R2': 0.9932604014933053}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 63 components'\n",
      "Running PLSR with 63 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7366,plsr_scale:1.7858'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8055,plsr_scale:2.8538'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7771,plsr_scale:1.8221'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1068,plsr_scale:3.1483'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8435,plsr_scale:1.8869'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6636,plsr_scale:2.7238'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8338,plsr_scale:1.8718'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2361,plsr_scale:3.2716'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6372,plsr_scale:1.6838'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.6672,plsr_scale:8.256'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8683,plsr_scale:1.9111'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6235,plsr_scale:2.66'\n",
      "Train times: {'fold_0': 10, 'fold_1': 10, 'fold_2': 10, 'fold_3': 10, 'fold_4': 10, 'mean': 10.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.805494937448327, 'plsr_scale': 2.853755982343711}, 'fold_1': {'plsr': 3.1068044683450666, 'plsr_scale': 3.148289975293722}, 'fold_2': {'plsr': 2.66357770388816, 'plsr_scale': 2.723808807358572}, 'fold_3': {'plsr': 3.2361240574078223, 'plsr_scale': 3.271647644328985}, 'fold_4': {'plsr': 8.667239967254355, 'plsr_scale': 8.256022634151726}, 'MSE': {'plsr': 4.095620560363757, 'plsr_scale': 4.050495323911109}, 'R2': {'plsr': 0.9931853393712125, 'plsr_scale': 0.993260422784748}}'\n",
      "plsr: {'fold_0': 2.805494937448327, 'fold_1': 3.1068044683450666, 'fold_2': 2.66357770388816, 'fold_3': 3.2361240574078223, 'fold_4': 8.667239967254355, 'MSE': 4.095620560363757, 'R2': 0.9931853393712125}'\n",
      "plsr_scale: {'fold_0': 2.853755982343711, 'fold_1': 3.148289975293722, 'fold_2': 2.723808807358572, 'fold_3': 3.271647644328985, 'fold_4': 8.256022634151726, 'MSE': 4.050495323911109, 'R2': 0.993260422784748}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 64 components'\n",
      "Running PLSR with 64 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7343,plsr_scale:1.7834'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8073,plsr_scale:2.8499'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.774,plsr_scale:1.8195'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1095,plsr_scale:3.1539'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8412,plsr_scale:1.8844'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6702,plsr_scale:2.717'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8316,plsr_scale:1.8692'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2401,plsr_scale:3.2737'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6352,plsr_scale:1.6812'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.641,plsr_scale:8.2305'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8668,plsr_scale:1.9086'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6292,plsr_scale:2.6623'\n",
      "Train times: {'fold_0': 11, 'fold_1': 10, 'fold_2': 10, 'fold_3': 10, 'fold_4': 10, 'mean': 10.2}'\n",
      "Test times: {'fold_0': 1, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.2}'\n",
      "Scores: {'fold_0': {'plsr': 2.807290429321935, 'plsr_scale': 2.849947990849515}, 'fold_1': {'plsr': 3.109541230439485, 'plsr_scale': 3.1538664498792217}, 'fold_2': {'plsr': 2.6701698312610103, 'plsr_scale': 2.716955120989979}, 'fold_3': {'plsr': 3.2401282857550653, 'plsr_scale': 3.273743396618677}, 'fold_4': {'plsr': 8.64099183198057, 'plsr_scale': 8.230538852293433}, 'MSE': {'plsr': 4.093397552176729, 'plsr_scale': 4.0448019915425135}, 'R2': {'plsr': 0.9931890382115094, 'plsr_scale': 0.9932698958615057}}'\n",
      "plsr: {'fold_0': 2.807290429321935, 'fold_1': 3.109541230439485, 'fold_2': 2.6701698312610103, 'fold_3': 3.2401282857550653, 'fold_4': 8.64099183198057, 'MSE': 4.093397552176729, 'R2': 0.9931890382115094}'\n",
      "plsr_scale: {'fold_0': 2.849947990849515, 'fold_1': 3.1538664498792217, 'fold_2': 2.716955120989979, 'fold_3': 3.273743396618677, 'fold_4': 8.230538852293433, 'MSE': 4.0448019915425135, 'R2': 0.9932698958615057}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 65 components'\n",
      "Running PLSR with 65 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.732,plsr_scale:1.7811'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8158,plsr_scale:2.851'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7716,plsr_scale:1.817'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1064,plsr_scale:3.1602'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8389,plsr_scale:1.8819'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6774,plsr_scale:2.7127'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8293,plsr_scale:1.8669'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2434,plsr_scale:3.2758'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6337,plsr_scale:1.6787'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.6782,plsr_scale:8.2462'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8649,plsr_scale:1.9063'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6278,plsr_scale:2.6631'\n",
      "Train times: {'fold_0': 10, 'fold_1': 10, 'fold_2': 10, 'fold_3': 10, 'fold_4': 10, 'mean': 10.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8158095263870333, 'plsr_scale': 2.851014515401128}, 'fold_1': {'plsr': 3.1063771357093177, 'plsr_scale': 3.160204217535631}, 'fold_2': {'plsr': 2.6773911019774865, 'plsr_scale': 2.712665304650511}, 'fold_3': {'plsr': 3.2433856978124282, 'plsr_scale': 3.2757869843595206}, 'fold_4': {'plsr': 8.678177885034422, 'plsr_scale': 8.246187823713896}, 'MSE': {'plsr': 4.103999916420026, 'plsr_scale': 4.048963306806396}, 'R2': {'plsr': 0.993171397047462, 'plsr_scale': 0.9932629718921402}}'\n",
      "plsr: {'fold_0': 2.8158095263870333, 'fold_1': 3.1063771357093177, 'fold_2': 2.6773911019774865, 'fold_3': 3.2433856978124282, 'fold_4': 8.678177885034422, 'MSE': 4.103999916420026, 'R2': 0.993171397047462}'\n",
      "plsr_scale: {'fold_0': 2.851014515401128, 'fold_1': 3.160204217535631, 'fold_2': 2.712665304650511, 'fold_3': 3.2757869843595206, 'fold_4': 8.246187823713896, 'MSE': 4.048963306806396, 'R2': 0.9932629718921402}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 66 components'\n",
      "Running PLSR with 66 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7305,plsr_scale:1.7788'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.817,plsr_scale:2.8482'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7695,plsr_scale:1.8146'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1131,plsr_scale:3.1575'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.837,plsr_scale:1.8798'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6798,plsr_scale:2.7124'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8273,plsr_scale:1.8646'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2447,plsr_scale:3.2744'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6323,plsr_scale:1.6765'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.6324,plsr_scale:8.3048'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8633,plsr_scale:1.9041'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6308,plsr_scale:2.6575'\n",
      "Train times: {'fold_0': 10, 'fold_1': 10, 'fold_2': 10, 'fold_3': 10, 'fold_4': 10, 'mean': 10.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.817012718299324, 'plsr_scale': 2.848196685434975}, 'fold_1': {'plsr': 3.1130623980459062, 'plsr_scale': 3.1574744434468274}, 'fold_2': {'plsr': 2.6798097728799535, 'plsr_scale': 2.7124093247255665}, 'fold_3': {'plsr': 3.244677876868206, 'plsr_scale': 3.2743669050570317}, 'fold_4': {'plsr': 8.632437362905806, 'plsr_scale': 8.304778994213114}, 'MSE': {'plsr': 4.097173824747576, 'plsr_scale': 4.0592342019166665}, 'R2': {'plsr': 0.9931827549106926, 'plsr_scale': 0.9932458822561501}}'\n",
      "plsr: {'fold_0': 2.817012718299324, 'fold_1': 3.1130623980459062, 'fold_2': 2.6798097728799535, 'fold_3': 3.244677876868206, 'fold_4': 8.632437362905806, 'MSE': 4.097173824747576, 'R2': 0.9931827549106926}'\n",
      "plsr_scale: {'fold_0': 2.848196685434975, 'fold_1': 3.1574744434468274, 'fold_2': 2.7124093247255665, 'fold_3': 3.2743669050570317, 'fold_4': 8.304778994213114, 'MSE': 4.0592342019166665, 'R2': 0.9932458822561501}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 67 components'\n",
      "Running PLSR with 67 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7289,plsr_scale:1.7765'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8174,plsr_scale:2.8463'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7672,plsr_scale:1.8123'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1118,plsr_scale:3.1506'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8348,plsr_scale:1.8776'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6811,plsr_scale:2.7158'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8251,plsr_scale:1.8624'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2397,plsr_scale:3.2705'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6305,plsr_scale:1.6744'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.6429,plsr_scale:8.3641'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8619,plsr_scale:1.9021'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6405,plsr_scale:2.6537'\n",
      "Train times: {'fold_0': 10, 'fold_1': 10, 'fold_2': 10, 'fold_3': 10, 'fold_4': 10, 'mean': 10.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8174345135696903, 'plsr_scale': 2.8462637945443436}, 'fold_1': {'plsr': 3.111751570837562, 'plsr_scale': 3.150566776029358}, 'fold_2': {'plsr': 2.6810668291440685, 'plsr_scale': 2.7157683122281613}, 'fold_3': {'plsr': 3.239720930408089, 'plsr_scale': 3.2705450994447753}, 'fold_4': {'plsr': 8.642914544283311, 'plsr_scale': 8.364147151382367}, 'MSE': {'plsr': 4.0983511525515715, 'plsr_scale': 4.069244274879728}, 'R2': {'plsr': 0.993180795967154, 'plsr_scale': 0.9932292265994291}}'\n",
      "plsr: {'fold_0': 2.8174345135696903, 'fold_1': 3.111751570837562, 'fold_2': 2.6810668291440685, 'fold_3': 3.239720930408089, 'fold_4': 8.642914544283311, 'MSE': 4.0983511525515715, 'R2': 0.993180795967154}'\n",
      "plsr_scale: {'fold_0': 2.8462637945443436, 'fold_1': 3.150566776029358, 'fold_2': 2.7157683122281613, 'fold_3': 3.2705450994447753, 'fold_4': 8.364147151382367, 'MSE': 4.069244274879728, 'R2': 0.9932292265994291}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 68 components'\n",
      "Running PLSR with 68 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7272,plsr_scale:1.7744'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8286,plsr_scale:2.8412'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7655,plsr_scale:1.8101'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1187,plsr_scale:3.1517'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8331,plsr_scale:1.8755'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6865,plsr_scale:2.7205'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8236,plsr_scale:1.8604'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.242,plsr_scale:3.2633'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.629,plsr_scale:1.6723'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.6645,plsr_scale:8.4456'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8607,plsr_scale:1.9002'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6429,plsr_scale:2.644'\n",
      "Train times: {'fold_0': 10, 'fold_1': 11, 'fold_2': 10, 'fold_3': 10, 'fold_4': 10, 'mean': 10.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.828609371754592, 'plsr_scale': 2.8412013522215243}, 'fold_1': {'plsr': 3.1186852245651826, 'plsr_scale': 3.1516553200451853}, 'fold_2': {'plsr': 2.686466519138308, 'plsr_scale': 2.7205235607346747}, 'fold_3': {'plsr': 3.2420269002100928, 'plsr_scale': 3.263270211143625}, 'fold_4': {'plsr': 8.664546660948307, 'plsr_scale': 8.445609694047988}, 'MSE': {'plsr': 4.107840323330256, 'plsr_scale': 4.084234683713009}, 'R2': {'plsr': 0.9931650070341823, 'plsr_scale': 0.993204284213439}}'\n",
      "plsr: {'fold_0': 2.828609371754592, 'fold_1': 3.1186852245651826, 'fold_2': 2.686466519138308, 'fold_3': 3.2420269002100928, 'fold_4': 8.664546660948307, 'MSE': 4.107840323330256, 'R2': 0.9931650070341823}'\n",
      "plsr_scale: {'fold_0': 2.8412013522215243, 'fold_1': 3.1516553200451853, 'fold_2': 2.7205235607346747, 'fold_3': 3.263270211143625, 'fold_4': 8.445609694047988, 'MSE': 4.084234683713009, 'R2': 0.993204284213439}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 69 components'\n",
      "Running PLSR with 69 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7257,plsr_scale:1.7726'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8312,plsr_scale:2.846'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7634,plsr_scale:1.808'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1195,plsr_scale:3.1499'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8316,plsr_scale:1.8734'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6924,plsr_scale:2.7227'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8219,plsr_scale:1.8585'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2405,plsr_scale:3.2598'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6278,plsr_scale:1.6705'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.6937,plsr_scale:8.4997'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8594,plsr_scale:1.8986'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6445,plsr_scale:2.6456'\n",
      "Train times: {'fold_0': 10, 'fold_1': 10, 'fold_2': 10, 'fold_3': 10, 'fold_4': 10, 'mean': 10.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8312072026205883, 'plsr_scale': 2.8460476985998726}, 'fold_1': {'plsr': 3.1195374815591985, 'plsr_scale': 3.1499242139796215}, 'fold_2': {'plsr': 2.692438644344776, 'plsr_scale': 2.722692952177661}, 'fold_3': {'plsr': 3.2405122706660774, 'plsr_scale': 3.259832883648028}, 'fold_4': {'plsr': 8.693736095696462, 'plsr_scale': 8.499726450609842}, 'MSE': {'plsr': 4.115258589477443, 'plsr_scale': 4.095425571148687}, 'R2': {'plsr': 0.9931526638579768, 'plsr_scale': 0.9931856638117477}}'\n",
      "plsr: {'fold_0': 2.8312072026205883, 'fold_1': 3.1195374815591985, 'fold_2': 2.692438644344776, 'fold_3': 3.2405122706660774, 'fold_4': 8.693736095696462, 'MSE': 4.115258589477443, 'R2': 0.9931526638579768}'\n",
      "plsr_scale: {'fold_0': 2.8460476985998726, 'fold_1': 3.1499242139796215, 'fold_2': 2.722692952177661, 'fold_3': 3.259832883648028, 'fold_4': 8.499726450609842, 'MSE': 4.095425571148687, 'R2': 0.9931856638117477}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 70 components'\n",
      "Running PLSR with 70 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7247,plsr_scale:1.7708'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8349,plsr_scale:2.8436'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7618,plsr_scale:1.8062'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1276,plsr_scale:3.152'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8305,plsr_scale:1.8715'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6891,plsr_scale:2.7267'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8202,plsr_scale:1.8568'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2381,plsr_scale:3.2572'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6266,plsr_scale:1.6688'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.6674,plsr_scale:8.5749'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8584,plsr_scale:1.8968'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6411,plsr_scale:2.6418'\n",
      "Train times: {'fold_0': 10, 'fold_1': 10, 'fold_2': 10, 'fold_3': 10, 'fold_4': 11, 'mean': 10.2}'\n",
      "Test times: {'fold_0': 1, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.2}'\n",
      "Scores: {'fold_0': {'plsr': 2.8348800958614015, 'plsr_scale': 2.8435969562232466}, 'fold_1': {'plsr': 3.1276380602679117, 'plsr_scale': 3.1520314001753387}, 'fold_2': {'plsr': 2.68908235547223, 'plsr_scale': 2.726706856194004}, 'fold_3': {'plsr': 3.2381087172843337, 'plsr_scale': 3.2572370897705576}, 'fold_4': {'plsr': 8.667397147704659, 'plsr_scale': 8.574859277458247}, 'MSE': {'plsr': 4.111195513792486, 'plsr_scale': 4.110663968353859}, 'R2': {'plsr': 0.9931594243675246, 'plsr_scale': 0.9931603088004742}}'\n",
      "plsr: {'fold_0': 2.8348800958614015, 'fold_1': 3.1276380602679117, 'fold_2': 2.68908235547223, 'fold_3': 3.2381087172843337, 'fold_4': 8.667397147704659, 'MSE': 4.111195513792486, 'R2': 0.9931594243675246}'\n",
      "plsr_scale: {'fold_0': 2.8435969562232466, 'fold_1': 3.1520314001753387, 'fold_2': 2.726706856194004, 'fold_3': 3.2572370897705576, 'fold_4': 8.574859277458247, 'MSE': 4.110663968353859, 'R2': 0.9931603088004742}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 71 components'\n",
      "Running PLSR with 71 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7236,plsr_scale:1.769'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8408,plsr_scale:2.8475'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7603,plsr_scale:1.8042'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1252,plsr_scale:3.1434'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8293,plsr_scale:1.8695'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6842,plsr_scale:2.7194'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8189,plsr_scale:1.8551'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2429,plsr_scale:3.2466'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6258,plsr_scale:1.6673'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.6309,plsr_scale:8.6103'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8575,plsr_scale:1.8952'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6417,plsr_scale:2.6427'\n",
      "Train times: {'fold_0': 11, 'fold_1': 11, 'fold_2': 11, 'fold_3': 11, 'fold_4': 11, 'mean': 11.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8407856086649717, 'plsr_scale': 2.8475435455974316}, 'fold_1': {'plsr': 3.12515041784687, 'plsr_scale': 3.1433886959017143}, 'fold_2': {'plsr': 2.6841869433006758, 'plsr_scale': 2.7194481508041823}, 'fold_3': {'plsr': 3.2428815794972863, 'plsr_scale': 3.2466434535437396}, 'fold_4': {'plsr': 8.63093703641015, 'plsr_scale': 8.610290133667553}, 'MSE': {'plsr': 4.104564221997389, 'plsr_scale': 4.113239464565499}, 'R2': {'plsr': 0.9931704581052568, 'plsr_scale': 0.9931560234590041}}'\n",
      "plsr: {'fold_0': 2.8407856086649717, 'fold_1': 3.12515041784687, 'fold_2': 2.6841869433006758, 'fold_3': 3.2428815794972863, 'fold_4': 8.63093703641015, 'MSE': 4.104564221997389, 'R2': 0.9931704581052568}'\n",
      "plsr_scale: {'fold_0': 2.8475435455974316, 'fold_1': 3.1433886959017143, 'fold_2': 2.7194481508041823, 'fold_3': 3.2466434535437396, 'fold_4': 8.610290133667553, 'MSE': 4.113239464565499, 'R2': 0.9931560234590041}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 72 components'\n",
      "Running PLSR with 72 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7225,plsr_scale:1.7673'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8418,plsr_scale:2.845'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7591,plsr_scale:1.8024'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1319,plsr_scale:3.1442'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8283,plsr_scale:1.8676'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6832,plsr_scale:2.7188'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8178,plsr_scale:1.8534'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2459,plsr_scale:3.2419'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6249,plsr_scale:1.6657'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.5995,plsr_scale:8.6234'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8568,plsr_scale:1.8936'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6423,plsr_scale:2.6387'\n",
      "Train times: {'fold_0': 11, 'fold_1': 11, 'fold_2': 11, 'fold_3': 11, 'fold_4': 11, 'mean': 11.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8418112243178895, 'plsr_scale': 2.8450251975200436}, 'fold_1': {'plsr': 3.1319471211655707, 'plsr_scale': 3.1442411421733714}, 'fold_2': {'plsr': 2.6831888879176993, 'plsr_scale': 2.7188072037214335}, 'fold_3': {'plsr': 3.2459047919857262, 'plsr_scale': 3.2419198361161587}, 'fold_4': {'plsr': 8.599471710300023, 'plsr_scale': 8.623371848310729}, 'MSE': {'plsr': 4.100242296962712, 'plsr_scale': 4.114449306080588}, 'R2': {'plsr': 0.9931776493115564, 'plsr_scale': 0.9931540104162385}}'\n",
      "plsr: {'fold_0': 2.8418112243178895, 'fold_1': 3.1319471211655707, 'fold_2': 2.6831888879176993, 'fold_3': 3.2459047919857262, 'fold_4': 8.599471710300023, 'MSE': 4.100242296962712, 'R2': 0.9931776493115564}'\n",
      "plsr_scale: {'fold_0': 2.8450251975200436, 'fold_1': 3.1442411421733714, 'fold_2': 2.7188072037214335, 'fold_3': 3.2419198361161587, 'fold_4': 8.623371848310729, 'MSE': 4.114449306080588, 'R2': 0.9931540104162385}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 73 components'\n",
      "Running PLSR with 73 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7217,plsr_scale:1.7657'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8463,plsr_scale:2.848'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7578,plsr_scale:1.8005'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1371,plsr_scale:3.1379'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8273,plsr_scale:1.8657'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6852,plsr_scale:2.7205'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8168,plsr_scale:1.8518'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2458,plsr_scale:3.2434'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6241,plsr_scale:1.6643'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.5567,plsr_scale:8.6209'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8562,plsr_scale:1.8922'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.64,plsr_scale:2.6406'\n",
      "Train times: {'fold_0': 11, 'fold_1': 11, 'fold_2': 11, 'fold_3': 11, 'fold_4': 11, 'mean': 11.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8463177177142547, 'plsr_scale': 2.8480274244312453}, 'fold_1': {'plsr': 3.137071575396377, 'plsr_scale': 3.137888627375676}, 'fold_2': {'plsr': 2.685208333666803, 'plsr_scale': 2.7205130976713314}, 'fold_3': {'plsr': 3.2458188792153178, 'plsr_scale': 3.243391853560251}, 'fold_4': {'plsr': 8.556737524162061, 'plsr_scale': 8.620873730989054}, 'MSE': {'plsr': 4.094010563090595, 'plsr_scale': 4.113914979382239}, 'R2': {'plsr': 0.9931880182289992, 'plsr_scale': 0.9931548994768974}}'\n",
      "plsr: {'fold_0': 2.8463177177142547, 'fold_1': 3.137071575396377, 'fold_2': 2.685208333666803, 'fold_3': 3.2458188792153178, 'fold_4': 8.556737524162061, 'MSE': 4.094010563090595, 'R2': 0.9931880182289992}'\n",
      "plsr_scale: {'fold_0': 2.8480274244312453, 'fold_1': 3.137888627375676, 'fold_2': 2.7205130976713314, 'fold_3': 3.243391853560251, 'fold_4': 8.620873730989054, 'MSE': 4.113914979382239, 'R2': 0.9931548994768974}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 74 components'\n",
      "Running PLSR with 74 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.721,plsr_scale:1.7643'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8491,plsr_scale:2.8471'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7566,plsr_scale:1.7989'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1395,plsr_scale:3.138'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8264,plsr_scale:1.8641'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6854,plsr_scale:2.7202'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.816,plsr_scale:1.8504'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2476,plsr_scale:3.2435'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6233,plsr_scale:1.6629'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.5665,plsr_scale:8.6504'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8558,plsr_scale:1.8909'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6392,plsr_scale:2.645'\n",
      "Train times: {'fold_0': 11, 'fold_1': 11, 'fold_2': 11, 'fold_3': 11, 'fold_4': 11, 'mean': 11.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8490554436337905, 'plsr_scale': 2.847061299626527}, 'fold_1': {'plsr': 3.13949681371057, 'plsr_scale': 3.1379804482730735}, 'fold_2': {'plsr': 2.6853522110329435, 'plsr_scale': 2.7201703382220925}, 'fold_3': {'plsr': 3.2475712146058533, 'plsr_scale': 3.2435061627782606}, 'fold_4': {'plsr': 8.566514671146185, 'plsr_scale': 8.650419987461408}, 'MSE': {'plsr': 4.097377670917328, 'plsr_scale': 4.119602456146958}, 'R2': {'plsr': 0.9931824157331621, 'plsr_scale': 0.9931454361432184}}'\n",
      "plsr: {'fold_0': 2.8490554436337905, 'fold_1': 3.13949681371057, 'fold_2': 2.6853522110329435, 'fold_3': 3.2475712146058533, 'fold_4': 8.566514671146185, 'MSE': 4.097377670917328, 'R2': 0.9931824157331621}'\n",
      "plsr_scale: {'fold_0': 2.847061299626527, 'fold_1': 3.1379804482730735, 'fold_2': 2.7201703382220925, 'fold_3': 3.2435061627782606, 'fold_4': 8.650419987461408, 'MSE': 4.119602456146958, 'R2': 0.9931454361432184}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 75 components'\n",
      "Running PLSR with 75 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7201,plsr_scale:1.7628'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8494,plsr_scale:2.8394'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7555,plsr_scale:1.7973'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1369,plsr_scale:3.1403'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8254,plsr_scale:1.8624'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6822,plsr_scale:2.7211'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8152,plsr_scale:1.8491'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2473,plsr_scale:3.2441'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6227,plsr_scale:1.6617'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.577,plsr_scale:8.7198'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8553,plsr_scale:1.8897'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6399,plsr_scale:2.6461'\n",
      "Train times: {'fold_0': 11, 'fold_1': 11, 'fold_2': 11, 'fold_3': 11, 'fold_4': 11, 'mean': 11.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8493568613513265, 'plsr_scale': 2.8393615738895788}, 'fold_1': {'plsr': 3.136935700596769, 'plsr_scale': 3.140339052566234}, 'fold_2': {'plsr': 2.682185293074754, 'plsr_scale': 2.7211426005749684}, 'fold_3': {'plsr': 3.247343358768398, 'plsr_scale': 3.244117923682338}, 'fold_4': {'plsr': 8.5770435895918, 'plsr_scale': 8.719798144472424}, 'MSE': {'plsr': 4.09835214032509, 'plsr_scale': 4.132723512743499}, 'R2': {'plsr': 0.993180794323608, 'plsr_scale': 0.9931236041530526}}'\n",
      "plsr: {'fold_0': 2.8493568613513265, 'fold_1': 3.136935700596769, 'fold_2': 2.682185293074754, 'fold_3': 3.247343358768398, 'fold_4': 8.5770435895918, 'MSE': 4.09835214032509, 'R2': 0.993180794323608}'\n",
      "plsr_scale: {'fold_0': 2.8393615738895788, 'fold_1': 3.140339052566234, 'fold_2': 2.7211426005749684, 'fold_3': 3.244117923682338, 'fold_4': 8.719798144472424, 'MSE': 4.132723512743499, 'R2': 0.9931236041530526}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 76 components'\n",
      "Running PLSR with 76 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7194,plsr_scale:1.7615'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8509,plsr_scale:2.8376'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7546,plsr_scale:1.7957'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1386,plsr_scale:3.1388'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8247,plsr_scale:1.8608'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6858,plsr_scale:2.7188'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8145,plsr_scale:1.848'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2465,plsr_scale:3.2468'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6222,plsr_scale:1.6604'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4691,plsr_scale:8.8069'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8548,plsr_scale:1.8886'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6388,plsr_scale:2.6496'\n",
      "Train times: {'fold_0': 11, 'fold_1': 11, 'fold_2': 11, 'fold_3': 11, 'fold_4': 11, 'mean': 11.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.850906450299223, 'plsr_scale': 2.837630284684202}, 'fold_1': {'plsr': 3.138559267055258, 'plsr_scale': 3.1388031314430447}, 'fold_2': {'plsr': 2.685818892341574, 'plsr_scale': 2.7187929747579482}, 'fold_3': {'plsr': 3.24651764769133, 'plsr_scale': 3.2467986496085732}, 'fold_4': {'plsr': 8.469115582846301, 'plsr_scale': 8.806862613536829}, 'MSE': {'plsr': 4.077967137621373, 'plsr_scale': 4.149545497082039}, 'R2': {'plsr': 0.993214712718463, 'plsr_scale': 0.9930956142275503}}'\n",
      "plsr: {'fold_0': 2.850906450299223, 'fold_1': 3.138559267055258, 'fold_2': 2.685818892341574, 'fold_3': 3.24651764769133, 'fold_4': 8.469115582846301, 'MSE': 4.077967137621373, 'R2': 0.993214712718463}'\n",
      "plsr_scale: {'fold_0': 2.837630284684202, 'fold_1': 3.1388031314430447, 'fold_2': 2.7187929747579482, 'fold_3': 3.2467986496085732, 'fold_4': 8.806862613536829, 'MSE': 4.149545497082039, 'R2': 0.9930956142275503}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 77 components'\n",
      "Running PLSR with 77 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7189,plsr_scale:1.7602'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8571,plsr_scale:2.8357'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7538,plsr_scale:1.7943'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1448,plsr_scale:3.145'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.824,plsr_scale:1.8593'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6827,plsr_scale:2.7172'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8139,plsr_scale:1.8469'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2463,plsr_scale:3.2476'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6218,plsr_scale:1.6593'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.5037,plsr_scale:8.8504'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8544,plsr_scale:1.8875'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6374,plsr_scale:2.6521'\n",
      "Train times: {'fold_0': 12, 'fold_1': 12, 'fold_2': 12, 'fold_3': 12, 'fold_4': 12, 'mean': 12.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8571324688117077, 'plsr_scale': 2.835733569774788}, 'fold_1': {'plsr': 3.1448321596248836, 'plsr_scale': 3.145008625778342}, 'fold_2': {'plsr': 2.6826932357594884, 'plsr_scale': 2.7172164870461835}, 'fold_3': {'plsr': 3.2462826960975635, 'plsr_scale': 3.247553983096025}, 'fold_4': {'plsr': 8.503691430934175, 'plsr_scale': 8.850440097048384}, 'MSE': {'plsr': 4.086709469742962, 'plsr_scale': 4.158957068838242}, 'R2': {'plsr': 0.9932001664425971, 'plsr_scale': 0.9930799544107883}}'\n",
      "plsr: {'fold_0': 2.8571324688117077, 'fold_1': 3.1448321596248836, 'fold_2': 2.6826932357594884, 'fold_3': 3.2462826960975635, 'fold_4': 8.503691430934175, 'MSE': 4.086709469742962, 'R2': 0.9932001664425971}'\n",
      "plsr_scale: {'fold_0': 2.835733569774788, 'fold_1': 3.145008625778342, 'fold_2': 2.7172164870461835, 'fold_3': 3.247553983096025, 'fold_4': 8.850440097048384, 'MSE': 4.158957068838242, 'R2': 0.9930799544107883}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 78 components'\n",
      "Running PLSR with 78 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7184,plsr_scale:1.7591'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8587,plsr_scale:2.8389'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7532,plsr_scale:1.7929'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1474,plsr_scale:3.1412'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8234,plsr_scale:1.8578'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6825,plsr_scale:2.7191'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8134,plsr_scale:1.8459'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2452,plsr_scale:3.244'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6214,plsr_scale:1.6583'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.5061,plsr_scale:8.8866'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.854,plsr_scale:1.8866'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6362,plsr_scale:2.6482'\n",
      "Train times: {'fold_0': 12, 'fold_1': 12, 'fold_2': 12, 'fold_3': 12, 'fold_4': 12, 'mean': 12.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.858701749150198, 'plsr_scale': 2.838928474291186}, 'fold_1': {'plsr': 3.14738047515956, 'plsr_scale': 3.1412084828296694}, 'fold_2': {'plsr': 2.682470226986147, 'plsr_scale': 2.719113087683487}, 'fold_3': {'plsr': 3.2452463869188555, 'plsr_scale': 3.2440219982428466}, 'fold_4': {'plsr': 8.506064742357513, 'plsr_scale': 8.886573649014297}, 'MSE': {'plsr': 4.087755989865162, 'plsr_scale': 4.165734240158232}, 'R2': {'plsr': 0.9931984251486055, 'plsr_scale': 0.9930686779456256}}'\n",
      "plsr: {'fold_0': 2.858701749150198, 'fold_1': 3.14738047515956, 'fold_2': 2.682470226986147, 'fold_3': 3.2452463869188555, 'fold_4': 8.506064742357513, 'MSE': 4.087755989865162, 'R2': 0.9931984251486055}'\n",
      "plsr_scale: {'fold_0': 2.838928474291186, 'fold_1': 3.1412084828296694, 'fold_2': 2.719113087683487, 'fold_3': 3.2440219982428466, 'fold_4': 8.886573649014297, 'MSE': 4.165734240158232, 'R2': 0.9930686779456256}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 79 components'\n",
      "Running PLSR with 79 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7179,plsr_scale:1.758'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8608,plsr_scale:2.8374'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7526,plsr_scale:1.7916'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1475,plsr_scale:3.1455'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8228,plsr_scale:1.8564'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6851,plsr_scale:2.7172'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.813,plsr_scale:1.8448'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2457,plsr_scale:3.2429'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.621,plsr_scale:1.6572'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.479,plsr_scale:8.8876'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8537,plsr_scale:1.8855'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6384,plsr_scale:2.6459'\n",
      "Train times: {'fold_0': 12, 'fold_1': 12, 'fold_2': 12, 'fold_3': 12, 'fold_4': 12, 'mean': 12.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.860789644096112, 'plsr_scale': 2.8374331146271654}, 'fold_1': {'plsr': 3.147464053329446, 'plsr_scale': 3.1455229030380516}, 'fold_2': {'plsr': 2.6851382393847385, 'plsr_scale': 2.7171575205052623}, 'fold_3': {'plsr': 3.2456573849980415, 'plsr_scale': 3.242914622926247}, 'fold_4': {'plsr': 8.478957908323244, 'plsr_scale': 8.887597271651908}, 'MSE': {'plsr': 4.083385809870241, 'plsr_scale': 4.165890438711588}, 'R2': {'plsr': 0.9932056966458336, 'plsr_scale': 0.9930684180484706}}'\n",
      "plsr: {'fold_0': 2.860789644096112, 'fold_1': 3.147464053329446, 'fold_2': 2.6851382393847385, 'fold_3': 3.2456573849980415, 'fold_4': 8.478957908323244, 'MSE': 4.083385809870241, 'R2': 0.9932056966458336}'\n",
      "plsr_scale: {'fold_0': 2.8374331146271654, 'fold_1': 3.1455229030380516, 'fold_2': 2.7171575205052623, 'fold_3': 3.242914622926247, 'fold_4': 8.887597271651908, 'MSE': 4.165890438711588, 'R2': 0.9930684180484706}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 80 components'\n",
      "Running PLSR with 80 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7175,plsr_scale:1.7569'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8639,plsr_scale:2.8399'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.752,plsr_scale:1.7903'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1443,plsr_scale:3.1439'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8224,plsr_scale:1.8551'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6835,plsr_scale:2.7129'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8126,plsr_scale:1.8438'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2438,plsr_scale:3.2376'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6206,plsr_scale:1.6561'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.5181,plsr_scale:8.8731'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8535,plsr_scale:1.8846'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6386,plsr_scale:2.6469'\n",
      "Train times: {'fold_0': 12, 'fold_1': 12, 'fold_2': 12, 'fold_3': 12, 'fold_4': 12, 'mean': 12.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.863914380766068, 'plsr_scale': 2.8399394901770063}, 'fold_1': {'plsr': 3.1442887497546956, 'plsr_scale': 3.14386173217843}, 'fold_2': {'plsr': 2.683469312872803, 'plsr_scale': 2.7128937811240363}, 'fold_3': {'plsr': 3.2438385229722453, 'plsr_scale': 3.2375817616188374}, 'fold_4': {'plsr': 8.51810077992176, 'plsr_scale': 8.873109669906919}, 'MSE': {'plsr': 4.09050528557713, 'plsr_scale': 4.161243652027848}, 'R2': {'plsr': 0.9931938506239469, 'plsr_scale': 0.9930761497887032}}'\n",
      "plsr: {'fold_0': 2.863914380766068, 'fold_1': 3.1442887497546956, 'fold_2': 2.683469312872803, 'fold_3': 3.2438385229722453, 'fold_4': 8.51810077992176, 'MSE': 4.09050528557713, 'R2': 0.9931938506239469}'\n",
      "plsr_scale: {'fold_0': 2.8399394901770063, 'fold_1': 3.14386173217843, 'fold_2': 2.7128937811240363, 'fold_3': 3.2375817616188374, 'fold_4': 8.873109669906919, 'MSE': 4.161243652027848, 'R2': 0.9930761497887032}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 81 components'\n",
      "Running PLSR with 81 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7171,plsr_scale:1.7559'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8645,plsr_scale:2.8403'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7515,plsr_scale:1.7891'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1458,plsr_scale:3.1358'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8219,plsr_scale:1.8539'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6843,plsr_scale:2.7066'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8123,plsr_scale:1.8429'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2463,plsr_scale:3.2385'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6202,plsr_scale:1.6552'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.5175,plsr_scale:8.8463'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8532,plsr_scale:1.8837'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6401,plsr_scale:2.6435'\n",
      "Train times: {'fold_0': 12, 'fold_1': 12, 'fold_2': 12, 'fold_3': 12, 'fold_4': 12, 'mean': 12.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8645052319661217, 'plsr_scale': 2.8403393242707096}, 'fold_1': {'plsr': 3.1458245401649036, 'plsr_scale': 3.135781909861014}, 'fold_2': {'plsr': 2.6842680093665763, 'plsr_scale': 2.7065516855711973}, 'fold_3': {'plsr': 3.2463199476135074, 'plsr_scale': 3.2385029050439607}, 'fold_4': {'plsr': 8.517467468018205, 'plsr_scale': 8.846328764251746}, 'MSE': {'plsr': 4.091459997445567, 'plsr_scale': 4.153268109110006}, 'R2': {'plsr': 0.9931922620887578, 'plsr_scale': 0.9930894202119551}}'\n",
      "plsr: {'fold_0': 2.8645052319661217, 'fold_1': 3.1458245401649036, 'fold_2': 2.6842680093665763, 'fold_3': 3.2463199476135074, 'fold_4': 8.517467468018205, 'MSE': 4.091459997445567, 'R2': 0.9931922620887578}'\n",
      "plsr_scale: {'fold_0': 2.8403393242707096, 'fold_1': 3.135781909861014, 'fold_2': 2.7065516855711973, 'fold_3': 3.2385029050439607, 'fold_4': 8.846328764251746, 'MSE': 4.153268109110006, 'R2': 0.9930894202119551}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 82 components'\n",
      "Running PLSR with 82 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7168,plsr_scale:1.7547'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8663,plsr_scale:2.841'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7511,plsr_scale:1.7879'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1467,plsr_scale:3.1387'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8215,plsr_scale:1.8528'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.688,plsr_scale:2.7063'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.812,plsr_scale:1.8419'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2503,plsr_scale:3.242'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.62,plsr_scale:1.6543'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4819,plsr_scale:8.8203'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.853,plsr_scale:1.8827'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.64,plsr_scale:2.6423'\n",
      "Train times: {'fold_0': 12, 'fold_1': 12, 'fold_2': 12, 'fold_3': 12, 'fold_4': 12, 'mean': 12.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.866349219430367, 'plsr_scale': 2.840963919081915}, 'fold_1': {'plsr': 3.1466857349960122, 'plsr_scale': 3.1386921595677326}, 'fold_2': {'plsr': 2.6879502861886237, 'plsr_scale': 2.7062738479329806}, 'fold_3': {'plsr': 3.25033986542193, 'plsr_scale': 3.2420099276540544}, 'fold_4': {'plsr': 8.481899557574637, 'plsr_scale': 8.820259250380152}, 'MSE': {'plsr': 4.086429166151098, 'plsr_scale': 4.1494081365882485}, 'R2': {'plsr': 0.9932006328368402, 'plsr_scale': 0.9930958427802532}}'\n",
      "plsr: {'fold_0': 2.866349219430367, 'fold_1': 3.1466857349960122, 'fold_2': 2.6879502861886237, 'fold_3': 3.25033986542193, 'fold_4': 8.481899557574637, 'MSE': 4.086429166151098, 'R2': 0.9932006328368402}'\n",
      "plsr_scale: {'fold_0': 2.840963919081915, 'fold_1': 3.1386921595677326, 'fold_2': 2.7062738479329806, 'fold_3': 3.2420099276540544, 'fold_4': 8.820259250380152, 'MSE': 4.1494081365882485, 'R2': 0.9930958427802532}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 83 components'\n",
      "Running PLSR with 83 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7165,plsr_scale:1.7538'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8662,plsr_scale:2.8483'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7507,plsr_scale:1.7868'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.148,plsr_scale:3.1421'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8212,plsr_scale:1.8517'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6873,plsr_scale:2.7048'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8118,plsr_scale:1.8409'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2487,plsr_scale:3.2454'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6198,plsr_scale:1.6533'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4703,plsr_scale:8.8094'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8528,plsr_scale:1.8819'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6389,plsr_scale:2.6464'\n",
      "Train times: {'fold_0': 12, 'fold_1': 12, 'fold_2': 12, 'fold_3': 12, 'fold_4': 13, 'mean': 12.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.866190949469479, 'plsr_scale': 2.8483443787920364}, 'fold_1': {'plsr': 3.1480330534049834, 'plsr_scale': 3.1421109982850206}, 'fold_2': {'plsr': 2.687250532073284, 'plsr_scale': 2.704815857365823}, 'fold_3': {'plsr': 3.2486713472464004, 'plsr_scale': 3.2453728956446892}, 'fold_4': {'plsr': 8.470321916890173, 'plsr_scale': 8.809407625682132}, 'MSE': {'plsr': 4.083878421670963, 'plsr_scale': 4.149779671437078}, 'R2': {'plsr': 0.9932048769941607, 'plsr_scale': 0.9930952245872665}}'\n",
      "plsr: {'fold_0': 2.866190949469479, 'fold_1': 3.1480330534049834, 'fold_2': 2.687250532073284, 'fold_3': 3.2486713472464004, 'fold_4': 8.470321916890173, 'MSE': 4.083878421670963, 'R2': 0.9932048769941607}'\n",
      "plsr_scale: {'fold_0': 2.8483443787920364, 'fold_1': 3.1421109982850206, 'fold_2': 2.704815857365823, 'fold_3': 3.2453728956446892, 'fold_4': 8.809407625682132, 'MSE': 4.149779671437078, 'R2': 0.9930952245872665}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 84 components'\n",
      "Running PLSR with 84 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7162,plsr_scale:1.7529'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8692,plsr_scale:2.8474'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7504,plsr_scale:1.7857'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1508,plsr_scale:3.1411'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8209,plsr_scale:1.8508'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6922,plsr_scale:2.7022'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8116,plsr_scale:1.8401'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2491,plsr_scale:3.2432'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6195,plsr_scale:1.6524'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.515,plsr_scale:8.8782'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8526,plsr_scale:1.8811'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6387,plsr_scale:2.6456'\n",
      "Train times: {'fold_0': 13, 'fold_1': 13, 'fold_2': 13, 'fold_3': 13, 'fold_4': 13, 'mean': 13.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8691589027556907, 'plsr_scale': 2.8474399497797567}, 'fold_1': {'plsr': 3.1508488960245193, 'plsr_scale': 3.1410779076947652}, 'fold_2': {'plsr': 2.6921555529981402, 'plsr_scale': 2.702171424523021}, 'fold_3': {'plsr': 3.2491436029173397, 'plsr_scale': 3.243179937943988}, 'fold_4': {'plsr': 8.51501184962462, 'plsr_scale': 8.878229479296198}, 'MSE': {'plsr': 4.095046969041954, 'plsr_scale': 4.162186387707892}, 'R2': {'plsr': 0.9931862937638716, 'plsr_scale': 0.9930745811805698}}'\n",
      "plsr: {'fold_0': 2.8691589027556907, 'fold_1': 3.1508488960245193, 'fold_2': 2.6921555529981402, 'fold_3': 3.2491436029173397, 'fold_4': 8.51501184962462, 'MSE': 4.095046969041954, 'R2': 0.9931862937638716}'\n",
      "plsr_scale: {'fold_0': 2.8474399497797567, 'fold_1': 3.1410779076947652, 'fold_2': 2.702171424523021, 'fold_3': 3.243179937943988, 'fold_4': 8.878229479296198, 'MSE': 4.162186387707892, 'R2': 0.9930745811805698}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 85 components'\n",
      "Running PLSR with 85 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.716,plsr_scale:1.752'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8684,plsr_scale:2.8523'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7501,plsr_scale:1.7847'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1517,plsr_scale:3.1453'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8207,plsr_scale:1.8496'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6926,plsr_scale:2.7001'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8114,plsr_scale:1.8393'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.249,plsr_scale:3.2435'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6194,plsr_scale:1.6516'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4648,plsr_scale:8.9143'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8525,plsr_scale:1.8803'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6394,plsr_scale:2.6422'\n",
      "Train times: {'fold_0': 13, 'fold_1': 13, 'fold_2': 13, 'fold_3': 13, 'fold_4': 13, 'mean': 13.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8684372841205232, 'plsr_scale': 2.8523395591016536}, 'fold_1': {'plsr': 3.15170485518761, 'plsr_scale': 3.145336715329519}, 'fold_2': {'plsr': 2.6925734964629706, 'plsr_scale': 2.7000669724558035}, 'fold_3': {'plsr': 3.248970920273842, 'plsr_scale': 3.2434821154656386}, 'fold_4': {'plsr': 8.464784881876826, 'plsr_scale': 8.91434760675814}, 'MSE': {'plsr': 4.0850795006850475, 'plsr_scale': 4.1708804195399685}, 'R2': {'plsr': 0.9932028785312297, 'plsr_scale': 0.9930601152710554}}'\n",
      "plsr: {'fold_0': 2.8684372841205232, 'fold_1': 3.15170485518761, 'fold_2': 2.6925734964629706, 'fold_3': 3.248970920273842, 'fold_4': 8.464784881876826, 'MSE': 4.0850795006850475, 'R2': 0.9932028785312297}'\n",
      "plsr_scale: {'fold_0': 2.8523395591016536, 'fold_1': 3.145336715329519, 'fold_2': 2.7000669724558035, 'fold_3': 3.2434821154656386, 'fold_4': 8.91434760675814, 'MSE': 4.1708804195399685, 'R2': 0.9930601152710554}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 86 components'\n",
      "Running PLSR with 86 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7159,plsr_scale:1.751'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.872,plsr_scale:2.8584'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7498,plsr_scale:1.7838'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1561,plsr_scale:3.1453'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8205,plsr_scale:1.8487'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6942,plsr_scale:2.7005'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8112,plsr_scale:1.8384'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2478,plsr_scale:3.2465'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6192,plsr_scale:1.6508'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4346,plsr_scale:8.9465'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8524,plsr_scale:1.8796'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6404,plsr_scale:2.6456'\n",
      "Train times: {'fold_0': 13, 'fold_1': 13, 'fold_2': 13, 'fold_3': 13, 'fold_4': 13, 'mean': 13.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8719891402518045, 'plsr_scale': 2.858357325299389}, 'fold_1': {'plsr': 3.1561454340512203, 'plsr_scale': 3.1453048246757076}, 'fold_2': {'plsr': 2.694196933995701, 'plsr_scale': 2.700497270246113}, 'fold_3': {'plsr': 3.2478476633860662, 'plsr_scale': 3.246474196059546}, 'fold_4': {'plsr': 8.43455291387869, 'plsr_scale': 8.946499021893505}, 'MSE': {'plsr': 4.080733297030803, 'plsr_scale': 4.1791912908284905}, 'R2': {'plsr': 0.9932101101344729, 'plsr_scale': 0.9930462868984007}}'\n",
      "plsr: {'fold_0': 2.8719891402518045, 'fold_1': 3.1561454340512203, 'fold_2': 2.694196933995701, 'fold_3': 3.2478476633860662, 'fold_4': 8.43455291387869, 'MSE': 4.080733297030803, 'R2': 0.9932101101344729}'\n",
      "plsr_scale: {'fold_0': 2.858357325299389, 'fold_1': 3.1453048246757076, 'fold_2': 2.700497270246113, 'fold_3': 3.246474196059546, 'fold_4': 8.946499021893505, 'MSE': 4.1791912908284905, 'R2': 0.9930462868984007}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 87 components'\n",
      "Running PLSR with 87 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7157,plsr_scale:1.7502'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8737,plsr_scale:2.8653'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7496,plsr_scale:1.7829'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1552,plsr_scale:3.1434'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8203,plsr_scale:1.8477'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6963,plsr_scale:2.7003'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.811,plsr_scale:1.8376'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2487,plsr_scale:3.2433'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6191,plsr_scale:1.6501'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4501,plsr_scale:8.9735'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8523,plsr_scale:1.8788'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6395,plsr_scale:2.6451'\n",
      "Train times: {'fold_0': 13, 'fold_1': 13, 'fold_2': 13, 'fold_3': 13, 'fold_4': 13, 'mean': 13.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8737137075847965, 'plsr_scale': 2.8653162468849254}, 'fold_1': {'plsr': 3.1551837510117955, 'plsr_scale': 3.14340441182286}, 'fold_2': {'plsr': 2.6962614837462757, 'plsr_scale': 2.70027641626387}, 'fold_3': {'plsr': 3.2486680365598772, 'plsr_scale': 3.243251958531945}, 'fold_4': {'plsr': 8.450110177614755, 'plsr_scale': 8.973495252045177}, 'MSE': {'plsr': 4.0845736201365, 'plsr_scale': 4.184912982453792}, 'R2': {'plsr': 0.9932037202606346, 'plsr_scale': 0.9930367666349695}}'\n",
      "plsr: {'fold_0': 2.8737137075847965, 'fold_1': 3.1551837510117955, 'fold_2': 2.6962614837462757, 'fold_3': 3.2486680365598772, 'fold_4': 8.450110177614755, 'MSE': 4.0845736201365, 'R2': 0.9932037202606346}'\n",
      "plsr_scale: {'fold_0': 2.8653162468849254, 'fold_1': 3.14340441182286, 'fold_2': 2.70027641626387, 'fold_3': 3.243251958531945, 'fold_4': 8.973495252045177, 'MSE': 4.184912982453792, 'R2': 0.9930367666349695}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 88 components'\n",
      "Running PLSR with 88 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7156,plsr_scale:1.7493'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8744,plsr_scale:2.8666'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7494,plsr_scale:1.782'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1561,plsr_scale:3.1452'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8202,plsr_scale:1.8469'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.6984,plsr_scale:2.6994'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8109,plsr_scale:1.8368'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2473,plsr_scale:3.244'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6189,plsr_scale:1.6493'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4427,plsr_scale:8.9936'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8522,plsr_scale:1.8781'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6397,plsr_scale:2.6448'\n",
      "Train times: {'fold_0': 13, 'fold_1': 13, 'fold_2': 13, 'fold_3': 13, 'fold_4': 13, 'mean': 13.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.874377774524492, 'plsr_scale': 2.86660414166334}, 'fold_1': {'plsr': 3.156134919576392, 'plsr_scale': 3.1452302792700486}, 'fold_2': {'plsr': 2.698353876737541, 'plsr_scale': 2.699350502122467}, 'fold_3': {'plsr': 3.247290073255121, 'plsr_scale': 3.2439800336627735}, 'fold_4': {'plsr': 8.44266003005194, 'plsr_scale': 8.993618197650811}, 'MSE': {'plsr': 4.083549889565858, 'plsr_scale': 4.1895201467707315}, 'R2': {'plsr': 0.9932054236353275, 'plsr_scale': 0.9930291008219826}}'\n",
      "plsr: {'fold_0': 2.874377774524492, 'fold_1': 3.156134919576392, 'fold_2': 2.698353876737541, 'fold_3': 3.247290073255121, 'fold_4': 8.44266003005194, 'MSE': 4.083549889565858, 'R2': 0.9932054236353275}'\n",
      "plsr_scale: {'fold_0': 2.86660414166334, 'fold_1': 3.1452302792700486, 'fold_2': 2.699350502122467, 'fold_3': 3.2439800336627735, 'fold_4': 8.993618197650811, 'MSE': 4.1895201467707315, 'R2': 0.9930291008219826}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 89 components'\n",
      "Running PLSR with 89 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7154,plsr_scale:1.7484'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8787,plsr_scale:2.8704'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7492,plsr_scale:1.781'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1588,plsr_scale:3.1455'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8201,plsr_scale:1.846'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.7002,plsr_scale:2.6995'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8108,plsr_scale:1.8361'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2488,plsr_scale:3.2438'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6188,plsr_scale:1.6486'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4279,plsr_scale:8.9909'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8521,plsr_scale:1.8775'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6401,plsr_scale:2.6447'\n",
      "Train times: {'fold_0': 13, 'fold_1': 13, 'fold_2': 14, 'fold_3': 13, 'fold_4': 13, 'mean': 13.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8787078544208264, 'plsr_scale': 2.8704374104417267}, 'fold_1': {'plsr': 3.1588325505143624, 'plsr_scale': 3.145478971456528}, 'fold_2': {'plsr': 2.7001931431256865, 'plsr_scale': 2.699545963709188}, 'fold_3': {'plsr': 3.2488366561674917, 'plsr_scale': 3.2437813067933394}, 'fold_4': {'plsr': 8.42788229450483, 'plsr_scale': 8.990898748942982}, 'MSE': {'plsr': 4.082677930769956, 'plsr_scale': 4.18979234956773}, 'R2': {'plsr': 0.9932068744785364, 'plsr_scale': 0.9930286479065681}}'\n",
      "plsr: {'fold_0': 2.8787078544208264, 'fold_1': 3.1588325505143624, 'fold_2': 2.7001931431256865, 'fold_3': 3.2488366561674917, 'fold_4': 8.42788229450483, 'MSE': 4.082677930769956, 'R2': 0.9932068744785364}'\n",
      "plsr_scale: {'fold_0': 2.8704374104417267, 'fold_1': 3.145478971456528, 'fold_2': 2.699545963709188, 'fold_3': 3.2437813067933394, 'fold_4': 8.990898748942982, 'MSE': 4.18979234956773, 'R2': 0.9930286479065681}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 90 components'\n",
      "Running PLSR with 90 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7153,plsr_scale:1.7477'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8792,plsr_scale:2.875'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7491,plsr_scale:1.7802'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1574,plsr_scale:3.1495'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.82,plsr_scale:1.8452'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.7015,plsr_scale:2.7056'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8107,plsr_scale:1.8355'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2497,plsr_scale:3.2511'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6187,plsr_scale:1.6479'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4193,plsr_scale:8.9459'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8521,plsr_scale:1.8768'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6402,plsr_scale:2.6448'\n",
      "Train times: {'fold_0': 13, 'fold_1': 13, 'fold_2': 13, 'fold_3': 13, 'fold_4': 13, 'mean': 13.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8792332349085616, 'plsr_scale': 2.8749939948474617}, 'fold_1': {'plsr': 3.1573668649303577, 'plsr_scale': 3.1495196627222044}, 'fold_2': {'plsr': 2.7015447622869075, 'plsr_scale': 2.7055676644736586}, 'fold_3': {'plsr': 3.2496757935452205, 'plsr_scale': 3.251132932187804}, 'fold_4': {'plsr': 8.41931862287006, 'plsr_scale': 8.945915311951808}, 'MSE': {'plsr': 4.081215484991923, 'plsr_scale': 4.18519156064281}, 'R2': {'plsr': 0.9932093078269187, 'plsr_scale': 0.9930363031116063}}'\n",
      "plsr: {'fold_0': 2.8792332349085616, 'fold_1': 3.1573668649303577, 'fold_2': 2.7015447622869075, 'fold_3': 3.2496757935452205, 'fold_4': 8.41931862287006, 'MSE': 4.081215484991923, 'R2': 0.9932093078269187}'\n",
      "plsr_scale: {'fold_0': 2.8749939948474617, 'fold_1': 3.1495196627222044, 'fold_2': 2.7055676644736586, 'fold_3': 3.251132932187804, 'fold_4': 8.945915311951808, 'MSE': 4.18519156064281, 'R2': 0.9930363031116063}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 91 components'\n",
      "Running PLSR with 91 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7152,plsr_scale:1.7469'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8812,plsr_scale:2.8689'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.749,plsr_scale:1.7793'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1572,plsr_scale:3.1532'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8198,plsr_scale:1.8444'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.7034,plsr_scale:2.7105'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8107,plsr_scale:1.8348'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2511,plsr_scale:3.2515'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6187,plsr_scale:1.6473'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.435,plsr_scale:8.9125'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.852,plsr_scale:1.8762'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6411,plsr_scale:2.6465'\n",
      "Train times: {'fold_0': 13, 'fold_1': 14, 'fold_2': 15, 'fold_3': 14, 'fold_4': 14, 'mean': 14.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.881156783678821, 'plsr_scale': 2.8688935853026902}, 'fold_1': {'plsr': 3.1571631829345304, 'plsr_scale': 3.153198994518804}, 'fold_2': {'plsr': 2.7034220846817454, 'plsr_scale': 2.7104512329937767}, 'fold_3': {'plsr': 3.251131505379779, 'plsr_scale': 3.251535831772661}, 'fold_4': {'plsr': 8.435030580015013, 'plsr_scale': 8.91248949547554}, 'MSE': {'plsr': 4.085367798803413, 'plsr_scale': 4.179080454553225}, 'R2': {'plsr': 0.9932023988349766, 'plsr_scale': 0.9930464713177312}}'\n",
      "plsr: {'fold_0': 2.881156783678821, 'fold_1': 3.1571631829345304, 'fold_2': 2.7034220846817454, 'fold_3': 3.251131505379779, 'fold_4': 8.435030580015013, 'MSE': 4.085367798803413, 'R2': 0.9932023988349766}'\n",
      "plsr_scale: {'fold_0': 2.8688935853026902, 'fold_1': 3.153198994518804, 'fold_2': 2.7104512329937767, 'fold_3': 3.251535831772661, 'fold_4': 8.91248949547554, 'MSE': 4.179080454553225, 'R2': 0.9930464713177312}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 92 components'\n",
      "Running PLSR with 92 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7152,plsr_scale:1.7462'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8813,plsr_scale:2.8677'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7488,plsr_scale:1.7785'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1582,plsr_scale:3.1564'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8198,plsr_scale:1.8437'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.7049,plsr_scale:2.7133'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8106,plsr_scale:1.8341'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2526,plsr_scale:3.2525'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6186,plsr_scale:1.6466'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4299,plsr_scale:8.8851'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.852,plsr_scale:1.8755'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6431,plsr_scale:2.6463'\n",
      "Train times: {'fold_0': 14, 'fold_1': 14, 'fold_2': 14, 'fold_3': 14, 'fold_4': 14, 'mean': 14.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.881257338875628, 'plsr_scale': 2.8677185125322127}, 'fold_1': {'plsr': 3.1581998989495315, 'plsr_scale': 3.156400143977779}, 'fold_2': {'plsr': 2.7048536298486074, 'plsr_scale': 2.7133270562182488}, 'fold_3': {'plsr': 3.2525848686718755, 'plsr_scale': 3.252517786648377}, 'fold_4': {'plsr': 8.42992639070063, 'plsr_scale': 8.885144379955804}, 'MSE': {'plsr': 4.085151553694013, 'plsr_scale': 4.17478926219337}, 'R2': {'plsr': 0.9932027586429744, 'plsr_scale': 0.9930536113882514}}'\n",
      "plsr: {'fold_0': 2.881257338875628, 'fold_1': 3.1581998989495315, 'fold_2': 2.7048536298486074, 'fold_3': 3.2525848686718755, 'fold_4': 8.42992639070063, 'MSE': 4.085151553694013, 'R2': 0.9932027586429744}'\n",
      "plsr_scale: {'fold_0': 2.8677185125322127, 'fold_1': 3.156400143977779, 'fold_2': 2.7133270562182488, 'fold_3': 3.252517786648377, 'fold_4': 8.885144379955804, 'MSE': 4.17478926219337, 'R2': 0.9930536113882514}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 93 components'\n",
      "Running PLSR with 93 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7151,plsr_scale:1.7455'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8818,plsr_scale:2.868'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7488,plsr_scale:1.7777'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1583,plsr_scale:3.157'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8197,plsr_scale:1.843'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.7045,plsr_scale:2.7131'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8105,plsr_scale:1.8335'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2525,plsr_scale:3.2536'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6185,plsr_scale:1.6459'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4185,plsr_scale:8.856'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8519,plsr_scale:1.8749'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6426,plsr_scale:2.6491'\n",
      "Train times: {'fold_0': 14, 'fold_1': 14, 'fold_2': 14, 'fold_3': 14, 'fold_4': 14, 'mean': 14.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8817572059839134, 'plsr_scale': 2.86797161015494}, 'fold_1': {'plsr': 3.158269738106432, 'plsr_scale': 3.1569598068886733}, 'fold_2': {'plsr': 2.704504464875712, 'plsr_scale': 2.7130964214171067}, 'fold_3': {'plsr': 3.2524830254196186, 'plsr_scale': 3.253617381657405}, 'fold_4': {'plsr': 8.41852314459746, 'plsr_scale': 8.856026761881287}, 'MSE': {'plsr': 4.082895151824644, 'plsr_scale': 4.169303260025955}, 'R2': {'plsr': 0.9932065130466735, 'plsr_scale': 0.9930627394904349}}'\n",
      "plsr: {'fold_0': 2.8817572059839134, 'fold_1': 3.158269738106432, 'fold_2': 2.704504464875712, 'fold_3': 3.2524830254196186, 'fold_4': 8.41852314459746, 'MSE': 4.082895151824644, 'R2': 0.9932065130466735}'\n",
      "plsr_scale: {'fold_0': 2.86797161015494, 'fold_1': 3.1569598068886733, 'fold_2': 2.7130964214171067, 'fold_3': 3.253617381657405, 'fold_4': 8.856026761881287, 'MSE': 4.169303260025955, 'R2': 0.9930627394904349}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 94 components'\n",
      "Running PLSR with 94 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.715,plsr_scale:1.7448'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8835,plsr_scale:2.8718'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7487,plsr_scale:1.7769'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1583,plsr_scale:3.1565'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8196,plsr_scale:1.8424'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.7061,plsr_scale:2.7179'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8105,plsr_scale:1.8329'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2527,plsr_scale:3.2534'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6185,plsr_scale:1.6453'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4214,plsr_scale:8.8556'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8519,plsr_scale:1.8743'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6431,plsr_scale:2.6506'\n",
      "Train times: {'fold_0': 14, 'fold_1': 14, 'fold_2': 14, 'fold_3': 14, 'fold_4': 14, 'mean': 14.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8834895814469967, 'plsr_scale': 2.871818194055022}, 'fold_1': {'plsr': 3.158297625866185, 'plsr_scale': 3.1564811792863448}, 'fold_2': {'plsr': 2.7060886817668925, 'plsr_scale': 2.7179148997498817}, 'fold_3': {'plsr': 3.252703432342187, 'plsr_scale': 3.25337823064912}, 'fold_4': {'plsr': 8.421384806924877, 'plsr_scale': 8.855632302752815}, 'MSE': {'plsr': 4.084180380758917, 'plsr_scale': 4.170813859565791}, 'R2': {'plsr': 0.9932043745675618, 'plsr_scale': 0.993060226019507}}'\n",
      "plsr: {'fold_0': 2.8834895814469967, 'fold_1': 3.158297625866185, 'fold_2': 2.7060886817668925, 'fold_3': 3.252703432342187, 'fold_4': 8.421384806924877, 'MSE': 4.084180380758917, 'R2': 0.9932043745675618}'\n",
      "plsr_scale: {'fold_0': 2.871818194055022, 'fold_1': 3.1564811792863448, 'fold_2': 2.7179148997498817, 'fold_3': 3.25337823064912, 'fold_4': 8.855632302752815, 'MSE': 4.170813859565791, 'R2': 0.993060226019507}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 95 components'\n",
      "Running PLSR with 95 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.715,plsr_scale:1.7441'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8835,plsr_scale:2.8675'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7486,plsr_scale:1.7762'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1588,plsr_scale:3.1585'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8196,plsr_scale:1.8418'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.707,plsr_scale:2.7188'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8104,plsr_scale:1.8324'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2532,plsr_scale:3.2557'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6184,plsr_scale:1.6447'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4285,plsr_scale:8.8802'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8518,plsr_scale:1.8738'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6434,plsr_scale:2.6536'\n",
      "Train times: {'fold_0': 14, 'fold_1': 14, 'fold_2': 14, 'fold_3': 14, 'fold_4': 14, 'mean': 14.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.883529881510803, 'plsr_scale': 2.8674868830651605}, 'fold_1': {'plsr': 3.15881843642326, 'plsr_scale': 3.158515382515701}, 'fold_2': {'plsr': 2.706968286988872, 'plsr_scale': 2.718810889058288}, 'fold_3': {'plsr': 3.253210095237933, 'plsr_scale': 3.2556967901044405}, 'fold_4': {'plsr': 8.428463003451377, 'plsr_scale': 8.880181047663145}, 'MSE': {'plsr': 4.085985191265446, 'plsr_scale': 4.175905849886522}, 'R2': {'plsr': 0.9932013715620539, 'plsr_scale': 0.9930517535095541}}'\n",
      "plsr: {'fold_0': 2.883529881510803, 'fold_1': 3.15881843642326, 'fold_2': 2.706968286988872, 'fold_3': 3.253210095237933, 'fold_4': 8.428463003451377, 'MSE': 4.085985191265446, 'R2': 0.9932013715620539}'\n",
      "plsr_scale: {'fold_0': 2.8674868830651605, 'fold_1': 3.158515382515701, 'fold_2': 2.718810889058288, 'fold_3': 3.2556967901044405, 'fold_4': 8.880181047663145, 'MSE': 4.175905849886522, 'R2': 0.9930517535095541}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 96 components'\n",
      "Running PLSR with 96 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7149,plsr_scale:1.7434'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8845,plsr_scale:2.8677'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7485,plsr_scale:1.7755'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1589,plsr_scale:3.1575'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8195,plsr_scale:1.8412'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.7082,plsr_scale:2.7162'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8104,plsr_scale:1.8318'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2544,plsr_scale:3.256'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6184,plsr_scale:1.6441'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4192,plsr_scale:8.8976'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8518,plsr_scale:1.8732'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6448,plsr_scale:2.6542'\n",
      "Train times: {'fold_0': 14, 'fold_1': 14, 'fold_2': 14, 'fold_3': 14, 'fold_4': 14, 'mean': 14.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.88447998522204, 'plsr_scale': 2.8677156970702598}, 'fold_1': {'plsr': 3.158909483159548, 'plsr_scale': 3.15753645895723}, 'fold_2': {'plsr': 2.708159914146863, 'plsr_scale': 2.7161713863607244}, 'fold_3': {'plsr': 3.2543822007849137, 'plsr_scale': 3.255984241783957}, 'fold_4': {'plsr': 8.419203133032635, 'plsr_scale': 8.897561894780816}, 'MSE': {'plsr': 4.084814531721243, 'plsr_scale': 4.1787609418118175}, 'R2': {'plsr': 0.993203319410344, 'plsr_scale': 0.9930470029516721}}'\n",
      "plsr: {'fold_0': 2.88447998522204, 'fold_1': 3.158909483159548, 'fold_2': 2.708159914146863, 'fold_3': 3.2543822007849137, 'fold_4': 8.419203133032635, 'MSE': 4.084814531721243, 'R2': 0.993203319410344}'\n",
      "plsr_scale: {'fold_0': 2.8677156970702598, 'fold_1': 3.15753645895723, 'fold_2': 2.7161713863607244, 'fold_3': 3.255984241783957, 'fold_4': 8.897561894780816, 'MSE': 4.1787609418118175, 'R2': 0.9930470029516721}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 97 components'\n",
      "Running PLSR with 97 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7149,plsr_scale:1.7428'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8851,plsr_scale:2.8675'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7485,plsr_scale:1.7749'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.16,plsr_scale:3.1589'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8195,plsr_scale:1.8407'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.7085,plsr_scale:2.7174'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8103,plsr_scale:1.8313'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2558,plsr_scale:3.2565'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6184,plsr_scale:1.6435'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4009,plsr_scale:8.9103'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8518,plsr_scale:1.8727'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6452,plsr_scale:2.6519'\n",
      "Train times: {'fold_0': 14, 'fold_1': 14, 'fold_2': 14, 'fold_3': 14, 'fold_4': 14, 'mean': 14.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8850933499546643, 'plsr_scale': 2.8674552717176853}, 'fold_1': {'plsr': 3.15997559242486, 'plsr_scale': 3.158946102406334}, 'fold_2': {'plsr': 2.708521140598575, 'plsr_scale': 2.717416539999033}, 'fold_3': {'plsr': 3.2558402223729095, 'plsr_scale': 3.2565055948107107}, 'fold_4': {'plsr': 8.400892507267105, 'plsr_scale': 8.910344061943011}, 'MSE': {'plsr': 4.081852910487799, 'plsr_scale': 4.181900007817561}, 'R2': {'plsr': 0.9932082472212386, 'plsr_scale': 0.993041779892259}}'\n",
      "plsr: {'fold_0': 2.8850933499546643, 'fold_1': 3.15997559242486, 'fold_2': 2.708521140598575, 'fold_3': 3.2558402223729095, 'fold_4': 8.400892507267105, 'MSE': 4.081852910487799, 'R2': 0.9932082472212386}'\n",
      "plsr_scale: {'fold_0': 2.8674552717176853, 'fold_1': 3.158946102406334, 'fold_2': 2.717416539999033, 'fold_3': 3.2565055948107107, 'fold_4': 8.910344061943011, 'MSE': 4.181900007817561, 'R2': 0.993041779892259}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 98 components'\n",
      "Running PLSR with 98 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7149,plsr_scale:1.7422'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8849,plsr_scale:2.8633'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7484,plsr_scale:1.7742'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1602,plsr_scale:3.1592'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8194,plsr_scale:1.8403'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.7091,plsr_scale:2.7209'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8103,plsr_scale:1.8309'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2567,plsr_scale:3.2564'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6183,plsr_scale:1.643'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.3987,plsr_scale:8.9085'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8518,plsr_scale:1.8722'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6463,plsr_scale:2.6462'\n",
      "Train times: {'fold_0': 15, 'fold_1': 15, 'fold_2': 15, 'fold_3': 15, 'fold_4': 14, 'mean': 14.8}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8848699396234956, 'plsr_scale': 2.863307972985576}, 'fold_1': {'plsr': 3.1601783477727046, 'plsr_scale': 3.159230156614455}, 'fold_2': {'plsr': 2.709051020239817, 'plsr_scale': 2.7208577639430294}, 'fold_3': {'plsr': 3.256655260850896, 'plsr_scale': 3.256445013177604}, 'fold_4': {'plsr': 8.398690294249283, 'plsr_scale': 8.908454558447069}, 'MSE': {'plsr': 4.081677353524297, 'plsr_scale': 4.181425295584839}, 'R2': {'plsr': 0.9932085393286517, 'plsr_scale': 0.993042569761026}}'\n",
      "plsr: {'fold_0': 2.8848699396234956, 'fold_1': 3.1601783477727046, 'fold_2': 2.709051020239817, 'fold_3': 3.256655260850896, 'fold_4': 8.398690294249283, 'MSE': 4.081677353524297, 'R2': 0.9932085393286517}'\n",
      "plsr_scale: {'fold_0': 2.863307972985576, 'fold_1': 3.159230156614455, 'fold_2': 2.7208577639430294, 'fold_3': 3.256445013177604, 'fold_4': 8.908454558447069, 'MSE': 4.181425295584839, 'R2': 0.993042569761026}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 99 components'\n",
      "Running PLSR with 99 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7148,plsr_scale:1.7416'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.885,plsr_scale:2.8632'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7484,plsr_scale:1.7736'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1604,plsr_scale:3.16'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8194,plsr_scale:1.8398'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.7105,plsr_scale:2.7218'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8103,plsr_scale:1.8304'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2572,plsr_scale:3.259'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6183,plsr_scale:1.6425'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.4007,plsr_scale:8.893'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8518,plsr_scale:1.8717'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6461,plsr_scale:2.6502'\n",
      "Train times: {'fold_0': 15, 'fold_1': 15, 'fold_2': 15, 'fold_3': 15, 'fold_4': 15, 'mean': 15.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 1, 'mean': 0.2}'\n",
      "Scores: {'fold_0': {'plsr': 2.8849500707348814, 'plsr_scale': 2.863221440971352}, 'fold_1': {'plsr': 3.1604078117377896, 'plsr_scale': 3.15998031717146}, 'fold_2': {'plsr': 2.7105261916902696, 'plsr_scale': 2.721821583973077}, 'fold_3': {'plsr': 3.257230145679823, 'plsr_scale': 3.2589820278391093}, 'fold_4': {'plsr': 8.40072880467671, 'plsr_scale': 8.893034795701972}, 'MSE': {'plsr': 4.082556841087741, 'plsr_scale': 4.179174751638374}, 'R2': {'plsr': 0.9932070759584044, 'plsr_scale': 0.9930463144177878}}'\n",
      "plsr: {'fold_0': 2.8849500707348814, 'fold_1': 3.1604078117377896, 'fold_2': 2.7105261916902696, 'fold_3': 3.257230145679823, 'fold_4': 8.40072880467671, 'MSE': 4.082556841087741, 'R2': 0.9932070759584044}'\n",
      "plsr_scale: {'fold_0': 2.863221440971352, 'fold_1': 3.15998031717146, 'fold_2': 2.721821583973077, 'fold_3': 3.2589820278391093, 'fold_4': 8.893034795701972, 'MSE': 4.179174751638374, 'R2': 0.9930463144177878}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 100 components'\n",
      "Running PLSR with 100 components'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7148,plsr_scale:1.741'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.8849,plsr_scale:2.863'\n",
      "-----------------------------------Fold 1 - Train 6006 - Val 2003 - Test 2003-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.7484,plsr_scale:1.7731'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:3.1607,plsr_scale:3.1598'\n",
      "-----------------------------------Fold 2 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8194,plsr_scale:1.8393'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:2.7109,plsr_scale:2.7196'\n",
      "-----------------------------------Fold 3 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.8102,plsr_scale:1.8299'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:3.2563,plsr_scale:3.2639'\n",
      "-----------------------------------Fold 4 - Train 6008 - Val 2002 - Test 2002-----------------------------------'\n",
      "Finished training SKLearn with a train loss of plsr:1.6183,plsr_scale:1.642'\n",
      "Tested (test) on 2002 instances with mean losses of: plsr:8.3939,plsr_scale:8.8711'\n",
      "Building final model - Train 8009 - Test 2003'\n",
      "Finished training SKLearn with a train loss of plsr:1.8517,plsr_scale:1.8713'\n",
      "Tested (test) on 2003 instances with mean losses of: plsr:2.6467,plsr_scale:2.6482'\n",
      "Train times: {'fold_0': 15, 'fold_1': 15, 'fold_2': 15, 'fold_3': 15, 'fold_4': 15, 'mean': 15.0}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n",
      "Scores: {'fold_0': {'plsr': 2.8848979473458556, 'plsr_scale': 2.8629816592347375}, 'fold_1': {'plsr': 3.160699282905075, 'plsr_scale': 3.159791924597924}, 'fold_2': {'plsr': 2.710935621162308, 'plsr_scale': 2.7195956351755908}, 'fold_3': {'plsr': 3.2563106032912357, 'plsr_scale': 3.263882365672394}, 'fold_4': {'plsr': 8.393885324183747, 'plsr_scale': 8.871087004112201}, 'MSE': {'plsr': 4.0811343000963305, 'plsr_scale': 4.17523518061797}, 'R2': {'plsr': 0.9932094429096257, 'plsr_scale': 0.9930528694292035}}'\n",
      "plsr: {'fold_0': 2.8848979473458556, 'fold_1': 3.160699282905075, 'fold_2': 2.710935621162308, 'fold_3': 3.2563106032912357, 'fold_4': 8.393885324183747, 'MSE': 4.0811343000963305, 'R2': 0.9932094429096257}'\n",
      "plsr_scale: {'fold_0': 2.8629816592347375, 'fold_1': 3.159791924597924, 'fold_2': 2.7195956351755908, 'fold_3': 3.263882365672394, 'fold_4': 8.871087004112201, 'MSE': 4.17523518061797, 'R2': 0.9930528694292035}'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "scores_df_pls = None #datframe for scores\n",
    "scores_df_pls_final = None #datframe for scores\n",
    "\n",
    "\n",
    "for n_component in n_comps:\n",
    "    save_loc = log_dir/f\"PLS_{n_component}\"\n",
    "    if not save_loc.exists():\n",
    "        save_loc.mkdir()\n",
    "    local_log_name = f\"pls_{n_component}\"\n",
    "    ut.setup_logger(logger_name=local_log_name,file_name=save_loc/f\"{local_log_name}_log.txt\")\n",
    "    local_logger = logging.getLogger(local_log_name)\n",
    "    local_logger.info(f\"Running {n_component} components\")\n",
    "\n",
    "    pls_models = {\n",
    "        'plsr':PLSRegression(n_components=n_component,scale=False),\n",
    "        'plsr_scale':PLSRegression(n_components=n_component,scale=True)\n",
    "    }\n",
    "\n",
    "    #run pls\n",
    "    scheme = ev.SKLearnScheme(logger=local_logger_name)\n",
    "    \n",
    "    \n",
    "    local_logger.info(f\"Running PLSR with {n_component} components\")\n",
    "    scores_pls, preds_pls, model_states_pls ,train_time_pls, test_time_pls,_ = eval.evaluate(pls_models,dataset,scheme,logger_name=local_logger_name)\n",
    "    scores_pls_final, _, model_states_pls_final , _, _,_= eval.build(pls_models,dataset,scheme,logger_name=local_logger_name)\n",
    "    \n",
    "    for fold,nested in model_states_pls.items():\n",
    "        for name,model in nested.items():\n",
    "            CustomWrapper(None).save_state(model,save_loc/(f\"{name}_{fold}\"))\n",
    "    for name,model in model_states_pls_final.items():\n",
    "        model.save_state(model.state(),save_loc/(f\"{name}_final\"))\n",
    "    \n",
    "    #log results\n",
    "    local_logger.info(f\"Train times: {train_time_pls}\")\n",
    "    local_logger.info(f\"Test times: {test_time_pls}\")\n",
    "    local_logger.info(f\"Scores: {scores_pls}\")\n",
    "    for key,value in ut.flip_dicts(scores_pls).items():\n",
    "        local_logger.info(f\"{key}: {value}\")\n",
    "\n",
    "    #write preds\n",
    "    preds_pls.to_csv(save_loc/ (f\"predictions_n_comp={n_component}\" + \".csv\"), index=False)\n",
    "    #plot our figures\n",
    "    plot_preds_and_res(preds_pls,name_lambda=lambda x:f\"PLS with {x} components\",save_lambda= lambda x:f\"pls_{x}\",save_loc=save_loc)\n",
    "\n",
    "    flipped = ut.flip_dicts(scores_pls)\n",
    "    for name,record in flipped.items():\n",
    "        record1 = {'model':f\"{name}\",'n_comp':n_component}\n",
    "        if scores_df_pls is None:\n",
    "            scores_df_pls =pd.DataFrame([{**record1,**record}])\n",
    "        else:\n",
    "            scores_df_pls=scores_df_pls.append([{**record1,**record}],ignore_index=True)\n",
    "            \n",
    "    flipped = ut.flip_dicts(scores_pls_final)\n",
    "    for name,record in flipped.items():\n",
    "        record1 = {'model':f\"{name}\",'n_comp':n_component}\n",
    "        if scores_df_pls_final is None:\n",
    "            scores_df_pls_final =pd.DataFrame([{**record1,**record}])\n",
    "        else:\n",
    "            scores_df_pls_final=scores_df_pls_final.append([{**record1,**record}],ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Concat scores and write summary\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Rankings\n",
      "-------------------------------'\n",
      "Rank - model - n_comp - fold_0 - fold_1 - fold_2 - fold_3 - fold_4 - MSE - R2'\n",
      "0 - pcr - 38 - 3.4970960881615922 - 3.4156646089976594 - 3.0377392839885293 - 3.56941532729817 - 3.781400711084807 - 3.4602624282658545 - 0.9942425051863003'\n",
      "1 - pcr_whiten - 38 - 3.49858360307533 - 3.415854619002844 - 3.03682235516337 - 3.5689990436746872 - 3.7920773752840056 - 3.4624663508404874 - 0.9942388381023561'\n",
      "2 - pcr - 37 - 3.488789535760328 - 3.501748824732714 - 3.1051236099075075 - 3.673449492179619 - 3.7272687103923454 - 3.4992752341841253 - 0.9941775921826196'\n",
      "3 - pcr_whiten - 37 - 3.4944966788855854 - 3.502325816224239 - 3.1050057037551855 - 3.674067653795543 - 3.727641899741557 - 3.5007070917702885 - 0.9941752097296128'\n",
      "4 - pcr_whiten - 36 - 3.544197983266485 - 3.5251610087452936 - 3.1069025746698613 - 3.7116276814182294 - 3.7489183585934582 - 3.5273629831793905 - 0.9941308572679936'\n",
      "5 - pcr - 36 - 3.5469563497023033 - 3.5247056147377664 - 3.1069002804627055 - 3.7117743302358304 - 3.7491311745974434 - 3.5278951355309633 - 0.9941299718252077'\n",
      "6 - pcr_whiten - 35 - 3.570262630302021 - 3.550409744506352 - 3.1946172680209672 - 3.751189788926855 - 3.7497760649425196 - 3.5632505170560957 - 0.9940711443720918'\n",
      "7 - pcr - 35 - 3.570583451313759 - 3.5506416049618483 - 3.1945270557368226 - 3.751213626217954 - 3.750081933550629 - 3.563408975625435 - 0.9940708807145195'\n",
      "8 - pcr - 34 - 3.5746612004875398 - 3.5537964535573523 - 3.18930162099085 - 3.7529370303335843 - 3.8109865300223755 - 3.5763341484327036 - 0.9940493746533619'\n",
      "9 - pcr_whiten - 34 - 3.5745539554494776 - 3.554493152401633 - 3.189411579231179 - 3.7526376672252053 - 3.810774845851406 - 3.576371872735315 - 0.9940493118842855'\n",
      "10 - pcr_whiten - 33 - 3.5770212995960393 - 3.6500122197411757 - 3.22982574278377 - 3.7653867851088103 - 3.810754561524343 - 3.6066015034204075 - 0.9939990131149009'\n",
      "11 - pcr - 33 - 3.5771277904092087 - 3.6499066110285017 - 3.229956367275253 - 3.7653009029559574 - 3.8110572443177975 - 3.606671151039437 - 0.993998897228949'\n",
      "12 - pcr_whiten - 31 - 3.585891713517162 - 3.6539218890159586 - 3.236698077532007 - 3.7690958367742033 - 3.808159195957647 - 3.61075517105694 - 0.9939921018703433'\n",
      "13 - pcr - 31 - 3.5859705779515556 - 3.654038069605388 - 3.237169852039428 - 3.769076424381019 - 3.8086708206387425 - 3.6109869505961907 - 0.9939917162147687'\n",
      "14 - pcr - 32 - 3.586139238484226 - 3.6494335980926906 - 3.2373877503558144 - 3.7690511932939375 - 3.8132903056533385 - 3.611061760763918 - 0.9939915917389055'\n",
      "15 - pcr_whiten - 32 - 3.5854531222504646 - 3.649329479491671 - 3.237091601673036 - 3.769035216594211 - 3.81474569364168 - 3.6111322732851745 - 0.9939914744138517'\n",
      "16 - pcr - 30 - 3.6656134496328994 - 3.6566473058008264 - 3.3035381749589883 - 3.8002884547783324 - 3.8271153141582013 - 3.6506426353188757 - 0.9939257335317041'\n",
      "17 - pcr_whiten - 30 - 3.6657329975314874 - 3.656911314595389 - 3.303587974441177 - 3.8003857023199847 - 3.8278125035003367 - 3.6508881831875404 - 0.9939253249671488'\n",
      "18 - plsr - 14 - 3.496765365206318 - 3.578866439079729 - 3.1845191875148995 - 3.7255789427006096 - 4.3482861999708025 - 3.6667774603493752 - 0.9938988869634571'\n",
      "19 - pcr_whiten - 29 - 3.6631261933346 - 3.7263226241344225 - 3.3217253467008616 - 3.819768531025644 - 3.8267860811472914 - 3.6715503854430476 - 0.9938909453428307'\n",
      "20 - pcr - 29 - 3.662973398437672 - 3.726249955488119 - 3.321802380167558 - 3.819610721567249 - 3.828545248260347 - 3.6718408903918958 - 0.9938904619746552'\n",
      "21 - pcr - 28 - 3.6760005156437514 - 3.736454215684881 - 3.3179204167988456 - 3.8260673591045053 - 3.9020772383866116 - 3.6917068503255845 - 0.9938574072096892'\n",
      "22 - pcr_whiten - 28 - 3.6762615325916537 - 3.7365747221083616 - 3.317851648688199 - 3.8261208742238217 - 3.902150522568682 - 3.6917947817835093 - 0.9938572609014471'\n",
      "23 - pcr_whiten - 27 - 3.6794184931651612 - 3.7413876946589233 - 3.3180975106339123 - 3.8390286092060126 - 3.8826827394572985 - 3.6921266610591967 - 0.9938567086909579'\n",
      "24 - pcr - 27 - 3.679624733884881 - 3.741385126078089 - 3.3182304236584548 - 3.839024484598185 - 3.8828267745035814 - 3.692221961485397 - 0.9938565501215658'\n",
      "25 - pcr - 26 - 3.687770669505507 - 3.762488818392643 - 3.376983795227312 - 3.836195331309741 - 3.899550953668653 - 3.7126004169828026 - 0.9938226426205395'\n",
      "26 - pcr_whiten - 26 - 3.6880768160128894 - 3.7623521611640798 - 3.3771461820601165 - 3.8362166413007235 - 3.8995387731862525 - 3.7126686214115807 - 0.993822529135897'\n",
      "27 - pcr_whiten - 25 - 3.7116575298953727 - 3.7657824975685394 - 3.380699576698736 - 3.834542946184167 - 3.8972917423053577 - 3.7179989985933988 - 0.993813659976515'\n",
      "28 - pcr - 25 - 3.7116370057412813 - 3.7656729554020774 - 3.380898308397261 - 3.834523687264165 - 3.897407868168723 - 3.718032085453267 - 0.9938136049236317'\n",
      "29 - pcr - 24 - 3.7083558830415164 - 3.7715090877360153 - 3.3799964572251664 - 3.8361478998773473 - 3.9055948708821515 - 3.7203247573804132 - 0.9938097901705591'\n",
      "30 - pcr_whiten - 24 - 3.708305333983882 - 3.771514653215261 - 3.380434479573136 - 3.836145477914551 - 3.9055322885503267 - 3.7203903466767865 - 0.9938096810372082'\n",
      "31 - plsr - 13 - 3.5784015985245086 - 3.8279228997302486 - 3.416091089506658 - 3.7894743894662613 - 4.083173525130365 - 3.7390055389751353 - 0.9937787074115554'\n",
      "32 - plsr - 15 - 3.166707917480144 - 3.385401185905249 - 2.942191595664603 - 3.674126417730456 - 5.6153417891657496 - 3.756657756572882 - 0.9937493360695325'\n",
      "33 - pcr_whiten - 23 - 3.708340353166657 - 3.9344999241182177 - 3.4947874038330506 - 3.8351341254371074 - 3.9173266304824437 - 3.7780263574936384 - 0.9937137810757921'\n",
      "34 - pcr - 23 - 3.7083662541224207 - 3.934495617176783 - 3.494959487738772 - 3.8353203454043787 - 3.91733194782623 - 3.778103387306533 - 0.9937136529066842'\n",
      "35 - plsr - 12 - 3.7084533969863522 - 3.8698880280910943 - 3.509357817845344 - 3.989623923886764 - 3.951280414478863 - 3.8057174102241804 - 0.993667706219972'\n",
      "36 - pcr - 22 - 3.828825923789613 - 3.9345792826558843 - 3.5777627489895645 - 3.9547644608410573 - 3.967418538120763 - 3.8526759904024175 - 0.9935895723248008'\n",
      "37 - pcr_whiten - 22 - 3.828820845520548 - 3.934651225986465 - 3.5777708868723948 - 3.9548287738505516 - 3.9674296231166406 - 3.8527060712620256 - 0.9935895222735701'\n",
      "38 - plsr_scale - 52 - 2.851987012066858 - 3.159620771991296 - 2.7504959416261547 - 3.25802489973894 - 7.247033740318592 - 3.8532631506191795 - 0.9935885953549979'\n",
      "39 - plsr_scale - 45 - 2.90643466414855 - 3.2185902558266717 - 2.8024017584721994 - 3.272178214748197 - 7.0989455067195335 - 3.8595508315571427 - 0.9935781333478116'\n",
      "40 - plsr_scale - 37 - 2.9902650272204534 - 3.2822548920565806 - 2.8450084209778983 - 3.3993076689960264 - 6.784357578956614 - 3.86009409543656 - 0.9935772294166697'\n",
      "41 - plsr_scale - 44 - 2.9127252251042925 - 3.226080956503221 - 2.8044793863022446 - 3.284890533891846 - 7.08267091653972 - 3.8620110404415637 - 0.9935740398317312'\n",
      "42 - pcr - 21 - 3.8323342356015795 - 3.9514312190928127 - 3.5908165577125333 - 3.9833411223335293 - 3.9905264920070325 - 3.8696943585900083 - 0.9935612556382463'\n",
      "43 - pcr_whiten - 21 - 3.8323458896993823 - 3.9514394244064492 - 3.590834064715739 - 3.983333917742739 - 3.990521415684795 - 3.8696993766716754 - 0.9935612472887122'\n",
      "44 - plsr_scale - 53 - 2.8513142412301162 - 3.162788115820406 - 2.739695777940976 - 3.262908034134454 - 7.340531859818172 - 3.8712749337098664 - 0.9935586257356757'\n",
      "45 - plsr_scale - 51 - 2.858401877507126 - 3.173312141080237 - 2.759662536584723 - 3.2651717216475538 - 7.301229159659004 - 3.8713845527216177 - 0.9935584433417374'\n",
      "46 - plsr_scale - 46 - 2.892347489399446 - 3.2130554286265394 - 2.788839290885738 - 3.2756242929443924 - 7.190942336413059 - 3.871998072026859 - 0.9935574225133201'\n",
      "47 - plsr_scale - 39 - 2.9708093536067124 - 3.2488838530172046 - 2.8160811072810072 - 3.3541369596440744 - 6.981615764349888 - 3.8741526990691364 - 0.9935538374517017'\n",
      "48 - plsr_scale - 42 - 2.9418274613928506 - 3.2285161573105308 - 2.816565379583131 - 3.3207180885447753 - 7.064502210140384 - 3.8742681977782647 - 0.9935536452745959'\n",
      "49 - plsr_scale - 50 - 2.851803802135314 - 3.17711846825215 - 2.7755727052850103 - 3.257748527766525 - 7.314532471421716 - 3.875183222527122 - 0.9935521227743939'\n",
      "50 - plsr_scale - 49 - 2.855995282978433 - 3.189805698540803 - 2.794732720295832 - 3.2566020745995896 - 7.282811202013921 - 3.8758189824006726 - 0.9935510649401254'\n",
      "51 - plsr_scale - 43 - 2.931232872908523 - 3.2324140280608593 - 2.8082390695214583 - 3.30138166004445 - 7.107745169579097 - 3.8760438746234493 - 0.9935506907442853'\n",
      "52 - plsr_scale - 40 - 2.9725560865161786 - 3.2401484194080425 - 2.82386082890367 - 3.343669775556334 - 7.013222756514045 - 3.8785372906548403 - 0.9935465419751769'\n",
      "53 - plsr_scale - 47 - 2.8886895698576005 - 3.203694685903653 - 2.784311683292986 - 3.2726693672939686 - 7.261640581550048 - 3.882034176171402 - 0.9935407235435859'\n",
      "54 - plsr_scale - 48 - 2.871672382480752 - 3.193272082770921 - 2.7869528829984573 - 3.2677647440708872 - 7.305203258211207 - 3.8848027742939237 - 0.9935361169018464'\n",
      "55 - plsr_scale - 54 - 2.850178424035136 - 3.155471041927269 - 2.730202823162093 - 3.2593313841696645 - 7.441972009626719 - 3.887254427354531 - 0.9935320376217126'\n",
      "56 - pcr_whiten - 20 - 3.8419537400985604 - 3.9918523076418704 - 3.6134213786514358 - 4.026103793993279 - 3.995355666776608 - 3.8937420050085465 - 0.9935212430084511'\n",
      "57 - pcr - 20 - 3.841953858281984 - 3.9918532116833965 - 3.613421447994475 - 4.0261039137389165 - 3.995355612353662 - 3.893742236442563 - 0.9935212426233704'\n",
      "58 - plsr_scale - 35 - 2.9888733297780266 - 3.2935675581989408 - 2.8126795949604015 - 3.429710182363282 - 6.952349355618659 - 3.8952853418666034 - 0.9935186750662386'\n",
      "59 - pcr - 19 - 3.8415071629908737 - 3.9990372469855955 - 3.612867586977726 - 4.035355966912731 - 3.994942033167549 - 3.896746699807531 - 0.993516243527897'\n",
      "60 - pcr_whiten - 19 - 3.84150718357863 - 3.9990373464553555 - 3.6128676656669225 - 4.035355942375712 - 3.994942060177944 - 3.8967467400555007 - 0.9935162434609289'\n",
      "61 - plsr_scale - 36 - 2.986842398662051 - 3.293828707211721 - 2.820967704803646 - 3.4319739934470266 - 6.95108209874948 - 3.89678784125644 - 0.9935161750730663'\n",
      "62 - pcr - 18 - 3.8417729186538225 - 3.9936614841560485 - 3.611601635809121 - 4.044454921878971 - 4.02007360385149 - 3.902315990035 - 0.9935069768435731'\n",
      "63 - pcr_whiten - 18 - 3.841772942068719 - 3.9936615042340016 - 3.6116015035989184 - 4.044455056561007 - 4.020073707645861 - 3.902316019985171 - 0.9935069767937393'\n",
      "64 - plsr_scale - 41 - 2.9661935526917422 - 3.2256385130200522 - 2.824070499744064 - 3.349292348994343 - 7.164146873595909 - 3.9057065612998425 - 0.9935013353071644'\n",
      "65 - plsr_scale - 38 - 2.9772477191130635 - 3.2603364305964506 - 2.8096693095306327 - 3.3929517486795273 - 7.090127313912072 - 3.905909238199847 - 0.9935009980751698'\n",
      "66 - pcr - 17 - 3.853819830121315 - 4.001693504274492 - 3.624809503985633 - 4.049743986922327 - 4.004288313138742 - 3.9068751998098583 - 0.9934993908216522'\n",
      "67 - pcr_whiten - 17 - 3.8538198201156004 - 4.00169352150415 - 3.624809525465296 - 4.049744273562227 - 4.004288271685889 - 3.906875254577767 - 0.9934993907305244'\n",
      "68 - plsr_scale - 34 - 2.970745195988395 - 3.3110801332076347 - 2.8167289364425554 - 3.431750375860784 - 7.086421728542899 - 3.9231889750453277 - 0.9934722465000126'\n",
      "69 - plsr_scale - 55 - 2.8525119975095334 - 3.149614771589277 - 2.7253999480179174 - 3.2664316213444358 - 7.6429490803926905 - 3.9271964422008105 - 0.9934655785169211'\n",
      "70 - pcr - 16 - 3.859665442712867 - 4.004131139650648 - 3.6172425515562407 - 4.113455641260559 - 4.0483873292638926 - 3.928577084466607 - 0.9934632812805555'\n",
      "71 - pcr_whiten - 16 - 3.859665449762231 - 4.004131119839211 - 3.6172425965344996 - 4.11345562362237 - 4.048387331513595 - 3.9285770878301993 - 0.9934632812749589'\n",
      "72 - plsr - 43 - 2.631859075382609 - 3.0655449659166467 - 2.58004444962225 - 3.1712230441687903 - 8.282727106940872 - 3.9460604759676086 - 0.9934341908465264'\n",
      "73 - plsr - 55 - 2.75991705626298 - 3.1085980684391608 - 2.659366738275536 - 3.218520311941759 - 7.998417249239891 - 3.9487611868050014 - 0.9934296971617375'\n",
      "74 - plsr - 42 - 2.6374074539095003 - 3.061885997930256 - 2.5666025557779166 - 3.1526800168752405 - 8.343837722553387 - 3.9522624465679717 - 0.9934238714518832'\n",
      "75 - plsr - 11 - 3.8370239108091164 - 4.044279222471675 - 3.672681700932697 - 4.19304035340397 - 4.04185882979958 - 3.9577733825411694 - 0.9934147018625985'\n",
      "76 - plsr_scale - 56 - 2.8514244570662544 - 3.1490112001454 - 2.7269786695278224 - 3.2703943790896903 - 7.875434003051972 - 3.974453889216665 - 0.9933869473403144'\n",
      "77 - plsr - 41 - 2.6115427381953107 - 3.0306244235581072 - 2.5671342431175015 - 3.1466105763037726 - 8.523404270666283 - 3.9756325712492395 - 0.993384986143489'\n",
      "78 - pcr_whiten - 15 - 3.8680123800150747 - 3.998502661251679 - 3.6514151797073082 - 4.247177656323814 - 4.146391577423763 - 3.982290094226327 - 0.9933739087599647'\n",
      "79 - pcr - 15 - 3.8680123819774193 - 3.998502668756031 - 3.651415220867968 - 4.247177678671207 - 4.1463915720554665 - 3.9822901077458623 - 0.9933739087374697'\n",
      "80 - plsr_scale - 33 - 3.0153310136257723 - 3.3157269504749984 - 2.827869324062168 - 3.4296963635016944 - 7.340000295124679 - 3.985560946807461 - 0.9933684664222338'\n",
      "81 - plsr - 46 - 2.6788840172475608 - 3.0867836380491713 - 2.6210695415951966 - 3.208356472877454 - 8.352354989243148 - 3.989268665900757 - 0.9933622971868382'\n",
      "82 - plsr - 44 - 2.658136237543454 - 3.0683310124121976 - 2.5790429814385325 - 3.193632055601616 - 8.498208180771549 - 3.999243118629663 - 0.9933457007982559'\n",
      "83 - plsr - 47 - 2.700282247032364 - 3.097030280272357 - 2.613406051463184 - 3.209436705432327 - 8.3847675148687 - 4.000764358396256 - 0.9933431696231649'\n",
      "84 - plsr - 49 - 2.7267357312518046 - 3.0962879566460773 - 2.64787078933328 - 3.2361057837028038 - 8.323437905874854 - 4.005868980587211 - 0.9933346760951741'\n",
      "85 - plsr - 50 - 2.734406447626324 - 3.08910329301568 - 2.641381249001373 - 3.236114539522222 - 8.352389878955172 - 4.010459560207593 - 0.993327037877292'\n",
      "86 - plsr - 52 - 2.738462714136287 - 3.1090280240721113 - 2.655520274319874 - 3.2395795238374974 - 8.310846000734943 - 4.01047017958588 - 0.9933270202078185'\n",
      "87 - plsr - 45 - 2.671364735223648 - 3.077222697831523 - 2.5969295342760375 - 3.216224993085759 - 8.519862693703361 - 4.016092799139228 - 0.9933176647893815'\n",
      "88 - plsr - 53 - 2.7594230384201532 - 3.1009999594893625 - 2.6539567386745513 - 3.22059145761308 - 8.351797982624598 - 4.017136667498506 - 0.9933159279076308'\n",
      "89 - plsr - 57 - 2.7732843794426842 - 3.103150434525503 - 2.656888499579214 - 3.225061400196116 - 8.330449386830058 - 4.0175511690134105 - 0.9933152382228534'\n",
      "90 - pcr_whiten - 39 - 3.323513011735848 - 3.433356536723334 - 3.038829379989476 - 3.563189263542445 - 6.758350684788747 - 4.0233189273733245 - 0.9933056413094596'\n",
      "91 - plsr - 51 - 2.7447966123473377 - 3.099465758251374 - 2.6540102532724466 - 3.2408792670364814 - 8.384505628535383 - 4.024511248131795 - 0.9933036574192995'\n",
      "92 - plsr_scale - 57 - 2.860670395694447 - 3.1521089199841454 - 2.733554912177295 - 3.268139100963901 - 8.114025316340294 - 4.0254961113589856 - 0.9933020187155768'\n",
      "93 - plsr - 56 - 2.768938271116904 - 3.095625855366141 - 2.6620828809228825 - 3.2215158819041827 - 8.41471000396972 - 4.032354783906583 - 0.9932906066413655'\n",
      "94 - ridge_norm - None - 2.8166520932324572 - 3.109206138558866 - 2.670286307008039 - 3.2133320299803128 - 8.360538423726583 - 4.033789040474363 - 0.9932882201967181'\n",
      "95 - plsr - 48 - 2.713399865648327 - 3.091474244172989 - 2.6241687569255117 - 3.2339380390491352 - 8.511469391234963 - 4.0346638402682515 - 0.9932867646264021'\n",
      "96 - plsr - 16 - 3.0703779311233057 - 3.350769718730353 - 2.860003913823001 - 3.4463183622303055 - 7.4700269893645554 - 4.0393337966463685 - 0.993278994334355'\n",
      "97 - plsr - 59 - 2.7910447016149953 - 3.1096170412493427 - 2.6475655139585483 - 3.2227933512748135 - 8.440971671971104 - 4.042180304278926 - 0.9932742580597888'\n",
      "98 - plsr_scale - 64 - 2.849947990849515 - 3.1538664498792217 - 2.716955120989979 - 3.273743396618677 - 8.230538852293433 - 4.0448019915425135 - 0.9932698958615057'\n",
      "99 - plsr - 58 - 2.7797391871444628 - 3.106275116157166 - 2.6518582010453335 - 3.2235759197099036 - 8.46463643185502 - 4.044996793431772 - 0.99326957173266'\n",
      "100 - plsr - 40 - 2.6005165212262438 - 3.0217760960927196 - 2.557939833348793 - 3.145703408800354 - 8.904188122459793 - 4.045778116703653 - 0.9932682716969606'\n",
      "101 - plsr_scale - 65 - 2.851014515401128 - 3.160204217535631 - 2.712665304650511 - 3.2757869843595206 - 8.246187823713896 - 4.048963306806396 - 0.9932629718921402'\n",
      "102 - plsr_scale - 63 - 2.853755982343711 - 3.148289975293722 - 2.723808807358572 - 3.271647644328985 - 8.256022634151726 - 4.050495323911109 - 0.993260422784748'\n",
      "103 - plsr_scale - 62 - 2.8546352327226963 - 3.1468864261518736 - 2.717271738778016 - 3.267503072940639 - 8.267292828488534 - 4.050508120097938 - 0.9932604014933053'\n",
      "104 - plsr_scale - 58 - 2.8501786679478114 - 3.1453420409527832 - 2.7322495940119054 - 3.2627381014996595 - 8.272461376341797 - 4.052383242287087 - 0.9932572814969168'\n",
      "105 - pcr - 39 - 3.3186600088218916 - 3.433082375382432 - 3.0393554865207264 - 3.563085606466513 - 6.941178670536534 - 4.058935953069901 - 0.993246378509317'\n",
      "106 - plsr_scale - 66 - 2.848196685434975 - 3.1574744434468274 - 2.7124093247255665 - 3.2743669050570317 - 8.304778994213114 - 4.0592342019166665 - 0.9932458822561501'\n",
      "107 - plsr_scale - 61 - 2.858729284543338 - 3.1433275547809156 - 2.7227799678808196 - 3.2692968639483837 - 8.322118755440279 - 4.063038295533358 - 0.9932395526641833'\n",
      "108 - plsr_scale - 59 - 2.8465164835003396 - 3.1433765713871744 - 2.733124827754558 - 3.259874509780305 - 8.352212274864781 - 4.066806775565699 - 0.9932332823292906'\n",
      "109 - plsr_scale - 67 - 2.8462637945443436 - 3.150566776029358 - 2.7157683122281613 - 3.2705450994447753 - 8.364147151382367 - 4.069244274879728 - 0.9932292265994291'\n",
      "110 - plsr_scale - 60 - 2.8560678204498435 - 3.1429160913129714 - 2.7291403770800127 - 3.263463736872969 - 8.366797436355979 - 4.071462912403062 - 0.9932255350314342'\n",
      "111 - plsr - 61 - 2.7865378502246556 - 3.120287133876798 - 2.6570292305847922 - 3.2249101603420876 - 8.570025951889765 - 4.071534664350193 - 0.9932254156441126'\n",
      "112 - plsr_scale - 32 - 2.983246158732634 - 3.3154972434640495 - 2.8543870269697393 - 3.440712195844975 - 7.772120144519228 - 4.073008011186826 - 0.9932229641575717'\n",
      "113 - ridge - None - 2.8847869791343714 - 3.163337537320763 - 2.7141161994032292 - 3.2544181798868266 - 8.371655429379814 - 4.077452397464714 - 0.993215569189278'\n",
      "114 - lr - None - 2.8847916016061004 - 3.1633414715432475 - 2.714119657163784 - 3.2544210386931307 - 8.37164852486796 - 4.077453991750834 - 0.9932155665365618'\n",
      "115 - lr_norm - None - 2.8847916016059294 - 3.1633414715432253 - 2.7141196571638715 - 3.2544210386927346 - 8.371648524869663 - 4.0774539917510735 - 0.9932155665365614'\n",
      "116 - plsr - 76 - 2.850906450299223 - 3.138559267055258 - 2.685818892341574 - 3.24651764769133 - 8.469115582846301 - 4.077967137621373 - 0.993214712718463'\n",
      "117 - plsr - 86 - 2.8719891402518045 - 3.1561454340512203 - 2.694196933995701 - 3.2478476633860662 - 8.43455291387869 - 4.080733297030803 - 0.9932101101344729'\n",
      "118 - plsr - 100 - 2.8848979473458556 - 3.160699282905075 - 2.710935621162308 - 3.2563106032912357 - 8.393885324183747 - 4.0811343000963305 - 0.9932094429096257'\n",
      "119 - plsr - 90 - 2.8792332349085616 - 3.1573668649303577 - 2.7015447622869075 - 3.2496757935452205 - 8.41931862287006 - 4.081215484991923 - 0.9932093078269187'\n",
      "120 - plsr - 98 - 2.8848699396234956 - 3.1601783477727046 - 2.709051020239817 - 3.256655260850896 - 8.398690294249283 - 4.081677353524297 - 0.9932085393286517'\n",
      "121 - plsr - 97 - 2.8850933499546643 - 3.15997559242486 - 2.708521140598575 - 3.2558402223729095 - 8.400892507267105 - 4.081852910487799 - 0.9932082472212386'\n",
      "122 - plsr - 99 - 2.8849500707348814 - 3.1604078117377896 - 2.7105261916902696 - 3.257230145679823 - 8.40072880467671 - 4.082556841087741 - 0.9932070759584044'\n",
      "123 - plsr - 89 - 2.8787078544208264 - 3.1588325505143624 - 2.7001931431256865 - 3.2488366561674917 - 8.42788229450483 - 4.082677930769956 - 0.9932068744785364'\n",
      "124 - plsr - 93 - 2.8817572059839134 - 3.158269738106432 - 2.704504464875712 - 3.2524830254196186 - 8.41852314459746 - 4.082895151824644 - 0.9932065130466735'\n",
      "125 - plsr - 79 - 2.860789644096112 - 3.147464053329446 - 2.6851382393847385 - 3.2456573849980415 - 8.478957908323244 - 4.083385809870241 - 0.9932056966458336'\n",
      "126 - plsr - 88 - 2.874377774524492 - 3.156134919576392 - 2.698353876737541 - 3.247290073255121 - 8.44266003005194 - 4.083549889565858 - 0.9932054236353275'\n",
      "127 - plsr - 83 - 2.866190949469479 - 3.1480330534049834 - 2.687250532073284 - 3.2486713472464004 - 8.470321916890173 - 4.083878421670963 - 0.9932048769941607'\n",
      "128 - plsr - 94 - 2.8834895814469967 - 3.158297625866185 - 2.7060886817668925 - 3.252703432342187 - 8.421384806924877 - 4.084180380758917 - 0.9932043745675618'\n",
      "129 - plsr_scale - 68 - 2.8412013522215243 - 3.1516553200451853 - 2.7205235607346747 - 3.263270211143625 - 8.445609694047988 - 4.084234683713009 - 0.993204284213439'\n",
      "130 - plsr - 87 - 2.8737137075847965 - 3.1551837510117955 - 2.6962614837462757 - 3.2486680365598772 - 8.450110177614755 - 4.0845736201365 - 0.9932037202606346'\n",
      "131 - plsr - 96 - 2.88447998522204 - 3.158909483159548 - 2.708159914146863 - 3.2543822007849137 - 8.419203133032635 - 4.084814531721243 - 0.993203319410344'\n",
      "132 - plsr - 85 - 2.8684372841205232 - 3.15170485518761 - 2.6925734964629706 - 3.248970920273842 - 8.464784881876826 - 4.0850795006850475 - 0.9932028785312297'\n",
      "133 - plsr - 92 - 2.881257338875628 - 3.1581998989495315 - 2.7048536298486074 - 3.2525848686718755 - 8.42992639070063 - 4.085151553694013 - 0.9932027586429744'\n",
      "134 - plsr - 91 - 2.881156783678821 - 3.1571631829345304 - 2.7034220846817454 - 3.251131505379779 - 8.435030580015013 - 4.085367798803413 - 0.9932023988349766'\n",
      "135 - plsr - 95 - 2.883529881510803 - 3.15881843642326 - 2.706968286988872 - 3.253210095237933 - 8.428463003451377 - 4.085985191265446 - 0.9932013715620539'\n",
      "136 - plsr - 54 - 2.761232812887876 - 3.103566490125502 - 2.658997144112395 - 3.2200004293195064 - 8.688974563701123 - 4.08632373376709 - 0.993200808264692'\n",
      "137 - plsr - 82 - 2.866349219430367 - 3.1466857349960122 - 2.6879502861886237 - 3.25033986542193 - 8.481899557574637 - 4.086429166151098 - 0.9932006328368402'\n",
      "138 - plsr - 77 - 2.8571324688117077 - 3.1448321596248836 - 2.6826932357594884 - 3.2462826960975635 - 8.503691430934175 - 4.086709469742962 - 0.9932001664425971'\n",
      "139 - plsr - 78 - 2.858701749150198 - 3.14738047515956 - 2.682470226986147 - 3.2452463869188555 - 8.506064742357513 - 4.087755989865162 - 0.9931984251486055'\n",
      "140 - plsr - 62 - 2.803734164581553 - 3.1133546895219055 - 2.659465227848912 - 3.2311817186262735 - 8.63422371634556 - 4.088166204727963 - 0.9931977425963441'\n",
      "141 - plsr - 10 - 3.9254400556552147 - 4.214215015948607 - 3.830503810392608 - 4.259778985850518 - 4.213203391291638 - 4.088624496191276 - 0.9931969800499252'\n",
      "142 - plsr - 80 - 2.863914380766068 - 3.1442887497546956 - 2.683469312872803 - 3.2438385229722453 - 8.51810077992176 - 4.09050528557713 - 0.9931938506239469'\n",
      "143 - plsr - 81 - 2.8645052319661217 - 3.1458245401649036 - 2.6842680093665763 - 3.2463199476135074 - 8.517467468018205 - 4.091459997445567 - 0.9931922620887578'\n",
      "144 - plsr - 64 - 2.807290429321935 - 3.109541230439485 - 2.6701698312610103 - 3.2401282857550653 - 8.64099183198057 - 4.093397552176729 - 0.9931890382115094'\n",
      "145 - plsr - 73 - 2.8463177177142547 - 3.137071575396377 - 2.685208333666803 - 3.2458188792153178 - 8.556737524162061 - 4.094010563090595 - 0.9931880182289992'\n",
      "146 - plsr - 60 - 2.790690034631912 - 3.110518538354102 - 2.6511903040606697 - 3.230265158755693 - 8.69203454408259 - 4.094711123202426 - 0.9931868525742854'\n",
      "147 - plsr - 84 - 2.8691589027556907 - 3.1508488960245193 - 2.6921555529981402 - 3.2491436029173397 - 8.51501184962462 - 4.095046969041954 - 0.9931862937638716'\n",
      "148 - plsr_scale - 69 - 2.8460476985998726 - 3.1499242139796215 - 2.722692952177661 - 3.259832883648028 - 8.499726450609842 - 4.095425571148687 - 0.9931856638117477'\n",
      "149 - plsr - 63 - 2.805494937448327 - 3.1068044683450666 - 2.66357770388816 - 3.2361240574078223 - 8.667239967254355 - 4.095620560363757 - 0.9931853393712125'\n",
      "150 - plsr - 66 - 2.817012718299324 - 3.1130623980459062 - 2.6798097728799535 - 3.244677876868206 - 8.632437362905806 - 4.097173824747576 - 0.9931827549106926'\n",
      "151 - plsr - 74 - 2.8490554436337905 - 3.13949681371057 - 2.6853522110329435 - 3.2475712146058533 - 8.566514671146185 - 4.097377670917328 - 0.9931824157331621'\n",
      "152 - plsr - 67 - 2.8174345135696903 - 3.111751570837562 - 2.6810668291440685 - 3.239720930408089 - 8.642914544283311 - 4.0983511525515715 - 0.993180795967154'\n",
      "153 - plsr - 75 - 2.8493568613513265 - 3.136935700596769 - 2.682185293074754 - 3.247343358768398 - 8.5770435895918 - 4.09835214032509 - 0.993180794323608'\n",
      "154 - plsr - 72 - 2.8418112243178895 - 3.1319471211655707 - 2.6831888879176993 - 3.2459047919857262 - 8.599471710300023 - 4.100242296962712 - 0.9931776493115564'\n",
      "155 - plsr - 65 - 2.8158095263870333 - 3.1063771357093177 - 2.6773911019774865 - 3.2433856978124282 - 8.678177885034422 - 4.103999916420026 - 0.993171397047462'\n",
      "156 - plsr - 71 - 2.8407856086649717 - 3.12515041784687 - 2.6841869433006758 - 3.2428815794972863 - 8.63093703641015 - 4.104564221997389 - 0.9931704581052568'\n",
      "157 - plsr - 68 - 2.828609371754592 - 3.1186852245651826 - 2.686466519138308 - 3.2420269002100928 - 8.664546660948307 - 4.107840323330256 - 0.9931650070341823'\n",
      "158 - plsr_scale - 70 - 2.8435969562232466 - 3.1520314001753387 - 2.726706856194004 - 3.2572370897705576 - 8.574859277458247 - 4.110663968353859 - 0.9931603088004742'\n",
      "159 - plsr - 70 - 2.8348800958614015 - 3.1276380602679117 - 2.68908235547223 - 3.2381087172843337 - 8.667397147704659 - 4.111195513792486 - 0.9931594243675246'\n",
      "160 - plsr_scale - 71 - 2.8475435455974316 - 3.1433886959017143 - 2.7194481508041823 - 3.2466434535437396 - 8.610290133667553 - 4.113239464565499 - 0.9931560234590041'\n",
      "161 - plsr_scale - 73 - 2.8480274244312453 - 3.137888627375676 - 2.7205130976713314 - 3.243391853560251 - 8.620873730989054 - 4.113914979382239 - 0.9931548994768974'\n",
      "162 - plsr_scale - 72 - 2.8450251975200436 - 3.1442411421733714 - 2.7188072037214335 - 3.2419198361161587 - 8.623371848310729 - 4.114449306080588 - 0.9931540104162385'\n",
      "163 - plsr - 69 - 2.8312072026205883 - 3.1195374815591985 - 2.692438644344776 - 3.2405122706660774 - 8.693736095696462 - 4.115258589477443 - 0.9931526638579768'\n",
      "164 - plsr_scale - 74 - 2.847061299626527 - 3.1379804482730735 - 2.7201703382220925 - 3.2435061627782606 - 8.650419987461408 - 4.119602456146958 - 0.9931454361432184'\n",
      "165 - plsr - 39 - 2.5864668669463105 - 2.997483767136765 - 2.5596124051464235 - 3.141459717391003 - 9.342785978410822 - 4.125295349397402 - 0.9931359637971048'\n",
      "166 - plsr_scale - 75 - 2.8393615738895788 - 3.140339052566234 - 2.7211426005749684 - 3.244117923682338 - 8.719798144472424 - 4.132723512743499 - 0.9931236041530526'\n",
      "167 - plsr_scale - 31 - 2.989210173232235 - 3.343607533620112 - 2.8435620381308957 - 3.456706906197977 - 8.05288536971946 - 4.137000479779266 - 0.9931164877519018'\n",
      "168 - plsr_scale - 82 - 2.840963919081915 - 3.1386921595677326 - 2.7062738479329806 - 3.2420099276540544 - 8.820259250380152 - 4.1494081365882485 - 0.9930958427802532'\n",
      "169 - plsr_scale - 76 - 2.837630284684202 - 3.1388031314430447 - 2.7187929747579482 - 3.2467986496085732 - 8.806862613536829 - 4.149545497082039 - 0.9930956142275503'\n",
      "170 - plsr_scale - 83 - 2.8483443787920364 - 3.1421109982850206 - 2.704815857365823 - 3.2453728956446892 - 8.809407625682132 - 4.149779671437078 - 0.9930952245872665'\n",
      "171 - plsr_scale - 81 - 2.8403393242707096 - 3.135781909861014 - 2.7065516855711973 - 3.2385029050439607 - 8.846328764251746 - 4.153268109110006 - 0.9930894202119551'\n",
      "172 - plsr_scale - 77 - 2.835733569774788 - 3.145008625778342 - 2.7172164870461835 - 3.247553983096025 - 8.850440097048384 - 4.158957068838242 - 0.9930799544107883'\n",
      "173 - plsr_scale - 80 - 2.8399394901770063 - 3.14386173217843 - 2.7128937811240363 - 3.2375817616188374 - 8.873109669906919 - 4.161243652027848 - 0.9930761497887032'\n",
      "174 - plsr_scale - 84 - 2.8474399497797567 - 3.1410779076947652 - 2.702171424523021 - 3.243179937943988 - 8.878229479296198 - 4.162186387707892 - 0.9930745811805698'\n",
      "175 - plsr_scale - 30 - 2.9856379868974017 - 3.3693947240398923 - 2.845304602381825 - 3.4469705564869413 - 8.178309867735873 - 4.164926262811615 - 0.9930700223307638'\n",
      "176 - plsr_scale - 78 - 2.838928474291186 - 3.1412084828296694 - 2.719113087683487 - 3.2440219982428466 - 8.886573649014297 - 4.165734240158232 - 0.9930686779456256'\n",
      "177 - plsr_scale - 79 - 2.8374331146271654 - 3.1455229030380516 - 2.7171575205052623 - 3.242914622926247 - 8.887597271651908 - 4.165890438711588 - 0.9930684180484706'\n",
      "178 - plsr_scale - 93 - 2.86797161015494 - 3.1569598068886733 - 2.7130964214171067 - 3.253617381657405 - 8.856026761881287 - 4.169303260025955 - 0.9930627394904349'\n",
      "179 - plsr_scale - 94 - 2.871818194055022 - 3.1564811792863448 - 2.7179148997498817 - 3.25337823064912 - 8.855632302752815 - 4.170813859565791 - 0.993060226019507'\n",
      "180 - plsr_scale - 85 - 2.8523395591016536 - 3.145336715329519 - 2.7000669724558035 - 3.2434821154656386 - 8.91434760675814 - 4.1708804195399685 - 0.9930601152710554'\n",
      "181 - plsr_scale - 92 - 2.8677185125322127 - 3.156400143977779 - 2.7133270562182488 - 3.252517786648377 - 8.885144379955804 - 4.17478926219337 - 0.9930536113882514'\n",
      "182 - plsr_scale - 100 - 2.8629816592347375 - 3.159791924597924 - 2.7195956351755908 - 3.263882365672394 - 8.871087004112201 - 4.17523518061797 - 0.9930528694292035'\n",
      "183 - plsr_scale - 95 - 2.8674868830651605 - 3.158515382515701 - 2.718810889058288 - 3.2556967901044405 - 8.880181047663145 - 4.175905849886522 - 0.9930517535095541'\n",
      "184 - plsr_scale - 96 - 2.8677156970702598 - 3.15753645895723 - 2.7161713863607244 - 3.255984241783957 - 8.897561894780816 - 4.1787609418118175 - 0.9930470029516721'\n",
      "185 - plsr_scale - 91 - 2.8688935853026902 - 3.153198994518804 - 2.7104512329937767 - 3.251535831772661 - 8.91248949547554 - 4.179080454553225 - 0.9930464713177312'\n",
      "186 - plsr_scale - 99 - 2.863221440971352 - 3.15998031717146 - 2.721821583973077 - 3.2589820278391093 - 8.893034795701972 - 4.179174751638374 - 0.9930463144177878'\n",
      "187 - plsr_scale - 86 - 2.858357325299389 - 3.1453048246757076 - 2.700497270246113 - 3.246474196059546 - 8.946499021893505 - 4.1791912908284905 - 0.9930462868984007'\n",
      "188 - plsr_scale - 98 - 2.863307972985576 - 3.159230156614455 - 2.7208577639430294 - 3.256445013177604 - 8.908454558447069 - 4.181425295584839 - 0.993042569761026'\n",
      "189 - plsr_scale - 97 - 2.8674552717176853 - 3.158946102406334 - 2.717416539999033 - 3.2565055948107107 - 8.910344061943011 - 4.181900007817561 - 0.993041779892259'\n",
      "190 - plsr_scale - 87 - 2.8653162468849254 - 3.14340441182286 - 2.70027641626387 - 3.243251958531945 - 8.973495252045177 - 4.184912982453792 - 0.9930367666349695'\n",
      "191 - plsr_scale - 90 - 2.8749939948474617 - 3.1495196627222044 - 2.7055676644736586 - 3.251132932187804 - 8.945915311951808 - 4.18519156064281 - 0.9930363031116063'\n",
      "192 - plsr_scale - 88 - 2.86660414166334 - 3.1452302792700486 - 2.699350502122467 - 3.2439800336627735 - 8.993618197650811 - 4.1895201467707315 - 0.9930291008219826'\n",
      "193 - plsr_scale - 89 - 2.8704374104417267 - 3.145478971456528 - 2.699545963709188 - 3.2437813067933394 - 8.990898748942982 - 4.18979234956773 - 0.9930286479065681'\n",
      "194 - plsr - 38 - 2.5955163376580797 - 2.969990220839751 - 2.541009746593468 - 3.1118829956766523 - 9.790468743188853 - 4.2014901448821425 - 0.9930091840661078'\n",
      "195 - plsr - 32 - 2.5243613385681227 - 2.959950912897472 - 2.605429113431218 - 3.0289868017761203 - 10.017491020069988 - 4.226947175800119 - 0.9929668263760422'\n",
      "196 - plsr_scale - 12 - 3.844703703431424 - 4.198071079643213 - 3.604549036863748 - 4.24103309467695 - 5.325658580710868 - 4.242758868999814 - 0.9929405174635014'\n",
      "197 - plsr - 37 - 2.5662846691031036 - 2.9672519329668186 - 2.540046799002737 - 3.1107617208446823 - 10.069034598367832 - 4.250379518239411 - 0.9929278375441648'\n",
      "198 - plsr - 31 - 2.5139417226225516 - 2.985007652357787 - 2.6202052521015244 - 3.0364606564017804 - 10.13583434742091 - 4.257988524814811 - 0.9929151769969365'\n",
      "199 - pcr_whiten - 40 - 3.3134290730927853 - 3.4339512773901477 - 3.0425725686121767 - 3.5515079378678105 - 7.97804911690791 - 4.263724165805023 - 0.9929056335233015'\n",
      "200 - plsr_scale - 13 - 3.8103475711186157 - 4.1012154226448905 - 3.5164859343804107 - 4.22346441289129 - 5.693429670495539 - 4.2689260359646735 - 0.9928969781854228'\n",
      "201 - plsr - 36 - 2.5456395183166105 - 2.959367598565298 - 2.548309657846483 - 3.0891860954805326 - 10.266635498835054 - 4.281522175583592 - 0.9928760195991791'\n",
      "202 - pcr - 40 - 3.3131148961446115 - 3.4343676704614876 - 3.0429864316304 - 3.551983418021782 - 8.100678652029703 - 4.2884434559807385 - 0.9928645033524155'\n",
      "203 - plsr - 33 - 2.5328000834934548 - 2.9626719315999903 - 2.584580716684515 - 3.0495930021295394 - 10.471461415679803 - 4.319907309777155 - 0.9928121509719798'\n",
      "204 - plsr - 35 - 2.5515682209510717 - 2.95323258670112 - 2.562386158277054 - 3.08126405063928 - 10.465675357582386 - 4.32251156630621 - 0.9928078177765155'\n",
      "205 - plsr_scale - 11 - 3.9284134850588748 - 4.294894517419298 - 3.6737155169270883 - 4.277946015578242 - 5.626816239735314 - 4.360307473930239 - 0.9927449295573022'\n",
      "206 - plsr - 34 - 2.5332487625069002 - 2.961516724240323 - 2.5749831503295155 - 3.0683629476916265 - 10.726107937279536 - 4.37251920182048 - 0.9927246105897521'\n",
      "207 - plsr_scale - 28 - 3.019841448750421 - 3.3988973307278503 - 2.8973627267878617 - 3.5100578123510595 - 9.106598435787644 - 4.386316396633836 - 0.9927016535802108'\n",
      "208 - plsr_scale - 9 - 4.19013814017239 - 4.426169271839418 - 3.952745117638546 - 4.462940576578784 - 4.999269339826623 - 4.40623289297 - 0.992668514728248'\n",
      "209 - plsr_scale - 29 - 3.0112679789242613 - 3.3676649151373454 - 2.8659023930090384 - 3.469136234313414 - 9.327681507576537 - 4.408087125137153 - 0.9926654294905508'\n",
      "210 - plsr - 9 - 4.256192678086356 - 4.622609742406996 - 4.1112974222273895 - 4.669138839818486 - 4.413283078210447 - 4.414509325553471 - 0.9926547436577979'\n",
      "211 - pcr_whiten - 14 - 4.375146893729534 - 4.499554365305432 - 4.07444353259602 - 4.6322538359269645 - 4.4932517913099455 - 4.414934562508246 - 0.9926540361104335'\n",
      "212 - pcr - 14 - 4.375146894115419 - 4.49955436691785 - 4.074443532538143 - 4.6322538353815395 - 4.493251791386481 - 4.414934562802695 - 0.9926540361099435'\n",
      "213 - plsr_scale - 14 - 3.7942721501425907 - 4.066195234491088 - 3.476835627623213 - 4.098412127929952 - 6.6949657913481575 - 4.426037124682152 - 0.9926355626722304'\n",
      "214 - plsr_scale - 15 - 3.7281597108298783 - 4.087240899564641 - 3.435075866667304 - 3.9860100104810634 - 7.121832957476318 - 4.471551231476113 - 0.9925598322213617'\n",
      "215 - plsr - 17 - 2.9677144989476556 - 3.23907075923449 - 2.783215537805106 - 3.456568911158483 - 10.12246599051052 - 4.513525394722933 - 0.9924899918458951'\n",
      "216 - plsr - 30 - 2.5398120694177453 - 2.9868049048175616 - 2.6374543436808855 - 3.045208435258502 - 11.399661512727963 - 4.521436978756627 - 0.992476827843168'\n",
      "217 - plsr_scale - 8 - 4.393522344997426 - 4.647777224305034 - 4.163118378696155 - 4.595963539531947 - 4.848085389185624 - 4.529691568792959 - 0.992463093116306'\n",
      "218 - plsr_scale - 16 - 3.735820628931863 - 4.0286585566484785 - 3.37069106469354 - 3.9830276373668503 - 7.590220501029208 - 4.541551946993887 - 0.9924433587558649'\n",
      "219 - pcr_s_w - 99 - 4.327177843344238 - 4.64910174580337 - 4.1172519761296105 - 4.614781980280495 - 5.257134970289659 - 4.5930687383455435 - 0.9923576405003353'\n",
      "220 - pcr_scale - 100 - 4.358358386082866 - 4.670390237937641 - 4.143103136769382 - 4.567053685735951 - 5.247692767197579 - 4.597303073561556 - 0.9923505950338276'\n",
      "221 - pcr_s_w - 100 - 4.355707605967643 - 4.676486038286927 - 4.109662617006119 - 4.6563301298923685 - 5.198866436816614 - 4.599393922816573 - 0.9923471160914088'\n",
      "222 - pcr_s_w - 98 - 4.361892289326213 - 4.61242400977456 - 4.176843119049437 - 4.61517169261641 - 5.235571478398748 - 4.600357900500216 - 0.9923455121389257'\n",
      "223 - pcr_scale - 95 - 4.365194493212171 - 4.713836912941233 - 4.111355175739864 - 4.609612906154908 - 5.23849995890227 - 4.607686268897418 - 0.9923333185426554'\n",
      "224 - pcr_scale - 97 - 4.369595002101403 - 4.682517950614738 - 4.1389771506851885 - 4.59653953859961 - 5.256050732230297 - 4.608719558745871 - 0.9923315992623791'\n",
      "225 - pcr_s_w - 96 - 4.372837655769842 - 4.675918250484166 - 4.119627844475517 - 4.629830856386101 - 5.2523353205633665 - 4.610092859680343 - 0.9923293142411787'\n",
      "226 - plsr_scale - 27 - 3.031114635739566 - 3.4435473779867607 - 2.8658519745761595 - 3.550336740674095 - 10.171084719463682 - 4.6121124080894065 - 0.9923259539354988'\n",
      "227 - pcr_scale - 98 - 4.385806648917716 - 4.725956683754507 - 4.163958660176167 - 4.590819618586796 - 5.203164618903953 - 4.6139296480694805 - 0.9923229302487185'\n",
      "228 - pcr_s_w - 94 - 4.369975904397865 - 4.673579188717814 - 4.168475810462523 - 4.648163796137463 - 5.211765910786638 - 4.614373621386209 - 0.9923221915261154'\n",
      "229 - pcr_scale - 96 - 4.385245199049733 - 4.670187872005333 - 4.095911734959231 - 4.626987591863463 - 5.295745628823532 - 4.614798206405019 - 0.9923214850635005'\n",
      "230 - pcr_scale - 99 - 4.356398097732031 - 4.681458414001417 - 4.138002689892184 - 4.628580701112026 - 5.27550129114188 - 4.615968850045801 - 0.9923195372416719'\n",
      "231 - pcr_s_w - 91 - 4.386222751948826 - 4.665016985421118 - 4.159938981253088 - 4.625565473664834 - 5.249289938572658 - 4.617188530735132 - 0.9923175078276061'\n",
      "232 - pcr_s_w - 95 - 4.351630163595458 - 4.690599400672627 - 4.148587599376732 - 4.640477543137637 - 5.266142282155929 - 4.619467746845677 - 0.9923137154635274'\n",
      "233 - pcr_scale - 88 - 4.338419013683829 - 4.686045449505415 - 4.18669800271009 - 4.622412466424355 - 5.2685223549477005 - 4.62039784594292 - 0.9923121678812733'\n",
      "234 - pcr_scale - 94 - 4.364226596060695 - 4.701308279635273 - 4.129006298589943 - 4.672124090661554 - 5.2446065722811746 - 4.62223649151093 - 0.992309108577957'\n",
      "235 - pcr_scale - 89 - 4.384801275232435 - 4.709837015357994 - 4.167721461539281 - 4.64459532542104 - 5.2061123140032315 - 4.622598437493174 - 0.9923085063397861'\n",
      "236 - pcr_scale - 92 - 4.382439983745347 - 4.700127719115096 - 4.128467972397021 - 4.67653501421109 - 5.2348350879729475 - 4.62446453597091 - 0.9923054013578576'\n",
      "237 - pcr_scale - 93 - 4.352252978379225 - 4.683003478181801 - 4.17291695539002 - 4.669666409718311 - 5.2612862187133995 - 4.6278031950961696 - 0.9922998461975202'\n",
      "238 - pcr_s_w - 92 - 4.373104382110784 - 4.697594140004734 - 4.161599968552479 - 4.6444547198746395 - 5.268906839769021 - 4.629113275993412 - 0.9922976663674848'\n",
      "239 - pcr_s_w - 93 - 4.391835403711129 - 4.6803886344188 - 4.121030663185496 - 4.632243265597351 - 5.32018617251649 - 4.629118245223284 - 0.9922976580992348'\n",
      "240 - pcr_s_w - 97 - 4.374329119499023 - 4.689284857391232 - 4.115761124250693 - 4.643075615674779 - 5.330902916538856 - 4.630650977622129 - 0.9922951078016721'\n",
      "241 - pcr_scale - 91 - 4.346316406436434 - 4.6941456787131814 - 4.18120883086641 - 4.684375190581647 - 5.256237182719863 - 4.632434239642314 - 0.9922921406504673'\n",
      "242 - pcr_scale - 85 - 4.376978878987367 - 4.685144614931627 - 4.195569482865083 - 4.695982522876962 - 5.213522657558033 - 4.63341918040816 - 0.9922905018177288'\n",
      "243 - pcr_scale - 86 - 4.367476582909645 - 4.677643620136995 - 4.186650893253913 - 4.676566105526811 - 5.266577260905122 - 4.634960434937423 - 0.9922879373402816'\n",
      "244 - pcr_scale - 87 - 4.374839066880355 - 4.708021271670438 - 4.165246638428425 - 4.672040266447682 - 5.257236628478735 - 4.635457987604238 - 0.9922871094675528'\n",
      "245 - pcr_s_w - 84 - 4.378947170939245 - 4.758306588675729 - 4.164509069755404 - 4.683249392043082 - 5.223689805096587 - 4.641725800123125 - 0.9922766805192234'\n",
      "246 - pcr_s_w - 90 - 4.394759520440211 - 4.712319039880389 - 4.220937748368516 - 4.667669634316251 - 5.218849236727294 - 4.64288918381793 - 0.9922747447771437'\n",
      "247 - pcr_s_w - 89 - 4.360076540114168 - 4.728614250450425 - 4.177943085720256 - 4.654779629098524 - 5.298850768972244 - 4.644032937280315 - 0.9922728416976044'\n",
      "248 - pcr_scale - 90 - 4.3540490503920415 - 4.692408465139063 - 4.194289511474507 - 4.663481135545473 - 5.318306428699977 - 4.644482691689987 - 0.9922720933559006'\n",
      "249 - pcr_s_w - 77 - 4.349954741132039 - 4.709020673142941 - 4.209673115543292 - 4.69982184959768 - 5.255294522352992 - 4.644729954929655 - 0.9922716819371572'\n",
      "250 - pcr_s_w - 81 - 4.3509955512006355 - 4.7600868561795435 - 4.187473566725909 - 4.698481419859835 - 5.229432524284916 - 4.645276054609026 - 0.9922707732875571'\n",
      "251 - pcr_scale - 77 - 4.40228278162269 - 4.743601812914577 - 4.1707658021141185 - 4.677577235786885 - 5.241982049219196 - 4.647227094214221 - 0.9922675269729665'\n",
      "252 - pcr_s_w - 87 - 4.414133816919221 - 4.705453688173696 - 4.171744841648583 - 4.688704612562158 - 5.259259456692049 - 4.647841691203405 - 0.9922665043514021'\n",
      "253 - pcr_s_w - 88 - 4.353714512429063 - 4.709976769316522 - 4.180358739867761 - 4.671525154276215 - 5.327735530763512 - 4.64863880603288 - 0.9922651780402937'\n",
      "254 - pcr_scale - 84 - 4.335701037485809 - 4.739988618253007 - 4.214848181114851 - 4.70216136244181 - 5.253689929851811 - 4.649255565941731 - 0.9922641518198696'\n",
      "255 - pcr_s_w - 73 - 4.354350600585811 - 4.772546899873968 - 4.194147122005211 - 4.743312933891271 - 5.20410974055235 - 4.653675432072663 - 0.9922567976503944'\n",
      "256 - pcr_scale - 78 - 4.365792531145264 - 4.728419207367108 - 4.208738823456102 - 4.696246909632389 - 5.2694376776827 - 4.653705731183002 - 0.9922567472360185'\n",
      "257 - pcr_s_w - 79 - 4.380725922816159 - 4.739830531698174 - 4.212355597334457 - 4.672450175493364 - 5.263392738850494 - 4.65373232109191 - 0.9922567029933446'\n",
      "258 - pcr_s_w - 85 - 4.366106929504328 - 4.711122436882105 - 4.220579734636714 - 4.695883471960186 - 5.279589007779727 - 4.654633135642633 - 0.992255204137344'\n",
      "259 - pcr_scale - 66 - 4.380272489070187 - 4.80020882771651 - 4.203353638481665 - 4.704051265470669 - 5.187516722949966 - 4.655067636294662 - 0.9922544811762096'\n",
      "260 - pcr_scale - 81 - 4.406018246247392 - 4.761328338826867 - 4.20307271504248 - 4.66159173140492 - 5.243938372692959 - 4.6551755946686715 - 0.9922543015453893'\n",
      "261 - pcr_scale - 82 - 4.378485544364505 - 4.718243557867255 - 4.21849630083142 - 4.679491788923585 - 5.283833229873857 - 4.655688640997522 - 0.9922534478929167'\n",
      "262 - pcr_scale - 74 - 4.352106144649106 - 4.758141795821787 - 4.210822802294543 - 4.714246712934368 - 5.2451335345981205 - 4.656070029016871 - 0.9922528133053417'\n",
      "263 - pcr_s_w - 86 - 4.374732567442655 - 4.773090321209403 - 4.196845859019121 - 4.686519949021256 - 5.250285045478045 - 4.65627829152157 - 0.9922524667795173'\n",
      "264 - pcr_scale - 83 - 4.3570339442746535 - 4.733721284292899 - 4.234501289896084 - 4.685942635857466 - 5.274417838928982 - 4.657101076279988 - 0.99225109775648'\n",
      "265 - pcr_s_w - 83 - 4.381811034737735 - 4.7211236023480705 - 4.19471300931148 - 4.700524971734792 - 5.287571883624512 - 4.657127789368135 - 0.9922510533088493'\n",
      "266 - pcr_scale - 68 - 4.352620075477843 - 4.8024920236473 - 4.208316683650718 - 4.73069690527916 - 5.201904199707296 - 4.659189667139361 - 0.9922476225717822'\n",
      "267 - pcr_scale - 67 - 4.404130952215203 - 4.742256453820184 - 4.247659402095059 - 4.723290328622107 - 5.183178323894817 - 4.660085731084906 - 0.9922461316202645'\n",
      "268 - pcr_s_w - 80 - 4.354916078785717 - 4.757402510795934 - 4.238680537124236 - 4.688398557696082 - 5.279777122942739 - 4.663813452146791 - 0.9922399291038007'\n",
      "269 - pcr_s_w - 82 - 4.380063423074936 - 4.756919924624099 - 4.209398308125189 - 4.6943323676860045 - 5.278985860118895 - 4.663920909945386 - 0.9922397503058825'\n",
      "270 - pcr_s_w - 71 - 4.384789567034777 - 4.7768149150958035 - 4.22213243934755 - 4.714379274819447 - 5.227942451546864 - 4.665194867905184 - 0.9922376305804287'\n",
      "271 - pcr_scale - 71 - 4.3809279511797845 - 4.77921678936133 - 4.2394372762250665 - 4.734060620483084 - 5.198524103084147 - 4.666416096572916 - 0.9922355985906977'\n",
      "272 - pcr_scale - 79 - 4.416107525172788 - 4.762464612233237 - 4.236905798791482 - 4.681935477833403 - 5.236856856818242 - 4.666838559166741 - 0.9922348956595636'\n",
      "273 - pcr_scale - 70 - 4.383871934694118 - 4.802033076175438 - 4.212040570098505 - 4.703527608125811 - 5.235620025643148 - 4.667403767570354 - 0.9922339552151551'\n",
      "274 - pcr_scale - 65 - 4.384901629734933 - 4.797621227218475 - 4.220334302444641 - 4.7164212913521775 - 5.219148387026569 - 4.667670101087305 - 0.9922335120655749'\n",
      "275 - pcr_s_w - 70 - 4.327526686138549 - 4.799411207137842 - 4.270812643073505 - 4.694274298212633 - 5.252438426337501 - 4.668871592710261 - 0.9922315129161082'\n",
      "276 - pcr_s_w - 76 - 4.351567450720377 - 4.77925758736343 - 4.240145369119115 - 4.723809686273131 - 5.250369054185094 - 4.66900913090848 - 0.9922312840677249'\n",
      "277 - pcr_scale - 73 - 4.383002652308217 - 4.790248368909594 - 4.230872152775115 - 4.703578116275557 - 5.245404581707247 - 4.670604395397187 - 0.9922286297236654'\n",
      "278 - pcr_s_w - 78 - 4.361116871616475 - 4.790355477346725 - 4.216529648594713 - 4.736442311557484 - 5.249528438978781 - 4.670775560730474 - 0.9922283449234404'\n",
      "279 - pcr_scale - 72 - 4.347791425404146 - 4.809043577164385 - 4.259507140338391 - 4.704638068750396 - 5.233376022250804 - 4.6708527781948295 - 0.9922282164421011'\n",
      "280 - plsr_scale - 18 - 3.608751836642751 - 3.9759067132866135 - 3.2805438655489625 - 3.8347704896033803 - 8.657450168805035 - 4.671308994453773 - 0.9922274573485933'\n",
      "281 - pcr_s_w - 75 - 4.348309318681557 - 4.779814907226796 - 4.2778939731387045 - 4.681731645581447 - 5.272686821593273 - 4.672065754095277 - 0.9922261981840642'\n",
      "282 - pcr_scale - 64 - 4.369616265654412 - 4.790431811342017 - 4.24205946320541 - 4.731341106061559 - 5.227504675178623 - 4.672172253056725 - 0.9922260209815453'\n",
      "283 - plsr_scale - 20 - 3.405212531987125 - 3.8140440648650484 - 3.1729468324274475 - 3.8563228181237017 - 9.113586161523411 - 4.672210177713561 - 0.9922259578791016'\n",
      "284 - pcr_scale - 76 - 4.364048314662949 - 4.805847857786592 - 4.249757391485085 - 4.695106717111714 - 5.247905500586624 - 4.672515660307795 - 0.9922254495897772'\n",
      "285 - pcr_scale - 60 - 4.397908795265646 - 4.768242329027221 - 4.282191160504343 - 4.71638980316659 - 5.198100682339129 - 4.672548677314299 - 0.9922253946531221'\n",
      "286 - pcr_scale - 62 - 4.355585614586933 - 4.806636970849181 - 4.258456652457768 - 4.736954463698425 - 5.210815727272558 - 4.673671392246593 - 0.9922235265793751'\n",
      "287 - pcr_scale - 80 - 4.395459271135235 - 4.776328504912455 - 4.2667828176980285 - 4.7069999351473 - 5.2262008799981325 - 4.674336610904527 - 0.9922224197289403'\n",
      "288 - plsr_scale - 10 - 4.027919403168943 - 4.351387716080604 - 3.7792072480954717 - 4.238735586335731 - 6.993456218169654 - 4.678043653931658 - 0.9922162516184443'\n",
      "289 - pcr_scale - 75 - 4.378417575807408 - 4.777834766886325 - 4.255609876651353 - 4.733830125841339 - 5.246875195914639 - 4.678493454816922 - 0.9922155031994102'\n",
      "290 - pcr_scale - 69 - 4.379013228666576 - 4.806111590210022 - 4.248947569755735 - 4.721123738473172 - 5.238060256910901 - 4.678634079666373 - 0.9922152692151798'\n",
      "291 - pcr_s_w - 60 - 4.402279450418058 - 4.818336871548612 - 4.228547510517174 - 4.698166188269679 - 5.250645188142233 - 4.679581201011913 - 0.992213693309783'\n",
      "292 - pcr_s_w - 72 - 4.373915476434526 - 4.787017973640534 - 4.281830734624522 - 4.7028643347401315 - 5.254751070581297 - 4.680056020043162 - 0.992212903263315'\n",
      "293 - pcr_s_w - 63 - 4.371248075989824 - 4.815325432079368 - 4.27144820177654 - 4.722736962339503 - 5.220812146563904 - 4.68029677912943 - 0.9922125026667651'\n",
      "294 - pcr_s_w - 62 - 4.416540433358168 - 4.799321733449631 - 4.291513236881751 - 4.705668642659577 - 5.193670889803105 - 4.681328322447421 - 0.9922107862925228'\n",
      "295 - pcr_s_w - 74 - 4.404880140488574 - 4.745074092934411 - 4.267621355819817 - 4.728073614203582 - 5.263973843153242 - 4.681903245458038 - 0.9922098296840804'\n",
      "296 - pcr_s_w - 67 - 4.403877948150945 - 4.778370991078707 - 4.233107735197169 - 4.735970909469228 - 5.25869321347612 - 4.681986005321446 - 0.9922096919808009'\n",
      "297 - pcr_scale - 61 - 4.391915276566372 - 4.737741116192845 - 4.265036816830935 - 4.741471860831512 - 5.277674688907699 - 4.682744392186391 - 0.9922084301087515'\n",
      "298 - pcr_s_w - 61 - 4.39450266366673 - 4.807562260022051 - 4.262223282099598 - 4.70207277462707 - 5.262234228960415 - 4.685702124859586 - 0.9922035087679922'\n",
      "299 - pcr_s_w - 66 - 4.386761110692521 - 4.808553818007257 - 4.24091746358932 - 4.756223444633608 - 5.238010888504086 - 4.686075679108384 - 0.9922028872149469'\n",
      "300 - pcr_s_w - 57 - 4.4114224305482646 - 4.841626575859235 - 4.218688607196204 - 4.724558775800426 - 5.24016747637392 - 4.687280634068525 - 0.9922008823028693'\n",
      "301 - pcr_s_w - 69 - 4.366631912980587 - 4.8115704727064434 - 4.24646387803363 - 4.703149684265918 - 5.312584363587898 - 4.688060290267457 - 0.9921995850409955'\n",
      "302 - plsr_scale - 17 - 3.689258756930435 - 4.024717708253123 - 3.336623213242257 - 3.946287761367941 - 8.449009411433565 - 4.689013131504423 - 0.9921979996183306'\n",
      "303 - pcr_s_w - 68 - 4.381213503979304 - 4.800881206180107 - 4.251835771123181 - 4.755528628078392 - 5.2663837061361765 - 4.6911485628581175 - 0.9921944464962196'\n",
      "304 - pcr_scale - 55 - 4.417084923382192 - 4.822147264159305 - 4.285734571879425 - 4.734168714944838 - 5.20560698921009 - 4.692933843814062 - 0.9921914759857285'\n",
      "305 - pcr_s_w - 65 - 4.445993861894604 - 4.795809411136598 - 4.250317757231479 - 4.742239443520806 - 5.230747617532303 - 4.693007211554859 - 0.9921913539099045'\n",
      "306 - pcr_scale - 59 - 4.372010445093625 - 4.806723920939904 - 4.262044148570671 - 4.772284583318112 - 5.255968260760861 - 4.69378540895423 - 0.9921900590753121'\n",
      "307 - pcr_s_w - 59 - 4.418400747729256 - 4.829876335020741 - 4.225656344554554 - 4.733143650031807 - 5.2666667258182445 - 4.69473465551321 - 0.9921884796337948'\n",
      "308 - pcr_scale - 63 - 4.40479463591277 - 4.802924831507444 - 4.271644098630779 - 4.777052919636735 - 5.2361679697245505 - 4.69849798234147 - 0.992182217873265'\n",
      "309 - pcr_scale - 50 - 4.432296987097908 - 4.8164158627454166 - 4.2613522197895 - 4.756436843528739 - 5.226582002154579 - 4.698601948792724 - 0.9921820448845636'\n",
      "310 - pcr_s_w - 64 - 4.391785682587529 - 4.843926725856652 - 4.244016908827778 - 4.749607066444793 - 5.264000244845504 - 4.698651182859576 - 0.9921819629645097'\n",
      "311 - pcr_scale - 58 - 4.4131826627264905 - 4.808126947602772 - 4.269221238630345 - 4.741322264110346 - 5.274019859205131 - 4.70115651219587 - 0.9921777943729767'\n",
      "312 - pcr_s_w - 51 - 4.409335590497614 - 4.809751914356637 - 4.271554974836034 - 4.7852466118070085 - 5.238885776517729 - 4.702936313750593 - 0.9921748329796046'\n",
      "313 - pcr_s_w - 56 - 4.442153101936713 - 4.854117300496077 - 4.272362477620567 - 4.712403018799094 - 5.244394059379158 - 4.7050746151400435 - 0.9921712750820708'\n",
      "314 - pcr_s_w - 49 - 4.430893653206028 - 4.833664977275076 - 4.277138934219083 - 4.729764683983076 - 5.264447172171945 - 4.707166921612327 - 0.9921677937150033'\n",
      "315 - pcr_scale - 54 - 4.398666355410989 - 4.826764020511645 - 4.2702222139864885 - 4.759252753518414 - 5.281424189910337 - 4.7072470191888085 - 0.9921676604414754'\n",
      "316 - pcr_s_w - 53 - 4.447413790211579 - 4.848131648931552 - 4.265734287667255 - 4.732123046260573 - 5.251520019139201 - 4.708972330747491 - 0.9921647897134434'\n",
      "317 - pcr_scale - 53 - 4.399624423472698 - 4.865660500697153 - 4.290412217853389 - 4.725880038113956 - 5.264111745415155 - 4.709122504382739 - 0.9921645398410871'\n",
      "318 - pcr_scale - 57 - 4.398048933683041 - 4.820030307357247 - 4.278339679463129 - 4.756568257165336 - 5.2945064400318875 - 4.709478655800812 - 0.9921639472444316'\n",
      "319 - pcr_scale - 52 - 4.432330565442626 - 4.856311213862186 - 4.282306718045453 - 4.766370175147668 - 5.214761910990445 - 4.710402913496109 - 0.9921624093816256'\n",
      "320 - pcr_s_w - 58 - 4.422795278251983 - 4.868874462135774 - 4.2707364901853575 - 4.7502482025830375 - 5.242979390796904 - 4.711113722062964 - 0.9921612266746136'\n",
      "321 - pcr_s_w - 55 - 4.4217070041084865 - 4.810619340469382 - 4.30322828023572 - 4.761519540295 - 5.258952711668708 - 4.711186389697635 - 0.992161105763689'\n",
      "322 - pcr_s_w - 54 - 4.421454927092567 - 4.809035696900574 - 4.319303377693797 - 4.731205840561936 - 5.280821030825843 - 4.71234477412301 - 0.9921591783398419'\n",
      "323 - pcr_s_w - 50 - 4.426746102374924 - 4.853017952300515 - 4.2430253745917454 - 4.7432655250937055 - 5.298002264433633 - 4.712796875357701 - 0.9921584260932803'\n",
      "324 - pcr_scale - 56 - 4.418038862373876 - 4.833431767314119 - 4.264123481224316 - 4.780934456144654 - 5.270102851888556 - 4.713308786591952 - 0.9921575743294799'\n",
      "325 - pcr_s_w - 40 - 4.411155594215743 - 4.8285898300524925 - 4.255411733244691 - 4.7686560237013556 - 5.3062913329246735 - 4.714002095758136 - 0.9921564207395395'\n",
      "326 - pcr_whiten - 41 - 3.1875371780808748 - 3.433746957374525 - 3.0354094039963755 - 3.548871120052905 - 10.370321140763995 - 4.714896589719671 - 0.9921549324003018'\n",
      "327 - pcr_s_w - 46 - 4.406591532941189 - 4.871994444711097 - 4.285132518243832 - 4.761468757639942 - 5.265509317580854 - 4.71812356385874 - 0.9921495630714562'\n",
      "328 - pcr_scale - 44 - 4.42006192945981 - 4.852511670124912 - 4.247007630743949 - 4.773090730165824 - 5.298427220151642 - 4.71820346916232 - 0.9921494301178492'\n",
      "329 - pcr_s_w - 48 - 4.430421819414225 - 4.863757174859581 - 4.262998260732709 - 4.756602820085168 - 5.277790583315749 - 4.718299903828002 - 0.9921492696612078'\n",
      "330 - pcr_scale - 48 - 4.415187209812081 - 4.825459671534759 - 4.275916622558766 - 4.795616003755508 - 5.279901786494402 - 4.718396663781531 - 0.9921491086633233'\n",
      "331 - pcr_s_w - 45 - 4.454106326957424 - 4.813359531686798 - 4.281750011096011 - 4.766096083325637 - 5.291202265785909 - 4.721285350779056 - 0.9921443022069486'\n",
      "332 - pcr_scale - 51 - 4.413818499903005 - 4.855900490772727 - 4.298098080227657 - 4.794305086631502 - 5.246755598523549 - 4.7217581888353655 - 0.9921435154566043'\n",
      "333 - pcr_scale - 45 - 4.444158432288752 - 4.838513994621884 - 4.262805734019838 - 4.7968686451310845 - 5.27508368594157 - 4.723469688115979 - 0.9921406677106785'\n",
      "334 - pcr_s_w - 52 - 4.438458673866586 - 4.852874817625478 - 4.2594499615224635 - 4.778689976276093 - 5.294879986206804 - 4.724854861298176 - 0.9921383629353681'\n",
      "335 - pcr_scale - 49 - 4.46600467270784 - 4.8688210755739805 - 4.238768233475156 - 4.755290685701073 - 5.30677281177441 - 4.727119566437442 - 0.9921345947159442'\n",
      "336 - pcr_s_w - 42 - 4.440806250106012 - 4.831956084545378 - 4.29739809190006 - 4.788884641974189 - 5.29205286937656 - 4.730200842390617 - 0.992129467812801'\n",
      "337 - pcr_s_w - 47 - 4.427155968534854 - 4.8328812305677555 - 4.319390100400569 - 4.764433750873827 - 5.328115264606815 - 4.734374412684449 - 0.992122523452418'\n",
      "338 - plsr_scale - 21 - 3.330669979720892 - 3.77764582681713 - 3.1260934586874396 - 3.8387562667287547 - 9.608932544474273 - 4.736183446346022 - 0.9921195134200461'\n",
      "339 - pcr_s_w - 43 - 4.4633044940663735 - 4.82963926852042 - 4.306393156244764 - 4.772357722524106 - 5.313206670582795 - 4.73696218240745 - 0.9921182176891795'\n",
      "340 - pcr_scale - 40 - 4.4394028403477 - 4.852630219538826 - 4.323135163034513 - 4.814610220074062 - 5.264352350453703 - 4.7388076190116255 - 0.9921151470863285'\n",
      "341 - pcr_s_w - 44 - 4.4547804623751786 - 4.834115173999018 - 4.312562648493571 - 4.761719399873846 - 5.334357735763151 - 4.739488095034649 - 0.992114014849322'\n",
      "342 - pcr_scale - 41 - 4.441937682532246 - 4.866585352622174 - 4.319606120451228 - 4.788362561005718 - 5.2883208900516 - 4.7409452019151415 - 0.992111590384276'\n",
      "343 - pcr_scale - 38 - 4.404343302985489 - 4.838219989390428 - 4.350800293191768 - 4.7821443277350655 - 5.329381071062909 - 4.74095388633564 - 0.9921115759343586'\n",
      "344 - pcr_scale - 46 - 4.501054063164411 - 4.844368305642887 - 4.270492693467381 - 4.814277551028795 - 5.278416516123412 - 4.741708040299784 - 0.9921103211053891'\n",
      "345 - pcr - 41 - 3.1874614287617145 - 3.433666586889335 - 3.0359828829758655 - 3.5484335317726674 - 10.512730457467503 - 4.743368702909065 - 0.9921075579460743'\n",
      "346 - pcr_s_w - 37 - 4.450951895604809 - 4.861878192071078 - 4.355861717495376 - 4.7720158008021984 - 5.276926663079478 - 4.74350945233037 - 0.99210732375457'\n",
      "347 - pcr_scale - 43 - 4.448048431417024 - 4.893396520734282 - 4.269936415082036 - 4.81028504064458 - 5.299136053331157 - 4.744145822242583 - 0.9921062649052645'\n",
      "348 - pcr_scale - 47 - 4.450878487275942 - 4.84602557723805 - 4.305577491280012 - 4.813219219534952 - 5.306116193315596 - 4.744344234447753 - 0.9921059347692515'\n",
      "349 - pcr_scale - 42 - 4.4403617024547 - 4.860421407823831 - 4.313105973475846 - 4.818393321155686 - 5.319024066690468 - 4.75024134431228 - 0.992096122629229'\n",
      "350 - pcr_scale - 39 - 4.453943490076519 - 4.845886521699226 - 4.407960527037493 - 4.78119495575785 - 5.2626294228186135 - 4.750302925951454 - 0.9920960201641773'\n",
      "351 - pcr_s_w - 41 - 4.455699571505066 - 4.861515360343637 - 4.271133368728205 - 4.833886353320536 - 5.330575932377745 - 4.750543748367436 - 0.9920956194622538'\n",
      "352 - pcr_scale - 37 - 4.448356427276498 - 4.897347870180365 - 4.307280042876364 - 4.822821886664589 - 5.312214423962719 - 4.757587200111911 - 0.9920838999358508'\n",
      "353 - pcr_s_w - 39 - 4.481828719063936 - 4.899767184237262 - 4.3006538228419675 - 4.797176180393338 - 5.315774821478611 - 4.759026513522728 - 0.9920815050771746'\n",
      "354 - pcr_s_w - 36 - 4.447987891550634 - 4.899473564696926 - 4.3296761866017555 - 4.8209606443922 - 5.303077107302716 - 4.76021779877485 - 0.9920795229099827'\n",
      "355 - pcr_scale - 36 - 4.510274472223413 - 4.866855536195431 - 4.346180790067726 - 4.814702447970137 - 5.275377919001362 - 4.7626634282116935 - 0.992075453652494'\n",
      "356 - pcr_s_w - 38 - 4.48991755266092 - 4.864773696394853 - 4.321722405267714 - 4.8231400360396135 - 5.318856151967133 - 4.7636647218931465 - 0.9920737876103087'\n",
      "357 - pcr_scale - 34 - 4.4872997431409285 - 4.897899554943775 - 4.320843277484181 - 4.821420473461734 - 5.312721314643104 - 4.768021803373239 - 0.9920665379075637'\n",
      "358 - pcr_s_w - 35 - 4.472555307579094 - 4.875204570535578 - 4.368271142933669 - 4.80163185058942 - 5.3313468011284755 - 4.769782773147835 - 0.9920636078481956'\n",
      "359 - pcr_scale - 35 - 4.477002001789146 - 4.903990062980239 - 4.376763147561782 - 4.809207755251592 - 5.298792961439466 - 4.773134674587222 - 0.9920580306541089'\n",
      "360 - pcr_s_w - 34 - 4.48028809421346 - 4.890761840950988 - 4.358118717564929 - 4.840243704976545 - 5.341071397768855 - 4.782077459887701 - 0.9920431508462749'\n",
      "361 - pcr_scale - 32 - 4.495964507137921 - 4.904031817370439 - 4.3786053683016215 - 4.8565730157347415 - 5.289150335675191 - 4.784848055818295 - 0.9920385408804033'\n",
      "362 - pcr_s_w - 32 - 4.490961800440612 - 4.924073446434774 - 4.3716668803249865 - 4.861350137600194 - 5.2949357646438395 - 4.7885814093282635 - 0.9920323289921674'\n",
      "363 - pcr_scale - 33 - 4.5040943182584945 - 4.912745064086047 - 4.387680808506413 - 4.8543403207845275 - 5.293331617254359 - 4.79042204169195 - 0.9920292663830423'\n",
      "364 - plsr_scale - 19 - 3.4940397501203364 - 3.9226261376551714 - 3.1987258001564913 - 3.860122042138591 - 9.48029803555321 - 4.79094604681049 - 0.9920283944963532'\n",
      "365 - pcr_s_w - 33 - 4.489669700537763 - 4.89988519893311 - 4.3978283367159605 - 4.839147307121183 - 5.340261738932098 - 4.793338763877765 - 0.9920244132792082'\n",
      "366 - plsr_scale - 26 - 3.1102429758648724 - 3.4709460065175106 - 2.894869469734693 - 3.570629877198152 - 10.922810898612646 - 4.793599544875548 - 0.9920239793684071'\n",
      "367 - plsr_scale - 24 - 3.151067604574485 - 3.5908373653243024 - 2.9912374205569834 - 3.6444973919084958 - 10.65872750405414 - 4.806986537393083 - 0.9920017048902169'\n",
      "368 - pcr_s_w - 31 - 4.490286730433227 - 4.926037734752956 - 4.405330272673592 - 4.888924567804342 - 5.3387403760844405 - 4.809843620388115 - 0.9919969510194145'\n",
      "369 - pcr_scale - 31 - 4.502472652899369 - 4.906884131846803 - 4.382861458940067 - 4.842238403408904 - 5.422493188682058 - 4.811368650420566 - 0.9919944135377395'\n",
      "370 - pcr_whiten - 42 - 3.185936456482598 - 3.449863248055303 - 3.0160133560063342 - 3.544835235650066 - 10.883601940052728 - 4.8157507763355065 - 0.9919871221638188'\n",
      "371 - pcr - 42 - 3.184616052064113 - 3.4499094696411503 - 3.016448947155719 - 3.5451027822375933 - 10.896007417522021 - 4.818117062734732 - 0.9919831849243886'\n",
      "372 - plsr - 26 - 2.507615851204255 - 2.9543476182289092 - 2.6648608132078917 - 3.1181605319290164 - 12.898946920577988 - 4.8283672889768114 - 0.9919661296791142'\n",
      "373 - plsr_scale - 25 - 3.1216990147034576 - 3.5524383970052313 - 2.9892578026317853 - 3.6339533667018946 - 10.873542128352758 - 4.833879078867434 - 0.9919569586690051'\n",
      "374 - pcr_scale - 30 - 4.48653914053559 - 4.954371317161575 - 4.456872832041323 - 4.887038050368209 - 5.422108446444815 - 4.841361800153198 - 0.9919445082465623'\n",
      "375 - pcr_s_w - 30 - 4.489214238248037 - 4.942610135382543 - 4.4591490139074335 - 4.885604731182493 - 5.466968220492462 - 4.848682740259488 - 0.9919323270101482'\n",
      "376 - plsr_scale - 23 - 3.1900211433328254 - 3.647312502429547 - 3.0585095590984857 - 3.6897933217112713 - 10.922494740042593 - 4.9013300169205385 - 0.9918447277518216'\n",
      "377 - plsr - 29 - 2.541812672993444 - 3.012070845807276 - 2.6668749957140703 - 3.02540858327028 - 13.341813449200588 - 4.917168491668407 - 0.9918183742777403'\n",
      "378 - pcr_s_w - 29 - 4.500635090100289 - 4.965777304193096 - 4.505608519209292 - 5.020938695482272 - 5.668479393023168 - 4.93224803180329 - 0.9917932835871007'\n",
      "379 - pcr_scale - 29 - 4.48987541410951 - 4.967978775721029 - 4.5143119948555155 - 5.018327935963143 - 5.682178952448857 - 4.934493542402331 - 0.9917895473052736'\n",
      "380 - pcr_whiten - 43 - 3.1577653876815996 - 3.4479472911544047 - 3.017205014197832 - 3.551531851147109 - 11.534748736851569 - 4.941512252427679 - 0.9917778689463608'\n",
      "381 - pcr_s_w - 28 - 4.563652011889995 - 5.002173607923582 - 4.518095532437563 - 5.021634680029731 - 5.613292612864988 - 4.943737556212726 - 0.991774166286442'\n",
      "382 - pcr - 43 - 3.1586746869813545 - 3.448099789638711 - 3.0169491724792796 - 3.551763741287025 - 11.552732027657843 - 4.945315825948975 - 0.9917715402197753'\n",
      "383 - pcr_scale - 28 - 4.56074077701035 - 5.0001077562529375 - 4.522080542706397 - 5.016634066053193 - 5.633763187190552 - 4.946632057492862 - 0.9917693501557426'\n",
      "384 - plsr - 27 - 2.513839647185926 - 2.9513066672453125 - 2.6506909751518766 - 3.0935526965230347 - 13.591432033587155 - 4.959719419670439 - 0.9917475742293717'\n",
      "385 - plsr_scale - 7 - 4.746335273504132 - 5.0072038893663855 - 4.459757292198208 - 5.032712662811895 - 5.5735244774999035 - 4.963889312536424 - 0.9917406359878228'\n",
      "386 - plsr_scale - 22 - 3.303583804120062 - 3.6509184889532746 - 3.0998931243224987 - 3.754836435432706 - 11.328677987063699 - 5.027272273447596 - 0.9916351737356704'\n",
      "387 - pcr_whiten - 61 - 3.0069985240819217 - 3.3765419148165057 - 2.956200868689437 - 3.454898938430782 - 12.50264384513834 - 5.059083728619176 - 0.991582242984907'\n",
      "388 - pcr - 64 - 2.957196165187918 - 3.341617349215766 - 2.953580045468834 - 3.402688082548029 - 12.643307359203192 - 5.059296204031675 - 0.991581889449269'\n",
      "389 - pcr_whiten - 50 - 3.1006094821734376 - 3.405441863232236 - 2.9893017910345816 - 3.4922538624176083 - 12.312867103063514 - 5.059733839731522 - 0.9915811612717609'\n",
      "390 - pcr_s_w - 27 - 4.586081333723341 - 5.078655446120414 - 4.548578961753149 - 4.983793794188381 - 6.11139731226013 - 5.061655557987092 - 0.9915779637446602'\n",
      "391 - pcr - 50 - 3.099792192710219 - 3.403384090400223 - 2.989371053020288 - 3.492489154368792 - 12.326892667130963 - 5.062024106058664 - 0.9915773505213413'\n",
      "392 - pcr_whiten - 64 - 2.956452285647473 - 3.333632853410051 - 2.9551344593952975 - 3.4022175277480424 - 12.670594368312333 - 5.063223046060175 - 0.9915753556174912'\n",
      "393 - pcr_scale - 27 - 4.587858011430393 - 5.07948803634165 - 4.547508067088997 - 4.9899381699016025 - 6.112839813647682 - 5.063480504101602 - 0.9915749272357227'\n",
      "394 - pcr - 60 - 3.0519334175223625 - 3.378484236335645 - 2.9845189534795775 - 3.448937384744803 - 12.456033572168227 - 5.063612201486576 - 0.991574708105808'\n",
      "395 - pcr - 51 - 3.097107931656047 - 3.405339049728547 - 2.9848965782152015 - 3.48727015092319 - 12.355403993904526 - 5.065641019900645 - 0.9915713323758629'\n",
      "396 - pcr - 61 - 3.007874018942019 - 3.3792934211985686 - 2.9604724487277965 - 3.457283708417754 - 12.530213350317247 - 5.066653149874362 - 0.9915696483032831'\n",
      "397 - plsr - 25 - 2.52036834500669 - 2.987952802533634 - 2.6734097712968086 - 3.1570408228614686 - 14.003600759921875 - 5.068012192308403 - 0.9915673870066537'\n",
      "398 - pcr - 44 - 3.12897796428632 - 3.4501562580790877 - 3.0149445031681954 - 3.554486018964996 - 12.196434136718484 - 5.068644316262382 - 0.9915663352221541'\n",
      "399 - pcr_whiten - 49 - 3.100349487214063 - 3.427667637441132 - 2.986034355303306 - 3.4931010902970234 - 12.340279271355154 - 5.069125705556256 - 0.9915655342434941'\n",
      "400 - pcr_whiten - 60 - 3.0516206073897 - 3.3814047564562197 - 2.9914676359932955 - 3.4507904752184992 - 12.476182847965207 - 5.06992295286214 - 0.9915642077119596'\n",
      "401 - pcr_whiten - 51 - 3.0970586448285173 - 3.405597156585685 - 2.9844041427559382 - 3.4875110549513453 - 12.377998412721261 - 5.070150481253555 - 0.9915638291298259'\n",
      "402 - plsr - 28 - 2.528955558648803 - 2.9979754261076894 - 2.6612494026881834 - 3.0582915127827706 - 14.106662550765371 - 5.070166010974069 - 0.9915638032900848'\n",
      "403 - pcr_whiten - 44 - 3.1298156626103757 - 3.450074257150369 - 3.015039800591177 - 3.5540946809048295 - 12.207464327992572 - 5.0709419023049245 - 0.9915625122925359'\n",
      "404 - pcr - 49 - 3.1028117473524643 - 3.426933300711931 - 2.9865319294833386 - 3.494328867246279 - 12.347088996369909 - 5.071178068024195 - 0.9915621193388418'\n",
      "405 - pcr - 65 - 2.9536421391573118 - 3.344052606124531 - 2.9499828574828806 - 3.406309055860253 - 12.728724605738712 - 5.076157175988953 - 0.9915538346526718'\n",
      "406 - pcr_whiten - 45 - 3.1305652130222783 - 3.4346369629884452 - 3.0156047826340044 - 3.553093535269844 - 12.254350194286843 - 5.077291558125774 - 0.991551947165984'\n",
      "407 - pcr_whiten - 46 - 3.134512214996119 - 3.437921199521252 - 3.016791189792611 - 3.5478716366941 - 12.252859872014096 - 5.077633297211037 - 0.9915513785498596'\n",
      "408 - pcr - 45 - 3.1298298341493282 - 3.4344932824429364 - 3.01443919755424 - 3.5531000436244944 - 12.261943971802514 - 5.078402376640307 - 0.9915500988865633'\n",
      "409 - pcr_whiten - 65 - 2.9683311822733556 - 3.350323126639993 - 2.9566459158828833 - 3.4072721539224453 - 12.722752385591694 - 5.080681065966668 - 0.9915463073989954'\n",
      "410 - pcr_whiten - 59 - 3.045441638216407 - 3.390342095989968 - 2.9833524945293215 - 3.446472033582859 - 12.5505588691252 - 5.082860805122313 - 0.9915426805535916'\n",
      "411 - pcr_whiten - 53 - 3.0931758874524666 - 3.397537939489288 - 2.9823410962252512 - 3.458911847648364 - 12.518778425857947 - 5.089780523128937 - 0.9915311669064734'\n",
      "412 - pcr - 46 - 3.133429366519955 - 3.4377087539629603 - 3.0164206724122478 - 3.5478114387268063 - 12.31680198945617 - 5.0900739037873475 - 0.9915306787534346'\n",
      "413 - pcr - 56 - 3.076121819578043 - 3.402409452033767 - 2.9849033336841364 - 3.456354823857114 - 12.537927350811515 - 5.091173344462713 - 0.9915288494054827'\n",
      "414 - pcr - 48 - 3.1015884350906777 - 3.432769267253811 - 2.99521718986236 - 3.4950943295711276 - 12.4409663614569 - 5.092762364696221 - 0.9915262054511749'\n",
      "415 - pcr - 62 - 2.9746610813032555 - 3.377977952426071 - 2.9562806579709604 - 3.427081244239827 - 12.73163306579584 - 5.093143818468747 - 0.9915255707541938'\n",
      "416 - pcr_whiten - 48 - 3.101621709813745 - 3.4335620515277463 - 2.9942930536884553 - 3.494391168413112 - 12.446861287496798 - 5.093780981240805 - 0.9915245105856569'\n",
      "417 - pcr - 59 - 3.0497830128057775 - 3.3775432393929865 - 2.987914189906418 - 3.4452659169945865 - 12.613582839358806 - 5.094442059685004 - 0.991523410624081'\n",
      "418 - pcr - 53 - 3.094017185898883 - 3.3961018999816335 - 2.9826160517437335 - 3.465849176819544 - 12.53747218590959 - 5.094841713223467 - 0.9915227456446979'\n",
      "419 - pcr - 55 - 3.0877296606207323 - 3.4047779646794862 - 2.982986493296787 - 3.4488142177960253 - 12.555518788306683 - 5.095595926016194 - 0.991521490717844'\n",
      "420 - pcr_whiten - 63 - 2.9510226371914174 - 3.34445691172356 - 2.9473163542630063 - 3.4100253284057747 - 12.827214470117154 - 5.095617953890745 - 0.9915214540658918'\n",
      "421 - pcr_whiten - 56 - 3.079384994018576 - 3.401870358678821 - 2.9876686733558744 - 3.455655418468882 - 12.557951800893823 - 5.096135518245653 - 0.9915205928959224'\n",
      "422 - pcr_whiten - 52 - 3.0945512294864654 - 3.405911698083394 - 2.9916250472803982 - 3.4766149825101413 - 12.514081845993308 - 5.096188138158379 - 0.9915205053421947'\n",
      "423 - pcr_whiten - 55 - 3.084937607131631 - 3.40473139185299 - 2.984182882712247 - 3.4495283661656413 - 12.566332437547834 - 5.097572359687424 - 0.9915182021503299'\n",
      "424 - pcr_whiten - 47 - 3.128943610949237 - 3.4184261275886754 - 3.0061303864649807 - 3.51618235451832 - 12.448219210812027 - 5.103214797621422 - 0.9915088137562948'\n",
      "425 - pcr - 47 - 3.1301364924990804 - 3.4194934545562843 - 3.0058161150269473 - 3.5157733720688404 - 12.446813809229143 - 5.1032413287249705 - 0.9915087696114664'\n",
      "426 - pcr_whiten - 57 - 3.060538226105482 - 3.388592763538554 - 2.9857646602747328 - 3.4576809455555324 - 12.627819690488867 - 5.103703804982811 - 0.9915080001020112'\n",
      "427 - pcr - 52 - 3.094688649022361 - 3.4048459647998097 - 2.993181456966448 - 3.472920383112924 - 12.561146085682635 - 5.104985834884274 - 0.9915058669457372'\n",
      "428 - pcr - 58 - 3.041208288442091 - 3.39161962653377 - 2.9789848560987564 - 3.455021174585498 - 12.693907079383886 - 5.1117695125901985 - 0.9914945796546663'\n",
      "429 - pcr - 63 - 2.953928528481968 - 3.3419020872771297 - 2.9403421202610884 - 3.4012562276313756 - 12.924726063907922 - 5.112038573291034 - 0.991494131967353'\n",
      "430 - pcr_whiten - 58 - 3.0494687669556897 - 3.393832786703421 - 2.9855090076232904 - 3.457617341717782 - 12.68145552713211 - 5.113198754362616 - 0.9914922015540849'\n",
      "431 - pcr - 57 - 3.063090550712499 - 3.3907323636733366 - 2.9846269410336284 - 3.458438644864891 - 12.692101796442559 - 5.117420335293815 - 0.9914851773092997'\n",
      "432 - pcr - 54 - 3.0870034887556614 - 3.399760633635602 - 2.9851347316553554 - 3.4545718908657537 - 12.675651089014474 - 5.120049408274466 - 0.9914808028219987'\n",
      "433 - pcr_whiten - 54 - 3.086132206555833 - 3.4012717023316448 - 2.9857770690085363 - 3.4549630062008885 - 12.73274470264869 - 5.131800494883496 - 0.9914612503107053'\n",
      "434 - pcr - 67 - 2.9690006658994545 - 3.335169018240064 - 2.922972979101876 - 3.3866643656660558 - 13.093491338673173 - 5.141062275427542 - 0.9914458397299897'\n",
      "435 - pcr - 68 - 2.877467366794392 - 3.3304954721910933 - 2.94196684704046 - 3.3822983139732115 - 13.213178398074934 - 5.148672749878477 - 0.9914331767403785'\n",
      "436 - pcr_whiten - 62 - 2.9691297135705246 - 3.3761583573333303 - 2.955551558425997 - 3.4333027212534932 - 13.02907647007852 - 5.152248238817015 - 0.9914272275213678'\n",
      "437 - pcr_whiten - 66 - 2.96301609929627 - 3.343277900901122 - 2.9543538736793056 - 3.3940564223256215 - 13.12337370131894 - 5.155215585800815 - 0.9914222901834566'\n",
      "438 - pcr_whiten - 13 - 5.390395962473412 - 5.172200644669933 - 4.570721604990994 - 5.319848003576041 - 5.353159049720209 - 5.161289030962764 - 0.9914121846409591'\n",
      "439 - pcr - 13 - 5.390395962336606 - 5.172200644716033 - 4.570721605041432 - 5.319848003707437 - 5.353159049695341 - 5.161289030976003 - 0.9914121846409372'\n",
      "440 - pcr_whiten - 67 - 2.937714023169441 - 3.335052695267989 - 2.9322331040956304 - 3.395063961569363 - 13.219842923838113 - 5.1635763080319 - 0.991408378864335'\n",
      "441 - pcr - 69 - 2.8984731686156224 - 3.339190429842431 - 2.919779722262143 - 3.3754515142828185 - 13.3250881121289 - 5.171186528541406 - 0.9913957162972543'\n",
      "442 - plsr - 24 - 2.514287116540102 - 2.9651730837575943 - 2.635375995362839 - 3.1681872964844575 - 14.62160573820382 - 5.180438192105336 - 0.9913803225500771'\n",
      "443 - pcr - 66 - 2.961843813228264 - 3.3461728814512495 - 2.949328993894702 - 3.4034961806418056 - 13.36627735008485 - 5.2050140525104895 - 0.9913394310305008'\n",
      "444 - pcr - 71 - 2.8491802197503904 - 3.3391222531970515 - 2.908806843210366 - 3.382842308350338 - 13.552275905011049 - 5.206023553392965 - 0.9913377513324386'\n",
      "445 - pcr_whiten - 70 - 2.851737151606629 - 3.3370634039871825 - 2.9210253882245527 - 3.3740590152352836 - 13.594016675921102 - 5.215156599458155 - 0.991322554951689'\n",
      "446 - pcr - 70 - 2.85449796836943 - 3.345693931872885 - 2.919667129085378 - 3.3889624617646015 - 13.625221650400535 - 5.226383795562214 - 0.9913038741363804'\n",
      "447 - pcr_whiten - 68 - 2.892950988453877 - 3.339729467162462 - 2.9445057214451427 - 3.388646808925148 - 13.69279192187232 - 5.251298416499124 - 0.9912624189566641'\n",
      "448 - pcr_whiten - 72 - 2.8377181062218284 - 3.3194899662097614 - 2.897980392691827 - 3.385762625609211 - 13.875075776684568 - 5.262768976891895 - 0.9912433332100363'\n",
      "449 - pcr - 75 - 2.8274483549869274 - 3.3087672968552755 - 2.8827822707259423 - 3.385556825262888 - 14.057465507114214 - 5.2919597249353 - 0.9911947630267187'\n",
      "450 - pcr - 73 - 2.8085795374245963 - 3.306635356075226 - 2.8935922098282356 - 3.382011837997499 - 14.248174824916699 - 5.327345259180033 - 0.991135885402805'\n",
      "451 - pcr_whiten - 69 - 2.891692484268844 - 3.3357177379016245 - 2.928674295989836 - 3.3802302854533233 - 14.118928488156563 - 5.3306057211692055 - 0.9911304603538724'\n",
      "452 - pcr_whiten - 75 - 2.8127814557048048 - 3.3074869888010863 - 2.889143185260523 - 3.370114440328761 - 14.297706889667978 - 5.334992074899155 - 0.9911231619453341'\n",
      "453 - plsr - 8 - 4.768937814831456 - 4.8307881878920504 - 4.3181991991314606 - 4.935779592842635 - 7.960765853191295 - 5.362781658317648 - 0.9910769231453229'\n",
      "454 - pcr - 72 - 2.829388448682214 - 3.30143338709357 - 2.8979859653182016 - 3.391867973373978 - 14.507589692676671 - 5.3851896011845115 - 0.9910396388012837'\n",
      "455 - pcr - 76 - 2.816440027418386 - 3.308071005616297 - 2.8883019639757435 - 3.389534040245997 - 14.563928673788153 - 5.392789501053165 - 0.9910269934066104'\n",
      "456 - pcr_whiten - 73 - 2.85249263290732 - 3.2961113341862736 - 2.8852709637394054 - 3.3915359742795737 - 14.56897868571382 - 5.398413560207904 - 0.9910176355928357'\n",
      "457 - pcr_scale - 26 - 5.146750102713522 - 5.334842376422209 - 4.816420491383012 - 5.589886313140694 - 6.167913338032578 - 5.41112849192035 - 0.990996479349658'\n",
      "458 - pcr_s_w - 26 - 5.1438221632081955 - 5.337174190450291 - 4.816816295109084 - 5.589437390470433 - 6.170786794910981 - 5.411573186008782 - 0.9909957394277703'\n",
      "459 - pcr_whiten - 71 - 2.8548531459773097 - 3.3400286665154852 - 2.887800600005997 - 3.3871185404414375 - 14.740253931462611 - 5.4415426248888314 - 0.9909458735888351'\n",
      "460 - pcr - 74 - 2.8212241047763142 - 3.2993765844078204 - 2.893095127573283 - 3.3844381796499454 - 14.94411454114349 - 5.4679686549007185 - 0.9909019035912138'\n",
      "461 - pcr_whiten - 77 - 2.794910274174708 - 3.2946500754738666 - 2.8772044564763064 - 3.3794879353096188 - 15.0399675295301 - 5.4767581445086675 - 0.9908872788504949'\n",
      "462 - plsr_scale - 6 - 4.953584173960316 - 5.441847797318303 - 4.908375754381764 - 5.448753858943966 - 6.639195920190893 - 5.478295441127782 - 0.9908847209585733'\n",
      "463 - plsr - 23 - 2.5172086244467873 - 3.0282147841534632 - 2.679611717688499 - 3.1419031975901435 - 16.143268964590057 - 5.5014962459971475 - 0.9908461173796603'\n",
      "464 - pcr - 79 - 2.797152707979102 - 3.312426597919143 - 2.88490359493414 - 3.4004254601036052 - 15.193173619748102 - 5.517124421158156 - 0.9908201138208834'\n",
      "465 - pcr_whiten - 76 - 2.8237979634802275 - 3.3081022880657844 - 2.8850802401821074 - 3.376148235461597 - 15.282436110957098 - 5.534619726949807 - 0.9907910035627895'\n",
      "466 - pcr - 78 - 2.7936890218107497 - 3.299512931020239 - 2.894786301833467 - 3.3997489804554366 - 15.307186756112014 - 5.5384869189371875 - 0.9907845689820973'\n",
      "467 - pcr_whiten - 78 - 2.7895420133122393 - 3.2865174733228457 - 2.8856875427167235 - 3.3717716960359505 - 15.399993790866322 - 5.54620137005866 - 0.990771732986781'\n",
      "468 - pcr_whiten - 74 - 2.818857288237587 - 3.314831528239216 - 2.9012504584876315 - 3.3776435299473557 - 15.328339823192985 - 5.5476888524053365 - 0.9907692579803113'\n",
      "469 - pcr_whiten - 82 - 2.7871566931652794 - 3.3013495386069054 - 2.8809633328876862 - 3.3698309221365004 - 15.440615985030377 - 5.5554815504223845 - 0.9907562917907959'\n",
      "470 - pcr - 80 - 2.804986151763569 - 3.3005339148284323 - 2.873265852901784 - 3.383311530892117 - 15.710024391527135 - 5.613912649578155 - 0.9906590688901281'\n",
      "471 - pcr - 81 - 2.7967626300496855 - 3.297815859143678 - 2.8924176270957913 - 3.37818729215335 - 15.717230320303957 - 5.615969522916461 - 0.9906556464798851'\n",
      "472 - pcr - 77 - 2.8146107327540086 - 3.3047303903629843 - 2.899262808241674 - 3.4054835781104074 - 15.682778705466246 - 5.620861516522536 - 0.9906475067423943'\n",
      "473 - pcr - 12 - 5.530661419667955 - 5.078295679088295 - 4.575428565832294 - 5.949791423469555 - 6.986613083779649 - 5.624094175101671 - 0.9906421279552677'\n",
      "474 - pcr_whiten - 12 - 5.5306614196473385 - 5.078295679232194 - 4.575428565950465 - 5.949791423455335 - 6.986613083786696 - 5.62409417514853 - 0.9906421279551897'\n",
      "475 - pcr - 85 - 2.7863397955866533 - 3.290756411702287 - 2.87917779243724 - 3.381584519901575 - 15.872591558316572 - 5.641569931307615 - 0.9906130502255269'\n",
      "476 - pcr_whiten - 79 - 2.788581992413416 - 3.2907974403459606 - 2.8920652114123317 - 3.386980365902059 - 15.88855982881406 - 5.648875651906331 - 0.9906008943126939'\n",
      "477 - pcr - 86 - 2.7841864400820246 - 3.290701467942102 - 2.8948470525565706 - 3.3857634940265977 - 15.903460860514945 - 5.651269620134114 - 0.9905969110137559'\n",
      "478 - pcr_whiten - 81 - 2.7727067438779014 - 3.284162033173946 - 2.8896173694924663 - 3.379905783618802 - 16.021264850644062 - 5.669003769871456 - 0.9905674033456946'\n",
      "479 - pcr_whiten - 85 - 2.7819231190953264 - 3.28547112723857 - 2.8640073329661364 - 3.3785666194504045 - 16.073187492190343 - 5.676103184929062 - 0.9905555907025146'\n",
      "480 - pcr_s_w - 25 - 5.24645966919224 - 5.642536808542947 - 5.15247290753823 - 5.654544545083872 - 6.734861534950066 - 5.686126815623559 - 0.9905389124872247'\n",
      "481 - pcr_scale - 25 - 5.246038589612322 - 5.642358567654683 - 5.151663990411331 - 5.6552402039854215 - 6.736362862266778 - 5.686284473975849 - 0.9905386501611254'\n",
      "482 - pcr_whiten - 90 - 2.7775803992338424 - 3.27509070807573 - 2.8621517811149837 - 3.3978655410853174 - 16.12792470824173 - 5.687590908198763 - 0.9905364763987536'\n",
      "483 - pcr_whiten - 86 - 2.7813736531536066 - 3.2633830450126062 - 2.884690464222405 - 3.389660300579595 - 16.124782117216334 - 5.688245275292412 - 0.9905353876041243'\n",
      "484 - pcr - 83 - 2.792042085821202 - 3.286107896542051 - 2.8826579933010987 - 3.3957474828996377 - 16.133830036692938 - 5.697545936025442 - 0.990519912331065'\n",
      "485 - pcr_whiten - 80 - 2.8049279115467116 - 3.288583559687708 - 2.890887133691888 - 3.3840743277179506 - 16.144247421038724 - 5.702013549694823 - 0.9905124787149551'\n",
      "486 - plsr - 18 - 2.802497083972449 - 3.247216457378626 - 2.7900230040496035 - 3.3568955908144558 - 16.319090000719974 - 5.702609411874294 - 0.9905114872660465'\n",
      "487 - pcr_whiten - 91 - 2.784536156082546 - 3.2528043663300146 - 2.8714499751826277 - 3.3838914597286442 - 16.252006104036795 - 5.708400203692207 - 0.9905018520275205'\n",
      "488 - pcr_whiten - 87 - 2.777249589454582 - 3.2765397579207898 - 2.8780336733823972 - 3.3892579369755964 - 16.236884375926532 - 5.711056770608718 - 0.9904974317933443'\n",
      "489 - pcr_scale - 24 - 5.232232361877974 - 5.666621501136174 - 5.215188707223484 - 5.758337048104395 - 6.7268741160306424 - 5.719796726935387 - 0.9904828894705391'\n",
      "490 - pcr_s_w - 24 - 5.232144001210381 - 5.666556971651962 - 5.215571322583753 - 5.7585922230688045 - 6.726716923587796 - 5.719862240118105 - 0.9904827804638329'\n",
      "491 - pcr_whiten - 83 - 2.7839408981657434 - 3.297073201028389 - 2.8841346534058343 - 3.3883600613197076 - 16.491679148138783 - 5.768492540365585 - 0.9904018650109538'\n",
      "492 - pcr_scale - 23 - 5.242568374967141 - 5.788248756752716 - 5.371016033487789 - 5.813865134994083 - 6.721347730692901 - 5.787354871252774 - 0.9903704801739628'\n",
      "493 - pcr_s_w - 23 - 5.242411861683299 - 5.788257521498012 - 5.371057922989418 - 5.8138550210349935 - 6.721544183267723 - 5.787370949196067 - 0.9903704534220396'\n",
      "494 - pcr - 87 - 2.780413135231276 - 3.286145204523235 - 2.8802605878038854 - 3.383422987927667 - 16.61202713390688 - 5.787903435399963 - 0.9903695674237603'\n",
      "495 - pcr - 84 - 2.7620878868936423 - 3.2925791641453785 - 2.897064935113392 - 3.373553543795674 - 16.62600272316021 - 5.789705728103661 - 0.9903665686075983'\n",
      "496 - pcr - 88 - 2.7694363565364966 - 3.2691305398595247 - 2.866024381094056 - 3.3804992730733963 - 16.91196112334464 - 5.838846985423536 - 0.9902848029785389'\n",
      "497 - pcr_whiten - 96 - 2.7575498580195976 - 3.2515504147788192 - 2.8354537058829368 - 3.389049071645887 - 17.008935467159453 - 5.847939593715658 - 0.990269673881781'\n",
      "498 - pcr_whiten - 84 - 2.803868436340324 - 3.2901348981968654 - 2.8775820760385242 - 3.3727028612704824 - 16.904526013562755 - 5.849202976700284 - 0.9902675717519187'\n",
      "499 - pcr - 93 - 2.778778797160232 - 3.2605253156277443 - 2.8560181401785933 - 3.3909877224259475 - 16.985592986498446 - 5.85381432619042 - 0.9902598989752656'\n",
      "500 - pcr_whiten - 88 - 2.7959956091176434 - 3.2777980807993394 - 2.871954028452658 - 3.375987060634073 - 16.96121099634996 - 5.8560258925237685 - 0.9902562191729505'\n",
      "501 - pcr - 82 - 2.7933744348539054 - 3.286688108217832 - 2.875230205238457 - 3.396663821416952 - 16.97746863759574 - 5.865320548102625 - 0.9902407538918049'\n",
      "502 - pcr - 90 - 2.774029937445448 - 3.248790975005264 - 2.8804191092000893 - 3.3852076861524134 - 17.08002371511552 - 5.873122513942844 - 0.9902277722816546'\n",
      "503 - pcr - 100 - 2.755212621713767 - 3.230405892508086 - 2.8305549854971956 - 3.403245988902947 - 17.15295651887073 - 5.873899559080569 - 0.9902264793642984'\n",
      "504 - pcr_s_w - 22 - 5.392994409647557 - 5.789298795132328 - 5.450508610520944 - 5.829413868248861 - 6.975146349001271 - 5.887413212382321 - 0.9902039941365413'\n",
      "505 - pcr_scale - 22 - 5.393324830960617 - 5.78931209813145 - 5.450484923761532 - 5.829407322730414 - 6.975185450069721 - 5.88748375124729 - 0.9902038767676544'\n",
      "506 - pcr - 91 - 2.786253468423701 - 3.2662072501188715 - 2.8586814837603907 - 3.39225750909316 - 17.141541719322497 - 5.888416420796767 - 0.9902023249084515'\n",
      "507 - pcr_whiten - 94 - 2.7639126694824645 - 3.2589985297163295 - 2.8273888465115444 - 3.366095461738399 - 17.34045670230504 - 5.910791154127672 - 0.9901650958214151'\n",
      "508 - pcr_whiten - 89 - 2.775069289137507 - 3.2771331693031622 - 2.880485276032562 - 3.3867959685855253 - 17.258996813573507 - 5.915118877023195 - 0.9901578949681149'\n",
      "509 - pcr_whiten - 100 - 2.7671510566462674 - 3.2478448233751163 - 2.8553966601256526 - 3.402771330511198 - 17.332638551565694 - 5.92057845037678 - 0.9901488108405611'\n",
      "510 - pcr_whiten - 98 - 2.7598205303281667 - 3.2536549184861676 - 2.8272813942042747 - 3.387490507044896 - 17.383347522991226 - 5.921736557261723 - 0.9901468838785106'\n",
      "511 - pcr - 89 - 2.7934411509818213 - 3.263064168075169 - 2.859798568365385 - 3.3942755427269713 - 17.319735631978737 - 5.925484144995953 - 0.9901406483060964'\n",
      "512 - pcr - 92 - 2.7823536458639415 - 3.2793072797962073 - 2.8556184938036964 - 3.3814108782508847 - 17.370163502011483 - 5.933190867756446 - 0.9901278251699198'\n",
      "513 - pcr_scale - 20 - 5.4643599433910515 - 6.029244689572096 - 5.576519896640859 - 5.821230222943697 - 6.783069563347375 - 5.934847291755386 - 0.9901250690631849'\n",
      "514 - pcr_s_w - 20 - 5.4643599303254895 - 6.029243897169741 - 5.576543226750167 - 5.8212471159128105 - 6.783127709940888 - 5.934866800617847 - 0.9901250366025908'\n",
      "515 - pcr_s_w - 21 - 5.40287785797021 - 5.831969560704546 - 5.458979631266924 - 5.803568057269151 - 7.180931756278096 - 5.935601800651568 - 0.9901238136436477'\n",
      "516 - pcr_scale - 21 - 5.402912034501016 - 5.831972845886646 - 5.4589407930520455 - 5.803554748444285 - 7.180980827552696 - 5.935608680209013 - 0.9901238021968233'\n",
      "517 - pcr - 95 - 2.7596834065235867 - 3.2473009187515 - 2.853597795166849 - 3.385846391942414 - 17.44410681596656 - 5.937520846152998 - 0.9901206205637149'\n",
      "518 - pcr_whiten - 97 - 2.7564455938080377 - 3.2564855457606674 - 2.84618503854093 - 3.368009244980546 - 17.46509483557487 - 5.937858358868059 - 0.9901200589798042'\n",
      "519 - pcr_whiten - 95 - 2.7599804923311098 - 3.2374135571687557 - 2.84251840185545 - 3.3764315184787845 - 17.481920117687352 - 5.939065331329148 - 0.9901180507108277'\n",
      "520 - pcr - 98 - 2.7819496485452486 - 3.2321089583886677 - 2.859523344765954 - 3.37844100000516 - 17.450822862425568 - 5.939983158059966 - 0.9901165235484369'\n",
      "521 - pcr_whiten - 92 - 2.773988663525142 - 3.2668191659265116 - 2.8482773840719706 - 3.3903571734571085 - 17.465785211921347 - 5.948460493490953 - 0.9901024181978199'\n",
      "522 - plsr - 7 - 5.234029201476464 - 5.145096612203966 - 4.841440168474167 - 5.509237388735012 - 9.076960305600016 - 5.961198562339783 - 0.9900812234570006'\n",
      "523 - pcr - 97 - 2.771638517425102 - 3.261796170547032 - 2.8342534574021907 - 3.3782167551358637 - 17.565779201270665 - 5.961748402562249 - 0.9900803085835496'\n",
      "524 - pcr_whiten - 99 - 2.7635160106015433 - 3.2295496258848218 - 2.845398292453448 - 3.385836041200861 - 17.64846810797684 - 5.973958725332376 - 0.9900599919539644'\n",
      "525 - pcr - 96 - 2.7681172110922607 - 3.2652728224825083 - 2.840661597404491 - 3.3844907654453085 - 17.75675192557446 - 6.002462307498565 - 0.9900125651388324'\n",
      "526 - pcr - 94 - 2.774006756145466 - 3.2670960371828675 - 2.856967019609719 - 3.3825924209389115 - 17.751601165634494 - 6.005856215403043 - 0.9900069180506235'\n",
      "527 - pcr_whiten - 93 - 2.7664714506963635 - 3.2493097314745576 - 2.876546287235846 - 3.3774482111420867 - 17.774233388828375 - 6.0082023509863545 - 0.9900030143399272'\n",
      "528 - pcr - 99 - 2.7528237209027258 - 3.2318033811473232 - 2.8298142414959666 - 3.375703441367005 - 17.903729335123018 - 6.0181702572327405 - 0.9899864288439694'\n",
      "529 - pcr_s_w - 19 - 5.508769334503575 - 6.167155269328543 - 5.679620616364381 - 6.12235751410529 - 6.9435139253817635 - 6.084234126776899 - 0.989876505855711'\n",
      "530 - pcr_scale - 19 - 5.508759194186853 - 6.167157734890696 - 5.679633740308773 - 6.122338199158942 - 6.9435389813656085 - 6.084236363608733 - 0.9898765021338697'\n",
      "531 - plsr_scale - 5 - 5.337369594912462 - 6.030202068338492 - 5.369825607619889 - 5.647329248956136 - 8.083844978254579 - 6.093632412187628 - 0.9898608681459615'\n",
      "532 - plsr - 6 - 5.781513449726835 - 5.593867938845555 - 5.273567307189637 - 6.355278699270272 - 7.545028017835381 - 6.109766751692935 - 0.9898340223855748'\n",
      "533 - pcr_s_w - 18 - 5.663450507565795 - 6.184464564671885 - 5.729483377040065 - 6.172006501233903 - 6.924165619416945 - 6.134672013191099 - 0.9897925827789317'\n",
      "534 - pcr_scale - 18 - 5.6634460481768505 - 6.1844526356104055 - 5.729472526907254 - 6.171982179077028 - 6.924219684330411 - 6.134672512288843 - 0.9897925819484882'\n",
      "535 - plsr - 19 - 2.7450698838421537 - 3.1668882613400586 - 2.792002370933062 - 3.3082223690617756 - 18.79037768543734 - 6.159871975680702 - 0.9897506528223613'\n",
      "536 - pcr_s_w - 17 - 5.646521188930549 - 6.331366386948305 - 5.85630541189906 - 6.223930370401382 - 6.919560315206662 - 6.195495465610723 - 0.9896913792664476'\n",
      "537 - pcr_scale - 17 - 5.646553028721408 - 6.33137489874845 - 5.856330641276295 - 6.223934601444064 - 6.919637427266962 - 6.195524848585372 - 0.9896913303764204'\n",
      "538 - plsr - 22 - 2.5772348998687 - 3.0837705972369815 - 2.7008509048237386 - 3.1256749109080997 - 19.52517756795832 - 6.20186817667303 - 0.9896807757785182'\n",
      "539 - pcr_whiten - 11 - 5.719134525479344 - 5.901581486194806 - 5.469032556501172 - 6.294810486875493 - 8.050547694953423 - 6.286926131594103 - 0.989539248728338'\n",
      "540 - pcr - 11 - 5.719134525478846 - 5.9015814861965055 - 5.469032556501605 - 6.294810486876256 - 8.050547694953513 - 6.2869261315946 - 0.9895392487283372'\n",
      "541 - plsr - 5 - 6.1907083983531574 - 6.13527932139438 - 5.661647462026362 - 6.7482662689257715 - 6.705009645922251 - 6.288157211661691 - 0.9895372003469648'\n",
      "542 - pcr_scale - 16 - 5.9902416739146895 - 6.382872969426697 - 5.887396369782689 - 6.2162427600242705 - 7.539330678631194 - 6.403173610378144 - 0.9893458257524569'\n",
      "543 - pcr_s_w - 16 - 5.990240647455607 - 6.382872430397183 - 5.88746209681958 - 6.2162899362290585 - 7.539332721092284 - 6.403196281734845 - 0.9893457880298213'\n",
      "544 - pcr_whiten - 8 - 6.6594447753791535 - 6.54692942542941 - 6.118748416490256 - 7.23289999320561 - 6.7182364070813945 - 6.6552414030570946 - 0.9889264127630851'\n",
      "545 - pcr - 8 - 6.659444775379159 - 6.546929425429421 - 6.118748416490256 - 7.232899993205603 - 6.7182364070814025 - 6.655241403057097 - 0.9889264127630851'\n",
      "546 - plsr - 21 - 2.599563285911879 - 3.1100431354335076 - 2.7909566040104195 - 3.1631833618554643 - 21.69292074472178 - 6.670571035212874 - 0.9889009059469224'\n",
      "547 - pcr - 10 - 5.918801401024682 - 6.1768794884391705 - 5.750518707760471 - 6.637528995248562 - 9.19890909569919 - 6.7363899653026325 - 0.988791390510885'\n",
      "548 - pcr_whiten - 10 - 5.918801401024666 - 6.176879488439202 - 5.750518707760484 - 6.637528995248654 - 9.198909095699182 - 6.7363899653026555 - 0.9887913905108849'\n",
      "549 - plsr - 20 - 2.6671366886039793 - 3.1243438466173896 - 2.769827014649314 - 3.208312667732252 - 22.271350774247942 - 6.80741264544753 - 0.9886732166090304'\n",
      "550 - plsr - 4 - 6.786406196458901 - 6.936194732543566 - 6.335091166107497 - 7.4865757910697095 - 6.668089049299173 - 6.842475148397687 - 0.9886148764735418'\n",
      "551 - pcr - 7 - 6.823451075059412 - 7.031056036697449 - 6.359303115700182 - 7.6033609163454425 - 6.834653755295386 - 6.930364358280632 - 0.9884686385275561'\n",
      "552 - pcr_whiten - 7 - 6.823451075059405 - 7.031056036697437 - 6.359303115700178 - 7.603360916345455 - 6.834653755295388 - 6.930364358280632 - 0.9884686385275561'\n",
      "553 - pcr_s_w - 15 - 6.302311228820965 - 6.851493162460278 - 6.514244356451207 - 7.118410454780858 - 7.936243451909713 - 6.944467091345002 - 0.9884451731360835'\n",
      "554 - pcr_scale - 15 - 6.302310735193374 - 6.851513164556428 - 6.514244137049131 - 7.118414746187443 - 7.936248581809341 - 6.9444728342210125 - 0.9884451635805717'\n",
      "555 - pcr_whiten - 6 - 7.001961431877877 - 7.209051168040363 - 6.450415526624993 - 7.775702531079177 - 6.896349766584355 - 7.066703837581089 - 0.9882417846801246'\n",
      "556 - pcr - 6 - 7.001961431877896 - 7.2090511680403555 - 6.450415526624994 - 7.775702531079188 - 6.896349766584353 - 7.066703837581094 - 0.9882417846801246'\n",
      "557 - pcr - 9 - 6.19305246797006 - 6.485270053132975 - 5.991531627899181 - 7.213745949709079 - 9.737749971939847 - 7.124113180579772 - 0.9881462618689433'\n",
      "558 - pcr_whiten - 9 - 6.193052467970067 - 6.4852700531329885 - 5.9915316278991755 - 7.213745949709094 - 9.73774997193982 - 7.124113180579774 - 0.9881462618689433'\n",
      "559 - pcr_s_w - 14 - 6.781736115304873 - 8.042937647895151 - 7.546376538683799 - 8.069856412716225 - 9.679434604244307 - 8.023946064132002 - 0.986649039254286'\n",
      "560 - pcr_scale - 14 - 6.781740343700101 - 8.042942334978294 - 7.546373891985349 - 8.06985616308959 - 9.679435413417727 - 8.023947430415017 - 0.9866490369809419'\n",
      "561 - pcr_whiten - 5 - 8.070901015205088 - 8.468715619629542 - 7.752240405485092 - 8.856722494956347 - 8.066792554012027 - 8.243079758229085 - 0.98628442497042'\n",
      "562 - pcr - 5 - 8.070901015205102 - 8.468715619629542 - 7.752240405485085 - 8.856722494956344 - 8.066792554012027 - 8.243079758229086 - 0.98628442497042'\n",
      "563 - plsr - 3 - 8.299170783598791 - 8.760291090659022 - 8.019336050104645 - 9.219056658504153 - 8.701970295227202 - 8.59995094564703 - 0.9856906306980742'\n",
      "564 - pcr - 4 - 8.94909410109938 - 9.133222488327787 - 8.611012667738954 - 9.746853628692556 - 9.178222128182933 - 9.123664518048415 - 0.9848192291094738'\n",
      "565 - pcr_whiten - 4 - 8.949094101099382 - 9.133222488327789 - 8.611012667738954 - 9.746853628692575 - 9.178222128182963 - 9.123664518048427 - 0.9848192291094737'\n",
      "566 - plsr_scale - 4 - 7.141759560305464 - 7.683783624175332 - 7.38709683115962 - 7.424794666546132 - 16.8707616380919 - 9.301261943306226 - 0.9845237265931052'\n",
      "567 - plsr - 2 - 8.97359510506624 - 9.6469645013587 - 9.23813025941362 - 10.743029237662146 - 9.674862413817277 - 9.655247378873055 - 0.9839347338933744'\n",
      "568 - pcr_scale - 13 - 9.670257112287134 - 8.232367764393107 - 7.549483279771231 - 8.106380744411323 - 20.643290511327645 - 10.839978526576303 - 0.9819634720079143'\n",
      "569 - pcr_s_w - 13 - 9.670273489356752 - 8.232334210532445 - 7.549481899865761 - 8.106387422018846 - 20.643388343342266 - 10.839995712011811 - 0.9819634434132463'\n",
      "570 - plsr_scale - 3 - 9.740009212316515 - 10.237383566337018 - 11.098995476399443 - 10.398406486849115 - 21.262981073938505 - 12.547044004803388 - 0.9791231034401281'\n",
      "571 - pcr_whiten - 3 - 12.837170535598098 - 13.338798001155157 - 12.31884041934114 - 13.692357789075793 - 13.997622927075899 - 13.23692817542683 - 0.9779752123143072'\n",
      "572 - pcr - 3 - 12.83717053559811 - 13.33879800115516 - 12.318840419341148 - 13.692357789075823 - 13.99762292707595 - 13.23692817542685 - 0.9779752123143071'\n",
      "573 - pcr_scale - 8 - 14.109195210986039 - 15.891265661577203 - 16.72376327563654 - 15.379800332209955 - 27.92998752051041 - 18.00620180650366 - 0.970039667318721'\n",
      "574 - pcr_s_w - 8 - 14.109195243647616 - 15.891264105813303 - 16.723764827527418 - 15.37980038956087 - 27.92999139728261 - 18.006202598775545 - 0.9700396660004681'\n",
      "575 - pcr_s_w - 9 - 14.131719162114065 - 16.061036223292888 - 16.738361061770338 - 15.099888234076282 - 30.027771270114222 - 18.411092909510963 - 0.9693659732062065'\n",
      "576 - pcr_scale - 9 - 14.131719074006055 - 16.061035942313477 - 16.738360984137774 - 15.099888643563288 - 30.027772242734166 - 18.411093096514122 - 0.969365972895054'\n",
      "577 - pcr_scale - 7 - 14.782315631878738 - 16.614344100298222 - 17.87805625629894 - 15.934304279840482 - 28.74194160244513 - 18.789574742808302 - 0.9687362212040207'\n",
      "578 - pcr_s_w - 7 - 14.782315682076227 - 16.61434405751291 - 17.878056320418366 - 15.934304470223097 - 28.741943719529182 - 18.78957521851365 - 0.9687362204124995'\n",
      "579 - plsr_scale - 2 - 15.319223596771787 - 16.850873736169984 - 17.24363015446805 - 16.23572168772845 - 28.848666308770316 - 18.89906085658389 - 0.9685540483933444'\n",
      "580 - pcr_scale - 10 - 13.632710918873732 - 16.09874452353171 - 16.549648046770663 - 14.981164539333342 - 33.94689114889297 - 19.040997615721338 - 0.9683178812899675'\n",
      "581 - pcr_s_w - 10 - 13.632710917209431 - 16.09874454261939 - 16.549648228573073 - 14.981164126317564 - 33.946891851219476 - 19.04099771341086 - 0.9683178811274229'\n",
      "582 - pcr_s_w - 6 - 15.064643498824797 - 16.335745005182563 - 17.449892044581947 - 15.850889846638701 - 36.88192708176947 - 20.315697316964936 - 0.9661969216601476'\n",
      "583 - pcr_scale - 6 - 15.06464312846911 - 16.335746223030444 - 17.44989279186883 - 15.85089004995927 - 36.88192913577328 - 20.315698087316377 - 0.9661969203783678'\n",
      "584 - pcr_scale - 5 - 17.72206940921658 - 17.63459696152566 - 20.620676683259067 - 20.621847013154795 - 38.049238520287176 - 22.928636705796265 - 0.9618492788753639'\n",
      "585 - pcr_s_w - 5 - 17.722071507960166 - 17.634591004186632 - 20.620677547062723 - 20.6218465090174 - 38.049245096722395 - 22.928637320789115 - 0.9618492778520836'\n",
      "586 - pcr_scale - 12 - 12.060949650353363 - 15.873569605798378 - 16.506415246107405 - 15.292771393635842 - 58.18227141189031 - 23.581274579448895 - 0.9607633614772831'\n",
      "587 - pcr_s_w - 12 - 12.060948365223314 - 15.873569745239626 - 16.506415429315357 - 15.292770955663912 - 58.18227381969008 - 23.581274780763618 - 0.9607633611423176'\n",
      "588 - pcr_scale - 11 - 12.358806757437993 - 15.849102136122603 - 16.638185964454365 - 15.265226343608683 - 59.19412914768845 - 23.859140981643666 - 0.9603010224487547'\n",
      "589 - pcr_s_w - 11 - 12.358807217817331 - 15.849102244035018 - 16.638185645157684 - 15.265226138534347 - 59.19418179329838 - 23.859151517501502 - 0.96030100491825'\n",
      "590 - pcr_s_w - 4 - 23.228766560628085 - 25.033324190493186 - 26.4926843510797 - 25.184224122433744 - 34.76343906124506 - 26.939926442177626 - 0.9551749354311192'\n",
      "591 - pcr_scale - 4 - 23.22877013301555 - 25.033324659707457 - 26.49269262746069 - 25.184222676903392 - 34.763435366371304 - 26.93992787781027 - 0.9551749330423849'\n",
      "592 - plsr - 1 - 29.98899917203568 - 31.143509922108578 - 30.311268741765097 - 31.687264644986186 - 31.465722835927046 - 30.919282528303334 - 0.9485537260567726'\n",
      "593 - pcr_whiten - 2 - 30.43499412512203 - 31.62230875298492 - 30.772024371142408 - 32.178062516971345 - 31.895756133771883 - 31.380558868823734 - 0.9477862131315868'\n",
      "594 - pcr - 2 - 30.434994125122017 - 31.62230875298492 - 30.772024371142397 - 32.17806251697134 - 31.89575613377192 - 31.380558868823734 - 0.9477862131315868'\n",
      "595 - pcr - 1 - 30.47657908221457 - 31.638222459809523 - 30.805575081711993 - 32.1734240935544 - 31.980576384088604 - 31.414804011037052 - 0.9477292329941623'\n",
      "596 - pcr_whiten - 1 - 30.476579082214585 - 31.638222459809516 - 30.805575081712014 - 32.173424093554395 - 31.980576384088618 - 31.41480401103706 - 0.9477292329941623'\n",
      "597 - pcr_s_w - 3 - 30.03059873098187 - 32.811523245137145 - 32.04115133559899 - 32.977961577906775 - 37.8750216906645 - 33.14690649178139 - 0.9448472056172157'\n",
      "598 - pcr_scale - 3 - 30.030598625350432 - 32.81152327076862 - 32.041154697860335 - 32.97796169507201 - 37.87502059452096 - 33.14690695233799 - 0.9448472048509003'\n",
      "599 - pcr_s_w - 2 - 57.98749901035426 - 57.85649750491954 - 58.81359675310727 - 58.67899439605261 - 71.17354746764032 - 60.90143173501074 - 0.898666738540713'\n",
      "600 - pcr_scale - 2 - 57.98749898459532 - 57.85649767828005 - 58.813598016198256 - 58.67899436137093 - 71.17354673620858 - 60.901431863915555 - 0.8986667383262296'\n",
      "601 - plsr_scale - 1 - 60.28923076084068 - 62.02179566066535 - 63.211701789643506 - 61.84323686206212 - 65.4171232157179 - 62.55633777275854 - 0.8959131575256833'\n",
      "602 - pcr_scale - 1 - 76.60305816384424 - 78.4231679806558 - 80.18854728283789 - 78.77341487721104 - 80.14228786329245 - 78.82583295187405 - 0.8688425130132629'\n",
      "603 - pcr_s_w - 1 - 76.60305816384715 - 78.42316798066103 - 80.18854728282963 - 78.77341487720932 - 80.14228786329915 - 78.82583295187504 - 0.8688425130132612'\n"
     ]
    }
   ],
   "source": [
    "scores_df = pd.concat((scores_df_lr,scores_df_pcr,scores_df_pls))\n",
    "scores_df.to_csv(log_dir / f\"scores.csv\", index=False)\n",
    "\n",
    "scores_df_final = pd.concat((scores_df_lr_final,scores_df_pcr_final,scores_df_pls_final))\n",
    "scores_df_final.to_csv(log_dir / f\"scores_final.csv\", index=False)\n",
    "\n",
    "summary_logger.info(\"-----------------------------\\n\"\n",
    "                    \"Rankings\\n\"\n",
    "                    \"-------------------------------\")\n",
    "scores_df_sorted= scores_df.sort_values(\"MSE\",ascending=True)\n",
    "summary_logger.info(f\"Rank - \" +\" - \".join(list(scores_df_sorted.columns)))\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    summary_logger.info(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%plot supervised\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Number of Components\")\n",
    "ax.set_ylabel(\"Loss (MSE)\")\n",
    "ax.set_title(\"PCR and PLSR by number of components\")\n",
    "\n",
    "series_labels = scores_df_lr['model'].unique()\n",
    "for name in series_labels:\n",
    "    subset = scores_df_lr[scores_df_lr[\"model\"]==name]\n",
    "    y = [subset[\"MSE\"].tolist()[0] for _ in n_comps]\n",
    "    x = n_comps\n",
    "    ax.plot(x,y,label = f\"{name}\")\n",
    "\n",
    "series_labels = scores_df_pls['model'].unique()\n",
    "for name in series_labels:\n",
    "    subset = scores_df_pls[scores_df_pls[\"model\"]==name]\n",
    "    ax.plot(subset[\"n_comp\"],subset[\"MSE\"],label = f\"{name}\")\n",
    "\n",
    "series_labels = scores_df_pcr['model'].unique()\n",
    "for name in series_labels:\n",
    "    subset = scores_df_pcr[scores_df_pcr[\"model\"]==name]\n",
    "    ax.plot(subset[\"n_comp\"],subset[\"MSE\"],label = f\"{name}\")\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"mse_plot.png\",bbox_inches='tight')\n",
    "\n",
    "#ax.set_ylim(200,300)\n",
    "ax.set_ylim(0,20)\n",
    "plt.savefig(log_dir / f\"mse_plot_compressed.png\",bbox_inches='tight')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Number of Components\")\n",
    "ax.set_ylabel(\"R2 Score)\")\n",
    "ax.set_title(\"PCR and PLSR by number of components\")\n",
    "\n",
    "series_labels = scores_df_lr['model'].unique()\n",
    "for name in series_labels:\n",
    "    subset = scores_df_lr[scores_df_lr[\"model\"]==name]\n",
    "    y = [subset[\"R2\"].tolist()[0] for _ in n_comps]\n",
    "    x = n_comps\n",
    "    ax.plot(x,y,label = f\"{name}\")\n",
    "\n",
    "series_labels = scores_df_pls['model'].unique()\n",
    "for name in series_labels:\n",
    "    subset = scores_df_pls[scores_df_pls[\"model\"]==name]\n",
    "    ax.plot(subset[\"n_comp\"],subset[\"R2\"],label = f\"{name}\")\n",
    "\n",
    "series_labels = scores_df_pcr['model'].unique()\n",
    "for name in series_labels:\n",
    "    subset = scores_df_pcr[scores_df_pcr[\"model\"]==name]\n",
    "    ax.plot(subset[\"n_comp\"],subset[\"R2\"],label = f\"{name}\")\n",
    "\n",
    "ax.set_ylim(0,1)\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot.png\",bbox_inches='tight')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (lazydeep)",
   "language": "python",
   "name": "pycharm-12fcba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
