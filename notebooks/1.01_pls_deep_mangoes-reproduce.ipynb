{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detected is GeForce GTX 970\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "# set seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils as ut\n",
    "import experiment as ex\n",
    "from evaluation import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import random\n",
    "#define fixed_hyperparams and create a config gen\n",
    "from configurations import RandomConfigGen, Configuration\n",
    "from torch import nn\n",
    "from deep_net import RandomNet\n",
    "from experiment import run_experiment\n",
    "import regex as re\n",
    "from pathlib import *\n",
    "from sk_models import PLSRegression\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "random_state = np.random.RandomState(seed)\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"GPU detected is {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory is D:\\workspace\\lazydeep\\experiments\\-1.1\\mango_684_990\n"
     ]
    }
   ],
   "source": [
    "#setup input and outpu t formats, load data\n",
    "\n",
    "#we need to set parametesr\n",
    "file_name = \"mango_684_990.csv\"#fitlered=513-1050 #\"mango_684_990.csv\" #\"mango_729_975.csv\" \n",
    "id_cols =['Set','Season','Region','Date','Type','Cultivar','Pop','Temp',\"FruitID\"]#\n",
    "output_cols = ['DM']\n",
    "\n",
    "data_path = Path('D:/workspace/lazydeep/data/soil_data/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/-1.1\") #1.01/\")\n",
    "if not log_path.exists():\n",
    "    log_path.mkdir()\n",
    "\n",
    "data_file = data_path / file_name\n",
    "log_dir = log_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "print(f\"Output directory is {log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is (11691, 113)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "nrow, ncol = data.shape\n",
    "n_features = ncol - 1-len(id_cols)\n",
    "n_comps = [i for i in range(1,min(101,n_features))]\n",
    "data = ut.sample_data(data,random_state)\n",
    "dataset = ut.TabularDataset(data,id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "eval = MangoesSplitter(preprocessing=None,tensorboard=None,time=True,random_state=random_state)\n",
    "print(f\"Dataset shape is {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup logging and tensorboard outputs\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set logging, in this case the root logger\n",
    "ut.setup_logger(logger_name=\"log\",file_name=log_dir/\"log.txt\")\n",
    "ut.setup_logger(logger_name=\"test_log\",file_name=log_dir/\"test_log.txt\")\n",
    "ut.setup_logger(logger_name=\"summary\",file_name=log_dir/\"summary.txt\")\n",
    "tb = SummaryWriter(log_dir/\"tb\")\n",
    "summary_logger = logging.getLogger(\"summary\")\n",
    "#step 1, run pls, set up pls - that runs best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.preprocessing= PLSRegression(n_components=59)\n",
    "selected_comps=59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the deep learners\n",
    "The following cells setup our models and run a train-test evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup experiment\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Experiment'\n",
      "Seed: 1'\n",
      "bs: 32'\n",
      "epochs: 100'\n",
      "--------------------'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5879 - Val 1929 - Test 1905-----------------------------------'\n",
      "Training extractors on 5879 instances, validating on 1929 instances, for 100 epochs'\n",
      "\n",
      "--- EPOCH 0---'\n",
      "Extractor Train Losses are random_59:22.3012(-0.751007)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:1.016'\n",
      "Testing (val) took 0:00:00.296002'\n",
      "Epoch 0 finished in 0:00:01.388361 '\n",
      "\n",
      "--- EPOCH 1---'\n",
      "Extractor Train Losses are random_59:1.2696(-0.773283)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:1.3452'\n",
      "Testing (val) took 0:00:00.319002'\n",
      "Epoch 1 finished in 0:00:01.328001 '\n",
      "\n",
      "--- EPOCH 2---'\n",
      "Extractor Train Losses are random_59:1.2024(-0.79556)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:1.264'\n",
      "Testing (val) took 0:00:00.294000'\n",
      "Epoch 2 finished in 0:00:01.287594 '\n",
      "\n",
      "--- EPOCH 3---'\n",
      "Extractor Train Losses are random_59:1.0683(-0.817836)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.8933'\n",
      "Testing (val) took 0:00:00.290001'\n",
      "Epoch 3 finished in 0:00:01.263936 '\n",
      "\n",
      "--- EPOCH 4---'\n",
      "Extractor Train Losses are random_59:0.9179(-0.840113)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.7118'\n",
      "Testing (val) took 0:00:00.302003'\n",
      "Epoch 4 finished in 0:00:01.306001 '\n",
      "\n",
      "--- EPOCH 5---'\n",
      "Extractor Train Losses are random_59:0.8381(-0.862389)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.7554'\n",
      "Testing (val) took 0:00:00.274002'\n",
      "Epoch 5 finished in 0:00:01.272998 '\n",
      "\n",
      "--- EPOCH 6---'\n",
      "Extractor Train Losses are random_59:0.8271(-0.884665)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6678'\n",
      "Testing (val) took 0:00:00.291001'\n",
      "Epoch 6 finished in 0:00:01.259422 '\n",
      "\n",
      "--- EPOCH 7---'\n",
      "Extractor Train Losses are random_59:0.7842(-0.906942)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.8821'\n",
      "Testing (val) took 0:00:00.307001'\n",
      "Epoch 7 finished in 0:00:01.314183 '\n",
      "\n",
      "--- EPOCH 8---'\n",
      "Extractor Train Losses are random_59:0.7447(-0.929218)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.9505'\n",
      "Testing (val) took 0:00:00.300999'\n",
      "Epoch 8 finished in 0:00:01.280000 '\n",
      "\n",
      "--- EPOCH 9---'\n",
      "Extractor Train Losses are random_59:0.7389(-0.951495)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.7061'\n",
      "Testing (val) took 0:00:00.307000'\n",
      "Epoch 9 finished in 0:00:01.302101 '\n",
      "\n",
      "--- EPOCH 10---'\n",
      "Extractor Train Losses are random_59:0.7078(-0.973771)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6767'\n",
      "Testing (val) took 0:00:00.304151'\n",
      "Epoch 10 finished in 0:00:01.328234 '\n",
      "\n",
      "--- EPOCH 11---'\n",
      "Extractor Train Losses are random_59:0.6762(-0.996047)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6814'\n",
      "Testing (val) took 0:00:00.299999'\n",
      "Epoch 11 finished in 0:00:01.305015 '\n",
      "\n",
      "--- EPOCH 12---'\n",
      "Extractor Train Losses are random_59:0.6592(-1.018324)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6395'\n",
      "Testing (val) took 0:00:00.292002'\n",
      "Epoch 12 finished in 0:00:01.265609 '\n",
      "\n",
      "--- EPOCH 13---'\n",
      "Extractor Train Losses are random_59:0.6614(-1.0406)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6955'\n",
      "Testing (val) took 0:00:00.308190'\n",
      "Epoch 13 finished in 0:00:01.308190 '\n",
      "\n",
      "--- EPOCH 14---'\n",
      "Extractor Train Losses are random_59:0.6433(-1.062877)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6901'\n",
      "Testing (val) took 0:00:00.287996'\n",
      "Epoch 14 finished in 0:00:01.311000 '\n",
      "\n",
      "--- EPOCH 15---'\n",
      "Extractor Train Losses are random_59:0.6414(-1.085153)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6633'\n",
      "Testing (val) took 0:00:00.293001'\n",
      "Epoch 15 finished in 0:00:01.339101 '\n",
      "\n",
      "--- EPOCH 16---'\n",
      "Extractor Train Losses are random_59:0.6321(-1.107429)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6334'\n",
      "Testing (val) took 0:00:00.283575'\n",
      "Epoch 16 finished in 0:00:01.315031 '\n",
      "\n",
      "--- EPOCH 17---'\n",
      "Extractor Train Losses are random_59:0.6091(-1.129706)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6286'\n",
      "Testing (val) took 0:00:00.290952'\n",
      "Epoch 17 finished in 0:00:01.287091 '\n",
      "\n",
      "--- EPOCH 18---'\n",
      "Extractor Train Losses are random_59:0.6195(-1.151982)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6185'\n",
      "Testing (val) took 0:00:00.314002'\n",
      "Epoch 18 finished in 0:00:01.311141 '\n",
      "\n",
      "--- EPOCH 19---'\n",
      "Extractor Train Losses are random_59:0.6256(-1.174259)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.604'\n",
      "Testing (val) took 0:00:00.296521'\n",
      "Epoch 19 finished in 0:00:01.325035 '\n",
      "\n",
      "--- EPOCH 20---'\n",
      "Extractor Train Losses are random_59:0.6008(-1.196535)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6266'\n",
      "Testing (val) took 0:00:00.301001'\n",
      "Epoch 20 finished in 0:00:01.297082 '\n",
      "\n",
      "--- EPOCH 21---'\n",
      "Extractor Train Losses are random_59:0.581(-1.218811)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6365'\n",
      "Testing (val) took 0:00:00.282997'\n",
      "Epoch 21 finished in 0:00:01.306279 '\n",
      "\n",
      "--- EPOCH 22---'\n",
      "Extractor Train Losses are random_59:0.5839(-1.241088)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6499'\n",
      "Testing (val) took 0:00:00.282002'\n",
      "Epoch 22 finished in 0:00:01.268002 '\n",
      "\n",
      "--- EPOCH 23---'\n",
      "Extractor Train Losses are random_59:0.5742(-1.263364)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6589'\n",
      "Testing (val) took 0:00:00.298033'\n",
      "Epoch 23 finished in 0:00:01.265136 '\n",
      "\n",
      "--- EPOCH 24---'\n",
      "Extractor Train Losses are random_59:0.5758(-1.285641)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.8246'\n",
      "Testing (val) took 0:00:00.312999'\n",
      "Epoch 24 finished in 0:00:01.285098 '\n",
      "\n",
      "--- EPOCH 25---'\n",
      "Extractor Train Losses are random_59:0.5604(-1.307917)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.7336'\n",
      "Testing (val) took 0:00:00.289001'\n",
      "Epoch 25 finished in 0:00:01.252576 '\n",
      "\n",
      "--- EPOCH 26---'\n",
      "Extractor Train Losses are random_59:0.5437(-1.330193)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.7183'\n",
      "Testing (val) took 0:00:00.303998'\n",
      "Epoch 26 finished in 0:00:01.270001 '\n",
      "\n",
      "--- EPOCH 27---'\n",
      "Extractor Train Losses are random_59:0.5438(-1.35247)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.695'\n",
      "Testing (val) took 0:00:00.285082'\n",
      "Epoch 27 finished in 0:00:01.262082 '\n",
      "\n",
      "--- EPOCH 28---'\n",
      "Extractor Train Losses are random_59:0.5419(-1.374746)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.7337'\n",
      "Testing (val) took 0:00:00.324000'\n",
      "Epoch 28 finished in 0:00:01.324996 '\n",
      "\n",
      "--- EPOCH 29---'\n",
      "Extractor Train Losses are random_59:0.5354(-1.397022)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.589'\n",
      "Testing (val) took 0:00:00.342998'\n",
      "Epoch 29 finished in 0:00:01.344133 '\n",
      "\n",
      "--- EPOCH 30---'\n",
      "Extractor Train Losses are random_59:0.5312(-1.419299)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.595'\n",
      "Testing (val) took 0:00:00.293090'\n",
      "Epoch 30 finished in 0:00:01.286089 '\n",
      "\n",
      "--- EPOCH 31---'\n",
      "Extractor Train Losses are random_59:0.5217(-1.441575)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5798'\n",
      "Testing (val) took 0:00:00.278001'\n",
      "Epoch 31 finished in 0:00:01.278189 '\n",
      "\n",
      "--- EPOCH 32---'\n",
      "Extractor Train Losses are random_59:0.5286(-1.463852)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5931'\n",
      "Testing (val) took 0:00:00.284001'\n",
      "Epoch 32 finished in 0:00:01.352642 '\n",
      "\n",
      "--- EPOCH 33---'\n",
      "Extractor Train Losses are random_59:0.509(-1.486128)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5792'\n",
      "Testing (val) took 0:00:00.283000'\n",
      "Epoch 33 finished in 0:00:01.256114 '\n",
      "\n",
      "--- EPOCH 34---'\n",
      "Extractor Train Losses are random_59:0.5085(-1.508404)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5506'\n",
      "Testing (val) took 0:00:00.303000'\n",
      "Epoch 34 finished in 0:00:01.313000 '\n",
      "\n",
      "--- EPOCH 35---'\n",
      "Extractor Train Losses are random_59:0.5017(-1.530681)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5858'\n",
      "Testing (val) took 0:00:00.295001'\n",
      "Epoch 35 finished in 0:00:01.329224 '\n",
      "\n",
      "--- EPOCH 36---'\n",
      "Extractor Train Losses are random_59:0.4961(-1.552957)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.574'\n",
      "Testing (val) took 0:00:00.301999'\n",
      "Epoch 36 finished in 0:00:01.306000 '\n",
      "\n",
      "--- EPOCH 37---'\n",
      "Extractor Train Losses are random_59:0.4924(-1.575234)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.718'\n",
      "Testing (val) took 0:00:00.288001'\n",
      "Epoch 37 finished in 0:00:01.310999 '\n",
      "\n",
      "--- EPOCH 38---'\n",
      "Extractor Train Losses are random_59:0.4964(-1.59751)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.7179'\n",
      "Testing (val) took 0:00:00.288997'\n",
      "Epoch 38 finished in 0:00:01.269083 '\n",
      "\n",
      "--- EPOCH 39---'\n",
      "Extractor Train Losses are random_59:0.4937(-1.619786)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6894'\n",
      "Testing (val) took 0:00:00.286000'\n",
      "Epoch 39 finished in 0:00:01.299513 '\n",
      "\n",
      "--- EPOCH 40---'\n",
      "Extractor Train Losses are random_59:0.4859(-1.642063)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6567'\n",
      "Testing (val) took 0:00:00.305998'\n",
      "Epoch 40 finished in 0:00:01.314999 '\n",
      "\n",
      "--- EPOCH 41---'\n",
      "Extractor Train Losses are random_59:0.4727(-1.664339)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.601'\n",
      "Testing (val) took 0:00:00.302002'\n",
      "Epoch 41 finished in 0:00:01.354001 '\n",
      "\n",
      "--- EPOCH 42---'\n",
      "Extractor Train Losses are random_59:0.4611(-1.686616)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6029'\n",
      "Testing (val) took 0:00:00.286002'\n",
      "Epoch 42 finished in 0:00:01.323001 '\n",
      "\n",
      "--- EPOCH 43---'\n",
      "Extractor Train Losses are random_59:0.4701(-1.708892)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6014'\n",
      "Testing (val) took 0:00:00.293998'\n",
      "Epoch 43 finished in 0:00:01.277090 '\n",
      "\n",
      "--- EPOCH 44---'\n",
      "Extractor Train Losses are random_59:0.4515(-1.731168)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6141'\n",
      "Testing (val) took 0:00:00.284003'\n",
      "Epoch 44 finished in 0:00:01.292882 '\n",
      "\n",
      "--- EPOCH 45---'\n",
      "Extractor Train Losses are random_59:0.4608(-1.753445)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.6303'\n",
      "Testing (val) took 0:00:00.300003'\n",
      "Epoch 45 finished in 0:00:01.304000 '\n",
      "\n",
      "--- EPOCH 46---'\n",
      "Extractor Train Losses are random_59:0.4482(-1.775721)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5794'\n",
      "Testing (val) took 0:00:00.301998'\n",
      "Epoch 46 finished in 0:00:01.315104 '\n",
      "\n",
      "--- EPOCH 47---'\n",
      "Extractor Train Losses are random_59:0.4417(-1.797998)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5281'\n",
      "Testing (val) took 0:00:00.301102'\n",
      "Epoch 47 finished in 0:00:01.281103 '\n",
      "\n",
      "--- EPOCH 48---'\n",
      "Extractor Train Losses are random_59:0.4308(-1.820274)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5284'\n",
      "Testing (val) took 0:00:00.302999'\n",
      "Epoch 48 finished in 0:00:01.280000 '\n",
      "\n",
      "--- EPOCH 49---'\n",
      "Extractor Train Losses are random_59:0.4277(-1.84255)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.535'\n",
      "Testing (val) took 0:00:00.281572'\n",
      "Epoch 49 finished in 0:00:01.268575 '\n",
      "\n",
      "--- EPOCH 50---'\n",
      "Extractor Train Losses are random_59:0.4208(-1.864827)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5366'\n",
      "Testing (val) took 0:00:00.290110'\n",
      "Epoch 50 finished in 0:00:01.302111 '\n",
      "\n",
      "--- EPOCH 51---'\n",
      "Extractor Train Losses are random_59:0.4152(-1.887103)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5502'\n",
      "Testing (val) took 0:00:00.295000'\n",
      "Epoch 51 finished in 0:00:01.325000 '\n",
      "\n",
      "--- EPOCH 52---'\n",
      "Extractor Train Losses are random_59:0.4117(-1.90938)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5728'\n",
      "Testing (val) took 0:00:00.304997'\n",
      "Epoch 52 finished in 0:00:01.304759 '\n",
      "\n",
      "--- EPOCH 53---'\n",
      "Extractor Train Losses are random_59:0.4023(-1.931656)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5475'\n",
      "Testing (val) took 0:00:00.300001'\n",
      "Epoch 53 finished in 0:00:01.354000 '\n",
      "\n",
      "--- EPOCH 54---'\n",
      "Extractor Train Losses are random_59:0.405(-1.953932)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5476'\n",
      "Testing (val) took 0:00:00.328000'\n",
      "Epoch 54 finished in 0:00:01.331084 '\n",
      "\n",
      "--- EPOCH 55---'\n",
      "Extractor Train Losses are random_59:0.3997(-1.976209)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.561'\n",
      "Testing (val) took 0:00:00.313001'\n",
      "Epoch 55 finished in 0:00:01.328100 '\n",
      "\n",
      "--- EPOCH 56---'\n",
      "Extractor Train Losses are random_59:0.4048(-1.998485)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.547'\n",
      "Testing (val) took 0:00:00.289999'\n",
      "Epoch 56 finished in 0:00:01.277163 '\n",
      "\n",
      "--- EPOCH 57---'\n",
      "Extractor Train Losses are random_59:0.4018(-2.020762)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5693'\n",
      "Testing (val) took 0:00:00.305000'\n",
      "Epoch 57 finished in 0:00:01.300151 '\n",
      "\n",
      "--- EPOCH 58---'\n",
      "Extractor Train Losses are random_59:0.3927(-2.043038)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5814'\n",
      "Testing (val) took 0:00:00.270000'\n",
      "Epoch 58 finished in 0:00:01.243121 '\n",
      "\n",
      "--- EPOCH 59---'\n",
      "Extractor Train Losses are random_59:0.3897(-2.065314)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5365'\n",
      "Testing (val) took 0:00:00.278577'\n",
      "Epoch 59 finished in 0:00:01.272605 '\n",
      "\n",
      "--- EPOCH 60---'\n",
      "Extractor Train Losses are random_59:0.388(-2.087591)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5457'\n",
      "Testing (val) took 0:00:00.305999'\n",
      "Epoch 60 finished in 0:00:01.273134 '\n",
      "\n",
      "--- EPOCH 61---'\n",
      "Extractor Train Losses are random_59:0.3789(-2.109867)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5437'\n",
      "Testing (val) took 0:00:00.292000'\n",
      "Epoch 61 finished in 0:00:01.282999 '\n",
      "\n",
      "--- EPOCH 62---'\n",
      "Extractor Train Losses are random_59:0.3781(-2.132144)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5268'\n",
      "Testing (val) took 0:00:00.290001'\n",
      "Epoch 62 finished in 0:00:01.276000 '\n",
      "\n",
      "--- EPOCH 63---'\n",
      "Extractor Train Losses are random_59:0.3706(-2.15442)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5178'\n",
      "Testing (val) took 0:00:00.277002'\n",
      "Epoch 63 finished in 0:00:01.260090 '\n",
      "\n",
      "--- EPOCH 64---'\n",
      "Extractor Train Losses are random_59:0.3708(-2.176696)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5096'\n",
      "Testing (val) took 0:00:00.290149'\n",
      "Epoch 64 finished in 0:00:01.314152 '\n",
      "\n",
      "--- EPOCH 65---'\n",
      "Extractor Train Losses are random_59:0.3645(-2.198973)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5241'\n",
      "Testing (val) took 0:00:00.277000'\n",
      "Epoch 65 finished in 0:00:01.252996 '\n",
      "\n",
      "--- EPOCH 66---'\n",
      "Extractor Train Losses are random_59:0.3687(-2.221249)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5046'\n",
      "Testing (val) took 0:00:00.283000'\n",
      "Epoch 66 finished in 0:00:01.253090 '\n",
      "\n",
      "--- EPOCH 67---'\n",
      "Extractor Train Losses are random_59:0.3623(-2.243525)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5091'\n",
      "Testing (val) took 0:00:00.291625'\n",
      "Epoch 67 finished in 0:00:01.269627 '\n",
      "\n",
      "--- EPOCH 68---'\n",
      "Extractor Train Losses are random_59:0.3518(-2.265802)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5013'\n",
      "Testing (val) took 0:00:00.287239'\n",
      "Epoch 68 finished in 0:00:01.261241 '\n",
      "\n",
      "--- EPOCH 69---'\n",
      "Extractor Train Losses are random_59:0.355(-2.288078)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5104'\n",
      "Testing (val) took 0:00:00.296999'\n",
      "Epoch 69 finished in 0:00:01.254168 '\n",
      "\n",
      "--- EPOCH 70---'\n",
      "Extractor Train Losses are random_59:0.3492(-2.310355)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4983'\n",
      "Testing (val) took 0:00:00.313000'\n",
      "Epoch 70 finished in 0:00:01.352000 '\n",
      "\n",
      "--- EPOCH 71---'\n",
      "Extractor Train Losses are random_59:0.3484(-2.332631)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4982'\n",
      "Testing (val) took 0:00:00.298517'\n",
      "Epoch 71 finished in 0:00:01.302192 '\n",
      "\n",
      "--- EPOCH 72---'\n",
      "Extractor Train Losses are random_59:0.3427(-2.354907)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4952'\n",
      "Testing (val) took 0:00:00.305999'\n",
      "Epoch 72 finished in 0:00:01.291001 '\n",
      "\n",
      "--- EPOCH 73---'\n",
      "Extractor Train Losses are random_59:0.3388(-2.377184)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5029'\n",
      "Testing (val) took 0:00:00.285996'\n",
      "Epoch 73 finished in 0:00:01.321000 '\n",
      "\n",
      "--- EPOCH 74---'\n",
      "Extractor Train Losses are random_59:0.3339(-2.39946)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4903'\n",
      "Testing (val) took 0:00:00.302999'\n",
      "Epoch 74 finished in 0:00:01.332081 '\n",
      "\n",
      "--- EPOCH 75---'\n",
      "Extractor Train Losses are random_59:0.3358(-2.421737)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.493'\n",
      "Testing (val) took 0:00:00.286139'\n",
      "Epoch 75 finished in 0:00:01.302241 '\n",
      "\n",
      "--- EPOCH 76---'\n",
      "Extractor Train Losses are random_59:0.3325(-2.444013)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.5005'\n",
      "Testing (val) took 0:00:00.303997'\n",
      "Epoch 76 finished in 0:00:01.323000 '\n",
      "\n",
      "--- EPOCH 77---'\n",
      "Extractor Train Losses are random_59:0.332(-2.466289)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4905'\n",
      "Testing (val) took 0:00:00.284000'\n",
      "Epoch 77 finished in 0:00:01.279086 '\n",
      "\n",
      "--- EPOCH 78---'\n",
      "Extractor Train Losses are random_59:0.3286(-2.488566)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4801'\n",
      "Testing (val) took 0:00:00.288082'\n",
      "Epoch 78 finished in 0:00:01.291078 '\n",
      "\n",
      "--- EPOCH 79---'\n",
      "Extractor Train Losses are random_59:0.3282(-2.510842)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4729'\n",
      "Testing (val) took 0:00:00.294996'\n",
      "Epoch 79 finished in 0:00:01.295199 '\n",
      "\n",
      "--- EPOCH 80---'\n",
      "Extractor Train Losses are random_59:0.3276(-2.533119)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4751'\n",
      "Testing (val) took 0:00:00.296001'\n",
      "Epoch 80 finished in 0:00:01.289629 '\n",
      "\n",
      "--- EPOCH 81---'\n",
      "Extractor Train Losses are random_59:0.3237(-2.555395)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.476'\n",
      "Testing (val) took 0:00:00.285999'\n",
      "Epoch 81 finished in 0:00:01.290512 '\n",
      "\n",
      "--- EPOCH 82---'\n",
      "Extractor Train Losses are random_59:0.3224(-2.577671)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4686'\n",
      "Testing (val) took 0:00:00.278997'\n",
      "Epoch 82 finished in 0:00:01.242137 '\n",
      "\n",
      "--- EPOCH 83---'\n",
      "Extractor Train Losses are random_59:0.3182(-2.599948)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4644'\n",
      "Testing (val) took 0:00:00.277000'\n",
      "Epoch 83 finished in 0:00:01.255385 '\n",
      "\n",
      "--- EPOCH 84---'\n",
      "Extractor Train Losses are random_59:0.3191(-2.622224)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4671'\n",
      "Testing (val) took 0:00:00.293000'\n",
      "Epoch 84 finished in 0:00:01.300001 '\n",
      "\n",
      "--- EPOCH 85---'\n",
      "Extractor Train Losses are random_59:0.3168(-2.644501)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.466'\n",
      "Testing (val) took 0:00:00.323001'\n",
      "Epoch 85 finished in 0:00:01.359139 '\n",
      "\n",
      "--- EPOCH 86---'\n",
      "Extractor Train Losses are random_59:0.3154(-2.666777)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4626'\n",
      "Testing (val) took 0:00:00.309999'\n",
      "Epoch 86 finished in 0:00:01.335998 '\n",
      "\n",
      "--- EPOCH 87---'\n",
      "Extractor Train Losses are random_59:0.3119(-2.689053)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4626'\n",
      "Testing (val) took 0:00:00.286996'\n",
      "Epoch 87 finished in 0:00:01.264573 '\n",
      "\n",
      "--- EPOCH 88---'\n",
      "Extractor Train Losses are random_59:0.313(-2.71133)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4576'\n",
      "Testing (val) took 0:00:00.287997'\n",
      "Epoch 88 finished in 0:00:01.280095 '\n",
      "\n",
      "--- EPOCH 89---'\n",
      "Extractor Train Losses are random_59:0.3138(-2.733606)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4599'\n",
      "Testing (val) took 0:00:00.282099'\n",
      "Epoch 89 finished in 0:00:01.245097 '\n",
      "\n",
      "--- EPOCH 90---'\n",
      "Extractor Train Losses are random_59:0.3062(-2.755883)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4555'\n",
      "Testing (val) took 0:00:00.297996'\n",
      "Epoch 90 finished in 0:00:01.278999 '\n",
      "\n",
      "--- EPOCH 91---'\n",
      "Extractor Train Losses are random_59:0.3052(-2.778159)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4551'\n",
      "Testing (val) took 0:00:00.282999'\n",
      "Epoch 91 finished in 0:00:01.250156 '\n",
      "\n",
      "--- EPOCH 92---'\n",
      "Extractor Train Losses are random_59:0.3075(-2.800435)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4581'\n",
      "Testing (val) took 0:00:00.291096'\n",
      "Epoch 92 finished in 0:00:01.254095 '\n",
      "\n",
      "--- EPOCH 93---'\n",
      "Extractor Train Losses are random_59:0.3055(-2.822712)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4502'\n",
      "Testing (val) took 0:00:00.302003'\n",
      "Epoch 93 finished in 0:00:01.273002 '\n",
      "\n",
      "--- EPOCH 94---'\n",
      "Extractor Train Losses are random_59:0.3002(-2.844988)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4576'\n",
      "Testing (val) took 0:00:00.282000'\n",
      "Epoch 94 finished in 0:00:01.274999 '\n",
      "\n",
      "--- EPOCH 95---'\n",
      "Extractor Train Losses are random_59:0.3049(-2.867265)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4502'\n",
      "Testing (val) took 0:00:00.289002'\n",
      "Epoch 95 finished in 0:00:01.255002 '\n",
      "\n",
      "--- EPOCH 96---'\n",
      "Extractor Train Losses are random_59:0.2991(-2.889541)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.453'\n",
      "Testing (val) took 0:00:00.288003'\n",
      "Epoch 96 finished in 0:00:01.277208 '\n",
      "\n",
      "--- EPOCH 97---'\n",
      "Extractor Train Losses are random_59:0.3022(-2.911817)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4544'\n",
      "Testing (val) took 0:00:00.293000'\n",
      "Epoch 97 finished in 0:00:01.310084 '\n",
      "\n",
      "--- EPOCH 98---'\n",
      "Extractor Train Losses are random_59:0.2977(-2.934094)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.449'\n",
      "Testing (val) took 0:00:00.282986'\n",
      "Epoch 98 finished in 0:00:01.268004 '\n",
      "\n",
      "--- EPOCH 99---'\n",
      "Extractor Train Losses are random_59:0.3005(-2.95637)'\n",
      "Tested (val) on 1929 instances with mean losses of: random_59:0.4489'\n",
      "Testing (val) took 0:00:00.299004'\n",
      "Epoch 99 finished in 0:00:01.344149 '\n",
      "\n",
      "-----------'\n",
      "Finished training extractors with a best validation loss of random_59:0.4489'\n",
      "Training took 0:02:09.558783'\n",
      "Tested (test) on 1905 instances with mean losses of: random_59:0.4335'\n",
      "Testing (test) took 0:00:00.293999'\n",
      "-----------------------------------Fold 1 - Train 5855 - Val 1903 - Test 1955-----------------------------------'\n",
      "Training extractors on 5855 instances, validating on 1903 instances, for 100 epochs'\n",
      "\n",
      "--- EPOCH 0---'\n",
      "Extractor Train Losses are random_59:17.4406(-0.751007)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:1.4688'\n",
      "Testing (val) took 0:00:00.284531'\n",
      "Epoch 0 finished in 0:00:01.332644 '\n",
      "\n",
      "--- EPOCH 1---'\n",
      "Extractor Train Losses are random_59:1.6339(-0.773283)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:1.2611'\n",
      "Testing (val) took 0:00:00.292127'\n",
      "Epoch 1 finished in 0:00:01.331238 '\n",
      "\n",
      "--- EPOCH 2---'\n",
      "Extractor Train Losses are random_59:1.2595(-0.79556)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:1.0421'\n",
      "Testing (val) took 0:00:00.315000'\n",
      "Epoch 2 finished in 0:00:01.332000 '\n",
      "\n",
      "--- EPOCH 3---'\n",
      "Extractor Train Losses are random_59:1.0452(-0.817836)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.9646'\n",
      "Testing (val) took 0:00:00.297001'\n",
      "Epoch 3 finished in 0:00:01.353297 '\n",
      "\n",
      "--- EPOCH 4---'\n",
      "Extractor Train Losses are random_59:1.0429(-0.840113)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.8081'\n",
      "Testing (val) took 0:00:00.291102'\n",
      "Epoch 4 finished in 0:00:01.305102 '\n",
      "\n",
      "--- EPOCH 5---'\n",
      "Extractor Train Losses are random_59:0.8803(-0.862389)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.8142'\n",
      "Testing (val) took 0:00:00.292997'\n",
      "Epoch 5 finished in 0:00:01.283000 '\n",
      "\n",
      "--- EPOCH 6---'\n",
      "Extractor Train Losses are random_59:0.8286(-0.884665)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.7867'\n",
      "Testing (val) took 0:00:00.286999'\n",
      "Epoch 6 finished in 0:00:01.325746 '\n",
      "\n",
      "--- EPOCH 7---'\n",
      "Extractor Train Losses are random_59:0.8205(-0.906942)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.9855'\n",
      "Testing (val) took 0:00:00.292110'\n",
      "Epoch 7 finished in 0:00:01.304111 '\n",
      "\n",
      "--- EPOCH 8---'\n",
      "Extractor Train Losses are random_59:0.7926(-0.929218)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.9057'\n",
      "Testing (val) took 0:00:00.310998'\n",
      "Epoch 8 finished in 0:00:01.374000 '\n",
      "\n",
      "--- EPOCH 9---'\n",
      "Extractor Train Losses are random_59:0.7202(-0.951495)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.7341'\n",
      "Testing (val) took 0:00:00.288514'\n",
      "Epoch 9 finished in 0:00:01.319171 '\n",
      "\n",
      "--- EPOCH 10---'\n",
      "Extractor Train Losses are random_59:0.6717(-0.973771)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.7878'\n",
      "Testing (val) took 0:00:00.298152'\n",
      "Epoch 10 finished in 0:00:01.290152 '\n",
      "\n",
      "--- EPOCH 11---'\n",
      "Extractor Train Losses are random_59:0.6843(-0.996047)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.761'\n",
      "Testing (val) took 0:00:00.294999'\n",
      "Epoch 11 finished in 0:00:01.289998 '\n",
      "\n",
      "--- EPOCH 12---'\n",
      "Extractor Train Losses are random_59:0.6723(-1.018324)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.7682'\n",
      "Testing (val) took 0:00:00.284999'\n",
      "Epoch 12 finished in 0:00:01.333002 '\n",
      "\n",
      "--- EPOCH 13---'\n",
      "Extractor Train Losses are random_59:0.6536(-1.0406)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.6525'\n",
      "Testing (val) took 0:00:00.276000'\n",
      "Epoch 13 finished in 0:00:01.299051 '\n",
      "\n",
      "--- EPOCH 14---'\n",
      "Extractor Train Losses are random_59:0.6498(-1.062877)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.6598'\n",
      "Testing (val) took 0:00:00.303001'\n",
      "Epoch 14 finished in 0:00:01.324034 '\n",
      "\n",
      "--- EPOCH 15---'\n",
      "Extractor Train Losses are random_59:0.6208(-1.085153)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.6561'\n",
      "Testing (val) took 0:00:00.280999'\n",
      "Epoch 15 finished in 0:00:01.255077 '\n",
      "\n",
      "--- EPOCH 16---'\n",
      "Extractor Train Losses are random_59:0.6135(-1.107429)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.6673'\n",
      "Testing (val) took 0:00:00.290001'\n",
      "Epoch 16 finished in 0:00:01.275000 '\n",
      "\n",
      "--- EPOCH 17---'\n",
      "Extractor Train Losses are random_59:0.6293(-1.129706)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.7072'\n",
      "Testing (val) took 0:00:00.285998'\n",
      "Epoch 17 finished in 0:00:01.298186 '\n",
      "\n",
      "--- EPOCH 18---'\n",
      "Extractor Train Losses are random_59:0.6382(-1.151982)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.6573'\n",
      "Testing (val) took 0:00:00.284997'\n",
      "Epoch 18 finished in 0:00:01.316091 '\n",
      "\n",
      "--- EPOCH 19---'\n",
      "Extractor Train Losses are random_59:0.6326(-1.174259)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.7845'\n",
      "Testing (val) took 0:00:00.282000'\n",
      "Epoch 19 finished in 0:00:01.274000 '\n",
      "\n",
      "--- EPOCH 20---'\n",
      "Extractor Train Losses are random_59:0.6217(-1.196535)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.7292'\n",
      "Testing (val) took 0:00:00.300000'\n",
      "Epoch 20 finished in 0:00:01.312084 '\n",
      "\n",
      "--- EPOCH 21---'\n",
      "Extractor Train Losses are random_59:0.5875(-1.218811)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.6209'\n",
      "Testing (val) took 0:00:00.290998'\n",
      "Epoch 21 finished in 0:00:01.317662 '\n",
      "\n",
      "--- EPOCH 22---'\n",
      "Extractor Train Losses are random_59:0.5829(-1.241088)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5984'\n",
      "Testing (val) took 0:00:00.276001'\n",
      "Epoch 22 finished in 0:00:01.246999 '\n",
      "\n",
      "--- EPOCH 23---'\n",
      "Extractor Train Losses are random_59:0.571(-1.263364)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5953'\n",
      "Testing (val) took 0:00:00.283000'\n",
      "Epoch 23 finished in 0:00:01.283042 '\n",
      "\n",
      "--- EPOCH 24---'\n",
      "Extractor Train Losses are random_59:0.5616(-1.285641)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5647'\n",
      "Testing (val) took 0:00:00.284106'\n",
      "Epoch 24 finished in 0:00:01.278108 '\n",
      "\n",
      "--- EPOCH 25---'\n",
      "Extractor Train Losses are random_59:0.558(-1.307917)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.6364'\n",
      "Testing (val) took 0:00:00.298000'\n",
      "Epoch 25 finished in 0:00:01.289998 '\n",
      "\n",
      "--- EPOCH 26---'\n",
      "Extractor Train Losses are random_59:0.5576(-1.330193)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5897'\n",
      "Testing (val) took 0:00:00.305001'\n",
      "Epoch 26 finished in 0:00:01.294424 '\n",
      "\n",
      "--- EPOCH 27---'\n",
      "Extractor Train Losses are random_59:0.5575(-1.35247)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.591'\n",
      "Testing (val) took 0:00:00.311940'\n",
      "Epoch 27 finished in 0:00:01.282477 '\n",
      "\n",
      "--- EPOCH 28---'\n",
      "Extractor Train Losses are random_59:0.5468(-1.374746)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.6432'\n",
      "Testing (val) took 0:00:00.293999'\n",
      "Epoch 28 finished in 0:00:01.284118 '\n",
      "\n",
      "--- EPOCH 29---'\n",
      "Extractor Train Losses are random_59:0.5422(-1.397022)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.7148'\n",
      "Testing (val) took 0:00:00.298998'\n",
      "Epoch 29 finished in 0:00:01.309000 '\n",
      "\n",
      "--- EPOCH 30---'\n",
      "Extractor Train Losses are random_59:0.5311(-1.419299)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.6676'\n",
      "Testing (val) took 0:00:00.283003'\n",
      "Epoch 30 finished in 0:00:01.269003 '\n",
      "\n",
      "--- EPOCH 31---'\n",
      "Extractor Train Losses are random_59:0.5336(-1.441575)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.7299'\n",
      "Testing (val) took 0:00:00.286002'\n",
      "Epoch 31 finished in 0:00:01.303669 '\n",
      "\n",
      "--- EPOCH 32---'\n",
      "Extractor Train Losses are random_59:0.5242(-1.463852)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.7795'\n",
      "Testing (val) took 0:00:00.275601'\n",
      "Epoch 32 finished in 0:00:01.293603 '\n",
      "\n",
      "--- EPOCH 33---'\n",
      "Extractor Train Losses are random_59:0.5161(-1.486128)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.7581'\n",
      "Testing (val) took 0:00:00.297000'\n",
      "Epoch 33 finished in 0:00:01.357999 '\n",
      "\n",
      "--- EPOCH 34---'\n",
      "Extractor Train Losses are random_59:0.5103(-1.508404)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.7847'\n",
      "Testing (val) took 0:00:00.302512'\n",
      "Epoch 34 finished in 0:00:01.378514 '\n",
      "\n",
      "--- EPOCH 35---'\n",
      "Extractor Train Losses are random_59:0.5028(-1.530681)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.6711'\n",
      "Testing (val) took 0:00:00.274000'\n",
      "Epoch 35 finished in 0:00:01.284606 '\n",
      "\n",
      "--- EPOCH 36---'\n",
      "Extractor Train Losses are random_59:0.4895(-1.552957)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.7804'\n",
      "Testing (val) took 0:00:00.291000'\n",
      "Epoch 36 finished in 0:00:01.295594 '\n",
      "\n",
      "--- EPOCH 37---'\n",
      "Extractor Train Losses are random_59:0.499(-1.575234)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.6788'\n",
      "Testing (val) took 0:00:00.276012'\n",
      "Epoch 37 finished in 0:00:01.252554 '\n",
      "\n",
      "--- EPOCH 38---'\n",
      "Extractor Train Losses are random_59:0.5007(-1.59751)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.6902'\n",
      "Testing (val) took 0:00:00.291107'\n",
      "Epoch 38 finished in 0:00:01.269221 '\n",
      "\n",
      "--- EPOCH 39---'\n",
      "Extractor Train Losses are random_59:0.4801(-1.619786)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.6505'\n",
      "Testing (val) took 0:00:00.284028'\n",
      "Epoch 39 finished in 0:00:01.323961 '\n",
      "\n",
      "--- EPOCH 40---'\n",
      "Extractor Train Losses are random_59:0.4976(-1.642063)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5769'\n",
      "Testing (val) took 0:00:00.286014'\n",
      "Epoch 40 finished in 0:00:01.282159 '\n",
      "\n",
      "--- EPOCH 41---'\n",
      "Extractor Train Losses are random_59:0.4766(-1.664339)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.6029'\n",
      "Testing (val) took 0:00:00.302107'\n",
      "Epoch 41 finished in 0:00:01.287412 '\n",
      "\n",
      "--- EPOCH 42---'\n",
      "Extractor Train Losses are random_59:0.4897(-1.686616)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5583'\n",
      "Testing (val) took 0:00:00.280000'\n",
      "Epoch 42 finished in 0:00:01.243000 '\n",
      "\n",
      "--- EPOCH 43---'\n",
      "Extractor Train Losses are random_59:0.48(-1.708892)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5716'\n",
      "Testing (val) took 0:00:00.301998'\n",
      "Epoch 43 finished in 0:00:01.286117 '\n",
      "\n",
      "--- EPOCH 44---'\n",
      "Extractor Train Losses are random_59:0.4708(-1.731168)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.6355'\n",
      "Testing (val) took 0:00:00.279002'\n",
      "Epoch 44 finished in 0:00:01.235582 '\n",
      "\n",
      "--- EPOCH 45---'\n",
      "Extractor Train Losses are random_59:0.4727(-1.753445)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5706'\n",
      "Testing (val) took 0:00:00.276998'\n",
      "Epoch 45 finished in 0:00:01.252791 '\n",
      "\n",
      "--- EPOCH 46---'\n",
      "Extractor Train Losses are random_59:0.4597(-1.775721)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.585'\n",
      "Testing (val) took 0:00:00.289000'\n",
      "Epoch 46 finished in 0:00:01.292101 '\n",
      "\n",
      "--- EPOCH 47---'\n",
      "Extractor Train Losses are random_59:0.4646(-1.797998)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5645'\n",
      "Testing (val) took 0:00:00.283302'\n",
      "Epoch 47 finished in 0:00:01.275186 '\n",
      "\n",
      "--- EPOCH 48---'\n",
      "Extractor Train Losses are random_59:0.4554(-1.820274)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5365'\n",
      "Testing (val) took 0:00:00.290999'\n",
      "Epoch 48 finished in 0:00:01.262179 '\n",
      "\n",
      "--- EPOCH 49---'\n",
      "Extractor Train Losses are random_59:0.4472(-1.84255)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5252'\n",
      "Testing (val) took 0:00:00.308185'\n",
      "Epoch 49 finished in 0:00:01.285185 '\n",
      "\n",
      "--- EPOCH 50---'\n",
      "Extractor Train Losses are random_59:0.4412(-1.864827)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5422'\n",
      "Testing (val) took 0:00:00.298040'\n",
      "Epoch 50 finished in 0:00:01.273043 '\n",
      "\n",
      "--- EPOCH 51---'\n",
      "Extractor Train Losses are random_59:0.4398(-1.887103)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5516'\n",
      "Testing (val) took 0:00:00.293002'\n",
      "Epoch 51 finished in 0:00:01.309067 '\n",
      "\n",
      "--- EPOCH 52---'\n",
      "Extractor Train Losses are random_59:0.4328(-1.90938)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5339'\n",
      "Testing (val) took 0:00:00.272073'\n",
      "Epoch 52 finished in 0:00:01.233637 '\n",
      "\n",
      "--- EPOCH 53---'\n",
      "Extractor Train Losses are random_59:0.4327(-1.931656)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5341'\n",
      "Testing (val) took 0:00:00.294000'\n",
      "Epoch 53 finished in 0:00:01.283001 '\n",
      "\n",
      "--- EPOCH 54---'\n",
      "Extractor Train Losses are random_59:0.4242(-1.953932)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5073'\n",
      "Testing (val) took 0:00:00.281001'\n",
      "Epoch 54 finished in 0:00:01.266000 '\n",
      "\n",
      "--- EPOCH 55---'\n",
      "Extractor Train Losses are random_59:0.4214(-1.976209)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.525'\n",
      "Testing (val) took 0:00:00.276999'\n",
      "Epoch 55 finished in 0:00:01.227001 '\n",
      "\n",
      "--- EPOCH 56---'\n",
      "Extractor Train Losses are random_59:0.4115(-1.998485)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5237'\n",
      "Testing (val) took 0:00:00.285002'\n",
      "Epoch 56 finished in 0:00:01.265671 '\n",
      "\n",
      "--- EPOCH 57---'\n",
      "Extractor Train Losses are random_59:0.4132(-2.020762)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5169'\n",
      "Testing (val) took 0:00:00.296998'\n",
      "Epoch 57 finished in 0:00:01.311999 '\n",
      "\n",
      "--- EPOCH 58---'\n",
      "Extractor Train Losses are random_59:0.405(-2.043038)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5053'\n",
      "Testing (val) took 0:00:00.304001'\n",
      "Epoch 58 finished in 0:00:01.349002 '\n",
      "\n",
      "--- EPOCH 59---'\n",
      "Extractor Train Losses are random_59:0.3962(-2.065314)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5559'\n",
      "Testing (val) took 0:00:00.296000'\n",
      "Epoch 59 finished in 0:00:01.391081 '\n",
      "\n",
      "--- EPOCH 60---'\n",
      "Extractor Train Losses are random_59:0.4054(-2.087591)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5129'\n",
      "Testing (val) took 0:00:00.289001'\n",
      "Epoch 60 finished in 0:00:01.295000 '\n",
      "\n",
      "--- EPOCH 61---'\n",
      "Extractor Train Losses are random_59:0.3939(-2.109867)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5085'\n",
      "Testing (val) took 0:00:00.317996'\n",
      "Epoch 61 finished in 0:00:01.329996 '\n",
      "\n",
      "--- EPOCH 62---'\n",
      "Extractor Train Losses are random_59:0.3914(-2.132144)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4975'\n",
      "Testing (val) took 0:00:00.313998'\n",
      "Epoch 62 finished in 0:00:01.308109 '\n",
      "\n",
      "--- EPOCH 63---'\n",
      "Extractor Train Losses are random_59:0.3852(-2.15442)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4857'\n",
      "Testing (val) took 0:00:00.308601'\n",
      "Epoch 63 finished in 0:00:01.376179 '\n",
      "\n",
      "--- EPOCH 64---'\n",
      "Extractor Train Losses are random_59:0.3874(-2.176696)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4965'\n",
      "Testing (val) took 0:00:00.317999'\n",
      "Epoch 64 finished in 0:00:01.347998 '\n",
      "\n",
      "--- EPOCH 65---'\n",
      "Extractor Train Losses are random_59:0.3817(-2.198973)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5047'\n",
      "Testing (val) took 0:00:00.296000'\n",
      "Epoch 65 finished in 0:00:01.359144 '\n",
      "\n",
      "--- EPOCH 66---'\n",
      "Extractor Train Losses are random_59:0.3777(-2.221249)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.5026'\n",
      "Testing (val) took 0:00:00.292999'\n",
      "Epoch 66 finished in 0:00:01.400114 '\n",
      "\n",
      "--- EPOCH 67---'\n",
      "Extractor Train Losses are random_59:0.3724(-2.243525)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4945'\n",
      "Testing (val) took 0:00:00.299000'\n",
      "Epoch 67 finished in 0:00:01.359000 '\n",
      "\n",
      "--- EPOCH 68---'\n",
      "Extractor Train Losses are random_59:0.3644(-2.265802)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4855'\n",
      "Testing (val) took 0:00:00.277998'\n",
      "Epoch 68 finished in 0:00:01.285210 '\n",
      "\n",
      "--- EPOCH 69---'\n",
      "Extractor Train Losses are random_59:0.3658(-2.288078)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4849'\n",
      "Testing (val) took 0:00:00.283000'\n",
      "Epoch 69 finished in 0:00:01.261101 '\n",
      "\n",
      "--- EPOCH 70---'\n",
      "Extractor Train Losses are random_59:0.3669(-2.310355)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4786'\n",
      "Testing (val) took 0:00:00.292000'\n",
      "Epoch 70 finished in 0:00:01.282998 '\n",
      "\n",
      "--- EPOCH 71---'\n",
      "Extractor Train Losses are random_59:0.3619(-2.332631)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4818'\n",
      "Testing (val) took 0:00:00.290999'\n",
      "Epoch 71 finished in 0:00:01.285213 '\n",
      "\n",
      "--- EPOCH 72---'\n",
      "Extractor Train Losses are random_59:0.3589(-2.354907)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4677'\n",
      "Testing (val) took 0:00:00.296735'\n",
      "Epoch 72 finished in 0:00:01.299327 '\n",
      "\n",
      "--- EPOCH 73---'\n",
      "Extractor Train Losses are random_59:0.3554(-2.377184)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4745'\n",
      "Testing (val) took 0:00:00.295000'\n",
      "Epoch 73 finished in 0:00:01.303000 '\n",
      "\n",
      "--- EPOCH 74---'\n",
      "Extractor Train Losses are random_59:0.3538(-2.39946)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4567'\n",
      "Testing (val) took 0:00:00.289000'\n",
      "Epoch 74 finished in 0:00:01.266781 '\n",
      "\n",
      "--- EPOCH 75---'\n",
      "Extractor Train Losses are random_59:0.3487(-2.421737)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4732'\n",
      "Testing (val) took 0:00:00.320100'\n",
      "Epoch 75 finished in 0:00:01.312665 '\n",
      "\n",
      "--- EPOCH 76---'\n",
      "Extractor Train Losses are random_59:0.3501(-2.444013)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4642'\n",
      "Testing (val) took 0:00:00.284996'\n",
      "Epoch 76 finished in 0:00:01.283124 '\n",
      "\n",
      "--- EPOCH 77---'\n",
      "Extractor Train Losses are random_59:0.3369(-2.466289)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4708'\n",
      "Testing (val) took 0:00:00.282002'\n",
      "Epoch 77 finished in 0:00:01.283085 '\n",
      "\n",
      "--- EPOCH 78---'\n",
      "Extractor Train Losses are random_59:0.3407(-2.488566)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4635'\n",
      "Testing (val) took 0:00:00.298000'\n",
      "Epoch 78 finished in 0:00:01.289997 '\n",
      "\n",
      "--- EPOCH 79---'\n",
      "Extractor Train Losses are random_59:0.3395(-2.510842)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4612'\n",
      "Testing (val) took 0:00:00.291002'\n",
      "Epoch 79 finished in 0:00:01.290744 '\n",
      "\n",
      "--- EPOCH 80---'\n",
      "Extractor Train Losses are random_59:0.3368(-2.533119)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4689'\n",
      "Testing (val) took 0:00:00.287999'\n",
      "Epoch 80 finished in 0:00:01.317068 '\n",
      "\n",
      "--- EPOCH 81---'\n",
      "Extractor Train Losses are random_59:0.3332(-2.555395)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4649'\n",
      "Testing (val) took 0:00:00.282000'\n",
      "Epoch 81 finished in 0:00:01.242001 '\n",
      "\n",
      "--- EPOCH 82---'\n",
      "Extractor Train Losses are random_59:0.3297(-2.577671)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4625'\n",
      "Testing (val) took 0:00:00.294999'\n",
      "Epoch 82 finished in 0:00:01.282120 '\n",
      "\n",
      "--- EPOCH 83---'\n",
      "Extractor Train Losses are random_59:0.3266(-2.599948)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4534'\n",
      "Testing (val) took 0:00:00.296000'\n",
      "Epoch 83 finished in 0:00:01.293714 '\n",
      "\n",
      "--- EPOCH 84---'\n",
      "Extractor Train Losses are random_59:0.3307(-2.622224)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4532'\n",
      "Testing (val) took 0:00:00.314000'\n",
      "Epoch 84 finished in 0:00:01.334999 '\n",
      "\n",
      "--- EPOCH 85---'\n",
      "Extractor Train Losses are random_59:0.3198(-2.644501)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4518'\n",
      "Testing (val) took 0:00:00.286001'\n",
      "Epoch 85 finished in 0:00:01.347000 '\n",
      "\n",
      "--- EPOCH 86---'\n",
      "Extractor Train Losses are random_59:0.3294(-2.666777)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4547'\n",
      "Testing (val) took 0:00:00.306085'\n",
      "Epoch 86 finished in 0:00:01.336191 '\n",
      "\n",
      "--- EPOCH 87---'\n",
      "Extractor Train Losses are random_59:0.3214(-2.689053)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4476'\n",
      "Testing (val) took 0:00:00.289999'\n",
      "Epoch 87 finished in 0:00:01.348003 '\n",
      "\n",
      "--- EPOCH 88---'\n",
      "Extractor Train Losses are random_59:0.3193(-2.71133)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4465'\n",
      "Testing (val) took 0:00:00.296998'\n",
      "Epoch 88 finished in 0:00:01.315171 '\n",
      "\n",
      "--- EPOCH 89---'\n",
      "Extractor Train Losses are random_59:0.3153(-2.733606)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4423'\n",
      "Testing (val) took 0:00:00.309000'\n",
      "Epoch 89 finished in 0:00:01.327173 '\n",
      "\n",
      "--- EPOCH 90---'\n",
      "Extractor Train Losses are random_59:0.3183(-2.755883)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4403'\n",
      "Testing (val) took 0:00:00.365000'\n",
      "Epoch 90 finished in 0:00:01.466115 '\n",
      "\n",
      "--- EPOCH 91---'\n",
      "Extractor Train Losses are random_59:0.3148(-2.778159)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4428'\n",
      "Testing (val) took 0:00:00.317998'\n",
      "Epoch 91 finished in 0:00:01.386856 '\n",
      "\n",
      "--- EPOCH 92---'\n",
      "Extractor Train Losses are random_59:0.3148(-2.800435)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4372'\n",
      "Testing (val) took 0:00:00.298000'\n",
      "Epoch 92 finished in 0:00:01.302095 '\n",
      "\n",
      "--- EPOCH 93---'\n",
      "Extractor Train Losses are random_59:0.3147(-2.822712)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.438'\n",
      "Testing (val) took 0:00:00.287003'\n",
      "Epoch 93 finished in 0:00:01.272998 '\n",
      "\n",
      "--- EPOCH 94---'\n",
      "Extractor Train Losses are random_59:0.3139(-2.844988)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4423'\n",
      "Testing (val) took 0:00:00.282000'\n",
      "Epoch 94 finished in 0:00:01.272092 '\n",
      "\n",
      "--- EPOCH 95---'\n",
      "Extractor Train Losses are random_59:0.3144(-2.867265)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4406'\n",
      "Testing (val) took 0:00:00.310193'\n",
      "Epoch 95 finished in 0:00:01.280195 '\n",
      "\n",
      "--- EPOCH 96---'\n",
      "Extractor Train Losses are random_59:0.3145(-2.889541)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4388'\n",
      "Testing (val) took 0:00:00.282000'\n",
      "Epoch 96 finished in 0:00:01.289000 '\n",
      "\n",
      "--- EPOCH 97---'\n",
      "Extractor Train Losses are random_59:0.3068(-2.911817)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4371'\n",
      "Testing (val) took 0:00:00.281999'\n",
      "Epoch 97 finished in 0:00:01.330217 '\n",
      "\n",
      "--- EPOCH 98---'\n",
      "Extractor Train Losses are random_59:0.3091(-2.934094)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.437'\n",
      "Testing (val) took 0:00:00.322686'\n",
      "Epoch 98 finished in 0:00:01.319266 '\n",
      "\n",
      "--- EPOCH 99---'\n",
      "Extractor Train Losses are random_59:0.3044(-2.95637)'\n",
      "Tested (val) on 1903 instances with mean losses of: random_59:0.4352'\n",
      "Testing (val) took 0:00:00.297000'\n",
      "Epoch 99 finished in 0:00:01.380000 '\n",
      "\n",
      "-----------'\n",
      "Finished training extractors with a best validation loss of random_59:0.4352'\n",
      "Training took 0:02:10.519393'\n",
      "Tested (test) on 1955 instances with mean losses of: random_59:0.4428'\n",
      "Testing (test) took 0:00:00.306998'\n",
      "-----------------------------------Fold 2 - Train 5821 - Val 1955 - Test 1937-----------------------------------'\n",
      "Training extractors on 5821 instances, validating on 1955 instances, for 100 epochs'\n",
      "\n",
      "--- EPOCH 0---'\n",
      "Extractor Train Losses are random_59:32.1845(-0.751007)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:1.36'\n",
      "Testing (val) took 0:00:00.299000'\n",
      "Epoch 0 finished in 0:00:01.274998 '\n",
      "\n",
      "--- EPOCH 1---'\n",
      "Extractor Train Losses are random_59:1.7373(-0.773283)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:1.2681'\n",
      "Testing (val) took 0:00:00.295000'\n",
      "Epoch 1 finished in 0:00:01.281682 '\n",
      "\n",
      "--- EPOCH 2---'\n",
      "Extractor Train Losses are random_59:1.264(-0.79556)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.7656'\n",
      "Testing (val) took 0:00:00.286001'\n",
      "Epoch 2 finished in 0:00:01.282001 '\n",
      "\n",
      "--- EPOCH 3---'\n",
      "Extractor Train Losses are random_59:1.0072(-0.817836)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.9009'\n",
      "Testing (val) took 0:00:00.299999'\n",
      "Epoch 3 finished in 0:00:01.279999 '\n",
      "\n",
      "--- EPOCH 4---'\n",
      "Extractor Train Losses are random_59:0.87(-0.840113)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.8135'\n",
      "Testing (val) took 0:00:00.310001'\n",
      "Epoch 4 finished in 0:00:01.353202 '\n",
      "\n",
      "--- EPOCH 5---'\n",
      "Extractor Train Losses are random_59:0.8067(-0.862389)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.8499'\n",
      "Testing (val) took 0:00:00.303000'\n",
      "Epoch 5 finished in 0:00:01.312580 '\n",
      "\n",
      "--- EPOCH 6---'\n",
      "Extractor Train Losses are random_59:0.7883(-0.884665)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.7636'\n",
      "Testing (val) took 0:00:00.291000'\n",
      "Epoch 6 finished in 0:00:01.251615 '\n",
      "\n",
      "--- EPOCH 7---'\n",
      "Extractor Train Losses are random_59:0.7355(-0.906942)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.7783'\n",
      "Testing (val) took 0:00:00.312001'\n",
      "Epoch 7 finished in 0:00:01.332102 '\n",
      "\n",
      "--- EPOCH 8---'\n",
      "Extractor Train Losses are random_59:0.7106(-0.929218)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.7214'\n",
      "Testing (val) took 0:00:00.312999'\n",
      "Epoch 8 finished in 0:00:01.311113 '\n",
      "\n",
      "--- EPOCH 9---'\n",
      "Extractor Train Losses are random_59:0.7117(-0.951495)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.949'\n",
      "Testing (val) took 0:00:00.321000'\n",
      "Epoch 9 finished in 0:00:01.374162 '\n",
      "\n",
      "--- EPOCH 10---'\n",
      "Extractor Train Losses are random_59:0.6795(-0.973771)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.7965'\n",
      "Testing (val) took 0:00:00.305000'\n",
      "Epoch 10 finished in 0:00:01.309105 '\n",
      "\n",
      "--- EPOCH 11---'\n",
      "Extractor Train Losses are random_59:0.683(-0.996047)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.7332'\n",
      "Testing (val) took 0:00:00.312999'\n",
      "Epoch 11 finished in 0:00:01.359999 '\n",
      "\n",
      "--- EPOCH 12---'\n",
      "Extractor Train Losses are random_59:0.6835(-1.018324)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5922'\n",
      "Testing (val) took 0:00:00.310593'\n",
      "Epoch 12 finished in 0:00:01.271591 '\n",
      "\n",
      "--- EPOCH 13---'\n",
      "Extractor Train Losses are random_59:0.6954(-1.0406)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5716'\n",
      "Testing (val) took 0:00:00.298000'\n",
      "Epoch 13 finished in 0:00:01.294093 '\n",
      "\n",
      "--- EPOCH 14---'\n",
      "Extractor Train Losses are random_59:0.6703(-1.062877)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5974'\n",
      "Testing (val) took 0:00:00.295999'\n",
      "Epoch 14 finished in 0:00:01.243000 '\n",
      "\n",
      "--- EPOCH 15---'\n",
      "Extractor Train Losses are random_59:0.6596(-1.085153)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5688'\n",
      "Testing (val) took 0:00:00.290998'\n",
      "Epoch 15 finished in 0:00:01.290604 '\n",
      "\n",
      "--- EPOCH 16---'\n",
      "Extractor Train Losses are random_59:0.6912(-1.107429)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5519'\n",
      "Testing (val) took 0:00:00.315126'\n",
      "Epoch 16 finished in 0:00:01.300126 '\n",
      "\n",
      "--- EPOCH 17---'\n",
      "Extractor Train Losses are random_59:0.6951(-1.129706)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5879'\n",
      "Testing (val) took 0:00:00.302000'\n",
      "Epoch 17 finished in 0:00:01.303013 '\n",
      "\n",
      "--- EPOCH 18---'\n",
      "Extractor Train Losses are random_59:0.66(-1.151982)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5609'\n",
      "Testing (val) took 0:00:00.300999'\n",
      "Epoch 18 finished in 0:00:01.301266 '\n",
      "\n",
      "--- EPOCH 19---'\n",
      "Extractor Train Losses are random_59:0.6555(-1.174259)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.6717'\n",
      "Testing (val) took 0:00:00.295569'\n",
      "Epoch 19 finished in 0:00:01.334569 '\n",
      "\n",
      "--- EPOCH 20---'\n",
      "Extractor Train Losses are random_59:0.6442(-1.196535)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.6712'\n",
      "Testing (val) took 0:00:00.302001'\n",
      "Epoch 20 finished in 0:00:01.323565 '\n",
      "\n",
      "--- EPOCH 21---'\n",
      "Extractor Train Losses are random_59:0.6149(-1.218811)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.6975'\n",
      "Testing (val) took 0:00:00.290012'\n",
      "Epoch 21 finished in 0:00:01.257650 '\n",
      "\n",
      "--- EPOCH 22---'\n",
      "Extractor Train Losses are random_59:0.595(-1.241088)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.6603'\n",
      "Testing (val) took 0:00:00.300999'\n",
      "Epoch 22 finished in 0:00:01.264000 '\n",
      "\n",
      "--- EPOCH 23---'\n",
      "Extractor Train Losses are random_59:0.5836(-1.263364)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.7141'\n",
      "Testing (val) took 0:00:00.288003'\n",
      "Epoch 23 finished in 0:00:01.244596 '\n",
      "\n",
      "--- EPOCH 24---'\n",
      "Extractor Train Losses are random_59:0.5898(-1.285641)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.701'\n",
      "Testing (val) took 0:00:00.306997'\n",
      "Epoch 24 finished in 0:00:01.273988 '\n",
      "\n",
      "--- EPOCH 25---'\n",
      "Extractor Train Losses are random_59:0.5808(-1.307917)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.832'\n",
      "Testing (val) took 0:00:00.306022'\n",
      "Epoch 25 finished in 0:00:01.310018 '\n",
      "\n",
      "--- EPOCH 26---'\n",
      "Extractor Train Losses are random_59:0.5698(-1.330193)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.6456'\n",
      "Testing (val) took 0:00:00.302000'\n",
      "Epoch 26 finished in 0:00:01.285500 '\n",
      "\n",
      "--- EPOCH 27---'\n",
      "Extractor Train Losses are random_59:0.5529(-1.35247)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.7011'\n",
      "Testing (val) took 0:00:00.306001'\n",
      "Epoch 27 finished in 0:00:01.303107 '\n",
      "\n",
      "--- EPOCH 28---'\n",
      "Extractor Train Losses are random_59:0.5564(-1.374746)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.7427'\n",
      "Testing (val) took 0:00:00.296997'\n",
      "Epoch 28 finished in 0:00:01.266123 '\n",
      "\n",
      "--- EPOCH 29---'\n",
      "Extractor Train Losses are random_59:0.545(-1.397022)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.7673'\n",
      "Testing (val) took 0:00:00.286000'\n",
      "Epoch 29 finished in 0:00:01.287000 '\n",
      "\n",
      "--- EPOCH 30---'\n",
      "Extractor Train Losses are random_59:0.5513(-1.419299)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.6857'\n",
      "Testing (val) took 0:00:00.296997'\n",
      "Epoch 30 finished in 0:00:01.244999 '\n",
      "\n",
      "--- EPOCH 31---'\n",
      "Extractor Train Losses are random_59:0.542(-1.441575)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.7377'\n",
      "Testing (val) took 0:00:00.295002'\n",
      "Epoch 31 finished in 0:00:01.301001 '\n",
      "\n",
      "--- EPOCH 32---'\n",
      "Extractor Train Losses are random_59:0.5495(-1.463852)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.7279'\n",
      "Testing (val) took 0:00:00.288998'\n",
      "Epoch 32 finished in 0:00:01.265668 '\n",
      "\n",
      "--- EPOCH 33---'\n",
      "Extractor Train Losses are random_59:0.5346(-1.486128)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.6599'\n",
      "Testing (val) took 0:00:00.298098'\n",
      "Epoch 33 finished in 0:00:01.281098 '\n",
      "\n",
      "--- EPOCH 34---'\n",
      "Extractor Train Losses are random_59:0.5386(-1.508404)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.6876'\n",
      "Testing (val) took 0:00:00.282000'\n",
      "Epoch 34 finished in 0:00:01.266516 '\n",
      "\n",
      "--- EPOCH 35---'\n",
      "Extractor Train Losses are random_59:0.538(-1.530681)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.587'\n",
      "Testing (val) took 0:00:00.312999'\n",
      "Epoch 35 finished in 0:00:01.286134 '\n",
      "\n",
      "--- EPOCH 36---'\n",
      "Extractor Train Losses are random_59:0.5289(-1.552957)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.545'\n",
      "Testing (val) took 0:00:00.282001'\n",
      "Epoch 36 finished in 0:00:01.267001 '\n",
      "\n",
      "--- EPOCH 37---'\n",
      "Extractor Train Losses are random_59:0.5234(-1.575234)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5794'\n",
      "Testing (val) took 0:00:00.287998'\n",
      "Epoch 37 finished in 0:00:01.264046 '\n",
      "\n",
      "--- EPOCH 38---'\n",
      "Extractor Train Losses are random_59:0.5106(-1.59751)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5308'\n",
      "Testing (val) took 0:00:00.336002'\n",
      "Epoch 38 finished in 0:00:01.310599 '\n",
      "\n",
      "--- EPOCH 39---'\n",
      "Extractor Train Losses are random_59:0.5055(-1.619786)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5482'\n",
      "Testing (val) took 0:00:00.295000'\n",
      "Epoch 39 finished in 0:00:01.265000 '\n",
      "\n",
      "--- EPOCH 40---'\n",
      "Extractor Train Losses are random_59:0.4908(-1.642063)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5415'\n",
      "Testing (val) took 0:00:00.290000'\n",
      "Epoch 40 finished in 0:00:01.271610 '\n",
      "\n",
      "--- EPOCH 41---'\n",
      "Extractor Train Losses are random_59:0.5003(-1.664339)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5629'\n",
      "Testing (val) took 0:00:00.312083'\n",
      "Epoch 41 finished in 0:00:01.307083 '\n",
      "\n",
      "--- EPOCH 42---'\n",
      "Extractor Train Losses are random_59:0.491(-1.686616)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5706'\n",
      "Testing (val) took 0:00:00.318000'\n",
      "Epoch 42 finished in 0:00:01.368043 '\n",
      "\n",
      "--- EPOCH 43---'\n",
      "Extractor Train Losses are random_59:0.4867(-1.708892)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5514'\n",
      "Testing (val) took 0:00:00.295572'\n",
      "Epoch 43 finished in 0:00:01.311724 '\n",
      "\n",
      "--- EPOCH 44---'\n",
      "Extractor Train Losses are random_59:0.4793(-1.731168)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5785'\n",
      "Testing (val) took 0:00:00.294415'\n",
      "Epoch 44 finished in 0:00:01.270488 '\n",
      "\n",
      "--- EPOCH 45---'\n",
      "Extractor Train Losses are random_59:0.4681(-1.753445)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5533'\n",
      "Testing (val) took 0:00:00.292004'\n",
      "Epoch 45 finished in 0:00:01.262012 '\n",
      "\n",
      "--- EPOCH 46---'\n",
      "Extractor Train Losses are random_59:0.4722(-1.775721)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5502'\n",
      "Testing (val) took 0:00:00.302000'\n",
      "Epoch 46 finished in 0:00:01.279610 '\n",
      "\n",
      "--- EPOCH 47---'\n",
      "Extractor Train Losses are random_59:0.4645(-1.797998)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5603'\n",
      "Testing (val) took 0:00:00.309157'\n",
      "Epoch 47 finished in 0:00:01.299158 '\n",
      "\n",
      "--- EPOCH 48---'\n",
      "Extractor Train Losses are random_59:0.451(-1.820274)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5596'\n",
      "Testing (val) took 0:00:00.288999'\n",
      "Epoch 48 finished in 0:00:01.277001 '\n",
      "\n",
      "--- EPOCH 49---'\n",
      "Extractor Train Losses are random_59:0.445(-1.84255)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5447'\n",
      "Testing (val) took 0:00:00.313000'\n",
      "Epoch 49 finished in 0:00:01.275150 '\n",
      "\n",
      "--- EPOCH 50---'\n",
      "Extractor Train Losses are random_59:0.4367(-1.864827)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5801'\n",
      "Testing (val) took 0:00:00.298998'\n",
      "Epoch 50 finished in 0:00:01.289999 '\n",
      "\n",
      "--- EPOCH 51---'\n",
      "Extractor Train Losses are random_59:0.4442(-1.887103)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5559'\n",
      "Testing (val) took 0:00:00.291092'\n",
      "Epoch 51 finished in 0:00:01.249069 '\n",
      "\n",
      "--- EPOCH 52---'\n",
      "Extractor Train Losses are random_59:0.4329(-1.90938)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.554'\n",
      "Testing (val) took 0:00:00.295999'\n",
      "Epoch 52 finished in 0:00:01.282229 '\n",
      "\n",
      "--- EPOCH 53---'\n",
      "Extractor Train Losses are random_59:0.4386(-1.931656)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.552'\n",
      "Testing (val) took 0:00:00.301000'\n",
      "Epoch 53 finished in 0:00:01.270000 '\n",
      "\n",
      "--- EPOCH 54---'\n",
      "Extractor Train Losses are random_59:0.4283(-1.953932)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5418'\n",
      "Testing (val) took 0:00:00.286998'\n",
      "Epoch 54 finished in 0:00:01.272109 '\n",
      "\n",
      "--- EPOCH 55---'\n",
      "Extractor Train Losses are random_59:0.4299(-1.976209)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.53'\n",
      "Testing (val) took 0:00:00.294169'\n",
      "Epoch 55 finished in 0:00:01.278258 '\n",
      "\n",
      "--- EPOCH 56---'\n",
      "Extractor Train Losses are random_59:0.4174(-1.998485)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5398'\n",
      "Testing (val) took 0:00:00.289002'\n",
      "Epoch 56 finished in 0:00:01.265001 '\n",
      "\n",
      "--- EPOCH 57---'\n",
      "Extractor Train Losses are random_59:0.4219(-2.020762)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5235'\n",
      "Testing (val) took 0:00:00.299518'\n",
      "Epoch 57 finished in 0:00:01.269623 '\n",
      "\n",
      "--- EPOCH 58---'\n",
      "Extractor Train Losses are random_59:0.4195(-2.043038)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5329'\n",
      "Testing (val) took 0:00:00.297002'\n",
      "Epoch 58 finished in 0:00:01.282002 '\n",
      "\n",
      "--- EPOCH 59---'\n",
      "Extractor Train Losses are random_59:0.4166(-2.065314)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5263'\n",
      "Testing (val) took 0:00:00.287999'\n",
      "Epoch 59 finished in 0:00:01.264095 '\n",
      "\n",
      "--- EPOCH 60---'\n",
      "Extractor Train Losses are random_59:0.4118(-2.087591)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.5132'\n",
      "Testing (val) took 0:00:00.305001'\n",
      "Epoch 60 finished in 0:00:01.288235 '\n",
      "\n",
      "--- EPOCH 61---'\n",
      "Extractor Train Losses are random_59:0.4021(-2.109867)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4993'\n",
      "Testing (val) took 0:00:00.296999'\n",
      "Epoch 61 finished in 0:00:01.272999 '\n",
      "\n",
      "--- EPOCH 62---'\n",
      "Extractor Train Losses are random_59:0.4032(-2.132144)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4998'\n",
      "Testing (val) took 0:00:00.298999'\n",
      "Epoch 62 finished in 0:00:01.286999 '\n",
      "\n",
      "--- EPOCH 63---'\n",
      "Extractor Train Losses are random_59:0.3979(-2.15442)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4876'\n",
      "Testing (val) took 0:00:00.285999'\n",
      "Epoch 63 finished in 0:00:01.293579 '\n",
      "\n",
      "--- EPOCH 64---'\n",
      "Extractor Train Losses are random_59:0.394(-2.176696)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4768'\n",
      "Testing (val) took 0:00:00.326998'\n",
      "Epoch 64 finished in 0:00:01.317000 '\n",
      "\n",
      "--- EPOCH 65---'\n",
      "Extractor Train Losses are random_59:0.3885(-2.198973)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4715'\n",
      "Testing (val) took 0:00:00.284999'\n",
      "Epoch 65 finished in 0:00:01.239086 '\n",
      "\n",
      "--- EPOCH 66---'\n",
      "Extractor Train Losses are random_59:0.3882(-2.221249)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.472'\n",
      "Testing (val) took 0:00:00.303071'\n",
      "Epoch 66 finished in 0:00:01.279072 '\n",
      "\n",
      "--- EPOCH 67---'\n",
      "Extractor Train Losses are random_59:0.3812(-2.243525)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4777'\n",
      "Testing (val) took 0:00:00.290999'\n",
      "Epoch 67 finished in 0:00:01.274575 '\n",
      "\n",
      "--- EPOCH 68---'\n",
      "Extractor Train Losses are random_59:0.3853(-2.265802)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.469'\n",
      "Testing (val) took 0:00:00.288000'\n",
      "Epoch 68 finished in 0:00:01.254000 '\n",
      "\n",
      "--- EPOCH 69---'\n",
      "Extractor Train Losses are random_59:0.3756(-2.288078)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.465'\n",
      "Testing (val) took 0:00:00.299001'\n",
      "Epoch 69 finished in 0:00:01.260035 '\n",
      "\n",
      "--- EPOCH 70---'\n",
      "Extractor Train Losses are random_59:0.3734(-2.310355)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4536'\n",
      "Testing (val) took 0:00:00.288000'\n",
      "Epoch 70 finished in 0:00:01.289135 '\n",
      "\n",
      "--- EPOCH 71---'\n",
      "Extractor Train Losses are random_59:0.371(-2.332631)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4561'\n",
      "Testing (val) took 0:00:00.299997'\n",
      "Epoch 71 finished in 0:00:01.302142 '\n",
      "\n",
      "--- EPOCH 72---'\n",
      "Extractor Train Losses are random_59:0.3702(-2.354907)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4564'\n",
      "Testing (val) took 0:00:00.283001'\n",
      "Epoch 72 finished in 0:00:01.252000 '\n",
      "\n",
      "--- EPOCH 73---'\n",
      "Extractor Train Losses are random_59:0.3661(-2.377184)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4498'\n",
      "Testing (val) took 0:00:00.287002'\n",
      "Epoch 73 finished in 0:00:01.256093 '\n",
      "\n",
      "--- EPOCH 74---'\n",
      "Extractor Train Losses are random_59:0.3673(-2.39946)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4472'\n",
      "Testing (val) took 0:00:00.288000'\n",
      "Epoch 74 finished in 0:00:01.261117 '\n",
      "\n",
      "--- EPOCH 75---'\n",
      "Extractor Train Losses are random_59:0.3581(-2.421737)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4436'\n",
      "Testing (val) took 0:00:00.293025'\n",
      "Epoch 75 finished in 0:00:01.272161 '\n",
      "\n",
      "--- EPOCH 76---'\n",
      "Extractor Train Losses are random_59:0.3546(-2.444013)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4434'\n",
      "Testing (val) took 0:00:00.298001'\n",
      "Epoch 76 finished in 0:00:01.288897 '\n",
      "\n",
      "--- EPOCH 77---'\n",
      "Extractor Train Losses are random_59:0.3618(-2.466289)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4429'\n",
      "Testing (val) took 0:00:00.297770'\n",
      "Epoch 77 finished in 0:00:01.267770 '\n",
      "\n",
      "--- EPOCH 78---'\n",
      "Extractor Train Losses are random_59:0.3546(-2.488566)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4414'\n",
      "Testing (val) took 0:00:00.295001'\n",
      "Epoch 78 finished in 0:00:01.262413 '\n",
      "\n",
      "--- EPOCH 79---'\n",
      "Extractor Train Losses are random_59:0.3553(-2.510842)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4428'\n",
      "Testing (val) took 0:00:00.286999'\n",
      "Epoch 79 finished in 0:00:01.257308 '\n",
      "\n",
      "--- EPOCH 80---'\n",
      "Extractor Train Losses are random_59:0.3521(-2.533119)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4425'\n",
      "Testing (val) took 0:00:00.282003'\n",
      "Epoch 80 finished in 0:00:01.229796 '\n",
      "\n",
      "--- EPOCH 81---'\n",
      "Extractor Train Losses are random_59:0.3511(-2.555395)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4499'\n",
      "Testing (val) took 0:00:00.294000'\n",
      "Epoch 81 finished in 0:00:01.326629 '\n",
      "\n",
      "--- EPOCH 82---'\n",
      "Extractor Train Losses are random_59:0.3469(-2.577671)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4433'\n",
      "Testing (val) took 0:00:00.300002'\n",
      "Epoch 82 finished in 0:00:01.314095 '\n",
      "\n",
      "--- EPOCH 83---'\n",
      "Extractor Train Losses are random_59:0.343(-2.599948)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4448'\n",
      "Testing (val) took 0:00:00.295002'\n",
      "Epoch 83 finished in 0:00:01.300083 '\n",
      "\n",
      "--- EPOCH 84---'\n",
      "Extractor Train Losses are random_59:0.3434(-2.622224)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4499'\n",
      "Testing (val) took 0:00:00.307999'\n",
      "Epoch 84 finished in 0:00:01.361181 '\n",
      "\n",
      "--- EPOCH 85---'\n",
      "Extractor Train Losses are random_59:0.3405(-2.644501)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4395'\n",
      "Testing (val) took 0:00:00.315000'\n",
      "Epoch 85 finished in 0:00:01.302108 '\n",
      "\n",
      "--- EPOCH 86---'\n",
      "Extractor Train Losses are random_59:0.3401(-2.666777)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.443'\n",
      "Testing (val) took 0:00:00.304592'\n",
      "Epoch 86 finished in 0:00:01.362591 '\n",
      "\n",
      "--- EPOCH 87---'\n",
      "Extractor Train Losses are random_59:0.3398(-2.689053)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4408'\n",
      "Testing (val) took 0:00:00.296999'\n",
      "Epoch 87 finished in 0:00:01.271104 '\n",
      "\n",
      "--- EPOCH 88---'\n",
      "Extractor Train Losses are random_59:0.3361(-2.71133)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4439'\n",
      "Testing (val) took 0:00:00.299998'\n",
      "Epoch 88 finished in 0:00:01.290103 '\n",
      "\n",
      "--- EPOCH 89---'\n",
      "Extractor Train Losses are random_59:0.3341(-2.733606)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4379'\n",
      "Testing (val) took 0:00:00.297000'\n",
      "Epoch 89 finished in 0:00:01.287536 '\n",
      "\n",
      "--- EPOCH 90---'\n",
      "Extractor Train Losses are random_59:0.3314(-2.755883)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4385'\n",
      "Testing (val) took 0:00:00.288107'\n",
      "Epoch 90 finished in 0:00:01.269603 '\n",
      "\n",
      "--- EPOCH 91---'\n",
      "Extractor Train Losses are random_59:0.3284(-2.778159)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4339'\n",
      "Testing (val) took 0:00:00.297101'\n",
      "Epoch 91 finished in 0:00:01.279991 '\n",
      "\n",
      "--- EPOCH 92---'\n",
      "Extractor Train Losses are random_59:0.3274(-2.800435)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4344'\n",
      "Testing (val) took 0:00:00.289002'\n",
      "Epoch 92 finished in 0:00:01.242891 '\n",
      "\n",
      "--- EPOCH 93---'\n",
      "Extractor Train Losses are random_59:0.3262(-2.822712)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4343'\n",
      "Testing (val) took 0:00:00.295999'\n",
      "Epoch 93 finished in 0:00:01.260992 '\n",
      "\n",
      "--- EPOCH 94---'\n",
      "Extractor Train Losses are random_59:0.3271(-2.844988)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4331'\n",
      "Testing (val) took 0:00:00.295000'\n",
      "Epoch 94 finished in 0:00:01.310083 '\n",
      "\n",
      "--- EPOCH 95---'\n",
      "Extractor Train Losses are random_59:0.3273(-2.867265)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4305'\n",
      "Testing (val) took 0:00:00.294000'\n",
      "Epoch 95 finished in 0:00:01.278177 '\n",
      "\n",
      "--- EPOCH 96---'\n",
      "Extractor Train Losses are random_59:0.3241(-2.889541)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4302'\n",
      "Testing (val) took 0:00:00.286000'\n",
      "Epoch 96 finished in 0:00:01.276108 '\n",
      "\n",
      "--- EPOCH 97---'\n",
      "Extractor Train Losses are random_59:0.3197(-2.911817)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4276'\n",
      "Testing (val) took 0:00:00.295000'\n",
      "Epoch 97 finished in 0:00:01.262001 '\n",
      "\n",
      "--- EPOCH 98---'\n",
      "Extractor Train Losses are random_59:0.3169(-2.934094)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4289'\n",
      "Testing (val) took 0:00:00.302999'\n",
      "Epoch 98 finished in 0:00:01.245228 '\n",
      "\n",
      "--- EPOCH 99---'\n",
      "Extractor Train Losses are random_59:0.3215(-2.95637)'\n",
      "Tested (val) on 1955 instances with mean losses of: random_59:0.4254'\n",
      "Testing (val) took 0:00:00.298997'\n",
      "Epoch 99 finished in 0:00:01.299238 '\n",
      "\n",
      "-----------'\n",
      "Finished training extractors with a best validation loss of random_59:0.4254'\n",
      "Training took 0:02:08.609998'\n",
      "Tested (test) on 1937 instances with mean losses of: random_59:0.3915'\n",
      "Testing (test) took 0:00:00.283001'\n",
      "-----------------------------------Fold 3 - Train 5787 - Val 1937 - Test 1989-----------------------------------'\n",
      "Training extractors on 5787 instances, validating on 1937 instances, for 100 epochs'\n",
      "\n",
      "--- EPOCH 0---'\n",
      "Extractor Train Losses are random_59:24.8606(-0.751007)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:1.2936'\n",
      "Testing (val) took 0:00:00.291088'\n",
      "Epoch 0 finished in 0:00:01.290605 '\n",
      "\n",
      "--- EPOCH 1---'\n",
      "Extractor Train Losses are random_59:1.9108(-0.773283)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.9417'\n",
      "Testing (val) took 0:00:00.300002'\n",
      "Epoch 1 finished in 0:00:01.301002 '\n",
      "\n",
      "--- EPOCH 2---'\n",
      "Extractor Train Losses are random_59:1.2933(-0.79556)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.6454'\n",
      "Testing (val) took 0:00:00.300998'\n",
      "Epoch 2 finished in 0:00:01.289930 '\n",
      "\n",
      "--- EPOCH 3---'\n",
      "Extractor Train Losses are random_59:1.0261(-0.817836)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.7629'\n",
      "Testing (val) took 0:00:00.289602'\n",
      "Epoch 3 finished in 0:00:01.291604 '\n",
      "\n",
      "--- EPOCH 4---'\n",
      "Extractor Train Losses are random_59:0.9355(-0.840113)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.7384'\n",
      "Testing (val) took 0:00:00.284000'\n",
      "Epoch 4 finished in 0:00:01.267520 '\n",
      "\n",
      "--- EPOCH 5---'\n",
      "Extractor Train Losses are random_59:0.8258(-0.862389)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5787'\n",
      "Testing (val) took 0:00:00.277997'\n",
      "Epoch 5 finished in 0:00:01.282093 '\n",
      "\n",
      "--- EPOCH 6---'\n",
      "Extractor Train Losses are random_59:0.8098(-0.884665)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.7043'\n",
      "Testing (val) took 0:00:00.295999'\n",
      "Epoch 6 finished in 0:00:01.273001 '\n",
      "\n",
      "--- EPOCH 7---'\n",
      "Extractor Train Losses are random_59:0.7309(-0.906942)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.7492'\n",
      "Testing (val) took 0:00:00.288000'\n",
      "Epoch 7 finished in 0:00:01.276624 '\n",
      "\n",
      "--- EPOCH 8---'\n",
      "Extractor Train Losses are random_59:0.6896(-0.929218)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.7435'\n",
      "Testing (val) took 0:00:00.285999'\n",
      "Epoch 8 finished in 0:00:01.313621 '\n",
      "\n",
      "--- EPOCH 9---'\n",
      "Extractor Train Losses are random_59:0.6638(-0.951495)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.7675'\n",
      "Testing (val) took 0:00:00.293565'\n",
      "Epoch 9 finished in 0:00:01.305565 '\n",
      "\n",
      "--- EPOCH 10---'\n",
      "Extractor Train Losses are random_59:0.642(-0.973771)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.7393'\n",
      "Testing (val) took 0:00:00.284001'\n",
      "Epoch 10 finished in 0:00:01.315140 '\n",
      "\n",
      "--- EPOCH 11---'\n",
      "Extractor Train Losses are random_59:0.6531(-0.996047)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.7141'\n",
      "Testing (val) took 0:00:00.289002'\n",
      "Epoch 11 finished in 0:00:01.265615 '\n",
      "\n",
      "--- EPOCH 12---'\n",
      "Extractor Train Losses are random_59:0.6513(-1.018324)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.6243'\n",
      "Testing (val) took 0:00:00.316000'\n",
      "Epoch 12 finished in 0:00:01.293783 '\n",
      "\n",
      "--- EPOCH 13---'\n",
      "Extractor Train Losses are random_59:0.6251(-1.0406)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.6331'\n",
      "Testing (val) took 0:00:00.301001'\n",
      "Epoch 13 finished in 0:00:01.289615 '\n",
      "\n",
      "--- EPOCH 14---'\n",
      "Extractor Train Losses are random_59:0.6351(-1.062877)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5765'\n",
      "Testing (val) took 0:00:00.284254'\n",
      "Epoch 14 finished in 0:00:01.243254 '\n",
      "\n",
      "--- EPOCH 15---'\n",
      "Extractor Train Losses are random_59:0.6339(-1.085153)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.548'\n",
      "Testing (val) took 0:00:00.297001'\n",
      "Epoch 15 finished in 0:00:01.269001 '\n",
      "\n",
      "--- EPOCH 16---'\n",
      "Extractor Train Losses are random_59:0.6425(-1.107429)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5412'\n",
      "Testing (val) took 0:00:00.310001'\n",
      "Epoch 16 finished in 0:00:01.326153 '\n",
      "\n",
      "--- EPOCH 17---'\n",
      "Extractor Train Losses are random_59:0.6306(-1.129706)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5311'\n",
      "Testing (val) took 0:00:00.307001'\n",
      "Epoch 17 finished in 0:00:01.286000 '\n",
      "\n",
      "--- EPOCH 18---'\n",
      "Extractor Train Losses are random_59:0.6326(-1.151982)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.6074'\n",
      "Testing (val) took 0:00:00.298001'\n",
      "Epoch 18 finished in 0:00:01.269999 '\n",
      "\n",
      "--- EPOCH 19---'\n",
      "Extractor Train Losses are random_59:0.6709(-1.174259)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5413'\n",
      "Testing (val) took 0:00:00.306999'\n",
      "Epoch 19 finished in 0:00:01.306622 '\n",
      "\n",
      "--- EPOCH 20---'\n",
      "Extractor Train Losses are random_59:0.6426(-1.196535)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5826'\n",
      "Testing (val) took 0:00:00.308001'\n",
      "Epoch 20 finished in 0:00:01.291001 '\n",
      "\n",
      "--- EPOCH 21---'\n",
      "Extractor Train Losses are random_59:0.6228(-1.218811)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5359'\n",
      "Testing (val) took 0:00:00.309998'\n",
      "Epoch 21 finished in 0:00:01.298207 '\n",
      "\n",
      "--- EPOCH 22---'\n",
      "Extractor Train Losses are random_59:0.6079(-1.241088)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.6094'\n",
      "Testing (val) took 0:00:00.307000'\n",
      "Epoch 22 finished in 0:00:01.361262 '\n",
      "\n",
      "--- EPOCH 23---'\n",
      "Extractor Train Losses are random_59:0.605(-1.263364)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.6504'\n",
      "Testing (val) took 0:00:00.299000'\n",
      "Epoch 23 finished in 0:00:01.314030 '\n",
      "\n",
      "--- EPOCH 24---'\n",
      "Extractor Train Losses are random_59:0.6019(-1.285641)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.6924'\n",
      "Testing (val) took 0:00:00.306999'\n",
      "Epoch 24 finished in 0:00:01.307197 '\n",
      "\n",
      "--- EPOCH 25---'\n",
      "Extractor Train Losses are random_59:0.5883(-1.307917)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.591'\n",
      "Testing (val) took 0:00:00.294003'\n",
      "Epoch 25 finished in 0:00:01.276120 '\n",
      "\n",
      "--- EPOCH 26---'\n",
      "Extractor Train Losses are random_59:0.5565(-1.330193)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5824'\n",
      "Testing (val) took 0:00:00.295001'\n",
      "Epoch 26 finished in 0:00:01.298999 '\n",
      "\n",
      "--- EPOCH 27---'\n",
      "Extractor Train Losses are random_59:0.562(-1.35247)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5514'\n",
      "Testing (val) took 0:00:00.291000'\n",
      "Epoch 27 finished in 0:00:01.267128 '\n",
      "\n",
      "--- EPOCH 28---'\n",
      "Extractor Train Losses are random_59:0.5554(-1.374746)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5713'\n",
      "Testing (val) took 0:00:00.277603'\n",
      "Epoch 28 finished in 0:00:01.248604 '\n",
      "\n",
      "--- EPOCH 29---'\n",
      "Extractor Train Losses are random_59:0.5457(-1.397022)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.6426'\n",
      "Testing (val) took 0:00:00.300000'\n",
      "Epoch 29 finished in 0:00:01.278613 '\n",
      "\n",
      "--- EPOCH 30---'\n",
      "Extractor Train Losses are random_59:0.5394(-1.419299)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5404'\n",
      "Testing (val) took 0:00:00.279002'\n",
      "Epoch 30 finished in 0:00:01.244160 '\n",
      "\n",
      "--- EPOCH 31---'\n",
      "Extractor Train Losses are random_59:0.5355(-1.441575)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5196'\n",
      "Testing (val) took 0:00:00.291998'\n",
      "Epoch 31 finished in 0:00:01.274000 '\n",
      "\n",
      "--- EPOCH 32---'\n",
      "Extractor Train Losses are random_59:0.525(-1.463852)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5288'\n",
      "Testing (val) took 0:00:00.302998'\n",
      "Epoch 32 finished in 0:00:01.275273 '\n",
      "\n",
      "--- EPOCH 33---'\n",
      "Extractor Train Losses are random_59:0.5096(-1.486128)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5173'\n",
      "Testing (val) took 0:00:00.296000'\n",
      "Epoch 33 finished in 0:00:01.272277 '\n",
      "\n",
      "--- EPOCH 34---'\n",
      "Extractor Train Losses are random_59:0.5071(-1.508404)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.493'\n",
      "Testing (val) took 0:00:00.294001'\n",
      "Epoch 34 finished in 0:00:01.296001 '\n",
      "\n",
      "--- EPOCH 35---'\n",
      "Extractor Train Losses are random_59:0.519(-1.530681)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5003'\n",
      "Testing (val) took 0:00:00.307001'\n",
      "Epoch 35 finished in 0:00:01.332672 '\n",
      "\n",
      "--- EPOCH 36---'\n",
      "Extractor Train Losses are random_59:0.5049(-1.552957)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4926'\n",
      "Testing (val) took 0:00:00.285000'\n",
      "Epoch 36 finished in 0:00:01.234101 '\n",
      "\n",
      "--- EPOCH 37---'\n",
      "Extractor Train Losses are random_59:0.4916(-1.575234)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5218'\n",
      "Testing (val) took 0:00:00.295000'\n",
      "Epoch 37 finished in 0:00:01.268181 '\n",
      "\n",
      "--- EPOCH 38---'\n",
      "Extractor Train Losses are random_59:0.487(-1.59751)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5082'\n",
      "Testing (val) took 0:00:00.279001'\n",
      "Epoch 38 finished in 0:00:01.250093 '\n",
      "\n",
      "--- EPOCH 39---'\n",
      "Extractor Train Losses are random_59:0.4841(-1.619786)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.519'\n",
      "Testing (val) took 0:00:00.296101'\n",
      "Epoch 39 finished in 0:00:01.280100 '\n",
      "\n",
      "--- EPOCH 40---'\n",
      "Extractor Train Losses are random_59:0.48(-1.642063)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5375'\n",
      "Testing (val) took 0:00:00.301583'\n",
      "Epoch 40 finished in 0:00:01.295585 '\n",
      "\n",
      "--- EPOCH 41---'\n",
      "Extractor Train Losses are random_59:0.4709(-1.664339)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4997'\n",
      "Testing (val) took 0:00:00.295999'\n",
      "Epoch 41 finished in 0:00:01.284131 '\n",
      "\n",
      "--- EPOCH 42---'\n",
      "Extractor Train Losses are random_59:0.4686(-1.686616)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.519'\n",
      "Testing (val) took 0:00:00.298002'\n",
      "Epoch 42 finished in 0:00:01.270999 '\n",
      "\n",
      "--- EPOCH 43---'\n",
      "Extractor Train Losses are random_59:0.4532(-1.708892)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5021'\n",
      "Testing (val) took 0:00:00.275000'\n",
      "Epoch 43 finished in 0:00:01.268000 '\n",
      "\n",
      "--- EPOCH 44---'\n",
      "Extractor Train Losses are random_59:0.4653(-1.731168)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4963'\n",
      "Testing (val) took 0:00:00.296070'\n",
      "Epoch 44 finished in 0:00:01.268154 '\n",
      "\n",
      "--- EPOCH 45---'\n",
      "Extractor Train Losses are random_59:0.4505(-1.753445)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5151'\n",
      "Testing (val) took 0:00:00.287537'\n",
      "Epoch 45 finished in 0:00:01.279547 '\n",
      "\n",
      "--- EPOCH 46---'\n",
      "Extractor Train Losses are random_59:0.4476(-1.775721)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5169'\n",
      "Testing (val) took 0:00:00.292000'\n",
      "Epoch 46 finished in 0:00:01.286188 '\n",
      "\n",
      "--- EPOCH 47---'\n",
      "Extractor Train Losses are random_59:0.4456(-1.797998)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5104'\n",
      "Testing (val) took 0:00:00.301000'\n",
      "Epoch 47 finished in 0:00:01.320135 '\n",
      "\n",
      "--- EPOCH 48---'\n",
      "Extractor Train Losses are random_59:0.4408(-1.820274)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4751'\n",
      "Testing (val) took 0:00:00.296000'\n",
      "Epoch 48 finished in 0:00:01.269577 '\n",
      "\n",
      "--- EPOCH 49---'\n",
      "Extractor Train Losses are random_59:0.4334(-1.84255)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4934'\n",
      "Testing (val) took 0:00:00.293999'\n",
      "Epoch 49 finished in 0:00:01.254213 '\n",
      "\n",
      "--- EPOCH 50---'\n",
      "Extractor Train Losses are random_59:0.4401(-1.864827)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5075'\n",
      "Testing (val) took 0:00:00.286122'\n",
      "Epoch 50 finished in 0:00:01.287122 '\n",
      "\n",
      "--- EPOCH 51---'\n",
      "Extractor Train Losses are random_59:0.4366(-1.887103)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4956'\n",
      "Testing (val) took 0:00:00.282998'\n",
      "Epoch 51 finished in 0:00:01.284002 '\n",
      "\n",
      "--- EPOCH 52---'\n",
      "Extractor Train Losses are random_59:0.4213(-1.90938)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5157'\n",
      "Testing (val) took 0:00:00.290999'\n",
      "Epoch 52 finished in 0:00:01.251143 '\n",
      "\n",
      "--- EPOCH 53---'\n",
      "Extractor Train Losses are random_59:0.4236(-1.931656)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.533'\n",
      "Testing (val) took 0:00:00.294000'\n",
      "Epoch 53 finished in 0:00:01.264000 '\n",
      "\n",
      "--- EPOCH 54---'\n",
      "Extractor Train Losses are random_59:0.4102(-1.953932)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4938'\n",
      "Testing (val) took 0:00:00.275512'\n",
      "Epoch 54 finished in 0:00:01.228664 '\n",
      "\n",
      "--- EPOCH 55---'\n",
      "Extractor Train Losses are random_59:0.4023(-1.976209)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4777'\n",
      "Testing (val) took 0:00:00.296519'\n",
      "Epoch 55 finished in 0:00:01.259602 '\n",
      "\n",
      "--- EPOCH 56---'\n",
      "Extractor Train Losses are random_59:0.4081(-1.998485)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5245'\n",
      "Testing (val) took 0:00:00.301000'\n",
      "Epoch 56 finished in 0:00:01.259680 '\n",
      "\n",
      "--- EPOCH 57---'\n",
      "Extractor Train Losses are random_59:0.4079(-2.020762)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5041'\n",
      "Testing (val) took 0:00:00.297000'\n",
      "Epoch 57 finished in 0:00:01.303788 '\n",
      "\n",
      "--- EPOCH 58---'\n",
      "Extractor Train Losses are random_59:0.407(-2.043038)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.5044'\n",
      "Testing (val) took 0:00:00.362000'\n",
      "Epoch 58 finished in 0:00:01.365107 '\n",
      "\n",
      "--- EPOCH 59---'\n",
      "Extractor Train Losses are random_59:0.3971(-2.065314)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4776'\n",
      "Testing (val) took 0:00:00.298998'\n",
      "Epoch 59 finished in 0:00:01.297511 '\n",
      "\n",
      "--- EPOCH 60---'\n",
      "Extractor Train Losses are random_59:0.3969(-2.087591)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4961'\n",
      "Testing (val) took 0:00:00.286999'\n",
      "Epoch 60 finished in 0:00:01.297104 '\n",
      "\n",
      "--- EPOCH 61---'\n",
      "Extractor Train Losses are random_59:0.3912(-2.109867)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4687'\n",
      "Testing (val) took 0:00:00.300137'\n",
      "Epoch 61 finished in 0:00:01.288137 '\n",
      "\n",
      "--- EPOCH 62---'\n",
      "Extractor Train Losses are random_59:0.387(-2.132144)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.456'\n",
      "Testing (val) took 0:00:00.306001'\n",
      "Epoch 62 finished in 0:00:01.354003 '\n",
      "\n",
      "--- EPOCH 63---'\n",
      "Extractor Train Losses are random_59:0.3891(-2.15442)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4549'\n",
      "Testing (val) took 0:00:00.294000'\n",
      "Epoch 63 finished in 0:00:01.309093 '\n",
      "\n",
      "--- EPOCH 64---'\n",
      "Extractor Train Losses are random_59:0.3841(-2.176696)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4445'\n",
      "Testing (val) took 0:00:00.317611'\n",
      "Epoch 64 finished in 0:00:01.342237 '\n",
      "\n",
      "--- EPOCH 65---'\n",
      "Extractor Train Losses are random_59:0.3778(-2.198973)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4394'\n",
      "Testing (val) took 0:00:00.281999'\n",
      "Epoch 65 finished in 0:00:01.240999 '\n",
      "\n",
      "--- EPOCH 66---'\n",
      "Extractor Train Losses are random_59:0.3778(-2.221249)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4422'\n",
      "Testing (val) took 0:00:00.314998'\n",
      "Epoch 66 finished in 0:00:01.307090 '\n",
      "\n",
      "--- EPOCH 67---'\n",
      "Extractor Train Losses are random_59:0.3736(-2.243525)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4331'\n",
      "Testing (val) took 0:00:00.291114'\n",
      "Epoch 67 finished in 0:00:01.301114 '\n",
      "\n",
      "--- EPOCH 68---'\n",
      "Extractor Train Losses are random_59:0.3688(-2.265802)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4373'\n",
      "Testing (val) took 0:00:00.293001'\n",
      "Epoch 68 finished in 0:00:01.305999 '\n",
      "\n",
      "--- EPOCH 69---'\n",
      "Extractor Train Losses are random_59:0.3616(-2.288078)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4262'\n",
      "Testing (val) took 0:00:00.296001'\n",
      "Epoch 69 finished in 0:00:01.314116 '\n",
      "\n",
      "--- EPOCH 70---'\n",
      "Extractor Train Losses are random_59:0.3611(-2.310355)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4271'\n",
      "Testing (val) took 0:00:00.286998'\n",
      "Epoch 70 finished in 0:00:01.277999 '\n",
      "\n",
      "--- EPOCH 71---'\n",
      "Extractor Train Losses are random_59:0.3628(-2.332631)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4211'\n",
      "Testing (val) took 0:00:00.299002'\n",
      "Epoch 71 finished in 0:00:01.270001 '\n",
      "\n",
      "--- EPOCH 72---'\n",
      "Extractor Train Losses are random_59:0.3596(-2.354907)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4247'\n",
      "Testing (val) took 0:00:00.313000'\n",
      "Epoch 72 finished in 0:00:01.309273 '\n",
      "\n",
      "--- EPOCH 73---'\n",
      "Extractor Train Losses are random_59:0.3523(-2.377184)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4236'\n",
      "Testing (val) took 0:00:00.287000'\n",
      "Epoch 73 finished in 0:00:01.299010 '\n",
      "\n",
      "--- EPOCH 74---'\n",
      "Extractor Train Losses are random_59:0.3505(-2.39946)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4292'\n",
      "Testing (val) took 0:00:00.303002'\n",
      "Epoch 74 finished in 0:00:01.292914 '\n",
      "\n",
      "--- EPOCH 75---'\n",
      "Extractor Train Losses are random_59:0.3491(-2.421737)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4291'\n",
      "Testing (val) took 0:00:00.301591'\n",
      "Epoch 75 finished in 0:00:01.323440 '\n",
      "\n",
      "--- EPOCH 76---'\n",
      "Extractor Train Losses are random_59:0.3466(-2.444013)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4197'\n",
      "Testing (val) took 0:00:00.299997'\n",
      "Epoch 76 finished in 0:00:01.332000 '\n",
      "\n",
      "--- EPOCH 77---'\n",
      "Extractor Train Losses are random_59:0.3446(-2.466289)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4235'\n",
      "Testing (val) took 0:00:00.304000'\n",
      "Epoch 77 finished in 0:00:01.331100 '\n",
      "\n",
      "--- EPOCH 78---'\n",
      "Extractor Train Losses are random_59:0.3467(-2.488566)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4158'\n",
      "Testing (val) took 0:00:00.299003'\n",
      "Epoch 78 finished in 0:00:01.294001 '\n",
      "\n",
      "--- EPOCH 79---'\n",
      "Extractor Train Losses are random_59:0.3392(-2.510842)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4167'\n",
      "Testing (val) took 0:00:00.313001'\n",
      "Epoch 79 finished in 0:00:01.348762 '\n",
      "\n",
      "--- EPOCH 80---'\n",
      "Extractor Train Losses are random_59:0.338(-2.533119)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4138'\n",
      "Testing (val) took 0:00:00.309002'\n",
      "Epoch 80 finished in 0:00:01.326001 '\n",
      "\n",
      "--- EPOCH 81---'\n",
      "Extractor Train Losses are random_59:0.3356(-2.555395)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4143'\n",
      "Testing (val) took 0:00:00.307003'\n",
      "Epoch 81 finished in 0:00:01.340425 '\n",
      "\n",
      "--- EPOCH 82---'\n",
      "Extractor Train Losses are random_59:0.3313(-2.577671)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4141'\n",
      "Testing (val) took 0:00:00.313000'\n",
      "Epoch 82 finished in 0:00:01.353997 '\n",
      "\n",
      "--- EPOCH 83---'\n",
      "Extractor Train Losses are random_59:0.3305(-2.599948)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4181'\n",
      "Testing (val) took 0:00:00.294000'\n",
      "Epoch 83 finished in 0:00:01.347228 '\n",
      "\n",
      "--- EPOCH 84---'\n",
      "Extractor Train Losses are random_59:0.3326(-2.622224)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4174'\n",
      "Testing (val) took 0:00:00.317999'\n",
      "Epoch 84 finished in 0:00:01.336112 '\n",
      "\n",
      "--- EPOCH 85---'\n",
      "Extractor Train Losses are random_59:0.3271(-2.644501)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4141'\n",
      "Testing (val) took 0:00:00.306997'\n",
      "Epoch 85 finished in 0:00:01.330028 '\n",
      "\n",
      "--- EPOCH 86---'\n",
      "Extractor Train Losses are random_59:0.3246(-2.666777)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4159'\n",
      "Testing (val) took 0:00:00.296001'\n",
      "Epoch 86 finished in 0:00:01.315104 '\n",
      "\n",
      "--- EPOCH 87---'\n",
      "Extractor Train Losses are random_59:0.3287(-2.689053)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4157'\n",
      "Testing (val) took 0:00:00.304999'\n",
      "Epoch 87 finished in 0:00:01.309347 '\n",
      "\n",
      "--- EPOCH 88---'\n",
      "Extractor Train Losses are random_59:0.3212(-2.71133)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4127'\n",
      "Testing (val) took 0:00:00.332998'\n",
      "Epoch 88 finished in 0:00:01.351001 '\n",
      "\n",
      "--- EPOCH 89---'\n",
      "Extractor Train Losses are random_59:0.3237(-2.733606)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4133'\n",
      "Testing (val) took 0:00:00.288998'\n",
      "Epoch 89 finished in 0:00:01.315622 '\n",
      "\n",
      "--- EPOCH 90---'\n",
      "Extractor Train Losses are random_59:0.3191(-2.755883)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4137'\n",
      "Testing (val) took 0:00:00.301571'\n",
      "Epoch 90 finished in 0:00:01.333655 '\n",
      "\n",
      "--- EPOCH 91---'\n",
      "Extractor Train Losses are random_59:0.3175(-2.778159)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4128'\n",
      "Testing (val) took 0:00:00.316000'\n",
      "Epoch 91 finished in 0:00:01.350001 '\n",
      "\n",
      "--- EPOCH 92---'\n",
      "Extractor Train Losses are random_59:0.3196(-2.800435)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4186'\n",
      "Testing (val) took 0:00:00.307001'\n",
      "Epoch 92 finished in 0:00:01.312621 '\n",
      "\n",
      "--- EPOCH 93---'\n",
      "Extractor Train Losses are random_59:0.3199(-2.822712)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4185'\n",
      "Testing (val) took 0:00:00.323000'\n",
      "Epoch 93 finished in 0:00:01.369001 '\n",
      "\n",
      "--- EPOCH 94---'\n",
      "Extractor Train Losses are random_59:0.315(-2.844988)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4182'\n",
      "Testing (val) took 0:00:00.326266'\n",
      "Epoch 94 finished in 0:00:01.319380 '\n",
      "\n",
      "--- EPOCH 95---'\n",
      "Extractor Train Losses are random_59:0.3124(-2.867265)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.417'\n",
      "Testing (val) took 0:00:00.315003'\n",
      "Epoch 95 finished in 0:00:01.309100 '\n",
      "\n",
      "--- EPOCH 96---'\n",
      "Extractor Train Losses are random_59:0.3121(-2.889541)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4154'\n",
      "Testing (val) took 0:00:00.283104'\n",
      "Epoch 96 finished in 0:00:01.263102 '\n",
      "\n",
      "--- EPOCH 97---'\n",
      "Extractor Train Losses are random_59:0.3119(-2.911817)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4147'\n",
      "Testing (val) took 0:00:00.291999'\n",
      "Epoch 97 finished in 0:00:01.254996 '\n",
      "\n",
      "--- EPOCH 98---'\n",
      "Extractor Train Losses are random_59:0.3132(-2.934094)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4141'\n",
      "Testing (val) took 0:00:00.297001'\n",
      "Epoch 98 finished in 0:00:01.278129 '\n",
      "\n",
      "--- EPOCH 99---'\n",
      "Extractor Train Losses are random_59:0.3077(-2.95637)'\n",
      "Tested (val) on 1937 instances with mean losses of: random_59:0.4134'\n",
      "Testing (val) took 0:00:00.293213'\n",
      "Epoch 99 finished in 0:00:01.273212 '\n",
      "\n",
      "-----------'\n",
      "Finished training extractors with a best validation loss of random_59:0.4127'\n",
      "Training took 0:02:09.651379'\n",
      "Tested (test) on 1989 instances with mean losses of: random_59:0.4542'\n",
      "Testing (test) took 0:00:00.325000'\n",
      "-----------------------------------Fold 4 - Train 5797 - Val 1989 - Test 1927-----------------------------------'\n",
      "Training extractors on 5797 instances, validating on 1989 instances, for 100 epochs'\n",
      "\n",
      "--- EPOCH 0---'\n",
      "Extractor Train Losses are random_59:42.115(-0.751007)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:1.5482'\n",
      "Testing (val) took 0:00:00.298997'\n",
      "Epoch 0 finished in 0:00:01.286998 '\n",
      "\n",
      "--- EPOCH 1---'\n",
      "Extractor Train Losses are random_59:2.0027(-0.773283)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:1.196'\n",
      "Testing (val) took 0:00:00.313562'\n",
      "Epoch 1 finished in 0:00:01.301566 '\n",
      "\n",
      "--- EPOCH 2---'\n",
      "Extractor Train Losses are random_59:1.2272(-0.79556)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.9967'\n",
      "Testing (val) took 0:00:00.288999'\n",
      "Epoch 2 finished in 0:00:01.285109 '\n",
      "\n",
      "--- EPOCH 3---'\n",
      "Extractor Train Losses are random_59:0.9937(-0.817836)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:1.0725'\n",
      "Testing (val) took 0:00:00.319000'\n",
      "Epoch 3 finished in 0:00:01.339000 '\n",
      "\n",
      "--- EPOCH 4---'\n",
      "Extractor Train Losses are random_59:0.9679(-0.840113)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:1.3428'\n",
      "Testing (val) took 0:00:00.314998'\n",
      "Epoch 4 finished in 0:00:01.324671 '\n",
      "\n",
      "--- EPOCH 5---'\n",
      "Extractor Train Losses are random_59:0.8423(-0.862389)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:1.5167'\n",
      "Testing (val) took 0:00:00.288000'\n",
      "Epoch 5 finished in 0:00:01.311512 '\n",
      "\n",
      "--- EPOCH 6---'\n",
      "Extractor Train Losses are random_59:0.8911(-0.884665)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:1.0589'\n",
      "Testing (val) took 0:00:00.301001'\n",
      "Epoch 6 finished in 0:00:01.252910 '\n",
      "\n",
      "--- EPOCH 7---'\n",
      "Extractor Train Losses are random_59:0.8001(-0.906942)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:1.2224'\n",
      "Testing (val) took 0:00:00.305015'\n",
      "Epoch 7 finished in 0:00:01.279016 '\n",
      "\n",
      "--- EPOCH 8---'\n",
      "Extractor Train Losses are random_59:0.7975(-0.929218)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.735'\n",
      "Testing (val) took 0:00:00.304001'\n",
      "Epoch 8 finished in 0:00:01.310222 '\n",
      "\n",
      "--- EPOCH 9---'\n",
      "Extractor Train Losses are random_59:0.697(-0.951495)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6985'\n",
      "Testing (val) took 0:00:00.298999'\n",
      "Epoch 9 finished in 0:00:01.271646 '\n",
      "\n",
      "--- EPOCH 10---'\n",
      "Extractor Train Losses are random_59:0.6812(-0.973771)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.643'\n",
      "Testing (val) took 0:00:00.290997'\n",
      "Epoch 10 finished in 0:00:01.258081 '\n",
      "\n",
      "--- EPOCH 11---'\n",
      "Extractor Train Losses are random_59:0.6518(-0.996047)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.7097'\n",
      "Testing (val) took 0:00:00.306090'\n",
      "Epoch 11 finished in 0:00:01.292099 '\n",
      "\n",
      "--- EPOCH 12---'\n",
      "Extractor Train Losses are random_59:0.6605(-1.018324)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6163'\n",
      "Testing (val) took 0:00:00.289001'\n",
      "Epoch 12 finished in 0:00:01.222998 '\n",
      "\n",
      "--- EPOCH 13---'\n",
      "Extractor Train Losses are random_59:0.6491(-1.0406)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6243'\n",
      "Testing (val) took 0:00:00.296591'\n",
      "Epoch 13 finished in 0:00:01.286142 '\n",
      "\n",
      "--- EPOCH 14---'\n",
      "Extractor Train Losses are random_59:0.6414(-1.062877)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6656'\n",
      "Testing (val) took 0:00:00.292002'\n",
      "Epoch 14 finished in 0:00:01.304994 '\n",
      "\n",
      "--- EPOCH 15---'\n",
      "Extractor Train Losses are random_59:0.6241(-1.085153)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.8251'\n",
      "Testing (val) took 0:00:00.343038'\n",
      "Epoch 15 finished in 0:00:01.453038 '\n",
      "\n",
      "--- EPOCH 16---'\n",
      "Extractor Train Losses are random_59:0.6402(-1.107429)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.8866'\n",
      "Testing (val) took 0:00:00.318002'\n",
      "Epoch 16 finished in 0:00:01.424132 '\n",
      "\n",
      "--- EPOCH 17---'\n",
      "Extractor Train Losses are random_59:0.658(-1.129706)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6966'\n",
      "Testing (val) took 0:00:00.304178'\n",
      "Epoch 17 finished in 0:00:01.451281 '\n",
      "\n",
      "--- EPOCH 18---'\n",
      "Extractor Train Losses are random_59:0.6435(-1.151982)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6128'\n",
      "Testing (val) took 0:00:00.326999'\n",
      "Epoch 18 finished in 0:00:01.341999 '\n",
      "\n",
      "--- EPOCH 19---'\n",
      "Extractor Train Losses are random_59:0.6098(-1.174259)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.658'\n",
      "Testing (val) took 0:00:00.302998'\n",
      "Epoch 19 finished in 0:00:01.306154 '\n",
      "\n",
      "--- EPOCH 20---'\n",
      "Extractor Train Losses are random_59:0.5838(-1.196535)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6285'\n",
      "Testing (val) took 0:00:00.304109'\n",
      "Epoch 20 finished in 0:00:01.275112 '\n",
      "\n",
      "--- EPOCH 21---'\n",
      "Extractor Train Losses are random_59:0.5795(-1.218811)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6652'\n",
      "Testing (val) took 0:00:00.298000'\n",
      "Epoch 21 finished in 0:00:01.287998 '\n",
      "\n",
      "--- EPOCH 22---'\n",
      "Extractor Train Losses are random_59:0.5695(-1.241088)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6813'\n",
      "Testing (val) took 0:00:00.304997'\n",
      "Epoch 22 finished in 0:00:01.274000 '\n",
      "\n",
      "--- EPOCH 23---'\n",
      "Extractor Train Losses are random_59:0.57(-1.263364)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6748'\n",
      "Testing (val) took 0:00:00.299090'\n",
      "Epoch 23 finished in 0:00:01.310088 '\n",
      "\n",
      "--- EPOCH 24---'\n",
      "Extractor Train Losses are random_59:0.5502(-1.285641)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6376'\n",
      "Testing (val) took 0:00:00.301999'\n",
      "Epoch 24 finished in 0:00:01.296594 '\n",
      "\n",
      "--- EPOCH 25---'\n",
      "Extractor Train Losses are random_59:0.5413(-1.307917)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6616'\n",
      "Testing (val) took 0:00:00.308001'\n",
      "Epoch 25 finished in 0:00:01.314999 '\n",
      "\n",
      "--- EPOCH 26---'\n",
      "Extractor Train Losses are random_59:0.5394(-1.330193)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6179'\n",
      "Testing (val) took 0:00:00.304003'\n",
      "Epoch 26 finished in 0:00:01.294001 '\n",
      "\n",
      "--- EPOCH 27---'\n",
      "Extractor Train Losses are random_59:0.5398(-1.35247)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6283'\n",
      "Testing (val) took 0:00:00.301998'\n",
      "Epoch 27 finished in 0:00:01.286115 '\n",
      "\n",
      "--- EPOCH 28---'\n",
      "Extractor Train Losses are random_59:0.5231(-1.374746)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6067'\n",
      "Testing (val) took 0:00:00.307000'\n",
      "Epoch 28 finished in 0:00:01.294188 '\n",
      "\n",
      "--- EPOCH 29---'\n",
      "Extractor Train Losses are random_59:0.532(-1.397022)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6655'\n",
      "Testing (val) took 0:00:00.299000'\n",
      "Epoch 29 finished in 0:00:01.292000 '\n",
      "\n",
      "--- EPOCH 30---'\n",
      "Extractor Train Losses are random_59:0.5367(-1.419299)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6528'\n",
      "Testing (val) took 0:00:00.310000'\n",
      "Epoch 30 finished in 0:00:01.337090 '\n",
      "\n",
      "--- EPOCH 31---'\n",
      "Extractor Train Losses are random_59:0.5375(-1.441575)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5915'\n",
      "Testing (val) took 0:00:00.353998'\n",
      "Epoch 31 finished in 0:00:01.394168 '\n",
      "\n",
      "--- EPOCH 32---'\n",
      "Extractor Train Losses are random_59:0.5342(-1.463852)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6647'\n",
      "Testing (val) took 0:00:00.313999'\n",
      "Epoch 32 finished in 0:00:01.354999 '\n",
      "\n",
      "--- EPOCH 33---'\n",
      "Extractor Train Losses are random_59:0.5297(-1.486128)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6404'\n",
      "Testing (val) took 0:00:00.299000'\n",
      "Epoch 33 finished in 0:00:01.351116 '\n",
      "\n",
      "--- EPOCH 34---'\n",
      "Extractor Train Losses are random_59:0.5223(-1.508404)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6079'\n",
      "Testing (val) took 0:00:00.294000'\n",
      "Epoch 34 finished in 0:00:01.303099 '\n",
      "\n",
      "--- EPOCH 35---'\n",
      "Extractor Train Losses are random_59:0.5095(-1.530681)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6411'\n",
      "Testing (val) took 0:00:00.303000'\n",
      "Epoch 35 finished in 0:00:01.277998 '\n",
      "\n",
      "--- EPOCH 36---'\n",
      "Extractor Train Losses are random_59:0.5093(-1.552957)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5764'\n",
      "Testing (val) took 0:00:00.319000'\n",
      "Epoch 36 finished in 0:00:01.309579 '\n",
      "\n",
      "--- EPOCH 37---'\n",
      "Extractor Train Losses are random_59:0.499(-1.575234)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.6147'\n",
      "Testing (val) took 0:00:00.348001'\n",
      "Epoch 37 finished in 0:00:01.369001 '\n",
      "\n",
      "--- EPOCH 38---'\n",
      "Extractor Train Losses are random_59:0.5034(-1.59751)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5649'\n",
      "Testing (val) took 0:00:00.295000'\n",
      "Epoch 38 finished in 0:00:01.281998 '\n",
      "\n",
      "--- EPOCH 39---'\n",
      "Extractor Train Losses are random_59:0.4955(-1.619786)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5856'\n",
      "Testing (val) took 0:00:00.312591'\n",
      "Epoch 39 finished in 0:00:01.291692 '\n",
      "\n",
      "--- EPOCH 40---'\n",
      "Extractor Train Losses are random_59:0.5042(-1.642063)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5742'\n",
      "Testing (val) took 0:00:00.301999'\n",
      "Epoch 40 finished in 0:00:01.292580 '\n",
      "\n",
      "--- EPOCH 41---'\n",
      "Extractor Train Losses are random_59:0.4811(-1.664339)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5448'\n",
      "Testing (val) took 0:00:00.300001'\n",
      "Epoch 41 finished in 0:00:01.277001 '\n",
      "\n",
      "--- EPOCH 42---'\n",
      "Extractor Train Losses are random_59:0.4659(-1.686616)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5549'\n",
      "Testing (val) took 0:00:00.302000'\n",
      "Epoch 42 finished in 0:00:01.272109 '\n",
      "\n",
      "--- EPOCH 43---'\n",
      "Extractor Train Losses are random_59:0.468(-1.708892)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5389'\n",
      "Testing (val) took 0:00:00.297734'\n",
      "Epoch 43 finished in 0:00:01.287737 '\n",
      "\n",
      "--- EPOCH 44---'\n",
      "Extractor Train Losses are random_59:0.4688(-1.731168)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5508'\n",
      "Testing (val) took 0:00:00.303002'\n",
      "Epoch 44 finished in 0:00:01.300001 '\n",
      "\n",
      "--- EPOCH 45---'\n",
      "Extractor Train Losses are random_59:0.4549(-1.753445)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5713'\n",
      "Testing (val) took 0:00:00.311001'\n",
      "Epoch 45 finished in 0:00:01.314110 '\n",
      "\n",
      "--- EPOCH 46---'\n",
      "Extractor Train Losses are random_59:0.459(-1.775721)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.535'\n",
      "Testing (val) took 0:00:00.318002'\n",
      "Epoch 46 finished in 0:00:01.384001 '\n",
      "\n",
      "--- EPOCH 47---'\n",
      "Extractor Train Losses are random_59:0.4496(-1.797998)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5515'\n",
      "Testing (val) took 0:00:00.301998'\n",
      "Epoch 47 finished in 0:00:01.296120 '\n",
      "\n",
      "--- EPOCH 48---'\n",
      "Extractor Train Losses are random_59:0.4459(-1.820274)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5412'\n",
      "Testing (val) took 0:00:00.295000'\n",
      "Epoch 48 finished in 0:00:01.299571 '\n",
      "\n",
      "--- EPOCH 49---'\n",
      "Extractor Train Losses are random_59:0.4366(-1.84255)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5832'\n",
      "Testing (val) took 0:00:00.333796'\n",
      "Epoch 49 finished in 0:00:01.343796 '\n",
      "\n",
      "--- EPOCH 50---'\n",
      "Extractor Train Losses are random_59:0.429(-1.864827)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5796'\n",
      "Testing (val) took 0:00:00.295001'\n",
      "Epoch 50 finished in 0:00:01.346570 '\n",
      "\n",
      "--- EPOCH 51---'\n",
      "Extractor Train Losses are random_59:0.4264(-1.887103)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5569'\n",
      "Testing (val) took 0:00:00.305000'\n",
      "Epoch 51 finished in 0:00:01.337683 '\n",
      "\n",
      "--- EPOCH 52---'\n",
      "Extractor Train Losses are random_59:0.4223(-1.90938)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5619'\n",
      "Testing (val) took 0:00:00.311984'\n",
      "Epoch 52 finished in 0:00:01.327988 '\n",
      "\n",
      "--- EPOCH 53---'\n",
      "Extractor Train Losses are random_59:0.42(-1.931656)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5741'\n",
      "Testing (val) took 0:00:00.305288'\n",
      "Epoch 53 finished in 0:00:01.291285 '\n",
      "\n",
      "--- EPOCH 54---'\n",
      "Extractor Train Losses are random_59:0.4102(-1.953932)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5309'\n",
      "Testing (val) took 0:00:00.316002'\n",
      "Epoch 54 finished in 0:00:01.346110 '\n",
      "\n",
      "--- EPOCH 55---'\n",
      "Extractor Train Losses are random_59:0.408(-1.976209)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.565'\n",
      "Testing (val) took 0:00:00.309084'\n",
      "Epoch 55 finished in 0:00:01.314181 '\n",
      "\n",
      "--- EPOCH 56---'\n",
      "Extractor Train Losses are random_59:0.4062(-1.998485)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5619'\n",
      "Testing (val) took 0:00:00.318003'\n",
      "Epoch 56 finished in 0:00:01.306000 '\n",
      "\n",
      "--- EPOCH 57---'\n",
      "Extractor Train Losses are random_59:0.4091(-2.020762)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5864'\n",
      "Testing (val) took 0:00:00.295998'\n",
      "Epoch 57 finished in 0:00:01.279088 '\n",
      "\n",
      "--- EPOCH 58---'\n",
      "Extractor Train Losses are random_59:0.3982(-2.043038)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5318'\n",
      "Testing (val) took 0:00:00.312769'\n",
      "Epoch 58 finished in 0:00:01.330771 '\n",
      "\n",
      "--- EPOCH 59---'\n",
      "Extractor Train Losses are random_59:0.3914(-2.065314)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5325'\n",
      "Testing (val) took 0:00:00.297000'\n",
      "Epoch 59 finished in 0:00:01.294126 '\n",
      "\n",
      "--- EPOCH 60---'\n",
      "Extractor Train Losses are random_59:0.3906(-2.087591)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.522'\n",
      "Testing (val) took 0:00:00.288999'\n",
      "Epoch 60 finished in 0:00:01.257094 '\n",
      "\n",
      "--- EPOCH 61---'\n",
      "Extractor Train Losses are random_59:0.3871(-2.109867)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5482'\n",
      "Testing (val) took 0:00:00.299998'\n",
      "Epoch 61 finished in 0:00:01.281998 '\n",
      "\n",
      "--- EPOCH 62---'\n",
      "Extractor Train Losses are random_59:0.3901(-2.132144)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5386'\n",
      "Testing (val) took 0:00:00.298671'\n",
      "Epoch 62 finished in 0:00:01.273760 '\n",
      "\n",
      "--- EPOCH 63---'\n",
      "Extractor Train Losses are random_59:0.3835(-2.15442)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5132'\n",
      "Testing (val) took 0:00:00.300000'\n",
      "Epoch 63 finished in 0:00:01.290118 '\n",
      "\n",
      "--- EPOCH 64---'\n",
      "Extractor Train Losses are random_59:0.3809(-2.176696)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5274'\n",
      "Testing (val) took 0:00:00.314000'\n",
      "Epoch 64 finished in 0:00:01.279000 '\n",
      "\n",
      "--- EPOCH 65---'\n",
      "Extractor Train Losses are random_59:0.3817(-2.198973)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5034'\n",
      "Testing (val) took 0:00:00.310001'\n",
      "Epoch 65 finished in 0:00:01.405092 '\n",
      "\n",
      "--- EPOCH 66---'\n",
      "Extractor Train Losses are random_59:0.3734(-2.221249)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4889'\n",
      "Testing (val) took 0:00:00.302128'\n",
      "Epoch 66 finished in 0:00:01.289746 '\n",
      "\n",
      "--- EPOCH 67---'\n",
      "Extractor Train Losses are random_59:0.3708(-2.243525)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.5051'\n",
      "Testing (val) took 0:00:00.301001'\n",
      "Epoch 67 finished in 0:00:01.306998 '\n",
      "\n",
      "--- EPOCH 68---'\n",
      "Extractor Train Losses are random_59:0.3657(-2.265802)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4696'\n",
      "Testing (val) took 0:00:00.308001'\n",
      "Epoch 68 finished in 0:00:01.341273 '\n",
      "\n",
      "--- EPOCH 69---'\n",
      "Extractor Train Losses are random_59:0.3648(-2.288078)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4638'\n",
      "Testing (val) took 0:00:00.312117'\n",
      "Epoch 69 finished in 0:00:01.316117 '\n",
      "\n",
      "--- EPOCH 70---'\n",
      "Extractor Train Losses are random_59:0.3667(-2.310355)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4588'\n",
      "Testing (val) took 0:00:00.294997'\n",
      "Epoch 70 finished in 0:00:01.273600 '\n",
      "\n",
      "--- EPOCH 71---'\n",
      "Extractor Train Losses are random_59:0.3596(-2.332631)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4615'\n",
      "Testing (val) took 0:00:00.289999'\n",
      "Epoch 71 finished in 0:00:01.246135 '\n",
      "\n",
      "--- EPOCH 72---'\n",
      "Extractor Train Losses are random_59:0.3581(-2.354907)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4563'\n",
      "Testing (val) took 0:00:00.295115'\n",
      "Epoch 72 finished in 0:00:01.354121 '\n",
      "\n",
      "--- EPOCH 73---'\n",
      "Extractor Train Losses are random_59:0.3521(-2.377184)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4549'\n",
      "Testing (val) took 0:00:00.301999'\n",
      "Epoch 73 finished in 0:00:01.279997 '\n",
      "\n",
      "--- EPOCH 74---'\n",
      "Extractor Train Losses are random_59:0.3521(-2.39946)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4556'\n",
      "Testing (val) took 0:00:00.301999'\n",
      "Epoch 74 finished in 0:00:01.277821 '\n",
      "\n",
      "--- EPOCH 75---'\n",
      "Extractor Train Losses are random_59:0.3499(-2.421737)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4492'\n",
      "Testing (val) took 0:00:00.302998'\n",
      "Epoch 75 finished in 0:00:01.261999 '\n",
      "\n",
      "--- EPOCH 76---'\n",
      "Extractor Train Losses are random_59:0.3508(-2.444013)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4536'\n",
      "Testing (val) took 0:00:00.313002'\n",
      "Epoch 76 finished in 0:00:01.296002 '\n",
      "\n",
      "--- EPOCH 77---'\n",
      "Extractor Train Losses are random_59:0.3447(-2.466289)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4494'\n",
      "Testing (val) took 0:00:00.294002'\n",
      "Epoch 77 finished in 0:00:01.249093 '\n",
      "\n",
      "--- EPOCH 78---'\n",
      "Extractor Train Losses are random_59:0.3434(-2.488566)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4474'\n",
      "Testing (val) took 0:00:00.301000'\n",
      "Epoch 78 finished in 0:00:01.292098 '\n",
      "\n",
      "--- EPOCH 79---'\n",
      "Extractor Train Losses are random_59:0.3404(-2.510842)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4487'\n",
      "Testing (val) took 0:00:00.335001'\n",
      "Epoch 79 finished in 0:00:01.321642 '\n",
      "\n",
      "--- EPOCH 80---'\n",
      "Extractor Train Losses are random_59:0.34(-2.533119)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4485'\n",
      "Testing (val) took 0:00:00.302000'\n",
      "Epoch 80 finished in 0:00:01.282108 '\n",
      "\n",
      "--- EPOCH 81---'\n",
      "Extractor Train Losses are random_59:0.3325(-2.555395)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4438'\n",
      "Testing (val) took 0:00:00.299001'\n",
      "Epoch 81 finished in 0:00:01.281002 '\n",
      "\n",
      "--- EPOCH 82---'\n",
      "Extractor Train Losses are random_59:0.3307(-2.577671)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4437'\n",
      "Testing (val) took 0:00:00.311999'\n",
      "Epoch 82 finished in 0:00:01.324215 '\n",
      "\n",
      "--- EPOCH 83---'\n",
      "Extractor Train Losses are random_59:0.3365(-2.599948)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4434'\n",
      "Testing (val) took 0:00:00.310121'\n",
      "Epoch 83 finished in 0:00:01.331121 '\n",
      "\n",
      "--- EPOCH 84---'\n",
      "Extractor Train Losses are random_59:0.3305(-2.622224)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4441'\n",
      "Testing (val) took 0:00:00.305999'\n",
      "Epoch 84 finished in 0:00:01.316515 '\n",
      "\n",
      "--- EPOCH 85---'\n",
      "Extractor Train Losses are random_59:0.3319(-2.644501)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4412'\n",
      "Testing (val) took 0:00:00.290082'\n",
      "Epoch 85 finished in 0:00:01.289769 '\n",
      "\n",
      "--- EPOCH 86---'\n",
      "Extractor Train Losses are random_59:0.3324(-2.666777)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4462'\n",
      "Testing (val) took 0:00:00.309171'\n",
      "Epoch 86 finished in 0:00:01.345357 '\n",
      "\n",
      "--- EPOCH 87---'\n",
      "Extractor Train Losses are random_59:0.3252(-2.689053)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4414'\n",
      "Testing (val) took 0:00:00.291000'\n",
      "Epoch 87 finished in 0:00:01.289001 '\n",
      "\n",
      "--- EPOCH 88---'\n",
      "Extractor Train Losses are random_59:0.3287(-2.71133)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4386'\n",
      "Testing (val) took 0:00:00.305000'\n",
      "Epoch 88 finished in 0:00:01.365109 '\n",
      "\n",
      "--- EPOCH 89---'\n",
      "Extractor Train Losses are random_59:0.3258(-2.733606)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4363'\n",
      "Testing (val) took 0:00:00.309141'\n",
      "Epoch 89 finished in 0:00:01.313240 '\n",
      "\n",
      "--- EPOCH 90---'\n",
      "Extractor Train Losses are random_59:0.3208(-2.755883)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.439'\n",
      "Testing (val) took 0:00:00.312000'\n",
      "Epoch 90 finished in 0:00:01.276998 '\n",
      "\n",
      "--- EPOCH 91---'\n",
      "Extractor Train Losses are random_59:0.3227(-2.778159)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4381'\n",
      "Testing (val) took 0:00:00.289000'\n",
      "Epoch 91 finished in 0:00:01.244102 '\n",
      "\n",
      "--- EPOCH 92---'\n",
      "Extractor Train Losses are random_59:0.3194(-2.800435)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4385'\n",
      "Testing (val) took 0:00:00.311999'\n",
      "Epoch 92 finished in 0:00:01.298997 '\n",
      "\n",
      "--- EPOCH 93---'\n",
      "Extractor Train Losses are random_59:0.3221(-2.822712)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4371'\n",
      "Testing (val) took 0:00:00.302998'\n",
      "Epoch 93 finished in 0:00:01.342665 '\n",
      "\n",
      "--- EPOCH 94---'\n",
      "Extractor Train Losses are random_59:0.3231(-2.844988)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4362'\n",
      "Testing (val) took 0:00:00.302001'\n",
      "Epoch 94 finished in 0:00:01.261000 '\n",
      "\n",
      "--- EPOCH 95---'\n",
      "Extractor Train Losses are random_59:0.3214(-2.867265)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4335'\n",
      "Testing (val) took 0:00:00.308999'\n",
      "Epoch 95 finished in 0:00:01.261998 '\n",
      "\n",
      "--- EPOCH 96---'\n",
      "Extractor Train Losses are random_59:0.316(-2.889541)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4346'\n",
      "Testing (val) took 0:00:00.291998'\n",
      "Epoch 96 finished in 0:00:01.290000 '\n",
      "\n",
      "--- EPOCH 97---'\n",
      "Extractor Train Losses are random_59:0.3197(-2.911817)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.435'\n",
      "Testing (val) took 0:00:00.297000'\n",
      "Epoch 97 finished in 0:00:01.314588 '\n",
      "\n",
      "--- EPOCH 98---'\n",
      "Extractor Train Losses are random_59:0.3179(-2.934094)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4358'\n",
      "Testing (val) took 0:00:00.294998'\n",
      "Epoch 98 finished in 0:00:01.286002 '\n",
      "\n",
      "--- EPOCH 99---'\n",
      "Extractor Train Losses are random_59:0.3164(-2.95637)'\n",
      "Tested (val) on 1989 instances with mean losses of: random_59:0.4355'\n",
      "Testing (val) took 0:00:00.294001'\n",
      "Epoch 99 finished in 0:00:01.254066 '\n",
      "\n",
      "-----------'\n",
      "Finished training extractors with a best validation loss of random_59:0.4335'\n",
      "Training took 0:02:10.695823'\n",
      "Tested (test) on 1927 instances with mean losses of: random_59:0.4478'\n",
      "Testing (test) took 0:00:00.330997'\n",
      "Train times: {'fold_0': 129, 'fold_1': 130, 'fold_2': 128, 'fold_3': 129, 'fold_4': 130, 'mean': 129.2}'\n",
      "Test times: {'fold_0': 0, 'fold_1': 0, 'fold_2': 0, 'fold_3': 0, 'fold_4': 0, 'mean': 0.0}'\n"
     ]
    }
   ],
   "source": [
    "n_models = 100\n",
    "epochs = 100\n",
    "bs = 32\n",
    "fixed_hyperparams = {'bs': bs,'loss': nn.MSELoss(),'epochs': epochs}\n",
    "device = \"cpu\" #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#setup models\n",
    "config_gen = RandomConfigGen(lr= (0,1),\n",
    "                             allow_increase_size=False,\n",
    "                             n_features=selected_comps,\n",
    "                             opt=[torch.optim.SGD,\n",
    "                                  torch.optim.Adam],\n",
    "                             lr_update = [None,\n",
    "                                          torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                                          torch.optim.lr_scheduler.ExponentialLR,\n",
    "                                          torch.optim.lr_scheduler.CosineAnnealingLR],\n",
    "                            dropout = [True,False],\n",
    "                            batch_norm = [True,False])\n",
    "configs = {f\"random_{i}\":config_gen.sample() for i in range(n_models)}\n",
    "config_gen.save(log_dir/'config_gen.txt')\n",
    "\n",
    "deep_models = {name:RandomNet(input_size=selected_comps,\n",
    "                             n_layers=config.n_layers,\n",
    "                             act_function=config.act_function,\n",
    "                             n_features = config.n_features,\n",
    "                             dropout=config.dropout,\n",
    "                             batch_norm=config.batch_norm,\n",
    "                             device=device,dtype=torch.float)\n",
    "              for name, config in configs.items()}\n",
    "\n",
    "ex.write_summary_head(seed,fixed_hyperparams)\n",
    "ex.save_models(deep_models,configs,log_dir)\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "name = \"random_59\"\n",
    "deep_models = {name:deep_models[name]}\n",
    "configs = {name:configs[name]}\n",
    "deep_scheme = DeepScheme(configs,fixed_hyperparams=fixed_hyperparams,logger=\"log\",device=device,adaptive_lr=True)\n",
    "scores_deep, preds_deep, model_states_deep , train_time_deep, test_time_deep, pp_states = eval.evaluate(deep_models,dataset,deep_scheme,logger_name=\"log\")\n",
    "\n",
    "\n",
    "summary_logger.info(f\"Train times: {train_time_deep}\")\n",
    "summary_logger.info(f\"Test times: {test_time_deep}\")\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building final model - Train 7413 - Test 1448'\n",
      "Training extractors on 7413 instances, validating on 2830 instances, for 100 epochs'\n",
      "\n",
      "--- EPOCH 0---'\n",
      "Extractor Train Losses are random_59:19.6336(-0.751007)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:2.2812'\n",
      "Testing (val) took 0:00:00.445000'\n",
      "Epoch 0 finished in 0:00:01.719191 '\n",
      "\n",
      "--- EPOCH 1---'\n",
      "Extractor Train Losses are random_59:1.4749(-0.773283)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:1.3877'\n",
      "Testing (val) took 0:00:00.410999'\n",
      "Epoch 1 finished in 0:00:01.687152 '\n",
      "\n",
      "--- EPOCH 2---'\n",
      "Extractor Train Losses are random_59:1.1501(-0.79556)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:1.2882'\n",
      "Testing (val) took 0:00:00.436997'\n",
      "Epoch 2 finished in 0:00:01.664099 '\n",
      "\n",
      "--- EPOCH 3---'\n",
      "Extractor Train Losses are random_59:0.9871(-0.817836)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.7229'\n",
      "Testing (val) took 0:00:00.434999'\n",
      "Epoch 3 finished in 0:00:01.696560 '\n",
      "\n",
      "--- EPOCH 4---'\n",
      "Extractor Train Losses are random_59:0.8672(-0.840113)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.6571'\n",
      "Testing (val) took 0:00:00.419118'\n",
      "Epoch 4 finished in 0:00:01.654118 '\n",
      "\n",
      "--- EPOCH 5---'\n",
      "Extractor Train Losses are random_59:0.8308(-0.862389)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.7062'\n",
      "Testing (val) took 0:00:00.423001'\n",
      "Epoch 5 finished in 0:00:01.658002 '\n",
      "\n",
      "--- EPOCH 6---'\n",
      "Extractor Train Losses are random_59:0.8879(-0.884665)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.6664'\n",
      "Testing (val) took 0:00:00.429999'\n",
      "Epoch 6 finished in 0:00:01.653666 '\n",
      "\n",
      "--- EPOCH 7---'\n",
      "Extractor Train Losses are random_59:0.7642(-0.906942)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5908'\n",
      "Testing (val) took 0:00:00.419000'\n",
      "Epoch 7 finished in 0:00:01.659132 '\n",
      "\n",
      "--- EPOCH 8---'\n",
      "Extractor Train Losses are random_59:0.7437(-0.929218)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5947'\n",
      "Testing (val) took 0:00:00.431000'\n",
      "Epoch 8 finished in 0:00:01.690084 '\n",
      "\n",
      "--- EPOCH 9---'\n",
      "Extractor Train Losses are random_59:0.7327(-0.951495)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.6412'\n",
      "Testing (val) took 0:00:00.439998'\n",
      "Epoch 9 finished in 0:00:01.705000 '\n",
      "\n",
      "--- EPOCH 10---'\n",
      "Extractor Train Losses are random_59:0.681(-0.973771)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.6413'\n",
      "Testing (val) took 0:00:00.416097'\n",
      "Epoch 10 finished in 0:00:01.677099 '\n",
      "\n",
      "--- EPOCH 11---'\n",
      "Extractor Train Losses are random_59:0.6579(-0.996047)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.6371'\n",
      "Testing (val) took 0:00:00.427996'\n",
      "Epoch 11 finished in 0:00:01.672029 '\n",
      "\n",
      "--- EPOCH 12---'\n",
      "Extractor Train Losses are random_59:0.6632(-1.018324)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5307'\n",
      "Testing (val) took 0:00:00.415000'\n",
      "Epoch 12 finished in 0:00:01.666719 '\n",
      "\n",
      "--- EPOCH 13---'\n",
      "Extractor Train Losses are random_59:0.6486(-1.0406)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5728'\n",
      "Testing (val) took 0:00:00.418997'\n",
      "Epoch 13 finished in 0:00:01.643002 '\n",
      "\n",
      "--- EPOCH 14---'\n",
      "Extractor Train Losses are random_59:0.6652(-1.062877)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.666'\n",
      "Testing (val) took 0:00:00.450997'\n",
      "Epoch 14 finished in 0:00:01.682096 '\n",
      "\n",
      "--- EPOCH 15---'\n",
      "Extractor Train Losses are random_59:0.6649(-1.085153)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.6299'\n",
      "Testing (val) took 0:00:00.416011'\n",
      "Epoch 15 finished in 0:00:01.667158 '\n",
      "\n",
      "--- EPOCH 16---'\n",
      "Extractor Train Losses are random_59:0.6391(-1.107429)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5865'\n",
      "Testing (val) took 0:00:00.425075'\n",
      "Epoch 16 finished in 0:00:01.681084 '\n",
      "\n",
      "--- EPOCH 17---'\n",
      "Extractor Train Losses are random_59:0.6219(-1.129706)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5862'\n",
      "Testing (val) took 0:00:00.417002'\n",
      "Epoch 17 finished in 0:00:01.651627 '\n",
      "\n",
      "--- EPOCH 18---'\n",
      "Extractor Train Losses are random_59:0.6229(-1.151982)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.532'\n",
      "Testing (val) took 0:00:00.425999'\n",
      "Epoch 18 finished in 0:00:01.654698 '\n",
      "\n",
      "--- EPOCH 19---'\n",
      "Extractor Train Losses are random_59:0.6349(-1.174259)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5401'\n",
      "Testing (val) took 0:00:00.412999'\n",
      "Epoch 19 finished in 0:00:01.631659 '\n",
      "\n",
      "--- EPOCH 20---'\n",
      "Extractor Train Losses are random_59:0.6291(-1.196535)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5102'\n",
      "Testing (val) took 0:00:00.419960'\n",
      "Epoch 20 finished in 0:00:01.675194 '\n",
      "\n",
      "--- EPOCH 21---'\n",
      "Extractor Train Losses are random_59:0.6255(-1.218811)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4986'\n",
      "Testing (val) took 0:00:00.433163'\n",
      "Epoch 21 finished in 0:00:01.709272 '\n",
      "\n",
      "--- EPOCH 22---'\n",
      "Extractor Train Losses are random_59:0.5949(-1.241088)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5352'\n",
      "Testing (val) took 0:00:00.423078'\n",
      "Epoch 22 finished in 0:00:01.665073 '\n",
      "\n",
      "--- EPOCH 23---'\n",
      "Extractor Train Losses are random_59:0.6218(-1.263364)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5567'\n",
      "Testing (val) took 0:00:00.435998'\n",
      "Epoch 23 finished in 0:00:01.684108 '\n",
      "\n",
      "--- EPOCH 24---'\n",
      "Extractor Train Losses are random_59:0.5858(-1.285641)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4949'\n",
      "Testing (val) took 0:00:00.436999'\n",
      "Epoch 24 finished in 0:00:01.711093 '\n",
      "\n",
      "--- EPOCH 25---'\n",
      "Extractor Train Losses are random_59:0.5943(-1.307917)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5131'\n",
      "Testing (val) took 0:00:00.451000'\n",
      "Epoch 25 finished in 0:00:01.747216 '\n",
      "\n",
      "--- EPOCH 26---'\n",
      "Extractor Train Losses are random_59:0.5995(-1.330193)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5327'\n",
      "Testing (val) took 0:00:00.418001'\n",
      "Epoch 26 finished in 0:00:01.683002 '\n",
      "\n",
      "--- EPOCH 27---'\n",
      "Extractor Train Losses are random_59:0.5687(-1.35247)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4988'\n",
      "Testing (val) took 0:00:00.425002'\n",
      "Epoch 27 finished in 0:00:01.703225 '\n",
      "\n",
      "--- EPOCH 28---'\n",
      "Extractor Train Losses are random_59:0.5664(-1.374746)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4985'\n",
      "Testing (val) took 0:00:00.454125'\n",
      "Epoch 28 finished in 0:00:01.729126 '\n",
      "\n",
      "--- EPOCH 29---'\n",
      "Extractor Train Losses are random_59:0.5738(-1.397022)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5087'\n",
      "Testing (val) took 0:00:00.431000'\n",
      "Epoch 29 finished in 0:00:01.758519 '\n",
      "\n",
      "--- EPOCH 30---'\n",
      "Extractor Train Losses are random_59:0.5697(-1.419299)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5513'\n",
      "Testing (val) took 0:00:00.435000'\n",
      "Epoch 30 finished in 0:00:01.732836 '\n",
      "\n",
      "--- EPOCH 31---'\n",
      "Extractor Train Losses are random_59:0.5475(-1.441575)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5175'\n",
      "Testing (val) took 0:00:00.416033'\n",
      "Epoch 31 finished in 0:00:01.644622 '\n",
      "\n",
      "--- EPOCH 32---'\n",
      "Extractor Train Losses are random_59:0.5376(-1.463852)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5294'\n",
      "Testing (val) took 0:00:00.429999'\n",
      "Epoch 32 finished in 0:00:01.704999 '\n",
      "\n",
      "--- EPOCH 33---'\n",
      "Extractor Train Losses are random_59:0.5274(-1.486128)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5345'\n",
      "Testing (val) took 0:00:00.447998'\n",
      "Epoch 33 finished in 0:00:01.742266 '\n",
      "\n",
      "--- EPOCH 34---'\n",
      "Extractor Train Losses are random_59:0.5235(-1.508404)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5142'\n",
      "Testing (val) took 0:00:00.412999'\n",
      "Epoch 34 finished in 0:00:01.707104 '\n",
      "\n",
      "--- EPOCH 35---'\n",
      "Extractor Train Losses are random_59:0.5311(-1.530681)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5455'\n",
      "Testing (val) took 0:00:00.417060'\n",
      "Epoch 35 finished in 0:00:01.693060 '\n",
      "\n",
      "--- EPOCH 36---'\n",
      "Extractor Train Losses are random_59:0.5288(-1.552957)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5316'\n",
      "Testing (val) took 0:00:00.426000'\n",
      "Epoch 36 finished in 0:00:01.703595 '\n",
      "\n",
      "--- EPOCH 37---'\n",
      "Extractor Train Losses are random_59:0.5034(-1.575234)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4923'\n",
      "Testing (val) took 0:00:00.424000'\n",
      "Epoch 37 finished in 0:00:01.674997 '\n",
      "\n",
      "--- EPOCH 38---'\n",
      "Extractor Train Losses are random_59:0.5085(-1.59751)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.512'\n",
      "Testing (val) took 0:00:00.431001'\n",
      "Epoch 38 finished in 0:00:01.685168 '\n",
      "\n",
      "--- EPOCH 39---'\n",
      "Extractor Train Losses are random_59:0.4902(-1.619786)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4938'\n",
      "Testing (val) took 0:00:00.431999'\n",
      "Epoch 39 finished in 0:00:01.647348 '\n",
      "\n",
      "--- EPOCH 40---'\n",
      "Extractor Train Losses are random_59:0.483(-1.642063)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5141'\n",
      "Testing (val) took 0:00:00.426000'\n",
      "Epoch 40 finished in 0:00:01.648997 '\n",
      "\n",
      "--- EPOCH 41---'\n",
      "Extractor Train Losses are random_59:0.4776(-1.664339)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5145'\n",
      "Testing (val) took 0:00:00.449102'\n",
      "Epoch 41 finished in 0:00:01.706100 '\n",
      "\n",
      "--- EPOCH 42---'\n",
      "Extractor Train Losses are random_59:0.4848(-1.686616)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5161'\n",
      "Testing (val) took 0:00:00.446000'\n",
      "Epoch 42 finished in 0:00:01.769604 '\n",
      "\n",
      "--- EPOCH 43---'\n",
      "Extractor Train Losses are random_59:0.4815(-1.708892)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.486'\n",
      "Testing (val) took 0:00:00.474517'\n",
      "Epoch 43 finished in 0:00:01.739509 '\n",
      "\n",
      "--- EPOCH 44---'\n",
      "Extractor Train Losses are random_59:0.461(-1.731168)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4868'\n",
      "Testing (val) took 0:00:00.431133'\n",
      "Epoch 44 finished in 0:00:01.746134 '\n",
      "\n",
      "--- EPOCH 45---'\n",
      "Extractor Train Losses are random_59:0.4642(-1.753445)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5162'\n",
      "Testing (val) took 0:00:00.431996'\n",
      "Epoch 45 finished in 0:00:01.709109 '\n",
      "\n",
      "--- EPOCH 46---'\n",
      "Extractor Train Losses are random_59:0.4599(-1.775721)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5057'\n",
      "Testing (val) took 0:00:00.430998'\n",
      "Epoch 46 finished in 0:00:01.677104 '\n",
      "\n",
      "--- EPOCH 47---'\n",
      "Extractor Train Losses are random_59:0.4602(-1.797998)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4947'\n",
      "Testing (val) took 0:00:00.436139'\n",
      "Epoch 47 finished in 0:00:01.784251 '\n",
      "\n",
      "--- EPOCH 48---'\n",
      "Extractor Train Losses are random_59:0.4529(-1.820274)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4855'\n",
      "Testing (val) took 0:00:00.423127'\n",
      "Epoch 48 finished in 0:00:01.717126 '\n",
      "\n",
      "--- EPOCH 49---'\n",
      "Extractor Train Losses are random_59:0.4498(-1.84255)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5333'\n",
      "Testing (val) took 0:00:00.462155'\n",
      "Epoch 49 finished in 0:00:01.750670 '\n",
      "\n",
      "--- EPOCH 50---'\n",
      "Extractor Train Losses are random_59:0.4473(-1.864827)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5106'\n",
      "Testing (val) took 0:00:00.438000'\n",
      "Epoch 50 finished in 0:00:01.724999 '\n",
      "\n",
      "--- EPOCH 51---'\n",
      "Extractor Train Losses are random_59:0.437(-1.887103)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4907'\n",
      "Testing (val) took 0:00:00.425001'\n",
      "Epoch 51 finished in 0:00:01.700305 '\n",
      "\n",
      "--- EPOCH 52---'\n",
      "Extractor Train Losses are random_59:0.429(-1.90938)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.507'\n",
      "Testing (val) took 0:00:00.436001'\n",
      "Epoch 52 finished in 0:00:01.747001 '\n",
      "\n",
      "--- EPOCH 53---'\n",
      "Extractor Train Losses are random_59:0.4292(-1.931656)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.5073'\n",
      "Testing (val) took 0:00:00.444999'\n",
      "Epoch 53 finished in 0:00:01.690648 '\n",
      "\n",
      "--- EPOCH 54---'\n",
      "Extractor Train Losses are random_59:0.4256(-1.953932)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.482'\n",
      "Testing (val) took 0:00:00.445997'\n",
      "Epoch 54 finished in 0:00:01.804214 '\n",
      "\n",
      "--- EPOCH 55---'\n",
      "Extractor Train Losses are random_59:0.4134(-1.976209)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4759'\n",
      "Testing (val) took 0:00:00.457999'\n",
      "Epoch 55 finished in 0:00:01.756523 '\n",
      "\n",
      "--- EPOCH 56---'\n",
      "Extractor Train Losses are random_59:0.4101(-1.998485)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4701'\n",
      "Testing (val) took 0:00:00.433002'\n",
      "Epoch 56 finished in 0:00:01.750573 '\n",
      "\n",
      "--- EPOCH 57---'\n",
      "Extractor Train Losses are random_59:0.4082(-2.020762)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4763'\n",
      "Testing (val) took 0:00:00.437000'\n",
      "Epoch 57 finished in 0:00:01.742999 '\n",
      "\n",
      "--- EPOCH 58---'\n",
      "Extractor Train Losses are random_59:0.4018(-2.043038)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4743'\n",
      "Testing (val) took 0:00:00.474000'\n",
      "Epoch 58 finished in 0:00:01.822000 '\n",
      "\n",
      "--- EPOCH 59---'\n",
      "Extractor Train Losses are random_59:0.4012(-2.065314)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4694'\n",
      "Testing (val) took 0:00:00.432000'\n",
      "Epoch 59 finished in 0:00:01.737295 '\n",
      "\n",
      "--- EPOCH 60---'\n",
      "Extractor Train Losses are random_59:0.3948(-2.087591)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4699'\n",
      "Testing (val) took 0:00:00.488000'\n",
      "Epoch 60 finished in 0:00:01.876348 '\n",
      "\n",
      "--- EPOCH 61---'\n",
      "Extractor Train Losses are random_59:0.3943(-2.109867)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4648'\n",
      "Testing (val) took 0:00:00.495002'\n",
      "Epoch 61 finished in 0:00:01.853022 '\n",
      "\n",
      "--- EPOCH 62---'\n",
      "Extractor Train Losses are random_59:0.3881(-2.132144)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4632'\n",
      "Testing (val) took 0:00:00.498000'\n",
      "Epoch 62 finished in 0:00:01.912193 '\n",
      "\n",
      "--- EPOCH 63---'\n",
      "Extractor Train Losses are random_59:0.384(-2.15442)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4484'\n",
      "Testing (val) took 0:00:00.573000'\n",
      "Epoch 63 finished in 0:00:02.052136 '\n",
      "\n",
      "--- EPOCH 64---'\n",
      "Extractor Train Losses are random_59:0.3853(-2.176696)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4593'\n",
      "Testing (val) took 0:00:00.444997'\n",
      "Epoch 64 finished in 0:00:01.845664 '\n",
      "\n",
      "--- EPOCH 65---'\n",
      "Extractor Train Losses are random_59:0.3777(-2.198973)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4562'\n",
      "Testing (val) took 0:00:00.423999'\n",
      "Epoch 65 finished in 0:00:01.720135 '\n",
      "\n",
      "--- EPOCH 66---'\n",
      "Extractor Train Losses are random_59:0.3797(-2.221249)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4524'\n",
      "Testing (val) took 0:00:00.445446'\n",
      "Epoch 66 finished in 0:00:01.712456 '\n",
      "\n",
      "--- EPOCH 67---'\n",
      "Extractor Train Losses are random_59:0.3729(-2.243525)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4565'\n",
      "Testing (val) took 0:00:00.425002'\n",
      "Epoch 67 finished in 0:00:01.739602 '\n",
      "\n",
      "--- EPOCH 68---'\n",
      "Extractor Train Losses are random_59:0.3654(-2.265802)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4526'\n",
      "Testing (val) took 0:00:00.461000'\n",
      "Epoch 68 finished in 0:00:01.751210 '\n",
      "\n",
      "--- EPOCH 69---'\n",
      "Extractor Train Losses are random_59:0.3658(-2.288078)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4438'\n",
      "Testing (val) took 0:00:00.437003'\n",
      "Epoch 69 finished in 0:00:01.743509 '\n",
      "\n",
      "--- EPOCH 70---'\n",
      "Extractor Train Losses are random_59:0.3652(-2.310355)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4475'\n",
      "Testing (val) took 0:00:00.478001'\n",
      "Epoch 70 finished in 0:00:01.869262 '\n",
      "\n",
      "--- EPOCH 71---'\n",
      "Extractor Train Losses are random_59:0.3635(-2.332631)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4426'\n",
      "Testing (val) took 0:00:00.452000'\n",
      "Epoch 71 finished in 0:00:01.721016 '\n",
      "\n",
      "--- EPOCH 72---'\n",
      "Extractor Train Losses are random_59:0.3597(-2.354907)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4414'\n",
      "Testing (val) took 0:00:00.423000'\n",
      "Epoch 72 finished in 0:00:01.665003 '\n",
      "\n",
      "--- EPOCH 73---'\n",
      "Extractor Train Losses are random_59:0.3566(-2.377184)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4415'\n",
      "Testing (val) took 0:00:00.441002'\n",
      "Epoch 73 finished in 0:00:01.643099 '\n",
      "\n",
      "--- EPOCH 74---'\n",
      "Extractor Train Losses are random_59:0.355(-2.39946)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4317'\n",
      "Testing (val) took 0:00:00.399603'\n",
      "Epoch 74 finished in 0:00:01.622600 '\n",
      "\n",
      "--- EPOCH 75---'\n",
      "Extractor Train Losses are random_59:0.3557(-2.421737)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4287'\n",
      "Testing (val) took 0:00:00.402000'\n",
      "Epoch 75 finished in 0:00:01.603515 '\n",
      "\n",
      "--- EPOCH 76---'\n",
      "Extractor Train Losses are random_59:0.3547(-2.444013)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4344'\n",
      "Testing (val) took 0:00:00.405999'\n",
      "Epoch 76 finished in 0:00:01.598666 '\n",
      "\n",
      "--- EPOCH 77---'\n",
      "Extractor Train Losses are random_59:0.3511(-2.466289)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4259'\n",
      "Testing (val) took 0:00:00.401999'\n",
      "Epoch 77 finished in 0:00:01.591001 '\n",
      "\n",
      "--- EPOCH 78---'\n",
      "Extractor Train Losses are random_59:0.3491(-2.488566)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4326'\n",
      "Testing (val) took 0:00:00.402002'\n",
      "Epoch 78 finished in 0:00:01.607087 '\n",
      "\n",
      "--- EPOCH 79---'\n",
      "Extractor Train Losses are random_59:0.3451(-2.510842)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4203'\n",
      "Testing (val) took 0:00:00.417589'\n",
      "Epoch 79 finished in 0:00:01.598180 '\n",
      "\n",
      "--- EPOCH 80---'\n",
      "Extractor Train Losses are random_59:0.345(-2.533119)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4268'\n",
      "Testing (val) took 0:00:00.393001'\n",
      "Epoch 80 finished in 0:00:01.557999 '\n",
      "\n",
      "--- EPOCH 81---'\n",
      "Extractor Train Losses are random_59:0.3413(-2.555395)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4222'\n",
      "Testing (val) took 0:00:00.389000'\n",
      "Epoch 81 finished in 0:00:01.574040 '\n",
      "\n",
      "--- EPOCH 82---'\n",
      "Extractor Train Losses are random_59:0.3413(-2.577671)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.415'\n",
      "Testing (val) took 0:00:00.412997'\n",
      "Epoch 82 finished in 0:00:01.586787 '\n",
      "\n",
      "--- EPOCH 83---'\n",
      "Extractor Train Losses are random_59:0.3346(-2.599948)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.419'\n",
      "Testing (val) took 0:00:00.449616'\n",
      "Epoch 83 finished in 0:00:01.698480 '\n",
      "\n",
      "--- EPOCH 84---'\n",
      "Extractor Train Losses are random_59:0.3372(-2.622224)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4153'\n",
      "Testing (val) took 0:00:00.393999'\n",
      "Epoch 84 finished in 0:00:01.616003 '\n",
      "\n",
      "--- EPOCH 85---'\n",
      "Extractor Train Losses are random_59:0.336(-2.644501)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4155'\n",
      "Testing (val) took 0:00:00.422000'\n",
      "Epoch 85 finished in 0:00:01.632010 '\n",
      "\n",
      "--- EPOCH 86---'\n",
      "Extractor Train Losses are random_59:0.3354(-2.666777)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4025'\n",
      "Testing (val) took 0:00:00.405001'\n",
      "Epoch 86 finished in 0:00:01.617124 '\n",
      "\n",
      "--- EPOCH 87---'\n",
      "Extractor Train Losses are random_59:0.3349(-2.689053)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4167'\n",
      "Testing (val) took 0:00:00.421282'\n",
      "Epoch 87 finished in 0:00:01.642932 '\n",
      "\n",
      "--- EPOCH 88---'\n",
      "Extractor Train Losses are random_59:0.3321(-2.71133)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4026'\n",
      "Testing (val) took 0:00:00.426998'\n",
      "Epoch 88 finished in 0:00:01.650649 '\n",
      "\n",
      "--- EPOCH 89---'\n",
      "Extractor Train Losses are random_59:0.3277(-2.733606)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4055'\n",
      "Testing (val) took 0:00:00.408858'\n",
      "Epoch 89 finished in 0:00:01.669860 '\n",
      "\n",
      "--- EPOCH 90---'\n",
      "Extractor Train Losses are random_59:0.329(-2.755883)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4075'\n",
      "Testing (val) took 0:00:00.394999'\n",
      "Epoch 90 finished in 0:00:01.602990 '\n",
      "\n",
      "--- EPOCH 91---'\n",
      "Extractor Train Losses are random_59:0.3276(-2.778159)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4085'\n",
      "Testing (val) took 0:00:00.408996'\n",
      "Epoch 91 finished in 0:00:01.665988 '\n",
      "\n",
      "--- EPOCH 92---'\n",
      "Extractor Train Losses are random_59:0.3271(-2.800435)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4008'\n",
      "Testing (val) took 0:00:00.432000'\n",
      "Epoch 92 finished in 0:00:01.665994 '\n",
      "\n",
      "--- EPOCH 93---'\n",
      "Extractor Train Losses are random_59:0.3218(-2.822712)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.3995'\n",
      "Testing (val) took 0:00:00.407001'\n",
      "Epoch 93 finished in 0:00:01.676733 '\n",
      "\n",
      "--- EPOCH 94---'\n",
      "Extractor Train Losses are random_59:0.3235(-2.844988)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.4014'\n",
      "Testing (val) took 0:00:00.432999'\n",
      "Epoch 94 finished in 0:00:01.710999 '\n",
      "\n",
      "--- EPOCH 95---'\n",
      "Extractor Train Losses are random_59:0.3186(-2.867265)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.3975'\n",
      "Testing (val) took 0:00:00.397518'\n",
      "Epoch 95 finished in 0:00:01.590598 '\n",
      "\n",
      "--- EPOCH 96---'\n",
      "Extractor Train Losses are random_59:0.3223(-2.889541)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.3976'\n",
      "Testing (val) took 0:00:00.410999'\n",
      "Epoch 96 finished in 0:00:01.615653 '\n",
      "\n",
      "--- EPOCH 97---'\n",
      "Extractor Train Losses are random_59:0.3191(-2.911817)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.3978'\n",
      "Testing (val) took 0:00:00.386997'\n",
      "Epoch 97 finished in 0:00:01.563473 '\n",
      "\n",
      "--- EPOCH 98---'\n",
      "Extractor Train Losses are random_59:0.3211(-2.934094)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.3948'\n",
      "Testing (val) took 0:00:00.416003'\n",
      "Epoch 98 finished in 0:00:01.630999 '\n",
      "\n",
      "--- EPOCH 99---'\n",
      "Extractor Train Losses are random_59:0.3163(-2.95637)'\n",
      "Tested (val) on 2830 instances with mean losses of: random_59:0.3922'\n",
      "Testing (val) took 0:00:00.416515'\n",
      "Epoch 99 finished in 0:00:01.600624 '\n",
      "\n",
      "-----------'\n",
      "Finished training extractors with a best validation loss of random_59:0.3922'\n",
      "Training took 0:02:49.536824'\n",
      "Tested (test) on 1448 instances with mean losses of: random_59:0.4212'\n",
      "Testing (test) took 0:00:00.200000'\n"
     ]
    }
   ],
   "source": [
    "scores_deep_final, preds_deep_final, model_states_deep_final , train_time_deep_final, test_time_deep_final,pp_states_final = eval.build(deep_models,dataset,deep_scheme,logger_name=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.save_pp(pp_states,log_dir)\n",
    "PLSRegression(n_components=selected_comps).save_state(pp_states_final.state(),log_dir / \"preprocessing\"   / f\"_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% log results\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments took 0:13:42.571821'\n",
      "Finished Random Deep Search'\n",
      "---Loss results---'\n",
      "0 - random_59 - fold_0:0.4335,fold_1:0.4428,fold_2:0.3915,fold_3:0.4542,fold_4:0.4478,MSE:0.4341,R2:0.9285'\n"
     ]
    }
   ],
   "source": [
    "ex.save_results(model_states_deep, preds_deep,configs, scores_deep, log_dir,tb,prefix=\"\")\n",
    "     \n",
    "for model, state_dict in model_states_deep_final.items():\n",
    "     torch.save(state_dict.state(), log_dir / \"models\" / f\"{model}\" / f\"_final\")\n",
    "        \n",
    "\n",
    "\n",
    "#summary_logger.info(f\"Scores: {scores_deep}\")\n",
    "#for key,value in flip_dicts(scores_deep).items():\n",
    "#    summary_logger.info(f\"{key}: {value}\")\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "diff = end - start\n",
    "ex.write_summary(diff, deep_models, scores_deep,prefix=\"\")\n",
    "ex.save_pred_plots(preds_deep, deep_models,log_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting deep results as a function of number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores_deep)\n",
    "scores_df.to_csv(log_dir / f\"scores.csv\", index=False)\n",
    "\n",
    "scores_df_final = pd.DataFrame(scores_deep_final)\n",
    "scores_df_final.to_csv(log_dir / f\"scores_final.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "if True:\n",
    "    # plot deep results as a function of number of features\n",
    "\n",
    "    n_features_dict = {name:config.n_features for name,config in configs.items()}\n",
    "    to_plot = pd.DataFrame([[name, scores_deep[\"R2\"][name],n_features_dict[name]] for name in scores_deep[\"R2\"].keys()]\n",
    "                           ,columns = [\"name\",\"score\",\"n_features\"])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(to_plot[\"score\"],bins=100,density=True)\n",
    "    #ax.set_xscale('log')\n",
    "    #ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "    ax.set_xlabel(\"Number of Models\")\n",
    "    ax.set_ylabel(\"R2\")\n",
    "    ax.set_title(\"Distribution of R2 Scoes\")\n",
    "    plt.savefig(log_dir / f\"dist_plot.png\",bbox_inches='tight')\n",
    "    #plt.savefig(log_dir / f\"pp_deep_pls_compressed.png\",bbox_inches='tight')\n",
    "\n",
    "    n_features_dict = {name:config.n_features for name,config in configs.items()}\n",
    "    to_plot = pd.DataFrame([[name, scores_deep[\"R2\"][name],n_features_dict[name]] for name in scores_deep[\"R2\"].keys()]\n",
    "                           ,columns = [\"name\",\"score\",\"n_features\"])\n",
    "    to_plot = to_plot[to_plot[\"score\"]>=0]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(to_plot[\"score\"],bins=100,density=True)\n",
    "    #ax.set_xscale('log')\n",
    "    #ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "    ax.set_xlabel(\"Number of Models\")\n",
    "    ax.set_ylabel(\"R2\")\n",
    "    ax.set_title(\"Distribution of R2 Scoes\")\n",
    "    plt.savefig(log_dir / f\"dist_plot_compressed.png\",bbox_inches='tight')\n",
    "    #plt.savefig(log_dir / f\"pp_deep_pls_compressed.png\",bbox_inches='tight')\n",
    "    pass\n",
    "\n",
    "    #plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Return our best models\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      " Top 5 performance on Test Set'\n",
      "Index - Model - Val MSE - Val R2 - Test MSE - Test R2'\n",
      "0 - random_59 - 0.43406463829089215 -0.9285156672809534 - 0.43406463829089215 - 0.421224474343811 - 0.9281727840683829'\n"
     ]
    }
   ],
   "source": [
    "summary_logger.info(\"------------------\\n Top 5 performance on Test Set\")\n",
    "summary_logger.info(f\"Index - Model - Val MSE - Val R2 - Test MSE - Test R2\")\n",
    "for i,key in enumerate(sorted(scores_deep['MSE'],key=scores_deep['MSE'].get)):\n",
    "    if i <5:\n",
    "        summary_logger.info(f\"{i} - {key} - {scores_deep['MSE'][key]} -{scores_deep['R2'][key]} - {scores_deep['MSE'][key]} - {scores_deep_final['MSE'][key]} - {scores_deep_final['R2'][key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5879 - Val 1929 - Test 1905-----------------------------------'\n",
      "Tested (test) on 1905 instances with mean losses of: random_59:0.4134'\n",
      "Testing (test) took 0:00:00.271999'\n",
      "-----------------------------------Fold 1 - Train 5855 - Val 1903 - Test 1955-----------------------------------'\n",
      "Tested (test) on 1955 instances with mean losses of: random_59:0.4268'\n",
      "Testing (test) took 0:00:00.280999'\n",
      "-----------------------------------Fold 2 - Train 5821 - Val 1955 - Test 1937-----------------------------------'\n",
      "Tested (test) on 1937 instances with mean losses of: random_59:0.3867'\n",
      "Testing (test) took 0:00:00.264000'\n",
      "-----------------------------------Fold 3 - Train 5787 - Val 1937 - Test 1989-----------------------------------'\n",
      "Tested (test) on 1989 instances with mean losses of: random_59:0.4572'\n",
      "Testing (test) took 0:00:00.275515'\n",
      "-----------------------------------Fold 4 - Train 5797 - Val 1989 - Test 1927-----------------------------------'\n",
      "Tested (test) on 1927 instances with mean losses of: random_59:0.4507'\n",
      "Testing (test) took 0:00:00.276997'\n"
     ]
    }
   ],
   "source": [
    "model_path = Path('D:/workspace/lazydeep/experiments/1.01/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/1.02\")\n",
    "\n",
    "log_dir = log_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "model_dir = model_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "    \n",
    "ut.setup_logger(logger_name=\"\",file_name=log_dir/\"log.txt\")\n",
    "ut.setup_logger(logger_name=\"summary2\",file_name=log_dir/\"summary.txt\")\n",
    "summary_logger = logging.getLogger(\"summary2\")\n",
    "tb = SummaryWriter(log_dir/\"tb\")\n",
    "\n",
    "    \n",
    "    \n",
    "deep_scores_dict={}\n",
    "deep_preds_dict={}\n",
    "actual_y = None\n",
    "preprocessing=PLSRegression(n_components=selected_comps)\n",
    "\n",
    "load_fun_cv = lambda name,model, fold : model.load_state(model_dir/'models'/name/f\"_fold_{fold}\")\n",
    "load_fun_pp_cv = lambda fold : preprocessing.from_state(preprocessing.load_state(model_dir/'preprocessing'/f\"_fold_{fold}\"))\n",
    "load_fun_build = lambda name,model : model.load_state(model_dir/'models'/name/f\"_final\")\n",
    "load_fun_pp_build = lambda : preprocessing.from_state(preprocessing.load_state(model_dir/'preprocessing'/f\"_final\"))\n",
    "\n",
    "deep_scheme = DeepScheme(configs, fixed_hyperparams=fixed_hyperparams,loss_eval=loss_target,device=device,tensorboard=tb,adaptive_lr=False,update=False)\n",
    "deep_scores, deep_preds, _ , _, _,_ = eval.evaluate(deep_models,dataset,deep_scheme,logger_name=\"log\",load_fun=load_fun_cv,load_fun_pp=load_fun_pp_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building final model - Train 7413 - Test 1448'\n",
      "Tested (test) on 1448 instances with mean losses of: random_59:0.425'\n",
      "Testing (test) took 0:00:00.195996'\n"
     ]
    }
   ],
   "source": [
    "deep_scores_final, deep_preds_final, _ ,_, _,_ = eval.build(deep_models,dataset,deep_scheme,logger_name=\"test_log\",load_fun=load_fun_build,load_fun_pp=load_fun_pp_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - random_59 - deep - 0.41344394868440204 - 0.4268353875640713 - 0.38668853449156804 - 0.4572330106437476 - 0.45067953918038345 - 0.42715798708023967 - 0.9296530954646005\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "for k,v in ut.flip_dicts(deep_scores).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores.append({**dict1,**v})\n",
    "    \n",
    "all_scores_final = []\n",
    "for k,v in ut.flip_dicts(deep_scores_final).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores_final.append({**dict1,**v})  \n",
    "\n",
    "scores_df_sorted = pd.DataFrame(all_scores).sort_values(by='MSE')\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_59'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5879 - Val 1929 - Test 1905-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.2714,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.072,lwr_k=40:0.119,lwr_k=50:0.1453,lwr_k=100:0.2067,lwr_k=200:0.2411,lwr_k=300:0.2512,lwr_k=400:0.2571,lwr_k=500:0.2607,lwr_k=600:0.2625,lwr_k=700:0.2641,lwr_k=800:0.2651,lwr_k=900:0.2656,lwr_k=1000:0.2657'\n",
      "Tested (test) on 1905 instances with mean losses of: lr:0.4141,lwr_k=10:0.7454,lwr_k=20:1.294,lwr_k=30:0.725,lwr_k=40:0.5702,lwr_k=50:0.5256,lwr_k=100:0.4373,lwr_k=200:0.4167,lwr_k=300:0.4127,lwr_k=400:0.4161,lwr_k=500:0.4142,lwr_k=600:0.4159,lwr_k=700:0.4164,lwr_k=800:0.4171,lwr_k=900:0.4158,lwr_k=1000:0.4166'\n",
      "-----------------------------------Fold 1 - Train 5855 - Val 1903 - Test 1955-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.2708,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0739,lwr_k=40:0.123,lwr_k=50:0.1468,lwr_k=100:0.2078,lwr_k=200:0.2399,lwr_k=300:0.2502,lwr_k=400:0.2564,lwr_k=500:0.259,lwr_k=600:0.2608,lwr_k=700:0.2632,lwr_k=800:0.265,lwr_k=900:0.2661,lwr_k=1000:0.2669'\n",
      "Tested (test) on 1955 instances with mean losses of: lr:0.4261,lwr_k=10:0.7981,lwr_k=20:1.3163,lwr_k=30:0.7608,lwr_k=40:0.5938,lwr_k=50:0.5325,lwr_k=100:0.4461,lwr_k=200:0.4312,lwr_k=300:0.4298,lwr_k=400:0.4317,lwr_k=500:0.4297,lwr_k=600:0.4283,lwr_k=700:0.4291,lwr_k=800:0.4297,lwr_k=900:0.4289,lwr_k=1000:0.427'\n",
      "-----------------------------------Fold 2 - Train 5821 - Val 1955 - Test 1937-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.287,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0725,lwr_k=40:0.1183,lwr_k=50:0.1479,lwr_k=100:0.2116,lwr_k=200:0.2467,lwr_k=300:0.2587,lwr_k=400:0.2663,lwr_k=500:0.2705,lwr_k=600:0.274,lwr_k=700:0.2759,lwr_k=800:0.2777,lwr_k=900:0.2792,lwr_k=1000:0.2799'\n",
      "Tested (test) on 1937 instances with mean losses of: lr:0.3912,lwr_k=10:0.6856,lwr_k=20:1.2291,lwr_k=30:0.6196,lwr_k=40:0.4914,lwr_k=50:0.4415,lwr_k=100:0.3862,lwr_k=200:0.3842,lwr_k=300:0.3888,lwr_k=400:0.3898,lwr_k=500:0.3913,lwr_k=600:0.3901,lwr_k=700:0.3918,lwr_k=800:0.3918,lwr_k=900:0.3909,lwr_k=1000:0.3923'\n",
      "-----------------------------------Fold 3 - Train 5787 - Val 1937 - Test 1989-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.2818,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0683,lwr_k=40:0.1101,lwr_k=50:0.1355,lwr_k=100:0.201,lwr_k=200:0.2394,lwr_k=300:0.253,lwr_k=400:0.2594,lwr_k=500:0.2641,lwr_k=600:0.2675,lwr_k=700:0.2695,lwr_k=800:0.2708,lwr_k=900:0.2724,lwr_k=1000:0.274'\n",
      "Tested (test) on 1989 instances with mean losses of: lr:0.4674,lwr_k=10:0.7445,lwr_k=20:1.2631,lwr_k=30:0.7825,lwr_k=40:0.6021,lwr_k=50:0.5277,lwr_k=100:0.4764,lwr_k=200:0.4634,lwr_k=300:0.4625,lwr_k=400:0.4652,lwr_k=500:0.4649,lwr_k=600:0.4661,lwr_k=700:0.4654,lwr_k=800:0.4663,lwr_k=900:0.4669,lwr_k=1000:0.4658'\n",
      "-----------------------------------Fold 4 - Train 5797 - Val 1989 - Test 1927-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.2734,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0722,lwr_k=40:0.1135,lwr_k=50:0.1417,lwr_k=100:0.2079,lwr_k=200:0.2403,lwr_k=300:0.2505,lwr_k=400:0.2582,lwr_k=500:0.2614,lwr_k=600:0.2635,lwr_k=700:0.2647,lwr_k=800:0.266,lwr_k=900:0.2668,lwr_k=1000:0.2674'\n",
      "Tested (test) on 1927 instances with mean losses of: lr:0.4457,lwr_k=10:0.7795,lwr_k=20:1.3866,lwr_k=30:0.7161,lwr_k=40:0.5653,lwr_k=50:0.4811,lwr_k=100:0.429,lwr_k=200:0.4317,lwr_k=300:0.4334,lwr_k=400:0.4342,lwr_k=500:0.4354,lwr_k=600:0.4383,lwr_k=700:0.4397,lwr_k=800:0.4404,lwr_k=900:0.4407,lwr_k=1000:0.4412'\n",
      "Building final model - Train 7413 - Test 1448'\n",
      "Finished training DeepLWR with a train loss of lr:0.2893,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0729,lwr_k=40:0.1148,lwr_k=50:0.1418,lwr_k=100:0.2041,lwr_k=200:0.2408,lwr_k=300:0.2552,lwr_k=400:0.2641,lwr_k=500:0.2686,lwr_k=600:0.2723,lwr_k=700:0.275,lwr_k=800:0.2765,lwr_k=900:0.2783,lwr_k=1000:0.2798'\n",
      "Tested (test) on 1448 instances with mean losses of: lr:0.4193,lwr_k=10:0.7188,lwr_k=20:1.1558,lwr_k=30:0.7567,lwr_k=40:0.5589,lwr_k=50:0.4816,lwr_k=100:0.4351,lwr_k=200:0.4236,lwr_k=300:0.4187,lwr_k=400:0.4187,lwr_k=500:0.4178,lwr_k=600:0.4175,lwr_k=700:0.4194,lwr_k=800:0.4191,lwr_k=900:0.4201,lwr_k=1000:0.4189'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "from sk_models import setup_pls_models_exh, StandardScaler, PLSRegression\n",
    "from plot import plot_preds_and_res\n",
    "\n",
    "for deep_name,deep_model in deep_models.items():\n",
    "    logging.getLogger().info(f\"Running model {deep_name}\")\n",
    "    temp_dict = {deep_name:deep_model}\n",
    "\n",
    "    lwr_scheme = DeepLWRScheme_1_to_n(lwr_models = setup_pls_models_exh(nrow),n_neighbours=500,loss_fun_sk = mean_squared_error)\n",
    "    lwr_scores, lwr_preds, _ , _, _,_= eval.evaluate(temp_dict,dataset,lwr_scheme,logger_name=\"log\",load_fun=load_fun_cv,load_fun_pp = load_fun_pp_cv)\n",
    "    lwr_scores_final, lwr_preds_final, _ , _, _,_= eval.build(temp_dict,dataset,lwr_scheme,logger_name=\"test_log\",load_fun=load_fun_build,load_fun_pp = load_fun_pp_build)\n",
    "\n",
    "    #scores\n",
    "    for k,v in ut.flip_dicts(lwr_scores).items():\n",
    "        dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "        all_scores.append({**dict1,**v})\n",
    "\n",
    "    for k,v in ut.flip_dicts(lwr_scores_final).items():\n",
    "        dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "        all_scores_final.append({**dict1,**v})\n",
    "\n",
    "    lwr_preds['deep'] = deep_preds[deep_name]\n",
    "    lwr_preds_final['deep'] = deep_preds_final[deep_name]\n",
    "\n",
    "    if not (log_dir/deep_name).exists():\n",
    "        (log_dir/deep_name).mkdir()    \n",
    "    \n",
    "    lwr_preds.to_csv(log_dir/deep_name/ f\"predictions.csv\",index=False)\n",
    "    lwr_preds_final.to_csv(log_dir/deep_name/ f\"predictions_test.csv\",index=False)\n",
    "\n",
    "    #preds\n",
    "    # todo save predictions - appending solns\n",
    "    plot_preds_and_res(lwr_preds,name_lambda=lambda x:f\"{deep_name} with {x} predictor\",save_lambda= lambda x:f\"deep_lwr{x}\",save_loc=log_dir/deep_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank - model_num - predictor - fold_0 - fold_1 - fold_2 - fold_3 - fold_4 - MSE - R2'\n",
      "0 - random_59 - lwr_k=200 - 0.4166653531983457 - 0.4312335240577252 - 0.384155462531544 - 0.46337699430476886 - 0.43172619858270145 - 0.42566780548135 - 0.9298985073021006'\n",
      "1 - random_59 - lwr_k=300 - 0.41274014202117054 - 0.429844055946837 - 0.3888081753748096 - 0.46248178429237957 - 0.43342722952650786 - 0.4257003063813988 - 0.9298931548615869'\n",
      "2 - random_59 - deep - 0.41344394868440204 - 0.4268353875640713 - 0.38668853449156804 - 0.4572330106437476 - 0.45067953918038345 - 0.42715798708023967 - 0.9296530954646005'\n",
      "3 - random_59 - lwr_k=500 - 0.4142444910065236 - 0.42971057198811546 - 0.39130599063477484 - 0.46491581217900924 - 0.43543866818952975 - 0.4273640987840034 - 0.92961915168479'\n",
      "4 - random_59 - lwr_k=400 - 0.4161330397397333 - 0.4316892216683089 - 0.3897847401674108 - 0.46515461254526735 - 0.434173676233281 - 0.4276273148588572 - 0.9295758037042481'\n",
      "5 - random_59 - lwr_k=600 - 0.41592664883773717 - 0.4283315845570873 - 0.39012803922749945 - 0.4660577248297239 - 0.4383354681300487 - 0.4279900944714904 - 0.9295160590112305'\n",
      "6 - random_59 - lwr_k=700 - 0.41642497609252627 - 0.429137946422461 - 0.3917618737851539 - 0.46539130389523997 - 0.43973920613557427 - 0.42871798289971186 - 0.9293961860382718'\n",
      "7 - random_59 - lwr_k=1000 - 0.4166339198564648 - 0.42703858179520615 - 0.3922798853420123 - 0.4657941818074098 - 0.44123112331176173 - 0.4288182008525044 - 0.9293796815528599'\n",
      "8 - random_59 - lwr_k=900 - 0.41584241031351143 - 0.42890387799896873 - 0.39094796425135125 - 0.4668516630329016 - 0.44066496973689656 - 0.42887701372856296 - 0.9293699959004604'\n",
      "9 - random_59 - lr - 0.41408102442508943 - 0.42609458089072494 - 0.3911672112210317 - 0.4673981941902492 - 0.4456553466460285 - 0.42911180958896356 - 0.9293313283289847'\n",
      "10 - random_59 - lwr_k=800 - 0.41711755056344973 - 0.42968981785842253 - 0.39178032909394067 - 0.4662879723403062 - 0.440368192075906 - 0.4292769801612984 - 0.9293041270618901'\n",
      "11 - random_59 - lwr_k=100 - 0.4373173055387326 - 0.44610830549098235 - 0.3861712595197143 - 0.47635655918253916 - 0.42897741144044316 - 0.4352267684583184 - 0.9283242807228278'\n",
      "12 - random_59 - lwr_k=50 - 0.5255547548297665 - 0.5325134646406959 - 0.4414533120219591 - 0.5276749970618342 - 0.4811494755814008 - 0.5018080207259497 - 0.9173592861670888'\n",
      "13 - random_59 - lwr_k=40 - 0.5702332091802065 - 0.5938010309750217 - 0.49144568710009273 - 0.6021410974830527 - 0.5652715850785307 - 0.5648144303817009 - 0.9069830178434629'\n",
      "14 - random_59 - lwr_k=30 - 0.7249685647085002 - 0.7608335654738849 - 0.6195917958162341 - 0.7825026928638968 - 0.7161438011908043 - 0.7212036451938798 - 0.8812279166612418'\n",
      "15 - random_59 - lwr_k=10 - 0.7454405647554818 - 0.7981005558253802 - 0.6856020501572047 - 0.7445448523294976 - 0.7795225526896076 - 0.7506848248706437 - 0.8763727815647571'\n",
      "16 - random_59 - lwr_k=20 - 1.2939574769788726 - 1.3162936801232672 - 1.2291303761846777 - 1.2631397049135582 - 1.3865692129506635 - 1.2975880184684914 - 0.7863055278547811'\n"
     ]
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(all_scores)\n",
    "scores_df.to_csv(log_dir/f\"scores.csv\",index=False)\n",
    "scores_df_final = pd.DataFrame(all_scores_final)\n",
    "scores_df_final.to_csv(log_dir/f\"test_scores.csv\",index=False)\n",
    "\n",
    "scores_df_sorted = pd.DataFrame(scores_df).sort_values(by='MSE')\n",
    "\n",
    "best_5 = []\n",
    "summary_logger.info(f\"Rank - \" +\" - \".join(list(scores_df_sorted.columns)))\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    if i < 5:\n",
    "        best_5.append((row[\"model_num\"],row[\"predictor\"],row[\"MSE\"]))\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    summary_logger.info(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      " Best 5 on Test Sest \n",
      " ---------------------'\n",
      "Rank -  Deep Model - Predictor - Val Set - Test Set'\n",
      "0 - random_59 - lwr_k=200 - 0.42566780548135 - 0.4235813499301762 - 0.9277708904110789'\n",
      "1 - random_59 - lwr_k=300 - 0.4257003063813988 - 0.41870617012542355 - 0.9286022062762397'\n",
      "2 - random_59 - deep - 0.42715798708023967 - 0.42503891224827856 - 0.9275223459487822'\n",
      "3 - random_59 - lwr_k=500 - 0.4273640987840034 - 0.4177533215608849 - 0.9287646860535034'\n",
      "4 - random_59 - lwr_k=400 - 0.4276273148588572 - 0.4187052927674857 - 0.928602355883352'\n"
     ]
    }
   ],
   "source": [
    "summary_logger.info(\"-----------------------\\n Best 5 on Test Sest \\n ---------------------\")\n",
    "summary_logger.info(f\"Rank -  Deep Model - Predictor - Val Set - Test Set\")\n",
    "for i, (j,k,v) in enumerate(best_5):\n",
    "\n",
    "    row = scores_df_final.loc[(scores_df_final['model_num']==j) & (scores_df_final['predictor'] == k)].iloc[0]\n",
    "    #print(row)\n",
    "    s = f\"{i} - {j} - {k} - {v} - {row['MSE']} - {row['R2']}\"\n",
    "    summary_logger.info(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (100) does not match length of index (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3032\\2119658250.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdeep_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscores_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"predictor\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"deep\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"R2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdeep_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"order\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdeep_ordering\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model_num\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"order\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdeep_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\lazydeep\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3653\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3654\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3655\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3657\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\lazydeep\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3830\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3831\u001b[0m         \"\"\"\n\u001b[1;32m-> 3832\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3834\u001b[0m         if (\n",
      "\u001b[1;32m~\\.conda\\envs\\lazydeep\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4528\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4529\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4530\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\lazydeep\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \"\"\"\n\u001b[0;32m    556\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    558\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (100) does not match length of index (1)"
     ]
    }
   ],
   "source": [
    "#take 1 is a scatter plot - lets, for each dataset\n",
    "#graph our deep models by rank - plot - then overlay our knn moels\n",
    "#plot points\n",
    "\n",
    "deep_set = scores_df[scores_df[\"predictor\"]==\"deep\"].sort_values(\"R2\")\n",
    "deep_set[\"order\"] = [i for i in range(0,100)]\n",
    "deep_ordering = {row[\"model_num\"]:row[\"order\"] for index, row in deep_set.iterrows()}\n",
    "\n",
    "def order_models(x):\n",
    "    x = [deep_ordering[i] for i in x]\n",
    "    return x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df[scores_df[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    if knn_model == \"deep\":\n",
    "        s=10\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot.png\", bbox_inches='tight')\n",
    "logging.getLogger().info(\"Wrote Summary Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df[\"n_features\"] = [deep_models[i].n_features for i in scores_df[\"model_num\"]] \n",
    "from matplotlib.colors import Colormap\n",
    "import seaborn as sns #heatmap of features - pls model - score\n",
    "class nlcmap(Colormap):\n",
    "    def __init__(self, cmap, levels):\n",
    "        self.cmap = cmap\n",
    "        self.N = cmap.N\n",
    "        self.monochrome = self.cmap.monochrome\n",
    "        self.levels = np.asarray(levels, dtype='float64')\n",
    "        self._x = self.levels\n",
    "        self.levmax = self.levels.max()\n",
    "        self.levmin = self.levels.min()\n",
    "        self.transformed_levels = np.linspace(self.levmin, self.levmax, #uniform spacing along levels (colour segments)\n",
    "             len(self.levels))\n",
    "\n",
    "    def __call__(self, xi, alpha=1.0, **kw):\n",
    "        yi = np.interp(xi, self._x, self.transformed_levels)\n",
    "        return self.cmap((yi-self.levmin) / (self.levmax-self.levmin), alpha)\n",
    "    \n",
    "levels = np.concatenate((\n",
    "    [0, 1],\n",
    "    [0.6,0.8,0.9,0.95,0.98]\n",
    "    ))\n",
    "\n",
    "levels = levels[levels <= 1]\n",
    "levels.sort()\n",
    "cmap_nonlin = nlcmap(plt.cm.YlGnBu, levels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = scores_df[[\"predictor\",\"n_features\",\"R2\"]]\n",
    "subset = subset[np.logical_not(subset[\"predictor\"]==\"deep\")]\n",
    "subset = subset[np.logical_not(subset[\"predictor\"]==\"lr\")]\n",
    "trans = subset[\"predictor\"].transform(lambda x: int(x.replace(\"lwr_k=\",\"\"))).tolist()\n",
    "subset.loc[:,\"predictor\"]=trans\n",
    "subset=subset.sort_values(\"predictor\",ascending=False)\n",
    "\n",
    "def rand_jitter(arr):\n",
    "    stdev = .01 * (max(arr) - min(arr))\n",
    "    return arr + np.random.randn(len(arr)) * stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sc = ax.scatter(x=rand_jitter(subset[\"n_features\"]), y=rand_jitter(subset[\"predictor\"]), s=20,c=subset[\"R2\"],cmap=cmap_nonlin,vmin=0)\n",
    "ax.set_xlabel(\"Number of Features\")\n",
    "ax.set_ylabel(\"Number of Neighbours\")\n",
    "\n",
    "cbar = fig.colorbar(sc,label=\"R2 Score\")\n",
    "\n",
    "ax.set_title(\"LWR performance as a function of the number of components\")\n",
    "plt.savefig(log_dir/f\"heat_scatter.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (lazydeep)",
   "language": "python",
   "name": "pycharm-12fcba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
