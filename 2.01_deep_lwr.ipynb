{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# set seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import utils as ut\n",
    "import experiment as exp\n",
    "from evaluation import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import random\n",
    "#define fixed_hyperparams and create a config gen\n",
    "from configurations import RandomConfigGen, Configuration\n",
    "from torch import nn\n",
    "from deep_net import RandomNet\n",
    "from experiment import run_experiment\n",
    "import regex as re\n",
    "from pathlib import *\n",
    "from plot import *\n",
    "from sk_models import setup_pls_models_slim\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "random_state = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\workspace\\lazydeep\\experiments\\2.01\\PLN7\n"
     ]
    }
   ],
   "source": [
    "#setup input and output formats, load data\n",
    "\n",
    "file_name = \"PLN7.csv\"\n",
    "\n",
    "id_cols =[\"sample_id\"]#[\"db_id\", \"sample_id\"]#[\"sample_id\"]\n",
    "\n",
    "data_path = Path('D:/workspace/lazydeep/data/soil_data/')\n",
    "model_path = Path('D:/workspace/lazydeep/experiments/2.00/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/2.01\")\n",
    "n_components = 24\n",
    "\n",
    "data_file = data_path / file_name\n",
    "log_dir = log_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "model_dir = model_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)/\"models\"\n",
    "\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "print(log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% load data\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 129)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data = ut.sample_data(data,random_state)\n",
    "nrow, ncol = data.shape\n",
    "\n",
    "n_features = ncol - 1-len(id_cols)\n",
    "dataset = TabularDataset(data,id_cols = id_cols, cat_cols=None, output_cols=None, ignore_cols= None)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% load models\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 models\n"
     ]
    }
   ],
   "source": [
    "n_models = 100\n",
    "model_names = [f\"random_{i}\" for i in range(0,n_models)]\n",
    "deep_models = {name:torch.load(model_dir/name/\"_model\") for name in model_names}\n",
    "#for each model, load state\n",
    "print(f\"Loaded {len(deep_models)} models\")\n",
    "#print(deep_models)\n",
    "for name in model_names:\n",
    "    sub_path = log_dir / name\n",
    "    if not sub_path.exists():\n",
    "        sub_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup logging and tensorboard outputs\n"
    }
   },
   "outputs": [],
   "source": [
    "# set logging, in this case the root logger\n",
    "ut.setup_logger(logger_name=\"\",file_name=log_dir/\"log.txt\")\n",
    "ut.setup_logger(logger_name=\"summary\",file_name=log_dir/\"summary.txt\")\n",
    "summary_logger = logging.getLogger(\"summary\")\n",
    "tb = SummaryWriter(log_dir/\"tb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup experiment\n"
    }
   },
   "outputs": [],
   "source": [
    "fixed_hyperparams = {'bs': 32,'loss': nn.MSELoss(),'epochs': 100}\n",
    "preprocessing = Preprocess_Std()\n",
    "eval = CrossValEvaluation(preprocessing=preprocessing,tensorboard=None,time=True)\n",
    "scores={} #->model->knn:{fold_0:number,...,fold_n:number,mean:number,median:number\n",
    "preds={} #model-> foldsxknn_models\n",
    "deep_scores_dict={}\n",
    "deep_preds_dict={}\n",
    "actual_y = None\n",
    "\n",
    "device = \"cpu\" #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_fun_cv = lambda name,model, fold : model.load_state(model_dir/name/f\"_fold_{fold}\")\n",
    "load_fun_build = lambda name,model : model.load_state(model_dir/name/f\"_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.901492684657638 2835.9494166313502\n",
      "0.7137130174344717 137.57458402118817\n",
      "0.6842488065116867 151.73354620972174\n",
      "0.6705859669251293 158.29919392385983\n",
      "0.6918871068024048 148.06297769239862\n",
      "0.6962878551588532 145.9482076840147\n",
      "0.7221339790066443 133.52790933494083\n"
     ]
    }
   ],
   "source": [
    "#best model is random_57  - MSE:0.4028,R2:0.9337'\n",
    "\n",
    "tt_splitter= train_test_split\n",
    "train_split1,test_split = tt_splitter([i for i in range(0,len(data))],train_size=5/6,random_state=random_state,shuffle=False)\n",
    "train_split,val_split = tt_splitter(train_split1,train_size=4/5,random_state=random_state,shuffle=False)\n",
    "\n",
    "train_data, val_data, test_data = dataset.split(train_split1, None, test_split, preprocessing = preprocessing)\n",
    "test_X,test_y = zip(*[ (X,y) for X,y in test_data])\n",
    "test_y = np.asarray(test_y)\n",
    "model = torch.load(model_dir/\"random_5\"/f\"_model\")\n",
    "for code in ['init_state','fold_0','fold_1','fold_2','fold_3','fold_4','final']:\n",
    "    model.load_state_dict(torch.load(model_dir/\"random_5\"/f\"_{code}\"))\n",
    "    preds = model.forward(torch.tensor(test_X).float()).detach().numpy()\n",
    "\n",
    "    val_score = r2_score(test_y,preds)\n",
    "    val_mse =  mean_squared_error(test_y,preds)\n",
    "\n",
    "    print(val_score,val_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% deep experiment\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Tested (test) on 1667 instances with mean losses of: random_0:136.2852,random_1:153.5712,random_2:2797.6633,random_3:158.378,random_4:143.021,random_5:142.3826,random_6:2800.7682,random_7:470.146,random_8:780.5786,random_9:135.0837,random_10:161.4849,random_11:150.2466,random_12:146.1845,random_13:150.9397,random_14:503.189,random_15:149.3638,random_16:158.8616,random_17:165.4746,random_18:147.1884,random_19:165.8623,random_20:129.491,random_21:158.1804,random_22:151.6569,random_23:157.3727,random_24:188.5457,random_25:125.0378,random_26:152.918,random_27:149.6584,random_28:155.8865,random_29:125.6509,random_30:163.6281,random_31:148.0907,random_32:2786.4241,random_33:2788.8558,random_34:145.8009,random_35:503.1885,random_36:153.426,random_37:131.4303,random_38:127.1206,random_39:2801.3368,random_40:162.6264,random_41:130.4509,random_42:148.809,random_43:2788.433,random_44:166.2972,random_45:2783.8559,random_46:144.6992,random_47:483.0659,random_48:161.376,random_49:132.0664,random_50:129.3602,random_51:127.378,random_52:153.2106,random_53:178.3485,random_54:179.3863,random_55:151.6615,random_56:155.0839,random_57:139.9835,random_58:502.3666,random_59:400.4574,random_60:126.8915,random_61:147.3839,random_62:2792.6448,random_63:502.3785,random_64:159.2419,random_65:156.5764,random_66:169.748,random_67:502.3803,random_68:152.2888,random_69:144.7287,random_70:180.8047,random_71:2787.0943,random_72:152.3576,random_73:149.0248,random_74:134.9177,random_75:167.7861,random_76:133.8802,random_77:149.3034,random_78:154.2885,random_79:145.8458,random_80:137.503,random_81:149.6568,random_82:150.7267,random_83:2813.978,random_84:196.3411,random_85:2817.2383,random_86:496.1046,random_87:269.6983,random_88:181.051,random_89:144.3729,random_90:166.3036,random_91:163.5509,random_92:149.7864,random_93:146.0438,random_94:158.4758,random_95:503.1913,random_96:181.4978,random_97:161.5134,random_98:146.9521,random_99:171.317'\n",
      "Testing (test) took 0:00:03.408999'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Tested (test) on 1667 instances with mean losses of: random_0:152.6778,random_1:158.425,random_2:2853.2999,random_3:159.4653,random_4:142.0542,random_5:148.5114,random_6:2856.4237,random_7:542.4177,random_8:1311.9958,random_9:143.4813,random_10:149.0452,random_11:168.315,random_12:144.8794,random_13:161.7639,random_14:455.0202,random_15:133.8571,random_16:155.6094,random_17:234.7786,random_18:296.4251,random_19:152.5319,random_20:135.248,random_21:152.2558,random_22:192.0852,random_23:171.5841,random_24:174.6203,random_25:131.5466,random_26:155.6981,random_27:167.3473,random_28:184.4005,random_29:161.0055,random_30:155.9993,random_31:159.7255,random_32:2841.7852,random_33:2844.2302,random_34:155.4636,random_35:455.0202,random_36:159.271,random_37:138.6988,random_38:134.3939,random_39:2857.0199,random_40:159.2526,random_41:142.1436,random_42:146.75,random_43:322.1948,random_44:151.2913,random_45:2839.157,random_46:158.119,random_47:455.7006,random_48:171.156,random_49:138.4653,random_50:139.0033,random_51:135.7932,random_52:161.0889,random_53:157.652,random_54:440.317,random_55:143.593,random_56:161.9522,random_57:154.6745,random_58:948.5504,random_59:156.1778,random_60:136.196,random_61:145.6595,random_62:2848.0882,random_63:137.5034,random_64:159.4115,random_65:144.6452,random_66:157.9471,random_67:456.0577,random_68:158.7679,random_69:149.2502,random_70:174.3552,random_71:2842.46,random_72:149.5085,random_73:142.918,random_74:144.4473,random_75:154.6178,random_76:141.9941,random_77:154.0558,random_78:156.1227,random_79:144.8833,random_80:147.3746,random_81:156.441,random_82:156.0526,random_83:2869.9291,random_84:187.4092,random_85:2873.3193,random_86:2863.278,random_87:401.1182,random_88:150.6094,random_89:138.7184,random_90:203.3162,random_91:2867.0714,random_92:145.9316,random_93:156.7671,random_94:176.2246,random_95:209012.4818,random_96:185.467,random_97:157.3634,random_98:157.6339,random_99:140.445'\n",
      "Testing (test) took 0:00:03.474999'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Tested (test) on 1667 instances with mean losses of: random_0:135.2845,random_1:152.2485,random_2:2902.1253,random_3:228.4738,random_4:140.1916,random_5:165.2193,random_6:2905.2261,random_7:578.8734,random_8:2913.6117,random_9:139.1667,random_10:162.8225,random_11:161.3183,random_12:147.1867,random_13:164.6384,random_14:491.7593,random_15:138.2801,random_16:158.8149,random_17:194.3703,random_18:2726.1706,random_19:1531.1868,random_20:144.4924,random_21:148.6747,random_22:491.7425,random_23:175.0059,random_24:177.2723,random_25:131.5338,random_26:162.9254,random_27:157.3026,random_28:205.7408,random_29:134.5865,random_30:157.5528,random_31:151.0345,random_32:2890.5706,random_33:2893.0044,random_34:161.827,random_35:155.9754,random_36:153.721,random_37:129.299,random_38:134.6397,random_39:2905.7142,random_40:164.4743,random_41:138.2983,random_42:157.9444,random_43:2892.6237,random_44:170.351,random_45:2887.9216,random_46:151.329,random_47:321.6051,random_48:233.1637,random_49:140.096,random_50:135.6857,random_51:131.4252,random_52:159.5622,random_53:552.397,random_54:185.5263,random_55:155.4218,random_56:202.8427,random_57:173.8158,random_58:2912.3573,random_59:478.449,random_60:135.1586,random_61:160.1177,random_62:2896.8469,random_63:134.7364,random_64:227.0186,random_65:148.534,random_66:172.158,random_67:491.7191,random_68:164.7666,random_69:147.4746,random_70:248.963,random_71:2891.2984,random_72:186.3274,random_73:156.2664,random_74:141.306,random_75:147.4422,random_76:135.5621,random_77:150.7113,random_78:163.6193,random_79:152.4872,random_80:149.6048,random_81:181.3543,random_82:160.0276,random_83:2918.7961,random_84:167.2076,random_85:188.6703,random_86:491.8665,random_87:274.6075,random_88:491.7046,random_89:141.9472,random_90:151.0267,random_91:2915.8946,random_92:156.7164,random_93:157.2324,random_94:165.3558,random_95:491.7031,random_96:182.7709,random_97:168.7259,random_98:491.4059,random_99:142.8099'\n",
      "Testing (test) took 0:00:03.454003'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Tested (test) on 1666 instances with mean losses of: random_0:130.5817,random_1:158.7359,random_2:2833.5765,random_3:227.0867,random_4:136.3491,random_5:148.1871,random_6:2836.5767,random_7:659.3378,random_8:445.3797,random_9:133.9316,random_10:158.8334,random_11:149.4666,random_12:139.8316,random_13:146.8805,random_14:479.133,random_15:132.3809,random_16:143.7506,random_17:183.5927,random_18:302.3886,random_19:674.0291,random_20:148.4902,random_21:144.5101,random_22:140.8432,random_23:166.3289,random_24:208.1893,random_25:125.5532,random_26:149.6917,random_27:478.8947,random_28:199.091,random_29:148.3721,random_30:145.6085,random_31:140.8437,random_32:2822.2726,random_33:2824.6564,random_34:135.2698,random_35:150.9249,random_36:142.9484,random_37:138.7311,random_38:125.8052,random_39:2837.4309,random_40:139.0744,random_41:133.8873,random_42:149.1254,random_43:2824.1706,random_44:188.5787,random_45:2819.5563,random_46:153.1868,random_47:478.885,random_48:163.3068,random_49:138.0658,random_50:131.2033,random_51:131.6907,random_52:135.8088,random_53:150.2634,random_54:178.6712,random_55:139.1232,random_56:156.5312,random_57:148.1147,random_58:429.4099,random_59:2849.8704,random_60:129.4184,random_61:157.8823,random_62:2828.4618,random_63:131.4399,random_64:167.5664,random_65:177.9367,random_66:144.3815,random_67:479.2117,random_68:146.3933,random_69:143.83,random_70:184.1174,random_71:2822.8111,random_72:147.5397,random_73:149.7685,random_74:133.8388,random_75:143.3703,random_76:135.611,random_77:142.0959,random_78:151.5998,random_79:167.3322,random_80:130.1267,random_81:189.9895,random_82:138.7544,random_83:2850.0939,random_84:148.7127,random_85:2853.3545,random_86:479.3087,random_87:277.7707,random_88:479.0554,random_89:129.9723,random_90:182.4685,random_91:380.9081,random_92:140.0897,random_93:139.8677,random_94:164.8231,random_95:479.4458,random_96:181.8149,random_97:138.0411,random_98:138.1942,random_99:140.8356'\n",
      "Testing (test) took 0:00:03.430002'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Tested (test) on 1666 instances with mean losses of: random_0:1420.5389,random_1:607.7041,random_2:2836.928,random_3:2807.9709,random_4:770.6154,random_5:269.9363,random_6:2840.0014,random_7:493.5293,random_8:2848.3103,random_9:234.3096,random_10:563.1731,random_11:280.7072,random_12:827.7249,random_13:649.4549,random_14:506.2175,random_15:626.4355,random_16:227.822,random_17:419.236,random_18:508.2706,random_19:188.8618,random_20:554.5057,random_21:246.9193,random_22:461.9414,random_23:250.1264,random_24:562.3248,random_25:1056.9688,random_26:159.674,random_27:1286.4686,random_28:627.9087,random_29:715.7621,random_30:272.856,random_31:362.4936,random_32:2825.6328,random_33:2828.0574,random_34:192.2286,random_35:900.9543,random_36:177.1591,random_37:819.0774,random_38:1540.7844,random_39:214.2148,random_40:204.4171,random_41:1430.8513,random_42:223.2633,random_43:2827.6144,random_44:496.7632,random_45:839.4297,random_46:712.0133,random_47:612.4236,random_48:226.3118,random_49:512.9346,random_50:1169.2734,random_51:809.0819,random_52:196.9914,random_53:1797.0479,random_54:226.7384,random_55:174.6378,random_56:277.9244,random_57:564.1976,random_58:644.8839,random_59:588.9634,random_60:520.7797,random_61:397.7635,random_62:22694.4586,random_63:970.2706,random_64:160.9884,random_65:1010.3479,random_66:215.684,random_67:506.2132,random_68:284.2606,random_69:2391.3579,random_70:245.5228,random_71:2826.2078,random_72:455.2436,random_73:2190.3048,random_74:792.8704,random_75:559.8314,random_76:435.4072,random_77:162.0005,random_78:314.3909,random_79:512.9609,random_80:311.898,random_81:543.0796,random_82:313.3208,random_83:2853.382,random_84:248.0086,random_85:2856.6673,random_86:2049.2329,random_87:255.2906,random_88:506.2175,random_89:916.2114,random_90:204.7718,random_91:2850.5448,random_92:161.5249,random_93:799.1797,random_94:145.5463,random_95:506.2173,random_96:263.5615,random_97:267.4362,random_98:154.5696,random_99:294.2192'\n",
      "Testing (test) took 0:00:03.361998'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Tested (test) on 1667 instances with mean losses of: random_0:137.3119,random_1:148.9765,random_2:169.822,random_3:165.7793,random_4:131.1875,random_5:140.331,random_6:2870.9991,random_7:534.3656,random_8:2879.3669,random_9:130.368,random_10:150.0302,random_11:145.4829,random_12:146.2965,random_13:154.2843,random_14:480.5818,random_15:130.0982,random_16:152.592,random_17:166.2634,random_18:162.3994,random_19:156.5683,random_20:132.2778,random_21:149.0307,random_22:480.5815,random_23:165.4764,random_24:480.5817,random_25:126.7826,random_26:160.0396,random_27:145.6321,random_28:141.4173,random_29:130.7315,random_30:149.0936,random_31:144.2778,random_32:2856.36,random_33:2858.8213,random_34:152.812,random_35:148.4787,random_36:155.5323,random_37:127.1283,random_38:134.2556,random_39:2278.8628,random_40:159.7875,random_41:132.107,random_42:158.7934,random_43:2858.4469,random_44:142.2953,random_45:2853.7525,random_46:147.4788,random_47:474.2663,random_48:162.8366,random_49:136.9516,random_50:144.6458,random_51:134.4036,random_52:150.1244,random_53:147.4951,random_54:174.471,random_55:147.052,random_56:158.1373,random_57:138.2178,random_58:746.4288,random_59:159.4292,random_60:133.0463,random_61:157.9117,random_62:1050.938,random_63:135.1463,random_64:150.4369,random_65:149.8592,random_66:153.1359,random_67:480.599,random_68:147.6675,random_69:137.0309,random_70:168.3804,random_71:2857.0854,random_72:159.7386,random_73:132.6991,random_74:130.8503,random_75:147.9487,random_76:128.201,random_77:140.2358,random_78:154.2957,random_79:148.6069,random_80:135.1861,random_81:195.5098,random_82:148.283,random_83:2884.4845,random_84:166.7536,random_85:2887.8472,random_86:480.7691,random_87:266.9049,random_88:480.5822,random_89:147.4827,random_90:181.1588,random_91:2881.6153,random_92:139.0634,random_93:148.9965,random_94:156.1277,random_95:1.1319705037951158e+16,random_96:162.6843,random_97:160.6878,random_98:158.5334,random_99:144.1922'\n",
      "Testing (test) took 0:00:03.406001'\n"
     ]
    }
   ],
   "source": [
    "deep_scheme = DeepScheme(None, fixed_hyperparams=fixed_hyperparams,loss_eval=loss_target,device=device,tensorboard=tb,adaptive_lr=True,update=False)\n",
    "deep_scores, deep_preds, _ , _, _ = eval.evaluate(deep_models,dataset,deep_scheme,logger_name=\"log\",load_fun=load_fun_cv)\n",
    "deep_scores_final, deep_preds_final, _ ,_, _ = eval.build(deep_models,dataset,deep_scheme,logger_name=\"test_log\",load_fun=load_fun_build)\n",
    "\n",
    "all_scores = []\n",
    "for k,v in ut.flip_dicts(deep_scores).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores.append({**dict1,**v})\n",
    "\n",
    "all_scores_final = []\n",
    "for k,v in ut.flip_dicts(deep_scores_final).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores_final.append({**dict1,**v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% lwr part\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_0'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.3089,lwr_k=20:35.6103,lwr_k=50:67.5774,lwr_k=100:88.9727,lwr_k=200:104.489,lwr_k=500:117.4388,lwr_k=1000:123.9295'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:137.9621,lwr_k=20:219.2102,lwr_k=50:193.7862,lwr_k=100:162.9808,lwr_k=200:147.5973,lwr_k=500:140.7937,lwr_k=1000:138.8587'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:174.232,lwr_k=20:44.5037,lwr_k=50:75.8081,lwr_k=100:98.322,lwr_k=200:115.3516,lwr_k=500:130.0423,lwr_k=1000:138.0594'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:168.8592,lwr_k=20:214.1841,lwr_k=50:194.741,lwr_k=100:178.1998,lwr_k=200:168.2305,lwr_k=500:154.2833,lwr_k=1000:151.4646'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.411,lwr_k=20:19.8922,lwr_k=50:50.8618,lwr_k=100:76.0336,lwr_k=200:95.7176,lwr_k=500:109.454,lwr_k=1000:115.8946'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:142.8967,lwr_k=20:241.9209,lwr_k=50:210.2959,lwr_k=100:171.5882,lwr_k=200:147.1412,lwr_k=500:151.2538,lwr_k=1000:130.0787'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:155.7404,lwr_k=20:29.5761,lwr_k=50:60.3501,lwr_k=100:82.2016,lwr_k=200:97.5936,lwr_k=500:111.0114,lwr_k=1000:118.3241'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:149.6721,lwr_k=20:202.0816,lwr_k=50:160.1853,lwr_k=100:151.9135,lwr_k=200:141.8455,lwr_k=500:131.9893,lwr_k=1000:124.567'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:139.7828,lwr_k=20:57.4152,lwr_k=50:80.5974,lwr_k=100:96.6585,lwr_k=200:109.9217,lwr_k=500:121.7555,lwr_k=1000:127.3461'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:1096.7472,lwr_k=20:289.0215,lwr_k=50:577.4296,lwr_k=100:479.8408,lwr_k=200:740.8333,lwr_k=500:889.4541,lwr_k=1000:937.2823'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:129.8333,lwr_k=20:30.2023,lwr_k=50:62.8163,lwr_k=100:84.7917,lwr_k=200:101.409,lwr_k=500:113.5756,lwr_k=1000:118.6762'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:134.5937,lwr_k=20:235.9754,lwr_k=50:183.2014,lwr_k=100:162.1784,lwr_k=200:150.1651,lwr_k=500:135.8145,lwr_k=1000:133.8765'\n",
      "Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.'\n",
      "NumExpr defaulting to 8 threads.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_1'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.3808,lwr_k=20:99.1485,lwr_k=50:112.3715,lwr_k=100:120.2689,lwr_k=200:125.3011,lwr_k=500:132.4599,lwr_k=1000:135.4453'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.9141,lwr_k=20:169.1595,lwr_k=50:164.4136,lwr_k=100:149.9653,lwr_k=200:148.0314,lwr_k=500:143.6564,lwr_k=1000:140.4217'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.1229,lwr_k=20:97.9355,lwr_k=50:111.6916,lwr_k=100:120.9095,lwr_k=200:127.7342,lwr_k=500:134.1459,lwr_k=1000:136.8385'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:152.9472,lwr_k=20:165.5201,lwr_k=50:157.2283,lwr_k=100:153.803,lwr_k=200:150.4924,lwr_k=500:148.6804,lwr_k=1000:149.1152'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:145.3448,lwr_k=20:104.6167,lwr_k=50:117.6015,lwr_k=100:124.8478,lwr_k=200:131.5277,lwr_k=500:135.6523,lwr_k=1000:138.6847'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:146.3159,lwr_k=20:166.0114,lwr_k=50:156.2295,lwr_k=100:150.5409,lwr_k=200:146.4469,lwr_k=500:143.2462,lwr_k=1000:142.3828'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:150.3017,lwr_k=20:92.4103,lwr_k=50:110.1179,lwr_k=100:124.9288,lwr_k=200:134.9853,lwr_k=500:141.1311,lwr_k=1000:143.3729'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:148.1215,lwr_k=20:163.8011,lwr_k=50:162.5685,lwr_k=100:152.6791,lwr_k=200:147.9092,lwr_k=500:146.0772,lwr_k=1000:144.2089'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:157.8325,lwr_k=20:111.5147,lwr_k=50:124.7239,lwr_k=100:132.7993,lwr_k=200:139.8533,lwr_k=500:145.6172,lwr_k=1000:149.1745'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:517.4258,lwr_k=20:318.0072,lwr_k=50:483.4133,lwr_k=100:1142.422,lwr_k=200:2067.395,lwr_k=500:1539.9435,lwr_k=1000:921.9734'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:133.5687,lwr_k=20:98.5675,lwr_k=50:108.0108,lwr_k=100:115.41,lwr_k=200:120.3143,lwr_k=500:123.6106,lwr_k=1000:125.6321'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:140.0461,lwr_k=20:147.8167,lwr_k=50:144.3667,lwr_k=100:143.5565,lwr_k=200:138.8846,lwr_k=500:136.1859,lwr_k=1000:134.6144'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_2'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:382.864,lwr_k=20:283.3634,lwr_k=50:295.0079,lwr_k=100:295.9047,lwr_k=200:294.3212,lwr_k=500:297.7097,lwr_k=1000:304.3441'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:414.5059,lwr_k=20:371.6862,lwr_k=50:358.4372,lwr_k=100:353.8839,lwr_k=200:341.5411,lwr_k=500:330.6716,lwr_k=1000:335.8101'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:397.3591,lwr_k=20:290.1322,lwr_k=50:302.9797,lwr_k=100:302.5214,lwr_k=200:299.9936,lwr_k=500:302.3509,lwr_k=1000:309.2371'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:375.2302,lwr_k=20:339.8461,lwr_k=50:328.3284,lwr_k=100:323.4194,lwr_k=200:312.0874,lwr_k=500:309.1923,lwr_k=1000:306.5905'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:405.1346,lwr_k=20:289.4246,lwr_k=50:303.4777,lwr_k=100:303.6171,lwr_k=200:300.2358,lwr_k=500:302.4963,lwr_k=1000:310.5933'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:384.1451,lwr_k=20:348.5742,lwr_k=50:335.416,lwr_k=100:330.4951,lwr_k=200:322.0919,lwr_k=500:311.8582,lwr_k=1000:319.1311'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:395.7128,lwr_k=20:293.4587,lwr_k=50:304.7524,lwr_k=100:304.8703,lwr_k=200:301.2637,lwr_k=500:300.3211,lwr_k=1000:308.6701'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:403.8922,lwr_k=20:337.8041,lwr_k=50:328.0518,lwr_k=100:321.5038,lwr_k=200:312.0368,lwr_k=500:310.0738,lwr_k=1000:318.9588'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:385.8836,lwr_k=20:287.2086,lwr_k=50:300.5588,lwr_k=100:302.1933,lwr_k=200:300.8986,lwr_k=500:300.7825,lwr_k=1000:310.7295'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:421.1719,lwr_k=20:388.3931,lwr_k=50:393.3804,lwr_k=100:392.8779,lwr_k=200:384.352,lwr_k=500:368.592,lwr_k=1000:375.9819'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:143.4569,lwr_k=20:6.4266,lwr_k=50:69.0267,lwr_k=100:95.3512,lwr_k=200:110.3589,lwr_k=500:121.9597,lwr_k=1000:128.3163'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.0979,lwr_k=20:1102.5381,lwr_k=50:300.1085,lwr_k=100:171.7627,lwr_k=200:147.4329,lwr_k=500:139.5923,lwr_k=1000:138.9806'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_3'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:145.9213,lwr_k=20:66.0029,lwr_k=50:105.7512,lwr_k=100:120.4002,lwr_k=200:126.6123,lwr_k=500:133.4373,lwr_k=1000:136.7245'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:151.7693,lwr_k=20:217.5581,lwr_k=50:160.6889,lwr_k=100:149.1585,lwr_k=200:145.1629,lwr_k=500:145.2081,lwr_k=1000:145.2528'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:147.8761,lwr_k=20:66.7743,lwr_k=50:103.9319,lwr_k=100:117.8541,lwr_k=200:125.6659,lwr_k=500:132.1164,lwr_k=1000:136.0803'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:154.5362,lwr_k=20:253.5481,lwr_k=50:175.2955,lwr_k=100:159.5229,lwr_k=200:150.2839,lwr_k=500:147.958,lwr_k=1000:149.0777'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:154.4175,lwr_k=20:103.3484,lwr_k=50:121.6135,lwr_k=100:130.1928,lwr_k=200:136.2105,lwr_k=500:141.4987,lwr_k=1000:145.0912'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:154.3358,lwr_k=20:204.3596,lwr_k=50:161.3396,lwr_k=100:160.7496,lwr_k=200:146.9081,lwr_k=500:148.3674,lwr_k=1000:148.086'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:160.955,lwr_k=20:155.0121,lwr_k=50:150.9632,lwr_k=100:152.6882,lwr_k=200:154.2335,lwr_k=500:154.9925,lwr_k=1000:154.9567'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:154.2239,lwr_k=20:164.9982,lwr_k=50:152.2368,lwr_k=100:159.1343,lwr_k=200:146.9245,lwr_k=500:147.1843,lwr_k=1000:147.9238'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:469.6371,lwr_k=20:420.0392,lwr_k=50:438.8294,lwr_k=100:445.2145,lwr_k=200:450.2369,lwr_k=500:454.7587,lwr_k=1000:458.6976'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:496.4262,lwr_k=20:486.5228,lwr_k=50:482.7428,lwr_k=100:480.0377,lwr_k=200:477.5453,lwr_k=500:478.9208,lwr_k=1000:485.8424'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:164.8355,lwr_k=20:74.1807,lwr_k=50:105.0722,lwr_k=100:117.5225,lwr_k=200:124.4313,lwr_k=500:131.3532,lwr_k=1000:134.9684'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:164.3369,lwr_k=20:214.0119,lwr_k=50:159.012,lwr_k=100:147.0706,lwr_k=200:142.8685,lwr_k=500:140.6144,lwr_k=1000:141.5779'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_4'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.5846,lwr_k=20:56.9236,lwr_k=50:86.9673,lwr_k=100:103.914,lwr_k=200:115.4495,lwr_k=500:124.7824,lwr_k=1000:130.0053'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.2651,lwr_k=20:197.0783,lwr_k=50:176.345,lwr_k=100:166.3764,lwr_k=200:155.6195,lwr_k=500:148.6583,lwr_k=1000:142.5351'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:167.8084,lwr_k=20:54.6054,lwr_k=50:86.1691,lwr_k=100:103.3031,lwr_k=200:115.0953,lwr_k=500:123.8174,lwr_k=1000:128.771'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:160.5898,lwr_k=20:182.8001,lwr_k=50:164.9158,lwr_k=100:155.3871,lwr_k=200:149.1982,lwr_k=500:141.0685,lwr_k=1000:138.6762'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:150.4645,lwr_k=20:48.905,lwr_k=50:80.7351,lwr_k=100:98.136,lwr_k=200:107.8794,lwr_k=500:117.0497,lwr_k=1000:121.6187'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:156.5551,lwr_k=20:198.3892,lwr_k=50:165.3467,lwr_k=100:156.2765,lwr_k=200:143.7917,lwr_k=500:139.2857,lwr_k=1000:137.856'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:180.9318,lwr_k=20:51.533,lwr_k=50:81.9632,lwr_k=100:97.7819,lwr_k=200:109.7309,lwr_k=500:119.9751,lwr_k=1000:125.8084'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:174.0096,lwr_k=20:192.1926,lwr_k=50:152.7883,lwr_k=100:140.7291,lwr_k=200:134.852,lwr_k=500:131.2,lwr_k=1000:133.0002'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:133.4148,lwr_k=20:46.4881,lwr_k=50:79.4051,lwr_k=100:98.5514,lwr_k=200:111.4141,lwr_k=500:121.2924,lwr_k=1000:125.4782'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:762.9134,lwr_k=20:2622.3465,lwr_k=50:1398.6346,lwr_k=100:629.2218,lwr_k=200:619.383,lwr_k=500:720.207,lwr_k=1000:646.7252'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:134.1117,lwr_k=20:18.848,lwr_k=50:59.6853,lwr_k=100:84.9976,lwr_k=200:99.2234,lwr_k=500:108.4128,lwr_k=1000:113.685'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:136.7454,lwr_k=20:286.5364,lwr_k=50:198.1166,lwr_k=100:155.9617,lwr_k=200:135.6255,lwr_k=500:126.1711,lwr_k=1000:127.924'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_5'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:130.248,lwr_k=20:51.2928,lwr_k=50:90.6767,lwr_k=100:105.5019,lwr_k=200:114.6233,lwr_k=500:121.0309,lwr_k=1000:125.094'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:135.1427,lwr_k=20:282.668,lwr_k=50:160.8247,lwr_k=100:141.009,lwr_k=200:135.0971,lwr_k=500:131.3024,lwr_k=1000:132.1617'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:131.79,lwr_k=20:51.0774,lwr_k=50:87.6938,lwr_k=100:102.2493,lwr_k=200:110.3584,lwr_k=500:119.129,lwr_k=1000:122.648'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.9173,lwr_k=20:249.0325,lwr_k=50:160.3516,lwr_k=100:140.3338,lwr_k=200:136.5792,lwr_k=500:134.3689,lwr_k=1000:135.3714'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:126.5391,lwr_k=20:69.2207,lwr_k=50:97.1763,lwr_k=100:108.0632,lwr_k=200:113.9056,lwr_k=500:119.1241,lwr_k=1000:121.5166'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:140.7064,lwr_k=20:215.4554,lwr_k=50:158.6036,lwr_k=100:149.283,lwr_k=200:143.2731,lwr_k=500:141.8,lwr_k=1000:142.035'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:131.8315,lwr_k=20:50.3258,lwr_k=50:82.8146,lwr_k=100:99.3996,lwr_k=200:108.0499,lwr_k=500:117.1618,lwr_k=1000:121.9295'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:141.453,lwr_k=20:231.841,lwr_k=50:158.8868,lwr_k=100:134.4617,lwr_k=200:129.6943,lwr_k=500:127.233,lwr_k=1000:127.9384'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:155.2188,lwr_k=20:63.1113,lwr_k=50:91.5582,lwr_k=100:105.714,lwr_k=200:113.9513,lwr_k=500:121.1135,lwr_k=1000:125.6359'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:510.2795,lwr_k=20:264.5394,lwr_k=50:742.0388,lwr_k=100:320.5159,lwr_k=200:419.9496,lwr_k=500:338.8528,lwr_k=1000:303.4317'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:128.4665,lwr_k=20:54.5135,lwr_k=50:88.845,lwr_k=100:100.3741,lwr_k=200:108.9881,lwr_k=500:114.7658,lwr_k=1000:117.4118'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:130.0591,lwr_k=20:222.5539,lwr_k=50:154.4935,lwr_k=100:136.4902,lwr_k=200:130.1789,lwr_k=500:127.0363,lwr_k=1000:125.0206'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_6'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:343.4432,lwr_k=20:259.8857,lwr_k=50:271.2263,lwr_k=100:272.2026,lwr_k=200:273.474,lwr_k=500:278.9502,lwr_k=1000:290.2881'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:361.2561,lwr_k=20:340.9306,lwr_k=50:334.8568,lwr_k=100:330.9629,lwr_k=200:323.5998,lwr_k=500:314.8821,lwr_k=1000:320.1126'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:353.3095,lwr_k=20:260.7845,lwr_k=50:273.0239,lwr_k=100:275.6197,lwr_k=200:277.9038,lwr_k=500:284.643,lwr_k=1000:296.0885'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:339.2105,lwr_k=20:305.6898,lwr_k=50:294.2609,lwr_k=100:291.0516,lwr_k=200:285.2153,lwr_k=500:281.8171,lwr_k=1000:287.6304'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:351.0528,lwr_k=20:263.3131,lwr_k=50:275.6538,lwr_k=100:279.3165,lwr_k=200:279.4257,lwr_k=500:283.6286,lwr_k=1000:294.618'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:357.3299,lwr_k=20:317.7862,lwr_k=50:315.4763,lwr_k=100:310.2684,lwr_k=200:304.9128,lwr_k=500:306.9099,lwr_k=1000:310.7436'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:341.4145,lwr_k=20:255.7155,lwr_k=50:271.5401,lwr_k=100:276.6389,lwr_k=200:277.6241,lwr_k=500:281.6351,lwr_k=1000:293.2254'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:390.5006,lwr_k=20:317.4774,lwr_k=50:305.0356,lwr_k=100:298.6166,lwr_k=200:294.141,lwr_k=500:295.5087,lwr_k=1000:303.8331'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:345.5951,lwr_k=20:263.4274,lwr_k=50:276.1008,lwr_k=100:278.9869,lwr_k=200:279.0157,lwr_k=500:283.632,lwr_k=1000:294.69'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:364.8396,lwr_k=20:332.2505,lwr_k=50:326.4196,lwr_k=100:316.4783,lwr_k=200:311.9016,lwr_k=500:306.8663,lwr_k=1000:315.5254'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:348.5536,lwr_k=20:257.5058,lwr_k=50:273.1639,lwr_k=100:275.4522,lwr_k=200:275.9386,lwr_k=500:280.1615,lwr_k=1000:290.1257'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:367.7634,lwr_k=20:325.3037,lwr_k=50:317.9252,lwr_k=100:312.8274,lwr_k=200:307.1045,lwr_k=500:306.3753,lwr_k=1000:312.0113'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_7'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:372.8802,lwr_k=20:307.6464,lwr_k=50:339.7724,lwr_k=100:354.4218,lwr_k=200:365.2087,lwr_k=500:373.9087,lwr_k=1000:376.7473'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:149985.9659,lwr_k=20:529.1042,lwr_k=50:438.7672,lwr_k=100:419.6605,lwr_k=200:426.3445,lwr_k=500:416.9624,lwr_k=1000:415.2353'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:327.1828,lwr_k=20:264.6367,lwr_k=50:294.3601,lwr_k=100:307.0863,lwr_k=200:317.8201,lwr_k=500:322.5295,lwr_k=1000:324.0717'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:290.9549,lwr_k=20:349.0438,lwr_k=50:312.0311,lwr_k=100:296.6342,lwr_k=200:293.8387,lwr_k=500:293.877,lwr_k=1000:290.5462'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:407.5977,lwr_k=20:359.6358,lwr_k=50:391.2123,lwr_k=100:406.6136,lwr_k=200:415.2737,lwr_k=500:423.6638,lwr_k=1000:425.0043'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:402.6713,lwr_k=20:461.3012,lwr_k=50:428.5387,lwr_k=100:417.048,lwr_k=200:416.4737,lwr_k=500:417.5358,lwr_k=1000:418.7868'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:404.8045,lwr_k=20:346.8992,lwr_k=50:381.4227,lwr_k=100:395.7492,lwr_k=200:401.6456,lwr_k=500:408.5736,lwr_k=1000:410.2048'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:394.8627,lwr_k=20:440.9046,lwr_k=50:420.5928,lwr_k=100:412.7949,lwr_k=200:408.9336,lwr_k=500:403.8,lwr_k=1000:401.3315'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:425.9751,lwr_k=20:317.7739,lwr_k=50:366.2388,lwr_k=100:391.6208,lwr_k=200:402.8734,lwr_k=500:410.9206,lwr_k=1000:414.2057'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:457.2151,lwr_k=20:566.6499,lwr_k=50:463.7285,lwr_k=100:458.5491,lwr_k=200:465.711,lwr_k=500:451.8277,lwr_k=1000:448.8779'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:406.2623,lwr_k=20:337.7545,lwr_k=50:376.5815,lwr_k=100:391.1485,lwr_k=200:396.4949,lwr_k=500:402.6422,lwr_k=1000:407.0266'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:405.559,lwr_k=20:502.5592,lwr_k=50:510.4286,lwr_k=100:417.6564,lwr_k=200:414.8184,lwr_k=500:413.6948,lwr_k=1000:410.8544'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_8'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:402.3654,lwr_k=20:319.7048,lwr_k=50:1180.9316,lwr_k=100:560.9915,lwr_k=200:373.5535,lwr_k=500:380.0414,lwr_k=1000:387.7888'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:432.5056,lwr_k=20:2347.4479,lwr_k=50:61701.3938,lwr_k=100:436.0497,lwr_k=200:426.4041,lwr_k=500:423.0309,lwr_k=1000:423.7373'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:427.2352,lwr_k=20:334.0766,lwr_k=50:384.6509,lwr_k=100:405.6074,lwr_k=200:415.664,lwr_k=500:420.0588,lwr_k=1000:422.2384'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:395.7438,lwr_k=20:532.6614,lwr_k=50:452.1164,lwr_k=100:411.2703,lwr_k=200:410.671,lwr_k=500:396.7453,lwr_k=1000:396.6393'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:424.9773,lwr_k=20:338.4313,lwr_k=50:358.6319,lwr_k=100:363.8154,lwr_k=200:364.8743,lwr_k=500:368.6115,lwr_k=1000:375.9818'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:417.7869,lwr_k=20:384.0913,lwr_k=50:379.5272,lwr_k=100:379.6268,lwr_k=200:378.5452,lwr_k=500:376.3339,lwr_k=1000:380.427'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:416.8499,lwr_k=20:307.2056,lwr_k=50:367.9456,lwr_k=100:434.9408,lwr_k=200:397.0498,lwr_k=500:400.4933,lwr_k=1000:403.2865'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:412.0857,lwr_k=20:489.3086,lwr_k=50:419.3307,lwr_k=100:433.5215,lwr_k=200:397.2603,lwr_k=500:397.2952,lwr_k=1000:398.0764'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:414.2527,lwr_k=20:342.5319,lwr_k=50:357.6978,lwr_k=100:364.3337,lwr_k=200:364.6909,lwr_k=500:367.6887,lwr_k=1000:375.1417'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:1083.6015,lwr_k=20:397.8618,lwr_k=50:392.0038,lwr_k=100:391.7129,lwr_k=200:391.3082,lwr_k=500:386.0273,lwr_k=1000:392.7966'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:421.5158,lwr_k=20:340.695,lwr_k=50:354.8845,lwr_k=100:361.884,lwr_k=200:363.9436,lwr_k=500:365.566,lwr_k=1000:371.528'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:412.1582,lwr_k=20:382.5614,lwr_k=50:380.4011,lwr_k=100:380.0747,lwr_k=200:377.5161,lwr_k=500:375.2219,lwr_k=1000:379.3758'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_9'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:127.8675,lwr_k=20:0.7999,lwr_k=50:19.7998,lwr_k=100:60.9904,lwr_k=200:87.3612,lwr_k=500:105.4173,lwr_k=1000:115.5499'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:125.6288,lwr_k=20:302.2082,lwr_k=50:322.8449,lwr_k=100:186.2018,lwr_k=200:145.3753,lwr_k=500:128.7426,lwr_k=1000:126.7563'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.0314,lwr_k=20:2.585,lwr_k=50:26.8332,lwr_k=100:64.5173,lwr_k=200:88.0961,lwr_k=500:107.6029,lwr_k=1000:117.2971'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:145.5423,lwr_k=20:330.159,lwr_k=50:320.0197,lwr_k=100:190.581,lwr_k=200:155.008,lwr_k=500:136.7105,lwr_k=1000:135.9093'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:131.601,lwr_k=20:0.128,lwr_k=50:12.7226,lwr_k=100:58.6813,lwr_k=200:87.5617,lwr_k=500:104.2952,lwr_k=1000:111.1679'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:135.2096,lwr_k=20:372.5605,lwr_k=50:533.6758,lwr_k=100:274.4749,lwr_k=200:150.107,lwr_k=500:139.9076,lwr_k=1000:134.4024'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:136.8696,lwr_k=20:0.6327,lwr_k=50:17.3229,lwr_k=100:56.2617,lwr_k=200:83.8634,lwr_k=500:102.9358,lwr_k=1000:112.9541'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:138.6348,lwr_k=20:361.5174,lwr_k=50:368.3682,lwr_k=100:193.4067,lwr_k=200:145.1426,lwr_k=500:129.4747,lwr_k=1000:125.2783'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:129.5709,lwr_k=20:0.9183,lwr_k=50:21.2392,lwr_k=100:60.8513,lwr_k=200:88.052,lwr_k=500:107.6108,lwr_k=1000:116.6082'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:190.6041,lwr_k=20:394.5534,lwr_k=50:4036.9188,lwr_k=100:354.5172,lwr_k=200:227.2989,lwr_k=500:231.5699,lwr_k=1000:189.7148'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:131.0622,lwr_k=20:0.1631,lwr_k=50:11.6593,lwr_k=100:55.2166,lwr_k=200:82.3865,lwr_k=500:101.6416,lwr_k=1000:111.0806'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:133.9361,lwr_k=20:306.8488,lwr_k=50:501.4295,lwr_k=100:199.4931,lwr_k=200:152.8673,lwr_k=500:129.427,lwr_k=1000:125.4995'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_10'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:150.4429,lwr_k=20:77.6462,lwr_k=50:109.1039,lwr_k=100:120.9603,lwr_k=200:130.112,lwr_k=500:136.7569,lwr_k=1000:140.4633'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:151.787,lwr_k=20:209.3419,lwr_k=50:160.7051,lwr_k=100:148.2137,lwr_k=200:146.7944,lwr_k=500:145.3718,lwr_k=1000:147.8919'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:148.2843,lwr_k=20:76.0578,lwr_k=50:104.8492,lwr_k=100:115.2551,lwr_k=200:121.6873,lwr_k=500:128.1948,lwr_k=1000:132.6958'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.3173,lwr_k=20:220.5123,lwr_k=50:150.9073,lwr_k=100:139.7523,lwr_k=200:135.5311,lwr_k=500:135.9081,lwr_k=1000:137.8713'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:170.6636,lwr_k=20:77.6849,lwr_k=50:110.3242,lwr_k=100:121.8114,lwr_k=200:128.7934,lwr_k=500:134.3839,lwr_k=1000:138.4259'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:161.0018,lwr_k=20:204.8993,lwr_k=50:155.0545,lwr_k=100:150.1794,lwr_k=200:146.5741,lwr_k=500:146.5396,lwr_k=1000:144.3003'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:184.7637,lwr_k=20:79.5229,lwr_k=50:105.9406,lwr_k=100:119.4083,lwr_k=200:128.1988,lwr_k=500:134.3265,lwr_k=1000:140.0001'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:164.0138,lwr_k=20:389.567,lwr_k=50:219.133,lwr_k=100:136.8366,lwr_k=200:133.8211,lwr_k=500:133.6476,lwr_k=1000:135.8984'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.3654,lwr_k=20:77.3553,lwr_k=50:105.6546,lwr_k=100:116.1663,lwr_k=200:122.1325,lwr_k=500:128.74,lwr_k=1000:131.7005'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:563.4225,lwr_k=20:796.8346,lwr_k=50:548.195,lwr_k=100:698.0781,lwr_k=200:579.2614,lwr_k=500:635.6055,lwr_k=1000:631.1339'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:144.297,lwr_k=20:77.6924,lwr_k=50:104.2504,lwr_k=100:114.8431,lwr_k=200:120.9402,lwr_k=500:126.15,lwr_k=1000:130.3354'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:148.6903,lwr_k=20:191.3345,lwr_k=50:169.0305,lwr_k=100:145.8224,lwr_k=200:141.4945,lwr_k=500:140.5584,lwr_k=1000:139.2374'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_11'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:134.3718,lwr_k=20:31.1716,lwr_k=50:62.2653,lwr_k=100:84.5099,lwr_k=200:103.1384,lwr_k=500:116.6267,lwr_k=1000:124.8155'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:135.5367,lwr_k=20:218.031,lwr_k=50:196.9447,lwr_k=100:164.9232,lwr_k=200:150.8122,lwr_k=500:141.8347,lwr_k=1000:137.3689'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:146.2654,lwr_k=20:73.9818,lwr_k=50:95.9202,lwr_k=100:106.6136,lwr_k=200:115.7026,lwr_k=500:124.8232,lwr_k=1000:130.1525'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:153.5128,lwr_k=20:191.6097,lwr_k=50:170.4828,lwr_k=100:162.7019,lwr_k=200:158.3471,lwr_k=500:149.4045,lwr_k=1000:150.0588'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:141.546,lwr_k=20:5.4322,lwr_k=50:35.2776,lwr_k=100:71.4237,lwr_k=200:95.3023,lwr_k=500:113.5535,lwr_k=1000:124.6371'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:148.9152,lwr_k=20:371.0576,lwr_k=50:272.1926,lwr_k=100:201.7754,lwr_k=200:165.3082,lwr_k=500:148.2728,lwr_k=1000:142.7283'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.3495,lwr_k=20:65.9424,lwr_k=50:89.6026,lwr_k=100:103.3231,lwr_k=200:113.4647,lwr_k=500:122.2267,lwr_k=1000:126.9884'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:137.7977,lwr_k=20:195.6078,lwr_k=50:173.0548,lwr_k=100:173.3524,lwr_k=200:153.018,lwr_k=500:146.7963,lwr_k=1000:139.2468'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:140.0784,lwr_k=20:42.611,lwr_k=50:70.7894,lwr_k=100:91.1656,lwr_k=200:107.3403,lwr_k=500:120.5175,lwr_k=1000:129.1031'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:359.836,lwr_k=20:557.2202,lwr_k=50:229.1422,lwr_k=100:160.3135,lwr_k=200:148.492,lwr_k=500:144.0498,lwr_k=1000:234.617'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:138.1029,lwr_k=20:1.1878,lwr_k=50:22.4153,lwr_k=100:64.0083,lwr_k=200:90.9047,lwr_k=500:111.5739,lwr_k=1000:120.4177'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:139.2155,lwr_k=20:305.8249,lwr_k=50:395.5989,lwr_k=100:213.4003,lwr_k=200:158.3855,lwr_k=500:137.8494,lwr_k=1000:133.0526'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_12'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.6222,lwr_k=20:108.1939,lwr_k=50:121.0424,lwr_k=100:126.9906,lwr_k=200:129.9406,lwr_k=500:131.3464,lwr_k=1000:132.4301'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:136.5712,lwr_k=20:164.8241,lwr_k=50:142.9854,lwr_k=100:139.5913,lwr_k=200:136.7556,lwr_k=500:134.6769,lwr_k=1000:134.7037'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.9638,lwr_k=20:109.4228,lwr_k=50:123.307,lwr_k=100:127.3854,lwr_k=200:130.7249,lwr_k=500:134.0762,lwr_k=1000:135.3725'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:142.0857,lwr_k=20:167.8887,lwr_k=50:144.8331,lwr_k=100:139.4348,lwr_k=200:136.8869,lwr_k=500:137.6683,lwr_k=1000:138.9921'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:133.69,lwr_k=20:109.9008,lwr_k=50:120.7872,lwr_k=100:125.6825,lwr_k=200:127.4934,lwr_k=500:129.3778,lwr_k=1000:130.7665'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:142.1206,lwr_k=20:164.6496,lwr_k=50:146.514,lwr_k=100:143.652,lwr_k=200:140.7561,lwr_k=500:140.1142,lwr_k=1000:140.183'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:139.5025,lwr_k=20:111.2223,lwr_k=50:122.1011,lwr_k=100:127.12,lwr_k=200:130.2974,lwr_k=500:133.0584,lwr_k=1000:134.3099'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:138.1315,lwr_k=20:155.2802,lwr_k=50:139.3446,lwr_k=100:135.1686,lwr_k=200:132.8506,lwr_k=500:133.4498,lwr_k=1000:133.9659'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.7792,lwr_k=20:112.7771,lwr_k=50:124.8987,lwr_k=100:128.0195,lwr_k=200:130.4033,lwr_k=500:133.2205,lwr_k=1000:134.5902'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:1387.6324,lwr_k=20:2687.5162,lwr_k=50:876.7855,lwr_k=100:1566.4697,lwr_k=200:907.7309,lwr_k=500:1102.9012,lwr_k=1000:942.7927'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:139.7401,lwr_k=20:110.3716,lwr_k=50:121.7383,lwr_k=100:126.386,lwr_k=200:128.9826,lwr_k=500:131.1245,lwr_k=1000:132.6325'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.4621,lwr_k=20:159.629,lwr_k=50:151.8121,lwr_k=100:138.7327,lwr_k=200:139.2508,lwr_k=500:139.7994,lwr_k=1000:139.3595'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_13'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.4131,lwr_k=20:84.0654,lwr_k=50:107.3822,lwr_k=100:115.2947,lwr_k=200:120.8245,lwr_k=500:126.8121,lwr_k=1000:128.3149'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:132.9041,lwr_k=20:187.4182,lwr_k=50:154.506,lwr_k=100:130.1172,lwr_k=200:127.008,lwr_k=500:126.4831,lwr_k=1000:127.8135'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:164.8276,lwr_k=20:92.5062,lwr_k=50:109.3866,lwr_k=100:116.6423,lwr_k=200:122.3209,lwr_k=500:127.6628,lwr_k=1000:130.3052'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:150.7227,lwr_k=20:162.8108,lwr_k=50:151.9733,lwr_k=100:143.7743,lwr_k=200:136.5709,lwr_k=500:136.4658,lwr_k=1000:136.131'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:169.027,lwr_k=20:87.3883,lwr_k=50:105.3701,lwr_k=100:114.2377,lwr_k=200:119.1628,lwr_k=500:123.246,lwr_k=1000:125.9996'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:163.3797,lwr_k=20:155.4664,lwr_k=50:145.1263,lwr_k=100:139.3066,lwr_k=200:135.1083,lwr_k=500:132.4277,lwr_k=1000:135.2773'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:140.7079,lwr_k=20:87.1648,lwr_k=50:105.6053,lwr_k=100:114.574,lwr_k=200:120.5786,lwr_k=500:124.7185,lwr_k=1000:127.6727'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:142.6538,lwr_k=20:151.2323,lwr_k=50:135.5171,lwr_k=100:130.5537,lwr_k=200:127.6252,lwr_k=500:128.093,lwr_k=1000:127.9545'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:141.8353,lwr_k=20:86.9237,lwr_k=50:106.331,lwr_k=100:114.961,lwr_k=200:119.3353,lwr_k=500:124.5656,lwr_k=1000:127.8919'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:775.9369,lwr_k=20:310.1453,lwr_k=50:232.9232,lwr_k=100:129.6743,lwr_k=200:202.8297,lwr_k=500:176.1541,lwr_k=1000:466.8308'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:154.445,lwr_k=20:79.63,lwr_k=50:102.1119,lwr_k=100:111.4715,lwr_k=200:116.7469,lwr_k=500:121.2054,lwr_k=1000:125.171'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:143.693,lwr_k=20:168.8282,lwr_k=50:149.0256,lwr_k=100:139.7414,lwr_k=200:134.334,lwr_k=500:131.8324,lwr_k=1000:133.1397'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_14'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:475.3153,lwr_k=20:476.266,lwr_k=50:478.4367,lwr_k=100:484.6798,lwr_k=200:476.1122,lwr_k=500:476.8619,lwr_k=1000:475.3224'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:502.902,lwr_k=20:502.0021,lwr_k=50:509.3768,lwr_k=100:518.0748,lwr_k=200:505.3931,lwr_k=500:506.8091,lwr_k=1000:503.0688'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:492.2828,lwr_k=20:492.6794,lwr_k=50:493.0456,lwr_k=100:492.3113,lwr_k=200:492.488,lwr_k=500:492.7045,lwr_k=1000:492.3409'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:455.1291,lwr_k=20:455.0952,lwr_k=50:455.2948,lwr_k=100:455.0422,lwr_k=200:455.0246,lwr_k=500:455.1069,lwr_k=1000:455.3521'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:495.6637,lwr_k=20:507.1876,lwr_k=50:500.5743,lwr_k=100:496.7399,lwr_k=200:496.8396,lwr_k=500:496.9601,lwr_k=1000:495.704'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:492.4333,lwr_k=20:498.1193,lwr_k=50:493.533,lwr_k=100:491.7255,lwr_k=200:491.7444,lwr_k=500:491.7717,lwr_k=1000:492.1285'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:487.7726,lwr_k=20:494.2739,lwr_k=50:487.8364,lwr_k=100:487.8469,lwr_k=200:487.8976,lwr_k=500:488.3433,lwr_k=1000:487.7771'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:478.8737,lwr_k=20:486.0777,lwr_k=50:479.0071,lwr_k=100:479.0232,lwr_k=200:478.9013,lwr_k=500:479.2361,lwr_k=1000:478.8966'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:483.1622,lwr_k=20:483.2334,lwr_k=50:483.964,lwr_k=100:483.2327,lwr_k=200:484.322,lwr_k=500:483.559,lwr_k=1000:483.2056'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:506.1586,lwr_k=20:506.0283,lwr_k=50:507.6364,lwr_k=100:506.0286,lwr_k=200:508.1315,lwr_k=500:507.0309,lwr_k=1000:506.0447'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:488.9731,lwr_k=20:504.3084,lwr_k=50:490.9649,lwr_k=100:490.0618,lwr_k=200:488.992,lwr_k=500:489.2524,lwr_k=1000:489.0042'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:480.6363,lwr_k=20:498.3014,lwr_k=50:483.4678,lwr_k=100:482.3458,lwr_k=200:480.737,lwr_k=500:480.6012,lwr_k=1000:480.7724'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_15'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:146.8912,lwr_k=20:28.6976,lwr_k=50:71.0698,lwr_k=100:94.8877,lwr_k=200:110.2602,lwr_k=500:125.0314,lwr_k=1000:131.59'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:146.8975,lwr_k=20:264.311,lwr_k=50:192.6019,lwr_k=100:158.4693,lwr_k=200:145.261,lwr_k=500:141.5341,lwr_k=1000:139.881'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.1992,lwr_k=20:9.9783,lwr_k=50:54.4735,lwr_k=100:79.4959,lwr_k=200:94.9052,lwr_k=500:106.9875,lwr_k=1000:114.0094'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.1132,lwr_k=20:421.2415,lwr_k=50:193.7735,lwr_k=100:149.9598,lwr_k=200:135.1813,lwr_k=500:131.4992,lwr_k=1000:130.9377'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:146.5211,lwr_k=20:20.772,lwr_k=50:59.6258,lwr_k=100:84.347,lwr_k=200:98.8836,lwr_k=500:111.5937,lwr_k=1000:118.6265'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:153.0104,lwr_k=20:483.1176,lwr_k=50:289.4956,lwr_k=100:176.8633,lwr_k=200:152.1568,lwr_k=500:147.3526,lwr_k=1000:136.8544'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:146.831,lwr_k=20:15.3878,lwr_k=50:59.0743,lwr_k=100:83.3059,lwr_k=200:99.2587,lwr_k=500:112.0554,lwr_k=1000:118.0155'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:143.051,lwr_k=20:312.9967,lwr_k=50:171.6725,lwr_k=100:145.1886,lwr_k=200:129.5533,lwr_k=500:124.4832,lwr_k=1000:125.2211'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:129.8564,lwr_k=20:15.8021,lwr_k=50:58.5373,lwr_k=100:84.5809,lwr_k=200:100.9593,lwr_k=500:113.8682,lwr_k=1000:119.4083'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:523.5141,lwr_k=20:736.5689,lwr_k=50:1311.6638,lwr_k=100:571.783,lwr_k=200:595.9305,lwr_k=500:584.9287,lwr_k=1000:399.2596'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:144.5938,lwr_k=20:9.7335,lwr_k=50:53.3052,lwr_k=100:80.5678,lwr_k=200:96.2311,lwr_k=500:107.3591,lwr_k=1000:113.8209'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:143.2378,lwr_k=20:390.9003,lwr_k=50:203.4151,lwr_k=100:160.4041,lwr_k=200:137.0705,lwr_k=500:128.4634,lwr_k=1000:125.8035'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_16'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:144.3333,lwr_k=20:125.1455,lwr_k=50:130.8844,lwr_k=100:133.8434,lwr_k=200:135.6394,lwr_k=500:137.2471,lwr_k=1000:138.1465'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:139.9308,lwr_k=20:145.0507,lwr_k=50:138.5329,lwr_k=100:137.5975,lwr_k=200:136.1117,lwr_k=500:135.8981,lwr_k=1000:136.2196'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:160.4299,lwr_k=20:139.6068,lwr_k=50:146.7202,lwr_k=100:150.0777,lwr_k=200:152.3523,lwr_k=500:153.9788,lwr_k=1000:156.2859'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:150.7333,lwr_k=20:152.751,lwr_k=50:150.0163,lwr_k=100:148.3141,lwr_k=200:147.5044,lwr_k=500:147.6475,lwr_k=1000:147.7639'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:156.2049,lwr_k=20:137.3867,lwr_k=50:142.0359,lwr_k=100:144.5074,lwr_k=200:147.7593,lwr_k=500:150.5681,lwr_k=1000:153.0688'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:147.534,lwr_k=20:152.349,lwr_k=50:149.6204,lwr_k=100:148.981,lwr_k=200:147.9441,lwr_k=500:146.8499,lwr_k=1000:146.5038'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.7436,lwr_k=20:118.8576,lwr_k=50:127.9073,lwr_k=100:132.544,lwr_k=200:135.8291,lwr_k=500:137.8721,lwr_k=1000:139.2321'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:139.0113,lwr_k=20:148.0112,lwr_k=50:139.9898,lwr_k=100:138.8334,lwr_k=200:137.2118,lwr_k=500:136.8012,lwr_k=1000:137.0108'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:149.1823,lwr_k=20:127.9901,lwr_k=50:134.6569,lwr_k=100:137.9202,lwr_k=200:140.1573,lwr_k=500:142.3015,lwr_k=1000:144.4555'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:218.8495,lwr_k=20:180.2587,lwr_k=50:177.1962,lwr_k=100:155.4238,lwr_k=200:171.8905,lwr_k=500:197.5763,lwr_k=1000:208.8388'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:139.3054,lwr_k=20:126.2199,lwr_k=50:131.2429,lwr_k=100:133.392,lwr_k=200:134.3448,lwr_k=500:135.3969,lwr_k=1000:136.3661'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.6512,lwr_k=20:148.096,lwr_k=50:142.9815,lwr_k=100:141.4223,lwr_k=200:141.4129,lwr_k=500:141.9123,lwr_k=1000:142.1599'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_17'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:140.0663,lwr_k=20:41.8415,lwr_k=50:74.9464,lwr_k=100:92.7014,lwr_k=200:105.6689,lwr_k=500:118.8427,lwr_k=1000:125.5676'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:138.9117,lwr_k=20:266.7071,lwr_k=50:201.7222,lwr_k=100:169.5921,lwr_k=200:138.8648,lwr_k=500:131.225,lwr_k=1000:132.1107'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:144.5556,lwr_k=20:95.4474,lwr_k=50:112.8291,lwr_k=100:121.8057,lwr_k=200:127.0872,lwr_k=500:131.2558,lwr_k=1000:134.2428'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:149.8791,lwr_k=20:183.9335,lwr_k=50:164.8931,lwr_k=100:159.3255,lwr_k=200:152.1461,lwr_k=500:145.2199,lwr_k=1000:143.5251'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.9161,lwr_k=20:88.5725,lwr_k=50:107.4124,lwr_k=100:114.5611,lwr_k=200:119.5289,lwr_k=500:125.1803,lwr_k=1000:127.6279'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:140.8242,lwr_k=20:161.7222,lwr_k=50:150.1954,lwr_k=100:139.4022,lwr_k=200:135.1174,lwr_k=500:134.5965,lwr_k=1000:135.2495'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:136.7533,lwr_k=20:50.2501,lwr_k=50:82.3796,lwr_k=100:97.59,lwr_k=200:108.8315,lwr_k=500:118.2195,lwr_k=1000:124.0464'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:141.12,lwr_k=20:341.4146,lwr_k=50:214.8016,lwr_k=100:163.6068,lwr_k=200:153.1287,lwr_k=500:139.7524,lwr_k=1000:135.8094'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:138.2959,lwr_k=20:40.9115,lwr_k=50:74.6997,lwr_k=100:93.7553,lwr_k=200:107.8405,lwr_k=500:119.5848,lwr_k=1000:126.1621'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:346.965,lwr_k=20:246.3962,lwr_k=50:332.0987,lwr_k=100:471.7562,lwr_k=200:156.0372,lwr_k=500:204.0543,lwr_k=1000:293.5303'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:139.5774,lwr_k=20:56.8611,lwr_k=50:85.0247,lwr_k=100:98.5735,lwr_k=200:108.8583,lwr_k=500:118.0195,lwr_k=1000:122.6019'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:146.6146,lwr_k=20:216.4069,lwr_k=50:171.2067,lwr_k=100:150.557,lwr_k=200:145.3381,lwr_k=500:137.9149,lwr_k=1000:136.9257'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_18'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:151.7851,lwr_k=20:83.8759,lwr_k=50:103.4761,lwr_k=100:112.6222,lwr_k=200:118.8347,lwr_k=500:124.9445,lwr_k=1000:128.2602'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:169.9762,lwr_k=20:177.0409,lwr_k=50:150.2467,lwr_k=100:143.3629,lwr_k=200:133.9791,lwr_k=500:132.2171,lwr_k=1000:132.6076'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.8014,lwr_k=20:85.1848,lwr_k=50:98.2733,lwr_k=100:107.2967,lwr_k=200:116.2015,lwr_k=500:122.5574,lwr_k=1000:126.6796'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:751.0762,lwr_k=20:1213.9019,lwr_k=50:592.2071,lwr_k=100:791.6849,lwr_k=200:463.4151,lwr_k=500:713.2096,lwr_k=1000:176.4135'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:130.6309,lwr_k=20:87.5704,lwr_k=50:100.2833,lwr_k=100:108.1889,lwr_k=200:114.4342,lwr_k=500:119.6976,lwr_k=1000:122.6361'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:480.6634,lwr_k=20:191.8777,lwr_k=50:163.6852,lwr_k=100:157.7797,lwr_k=200:152.1717,lwr_k=500:165.0789,lwr_k=1000:157.6226'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:131.4875,lwr_k=20:78.8988,lwr_k=50:97.363,lwr_k=100:108.1485,lwr_k=200:115.3407,lwr_k=500:121.8379,lwr_k=1000:125.1958'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:201192.3929,lwr_k=20:256.3824,lwr_k=50:225.7924,lwr_k=100:238.1511,lwr_k=200:729.9212,lwr_k=500:264.1965,lwr_k=1000:1424.7571'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:152.1985,lwr_k=20:98.2014,lwr_k=50:119.3382,lwr_k=100:128.7289,lwr_k=200:134.9603,lwr_k=500:141.5905,lwr_k=1000:145.3005'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:114024.1739,lwr_k=20:188.482,lwr_k=50:169.4851,lwr_k=100:3538.0204,lwr_k=200:5321.154,lwr_k=500:3366.5632,lwr_k=1000:549.3881'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:137.8619,lwr_k=20:91.0478,lwr_k=50:104.8071,lwr_k=100:112.2824,lwr_k=200:118.5756,lwr_k=500:124.7312,lwr_k=1000:127.6156'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:142.2858,lwr_k=20:172.6576,lwr_k=50:146.2672,lwr_k=100:143.1088,lwr_k=200:140.556,lwr_k=500:136.1675,lwr_k=1000:135.7059'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_19'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:155.9742,lwr_k=20:141.3653,lwr_k=50:146.9866,lwr_k=100:148.115,lwr_k=200:149.116,lwr_k=500:150.031,lwr_k=1000:151.2979'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:160.9793,lwr_k=20:165.0327,lwr_k=50:159.2264,lwr_k=100:156.7185,lwr_k=200:155.5056,lwr_k=500:155.3544,lwr_k=1000:155.7473'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:144.1061,lwr_k=20:133.8404,lwr_k=50:136.241,lwr_k=100:137.2704,lwr_k=200:138.0665,lwr_k=500:139.7896,lwr_k=1000:140.6469'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.1875,lwr_k=20:146.2915,lwr_k=50:142.399,lwr_k=100:141.2072,lwr_k=200:140.9291,lwr_k=500:140.4196,lwr_k=1000:140.6822'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:140.5298,lwr_k=20:131.0139,lwr_k=50:136.3375,lwr_k=100:136.9486,lwr_k=200:137.5738,lwr_k=500:137.7856,lwr_k=1000:137.9269'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.557,lwr_k=20:149.982,lwr_k=50:145.614,lwr_k=100:144.4103,lwr_k=200:143.3322,lwr_k=500:143.0133,lwr_k=1000:142.9693'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:157.6257,lwr_k=20:151.5179,lwr_k=50:153.4666,lwr_k=100:154.9462,lwr_k=200:155.4633,lwr_k=500:155.347,lwr_k=1000:155.7159'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:153.187,lwr_k=20:157.4089,lwr_k=50:153.8383,lwr_k=100:151.0649,lwr_k=200:150.1464,lwr_k=500:147.5977,lwr_k=1000:153.5606'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:148.2183,lwr_k=20:139.5312,lwr_k=50:142.6583,lwr_k=100:143.8783,lwr_k=200:143.7715,lwr_k=500:144.5952,lwr_k=1000:144.8481'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:1003.2389,lwr_k=20:209.867,lwr_k=50:186.3569,lwr_k=100:190.6976,lwr_k=200:187.6436,lwr_k=500:458.2557,lwr_k=1000:506.8112'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:137.1862,lwr_k=20:129.7234,lwr_k=50:132.6786,lwr_k=100:133.4673,lwr_k=200:133.8225,lwr_k=500:134.0836,lwr_k=1000:134.307'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:150.4836,lwr_k=20:149.5917,lwr_k=50:147.5306,lwr_k=100:145.331,lwr_k=200:144.7185,lwr_k=500:144.3834,lwr_k=1000:144.2695'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_20'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:134.5734,lwr_k=20:89.4608,lwr_k=50:110.2605,lwr_k=100:116.7561,lwr_k=200:121.4073,lwr_k=500:125.1877,lwr_k=1000:127.2234'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:130.5968,lwr_k=20:160.1102,lwr_k=50:139.5053,lwr_k=100:131.1179,lwr_k=200:127.9875,lwr_k=500:127.0123,lwr_k=1000:127.981'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:161.7139,lwr_k=20:87.9312,lwr_k=50:109.6611,lwr_k=100:117.794,lwr_k=200:121.7025,lwr_k=500:125.3769,lwr_k=1000:127.8987'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:156.8541,lwr_k=20:174.1594,lwr_k=50:148.9806,lwr_k=100:138.6778,lwr_k=200:134.4256,lwr_k=500:132.8383,lwr_k=1000:132.751'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:173.0109,lwr_k=20:88.4147,lwr_k=50:107.8125,lwr_k=100:115.3783,lwr_k=200:120.7041,lwr_k=500:124.9303,lwr_k=1000:127.1363'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:161.679,lwr_k=20:174.9398,lwr_k=50:155.888,lwr_k=100:147.6429,lwr_k=200:138.3115,lwr_k=500:135.1153,lwr_k=1000:134.8394'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:196.3664,lwr_k=20:100.1377,lwr_k=50:121.1688,lwr_k=100:130.0494,lwr_k=200:133.8457,lwr_k=500:138.0188,lwr_k=1000:139.8828'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:179.432,lwr_k=20:173.6826,lwr_k=50:155.2961,lwr_k=100:145.5532,lwr_k=200:143.1265,lwr_k=500:141.0443,lwr_k=1000:141.4985'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:133.9791,lwr_k=20:90.6345,lwr_k=50:112.0539,lwr_k=100:119.8072,lwr_k=200:124.5175,lwr_k=500:126.9517,lwr_k=1000:129.4927'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:509.2974,lwr_k=20:179.1034,lwr_k=50:150.9809,lwr_k=100:315.4127,lwr_k=200:269.9561,lwr_k=500:286.481,lwr_k=1000:394.703'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:147.5297,lwr_k=20:88.5557,lwr_k=50:107.0476,lwr_k=100:114.6887,lwr_k=200:119.3447,lwr_k=500:122.6883,lwr_k=1000:124.1194'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:143.9791,lwr_k=20:164.4811,lwr_k=50:142.0059,lwr_k=100:133.7861,lwr_k=200:132.0705,lwr_k=500:131.1934,lwr_k=1000:129.6284'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_21'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:158.7657,lwr_k=20:147.4217,lwr_k=50:152.2965,lwr_k=100:153.9346,lwr_k=200:154.8143,lwr_k=500:156.2986,lwr_k=1000:157.3696'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:156.386,lwr_k=20:162.7997,lwr_k=50:158.846,lwr_k=100:157.6173,lwr_k=200:156.1174,lwr_k=500:156.1799,lwr_k=1000:156.2977'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:195.3817,lwr_k=20:142.9804,lwr_k=50:143.1412,lwr_k=100:143.9013,lwr_k=200:145.4001,lwr_k=500:148.677,lwr_k=1000:157.4163'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:151.387,lwr_k=20:154.7948,lwr_k=50:149.1782,lwr_k=100:148.428,lwr_k=200:147.8365,lwr_k=500:147.3428,lwr_k=1000:146.8679'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:173.8715,lwr_k=20:137.5956,lwr_k=50:140.7125,lwr_k=100:141.3263,lwr_k=200:143.3273,lwr_k=500:149.4479,lwr_k=1000:156.8472'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:147.0147,lwr_k=20:150.6047,lwr_k=50:146.3256,lwr_k=100:145.5896,lwr_k=200:144.9322,lwr_k=500:143.8109,lwr_k=1000:144.0601'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:228.9196,lwr_k=20:145.5399,lwr_k=50:146.7129,lwr_k=100:147.3507,lwr_k=200:148.2048,lwr_k=500:152.0301,lwr_k=1000:158.8012'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:159.7669,lwr_k=20:149.0379,lwr_k=50:142.5978,lwr_k=100:142.1477,lwr_k=200:141.3671,lwr_k=500:142.0074,lwr_k=1000:141.5861'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:156.5481,lwr_k=20:145.2123,lwr_k=50:150.6037,lwr_k=100:151.017,lwr_k=200:153.2999,lwr_k=500:154.1936,lwr_k=1000:155.1595'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:241.4739,lwr_k=20:184.1455,lwr_k=50:157.462,lwr_k=100:164.1046,lwr_k=200:194.5643,lwr_k=500:221.2664,lwr_k=1000:236.2519'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:243.3683,lwr_k=20:141.404,lwr_k=50:144.015,lwr_k=100:144.6496,lwr_k=200:145.631,lwr_k=500:146.8453,lwr_k=1000:150.8691'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:169.2133,lwr_k=20:154.1017,lwr_k=50:148.0777,lwr_k=100:146.2718,lwr_k=200:146.5491,lwr_k=500:146.7241,lwr_k=1000:146.7322'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_22'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:139.6188,lwr_k=20:91.0831,lwr_k=50:111.3342,lwr_k=100:119.9657,lwr_k=200:125.05,lwr_k=500:128.5683,lwr_k=1000:130.72'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:138.536,lwr_k=20:161.8784,lwr_k=50:136.3692,lwr_k=100:133.3652,lwr_k=200:132.664,lwr_k=500:132.6723,lwr_k=1000:132.8229'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:170.8536,lwr_k=20:150.5815,lwr_k=50:156.5663,lwr_k=100:156.4099,lwr_k=200:156.5324,lwr_k=500:157.0517,lwr_k=1000:159.3408'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:181.9575,lwr_k=20:178.5618,lwr_k=50:176.1509,lwr_k=100:172.4207,lwr_k=200:172.5178,lwr_k=500:171.6358,lwr_k=1000:172.2783'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:495.6627,lwr_k=20:499.6988,lwr_k=50:495.2645,lwr_k=100:495.2729,lwr_k=200:495.5509,lwr_k=500:496.1067,lwr_k=1000:495.3099'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:492.4344,lwr_k=20:500.4833,lwr_k=50:492.4058,lwr_k=100:492.5448,lwr_k=200:491.7999,lwr_k=500:491.6974,lwr_k=1000:492.1309'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:166.6628,lwr_k=20:87.8962,lwr_k=50:113.4642,lwr_k=100:121.5431,lwr_k=200:127.3761,lwr_k=500:130.2404,lwr_k=1000:131.587'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:159.1424,lwr_k=20:171.6465,lwr_k=50:143.6526,lwr_k=100:132.7793,lwr_k=200:131.1894,lwr_k=500:130.5192,lwr_k=1000:130.6108'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:146.1987,lwr_k=20:93.537,lwr_k=50:116.7164,lwr_k=100:126.0145,lwr_k=200:129.6686,lwr_k=500:134.3502,lwr_k=1000:137.2566'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:503.9592,lwr_k=20:306.6919,lwr_k=50:181.1074,lwr_k=100:240.1203,lwr_k=200:363.2374,lwr_k=500:446.3219,lwr_k=1000:477.7544'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:488.9731,lwr_k=20:504.3084,lwr_k=50:490.9649,lwr_k=100:490.0618,lwr_k=200:488.992,lwr_k=500:489.2524,lwr_k=1000:489.0042'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:480.6363,lwr_k=20:498.3014,lwr_k=50:483.4678,lwr_k=100:482.3458,lwr_k=200:480.737,lwr_k=500:480.6012,lwr_k=1000:480.7724'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_23'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.7195,lwr_k=20:21.8484,lwr_k=50:75.4714,lwr_k=100:100.761,lwr_k=200:114.7436,lwr_k=500:125.4067,lwr_k=1000:131.4267'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:146.0615,lwr_k=20:332.2823,lwr_k=50:186.1031,lwr_k=100:159.024,lwr_k=200:146.3958,lwr_k=500:141.7763,lwr_k=1000:140.3323'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:151.6182,lwr_k=20:59.9582,lwr_k=50:90.7566,lwr_k=100:106.8556,lwr_k=200:118.1556,lwr_k=500:127.8227,lwr_k=1000:132.354'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:156.9095,lwr_k=20:197.7041,lwr_k=50:161.8042,lwr_k=100:149.8824,lwr_k=200:145.4782,lwr_k=500:143.3706,lwr_k=1000:143.3941'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:146.2442,lwr_k=20:48.3688,lwr_k=50:85.4119,lwr_k=100:104.0886,lwr_k=200:113.9017,lwr_k=500:124.9971,lwr_k=1000:130.1771'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:147.9376,lwr_k=20:227.9849,lwr_k=50:187.7939,lwr_k=100:151.63,lwr_k=200:143.3751,lwr_k=500:141.4099,lwr_k=1000:141.9728'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:145.3486,lwr_k=20:42.4823,lwr_k=50:84.8174,lwr_k=100:106.8435,lwr_k=200:120.0441,lwr_k=500:129.6132,lwr_k=1000:134.7849'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:142.5486,lwr_k=20:251.1238,lwr_k=50:178.5704,lwr_k=100:152.1803,lwr_k=200:141.7945,lwr_k=500:135.0184,lwr_k=1000:135.9051'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:156.952,lwr_k=20:96.507,lwr_k=50:118.1293,lwr_k=100:128.0958,lwr_k=200:132.7744,lwr_k=500:137.7915,lwr_k=1000:141.8682'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:210.5431,lwr_k=20:233.2203,lwr_k=50:189.5932,lwr_k=100:186.7148,lwr_k=200:160.7407,lwr_k=500:172.109,lwr_k=1000:174.7525'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:138.7351,lwr_k=20:63.9209,lwr_k=50:94.7108,lwr_k=100:107.2206,lwr_k=200:116.2124,lwr_k=500:124.3413,lwr_k=1000:128.3487'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:142.4451,lwr_k=20:212.7554,lwr_k=50:162.3861,lwr_k=100:145.8298,lwr_k=200:138.2557,lwr_k=500:135.2257,lwr_k=1000:136.174'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_24'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:163.8369,lwr_k=20:145.4318,lwr_k=50:149.439,lwr_k=100:153.1052,lwr_k=200:155.0582,lwr_k=500:156.7353,lwr_k=1000:157.2725'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:170.3249,lwr_k=20:162.8931,lwr_k=50:158.3597,lwr_k=100:159.3432,lwr_k=200:159.7697,lwr_k=500:160.6982,lwr_k=1000:161.3602'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:168.004,lwr_k=20:148.6377,lwr_k=50:152.3516,lwr_k=100:155.9106,lwr_k=200:158.8821,lwr_k=500:160.5313,lwr_k=1000:161.2502'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:170.0193,lwr_k=20:169.4773,lwr_k=50:165.4783,lwr_k=100:164.4998,lwr_k=200:164.308,lwr_k=500:164.11,lwr_k=1000:164.0243'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:188.0828,lwr_k=20:151.0898,lwr_k=50:156.8632,lwr_k=100:159.651,lwr_k=200:161.3868,lwr_k=500:167.4956,lwr_k=1000:174.9277'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:169.1594,lwr_k=20:173.4011,lwr_k=50:168.4578,lwr_k=100:166.4859,lwr_k=200:165.0933,lwr_k=500:164.9964,lwr_k=1000:165.8322'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:211.9311,lwr_k=20:195.3827,lwr_k=50:200.0818,lwr_k=100:203.3734,lwr_k=200:204.6404,lwr_k=500:205.6743,lwr_k=1000:210.1616'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:200.4495,lwr_k=20:196.1634,lwr_k=50:192.8133,lwr_k=100:192.5305,lwr_k=200:191.9873,lwr_k=500:191.9215,lwr_k=1000:198.5029'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:156.2099,lwr_k=20:140.1814,lwr_k=50:142.9915,lwr_k=100:145.2218,lwr_k=200:145.8933,lwr_k=500:146.0473,lwr_k=1000:149.5512'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:582.2336,lwr_k=20:503.9361,lwr_k=50:751.346,lwr_k=100:708.7342,lwr_k=200:651.2874,lwr_k=500:673.6419,lwr_k=1000:567.7778'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:468.8907,lwr_k=20:457.6761,lwr_k=50:452.2174,lwr_k=100:455.7847,lwr_k=200:457.5191,lwr_k=500:459.7894,lwr_k=1000:462.6673'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:460.7206,lwr_k=20:479.7011,lwr_k=50:467.7604,lwr_k=100:461.2465,lwr_k=200:458.6269,lwr_k=500:457.0278,lwr_k=1000:458.0797'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_25'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:127.0779,lwr_k=20:66.732,lwr_k=50:86.2809,lwr_k=100:98.2643,lwr_k=200:107.178,lwr_k=500:116.4657,lwr_k=1000:120.7051'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:125.8812,lwr_k=20:164.415,lwr_k=50:148.7687,lwr_k=100:140.2682,lwr_k=200:135.0537,lwr_k=500:130.9618,lwr_k=1000:128.7161'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.9232,lwr_k=20:75.4105,lwr_k=50:89.752,lwr_k=100:99.4712,lwr_k=200:107.2838,lwr_k=500:115.0407,lwr_k=1000:117.8173'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:139.7835,lwr_k=20:163.4777,lwr_k=50:161.3219,lwr_k=100:151.2344,lwr_k=200:138.2167,lwr_k=500:127.2696,lwr_k=1000:127.2038'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:140.1992,lwr_k=20:69.4312,lwr_k=50:90.1444,lwr_k=100:101.6363,lwr_k=200:111.1288,lwr_k=500:119.2344,lwr_k=1000:122.3843'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:139.596,lwr_k=20:174.4005,lwr_k=50:161.2723,lwr_k=100:148.8357,lwr_k=200:141.7406,lwr_k=500:137.4976,lwr_k=1000:134.3838'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:146.4101,lwr_k=20:76.2155,lwr_k=50:92.5376,lwr_k=100:103.3808,lwr_k=200:109.8003,lwr_k=500:117.3854,lwr_k=1000:121.2986'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:141.9838,lwr_k=20:144.9821,lwr_k=50:139.3799,lwr_k=100:132.532,lwr_k=200:128.5641,lwr_k=500:124.4933,lwr_k=1000:122.8193'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:132.8329,lwr_k=20:102.2971,lwr_k=50:113.8516,lwr_k=100:119.517,lwr_k=200:124.6921,lwr_k=500:128.3615,lwr_k=1000:130.311'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:1316.3614,lwr_k=20:1590.5623,lwr_k=50:1130.8371,lwr_k=100:1617.4996,lwr_k=200:1589.6933,lwr_k=500:1472.0846,lwr_k=1000:1385.4935'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:130.4972,lwr_k=20:69.2574,lwr_k=50:86.756,lwr_k=100:96.4369,lwr_k=200:103.6008,lwr_k=500:110.0556,lwr_k=1000:113.5377'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:135.6429,lwr_k=20:148.2027,lwr_k=50:143.6765,lwr_k=100:133.3754,lwr_k=200:130.4561,lwr_k=500:127.2006,lwr_k=1000:126.5527'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_26'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:141.6659,lwr_k=20:104.8265,lwr_k=50:119.916,lwr_k=100:126.8157,lwr_k=200:131.0625,lwr_k=500:134.4659,lwr_k=1000:136.4058'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:159.4792,lwr_k=20:162.5393,lwr_k=50:145.2391,lwr_k=100:141.8757,lwr_k=200:140.7203,lwr_k=500:137.3021,lwr_k=1000:137.2161'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:134.8889,lwr_k=20:106.1799,lwr_k=50:118.1876,lwr_k=100:124.0799,lwr_k=200:127.9435,lwr_k=500:131.5275,lwr_k=1000:133.487'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:137.9944,lwr_k=20:148.0606,lwr_k=50:139.9674,lwr_k=100:136.2084,lwr_k=200:134.2468,lwr_k=500:134.8391,lwr_k=1000:135.6049'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:134.7405,lwr_k=20:101.388,lwr_k=50:114.8784,lwr_k=100:121.3091,lwr_k=200:125.3949,lwr_k=500:128.6303,lwr_k=1000:130.9654'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.3094,lwr_k=20:154.6066,lwr_k=50:143.2002,lwr_k=100:138.2398,lwr_k=200:139.2259,lwr_k=500:137.4385,lwr_k=1000:137.0507'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.6421,lwr_k=20:107.5803,lwr_k=50:121.7938,lwr_k=100:130.0527,lwr_k=200:133.6421,lwr_k=500:137.9266,lwr_k=1000:139.9723'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:151.1595,lwr_k=20:160.0306,lwr_k=50:146.349,lwr_k=100:140.965,lwr_k=200:141.7423,lwr_k=500:141.9559,lwr_k=1000:143.4014'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:139.9937,lwr_k=20:107.2163,lwr_k=50:123.4021,lwr_k=100:128.124,lwr_k=200:131.8787,lwr_k=500:133.8511,lwr_k=1000:136.0511'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:147.9937,lwr_k=20:362.4904,lwr_k=50:193.8416,lwr_k=100:201.9229,lwr_k=200:170.5369,lwr_k=500:142.8915,lwr_k=1000:142.8655'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:142.3359,lwr_k=20:113.8065,lwr_k=50:125.309,lwr_k=100:130.8506,lwr_k=200:133.696,lwr_k=500:136.7413,lwr_k=1000:138.3365'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:147.5678,lwr_k=20:159.2806,lwr_k=50:153.7851,lwr_k=100:152.3485,lwr_k=200:150.0951,lwr_k=500:146.9936,lwr_k=1000:145.9939'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_27'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:141.2027,lwr_k=20:95.8994,lwr_k=50:111.1446,lwr_k=100:119.9615,lwr_k=200:125.5532,lwr_k=500:130.3251,lwr_k=1000:133.7622'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:147.7418,lwr_k=20:165.2739,lwr_k=50:152.1145,lwr_k=100:148.5023,lwr_k=200:145.9864,lwr_k=500:143.9078,lwr_k=1000:143.3461'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:145.5398,lwr_k=20:95.4153,lwr_k=50:111.7567,lwr_k=100:121.7694,lwr_k=200:130.2835,lwr_k=500:136.2873,lwr_k=1000:137.8715'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:153.4689,lwr_k=20:175.6552,lwr_k=50:165.9702,lwr_k=100:162.1061,lwr_k=200:154.9007,lwr_k=500:152.2266,lwr_k=1000:150.4256'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:141.7249,lwr_k=20:100.5325,lwr_k=50:115.7172,lwr_k=100:122.7161,lwr_k=200:128.4867,lwr_k=500:132.1007,lwr_k=1000:134.4469'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:150.2645,lwr_k=20:165.4836,lwr_k=50:161.3497,lwr_k=100:156.5053,lwr_k=200:152.287,lwr_k=500:151.0846,lwr_k=1000:149.9934'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:487.7726,lwr_k=20:494.2739,lwr_k=50:487.8364,lwr_k=100:487.8469,lwr_k=200:487.8976,lwr_k=500:488.3433,lwr_k=1000:487.7771'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:478.8737,lwr_k=20:486.0777,lwr_k=50:479.0071,lwr_k=100:479.0232,lwr_k=200:478.9013,lwr_k=500:479.2361,lwr_k=1000:478.8966'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:146.0629,lwr_k=20:101.5628,lwr_k=50:116.0593,lwr_k=100:124.9949,lwr_k=200:129.0793,lwr_k=500:135.5094,lwr_k=1000:138.3379'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:1118.6068,lwr_k=20:727.3341,lwr_k=50:1179.8112,lwr_k=100:1582.7862,lwr_k=200:1517.5189,lwr_k=500:1495.7541,lwr_k=1000:1340.5342'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:143.0059,lwr_k=20:93.6202,lwr_k=50:106.7178,lwr_k=100:114.4579,lwr_k=200:121.071,lwr_k=500:126.1802,lwr_k=1000:128.6244'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:151.2952,lwr_k=20:165.0954,lwr_k=50:156.393,lwr_k=100:154.387,lwr_k=200:149.819,lwr_k=500:145.0297,lwr_k=1000:144.3337'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_28'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:147.2999,lwr_k=20:130.4626,lwr_k=50:135.7801,lwr_k=100:138.8535,lwr_k=200:141.9631,lwr_k=500:143.1023,lwr_k=1000:143.9344'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.544,lwr_k=20:153.9399,lwr_k=50:145.0421,lwr_k=100:142.6245,lwr_k=200:143.9754,lwr_k=500:142.8518,lwr_k=1000:142.7247'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:217.4334,lwr_k=20:130.9315,lwr_k=50:136.7451,lwr_k=100:138.6871,lwr_k=200:140.4199,lwr_k=500:144.3016,lwr_k=1000:149.9051'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:156.8343,lwr_k=20:150.6705,lwr_k=50:143.7177,lwr_k=100:141.2353,lwr_k=200:142.0829,lwr_k=500:139.0401,lwr_k=1000:138.6241'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:204.543,lwr_k=20:129.9333,lwr_k=50:136.1105,lwr_k=100:138.6654,lwr_k=200:140.3054,lwr_k=500:142.6356,lwr_k=1000:148.8738'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:152.355,lwr_k=20:200.6503,lwr_k=50:158.1439,lwr_k=100:160.8875,lwr_k=200:153.2918,lwr_k=500:145.8101,lwr_k=1000:146.5711'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:252.668,lwr_k=20:144.8299,lwr_k=50:155.5818,lwr_k=100:159.6969,lwr_k=200:162.856,lwr_k=500:166.0473,lwr_k=1000:171.7567'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:193.0933,lwr_k=20:182.4213,lwr_k=50:171.6734,lwr_k=100:169.1003,lwr_k=200:167.3772,lwr_k=500:165.9532,lwr_k=1000:165.5555'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:136.016,lwr_k=20:122.3683,lwr_k=50:126.854,lwr_k=100:129.5406,lwr_k=200:131.1724,lwr_k=500:132.2388,lwr_k=1000:133.1718'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:500.2958,lwr_k=20:569.9595,lwr_k=50:734.7429,lwr_k=100:680.22,lwr_k=200:618.1089,lwr_k=500:532.1657,lwr_k=1000:517.7123'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:200.0781,lwr_k=20:122.4944,lwr_k=50:130.4401,lwr_k=100:132.661,lwr_k=200:134.6429,lwr_k=500:137.6912,lwr_k=1000:142.7002'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:151.183,lwr_k=20:150.2134,lwr_k=50:145.1017,lwr_k=100:141.7125,lwr_k=200:140.6483,lwr_k=500:139.6946,lwr_k=1000:139.619'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_29'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:124.2709,lwr_k=20:26.1168,lwr_k=50:61.7005,lwr_k=100:85.1299,lwr_k=200:101.3074,lwr_k=500:113.0849,lwr_k=1000:118.136'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:124.8811,lwr_k=20:231.5998,lwr_k=50:177.065,lwr_k=100:152.0723,lwr_k=200:135.074,lwr_k=500:127.9107,lwr_k=1000:126.9256'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:148.8042,lwr_k=20:134.3926,lwr_k=50:139.8801,lwr_k=100:142.5553,lwr_k=200:144.5087,lwr_k=500:146.1175,lwr_k=1000:147.2235'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:158.0321,lwr_k=20:170.9629,lwr_k=50:168.4434,lwr_k=100:165.7402,lwr_k=200:160.1386,lwr_k=500:157.9424,lwr_k=1000:158.5259'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:132.5553,lwr_k=20:22.4752,lwr_k=50:61.5774,lwr_k=100:86.2543,lwr_k=200:102.2451,lwr_k=500:112.1598,lwr_k=1000:116.5543'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:142.8229,lwr_k=20:417.0572,lwr_k=50:280.551,lwr_k=100:180.8809,lwr_k=200:147.8853,lwr_k=500:139.7064,lwr_k=1000:135.2885'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.7796,lwr_k=20:31.8155,lwr_k=50:72.3415,lwr_k=100:96.0778,lwr_k=200:111.0403,lwr_k=500:123.1849,lwr_k=1000:128.752'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:138.0822,lwr_k=20:291.9522,lwr_k=50:191.9543,lwr_k=100:165.537,lwr_k=200:145.1149,lwr_k=500:135.7117,lwr_k=1000:135.9215'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:127.209,lwr_k=20:30.3514,lwr_k=50:66.394,lwr_k=100:88.8701,lwr_k=200:104.8154,lwr_k=500:116.3336,lwr_k=1000:120.3032'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:627.9072,lwr_k=20:964.605,lwr_k=50:579.0485,lwr_k=100:801.9701,lwr_k=200:570.2786,lwr_k=500:522.1121,lwr_k=1000:455.2438'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:139.5389,lwr_k=20:29.7304,lwr_k=50:63.6245,lwr_k=100:87.1116,lwr_k=200:101.2011,lwr_k=500:110.1931,lwr_k=1000:114.9381'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:140.9485,lwr_k=20:203.3958,lwr_k=50:168.2928,lwr_k=100:144.9359,lwr_k=200:138.2737,lwr_k=500:128.7965,lwr_k=1000:126.1551'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_30'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.5196,lwr_k=20:128.7773,lwr_k=50:132.8219,lwr_k=100:134.3353,lwr_k=200:135.4669,lwr_k=500:136.6953,lwr_k=1000:136.9432'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:513036.0087,lwr_k=20:145.6791,lwr_k=50:142.7562,lwr_k=100:139.5517,lwr_k=200:138.8589,lwr_k=500:139.0719,lwr_k=1000:138.7375'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:144.0095,lwr_k=20:131.3828,lwr_k=50:135.9824,lwr_k=100:138.3419,lwr_k=200:139.4014,lwr_k=500:141.1643,lwr_k=1000:141.8741'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:147.6441,lwr_k=20:158.1557,lwr_k=50:153.2577,lwr_k=100:153.3151,lwr_k=200:151.7683,lwr_k=500:146.8189,lwr_k=1000:147.1903'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:134.8989,lwr_k=20:124.3905,lwr_k=50:129.0019,lwr_k=100:131.2287,lwr_k=200:132.6014,lwr_k=500:134.1038,lwr_k=1000:134.2501'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.0048,lwr_k=20:144.6814,lwr_k=50:140.5359,lwr_k=100:139.8884,lwr_k=200:138.4996,lwr_k=500:138.675,lwr_k=1000:138.7347'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.9502,lwr_k=20:124.4625,lwr_k=50:130.3773,lwr_k=100:132.3335,lwr_k=200:133.3611,lwr_k=500:134.3321,lwr_k=1000:135.1602'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:139.3612,lwr_k=20:142.6125,lwr_k=50:138.1474,lwr_k=100:137.1707,lwr_k=200:135.7999,lwr_k=500:134.8233,lwr_k=1000:134.4289'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:146.6803,lwr_k=20:134.1325,lwr_k=50:139.1798,lwr_k=100:141.43,lwr_k=200:143.4047,lwr_k=500:145.1455,lwr_k=1000:145.4684'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:293.2643,lwr_k=20:481.0563,lwr_k=50:450.8953,lwr_k=100:713.2429,lwr_k=200:456.0588,lwr_k=500:481.7633,lwr_k=1000:477.4972'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:135.153,lwr_k=20:125.3001,lwr_k=50:129.9622,lwr_k=100:130.9065,lwr_k=200:132.0529,lwr_k=500:133.4802,lwr_k=1000:133.9223'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:135.2114,lwr_k=20:138.6399,lwr_k=50:135.7248,lwr_k=100:136.1394,lwr_k=200:135.9772,lwr_k=500:135.66,lwr_k=1000:135.3007'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_31'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:132.7319,lwr_k=20:30.8738,lwr_k=50:63.2859,lwr_k=100:87.1951,lwr_k=200:103.6761,lwr_k=500:114.8996,lwr_k=1000:120.4263'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:130.428,lwr_k=20:238.3299,lwr_k=50:195.5722,lwr_k=100:163.2514,lwr_k=200:142.5241,lwr_k=500:132.1094,lwr_k=1000:129.8802'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:132.0514,lwr_k=20:39.3887,lwr_k=50:69.344,lwr_k=100:89.6222,lwr_k=200:102.4623,lwr_k=500:114.2468,lwr_k=1000:120.6959'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.9008,lwr_k=20:238.1663,lwr_k=50:198.674,lwr_k=100:170.8698,lwr_k=200:154.5546,lwr_k=500:147.2989,lwr_k=1000:141.6177'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:134.6169,lwr_k=20:37.4754,lwr_k=50:69.2589,lwr_k=100:88.0652,lwr_k=200:102.6361,lwr_k=500:114.4478,lwr_k=1000:120.1088'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:137.9797,lwr_k=20:233.0562,lwr_k=50:193.41,lwr_k=100:186.777,lwr_k=200:181.5017,lwr_k=500:142.5626,lwr_k=1000:141.3196'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:138.978,lwr_k=20:30.1614,lwr_k=50:63.8494,lwr_k=100:86.1019,lwr_k=200:101.8206,lwr_k=500:114.8863,lwr_k=1000:120.9258'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:138.9108,lwr_k=20:233.8556,lwr_k=50:196.1421,lwr_k=100:160.7539,lwr_k=200:147.1754,lwr_k=500:138.5571,lwr_k=1000:130.6141'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:133.5915,lwr_k=20:34.0929,lwr_k=50:66.5115,lwr_k=100:88.2372,lwr_k=200:104.5579,lwr_k=500:117.0556,lwr_k=1000:124.1575'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:370.8809,lwr_k=20:249.5905,lwr_k=50:294.4855,lwr_k=100:347.3606,lwr_k=200:404.1363,lwr_k=500:219.5251,lwr_k=1000:285.0444'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:129.8457,lwr_k=20:40.6851,lwr_k=50:69.1969,lwr_k=100:88.6901,lwr_k=200:100.5309,lwr_k=500:111.4104,lwr_k=1000:117.2351'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:135.6586,lwr_k=20:211.7282,lwr_k=50:167.1157,lwr_k=100:157.1854,lwr_k=200:146.0129,lwr_k=500:138.8574,lwr_k=1000:133.7207'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_32'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:335.1807,lwr_k=20:262.1259,lwr_k=50:271.1497,lwr_k=100:271.316,lwr_k=200:268.1239,lwr_k=500:268.3812,lwr_k=1000:276.5778'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:377.8005,lwr_k=20:352.7198,lwr_k=50:341.1703,lwr_k=100:330.2711,lwr_k=200:323.0768,lwr_k=500:313.5666,lwr_k=1000:314.9052'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:348.4576,lwr_k=20:268.7599,lwr_k=50:279.6609,lwr_k=100:278.3811,lwr_k=200:274.1995,lwr_k=500:276.4417,lwr_k=1000:283.7206'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:337.8139,lwr_k=20:318.4663,lwr_k=50:303.2347,lwr_k=100:291.4827,lwr_k=200:279.4455,lwr_k=500:272.6723,lwr_k=1000:278.3801'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:351.6667,lwr_k=20:268.2253,lwr_k=50:277.643,lwr_k=100:278.8703,lwr_k=200:276.1616,lwr_k=500:278.1453,lwr_k=1000:284.6449'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:348.2771,lwr_k=20:333.6107,lwr_k=50:328.0382,lwr_k=100:316.9718,lwr_k=200:307.5475,lwr_k=500:299.2355,lwr_k=1000:301.4352'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:351.1314,lwr_k=20:268.1189,lwr_k=50:276.0397,lwr_k=100:277.0486,lwr_k=200:274.6298,lwr_k=500:277.076,lwr_k=1000:286.651'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:348.6845,lwr_k=20:344.6266,lwr_k=50:343.2734,lwr_k=100:304.9843,lwr_k=200:292.4529,lwr_k=500:287.9836,lwr_k=1000:285.7888'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:348.4802,lwr_k=20:268.2448,lwr_k=50:278.0395,lwr_k=100:278.2185,lwr_k=200:276.5176,lwr_k=500:278.7784,lwr_k=1000:287.7831'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:406.4996,lwr_k=20:360.4277,lwr_k=50:347.6282,lwr_k=100:332.3228,lwr_k=200:314.6445,lwr_k=500:308.5667,lwr_k=1000:312.7666'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:353.1003,lwr_k=20:269.6413,lwr_k=50:278.4581,lwr_k=100:277.9878,lwr_k=200:276.4554,lwr_k=500:276.5309,lwr_k=1000:282.7123'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:357.719,lwr_k=20:332.6615,lwr_k=50:325.646,lwr_k=100:317.8521,lwr_k=200:308.6383,lwr_k=500:301.9168,lwr_k=1000:303.3943'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_33'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:323.6756,lwr_k=20:299.1303,lwr_k=50:314.0107,lwr_k=100:320.0673,lwr_k=200:318.6466,lwr_k=500:312.9921,lwr_k=1000:311.8842'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:365.1235,lwr_k=20:361.025,lwr_k=50:364.4625,lwr_k=100:363.1669,lwr_k=200:359.0928,lwr_k=500:346.5402,lwr_k=1000:341.5161'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:329.6624,lwr_k=20:302.8631,lwr_k=50:322.7337,lwr_k=100:328.2343,lwr_k=200:325.7514,lwr_k=500:318.3186,lwr_k=1000:317.298'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:346.9156,lwr_k=20:331.1235,lwr_k=50:324.0531,lwr_k=100:324.0316,lwr_k=200:321.9134,lwr_k=500:313.2268,lwr_k=1000:310.0158'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:332.2715,lwr_k=20:304.82,lwr_k=50:323.6582,lwr_k=100:330.2421,lwr_k=200:327.5633,lwr_k=500:320.974,lwr_k=1000:319.8715'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:344.7224,lwr_k=20:340.6691,lwr_k=50:343.9638,lwr_k=100:341.8738,lwr_k=200:338.1314,lwr_k=500:329.843,lwr_k=1000:330.5291'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:331.2345,lwr_k=20:306.6887,lwr_k=50:320.6793,lwr_k=100:327.2739,lwr_k=200:326.3674,lwr_k=500:320.6517,lwr_k=1000:319.4138'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:416.971,lwr_k=20:333.2284,lwr_k=50:335.5051,lwr_k=100:336.1418,lwr_k=200:329.6124,lwr_k=500:319.2186,lwr_k=1000:316.2731'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:336.1483,lwr_k=20:308.6122,lwr_k=50:323.0478,lwr_k=100:327.2973,lwr_k=200:326.7584,lwr_k=500:320.9557,lwr_k=1000:320.9836'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:462.9219,lwr_k=20:367.2164,lwr_k=50:364.0952,lwr_k=100:362.9773,lwr_k=200:358.3695,lwr_k=500:344.7286,lwr_k=1000:338.8969'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:336.7716,lwr_k=20:306.3551,lwr_k=50:321.5553,lwr_k=100:326.4232,lwr_k=200:325.4833,lwr_k=500:319.3035,lwr_k=1000:316.8454'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:345.785,lwr_k=20:354.1491,lwr_k=50:350.1694,lwr_k=100:348.088,lwr_k=200:340.9681,lwr_k=500:332.1927,lwr_k=1000:326.8842'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_34'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:130.6255,lwr_k=20:21.242,lwr_k=50:52.9769,lwr_k=100:79.8942,lwr_k=200:98.8411,lwr_k=500:114.2671,lwr_k=1000:120.8134'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:130.3269,lwr_k=20:225.5724,lwr_k=50:182.5913,lwr_k=100:157.7718,lwr_k=200:139.0846,lwr_k=500:131.2923,lwr_k=1000:127.3952'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:134.7559,lwr_k=20:18.8048,lwr_k=50:52.6882,lwr_k=100:80.5948,lwr_k=200:100.8212,lwr_k=500:115.2347,lwr_k=1000:123.3919'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:140.3985,lwr_k=20:265.2569,lwr_k=50:212.0487,lwr_k=100:174.5223,lwr_k=200:152.6428,lwr_k=500:143.4289,lwr_k=1000:140.0815'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:130.7947,lwr_k=20:89.4847,lwr_k=50:102.3744,lwr_k=100:108.8169,lwr_k=200:113.2387,lwr_k=500:118.8958,lwr_k=1000:122.146'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:140.237,lwr_k=20:161.2113,lwr_k=50:151.485,lwr_k=100:145.4942,lwr_k=200:140.3856,lwr_k=500:135.2634,lwr_k=1000:135.757'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:141.1677,lwr_k=20:75.9809,lwr_k=50:94.1005,lwr_k=100:103.7783,lwr_k=200:111.3902,lwr_k=500:118.6248,lwr_k=1000:123.0092'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:138.6787,lwr_k=20:158.5932,lwr_k=50:141.6842,lwr_k=100:138.1468,lwr_k=200:133.0263,lwr_k=500:128.7426,lwr_k=1000:130.1537'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:141.7067,lwr_k=20:124.7698,lwr_k=50:135.3733,lwr_k=100:139.6585,lwr_k=200:142.6655,lwr_k=500:144.0621,lwr_k=1000:145.7802'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:236773.1874,lwr_k=20:185.5851,lwr_k=50:157.8332,lwr_k=100:174.3881,lwr_k=200:168.7848,lwr_k=500:189.4608,lwr_k=1000:220.8091'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:131.543,lwr_k=20:79.7908,lwr_k=50:96.3928,lwr_k=100:104.6355,lwr_k=200:111.4849,lwr_k=500:117.2654,lwr_k=1000:120.7991'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:143.2674,lwr_k=20:170.8817,lwr_k=50:153.3006,lwr_k=100:146.6851,lwr_k=200:142.1791,lwr_k=500:135.0536,lwr_k=1000:135.2414'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_35'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:475.3153,lwr_k=20:476.266,lwr_k=50:478.4367,lwr_k=100:484.6798,lwr_k=200:476.1122,lwr_k=500:476.8619,lwr_k=1000:475.3224'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:502.902,lwr_k=20:502.0021,lwr_k=50:509.3768,lwr_k=100:518.0748,lwr_k=200:505.3931,lwr_k=500:506.8091,lwr_k=1000:503.0688'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:492.2828,lwr_k=20:492.6794,lwr_k=50:493.0456,lwr_k=100:492.3113,lwr_k=200:492.488,lwr_k=500:492.7045,lwr_k=1000:492.3409'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:455.1291,lwr_k=20:455.0952,lwr_k=50:455.2948,lwr_k=100:455.0422,lwr_k=200:455.0246,lwr_k=500:455.1069,lwr_k=1000:455.3521'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:139.1819,lwr_k=20:123.4308,lwr_k=50:128.1171,lwr_k=100:131.1156,lwr_k=200:133.3503,lwr_k=500:135.2082,lwr_k=1000:136.2116'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:140.0471,lwr_k=20:150.9149,lwr_k=50:145.5448,lwr_k=100:143.9946,lwr_k=200:143.2475,lwr_k=500:141.876,lwr_k=1000:140.2718'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:148.2827,lwr_k=20:130.4912,lwr_k=50:135.7649,lwr_k=100:138.3981,lwr_k=200:140.4427,lwr_k=500:142.2869,lwr_k=1000:142.952'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:144.402,lwr_k=20:152.0246,lwr_k=50:146.3274,lwr_k=100:144.5002,lwr_k=200:143.4481,lwr_k=500:143.316,lwr_k=1000:142.994'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:140.7069,lwr_k=20:128.3136,lwr_k=50:134.3823,lwr_k=100:136.5435,lwr_k=200:137.5689,lwr_k=500:139.314,lwr_k=1000:139.8187'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:1104.3591,lwr_k=20:973.843,lwr_k=50:861.92,lwr_k=100:1298.2311,lwr_k=200:1425.5258,lwr_k=500:656.246,lwr_k=1000:737.2263'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:137.6797,lwr_k=20:125.6989,lwr_k=50:128.9489,lwr_k=100:130.9391,lwr_k=200:132.5064,lwr_k=500:134.0987,lwr_k=1000:134.8805'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:137.3011,lwr_k=20:141.2496,lwr_k=50:139.6234,lwr_k=100:137.4398,lwr_k=200:136.1676,lwr_k=500:136.2651,lwr_k=1000:135.3469'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_36'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:141.7202,lwr_k=20:122.4798,lwr_k=50:130.674,lwr_k=100:134.8817,lwr_k=200:136.964,lwr_k=500:138.135,lwr_k=1000:139.2485'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:161.1317,lwr_k=20:148.1978,lwr_k=50:138.6105,lwr_k=100:135.8679,lwr_k=200:134.5904,lwr_k=500:135.1454,lwr_k=1000:135.196'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:150.0672,lwr_k=20:137.2806,lwr_k=50:142.2991,lwr_k=100:143.9422,lwr_k=200:144.6297,lwr_k=500:145.4329,lwr_k=1000:146.1558'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:151.1653,lwr_k=20:154.9519,lwr_k=50:150.0487,lwr_k=100:148.1376,lwr_k=200:147.7405,lwr_k=500:147.3602,lwr_k=1000:148.0192'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:145.1873,lwr_k=20:134.4452,lwr_k=50:140.0665,lwr_k=100:141.1934,lwr_k=200:142.5365,lwr_k=500:143.6324,lwr_k=1000:144.2481'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:145.3078,lwr_k=20:153.7333,lwr_k=50:148.9294,lwr_k=100:147.1175,lwr_k=200:145.7077,lwr_k=500:145.0593,lwr_k=1000:145.0231'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.5407,lwr_k=20:133.9658,lwr_k=50:138.6564,lwr_k=100:140.131,lwr_k=200:141.5706,lwr_k=500:142.4732,lwr_k=1000:142.5834'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:83610.1405,lwr_k=20:147.2971,lwr_k=50:143.157,lwr_k=100:141.604,lwr_k=200:140.1758,lwr_k=500:140.5352,lwr_k=1000:140.0002'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:156.5563,lwr_k=20:135.7481,lwr_k=50:142.5997,lwr_k=100:145.2439,lwr_k=200:147.3738,lwr_k=500:149.4959,lwr_k=1000:150.6019'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:830.8898,lwr_k=20:157.8358,lwr_k=50:161.8449,lwr_k=100:1133.7726,lwr_k=200:332.7167,lwr_k=500:158.6461,lwr_k=1000:238.0656'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:135.2955,lwr_k=20:125.8493,lwr_k=50:131.5623,lwr_k=100:132.4754,lwr_k=200:133.1482,lwr_k=500:134.1961,lwr_k=1000:134.4031'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:137.1312,lwr_k=20:144.7521,lwr_k=50:137.7411,lwr_k=100:136.9082,lwr_k=200:135.7017,lwr_k=500:135.7772,lwr_k=1000:135.9951'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_37'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:132.8274,lwr_k=20:12.5091,lwr_k=50:51.9475,lwr_k=100:78.6193,lwr_k=200:97.6997,lwr_k=500:111.3026,lwr_k=1000:119.086'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:131.7352,lwr_k=20:304.0659,lwr_k=50:203.6657,lwr_k=100:169.9963,lwr_k=200:145.4063,lwr_k=500:135.8332,lwr_k=1000:128.6608'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:152.863,lwr_k=20:15.0033,lwr_k=50:53.2111,lwr_k=100:78.8973,lwr_k=200:96.9491,lwr_k=500:111.7048,lwr_k=1000:119.0532'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:150.3282,lwr_k=20:312.4518,lwr_k=50:233.619,lwr_k=100:172.1093,lwr_k=200:156.2484,lwr_k=500:136.1816,lwr_k=1000:134.1113'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:127.1596,lwr_k=20:1.7186,lwr_k=50:38.9857,lwr_k=100:71.0186,lwr_k=200:90.6864,lwr_k=500:105.0024,lwr_k=1000:110.5374'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:134.0266,lwr_k=20:537.9364,lwr_k=50:385.8631,lwr_k=100:170.6083,lwr_k=200:138.8354,lwr_k=500:126.4569,lwr_k=1000:126.206'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:162.026,lwr_k=20:16.2875,lwr_k=50:53.7351,lwr_k=100:80.6605,lwr_k=200:98.5029,lwr_k=500:114.0892,lwr_k=1000:121.2334'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:163.4522,lwr_k=20:259.2716,lwr_k=50:194.2651,lwr_k=100:151.255,lwr_k=200:138.3267,lwr_k=500:131.5452,lwr_k=1000:131.8881'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:140.992,lwr_k=20:18.4108,lwr_k=50:59.3286,lwr_k=100:87.4109,lwr_k=200:105.2067,lwr_k=500:120.9498,lwr_k=1000:127.9155'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:736.3765,lwr_k=20:4856.2666,lwr_k=50:497.139,lwr_k=100:730.1169,lwr_k=200:724.5964,lwr_k=500:862.4818,lwr_k=1000:819.1905'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:126.8689,lwr_k=20:2.1187,lwr_k=50:36.2118,lwr_k=100:68.4101,lwr_k=200:86.9411,lwr_k=500:101.5224,lwr_k=1000:108.0501'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:130.2227,lwr_k=20:385.3631,lwr_k=50:237.0994,lwr_k=100:164.2178,lwr_k=200:139.9976,lwr_k=500:127.806,lwr_k=1000:126.419'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_38'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:127.6925,lwr_k=20:43.6925,lwr_k=50:78.8236,lwr_k=100:96.1591,lwr_k=200:105.8677,lwr_k=500:114.6115,lwr_k=1000:118.6011'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:127.0572,lwr_k=20:209.7134,lwr_k=50:171.981,lwr_k=100:136.6613,lwr_k=200:133.0983,lwr_k=500:125.1738,lwr_k=1000:124.5314'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:147.5222,lwr_k=20:42.1063,lwr_k=50:76.7033,lwr_k=100:94.9465,lwr_k=200:105.3173,lwr_k=500:113.9721,lwr_k=1000:118.0266'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:154.7049,lwr_k=20:204.4058,lwr_k=50:162.0115,lwr_k=100:149.7636,lwr_k=200:135.6387,lwr_k=500:129.5104,lwr_k=1000:129.2665'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:149.3263,lwr_k=20:48.532,lwr_k=50:81.4281,lwr_k=100:97.4406,lwr_k=200:106.0149,lwr_k=500:114.2179,lwr_k=1000:117.6043'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:155.4568,lwr_k=20:206.7167,lwr_k=50:152.316,lwr_k=100:145.7161,lwr_k=200:136.7348,lwr_k=500:132.1913,lwr_k=1000:132.6655'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:132.9617,lwr_k=20:37.4953,lwr_k=50:74.2708,lwr_k=100:92.4686,lwr_k=200:105.0621,lwr_k=500:114.4436,lwr_k=1000:118.7121'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:130.8606,lwr_k=20:224.1999,lwr_k=50:169.8182,lwr_k=100:144.3351,lwr_k=200:132.1082,lwr_k=500:125.3553,lwr_k=1000:122.9755'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:124.6338,lwr_k=20:35.6831,lwr_k=50:74.3386,lwr_k=100:90.8191,lwr_k=200:104.2468,lwr_k=500:111.8189,lwr_k=1000:116.6603'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:897.0552,lwr_k=20:2481.7096,lwr_k=50:2880.9518,lwr_k=100:521.1891,lwr_k=200:1170.7246,lwr_k=500:600.2136,lwr_k=1000:385.549'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:159.1754,lwr_k=20:60.4199,lwr_k=50:88.3455,lwr_k=100:102.337,lwr_k=200:111.6097,lwr_k=500:119.3762,lwr_k=1000:123.2275'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:153.6905,lwr_k=20:174.819,lwr_k=50:153.0339,lwr_k=100:138.5406,lwr_k=200:135.0434,lwr_k=500:133.6725,lwr_k=1000:131.4594'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_39'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:302.4213,lwr_k=20:172.1787,lwr_k=50:188.4078,lwr_k=100:199.165,lwr_k=200:208.5175,lwr_k=500:223.6341,lwr_k=1000:239.3094'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:329.6641,lwr_k=20:303.6298,lwr_k=50:287.1212,lwr_k=100:268.5367,lwr_k=200:260.9975,lwr_k=500:260.938,lwr_k=1000:267.5124'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:301.8957,lwr_k=20:179.9999,lwr_k=50:194.5007,lwr_k=100:203.5672,lwr_k=200:212.8475,lwr_k=500:228.6,lwr_k=1000:243.0446'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:309.0134,lwr_k=20:286.9766,lwr_k=50:265.9596,lwr_k=100:249.4437,lwr_k=200:244.5082,lwr_k=500:246.1053,lwr_k=1000:261.3705'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:306.9126,lwr_k=20:178.4531,lwr_k=50:191.9576,lwr_k=100:200.2757,lwr_k=200:209.1901,lwr_k=500:225.9273,lwr_k=1000:242.6382'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:302.1825,lwr_k=20:293.2375,lwr_k=50:276.752,lwr_k=100:268.2754,lwr_k=200:261.9531,lwr_k=500:261.2323,lwr_k=1000:263.7981'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:306.2206,lwr_k=20:174.7453,lwr_k=50:189.984,lwr_k=100:199.6231,lwr_k=200:209.5025,lwr_k=500:225.9679,lwr_k=1000:243.5595'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:331.6215,lwr_k=20:329.6174,lwr_k=50:336.4577,lwr_k=100:317.073,lwr_k=200:293.8157,lwr_k=500:254.2535,lwr_k=1000:301.028'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.3335,lwr_k=20:0.1027,lwr_k=50:42.5922,lwr_k=100:83.0835,lwr_k=200:103.8763,lwr_k=500:116.9885,lwr_k=1000:123.6227'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:224.9214,lwr_k=20:5237.4678,lwr_k=50:770.8346,lwr_k=100:334.6191,lwr_k=200:499.2666,lwr_k=500:285.9823,lwr_k=1000:288.3655'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:316.1336,lwr_k=20:193.9978,lwr_k=50:208.2162,lwr_k=100:219.8997,lwr_k=200:228.2705,lwr_k=500:237.6369,lwr_k=1000:247.5808'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:305.1454,lwr_k=20:299.3379,lwr_k=50:281.658,lwr_k=100:274.5134,lwr_k=200:262.7707,lwr_k=500:257.6428,lwr_k=1000:258.4523'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_40'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.3968,lwr_k=20:119.5123,lwr_k=50:128.6127,lwr_k=100:134.0584,lwr_k=200:136.2326,lwr_k=500:138.0335,lwr_k=1000:139.5605'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:142.4937,lwr_k=20:152.1204,lwr_k=50:145.4999,lwr_k=100:141.3916,lwr_k=200:140.9328,lwr_k=500:138.978,lwr_k=1000:138.8334'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.1562,lwr_k=20:113.2458,lwr_k=50:121.0935,lwr_k=100:125.348,lwr_k=200:128.8073,lwr_k=500:130.5723,lwr_k=1000:131.8281'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.9066,lwr_k=20:156.2937,lwr_k=50:150.0657,lwr_k=100:147.9363,lwr_k=200:145.5393,lwr_k=500:142.9057,lwr_k=1000:142.2101'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:138.438,lwr_k=20:122.2774,lwr_k=50:129.4734,lwr_k=100:132.8697,lwr_k=200:134.291,lwr_k=500:135.5485,lwr_k=1000:136.1546'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.7135,lwr_k=20:152.54,lwr_k=50:146.5355,lwr_k=100:143.3338,lwr_k=200:141.6838,lwr_k=500:140.042,lwr_k=1000:140.2151'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:132.5243,lwr_k=20:110.7328,lwr_k=50:119.871,lwr_k=100:124.1098,lwr_k=200:126.6178,lwr_k=500:129.2005,lwr_k=1000:130.5967'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:133.1375,lwr_k=20:149.3757,lwr_k=50:139.6632,lwr_k=100:133.8214,lwr_k=200:133.4105,lwr_k=500:132.4148,lwr_k=1000:130.9688'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.2346,lwr_k=20:117.591,lwr_k=50:127.4928,lwr_k=100:132.3171,lwr_k=200:135.1041,lwr_k=500:137.3586,lwr_k=1000:138.1368'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:496.4022,lwr_k=20:515.7732,lwr_k=50:155.4038,lwr_k=100:354.1008,lwr_k=200:744.7088,lwr_k=500:1026.1388,lwr_k=1000:928.3385'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:131.2814,lwr_k=20:112.7352,lwr_k=50:120.5828,lwr_k=100:123.9403,lwr_k=200:126.2277,lwr_k=500:128.3652,lwr_k=1000:129.4411'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:143.6812,lwr_k=20:153.6161,lwr_k=50:149.1712,lwr_k=100:145.4965,lwr_k=200:141.863,lwr_k=500:142.0525,lwr_k=1000:142.1981'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_41'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:131.7918,lwr_k=20:101.959,lwr_k=50:111.0917,lwr_k=100:117.3309,lwr_k=200:121.5311,lwr_k=500:126.3565,lwr_k=1000:128.3256'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:130.8389,lwr_k=20:137.6179,lwr_k=50:132.9032,lwr_k=100:129.3964,lwr_k=200:126.5986,lwr_k=500:129.1074,lwr_k=1000:127.6508'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.9845,lwr_k=20:87.78,lwr_k=50:105.0757,lwr_k=100:114.8798,lwr_k=200:119.6961,lwr_k=500:125.7141,lwr_k=1000:129.1827'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.9525,lwr_k=20:163.7782,lwr_k=50:150.3249,lwr_k=100:147.3229,lwr_k=200:139.164,lwr_k=500:138.3601,lwr_k=1000:138.2093'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.6908,lwr_k=20:94.2144,lwr_k=50:105.3458,lwr_k=100:111.6451,lwr_k=200:117.6921,lwr_k=500:123.7175,lwr_k=1000:126.7176'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:137.4144,lwr_k=20:154.4915,lwr_k=50:148.5446,lwr_k=100:143.8271,lwr_k=200:142.7667,lwr_k=500:137.7003,lwr_k=1000:134.7694'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:134.2193,lwr_k=20:94.6952,lwr_k=50:108.0616,lwr_k=100:115.9065,lwr_k=200:121.4711,lwr_k=500:126.4168,lwr_k=1000:128.8195'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:132.046,lwr_k=20:147.1514,lwr_k=50:138.504,lwr_k=100:136.0376,lwr_k=200:133.9858,lwr_k=500:132.0085,lwr_k=1000:130.3714'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.1949,lwr_k=20:96.7923,lwr_k=50:109.8001,lwr_k=100:117.3096,lwr_k=200:123.4483,lwr_k=500:128.7023,lwr_k=1000:130.6767'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:1460.9082,lwr_k=20:384.6123,lwr_k=50:1199.8732,lwr_k=100:1738.4366,lwr_k=200:1311.4237,lwr_k=500:1799.7106,lwr_k=1000:1742.8148'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:123.1272,lwr_k=20:85.2606,lwr_k=50:98.2665,lwr_k=100:105.925,lwr_k=200:111.7286,lwr_k=500:116.8214,lwr_k=1000:120.2653'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:131.8129,lwr_k=20:148.7968,lwr_k=50:140.4525,lwr_k=100:138.4001,lwr_k=200:133.7523,lwr_k=500:130.0426,lwr_k=1000:129.4439'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_42'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.9954,lwr_k=20:126.3519,lwr_k=50:131.4757,lwr_k=100:133.7177,lwr_k=200:134.3871,lwr_k=500:136.0703,lwr_k=1000:136.6239'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:143.8665,lwr_k=20:152.5428,lwr_k=50:148.6727,lwr_k=100:147.0681,lwr_k=200:145.1589,lwr_k=500:144.3403,lwr_k=1000:144.1952'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:156.4596,lwr_k=20:131.41,lwr_k=50:135.5331,lwr_k=100:136.9963,lwr_k=200:139.6034,lwr_k=500:144.7549,lwr_k=1000:150.1739'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:145.6527,lwr_k=20:147.94,lwr_k=50:146.4301,lwr_k=100:143.848,lwr_k=200:143.6555,lwr_k=500:143.798,lwr_k=1000:144.0589'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:145.3853,lwr_k=20:131.8298,lwr_k=50:135.9115,lwr_k=100:138.4683,lwr_k=200:140.284,lwr_k=500:142.1059,lwr_k=1000:142.3812'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:153.5327,lwr_k=20:156.1935,lwr_k=50:148.338,lwr_k=100:148.8919,lwr_k=200:149.9102,lwr_k=500:151.8776,lwr_k=1000:151.7165'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.5121,lwr_k=20:131.5098,lwr_k=50:138.4262,lwr_k=100:140.3539,lwr_k=200:141.4773,lwr_k=500:141.8886,lwr_k=1000:142.2911'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:149.3387,lwr_k=20:154.1566,lwr_k=50:149.8228,lwr_k=100:149.0523,lwr_k=200:149.8708,lwr_k=500:148.709,lwr_k=1000:149.0244'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:148.6401,lwr_k=20:136.8153,lwr_k=50:142.6735,lwr_k=100:144.8386,lwr_k=200:145.5365,lwr_k=500:146.1657,lwr_k=1000:146.7472'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:230.0672,lwr_k=20:196.9941,lwr_k=50:382.7637,lwr_k=100:326.5716,lwr_k=200:355.032,lwr_k=500:289.072,lwr_k=1000:266.984'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:158.3385,lwr_k=20:132.9623,lwr_k=50:138.0469,lwr_k=100:141.3254,lwr_k=200:142.2975,lwr_k=500:145.8902,lwr_k=1000:146.5177'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:159.1877,lwr_k=20:164.2174,lwr_k=50:156.4043,lwr_k=100:155.0481,lwr_k=200:153.7011,lwr_k=500:153.8997,lwr_k=1000:153.8789'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_43'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:339.0498,lwr_k=20:285.5952,lwr_k=50:302.3233,lwr_k=100:309.9395,lwr_k=200:313.6305,lwr_k=500:314.657,lwr_k=1000:314.2256'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:388.1371,lwr_k=20:348.3394,lwr_k=50:350.1495,lwr_k=100:350.501,lwr_k=200:351.8184,lwr_k=500:348.6458,lwr_k=1000:348.3129'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:316.1382,lwr_k=20:240.2554,lwr_k=50:267.9296,lwr_k=100:278.333,lwr_k=200:286.4219,lwr_k=500:294.2285,lwr_k=1000:296.9588'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:3470272.9537,lwr_k=20:360.5109,lwr_k=50:348.5046,lwr_k=100:339.6335,lwr_k=200:314.1679,lwr_k=500:294.4655,lwr_k=1000:285.929'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:357.9369,lwr_k=20:300.1996,lwr_k=50:319.5426,lwr_k=100:328.2073,lwr_k=200:331.2439,lwr_k=500:331.0729,lwr_k=1000:331.2865'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:603.327,lwr_k=20:322.0041,lwr_k=50:322.8842,lwr_k=100:327.0269,lwr_k=200:327.378,lwr_k=500:322.9605,lwr_k=1000:318.5045'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:353.2268,lwr_k=20:297.7211,lwr_k=50:313.13,lwr_k=100:321.9703,lwr_k=200:325.7438,lwr_k=500:326.4161,lwr_k=1000:327.2007'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:397.0904,lwr_k=20:326.362,lwr_k=50:325.5428,lwr_k=100:326.273,lwr_k=200:326.3833,lwr_k=500:325.7795,lwr_k=1000:324.8843'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:346.4493,lwr_k=20:291.2463,lwr_k=50:308.5913,lwr_k=100:315.6603,lwr_k=200:319.5814,lwr_k=500:319.3972,lwr_k=1000:320.2829'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:1096.4771,lwr_k=20:355.4599,lwr_k=50:352.3325,lwr_k=100:358.2289,lwr_k=200:358.852,lwr_k=500:356.0762,lwr_k=1000:357.5262'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:352.8748,lwr_k=20:294.2553,lwr_k=50:309.5088,lwr_k=100:318.0196,lwr_k=200:322.2239,lwr_k=500:321.8828,lwr_k=1000:322.7596'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:349.3335,lwr_k=20:329.8789,lwr_k=50:327.9692,lwr_k=100:327.6837,lwr_k=200:328.8825,lwr_k=500:325.2396,lwr_k=1000:323.4561'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_44'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:131.7635,lwr_k=20:5.1771,lwr_k=50:39.3174,lwr_k=100:72.5815,lwr_k=200:93.5801,lwr_k=500:109.9988,lwr_k=1000:118.239'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:134.3254,lwr_k=20:311.0291,lwr_k=50:247.9859,lwr_k=100:171.2956,lwr_k=200:145.9352,lwr_k=500:134.9055,lwr_k=1000:130.9697'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:151.8,lwr_k=20:50.0036,lwr_k=50:83.2349,lwr_k=100:98.9967,lwr_k=200:110.0087,lwr_k=500:119.7495,lwr_k=1000:124.1145'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:154.33,lwr_k=20:349.4538,lwr_k=50:207.9566,lwr_k=100:169.0633,lwr_k=200:147.6518,lwr_k=500:142.6367,lwr_k=1000:140.5009'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:140.4636,lwr_k=20:5.058,lwr_k=50:38.6309,lwr_k=100:73.3453,lwr_k=200:95.5797,lwr_k=500:111.1528,lwr_k=1000:117.5771'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:150.0423,lwr_k=20:284.8606,lwr_k=50:356.6152,lwr_k=100:186.6853,lwr_k=200:150.2742,lwr_k=500:136.2762,lwr_k=1000:134.9865'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:139.9513,lwr_k=20:2.4494,lwr_k=50:35.0156,lwr_k=100:72.1214,lwr_k=200:93.6556,lwr_k=500:111.363,lwr_k=1000:119.138'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:136.5164,lwr_k=20:342.345,lwr_k=50:281.3124,lwr_k=100:179.9024,lwr_k=200:140.4027,lwr_k=500:130.8618,lwr_k=1000:128.0509'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:130.0613,lwr_k=20:3.5411,lwr_k=50:37.8439,lwr_k=100:75.2969,lwr_k=200:96.5016,lwr_k=500:112.8697,lwr_k=1000:119.7089'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:445.9383,lwr_k=20:324.962,lwr_k=50:2002.4505,lwr_k=100:1041.3791,lwr_k=200:434.6744,lwr_k=500:380.4747,lwr_k=1000:387.9721'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:144.2344,lwr_k=20:0.9705,lwr_k=50:28.3448,lwr_k=100:64.7327,lwr_k=200:89.4664,lwr_k=500:108.9436,lwr_k=1000:116.5277'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:142.5882,lwr_k=20:682.545,lwr_k=50:475.7356,lwr_k=100:197.3921,lwr_k=200:147.1812,lwr_k=500:132.3514,lwr_k=1000:128.552'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_45'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:408.1028,lwr_k=20:349.6156,lwr_k=50:370.8611,lwr_k=100:380.5389,lwr_k=200:386.3099,lwr_k=500:388.0177,lwr_k=1000:389.5167'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:437.3539,lwr_k=20:405.5813,lwr_k=50:408.6241,lwr_k=100:410.0495,lwr_k=200:414.3907,lwr_k=500:415.8073,lwr_k=1000:419.5545'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:423.4138,lwr_k=20:365.1393,lwr_k=50:385.5292,lwr_k=100:396.9523,lwr_k=200:401.4041,lwr_k=500:403.3797,lwr_k=1000:404.3278'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:385.3729,lwr_k=20:365.1688,lwr_k=50:370.1369,lwr_k=100:374.3085,lwr_k=200:377.752,lwr_k=500:375.4558,lwr_k=1000:375.8807'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:426.2123,lwr_k=20:367.047,lwr_k=50:385.7761,lwr_k=100:397.1942,lwr_k=200:402.0506,lwr_k=500:404.2092,lwr_k=1000:406.4606'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:475.6468,lwr_k=20:391.9233,lwr_k=50:393.2458,lwr_k=100:401.304,lwr_k=200:406.5451,lwr_k=500:407.4494,lwr_k=1000:407.1601'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:414.3914,lwr_k=20:357.5126,lwr_k=50:379.1728,lwr_k=100:390.5,lwr_k=200:396.4341,lwr_k=500:398.0962,lwr_k=1000:399.4494'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:532.6447,lwr_k=20:388.4011,lwr_k=50:389.7329,lwr_k=100:394.593,lwr_k=200:396.5459,lwr_k=500:397.0341,lwr_k=1000:400.0487'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:422.9868,lwr_k=20:350.9844,lwr_k=50:374.047,lwr_k=100:386.9822,lwr_k=200:392.663,lwr_k=500:408.476,lwr_k=1000:414.6019'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:447.1308,lwr_k=20:511.7161,lwr_k=50:468.4423,lwr_k=100:454.3386,lwr_k=200:447.7953,lwr_k=500:448.7973,lwr_k=1000:444.6802'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:415.6731,lwr_k=20:352.8195,lwr_k=50:375.2316,lwr_k=100:388.2322,lwr_k=200:394.6096,lwr_k=500:396.4855,lwr_k=1000:397.9434'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:418.7018,lwr_k=20:404.5384,lwr_k=50:405.8085,lwr_k=100:404.6484,lwr_k=200:406.2389,lwr_k=500:405.7301,lwr_k=1000:405.2253'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_46'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:129.7062,lwr_k=20:100.7126,lwr_k=50:111.0269,lwr_k=100:117.3115,lwr_k=200:121.435,lwr_k=500:126.1486,lwr_k=1000:127.8099'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:133.9169,lwr_k=20:143.6942,lwr_k=50:139.0828,lwr_k=100:137.4183,lwr_k=200:136.7487,lwr_k=500:133.074,lwr_k=1000:133.5587'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:151.1752,lwr_k=20:115.2191,lwr_k=50:123.542,lwr_k=100:131.2478,lwr_k=200:135.3199,lwr_k=500:140.0597,lwr_k=1000:143.6261'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:228.3835,lwr_k=20:163.7675,lwr_k=50:159.5171,lwr_k=100:157.888,lwr_k=200:155.1339,lwr_k=500:152.9448,lwr_k=1000:152.4436'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:138.9214,lwr_k=20:110.4832,lwr_k=50:121.5432,lwr_k=100:126.9432,lwr_k=200:131.6377,lwr_k=500:134.3356,lwr_k=1000:136.866'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:137.5183,lwr_k=20:153.2019,lwr_k=50:145.4055,lwr_k=100:142.9783,lwr_k=200:138.9368,lwr_k=500:137.7187,lwr_k=1000:136.6727'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:154.9066,lwr_k=20:91.4116,lwr_k=50:110.7546,lwr_k=100:121.3623,lwr_k=200:128.1805,lwr_k=500:135.9769,lwr_k=1000:139.6135'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:150.3767,lwr_k=20:156.484,lwr_k=50:151.6991,lwr_k=100:145.9775,lwr_k=200:146.1384,lwr_k=500:142.7594,lwr_k=1000:141.5938'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:154.2673,lwr_k=20:115.8125,lwr_k=50:127.7378,lwr_k=100:133.2251,lwr_k=200:138.5213,lwr_k=500:143.9778,lwr_k=1000:145.7344'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:151.0942,lwr_k=20:214.8123,lwr_k=50:155.5895,lwr_k=100:162.4441,lwr_k=200:150.1719,lwr_k=500:141.4881,lwr_k=1000:144.0464'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:139.0425,lwr_k=20:106.9715,lwr_k=50:115.1978,lwr_k=100:120.4699,lwr_k=200:125.4955,lwr_k=500:130.1427,lwr_k=1000:132.6101'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:142.4489,lwr_k=20:153.2533,lwr_k=50:152.8454,lwr_k=100:150.6104,lwr_k=200:145.0705,lwr_k=500:141.5587,lwr_k=1000:140.4949'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_47'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:456.9862,lwr_k=20:469.9692,lwr_k=50:458.0458,lwr_k=100:457.9349,lwr_k=200:456.9813,lwr_k=500:457.1796,lwr_k=1000:456.893'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:483.1117,lwr_k=20:502.3653,lwr_k=50:485.7593,lwr_k=100:482.8227,lwr_k=200:482.618,lwr_k=500:482.4041,lwr_k=1000:483.0509'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:31690.1409,lwr_k=20:492.6794,lwr_k=50:493.0456,lwr_k=100:492.3113,lwr_k=200:492.488,lwr_k=500:492.7045,lwr_k=1000:492.3409'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:31785.1421,lwr_k=20:455.0952,lwr_k=50:455.2948,lwr_k=100:455.0422,lwr_k=200:455.0246,lwr_k=500:455.1069,lwr_k=1000:455.3521'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:280.2459,lwr_k=20:138.5168,lwr_k=50:192.4806,lwr_k=100:215.7946,lwr_k=200:234.7281,lwr_k=500:266.3237,lwr_k=1000:274.0141'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:279.0368,lwr_k=20:395.9211,lwr_k=50:329.1025,lwr_k=100:298.477,lwr_k=200:291.4294,lwr_k=500:307.3737,lwr_k=1000:285.3586'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:952163.1792,lwr_k=20:494.2739,lwr_k=50:487.8364,lwr_k=100:487.8469,lwr_k=200:487.8976,lwr_k=500:488.3433,lwr_k=1000:487.7771'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:950950.3346,lwr_k=20:486.0777,lwr_k=50:479.0071,lwr_k=100:479.0232,lwr_k=200:478.9013,lwr_k=500:479.2361,lwr_k=1000:478.8966'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:471.6926,lwr_k=20:491.9552,lwr_k=50:475.5908,lwr_k=100:473.3968,lwr_k=200:471.7025,lwr_k=500:471.687,lwr_k=1000:471.9314'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:493.9581,lwr_k=20:511.0451,lwr_k=50:496.1542,lwr_k=100:494.499,lwr_k=200:493.9231,lwr_k=500:494.0559,lwr_k=1000:493.7787'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:482.8012,lwr_k=20:485.6498,lwr_k=50:487.3117,lwr_k=100:487.3273,lwr_k=200:482.7291,lwr_k=500:482.7864,lwr_k=1000:482.7576'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:474.2479,lwr_k=20:477.7487,lwr_k=50:477.7097,lwr_k=100:477.7298,lwr_k=200:474.2769,lwr_k=500:474.5328,lwr_k=1000:474.4692'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_48'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:138.8972,lwr_k=20:43.913,lwr_k=50:77.189,lwr_k=100:95.9304,lwr_k=200:108.68,lwr_k=500:119.7812,lwr_k=1000:125.1288'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:140.9197,lwr_k=20:207.1324,lwr_k=50:174.5046,lwr_k=100:151.3016,lwr_k=200:142.7934,lwr_k=500:139.5532,lwr_k=1000:137.5094'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:138.7678,lwr_k=20:21.7799,lwr_k=50:55.1757,lwr_k=100:79.6962,lwr_k=200:99.4211,lwr_k=500:116.4425,lwr_k=1000:124.3122'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:145.8385,lwr_k=20:257.6613,lwr_k=50:193.1901,lwr_k=100:171.682,lwr_k=200:152.8761,lwr_k=500:146.4428,lwr_k=1000:141.5787'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:136.9427,lwr_k=20:82.8844,lwr_k=50:102.1996,lwr_k=100:111.4517,lwr_k=200:117.0434,lwr_k=500:121.5746,lwr_k=1000:124.359'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:160.6519,lwr_k=20:168.8074,lwr_k=50:154.9318,lwr_k=100:141.373,lwr_k=200:137.8343,lwr_k=500:132.5676,lwr_k=1000:133.7948'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:146.5147,lwr_k=20:56.5445,lwr_k=50:83.2736,lwr_k=100:98.0188,lwr_k=200:108.7977,lwr_k=500:118.5298,lwr_k=1000:124.8493'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:160.0529,lwr_k=20:226.7338,lwr_k=50:179.0272,lwr_k=100:165.9065,lwr_k=200:154.4916,lwr_k=500:157.1382,lwr_k=1000:141.5823'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:139.1503,lwr_k=20:78.9516,lwr_k=50:98.9006,lwr_k=100:108.9487,lwr_k=200:115.6555,lwr_k=500:122.2894,lwr_k=1000:125.4827'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:213.4503,lwr_k=20:1158.0911,lwr_k=50:391.8127,lwr_k=100:195.7211,lwr_k=200:136.9461,lwr_k=500:190.0273,lwr_k=1000:220.59'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:138.8048,lwr_k=20:34.818,lwr_k=50:65.9343,lwr_k=100:86.4165,lwr_k=200:100.5013,lwr_k=500:112.1922,lwr_k=1000:119.0062'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.7332,lwr_k=20:247.9341,lwr_k=50:173.3935,lwr_k=100:156.4568,lwr_k=200:147.5722,lwr_k=500:138.3002,lwr_k=1000:135.374'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_49'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:138.6171,lwr_k=20:109.4046,lwr_k=50:123.0597,lwr_k=100:128.1734,lwr_k=200:130.942,lwr_k=500:134.3927,lwr_k=1000:135.8975'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:131.6953,lwr_k=20:152.022,lwr_k=50:138.7415,lwr_k=100:133.927,lwr_k=200:132.3702,lwr_k=500:131.5499,lwr_k=1000:131.08'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:191.2666,lwr_k=20:114.3053,lwr_k=50:121.2092,lwr_k=100:124.637,lwr_k=200:127.5366,lwr_k=500:129.8995,lwr_k=1000:132.5547'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:160.8859,lwr_k=20:145.9553,lwr_k=50:141.3344,lwr_k=100:136.8437,lwr_k=200:133.9068,lwr_k=500:134.7843,lwr_k=1000:134.9892'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:181.563,lwr_k=20:114.4875,lwr_k=50:124.5078,lwr_k=100:127.9914,lwr_k=200:131.3465,lwr_k=500:135.9446,lwr_k=1000:143.7288'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:143.9015,lwr_k=20:152.6307,lwr_k=50:143.8101,lwr_k=100:140.1735,lwr_k=200:139.4388,lwr_k=500:137.0761,lwr_k=1000:137.6001'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:244.8101,lwr_k=20:117.4771,lwr_k=50:127.4068,lwr_k=100:131.7394,lwr_k=200:134.8673,lwr_k=500:138.9979,lwr_k=1000:145.3499'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:167.7068,lwr_k=20:155.9804,lwr_k=50:141.9169,lwr_k=100:139.9308,lwr_k=200:137.9123,lwr_k=500:136.291,lwr_k=1000:135.7639'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:139.7031,lwr_k=20:117.8409,lwr_k=50:127.7562,lwr_k=100:131.7764,lwr_k=200:133.4412,lwr_k=500:136.0541,lwr_k=1000:137.3437'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:483.626,lwr_k=20:1212.2141,lwr_k=50:1182.5912,lwr_k=100:743.975,lwr_k=200:611.8344,lwr_k=500:559.6416,lwr_k=1000:524.2334'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:187.7775,lwr_k=20:109.941,lwr_k=50:119.0301,lwr_k=100:122.2292,lwr_k=200:124.5363,lwr_k=500:128.4627,lwr_k=1000:133.3942'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:151.4185,lwr_k=20:144.349,lwr_k=50:136.5878,lwr_k=100:133.9584,lwr_k=200:133.1172,lwr_k=500:133.1629,lwr_k=1000:133.9032'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_50'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:134.4414,lwr_k=20:117.7579,lwr_k=50:123.7845,lwr_k=100:127.6108,lwr_k=200:130.4728,lwr_k=500:132.4149,lwr_k=1000:133.447'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:129.6292,lwr_k=20:138.4255,lwr_k=50:137.2436,lwr_k=100:133.0972,lwr_k=200:131.4042,lwr_k=500:129.1535,lwr_k=1000:128.793'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:136.3122,lwr_k=20:110.0856,lwr_k=50:118.1163,lwr_k=100:121.6728,lwr_k=200:123.9456,lwr_k=500:125.7834,lwr_k=1000:126.3214'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.205,lwr_k=20:145.9676,lwr_k=50:137.9328,lwr_k=100:135.6374,lwr_k=200:136.3259,lwr_k=500:134.9305,lwr_k=1000:135.3636'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:140.1685,lwr_k=20:111.5752,lwr_k=50:117.851,lwr_k=100:121.5493,lwr_k=200:124.2777,lwr_k=500:126.0567,lwr_k=1000:127.1044'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:137.1278,lwr_k=20:142.188,lwr_k=50:140.6155,lwr_k=100:137.1718,lwr_k=200:136.7413,lwr_k=500:134.6697,lwr_k=1000:133.6994'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:138.3375,lwr_k=20:116.3951,lwr_k=50:120.981,lwr_k=100:123.8039,lwr_k=200:127.1504,lwr_k=500:128.6445,lwr_k=1000:129.901'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:135.8632,lwr_k=20:135.5624,lwr_k=50:134.0217,lwr_k=100:133.2321,lwr_k=200:129.4096,lwr_k=500:127.4871,lwr_k=1000:127.3801'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:140.208,lwr_k=20:122.9121,lwr_k=50:130.7381,lwr_k=100:133.156,lwr_k=200:134.8949,lwr_k=500:136.3718,lwr_k=1000:137.2733'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:1188.2673,lwr_k=20:533.0,lwr_k=50:788.1901,lwr_k=100:794.7496,lwr_k=200:1023.2384,lwr_k=500:1077.3552,lwr_k=1000:1282.9537'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:138.2061,lwr_k=20:118.3251,lwr_k=50:124.7606,lwr_k=100:127.2286,lwr_k=200:129.187,lwr_k=500:131.4935,lwr_k=1000:133.0405'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:143.991,lwr_k=20:150.0392,lwr_k=50:145.6038,lwr_k=100:144.8653,lwr_k=200:144.1683,lwr_k=500:143.4269,lwr_k=1000:143.4329'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_51'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:124.1124,lwr_k=20:45.3635,lwr_k=50:71.4476,lwr_k=100:86.2131,lwr_k=200:98.937,lwr_k=500:108.8122,lwr_k=1000:114.0019'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:127.5381,lwr_k=20:226.0184,lwr_k=50:151.4336,lwr_k=100:146.5703,lwr_k=200:138.614,lwr_k=500:129.7332,lwr_k=1000:122.9032'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:130.7681,lwr_k=20:56.8802,lwr_k=50:79.4532,lwr_k=100:92.6063,lwr_k=200:102.683,lwr_k=500:110.6025,lwr_k=1000:116.2573'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.2232,lwr_k=20:174.1609,lwr_k=50:156.9826,lwr_k=100:145.4279,lwr_k=200:138.994,lwr_k=500:136.6592,lwr_k=1000:132.2769'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:134.1989,lwr_k=20:69.0211,lwr_k=50:87.0604,lwr_k=100:98.1285,lwr_k=200:105.8807,lwr_k=500:115.075,lwr_k=1000:118.9655'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:138.2833,lwr_k=20:166.9858,lwr_k=50:153.6847,lwr_k=100:144.1166,lwr_k=200:140.5204,lwr_k=500:132.9131,lwr_k=1000:130.0023'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:136.5675,lwr_k=20:71.7453,lwr_k=50:89.2707,lwr_k=100:100.3425,lwr_k=200:108.1527,lwr_k=500:116.3682,lwr_k=1000:120.099'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:141.4899,lwr_k=20:154.6501,lwr_k=50:145.0815,lwr_k=100:140.0223,lwr_k=200:138.4747,lwr_k=500:132.9768,lwr_k=1000:130.2574'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:136.7168,lwr_k=20:85.8397,lwr_k=50:103.2746,lwr_k=100:113.5661,lwr_k=200:120.5158,lwr_k=500:127.9806,lwr_k=1000:130.9575'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:822.0925,lwr_k=20:372.6193,lwr_k=50:1525.4728,lwr_k=100:1189.705,lwr_k=200:1070.3609,lwr_k=500:877.7123,lwr_k=1000:780.4389'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:142.0038,lwr_k=20:76.3575,lwr_k=50:91.9883,lwr_k=100:102.9629,lwr_k=200:111.1775,lwr_k=500:117.9336,lwr_k=1000:120.4076'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.4733,lwr_k=20:165.4953,lwr_k=50:167.0616,lwr_k=100:143.4119,lwr_k=200:135.5896,lwr_k=500:132.4556,lwr_k=1000:130.945'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_52'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:139.779,lwr_k=20:15.5534,lwr_k=50:59.9582,lwr_k=100:89.5749,lwr_k=200:107.925,lwr_k=500:124.6746,lwr_k=1000:130.0056'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:136.1249,lwr_k=20:341.0507,lwr_k=50:221.8637,lwr_k=100:166.4706,lwr_k=200:146.3462,lwr_k=500:134.5154,lwr_k=1000:134.1669'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:147.5226,lwr_k=20:56.8409,lwr_k=50:88.8641,lwr_k=100:105.9314,lwr_k=200:117.6135,lwr_k=500:126.518,lwr_k=1000:132.0699'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:153.3908,lwr_k=20:223.2592,lwr_k=50:185.3714,lwr_k=100:163.9022,lwr_k=200:152.4481,lwr_k=500:145.1158,lwr_k=1000:143.9752'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:132.3408,lwr_k=20:34.0438,lwr_k=50:73.4902,lwr_k=100:95.118,lwr_k=200:106.8765,lwr_k=500:118.4658,lwr_k=1000:123.3056'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.0471,lwr_k=20:243.7561,lwr_k=50:182.2383,lwr_k=100:157.6646,lwr_k=200:148.0778,lwr_k=500:140.4685,lwr_k=1000:136.8297'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:136.4797,lwr_k=20:27.9705,lwr_k=50:68.9442,lwr_k=100:93.5652,lwr_k=200:107.4427,lwr_k=500:119.1153,lwr_k=1000:125.1244'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:138.6143,lwr_k=20:277.0141,lwr_k=50:185.1889,lwr_k=100:155.2032,lwr_k=200:141.6729,lwr_k=500:132.3157,lwr_k=1000:130.255'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:138.4179,lwr_k=20:49.107,lwr_k=50:81.1224,lwr_k=100:99.1705,lwr_k=200:110.0181,lwr_k=500:120.8523,lwr_k=1000:127.2781'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:194.1215,lwr_k=20:391.77,lwr_k=50:275.8823,lwr_k=100:197.7189,lwr_k=200:294.1089,lwr_k=500:348.2699,lwr_k=1000:343.0982'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:139.7347,lwr_k=20:48.4652,lwr_k=50:81.6568,lwr_k=100:97.591,lwr_k=200:108.9219,lwr_k=500:119.1735,lwr_k=1000:124.485'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:145.2438,lwr_k=20:228.0286,lwr_k=50:185.2698,lwr_k=100:163.6517,lwr_k=200:151.0656,lwr_k=500:143.5489,lwr_k=1000:142.7345'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_53'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:159.097,lwr_k=20:137.392,lwr_k=50:142.7497,lwr_k=100:146.475,lwr_k=200:148.7346,lwr_k=500:151.2137,lwr_k=1000:152.9897'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:167.9855,lwr_k=20:175.043,lwr_k=50:168.5857,lwr_k=100:164.0128,lwr_k=200:163.0396,lwr_k=500:163.6338,lwr_k=1000:164.4516'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.1258,lwr_k=20:122.6332,lwr_k=50:128.4207,lwr_k=100:130.4987,lwr_k=200:132.5387,lwr_k=500:135.3324,lwr_k=1000:138.1859'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.3876,lwr_k=20:147.1733,lwr_k=50:142.7597,lwr_k=100:140.9258,lwr_k=200:139.0441,lwr_k=500:139.8672,lwr_k=1000:142.2045'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:138.2888,lwr_k=20:122.2245,lwr_k=50:128.5449,lwr_k=100:131.2508,lwr_k=200:133.0016,lwr_k=500:134.8543,lwr_k=1000:135.8964'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:166.4858,lwr_k=20:153.522,lwr_k=50:151.888,lwr_k=100:148.5778,lwr_k=200:148.968,lwr_k=500:144.4081,lwr_k=1000:144.6233'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:136.2123,lwr_k=20:116.8905,lwr_k=50:123.5557,lwr_k=100:126.61,lwr_k=200:129.2434,lwr_k=500:131.8791,lwr_k=1000:133.7392'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:132.4119,lwr_k=20:135.9003,lwr_k=50:135.1758,lwr_k=100:133.7486,lwr_k=200:133.6257,lwr_k=500:131.8551,lwr_k=1000:131.6986'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.7077,lwr_k=20:127.3977,lwr_k=50:131.8551,lwr_k=100:134.0423,lwr_k=200:136.7007,lwr_k=500:139.027,lwr_k=1000:140.3491'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:6070716641.0497,lwr_k=20:8180.2078,lwr_k=50:498.2464,lwr_k=100:8759.1411,lwr_k=200:18474.3038,lwr_k=500:12611.2236,lwr_k=1000:9433.781'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:134.2246,lwr_k=20:113.9441,lwr_k=50:119.6468,lwr_k=100:122.471,lwr_k=200:125.438,lwr_k=500:128.2737,lwr_k=1000:130.0946'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:137.8359,lwr_k=20:141.8966,lwr_k=50:138.5707,lwr_k=100:139.7177,lwr_k=200:138.6073,lwr_k=500:138.5966,lwr_k=1000:136.7726'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_54'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:141.6826,lwr_k=20:61.6437,lwr_k=50:92.7097,lwr_k=100:107.4842,lwr_k=200:118.571,lwr_k=500:127.2293,lwr_k=1000:132.8059'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:147.0503,lwr_k=20:200.189,lwr_k=50:167.3745,lwr_k=100:148.2173,lwr_k=200:143.7379,lwr_k=500:142.0603,lwr_k=1000:143.0154'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:447.678,lwr_k=20:429.591,lwr_k=50:440.2524,lwr_k=100:442.0726,lwr_k=200:445.3349,lwr_k=500:445.65,lwr_k=1000:445.7672'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:410.9421,lwr_k=20:429.0349,lwr_k=50:417.5401,lwr_k=100:415.2754,lwr_k=200:412.0719,lwr_k=500:410.4029,lwr_k=1000:409.364'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:162.3611,lwr_k=20:74.2739,lwr_k=50:110.7079,lwr_k=100:127.4895,lwr_k=200:137.4975,lwr_k=500:147.9844,lwr_k=1000:151.8146'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:168.1816,lwr_k=20:308.4393,lwr_k=50:208.2797,lwr_k=100:178.6216,lwr_k=200:169.4438,lwr_k=500:163.4353,lwr_k=1000:160.654'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:152.2328,lwr_k=20:59.9431,lwr_k=50:97.5167,lwr_k=100:114.4878,lwr_k=200:124.2785,lwr_k=500:133.8662,lwr_k=1000:138.7012'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:152.664,lwr_k=20:239.148,lwr_k=50:181.1285,lwr_k=100:156.3547,lwr_k=200:147.3446,lwr_k=500:142.2756,lwr_k=1000:143.4575'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:151.8477,lwr_k=20:53.1595,lwr_k=50:89.9351,lwr_k=100:110.1273,lwr_k=200:122.9868,lwr_k=500:134.265,lwr_k=1000:139.2616'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:193.1792,lwr_k=20:368.6301,lwr_k=50:179.3861,lwr_k=100:155.7058,lwr_k=200:149.5842,lwr_k=500:177.9658,lwr_k=1000:194.5075'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:153.9467,lwr_k=20:80.2525,lwr_k=50:108.7039,lwr_k=100:121.746,lwr_k=200:130.3825,lwr_k=500:138.8666,lwr_k=1000:143.3518'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:157.0728,lwr_k=20:216.142,lwr_k=50:184.2361,lwr_k=100:161.087,lwr_k=200:155.2016,lwr_k=500:149.9087,lwr_k=1000:152.382'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_55'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.3055,lwr_k=20:102.5337,lwr_k=50:115.2343,lwr_k=100:121.1837,lwr_k=200:126.0972,lwr_k=500:130.1078,lwr_k=1000:131.5782'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:140.9377,lwr_k=20:151.0715,lwr_k=50:141.7328,lwr_k=100:138.1761,lwr_k=200:137.5225,lwr_k=500:136.4434,lwr_k=1000:138.5957'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:133.0657,lwr_k=20:116.1465,lwr_k=50:122.1232,lwr_k=100:125.596,lwr_k=200:128.1803,lwr_k=500:130.3519,lwr_k=1000:131.3132'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:137.3866,lwr_k=20:148.3788,lwr_k=50:140.7155,lwr_k=100:137.1571,lwr_k=200:133.9006,lwr_k=500:134.3941,lwr_k=1000:134.7976'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:136.4351,lwr_k=20:105.6036,lwr_k=50:118.1031,lwr_k=100:121.7069,lwr_k=200:126.2489,lwr_k=500:130.503,lwr_k=1000:132.7292'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:145.6252,lwr_k=20:159.2108,lwr_k=50:148.9406,lwr_k=100:141.9556,lwr_k=200:140.2384,lwr_k=500:139.5229,lwr_k=1000:140.2691'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:138.2739,lwr_k=20:118.5428,lwr_k=50:126.5983,lwr_k=100:130.2317,lwr_k=200:132.3697,lwr_k=500:134.4996,lwr_k=1000:135.6273'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:138.2585,lwr_k=20:145.7107,lwr_k=50:141.9963,lwr_k=100:139.7445,lwr_k=200:138.2323,lwr_k=500:137.1728,lwr_k=1000:137.4126'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.7474,lwr_k=20:120.162,lwr_k=50:127.0482,lwr_k=100:129.6578,lwr_k=200:132.278,lwr_k=500:133.9231,lwr_k=1000:135.0602'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:140.5025,lwr_k=20:183.0101,lwr_k=50:337.6083,lwr_k=100:315.1422,lwr_k=200:263.1315,lwr_k=500:273.2594,lwr_k=1000:308.8606'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:140.5744,lwr_k=20:119.5947,lwr_k=50:125.1409,lwr_k=100:129.8779,lwr_k=200:132.4288,lwr_k=500:133.5191,lwr_k=1000:134.8126'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:139.1271,lwr_k=20:146.2749,lwr_k=50:142.2973,lwr_k=100:140.4901,lwr_k=200:138.8706,lwr_k=500:137.9999,lwr_k=1000:138.5813'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_56'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:144.3066,lwr_k=20:81.5941,lwr_k=50:104.9582,lwr_k=100:114.7134,lwr_k=200:121.2705,lwr_k=500:128.381,lwr_k=1000:131.8545'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:142.6375,lwr_k=20:168.5055,lwr_k=50:149.7023,lwr_k=100:137.4428,lwr_k=200:133.694,lwr_k=500:133.8441,lwr_k=1000:133.7172'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:167.3536,lwr_k=20:96.7343,lwr_k=50:111.7749,lwr_k=100:118.711,lwr_k=200:123.7207,lwr_k=500:127.384,lwr_k=1000:130.3715'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:160.5683,lwr_k=20:162.0178,lwr_k=50:151.2117,lwr_k=100:143.1328,lwr_k=200:141.1625,lwr_k=500:138.9435,lwr_k=1000:138.5496'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:157.9293,lwr_k=20:81.5406,lwr_k=50:103.3513,lwr_k=100:112.9999,lwr_k=200:119.8745,lwr_k=500:125.3088,lwr_k=1000:128.532'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:175.243,lwr_k=20:174.3238,lwr_k=50:157.6392,lwr_k=100:154.8515,lwr_k=200:141.6045,lwr_k=500:136.2888,lwr_k=1000:137.9222'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:156.4722,lwr_k=20:80.4997,lwr_k=50:102.0006,lwr_k=100:112.344,lwr_k=200:119.0241,lwr_k=500:124.6374,lwr_k=1000:127.614'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:168.4428,lwr_k=20:165.9557,lwr_k=50:142.7312,lwr_k=100:134.6118,lwr_k=200:131.5425,lwr_k=500:134.8814,lwr_k=1000:137.9911'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.3717,lwr_k=20:105.5846,lwr_k=50:118.4173,lwr_k=100:124.5812,lwr_k=200:128.4094,lwr_k=500:132.2748,lwr_k=1000:135.6598'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:441.5907,lwr_k=20:1844.058,lwr_k=50:824.0699,lwr_k=100:978.5861,lwr_k=200:832.0276,lwr_k=500:662.031,lwr_k=1000:531.8161'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:169.3803,lwr_k=20:93.7195,lwr_k=50:110.615,lwr_k=100:116.7971,lwr_k=200:121.3465,lwr_k=500:127.0607,lwr_k=1000:130.74'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:168.1979,lwr_k=20:154.8227,lwr_k=50:140.3964,lwr_k=100:137.9775,lwr_k=200:134.6065,lwr_k=500:135.4863,lwr_k=1000:137.044'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_57'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.4841,lwr_k=20:78.7148,lwr_k=50:103.799,lwr_k=100:113.224,lwr_k=200:119.8722,lwr_k=500:124.9562,lwr_k=1000:128.0877'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:133.4748,lwr_k=20:181.5774,lwr_k=50:146.5565,lwr_k=100:137.6947,lwr_k=200:132.9092,lwr_k=500:128.2901,lwr_k=1000:127.7024'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:167.1471,lwr_k=20:85.7912,lwr_k=50:112.4829,lwr_k=100:121.4911,lwr_k=200:127.2067,lwr_k=500:131.5596,lwr_k=1000:135.0698'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:161.7006,lwr_k=20:178.3325,lwr_k=50:150.5104,lwr_k=100:143.2859,lwr_k=200:141.0191,lwr_k=500:138.7982,lwr_k=1000:139.7279'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:162.612,lwr_k=20:83.6689,lwr_k=50:107.1638,lwr_k=100:116.979,lwr_k=200:121.3764,lwr_k=500:126.7721,lwr_k=1000:129.7055'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:163.5014,lwr_k=20:177.4521,lwr_k=50:167.6333,lwr_k=100:141.7218,lwr_k=200:137.8824,lwr_k=500:135.8969,lwr_k=1000:134.8368'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:154.3535,lwr_k=20:75.4654,lwr_k=50:102.9581,lwr_k=100:111.7753,lwr_k=200:118.4171,lwr_k=500:124.2462,lwr_k=1000:128.2056'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:150.6986,lwr_k=20:170.0771,lwr_k=50:149.5989,lwr_k=100:133.7772,lwr_k=200:129.0392,lwr_k=500:128.1072,lwr_k=1000:129.6766'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:136.9272,lwr_k=20:76.9059,lwr_k=50:103.4035,lwr_k=100:113.7552,lwr_k=200:118.9963,lwr_k=500:123.8315,lwr_k=1000:127.8279'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:724.0709,lwr_k=20:5562.2729,lwr_k=50:876.3769,lwr_k=100:2136.6242,lwr_k=200:1838.0889,lwr_k=500:1190.516,lwr_k=1000:814.3972'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:138.9403,lwr_k=20:71.3286,lwr_k=50:98.5633,lwr_k=100:107.4932,lwr_k=200:112.406,lwr_k=500:116.3446,lwr_k=1000:118.8729'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:139.1928,lwr_k=20:174.5101,lwr_k=50:140.7437,lwr_k=100:131.4911,lwr_k=200:127.1951,lwr_k=500:126.5739,lwr_k=1000:125.4936'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_58'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:409.4867,lwr_k=20:287.8394,lwr_k=50:338.3899,lwr_k=100:357.2269,lwr_k=200:371.2168,lwr_k=500:382.732,lwr_k=1000:390.8977'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:448.3627,lwr_k=20:3824.5853,lwr_k=50:430.6541,lwr_k=100:470.2136,lwr_k=200:459.9266,lwr_k=500:424.0408,lwr_k=1000:438.4628'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:432.6352,lwr_k=20:387.4993,lwr_k=50:404.6434,lwr_k=100:411.9281,lwr_k=200:414.9357,lwr_k=500:416.7792,lwr_k=1000:420.2482'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:19475.1727,lwr_k=20:407.8101,lwr_k=50:398.8463,lwr_k=100:398.8522,lwr_k=200:396.4965,lwr_k=500:394.3884,lwr_k=1000:394.0328'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:433.855,lwr_k=20:366.2144,lwr_k=50:388.7468,lwr_k=100:399.1412,lwr_k=200:408.3764,lwr_k=500:414.5183,lwr_k=1000:414.9616'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:442.8393,lwr_k=20:410.0443,lwr_k=50:412.3282,lwr_k=100:414.6755,lwr_k=200:419.3978,lwr_k=500:422.4408,lwr_k=1000:420.4686'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:288.1634,lwr_k=20:250.4963,lwr_k=50:271.7649,lwr_k=100:280.3933,lwr_k=200:286.0929,lwr_k=500:288.861,lwr_k=1000:291.6806'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:687.9121,lwr_k=20:344.341,lwr_k=50:318.0915,lwr_k=100:307.6955,lwr_k=200:302.8462,lwr_k=500:300.9225,lwr_k=1000:305.1303'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:377.8846,lwr_k=20:352.2518,lwr_k=50:375.4017,lwr_k=100:382.2801,lwr_k=200:386.156,lwr_k=500:389.9877,lwr_k=1000:392.5186'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:394.4307,lwr_k=20:439.6239,lwr_k=50:421.4926,lwr_k=100:418.8133,lwr_k=200:412.5545,lwr_k=500:405.2222,lwr_k=1000:409.1482'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:390.821,lwr_k=20:285.7029,lwr_k=50:337.8372,lwr_k=100:362.1421,lwr_k=200:373.9983,lwr_k=500:385.7319,lwr_k=1000:387.8502'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:390.1099,lwr_k=20:670.6849,lwr_k=50:519.3083,lwr_k=100:2193.0368,lwr_k=200:423.1165,lwr_k=500:461.8184,lwr_k=1000:1397.7882'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_59'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:289.4183,lwr_k=20:0.2168,lwr_k=50:111.4895,lwr_k=100:156.439,lwr_k=200:184.6178,lwr_k=500:215.5271,lwr_k=1000:236.9587'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:319.4818,lwr_k=20:7718.2555,lwr_k=50:365.9858,lwr_k=100:270.6553,lwr_k=200:255.7714,lwr_k=500:262.8471,lwr_k=1000:276.0998'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:171.0747,lwr_k=20:0.2237,lwr_k=50:79.6921,lwr_k=100:107.9444,lwr_k=200:127.2341,lwr_k=500:140.817,lwr_k=1000:147.9667'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:178.0665,lwr_k=20:6730.6212,lwr_k=50:237.3375,lwr_k=100:175.3689,lwr_k=200:161.6523,lwr_k=500:153.0319,lwr_k=1000:155.2992'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:281.1141,lwr_k=20:85.1343,lwr_k=50:145.2866,lwr_k=100:175.9471,lwr_k=200:198.667,lwr_k=500:221.7515,lwr_k=1000:237.5852'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:284.8002,lwr_k=20:399.2937,lwr_k=50:289.5794,lwr_k=100:270.419,lwr_k=200:251.9487,lwr_k=500:252.9873,lwr_k=1000:256.0856'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:368.5447,lwr_k=20:134.7641,lwr_k=50:184.3357,lwr_k=100:215.537,lwr_k=200:238.922,lwr_k=500:269.3653,lwr_k=1000:293.2859'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:362.5704,lwr_k=20:427.0992,lwr_k=50:339.3591,lwr_k=100:314.4357,lwr_k=200:281.9996,lwr_k=500:290.5317,lwr_k=1000:301.394'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:132.2913,lwr_k=20:0.4396,lwr_k=50:63.8536,lwr_k=100:88.1254,lwr_k=200:102.2931,lwr_k=500:114.303,lwr_k=1000:120.9409'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:611.0344,lwr_k=20:3501.8452,lwr_k=50:935.4395,lwr_k=100:246.1113,lwr_k=200:192.5995,lwr_k=500:556.7492,lwr_k=1000:658.3948'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:135.3293,lwr_k=20:0.5173,lwr_k=50:67.1624,lwr_k=100:91.3795,lwr_k=200:105.7222,lwr_k=500:118.0998,lwr_k=1000:123.5603'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:140.8145,lwr_k=20:2579.7333,lwr_k=50:209.9859,lwr_k=100:161.2044,lwr_k=200:145.6105,lwr_k=500:138.3887,lwr_k=1000:135.9368'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_60'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:127.9423,lwr_k=20:105.3977,lwr_k=50:114.36,lwr_k=100:118.667,lwr_k=200:121.5322,lwr_k=500:124.891,lwr_k=1000:125.6439'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:126.3296,lwr_k=20:137.0639,lwr_k=50:131.9015,lwr_k=100:130.2643,lwr_k=200:126.827,lwr_k=500:125.2391,lwr_k=1000:123.6175'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:204.0815,lwr_k=20:112.0311,lwr_k=50:121.3444,lwr_k=100:124.6404,lwr_k=200:127.024,lwr_k=500:129.4859,lwr_k=1000:132.4148'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:161.5767,lwr_k=20:147.6662,lwr_k=50:138.2463,lwr_k=100:137.0002,lwr_k=200:136.0409,lwr_k=500:135.1545,lwr_k=1000:135.2679'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:172.3952,lwr_k=20:113.2971,lwr_k=50:119.789,lwr_k=100:123.1429,lwr_k=200:126.0405,lwr_k=500:129.1938,lwr_k=1000:134.239'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:153.4563,lwr_k=20:145.8022,lwr_k=50:138.7414,lwr_k=100:135.9421,lwr_k=200:133.8321,lwr_k=500:132.3394,lwr_k=1000:132.7177'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:177.6183,lwr_k=20:110.9701,lwr_k=50:118.3856,lwr_k=100:122.0668,lwr_k=200:124.1839,lwr_k=500:127.7639,lwr_k=1000:129.5368'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:154.757,lwr_k=20:138.6282,lwr_k=50:134.3111,lwr_k=100:130.8588,lwr_k=200:128.592,lwr_k=500:128.3324,lwr_k=1000:128.1404'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.2691,lwr_k=20:115.3481,lwr_k=50:123.5302,lwr_k=100:128.0824,lwr_k=200:131.5261,lwr_k=500:133.4087,lwr_k=1000:134.0193'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:592.3306,lwr_k=20:1171.7732,lwr_k=50:305.0836,lwr_k=100:383.8713,lwr_k=200:507.3759,lwr_k=500:617.0541,lwr_k=1000:585.9782'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:151.6748,lwr_k=20:104.631,lwr_k=50:113.5301,lwr_k=100:117.3261,lwr_k=200:119.9375,lwr_k=500:121.3545,lwr_k=1000:122.063'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:152.2,lwr_k=20:143.2002,lwr_k=50:138.1328,lwr_k=100:136.2394,lwr_k=200:133.5386,lwr_k=500:132.3265,lwr_k=1000:131.6096'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_61'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.9939,lwr_k=20:77.9887,lwr_k=50:102.7982,lwr_k=100:113.8643,lwr_k=200:120.3303,lwr_k=500:125.4007,lwr_k=1000:128.5021'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:143.4807,lwr_k=20:187.1944,lwr_k=50:154.8202,lwr_k=100:140.4443,lwr_k=200:138.7298,lwr_k=500:137.9479,lwr_k=1000:138.6087'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:174.7522,lwr_k=20:77.4222,lwr_k=50:104.9763,lwr_k=100:115.6093,lwr_k=200:121.5609,lwr_k=500:127.334,lwr_k=1000:131.9989'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:155.4789,lwr_k=20:174.5393,lwr_k=50:145.5108,lwr_k=100:140.6519,lwr_k=200:138.3984,lwr_k=500:135.4978,lwr_k=1000:135.0004'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:162.6457,lwr_k=20:77.1038,lwr_k=50:100.8634,lwr_k=100:111.579,lwr_k=200:118.0146,lwr_k=500:125.8257,lwr_k=1000:129.9779'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:158.0135,lwr_k=20:186.3542,lwr_k=50:156.6475,lwr_k=100:161.3559,lwr_k=200:142.635,lwr_k=500:139.9243,lwr_k=1000:139.6455'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:192.0667,lwr_k=20:74.2669,lwr_k=50:99.2297,lwr_k=100:110.4295,lwr_k=200:117.4366,lwr_k=500:123.2579,lwr_k=1000:126.6353'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:177.3552,lwr_k=20:173.6624,lwr_k=50:139.3903,lwr_k=100:133.4786,lwr_k=200:130.9891,lwr_k=500:131.806,lwr_k=1000:131.8879'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.1024,lwr_k=20:92.4337,lwr_k=50:111.839,lwr_k=100:120.4588,lwr_k=200:125.6602,lwr_k=500:130.4606,lwr_k=1000:134.1141'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:573.0754,lwr_k=20:2401.6799,lwr_k=50:971.4498,lwr_k=100:750.6086,lwr_k=200:278.5487,lwr_k=500:384.4497,lwr_k=1000:541.8223'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:174.2605,lwr_k=20:71.2269,lwr_k=50:97.8613,lwr_k=100:109.2098,lwr_k=200:116.162,lwr_k=500:122.3146,lwr_k=1000:126.4635'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:168.0385,lwr_k=20:197.8438,lwr_k=50:155.3899,lwr_k=100:143.603,lwr_k=200:138.4689,lwr_k=500:135.867,lwr_k=1000:136.6381'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_62'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:381.6763,lwr_k=20:213.1454,lwr_k=50:233.7599,lwr_k=100:249.2901,lwr_k=200:265.0954,lwr_k=500:291.6559,lwr_k=1000:310.0388'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:419.2758,lwr_k=20:356.8704,lwr_k=50:340.1151,lwr_k=100:336.9856,lwr_k=200:334.1612,lwr_k=500:342.7514,lwr_k=1000:358.7298'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:394.4499,lwr_k=20:219.4836,lwr_k=50:240.737,lwr_k=100:257.8188,lwr_k=200:271.7864,lwr_k=500:296.851,lwr_k=1000:317.7944'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:374.25,lwr_k=20:327.7084,lwr_k=50:308.9305,lwr_k=100:307.6108,lwr_k=200:303.2143,lwr_k=500:305.7258,lwr_k=1000:315.0959'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:396.7409,lwr_k=20:218.747,lwr_k=50:239.2447,lwr_k=100:257.0199,lwr_k=200:273.6629,lwr_k=500:298.0121,lwr_k=1000:320.9949'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:404.0115,lwr_k=20:341.6246,lwr_k=50:343.4797,lwr_k=100:329.9015,lwr_k=200:322.6657,lwr_k=500:326.1993,lwr_k=1000:339.6466'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:395.5579,lwr_k=20:218.6587,lwr_k=50:239.2648,lwr_k=100:262.3287,lwr_k=200:277.4273,lwr_k=500:301.2133,lwr_k=1000:325.0658'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:386.2515,lwr_k=20:328.5583,lwr_k=50:311.4185,lwr_k=100:307.0023,lwr_k=200:300.2955,lwr_k=500:307.3726,lwr_k=1000:322.2882'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:368.1039,lwr_k=20:258.7439,lwr_k=50:318.0607,lwr_k=100:344.5986,lwr_k=200:358.4098,lwr_k=500:367.9848,lwr_k=1000:370.6853'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:1925.3843,lwr_k=20:2436.2084,lwr_k=50:5089.5565,lwr_k=100:5931.4244,lwr_k=200:7945.2976,lwr_k=500:736.7521,lwr_k=1000:544.3717'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:377.695,lwr_k=20:245.3043,lwr_k=50:316.7565,lwr_k=100:343.6417,lwr_k=200:359.5817,lwr_k=500:366.5284,lwr_k=1000:369.9542'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:375.5594,lwr_k=20:559.8721,lwr_k=50:433.5491,lwr_k=100:421.6729,lwr_k=200:406.7032,lwr_k=500:384.9606,lwr_k=1000:376.4009'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_63'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:475.3153,lwr_k=20:476.266,lwr_k=50:478.4367,lwr_k=100:484.6798,lwr_k=200:476.1122,lwr_k=500:476.8619,lwr_k=1000:475.3224'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:502.902,lwr_k=20:502.0021,lwr_k=50:509.3768,lwr_k=100:518.0748,lwr_k=200:505.3931,lwr_k=500:506.8091,lwr_k=1000:503.0688'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:180.3457,lwr_k=20:104.7733,lwr_k=50:115.1106,lwr_k=100:120.9593,lwr_k=200:124.0651,lwr_k=500:126.387,lwr_k=1000:128.3653'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:170.1816,lwr_k=20:146.7555,lwr_k=50:140.705,lwr_k=100:136.8362,lwr_k=200:136.5221,lwr_k=500:135.923,lwr_k=1000:135.2261'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:152.989,lwr_k=20:111.5848,lwr_k=50:116.4246,lwr_k=100:119.6932,lwr_k=200:121.9848,lwr_k=500:124.7848,lwr_k=1000:127.8808'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:153.1033,lwr_k=20:144.2293,lwr_k=50:140.2705,lwr_k=100:138.1784,lwr_k=200:137.0847,lwr_k=500:134.6104,lwr_k=1000:133.7888'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:144.7394,lwr_k=20:110.6677,lwr_k=50:120.21,lwr_k=100:123.9189,lwr_k=200:127.3834,lwr_k=500:130.2042,lwr_k=1000:131.2102'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:139.0544,lwr_k=20:141.2546,lwr_k=50:137.9092,lwr_k=100:134.9569,lwr_k=200:132.6186,lwr_k=500:131.6234,lwr_k=1000:131.1562'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:141.0177,lwr_k=20:113.7728,lwr_k=50:120.774,lwr_k=100:126.5814,lwr_k=200:129.5962,lwr_k=500:133.8867,lwr_k=1000:136.0491'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:902.5347,lwr_k=20:603.4934,lwr_k=50:672.5159,lwr_k=100:985.2641,lwr_k=200:811.4305,lwr_k=500:897.0999,lwr_k=1000:918.669'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:164.6093,lwr_k=20:103.8282,lwr_k=50:111.7625,lwr_k=100:116.9434,lwr_k=200:120.6476,lwr_k=500:124.7385,lwr_k=1000:126.946'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:148.334,lwr_k=20:143.9717,lwr_k=50:137.2311,lwr_k=100:135.101,lwr_k=200:134.6344,lwr_k=500:134.048,lwr_k=1000:133.5207'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_64'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:144.5408,lwr_k=20:122.8086,lwr_k=50:132.8483,lwr_k=100:135.7167,lwr_k=200:138.8091,lwr_k=500:140.6184,lwr_k=1000:141.741'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:145.6225,lwr_k=20:152.9358,lwr_k=50:145.3671,lwr_k=100:144.3965,lwr_k=200:143.9665,lwr_k=500:143.5276,lwr_k=1000:143.7011'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.5722,lwr_k=20:119.3094,lwr_k=50:126.6485,lwr_k=100:132.5674,lwr_k=200:135.6826,lwr_k=500:138.7221,lwr_k=1000:140.4977'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:148.9165,lwr_k=20:159.8054,lwr_k=50:155.836,lwr_k=100:152.5581,lwr_k=200:152.7911,lwr_k=500:148.8285,lwr_k=1000:148.6187'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:147.8216,lwr_k=20:127.5936,lwr_k=50:133.8679,lwr_k=100:137.8407,lwr_k=200:140.0433,lwr_k=500:143.0437,lwr_k=1000:143.941'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:148.2941,lwr_k=20:157.1857,lwr_k=50:148.5498,lwr_k=100:145.2321,lwr_k=200:144.7415,lwr_k=500:145.3337,lwr_k=1000:145.8252'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:161.887,lwr_k=20:137.5653,lwr_k=50:145.9531,lwr_k=100:150.9563,lwr_k=200:155.0378,lwr_k=500:158.4575,lwr_k=1000:159.504'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:155.8483,lwr_k=20:166.5733,lwr_k=50:160.4968,lwr_k=100:158.3967,lwr_k=200:156.6382,lwr_k=500:156.7716,lwr_k=1000:156.4163'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.3555,lwr_k=20:121.1404,lwr_k=50:131.1133,lwr_k=100:135.731,lwr_k=200:137.3859,lwr_k=500:139.4661,lwr_k=1000:140.4748'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:145.6286,lwr_k=20:159.4596,lwr_k=50:147.7119,lwr_k=100:147.612,lwr_k=200:151.2963,lwr_k=500:150.393,lwr_k=1000:149.2216'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:138.1444,lwr_k=20:121.0432,lwr_k=50:127.4006,lwr_k=100:130.4919,lwr_k=200:132.2348,lwr_k=500:134.2819,lwr_k=1000:136.2818'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:140.6893,lwr_k=20:150.4118,lwr_k=50:146.7026,lwr_k=100:142.5516,lwr_k=200:140.0842,lwr_k=500:139.1222,lwr_k=1000:139.4292'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_65'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:133.5632,lwr_k=20:75.8729,lwr_k=50:96.6524,lwr_k=100:107.4556,lwr_k=200:114.6909,lwr_k=500:120.171,lwr_k=1000:124.5467'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:140.8809,lwr_k=20:175.9876,lwr_k=50:152.9084,lwr_k=100:142.3792,lwr_k=200:137.1988,lwr_k=500:135.2008,lwr_k=1000:135.4561'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:130.4155,lwr_k=20:30.0748,lwr_k=50:61.2461,lwr_k=100:79.5182,lwr_k=200:94.5465,lwr_k=500:109.7343,lwr_k=1000:116.2182'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:137.6248,lwr_k=20:221.2962,lwr_k=50:175.2997,lwr_k=100:159.315,lwr_k=200:148.6591,lwr_k=500:135.4772,lwr_k=1000:131.8534'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:127.8407,lwr_k=20:24.3911,lwr_k=50:53.0855,lwr_k=100:74.1267,lwr_k=200:90.0812,lwr_k=500:103.4073,lwr_k=1000:110.2501'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:133.4506,lwr_k=20:227.9488,lwr_k=50:186.0663,lwr_k=100:168.7624,lwr_k=200:141.3481,lwr_k=500:134.042,lwr_k=1000:130.9667'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:127.8708,lwr_k=20:62.3513,lwr_k=50:89.72,lwr_k=100:101.0491,lwr_k=200:109.2788,lwr_k=500:116.3885,lwr_k=1000:120.0039'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:132.9784,lwr_k=20:262.2421,lwr_k=50:164.7819,lwr_k=100:147.0954,lwr_k=200:138.8053,lwr_k=500:134.4594,lwr_k=1000:132.6309'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:129.9323,lwr_k=20:57.1347,lwr_k=50:83.0485,lwr_k=100:96.4223,lwr_k=200:105.564,lwr_k=500:114.0246,lwr_k=1000:118.1065'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:1092.8709,lwr_k=20:700.3351,lwr_k=50:217.1665,lwr_k=100:202.557,lwr_k=200:203.1681,lwr_k=500:181.0733,lwr_k=1000:379.1115'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:135.1428,lwr_k=20:47.1668,lwr_k=50:75.6876,lwr_k=100:90.0134,lwr_k=200:101.6888,lwr_k=500:111.0867,lwr_k=1000:116.2634'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.2654,lwr_k=20:204.1791,lwr_k=50:165.1256,lwr_k=100:151.1623,lwr_k=200:137.9913,lwr_k=500:130.2421,lwr_k=1000:130.9148'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_66'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:149.5286,lwr_k=20:97.7345,lwr_k=50:114.901,lwr_k=100:122.3147,lwr_k=200:130.3261,lwr_k=500:135.8767,lwr_k=1000:139.7307'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:149.0102,lwr_k=20:165.739,lwr_k=50:152.1128,lwr_k=100:141.659,lwr_k=200:142.3351,lwr_k=500:139.6451,lwr_k=1000:141.4716'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:154.6617,lwr_k=20:81.1075,lwr_k=50:108.4856,lwr_k=100:118.925,lwr_k=200:125.2746,lwr_k=500:131.1316,lwr_k=1000:134.707'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:161.9965,lwr_k=20:203.1715,lwr_k=50:165.2397,lwr_k=100:154.8264,lwr_k=200:150.3101,lwr_k=500:149.4932,lwr_k=1000:150.1114'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:167.7783,lwr_k=20:92.963,lwr_k=50:113.2363,lwr_k=100:122.9484,lwr_k=200:128.0947,lwr_k=500:132.1946,lwr_k=1000:135.3981'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:165.8721,lwr_k=20:178.6327,lwr_k=50:159.1684,lwr_k=100:150.782,lwr_k=200:147.155,lwr_k=500:144.2392,lwr_k=1000:144.6477'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:150.0497,lwr_k=20:90.156,lwr_k=50:112.8602,lwr_k=100:122.0464,lwr_k=200:126.4027,lwr_k=500:131.0147,lwr_k=1000:134.1017'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:145.7965,lwr_k=20:190.4178,lwr_k=50:153.9394,lwr_k=100:141.7838,lwr_k=200:136.2754,lwr_k=500:135.9695,lwr_k=1000:135.9373'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:145.1702,lwr_k=20:100.5702,lwr_k=50:117.2192,lwr_k=100:122.82,lwr_k=200:126.9263,lwr_k=500:131.9369,lwr_k=1000:136.1132'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:229.5958,lwr_k=20:163.3315,lwr_k=50:400.1722,lwr_k=100:1158.2607,lwr_k=200:904.0541,lwr_k=500:334.6265,lwr_k=1000:156.6509'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:178.0944,lwr_k=20:84.756,lwr_k=50:110.8536,lwr_k=100:120.4416,lwr_k=200:126.4887,lwr_k=500:132.3499,lwr_k=1000:136.2679'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:161.4795,lwr_k=20:202.9202,lwr_k=50:162.382,lwr_k=100:151.6034,lwr_k=200:146.1314,lwr_k=500:144.4883,lwr_k=1000:144.4828'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_67'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:475.3153,lwr_k=20:476.266,lwr_k=50:478.4367,lwr_k=100:484.6798,lwr_k=200:476.1122,lwr_k=500:476.8619,lwr_k=1000:475.3224'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:502.902,lwr_k=20:502.0021,lwr_k=50:509.3768,lwr_k=100:518.0748,lwr_k=200:505.3931,lwr_k=500:506.8091,lwr_k=1000:503.0688'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:491.678,lwr_k=20:492.0574,lwr_k=50:492.429,lwr_k=100:491.679,lwr_k=200:491.862,lwr_k=500:492.083,lwr_k=1000:491.6993'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:455.1335,lwr_k=20:455.0952,lwr_k=50:455.2948,lwr_k=100:455.0422,lwr_k=200:455.0246,lwr_k=500:455.1069,lwr_k=1000:455.3521'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:495.6637,lwr_k=20:507.1876,lwr_k=50:500.5743,lwr_k=100:496.7399,lwr_k=200:496.8396,lwr_k=500:496.9601,lwr_k=1000:495.704'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:492.4333,lwr_k=20:498.1193,lwr_k=50:493.533,lwr_k=100:491.7255,lwr_k=200:491.7444,lwr_k=500:491.7717,lwr_k=1000:492.1285'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:487.7302,lwr_k=20:494.2196,lwr_k=50:487.7659,lwr_k=100:487.7765,lwr_k=200:487.8225,lwr_k=500:488.2649,lwr_k=1000:487.7051'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:478.8711,lwr_k=20:486.0777,lwr_k=50:479.0071,lwr_k=100:479.0232,lwr_k=200:478.9013,lwr_k=500:479.2361,lwr_k=1000:478.8966'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2848.5194,lwr_k=20:483.2334,lwr_k=50:483.964,lwr_k=100:483.2327,lwr_k=200:484.322,lwr_k=500:483.559,lwr_k=1000:483.2056'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:2834.8004,lwr_k=20:506.0283,lwr_k=50:507.6364,lwr_k=100:506.0286,lwr_k=200:508.1315,lwr_k=500:507.0309,lwr_k=1000:506.0447'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:489.1842,lwr_k=20:504.2956,lwr_k=50:490.9581,lwr_k=100:490.0557,lwr_k=200:488.9875,lwr_k=500:489.249,lwr_k=1000:488.9997'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:480.5973,lwr_k=20:498.4864,lwr_k=50:483.5299,lwr_k=100:482.4274,lwr_k=200:480.8348,lwr_k=500:480.6863,lwr_k=1000:480.8884'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_68'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:131.9155,lwr_k=20:94.947,lwr_k=50:108.7104,lwr_k=100:114.9955,lwr_k=200:118.962,lwr_k=500:122.7657,lwr_k=1000:124.8735'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:137.933,lwr_k=20:152.7895,lwr_k=50:144.6251,lwr_k=100:143.8122,lwr_k=200:138.1953,lwr_k=500:133.6821,lwr_k=1000:132.3187'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.6893,lwr_k=20:108.0771,lwr_k=50:119.4996,lwr_k=100:124.8568,lwr_k=200:128.8077,lwr_k=500:133.13,lwr_k=1000:134.294'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:139.4416,lwr_k=20:152.8597,lwr_k=50:143.0134,lwr_k=100:139.0007,lwr_k=200:138.5318,lwr_k=500:137.9034,lwr_k=1000:135.5155'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:134.5877,lwr_k=20:116.3353,lwr_k=50:124.9314,lwr_k=100:129.2435,lwr_k=200:131.0478,lwr_k=500:132.0016,lwr_k=1000:133.1413'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.0778,lwr_k=20:155.7336,lwr_k=50:148.5144,lwr_k=100:142.7555,lwr_k=200:137.396,lwr_k=500:136.343,lwr_k=1000:135.8195'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:134.0312,lwr_k=20:100.1833,lwr_k=50:113.766,lwr_k=100:121.8277,lwr_k=200:127.3613,lwr_k=500:131.6803,lwr_k=1000:132.8027'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:132.5624,lwr_k=20:149.9665,lwr_k=50:142.0537,lwr_k=100:138.7683,lwr_k=200:136.5084,lwr_k=500:137.4373,lwr_k=1000:132.5511'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.1171,lwr_k=20:124.4113,lwr_k=50:132.517,lwr_k=100:136.2512,lwr_k=200:138.7442,lwr_k=500:140.7466,lwr_k=1000:141.7282'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:24824.6509,lwr_k=20:554.2969,lwr_k=50:803.435,lwr_k=100:794.7577,lwr_k=200:1222.9306,lwr_k=500:2577.3289,lwr_k=1000:2720.4091'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:127.3026,lwr_k=20:104.5181,lwr_k=50:114.4881,lwr_k=100:119.088,lwr_k=200:120.9581,lwr_k=500:123.1441,lwr_k=1000:124.4244'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:134.7552,lwr_k=20:145.08,lwr_k=50:136.3575,lwr_k=100:133.4159,lwr_k=200:131.9603,lwr_k=500:131.8228,lwr_k=1000:131.1084'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_69'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:132.4583,lwr_k=20:86.797,lwr_k=50:110.1753,lwr_k=100:118.8986,lwr_k=200:124.5551,lwr_k=500:128.5065,lwr_k=1000:130.4529'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:136.4973,lwr_k=20:191.4301,lwr_k=50:150.3999,lwr_k=100:141.2984,lwr_k=200:135.0785,lwr_k=500:132.508,lwr_k=1000:133.3917'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.9285,lwr_k=20:98.4685,lwr_k=50:116.8272,lwr_k=100:123.6695,lwr_k=200:127.8956,lwr_k=500:132.0005,lwr_k=1000:133.9352'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:146.3481,lwr_k=20:181.5094,lwr_k=50:157.77,lwr_k=100:152.6132,lwr_k=200:149.6144,lwr_k=500:146.8711,lwr_k=1000:145.6432'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.2577,lwr_k=20:100.6125,lwr_k=50:118.4282,lwr_k=100:123.918,lwr_k=200:127.2322,lwr_k=500:130.148,lwr_k=1000:132.0117'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.4349,lwr_k=20:183.5239,lwr_k=50:151.4635,lwr_k=100:146.7886,lwr_k=200:142.4825,lwr_k=500:140.2481,lwr_k=1000:139.8984'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:141.7246,lwr_k=20:103.7085,lwr_k=50:121.6719,lwr_k=100:127.8738,lwr_k=200:130.6779,lwr_k=500:133.8987,lwr_k=1000:136.084'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:447.9521,lwr_k=20:368.886,lwr_k=50:365.4811,lwr_k=100:326.3224,lwr_k=200:315.9568,lwr_k=500:320.8488,lwr_k=1000:347.3683'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:146.3104,lwr_k=20:100.7255,lwr_k=50:121.6479,lwr_k=100:128.1451,lwr_k=200:131.6101,lwr_k=500:136.3448,lwr_k=1000:139.709'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:244.5617,lwr_k=20:2185.1958,lwr_k=50:2907.2026,lwr_k=100:3386.6854,lwr_k=200:2234.7334,lwr_k=500:2423.6864,lwr_k=1000:2292.3661'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:132.2057,lwr_k=20:110.3421,lwr_k=50:120.4789,lwr_k=100:124.2025,lwr_k=200:126.3068,lwr_k=500:127.7111,lwr_k=1000:128.8848'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:129.9509,lwr_k=20:169.1624,lwr_k=50:144.7586,lwr_k=100:140.5192,lwr_k=200:138.3642,lwr_k=500:138.8286,lwr_k=1000:130.021'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_70'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:158.4514,lwr_k=20:145.4046,lwr_k=50:149.1615,lwr_k=100:151.6149,lwr_k=200:152.4478,lwr_k=500:153.0331,lwr_k=1000:153.1724'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:161.821,lwr_k=20:162.3765,lwr_k=50:158.8933,lwr_k=100:158.3441,lwr_k=200:157.2482,lwr_k=500:157.7101,lwr_k=1000:158.744'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:174.7917,lwr_k=20:138.1683,lwr_k=50:143.6454,lwr_k=100:146.1502,lwr_k=200:149.2169,lwr_k=500:150.5996,lwr_k=1000:152.0547'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:163.6738,lwr_k=20:154.9408,lwr_k=50:153.0548,lwr_k=100:150.2645,lwr_k=200:151.1246,lwr_k=500:152.751,lwr_k=1000:154.1703'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:233.5339,lwr_k=20:149.3343,lwr_k=50:153.8765,lwr_k=100:154.9978,lwr_k=200:157.2601,lwr_k=500:161.3484,lwr_k=1000:167.327'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:235.5446,lwr_k=20:163.1388,lwr_k=50:160.311,lwr_k=100:159.6264,lwr_k=200:159.997,lwr_k=500:160.4721,lwr_k=1000:161.9615'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:182.929,lwr_k=20:151.9142,lwr_k=50:155.6902,lwr_k=100:157.729,lwr_k=200:158.9487,lwr_k=500:159.3527,lwr_k=1000:177.588'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:179.0873,lwr_k=20:165.2738,lwr_k=50:160.3896,lwr_k=100:158.5056,lwr_k=200:157.7804,lwr_k=500:156.9783,lwr_k=1000:173.5281'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:212.792,lwr_k=20:157.8856,lwr_k=50:162.8142,lwr_k=100:163.574,lwr_k=200:164.0004,lwr_k=500:164.2273,lwr_k=1000:164.4024'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:213.0219,lwr_k=20:176.3569,lwr_k=50:185.9296,lwr_k=100:187.2844,lwr_k=200:211.5533,lwr_k=500:216.1518,lwr_k=1000:217.0209'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:159.1086,lwr_k=20:144.1078,lwr_k=50:148.3926,lwr_k=100:150.0258,lwr_k=200:150.7069,lwr_k=500:154.4287,lwr_k=1000:157.4231'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:159.7602,lwr_k=20:165.9352,lwr_k=50:159.4292,lwr_k=100:157.746,lwr_k=200:157.7315,lwr_k=500:157.7907,lwr_k=1000:158.5633'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_71'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:300.2354,lwr_k=20:170.7912,lwr_k=50:187.685,lwr_k=100:198.2737,lwr_k=200:207.1657,lwr_k=500:220.1493,lwr_k=1000:231.901'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:340.1196,lwr_k=20:339.0813,lwr_k=50:316.5046,lwr_k=100:291.7532,lwr_k=200:281.3878,lwr_k=500:270.6597,lwr_k=1000:279.5989'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:306.0404,lwr_k=20:172.3835,lwr_k=50:189.5563,lwr_k=100:199.9376,lwr_k=200:208.5097,lwr_k=500:220.6274,lwr_k=1000:234.1399'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:305.9704,lwr_k=20:297.0942,lwr_k=50:278.6232,lwr_k=100:265.9057,lwr_k=200:256.0632,lwr_k=500:249.7815,lwr_k=1000:249.9374'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:312.47,lwr_k=20:172.7034,lwr_k=50:192.5013,lwr_k=100:202.8723,lwr_k=200:212.6887,lwr_k=500:228.1021,lwr_k=1000:238.5604'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:311.1225,lwr_k=20:313.744,lwr_k=50:290.913,lwr_k=100:270.3137,lwr_k=200:253.698,lwr_k=500:247.928,lwr_k=1000:251.8461'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:313.8722,lwr_k=20:170.4731,lwr_k=50:190.1842,lwr_k=100:202.3044,lwr_k=200:214.5309,lwr_k=500:230.3294,lwr_k=1000:240.7455'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:311.5565,lwr_k=20:298.6687,lwr_k=50:288.5974,lwr_k=100:267.8895,lwr_k=200:253.0762,lwr_k=500:268.3022,lwr_k=1000:267.6413'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:310.4065,lwr_k=20:175.3263,lwr_k=50:191.4372,lwr_k=100:203.1062,lwr_k=200:215.1854,lwr_k=500:228.5895,lwr_k=1000:241.3004'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:329.3025,lwr_k=20:335.7152,lwr_k=50:308.1726,lwr_k=100:300.6358,lwr_k=200:281.3496,lwr_k=500:270.2668,lwr_k=1000:268.7867'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:313.5421,lwr_k=20:175.6894,lwr_k=50:192.532,lwr_k=100:203.6845,lwr_k=200:212.9369,lwr_k=500:224.053,lwr_k=1000:235.8334'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:312.6737,lwr_k=20:307.9579,lwr_k=50:286.6691,lwr_k=100:261.043,lwr_k=200:250.9057,lwr_k=500:246.7324,lwr_k=1000:249.1388'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_72'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:138.6963,lwr_k=20:113.7039,lwr_k=50:123.8769,lwr_k=100:128.6554,lwr_k=200:131.3308,lwr_k=500:133.5726,lwr_k=1000:134.6599'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.139,lwr_k=20:181.7195,lwr_k=50:173.3886,lwr_k=100:163.2088,lwr_k=200:152.8725,lwr_k=500:153.6105,lwr_k=1000:147.1442'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:141.88,lwr_k=20:127.9253,lwr_k=50:132.4026,lwr_k=100:134.4841,lwr_k=200:135.4423,lwr_k=500:137.0459,lwr_k=1000:137.7577'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:149.6677,lwr_k=20:157.8943,lwr_k=50:149.3336,lwr_k=100:147.8772,lwr_k=200:145.599,lwr_k=500:143.2298,lwr_k=1000:143.9091'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:152.6516,lwr_k=20:127.2549,lwr_k=50:137.1,lwr_k=100:139.9611,lwr_k=200:140.6818,lwr_k=500:141.7438,lwr_k=1000:143.1367'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:1695708826.5568,lwr_k=20:175.2999,lwr_k=50:160.1093,lwr_k=100:157.655,lwr_k=200:155.7989,lwr_k=500:155.5208,lwr_k=1000:156.127'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:149.4086,lwr_k=20:132.3565,lwr_k=50:135.9482,lwr_k=100:139.1669,lwr_k=200:141.0821,lwr_k=500:143.1507,lwr_k=1000:144.4516'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:167.3395,lwr_k=20:151.3928,lwr_k=50:145.6964,lwr_k=100:143.3554,lwr_k=200:141.3533,lwr_k=500:140.6375,lwr_k=1000:141.959'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:150.0758,lwr_k=20:127.6024,lwr_k=50:134.7913,lwr_k=100:137.4959,lwr_k=200:141.1756,lwr_k=500:144.2355,lwr_k=1000:145.8647'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:22625.6797,lwr_k=20:581.6354,lwr_k=50:581.293,lwr_k=100:2203.6056,lwr_k=200:1389.7288,lwr_k=500:2362.6881,lwr_k=1000:2083.879'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:143.2984,lwr_k=20:131.5255,lwr_k=50:136.5099,lwr_k=100:138.7765,lwr_k=200:139.1184,lwr_k=500:140.1986,lwr_k=1000:141.2272'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:150.8715,lwr_k=20:158.0912,lwr_k=50:152.5913,lwr_k=100:151.2263,lwr_k=200:149.8676,lwr_k=500:149.8025,lwr_k=1000:150.3209'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_73'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:138.5975,lwr_k=20:14.149,lwr_k=50:63.7776,lwr_k=100:92.8292,lwr_k=200:109.2373,lwr_k=500:120.9384,lwr_k=1000:127.6588'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.4753,lwr_k=20:683.1898,lwr_k=50:261.185,lwr_k=100:202.0472,lwr_k=200:142.1696,lwr_k=500:143.0001,lwr_k=1000:138.4976'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.7439,lwr_k=20:82.9307,lwr_k=50:107.5365,lwr_k=100:117.8398,lwr_k=200:123.6299,lwr_k=500:129.4711,lwr_k=1000:133.564'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:469.838,lwr_k=20:228.2569,lwr_k=50:171.5761,lwr_k=100:148.778,lwr_k=200:140.0847,lwr_k=500:140.1677,lwr_k=1000:140.3588'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:150.256,lwr_k=20:69.1307,lwr_k=50:99.9488,lwr_k=100:112.3652,lwr_k=200:121.1508,lwr_k=500:128.5667,lwr_k=1000:131.4484'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:156.2102,lwr_k=20:314.611,lwr_k=50:201.7235,lwr_k=100:173.7245,lwr_k=200:143.7552,lwr_k=500:138.4961,lwr_k=1000:138.6794'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:155.6172,lwr_k=20:2.813,lwr_k=50:43.6261,lwr_k=100:76.8789,lwr_k=200:99.9162,lwr_k=500:117.5868,lwr_k=1000:124.8043'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:155.327,lwr_k=20:530.1841,lwr_k=50:291.6034,lwr_k=100:168.0937,lwr_k=200:143.2162,lwr_k=500:134.1713,lwr_k=1000:131.853'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.3863,lwr_k=20:15.9266,lwr_k=50:68.9509,lwr_k=100:94.4413,lwr_k=200:107.2964,lwr_k=500:118.4296,lwr_k=1000:123.1537'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:1451.1986,lwr_k=20:775.8217,lwr_k=50:315.7428,lwr_k=100:1861.1889,lwr_k=200:2966.397,lwr_k=500:2337.6222,lwr_k=1000:1967.8633'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:143.1759,lwr_k=20:4.1479,lwr_k=50:44.5062,lwr_k=100:75.7021,lwr_k=200:94.2971,lwr_k=500:106.9933,lwr_k=1000:112.2384'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:147.6031,lwr_k=20:450.0853,lwr_k=50:227.6479,lwr_k=100:162.6316,lwr_k=200:134.5962,lwr_k=500:128.9833,lwr_k=1000:127.2741'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_74'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:129.4003,lwr_k=20:1.9521,lwr_k=50:38.8505,lwr_k=100:75.9835,lwr_k=200:96.7366,lwr_k=500:110.4612,lwr_k=1000:117.0942'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:126.5857,lwr_k=20:345.3012,lwr_k=50:302.3505,lwr_k=100:166.5892,lwr_k=200:132.7427,lwr_k=500:124.9133,lwr_k=1000:123.0528'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.4239,lwr_k=20:0.321,lwr_k=50:33.2491,lwr_k=100:71.4332,lwr_k=200:96.1265,lwr_k=500:113.3933,lwr_k=1000:122.8669'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:143.2133,lwr_k=20:404.5325,lwr_k=50:334.3079,lwr_k=100:189.2775,lwr_k=200:150.4155,lwr_k=500:141.3337,lwr_k=1000:138.1603'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:134.6962,lwr_k=20:2.1795,lwr_k=50:36.6953,lwr_k=100:73.4168,lwr_k=200:93.1156,lwr_k=500:107.3438,lwr_k=1000:114.3569'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:142.4032,lwr_k=20:427.2195,lwr_k=50:272.9229,lwr_k=100:169.485,lwr_k=200:147.0597,lwr_k=500:136.522,lwr_k=1000:134.1446'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:140.8612,lwr_k=20:0.6402,lwr_k=50:33.4543,lwr_k=100:69.5575,lwr_k=200:88.5159,lwr_k=500:106.4474,lwr_k=1000:115.612'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:140.7773,lwr_k=20:350.707,lwr_k=50:313.6433,lwr_k=100:170.9221,lwr_k=200:141.0742,lwr_k=500:127.2835,lwr_k=1000:124.8676'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:130.7502,lwr_k=20:4.0112,lwr_k=50:45.208,lwr_k=100:80.3181,lwr_k=200:100.3784,lwr_k=500:114.8048,lwr_k=1000:120.9786'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:1008.0793,lwr_k=20:2161.0354,lwr_k=50:800.2475,lwr_k=100:251.8054,lwr_k=200:979.6007,lwr_k=500:1046.4079,lwr_k=1000:1009.3317'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:133.6137,lwr_k=20:0.7603,lwr_k=50:34.485,lwr_k=100:71.2178,lwr_k=200:88.9875,lwr_k=500:103.0979,lwr_k=1000:109.8052'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:136.5075,lwr_k=20:364.0796,lwr_k=50:277.538,lwr_k=100:169.7726,lwr_k=200:140.8992,lwr_k=500:128.4666,lwr_k=1000:125.6134'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_75'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:140.1419,lwr_k=20:40.8734,lwr_k=50:77.6893,lwr_k=100:99.3633,lwr_k=200:112.8333,lwr_k=500:125.9374,lwr_k=1000:131.2294'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:154.2337,lwr_k=20:304.5728,lwr_k=50:210.0733,lwr_k=100:174.8901,lwr_k=200:160.9411,lwr_k=500:165.6097,lwr_k=1000:150.7034'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:162.8838,lwr_k=20:53.9839,lwr_k=50:85.5134,lwr_k=100:101.2113,lwr_k=200:111.2732,lwr_k=500:119.9904,lwr_k=1000:124.1479'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:151.31,lwr_k=20:201.5089,lwr_k=50:175.5073,lwr_k=100:161.6523,lwr_k=200:151.0853,lwr_k=500:143.701,lwr_k=1000:137.2369'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:168.8701,lwr_k=20:51.5429,lwr_k=50:84.4904,lwr_k=100:102.5459,lwr_k=200:111.9725,lwr_k=500:120.8174,lwr_k=1000:125.5503'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:148.3444,lwr_k=20:212.1448,lwr_k=50:181.0637,lwr_k=100:156.2864,lwr_k=200:144.7269,lwr_k=500:154.8427,lwr_k=1000:151.0237'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:166.8781,lwr_k=20:49.7858,lwr_k=50:83.5605,lwr_k=100:98.9339,lwr_k=200:111.4287,lwr_k=500:122.6497,lwr_k=1000:128.2298'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:167.0821,lwr_k=20:264.3203,lwr_k=50:195.5637,lwr_k=100:162.2707,lwr_k=200:150.2573,lwr_k=500:137.633,lwr_k=1000:135.3486'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:128.9518,lwr_k=20:49.4875,lwr_k=50:82.3997,lwr_k=100:100.9682,lwr_k=200:112.7376,lwr_k=500:120.4771,lwr_k=1000:124.5306'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:450.9748,lwr_k=20:456.7393,lwr_k=50:528.3616,lwr_k=100:950.5038,lwr_k=200:746.5867,lwr_k=500:616.6874,lwr_k=1000:563.7133'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:136.5906,lwr_k=20:35.3603,lwr_k=50:75.0172,lwr_k=100:94.7149,lwr_k=200:107.3452,lwr_k=500:116.9456,lwr_k=1000:121.2889'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:140.3523,lwr_k=20:261.728,lwr_k=50:188.2359,lwr_k=100:154.6086,lwr_k=200:144.384,lwr_k=500:138.166,lwr_k=1000:136.2785'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_76'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:130.0411,lwr_k=20:57.2285,lwr_k=50:88.7938,lwr_k=100:102.4212,lwr_k=200:111.4846,lwr_k=500:118.8487,lwr_k=1000:122.7299'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:132.9287,lwr_k=20:184.419,lwr_k=50:151.336,lwr_k=100:138.48,lwr_k=200:132.8995,lwr_k=500:131.8682,lwr_k=1000:134.2887'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:139.7359,lwr_k=20:48.3532,lwr_k=50:84.4386,lwr_k=100:101.674,lwr_k=200:110.2349,lwr_k=500:117.9004,lwr_k=1000:123.0339'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.8094,lwr_k=20:214.923,lwr_k=50:171.0052,lwr_k=100:151.3039,lwr_k=200:140.4536,lwr_k=500:136.0952,lwr_k=1000:135.6244'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:128.3099,lwr_k=20:53.4013,lwr_k=50:83.8997,lwr_k=100:98.2917,lwr_k=200:108.8881,lwr_k=500:116.5272,lwr_k=1000:119.3106'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:130.1907,lwr_k=20:187.5379,lwr_k=50:159.8254,lwr_k=100:143.0209,lwr_k=200:137.2501,lwr_k=500:131.2982,lwr_k=1000:131.7037'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:149.7766,lwr_k=20:60.9296,lwr_k=50:86.7677,lwr_k=100:100.8769,lwr_k=200:111.7882,lwr_k=500:119.5271,lwr_k=1000:123.3629'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:137.0288,lwr_k=20:171.1078,lwr_k=50:147.6198,lwr_k=100:139.3019,lwr_k=200:131.0459,lwr_k=500:129.8316,lwr_k=1000:126.3664'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:128.8888,lwr_k=20:54.3879,lwr_k=50:89.9388,lwr_k=100:103.8297,lwr_k=200:111.6989,lwr_k=500:118.338,lwr_k=1000:123.106'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:441.1548,lwr_k=20:310.1322,lwr_k=50:714.1886,lwr_k=100:612.4213,lwr_k=200:801.2101,lwr_k=500:666.0503,lwr_k=1000:538.1848'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:137.1732,lwr_k=20:58.961,lwr_k=50:84.6514,lwr_k=100:99.352,lwr_k=200:108.1572,lwr_k=500:114.7928,lwr_k=1000:117.6981'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:133.4569,lwr_k=20:172.7521,lwr_k=50:148.8865,lwr_k=100:138.5055,lwr_k=200:134.3409,lwr_k=500:130.988,lwr_k=1000:128.0025'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_77'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.1267,lwr_k=20:95.8783,lwr_k=50:114.8091,lwr_k=100:120.8613,lwr_k=200:123.7971,lwr_k=500:127.5809,lwr_k=1000:129.1479'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:137.8615,lwr_k=20:161.5574,lwr_k=50:130.1255,lwr_k=100:125.5931,lwr_k=200:126.9453,lwr_k=500:133.5698,lwr_k=1000:127.1305'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:148.3043,lwr_k=20:113.161,lwr_k=50:123.0784,lwr_k=100:127.1148,lwr_k=200:128.9593,lwr_k=500:131.7185,lwr_k=1000:134.0302'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:143.1025,lwr_k=20:146.6029,lwr_k=50:138.7981,lwr_k=100:134.9508,lwr_k=200:135.4621,lwr_k=500:134.857,lwr_k=1000:135.5603'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:133.5598,lwr_k=20:86.3814,lwr_k=50:104.5477,lwr_k=100:112.054,lwr_k=200:116.9168,lwr_k=500:121.7253,lwr_k=1000:125.0624'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.8118,lwr_k=20:171.9142,lwr_k=50:151.3912,lwr_k=100:153.1317,lwr_k=200:146.8502,lwr_k=500:137.5951,lwr_k=1000:137.3371'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.4098,lwr_k=20:83.7981,lwr_k=50:105.0843,lwr_k=100:113.8361,lwr_k=200:119.7312,lwr_k=500:126.0122,lwr_k=1000:129.4716'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:134.4783,lwr_k=20:180.7448,lwr_k=50:150.5873,lwr_k=100:137.5765,lwr_k=200:131.262,lwr_k=500:129.5031,lwr_k=1000:131.8719'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.4707,lwr_k=20:87.394,lwr_k=50:108.7416,lwr_k=100:116.6339,lwr_k=200:122.0985,lwr_k=500:127.9293,lwr_k=1000:130.7572'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:153.2534,lwr_k=20:234.1572,lwr_k=50:144.4158,lwr_k=100:153.6978,lwr_k=200:132.3918,lwr_k=500:141.5073,lwr_k=1000:140.3006'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:145.471,lwr_k=20:91.4204,lwr_k=50:106.3517,lwr_k=100:113.0722,lwr_k=200:117.1329,lwr_k=500:121.399,lwr_k=1000:123.3892'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:139.7814,lwr_k=20:150.1179,lwr_k=50:138.0838,lwr_k=100:133.2207,lwr_k=200:129.0484,lwr_k=500:126.8883,lwr_k=1000:127.0911'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_78'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:136.1822,lwr_k=20:80.2365,lwr_k=50:101.623,lwr_k=100:110.843,lwr_k=200:117.9588,lwr_k=500:124.9644,lwr_k=1000:127.8169'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:137.0039,lwr_k=20:166.7121,lwr_k=50:143.6131,lwr_k=100:136.9208,lwr_k=200:134.3655,lwr_k=500:133.3433,lwr_k=1000:132.2444'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:146.8671,lwr_k=20:108.0977,lwr_k=50:118.7707,lwr_k=100:122.3608,lwr_k=200:125.2808,lwr_k=500:129.4757,lwr_k=1000:133.5573'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:138.2812,lwr_k=20:160.176,lwr_k=50:146.5818,lwr_k=100:139.0597,lwr_k=200:138.2285,lwr_k=500:136.5058,lwr_k=1000:135.8903'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:167.2132,lwr_k=20:99.6748,lwr_k=50:112.2267,lwr_k=100:117.6023,lwr_k=200:120.7091,lwr_k=500:125.2624,lwr_k=1000:128.154'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:152.9591,lwr_k=20:154.0093,lwr_k=50:143.9327,lwr_k=100:139.5998,lwr_k=200:137.7131,lwr_k=500:136.2883,lwr_k=1000:135.3187'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:169.4775,lwr_k=20:69.3826,lwr_k=50:97.9498,lwr_k=100:112.1338,lwr_k=200:121.3381,lwr_k=500:128.8752,lwr_k=1000:133.9973'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:154.6526,lwr_k=20:193.0369,lwr_k=50:155.9925,lwr_k=100:140.797,lwr_k=200:136.6261,lwr_k=500:132.0998,lwr_k=1000:132.3674'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:134.9608,lwr_k=20:86.9321,lwr_k=50:105.328,lwr_k=100:113.2509,lwr_k=200:118.5358,lwr_k=500:123.685,lwr_k=1000:126.1993'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:346.237,lwr_k=20:169.3421,lwr_k=50:133.5682,lwr_k=100:209.8604,lwr_k=200:161.5227,lwr_k=500:197.4158,lwr_k=1000:268.8077'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:150.5964,lwr_k=20:45.2027,lwr_k=50:86.8852,lwr_k=100:102.9328,lwr_k=200:111.0493,lwr_k=500:118.8517,lwr_k=1000:123.5613'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:149.7368,lwr_k=20:237.7215,lwr_k=50:166.4989,lwr_k=100:153.0723,lwr_k=200:144.0359,lwr_k=500:136.7934,lwr_k=1000:136.7003'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_79'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.6573,lwr_k=20:26.7833,lwr_k=50:74.1674,lwr_k=100:96.9143,lwr_k=200:110.8027,lwr_k=500:121.1768,lwr_k=1000:127.1451'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:134.4328,lwr_k=20:374.0379,lwr_k=50:183.0386,lwr_k=100:158.892,lwr_k=200:141.8782,lwr_k=500:134.7271,lwr_k=1000:136.4297'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:162.6275,lwr_k=20:14.161,lwr_k=50:66.4162,lwr_k=100:95.3344,lwr_k=200:108.7934,lwr_k=500:120.5137,lwr_k=1000:127.2719'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:153.8904,lwr_k=20:404.3444,lwr_k=50:204.5565,lwr_k=100:158.144,lwr_k=200:146.2787,lwr_k=500:134.723,lwr_k=1000:134.0048'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:144.7721,lwr_k=20:21.7259,lwr_k=50:68.3624,lwr_k=100:93.8324,lwr_k=200:107.6753,lwr_k=500:118.2643,lwr_k=1000:124.3163'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:143.9138,lwr_k=20:390.0694,lwr_k=50:219.5341,lwr_k=100:159.5408,lwr_k=200:144.612,lwr_k=500:136.5675,lwr_k=1000:139.1224'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:139.5177,lwr_k=20:39.9935,lwr_k=50:81.8059,lwr_k=100:101.8833,lwr_k=200:113.9343,lwr_k=500:125.0032,lwr_k=1000:130.944'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:137.6199,lwr_k=20:341.8487,lwr_k=50:227.7983,lwr_k=100:177.9545,lwr_k=200:187.0738,lwr_k=500:140.3971,lwr_k=1000:136.022'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:139.7474,lwr_k=20:27.6603,lwr_k=50:71.4337,lwr_k=100:97.3156,lwr_k=200:112.5031,lwr_k=500:122.3895,lwr_k=1000:128.5833'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:723.2115,lwr_k=20:1501.9456,lwr_k=50:2040.6121,lwr_k=100:1279.5951,lwr_k=200:856.5082,lwr_k=500:1748.6169,lwr_k=1000:766.088'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:143.8023,lwr_k=20:37.0421,lwr_k=50:78.5755,lwr_k=100:97.8941,lwr_k=200:110.8418,lwr_k=500:120.7602,lwr_k=1000:125.2025'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:143.6263,lwr_k=20:258.8988,lwr_k=50:179.2734,lwr_k=100:158.3818,lwr_k=200:144.7392,lwr_k=500:134.4522,lwr_k=1000:132.0748'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_80'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:129.6426,lwr_k=20:0.0375,lwr_k=50:8.9081,lwr_k=100:52.8423,lwr_k=200:83.0876,lwr_k=500:107.3148,lwr_k=1000:117.2765'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:130.3979,lwr_k=20:298.205,lwr_k=50:659.1144,lwr_k=100:218.9817,lwr_k=200:147.9959,lwr_k=500:128.2863,lwr_k=1000:126.0465'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:136.1096,lwr_k=20:1.5392,lwr_k=50:23.1076,lwr_k=100:61.1703,lwr_k=200:88.4478,lwr_k=500:105.7246,lwr_k=1000:114.7112'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:143.6746,lwr_k=20:312.6419,lwr_k=50:321.3845,lwr_k=100:193.0083,lwr_k=200:147.5617,lwr_k=500:134.2861,lwr_k=1000:133.2231'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:132.1316,lwr_k=20:5.9513,lwr_k=50:38.1437,lwr_k=100:67.3485,lwr_k=200:88.4611,lwr_k=500:106.5203,lwr_k=1000:114.3608'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:140.2683,lwr_k=20:322.8728,lwr_k=50:258.3313,lwr_k=100:188.8188,lwr_k=200:156.2859,lwr_k=500:137.7123,lwr_k=1000:133.8572'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:131.8651,lwr_k=20:0.8645,lwr_k=50:19.0674,lwr_k=100:57.3239,lwr_k=200:82.8173,lwr_k=500:102.3334,lwr_k=1000:112.2052'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:132.8319,lwr_k=20:523.3569,lwr_k=50:327.6909,lwr_k=100:197.9495,lwr_k=200:143.7031,lwr_k=500:124.3886,lwr_k=1000:124.5634'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:128.4855,lwr_k=20:0.0811,lwr_k=50:9.4363,lwr_k=100:52.948,lwr_k=200:81.4299,lwr_k=500:104.5422,lwr_k=1000:114.0568'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:394.7579,lwr_k=20:469.3774,lwr_k=50:505.8489,lwr_k=100:329.6579,lwr_k=200:1340.8542,lwr_k=500:425.6384,lwr_k=1000:394.7776'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:130.1479,lwr_k=20:1.6833,lwr_k=50:23.3705,lwr_k=100:58.5483,lwr_k=200:83.4289,lwr_k=500:102.1624,lwr_k=1000:110.6656'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:136.4537,lwr_k=20:328.0381,lwr_k=50:292.7759,lwr_k=100:183.5733,lwr_k=200:144.3589,lwr_k=500:129.5049,lwr_k=1000:125.626'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_81'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.8834,lwr_k=20:122.1346,lwr_k=50:127.2533,lwr_k=100:129.4315,lwr_k=200:130.8438,lwr_k=500:132.4798,lwr_k=1000:134.3121'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:137.3874,lwr_k=20:145.3415,lwr_k=50:138.4936,lwr_k=100:137.8794,lwr_k=200:135.6413,lwr_k=500:134.3354,lwr_k=1000:135.7213'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.6338,lwr_k=20:129.8878,lwr_k=50:135.2661,lwr_k=100:136.4006,lwr_k=200:136.9989,lwr_k=500:138.3072,lwr_k=1000:138.935'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:19048.1891,lwr_k=20:149.6546,lwr_k=50:147.5077,lwr_k=100:145.8163,lwr_k=200:143.8189,lwr_k=500:144.7775,lwr_k=1000:143.1358'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:144.4422,lwr_k=20:128.9973,lwr_k=50:133.9922,lwr_k=100:134.892,lwr_k=200:135.6197,lwr_k=500:136.3468,lwr_k=1000:137.2981'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:14280.2627,lwr_k=20:152.0315,lwr_k=50:149.6962,lwr_k=100:145.9316,lwr_k=200:149.2847,lwr_k=500:148.9215,lwr_k=1000:153.3048'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:181.1434,lwr_k=20:154.6678,lwr_k=50:162.6798,lwr_k=100:167.1338,lwr_k=200:168.9506,lwr_k=500:171.1433,lwr_k=1000:172.898'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:7817.7232,lwr_k=20:184.0234,lwr_k=50:173.7758,lwr_k=100:173.4215,lwr_k=200:170.6957,lwr_k=500:172.16,lwr_k=1000:171.0809'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:159.9905,lwr_k=20:140.6858,lwr_k=50:146.5417,lwr_k=100:148.462,lwr_k=200:150.2027,lwr_k=500:151.9471,lwr_k=1000:152.901'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:118478223863.6559,lwr_k=20:5126.9652,lwr_k=50:2054.5249,lwr_k=100:2061.4901,lwr_k=200:1456.8069,lwr_k=500:1043.8042,lwr_k=1000:807.2067'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:139.4758,lwr_k=20:124.1345,lwr_k=50:129.5782,lwr_k=100:132.8536,lwr_k=200:133.9945,lwr_k=500:135.0374,lwr_k=1000:135.633'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:139.8318,lwr_k=20:146.6667,lwr_k=50:147.5848,lwr_k=100:145.1337,lwr_k=200:141.9449,lwr_k=500:138.9411,lwr_k=1000:138.8258'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_82'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:129.3559,lwr_k=20:61.8277,lwr_k=50:88.8948,lwr_k=100:101.8852,lwr_k=200:110.5841,lwr_k=500:117.5903,lwr_k=1000:121.4821'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:129.963,lwr_k=20:198.9229,lwr_k=50:146.7436,lwr_k=100:136.9116,lwr_k=200:134.4362,lwr_k=500:130.187,lwr_k=1000:130.4716'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:126.8215,lwr_k=20:61.4379,lwr_k=50:87.7614,lwr_k=100:99.4525,lwr_k=200:106.7853,lwr_k=500:113.1675,lwr_k=1000:116.9035'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:134.1712,lwr_k=20:183.4197,lwr_k=50:146.5551,lwr_k=100:136.414,lwr_k=200:130.4383,lwr_k=500:127.9603,lwr_k=1000:130.3417'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:129.4017,lwr_k=20:78.4353,lwr_k=50:101.2746,lwr_k=100:109.1779,lwr_k=200:115.9958,lwr_k=500:120.8272,lwr_k=1000:123.1386'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:136.712,lwr_k=20:172.108,lwr_k=50:143.8958,lwr_k=100:135.9881,lwr_k=200:130.9118,lwr_k=500:130.5097,lwr_k=1000:130.1176'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:127.0256,lwr_k=20:66.8328,lwr_k=50:92.0333,lwr_k=100:104.8035,lwr_k=200:113.0893,lwr_k=500:118.2122,lwr_k=1000:121.2497'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:133.9575,lwr_k=20:177.5078,lwr_k=50:152.5453,lwr_k=100:140.8496,lwr_k=200:134.234,lwr_k=500:131.9834,lwr_k=1000:133.4887'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.0415,lwr_k=20:58.3453,lwr_k=50:90.264,lwr_k=100:106.2278,lwr_k=200:113.7559,lwr_k=500:121.1052,lwr_k=1000:124.4431'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:796.043,lwr_k=20:512.656,lwr_k=50:151.4385,lwr_k=100:154.2612,lwr_k=200:549.306,lwr_k=500:638.7502,lwr_k=1000:490.4871'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:129.5326,lwr_k=20:64.9266,lwr_k=50:91.9538,lwr_k=100:103.5867,lwr_k=200:110.5858,lwr_k=500:116.4038,lwr_k=1000:119.7545'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:132.7132,lwr_k=20:183.2398,lwr_k=50:147.3024,lwr_k=100:136.3268,lwr_k=200:136.2427,lwr_k=500:131.8991,lwr_k=1000:130.4474'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_83'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:326.455,lwr_k=20:288.8641,lwr_k=50:309.1732,lwr_k=100:317.2835,lwr_k=200:317.5336,lwr_k=500:312.9819,lwr_k=1000:310.1121'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:363.7696,lwr_k=20:368.3786,lwr_k=50:367.3829,lwr_k=100:368.2439,lwr_k=200:363.6286,lwr_k=500:355.5213,lwr_k=1000:346.7374'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:335.0407,lwr_k=20:299.8824,lwr_k=50:317.8181,lwr_k=100:325.6755,lwr_k=200:327.4089,lwr_k=500:322.4145,lwr_k=1000:319.3556'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:326.0359,lwr_k=20:317.3629,lwr_k=50:321.1428,lwr_k=100:321.0633,lwr_k=200:318.7863,lwr_k=500:311.0222,lwr_k=1000:306.7345'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:337.2771,lwr_k=20:305.8696,lwr_k=50:321.6628,lwr_k=100:329.2748,lwr_k=200:330.7841,lwr_k=500:325.7112,lwr_k=1000:321.3462'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:350.787,lwr_k=20:332.4417,lwr_k=50:339.229,lwr_k=100:343.1543,lwr_k=200:341.1488,lwr_k=500:331.5312,lwr_k=1000:326.8872'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:335.0896,lwr_k=20:302.3675,lwr_k=50:319.8857,lwr_k=100:328.0606,lwr_k=200:329.8878,lwr_k=500:324.9699,lwr_k=1000:321.5542'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:342.585,lwr_k=20:322.8978,lwr_k=50:326.4761,lwr_k=100:325.7682,lwr_k=200:324.6721,lwr_k=500:317.9423,lwr_k=1000:312.4789'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:335.4192,lwr_k=20:300.5729,lwr_k=50:321.2762,lwr_k=100:328.4299,lwr_k=200:328.1115,lwr_k=500:324.2259,lwr_k=1000:321.1525'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:377.3195,lwr_k=20:359.8726,lwr_k=50:356.9847,lwr_k=100:360.6852,lwr_k=200:356.1654,lwr_k=500:347.0477,lwr_k=1000:341.9507'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:338.2164,lwr_k=20:300.7293,lwr_k=50:318.5929,lwr_k=100:326.2907,lwr_k=200:327.4248,lwr_k=500:322.9815,lwr_k=1000:318.3565'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:343.7247,lwr_k=20:348.5511,lwr_k=50:347.4892,lwr_k=100:347.57,lwr_k=200:344.1097,lwr_k=500:334.9137,lwr_k=1000:326.9671'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_84'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:139.72,lwr_k=20:53.4106,lwr_k=50:80.5348,lwr_k=100:96.7955,lwr_k=200:109.6452,lwr_k=500:122.0884,lwr_k=1000:127.7278'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.9173,lwr_k=20:195.176,lwr_k=50:168.3968,lwr_k=100:155.9501,lwr_k=200:148.3671,lwr_k=500:140.8616,lwr_k=1000:139.3064'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.3149,lwr_k=20:23.0538,lwr_k=50:59.7753,lwr_k=100:85.7465,lwr_k=200:103.1559,lwr_k=500:118.5779,lwr_k=1000:126.3402'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:147.8582,lwr_k=20:266.1572,lwr_k=50:204.4583,lwr_k=100:169.9716,lwr_k=200:152.5163,lwr_k=500:141.0624,lwr_k=1000:143.716'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:144.0369,lwr_k=20:7.2832,lwr_k=50:39.965,lwr_k=100:74.4698,lwr_k=200:98.0182,lwr_k=500:114.0187,lwr_k=1000:122.9228'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:149.4169,lwr_k=20:329.3557,lwr_k=50:244.2131,lwr_k=100:188.378,lwr_k=200:158.1664,lwr_k=500:146.6307,lwr_k=1000:144.7673'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:141.311,lwr_k=20:0.5992,lwr_k=50:20.5519,lwr_k=100:68.2285,lwr_k=200:96.4898,lwr_k=500:115.9125,lwr_k=1000:126.1052'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:143.8697,lwr_k=20:347.4728,lwr_k=50:472.8958,lwr_k=100:202.0196,lwr_k=200:160.9181,lwr_k=500:144.4054,lwr_k=1000:139.7478'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:140.6829,lwr_k=20:81.5221,lwr_k=50:98.5663,lwr_k=100:108.3159,lwr_k=200:115.5768,lwr_k=500:123.7281,lwr_k=1000:128.3629'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:233.2946,lwr_k=20:307.8715,lwr_k=50:237.0683,lwr_k=100:227.4261,lwr_k=200:169.8104,lwr_k=500:198.7286,lwr_k=1000:171.9626'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:136.2098,lwr_k=20:52.1489,lwr_k=50:78.6931,lwr_k=100:92.4423,lwr_k=200:104.3168,lwr_k=500:113.8757,lwr_k=1000:120.2508'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:145.0233,lwr_k=20:181.2352,lwr_k=50:156.6426,lwr_k=100:150.3194,lwr_k=200:146.182,lwr_k=500:140.9575,lwr_k=1000:137.373'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_85'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:347.3387,lwr_k=20:321.4172,lwr_k=50:342.5351,lwr_k=100:354.161,lwr_k=200:361.1982,lwr_k=500:359.4859,lwr_k=1000:354.3417'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:381.9382,lwr_k=20:390.5071,lwr_k=50:390.8235,lwr_k=100:396.1672,lwr_k=200:398.8549,lwr_k=500:394.9876,lwr_k=1000:387.8129'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:365.0163,lwr_k=20:328.8147,lwr_k=50:352.1764,lwr_k=100:363.927,lwr_k=200:371.7669,lwr_k=500:370.8862,lwr_k=1000:365.2597'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:341.1045,lwr_k=20:351.6427,lwr_k=50:352.1415,lwr_k=100:355.1652,lwr_k=200:358.4301,lwr_k=500:354.2922,lwr_k=1000:348.6301'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:185.6242,lwr_k=20:33.4503,lwr_k=50:72.7616,lwr_k=100:100.4969,lwr_k=200:117.4318,lwr_k=500:129.7111,lwr_k=1000:135.5044'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:170.1298,lwr_k=20:902.1166,lwr_k=50:422.7847,lwr_k=100:194.6706,lwr_k=200:150.2488,lwr_k=500:145.1373,lwr_k=1000:140.4144'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:364.4443,lwr_k=20:333.4162,lwr_k=50:355.9822,lwr_k=100:364.3712,lwr_k=200:373.0339,lwr_k=500:370.9415,lwr_k=1000:365.3076'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:357.9108,lwr_k=20:360.5235,lwr_k=50:360.4141,lwr_k=100:363.9791,lwr_k=200:365.7691,lwr_k=500:359.8943,lwr_k=1000:352.838'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:360.0261,lwr_k=20:334.7324,lwr_k=50:354.5417,lwr_k=100:364.0219,lwr_k=200:370.6047,lwr_k=500:369.5764,lwr_k=1000:365.2685'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:720.6052,lwr_k=20:388.1854,lwr_k=50:391.4483,lwr_k=100:396.6542,lwr_k=200:399.9061,lwr_k=500:399.1999,lwr_k=1000:397.2824'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:367.7052,lwr_k=20:331.18,lwr_k=50:352.2757,lwr_k=100:363.5207,lwr_k=200:369.8204,lwr_k=500:369.3706,lwr_k=1000:364.1445'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:353.452,lwr_k=20:358.1216,lwr_k=50:359.7568,lwr_k=100:368.1275,lwr_k=200:372.9236,lwr_k=500:370.7759,lwr_k=1000:364.0862'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_86'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:468.1873,lwr_k=20:520.2778,lwr_k=50:470.5699,lwr_k=100:468.8486,lwr_k=200:468.2362,lwr_k=500:468.9177,lwr_k=1000:468.1659'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:1956927.3337,lwr_k=20:534.6773,lwr_k=50:494.0701,lwr_k=100:496.2103,lwr_k=200:494.6596,lwr_k=500:495.8867,lwr_k=1000:493.6593'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:367.545,lwr_k=20:306.8259,lwr_k=50:328.0786,lwr_k=100:336.953,lwr_k=200:338.5858,lwr_k=500:331.8542,lwr_k=1000:328.4879'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:406.4635,lwr_k=20:334.2444,lwr_k=50:333.7789,lwr_k=100:335.4819,lwr_k=200:332.3209,lwr_k=500:324.5893,lwr_k=1000:321.4231'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:495.6637,lwr_k=20:507.1876,lwr_k=50:500.5743,lwr_k=100:496.7399,lwr_k=200:496.8396,lwr_k=500:496.9601,lwr_k=1000:495.704'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:492.4333,lwr_k=20:498.1193,lwr_k=50:493.533,lwr_k=100:491.7255,lwr_k=200:491.7444,lwr_k=500:491.7717,lwr_k=1000:492.1285'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2511078.9792,lwr_k=20:494.2739,lwr_k=50:487.8364,lwr_k=100:487.8469,lwr_k=200:487.8976,lwr_k=500:488.3433,lwr_k=1000:487.7771'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:2512254.1245,lwr_k=20:486.0777,lwr_k=50:479.0071,lwr_k=100:479.0232,lwr_k=200:478.9013,lwr_k=500:479.2361,lwr_k=1000:478.8966'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2848.5194,lwr_k=20:483.2334,lwr_k=50:483.964,lwr_k=100:483.2327,lwr_k=200:484.322,lwr_k=500:483.559,lwr_k=1000:483.2056'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:3877194717197632.5,lwr_k=20:506.0283,lwr_k=50:507.6364,lwr_k=100:506.0286,lwr_k=200:508.1315,lwr_k=500:507.0309,lwr_k=1000:506.0447'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:488.9731,lwr_k=20:504.3084,lwr_k=50:490.9649,lwr_k=100:490.0618,lwr_k=200:488.992,lwr_k=500:489.2524,lwr_k=1000:489.0042'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:480.6363,lwr_k=20:498.3014,lwr_k=50:483.4678,lwr_k=100:482.3458,lwr_k=200:480.737,lwr_k=500:480.6012,lwr_k=1000:480.7724'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_87'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:244.7657,lwr_k=20:136.3738,lwr_k=50:178.973,lwr_k=100:199.8025,lwr_k=200:214.5119,lwr_k=500:230.3829,lwr_k=1000:236.4579'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:260.3259,lwr_k=20:344.3713,lwr_k=50:299.5121,lwr_k=100:277.8075,lwr_k=200:264.151,lwr_k=500:259.249,lwr_k=1000:260.7426'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:393.69,lwr_k=20:337.1946,lwr_k=50:365.2101,lwr_k=100:373.4813,lwr_k=200:379.1683,lwr_k=500:380.841,lwr_k=1000:381.8963'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:364.5363,lwr_k=20:424.648,lwr_k=50:377.9227,lwr_k=100:368.4657,lwr_k=200:360.1038,lwr_k=500:360.7656,lwr_k=1000:355.6379'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:262.7677,lwr_k=20:181.9095,lwr_k=50:219.7535,lwr_k=100:234.9072,lwr_k=200:243.5445,lwr_k=500:252.2905,lwr_k=1000:256.1675'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:271.057,lwr_k=20:348.5289,lwr_k=50:306.435,lwr_k=100:288.261,lwr_k=200:276.6514,lwr_k=500:272.5901,lwr_k=1000:15444.9299'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:278.5746,lwr_k=20:229.2385,lwr_k=50:254.4,lwr_k=100:263.0624,lwr_k=200:267.4841,lwr_k=500:270.6825,lwr_k=1000:272.0471'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:8339.0183,lwr_k=20:304.9725,lwr_k=50:336.0713,lwr_k=100:308.7667,lwr_k=200:403.971,lwr_k=500:291.0171,lwr_k=1000:284.2501'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:243.5603,lwr_k=20:133.4156,lwr_k=50:182.3005,lwr_k=100:203.0904,lwr_k=200:217.4892,lwr_k=500:233.3085,lwr_k=1000:248.4352'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:251.8548,lwr_k=20:328.8662,lwr_k=50:283.4275,lwr_k=100:270.3706,lwr_k=200:260.8196,lwr_k=500:253.1006,lwr_k=1000:288.2592'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:253.6354,lwr_k=20:153.9957,lwr_k=50:191.6625,lwr_k=100:208.5621,lwr_k=200:221.8808,lwr_k=500:235.3285,lwr_k=1000:240.3577'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:263.6154,lwr_k=20:345.6934,lwr_k=50:305.0501,lwr_k=100:284.716,lwr_k=200:274.046,lwr_k=500:271.1515,lwr_k=1000:262.2382'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_88'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:177.6607,lwr_k=20:164.7673,lwr_k=50:170.7637,lwr_k=100:173.0317,lwr_k=200:173.6464,lwr_k=500:174.7743,lwr_k=1000:175.2858'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:179.0364,lwr_k=20:189.4518,lwr_k=50:186.4902,lwr_k=100:183.0523,lwr_k=200:181.1699,lwr_k=500:179.5255,lwr_k=1000:178.6851'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:226.0294,lwr_k=20:136.8001,lwr_k=50:142.9059,lwr_k=100:144.7323,lwr_k=200:147.3267,lwr_k=500:150.2996,lwr_k=1000:157.0988'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:160.5291,lwr_k=20:157.8882,lwr_k=50:154.3174,lwr_k=100:152.3764,lwr_k=200:150.3691,lwr_k=500:149.3687,lwr_k=1000:148.8487'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:495.6637,lwr_k=20:507.1876,lwr_k=50:500.5743,lwr_k=100:496.7399,lwr_k=200:496.8396,lwr_k=500:496.9601,lwr_k=1000:495.704'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:492.4333,lwr_k=20:498.1193,lwr_k=50:493.533,lwr_k=100:491.7255,lwr_k=200:491.7444,lwr_k=500:491.7717,lwr_k=1000:492.1285'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:487.7726,lwr_k=20:494.2739,lwr_k=50:487.8364,lwr_k=100:487.8469,lwr_k=200:487.8976,lwr_k=500:488.3433,lwr_k=1000:487.7771'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:478.8737,lwr_k=20:486.0777,lwr_k=50:479.0071,lwr_k=100:479.0232,lwr_k=200:478.9013,lwr_k=500:479.2361,lwr_k=1000:478.8966'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:483.1622,lwr_k=20:483.2334,lwr_k=50:483.964,lwr_k=100:483.2327,lwr_k=200:484.322,lwr_k=500:483.559,lwr_k=1000:483.2056'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:506.1586,lwr_k=20:506.0283,lwr_k=50:507.6364,lwr_k=100:506.0286,lwr_k=200:508.1315,lwr_k=500:507.0309,lwr_k=1000:506.0447'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:488.9731,lwr_k=20:504.3084,lwr_k=50:490.9649,lwr_k=100:490.0618,lwr_k=200:488.992,lwr_k=500:489.2524,lwr_k=1000:489.0042'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:480.6363,lwr_k=20:498.3014,lwr_k=50:483.4678,lwr_k=100:482.3458,lwr_k=200:480.737,lwr_k=500:480.6012,lwr_k=1000:480.7724'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_89'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:140.6955,lwr_k=20:112.5094,lwr_k=50:124.528,lwr_k=100:130.1797,lwr_k=200:133.2515,lwr_k=500:135.7295,lwr_k=1000:137.3842'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:142.4466,lwr_k=20:157.9309,lwr_k=50:151.3385,lwr_k=100:144.964,lwr_k=200:143.0555,lwr_k=500:142.2378,lwr_k=1000:141.621'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:161.7787,lwr_k=20:98.6021,lwr_k=50:111.9583,lwr_k=100:117.479,lwr_k=200:121.7877,lwr_k=500:125.9767,lwr_k=1000:129.9007'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:152.4526,lwr_k=20:156.7936,lwr_k=50:144.9303,lwr_k=100:139.8038,lwr_k=200:137.3481,lwr_k=500:134.8256,lwr_k=1000:134.0865'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:258.767,lwr_k=20:113.7737,lwr_k=50:123.1367,lwr_k=100:127.9719,lwr_k=200:131.7266,lwr_k=500:135.6057,lwr_k=1000:141.4524'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:180.7445,lwr_k=20:155.9143,lwr_k=50:151.0256,lwr_k=100:146.9454,lwr_k=200:144.2963,lwr_k=500:144.1619,lwr_k=1000:142.2356'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:245.3428,lwr_k=20:102.2031,lwr_k=50:113.9228,lwr_k=100:119.6375,lwr_k=200:123.5997,lwr_k=500:127.8594,lwr_k=1000:132.2593'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:173.6723,lwr_k=20:142.7106,lwr_k=50:132.246,lwr_k=100:128.252,lwr_k=200:128.0322,lwr_k=500:126.522,lwr_k=1000:126.4084'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:138.0722,lwr_k=20:112.799,lwr_k=50:123.0463,lwr_k=100:127.6344,lwr_k=200:131.2402,lwr_k=500:134.2956,lwr_k=1000:136.3311'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:903.2396,lwr_k=20:347.8753,lwr_k=50:691.6571,lwr_k=100:670.543,lwr_k=200:830.3356,lwr_k=500:976.8943,lwr_k=1000:1010.3782'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:243.331,lwr_k=20:120.8549,lwr_k=50:132.2625,lwr_k=100:137.7804,lwr_k=200:142.0486,lwr_k=500:145.5779,lwr_k=1000:149.587'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:177.6245,lwr_k=20:166.3214,lwr_k=50:156.8588,lwr_k=100:154.9969,lwr_k=200:150.4302,lwr_k=500:149.4801,lwr_k=1000:147.7837'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_90'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:163.5565,lwr_k=20:136.6113,lwr_k=50:145.2225,lwr_k=100:150.9687,lwr_k=200:152.7297,lwr_k=500:156.2667,lwr_k=1000:158.7203'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:164.7223,lwr_k=20:183.6025,lwr_k=50:163.9642,lwr_k=100:159.9146,lwr_k=200:159.5259,lwr_k=500:158.3669,lwr_k=1000:159.8656'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:179.348,lwr_k=20:156.7307,lwr_k=50:159.5661,lwr_k=100:162.8577,lwr_k=200:165.5135,lwr_k=500:168.1286,lwr_k=1000:169.4526'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:166.808,lwr_k=20:170.2096,lwr_k=50:163.9389,lwr_k=100:163.4335,lwr_k=200:162.8727,lwr_k=500:160.1935,lwr_k=1000:160.3794'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:146.4176,lwr_k=20:60.6101,lwr_k=50:98.9493,lwr_k=100:113.1103,lwr_k=200:121.5991,lwr_k=500:128.2364,lwr_k=1000:131.5879'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:148.9984,lwr_k=20:236.0278,lwr_k=50:160.588,lwr_k=100:150.716,lwr_k=200:144.0873,lwr_k=500:143.4677,lwr_k=1000:142.9457'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:204.1422,lwr_k=20:81.3906,lwr_k=50:121.1106,lwr_k=100:137.9871,lwr_k=200:146.834,lwr_k=500:155.2706,lwr_k=1000:163.3317'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:168.7891,lwr_k=20:279.851,lwr_k=50:172.691,lwr_k=100:158.865,lwr_k=200:157.0848,lwr_k=500:155.3116,lwr_k=1000:154.6531'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:145.8844,lwr_k=20:69.2865,lwr_k=50:105.1133,lwr_k=100:119.7801,lwr_k=200:126.7918,lwr_k=500:133.5887,lwr_k=1000:137.5168'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:212.3238,lwr_k=20:240.5208,lwr_k=50:278.5579,lwr_k=100:178.4129,lwr_k=200:210.4005,lwr_k=500:210.3906,lwr_k=1000:220.0455'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:147.367,lwr_k=20:103.6888,lwr_k=50:122.1804,lwr_k=100:129.4938,lwr_k=200:134.559,lwr_k=500:138.7795,lwr_k=1000:141.0879'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:154.68,lwr_k=20:174.1756,lwr_k=50:158.1209,lwr_k=100:154.2121,lwr_k=200:148.8878,lwr_k=500:150.5718,lwr_k=1000:150.2654'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_91'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:155.2203,lwr_k=20:59.6843,lwr_k=50:102.0305,lwr_k=100:117.652,lwr_k=200:128.7628,lwr_k=500:139.5243,lwr_k=1000:143.6094'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:164.9599,lwr_k=20:279.9653,lwr_k=50:190.8717,lwr_k=100:159.9834,lwr_k=200:158.3861,lwr_k=500:151.2409,lwr_k=1000:150.9101'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:373.6005,lwr_k=20:316.2256,lwr_k=50:337.0355,lwr_k=100:347.9207,lwr_k=200:353.936,lwr_k=500:353.3705,lwr_k=1000:350.6426'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:333.7739,lwr_k=20:323.5126,lwr_k=50:327.381,lwr_k=100:331.3575,lwr_k=200:334.9148,lwr_k=500:330.6941,lwr_k=1000:325.8144'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:380.7884,lwr_k=20:314.5008,lwr_k=50:340.8045,lwr_k=100:352.8879,lwr_k=200:359.1068,lwr_k=500:359.2428,lwr_k=1000:355.8082'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:367.4762,lwr_k=20:357.3204,lwr_k=50:354.9989,lwr_k=100:358.2734,lwr_k=200:360.1027,lwr_k=500:355.7717,lwr_k=1000:350.8923'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:263.0697,lwr_k=20:95.8364,lwr_k=50:158.3285,lwr_k=100:185.2427,lwr_k=200:202.3939,lwr_k=500:217.8531,lwr_k=1000:225.2331'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:261.5585,lwr_k=20:509.0838,lwr_k=50:305.063,lwr_k=100:273.6853,lwr_k=200:240.3273,lwr_k=500:247.3688,lwr_k=1000:238.6638'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:368.4936,lwr_k=20:309.8527,lwr_k=50:333.4468,lwr_k=100:344.9743,lwr_k=200:350.3263,lwr_k=500:351.1109,lwr_k=1000:348.3576'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:422.3953,lwr_k=20:367.6448,lwr_k=50:374.8453,lwr_k=100:377.0931,lwr_k=200:376.0215,lwr_k=500:372.6995,lwr_k=1000:370.6085'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:378.1967,lwr_k=20:310.1443,lwr_k=50:333.2503,lwr_k=100:344.7646,lwr_k=200:350.4077,lwr_k=500:351.6273,lwr_k=1000:349.2093'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:362.91,lwr_k=20:351.2365,lwr_k=50:350.3896,lwr_k=100:350.8977,lwr_k=200:350.7102,lwr_k=500:349.1429,lwr_k=1000:343.3465'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_92'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:130.9397,lwr_k=20:40.117,lwr_k=50:75.1142,lwr_k=100:93.0726,lwr_k=200:106.6039,lwr_k=500:117.2106,lwr_k=1000:123.2118'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:130.1055,lwr_k=20:210.1147,lwr_k=50:165.0104,lwr_k=100:141.5836,lwr_k=200:130.608,lwr_k=500:126.9406,lwr_k=1000:128.2937'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:136.3734,lwr_k=20:39.4263,lwr_k=50:77.2131,lwr_k=100:98.8156,lwr_k=200:114.5298,lwr_k=500:123.5488,lwr_k=1000:127.8466'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:136.0788,lwr_k=20:236.715,lwr_k=50:185.4294,lwr_k=100:148.2147,lwr_k=200:137.7313,lwr_k=500:134.7424,lwr_k=1000:132.2878'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.5291,lwr_k=20:85.4322,lwr_k=50:101.869,lwr_k=100:110.8398,lwr_k=200:117.2911,lwr_k=500:122.168,lwr_k=1000:124.6581'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.7934,lwr_k=20:166.157,lwr_k=50:154.4143,lwr_k=100:149.2014,lwr_k=200:143.4985,lwr_k=500:140.0428,lwr_k=1000:136.0748'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.8899,lwr_k=20:85.7387,lwr_k=50:100.7802,lwr_k=100:109.2891,lwr_k=200:115.672,lwr_k=500:121.1467,lwr_k=1000:124.3817'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:138.8093,lwr_k=20:149.9748,lwr_k=50:139.1073,lwr_k=100:133.5452,lwr_k=200:132.1531,lwr_k=500:129.0236,lwr_k=1000:128.3391'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:133.8228,lwr_k=20:66.7133,lwr_k=50:93.0032,lwr_k=100:106.0469,lwr_k=200:113.3313,lwr_k=500:122.1844,lwr_k=1000:126.241'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:151.4419,lwr_k=20:201.2497,lwr_k=50:238.6382,lwr_k=100:164.0744,lwr_k=200:260.0461,lwr_k=500:140.5352,lwr_k=1000:130.0258'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:140.7896,lwr_k=20:14.9178,lwr_k=50:61.7625,lwr_k=100:89.623,lwr_k=200:106.4877,lwr_k=500:118.1899,lwr_k=1000:122.0424'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:139.3615,lwr_k=20:337.2413,lwr_k=50:198.6013,lwr_k=100:159.688,lwr_k=200:141.6937,lwr_k=500:133.1468,lwr_k=1000:131.7717'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_93'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:129.3176,lwr_k=20:21.2281,lwr_k=50:53.0042,lwr_k=100:77.5685,lwr_k=200:97.2132,lwr_k=500:112.5447,lwr_k=1000:117.9075'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:133.2008,lwr_k=20:219.7924,lwr_k=50:195.6382,lwr_k=100:165.5824,lwr_k=200:147.8222,lwr_k=500:141.0969,lwr_k=1000:133.401'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:133.0671,lwr_k=20:23.3502,lwr_k=50:56.576,lwr_k=100:81.4244,lwr_k=200:98.1237,lwr_k=500:112.1059,lwr_k=1000:117.3299'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:142.9214,lwr_k=20:233.959,lwr_k=50:204.17,lwr_k=100:177.2353,lwr_k=200:160.9332,lwr_k=500:146.9368,lwr_k=1000:139.9631'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:131.7376,lwr_k=20:12.993,lwr_k=50:46.9327,lwr_k=100:75.2232,lwr_k=200:94.4756,lwr_k=500:109.078,lwr_k=1000:115.8647'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:139.6942,lwr_k=20:489.2324,lwr_k=50:317.5586,lwr_k=100:182.8625,lwr_k=200:155.5555,lwr_k=500:142.8258,lwr_k=1000:139.1185'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:141.6932,lwr_k=20:8.9911,lwr_k=50:41.9849,lwr_k=100:72.4728,lwr_k=200:92.043,lwr_k=500:109.6197,lwr_k=1000:117.1123'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:140.9525,lwr_k=20:300.7741,lwr_k=50:257.3877,lwr_k=100:181.7483,lwr_k=200:154.7508,lwr_k=500:136.3689,lwr_k=1000:129.5571'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:137.2159,lwr_k=20:13.5453,lwr_k=50:46.3841,lwr_k=100:76.2794,lwr_k=200:97.519,lwr_k=500:115.9127,lwr_k=1000:123.0171'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:804.5163,lwr_k=20:426.5985,lwr_k=50:10079.9191,lwr_k=100:1614.8893,lwr_k=200:888.5078,lwr_k=500:1579.2028,lwr_k=1000:1096.5158'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:138.2762,lwr_k=20:28.5583,lwr_k=50:59.6887,lwr_k=100:82.1498,lwr_k=200:99.1115,lwr_k=500:111.4866,lwr_k=1000:117.5749'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:141.6252,lwr_k=20:212.0462,lwr_k=50:178.7891,lwr_k=100:159.2866,lwr_k=200:146.1129,lwr_k=500:135.8403,lwr_k=1000:132.9402'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_94'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:139.0739,lwr_k=20:59.4824,lwr_k=50:90.1628,lwr_k=100:103.7426,lwr_k=200:112.967,lwr_k=500:121.7708,lwr_k=1000:125.6176'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:139.9095,lwr_k=20:202.8376,lwr_k=50:155.5532,lwr_k=100:142.6211,lwr_k=200:135.4691,lwr_k=500:129.6821,lwr_k=1000:130.0985'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:140.1941,lwr_k=20:86.8775,lwr_k=50:104.5086,lwr_k=100:113.3194,lwr_k=200:119.437,lwr_k=500:125.558,lwr_k=1000:128.7153'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:145.3665,lwr_k=20:185.8366,lwr_k=50:164.3665,lwr_k=100:150.7253,lwr_k=200:149.6446,lwr_k=500:141.0741,lwr_k=1000:139.0963'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.0206,lwr_k=20:73.0959,lwr_k=50:96.2262,lwr_k=100:107.1551,lwr_k=200:113.93,lwr_k=500:122.9714,lwr_k=1000:127.0252'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:145.8824,lwr_k=20:165.493,lwr_k=50:156.8949,lwr_k=100:143.6528,lwr_k=200:139.3031,lwr_k=500:135.8784,lwr_k=1000:136.258'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:138.1811,lwr_k=20:98.3609,lwr_k=50:113.3636,lwr_k=100:118.6448,lwr_k=200:123.2087,lwr_k=500:127.8015,lwr_k=1000:130.4405'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:136.2967,lwr_k=20:161.3465,lwr_k=50:145.3915,lwr_k=100:141.3913,lwr_k=200:136.173,lwr_k=500:131.6851,lwr_k=1000:130.5255'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:133.4404,lwr_k=20:97.6725,lwr_k=50:111.4568,lwr_k=100:117.8354,lwr_k=200:121.6949,lwr_k=500:125.4278,lwr_k=1000:128.3435'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:132.2741,lwr_k=20:159.5498,lwr_k=50:148.8017,lwr_k=100:132.3399,lwr_k=200:130.2908,lwr_k=500:130.6127,lwr_k=1000:131.1043'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:153.8606,lwr_k=20:15.2578,lwr_k=50:65.1478,lwr_k=100:92.0869,lwr_k=200:107.2873,lwr_k=500:119.2326,lwr_k=1000:126.002'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:152.9515,lwr_k=20:333.4461,lwr_k=50:200.8714,lwr_k=100:155.8526,lwr_k=200:144.681,lwr_k=500:138.2341,lwr_k=1000:135.6711'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_95'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:475.3153,lwr_k=20:476.266,lwr_k=50:478.4367,lwr_k=100:484.6798,lwr_k=200:476.1122,lwr_k=500:476.8619,lwr_k=1000:475.3224'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:502.902,lwr_k=20:502.0021,lwr_k=50:509.3768,lwr_k=100:518.0748,lwr_k=200:505.3931,lwr_k=500:506.8091,lwr_k=1000:503.0688'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:492.2828,lwr_k=20:492.6794,lwr_k=50:493.0456,lwr_k=100:492.3113,lwr_k=200:492.488,lwr_k=500:492.7045,lwr_k=1000:492.3409'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:455.1291,lwr_k=20:455.0952,lwr_k=50:455.2948,lwr_k=100:455.0422,lwr_k=200:455.0246,lwr_k=500:455.1069,lwr_k=1000:455.3521'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:495.6442,lwr_k=20:507.6224,lwr_k=50:500.4812,lwr_k=100:496.6385,lwr_k=200:496.7375,lwr_k=500:496.8562,lwr_k=1000:495.5894'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:492.4382,lwr_k=20:498.1193,lwr_k=50:493.533,lwr_k=100:491.7255,lwr_k=200:491.7444,lwr_k=500:491.7717,lwr_k=1000:492.1416'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:487.6062,lwr_k=20:494.1356,lwr_k=50:487.6729,lwr_k=100:487.6837,lwr_k=200:487.7271,lwr_k=500:488.1681,lwr_k=1000:487.6115'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:478.8721,lwr_k=20:486.0777,lwr_k=50:479.0071,lwr_k=100:479.0232,lwr_k=200:478.9013,lwr_k=500:479.2361,lwr_k=1000:478.8966'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:483.1039,lwr_k=20:483.177,lwr_k=50:483.8995,lwr_k=100:483.1763,lwr_k=200:484.2562,lwr_k=500:483.4964,lwr_k=1000:483.1488'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:506.1612,lwr_k=20:506.0283,lwr_k=50:507.6364,lwr_k=100:506.0286,lwr_k=200:508.1315,lwr_k=500:507.0309,lwr_k=1000:506.0447'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:488.8467,lwr_k=20:504.2138,lwr_k=50:490.8506,lwr_k=100:489.9444,lwr_k=200:488.8668,lwr_k=500:489.1214,lwr_k=1000:488.8794'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:480.6337,lwr_k=20:498.3014,lwr_k=50:483.4678,lwr_k=100:482.3458,lwr_k=200:480.737,lwr_k=500:480.6012,lwr_k=1000:480.7724'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_96'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:151.1526,lwr_k=20:48.1939,lwr_k=50:87.9894,lwr_k=100:108.0959,lwr_k=200:119.7276,lwr_k=500:129.7696,lwr_k=1000:138.3041'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:149.8695,lwr_k=20:247.4981,lwr_k=50:190.4463,lwr_k=100:162.7346,lwr_k=200:147.297,lwr_k=500:141.8756,lwr_k=1000:143.1309'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:160.4401,lwr_k=20:58.7492,lwr_k=50:99.3531,lwr_k=100:117.6841,lwr_k=200:131.3274,lwr_k=500:140.6223,lwr_k=1000:146.1845'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:163.9016,lwr_k=20:246.2643,lwr_k=50:183.2621,lwr_k=100:167.3497,lwr_k=200:159.4416,lwr_k=500:153.6068,lwr_k=1000:156.9767'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:133.2213,lwr_k=20:115.3416,lwr_k=50:120.7584,lwr_k=100:123.39,lwr_k=200:125.8658,lwr_k=500:128.4591,lwr_k=1000:129.6494'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:6522.7601,lwr_k=20:141.1131,lwr_k=50:138.9986,lwr_k=100:136.3952,lwr_k=200:134.4914,lwr_k=500:132.3432,lwr_k=1000:132.6401'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:157.1455,lwr_k=20:143.326,lwr_k=50:149.277,lwr_k=100:152.4373,lwr_k=200:153.7141,lwr_k=500:155.5039,lwr_k=1000:157.0255'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:68040.947,lwr_k=20:164.7512,lwr_k=50:157.5155,lwr_k=100:157.4888,lwr_k=200:156.1327,lwr_k=500:156.4009,lwr_k=1000:156.008'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:141.6389,lwr_k=20:47.2642,lwr_k=50:84.0409,lwr_k=100:104.9116,lwr_k=200:118.8102,lwr_k=500:128.4853,lwr_k=1000:133.934'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:217.2081,lwr_k=20:215.6431,lwr_k=50:203.6052,lwr_k=100:336.1805,lwr_k=200:244.4261,lwr_k=500:189.8759,lwr_k=1000:186.5557'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:145.1086,lwr_k=20:93.9486,lwr_k=50:114.1443,lwr_k=100:123.7969,lwr_k=200:129.0179,lwr_k=500:134.0414,lwr_k=1000:136.89'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:156.2086,lwr_k=20:180.6261,lwr_k=50:157.383,lwr_k=100:153.6497,lwr_k=200:157.0777,lwr_k=500:155.2981,lwr_k=1000:152.06'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_97'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:152.8576,lwr_k=20:131.7903,lwr_k=50:139.3156,lwr_k=100:141.2198,lwr_k=200:143.6358,lwr_k=500:145.3793,lwr_k=1000:146.2924'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:148.1962,lwr_k=20:152.454,lwr_k=50:144.1299,lwr_k=100:144.1012,lwr_k=200:142.8253,lwr_k=500:142.547,lwr_k=1000:143.2721'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:151.9518,lwr_k=20:137.2732,lwr_k=50:141.7505,lwr_k=100:143.9114,lwr_k=200:145.0895,lwr_k=500:145.877,lwr_k=1000:146.8753'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:146.3303,lwr_k=20:147.7558,lwr_k=50:141.6703,lwr_k=100:140.5218,lwr_k=200:140.0054,lwr_k=500:141.1817,lwr_k=1000:142.1177'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:167.2347,lwr_k=20:136.1986,lwr_k=50:139.9068,lwr_k=100:141.2429,lwr_k=200:143.9207,lwr_k=500:148.7364,lwr_k=1000:149.6324'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:157.7469,lwr_k=20:153.1768,lwr_k=50:146.8533,lwr_k=100:145.817,lwr_k=200:144.9087,lwr_k=500:144.6896,lwr_k=1000:144.7662'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.6503,lwr_k=20:131.2334,lwr_k=50:136.002,lwr_k=100:138.7564,lwr_k=200:139.8682,lwr_k=500:141.8707,lwr_k=1000:142.6241'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:137.9507,lwr_k=20:150.2329,lwr_k=50:141.7517,lwr_k=100:140.1761,lwr_k=200:138.8252,lwr_k=500:138.4701,lwr_k=1000:138.506'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:144.105,lwr_k=20:133.3285,lwr_k=50:137.4923,lwr_k=100:140.1777,lwr_k=200:140.7692,lwr_k=500:141.6806,lwr_k=1000:142.3188'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:267.9741,lwr_k=20:286.432,lwr_k=50:452.9133,lwr_k=100:243.6353,lwr_k=200:340.0115,lwr_k=500:269.4218,lwr_k=1000:280.8762'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:147.902,lwr_k=20:139.097,lwr_k=50:142.8372,lwr_k=100:144.2063,lwr_k=200:144.5914,lwr_k=500:145.1519,lwr_k=1000:145.4671'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:148.9549,lwr_k=20:154.2764,lwr_k=50:149.4135,lwr_k=100:148.5894,lwr_k=200:148.1323,lwr_k=500:147.1061,lwr_k=1000:146.8672'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_98'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.1089,lwr_k=20:0.7726,lwr_k=50:39.3217,lwr_k=100:79.0279,lwr_k=200:102.9166,lwr_k=500:119.17,lwr_k=1000:127.148'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:142.9185,lwr_k=20:389.6249,lwr_k=50:310.1015,lwr_k=100:183.2895,lwr_k=200:153.8595,lwr_k=500:143.7029,lwr_k=1000:140.5649'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.2289,lwr_k=20:15.5402,lwr_k=50:56.1795,lwr_k=100:85.9955,lwr_k=200:105.5927,lwr_k=500:119.996,lwr_k=1000:127.6098'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:151.1349,lwr_k=20:301.8785,lwr_k=50:219.0139,lwr_k=100:168.2704,lwr_k=200:152.3281,lwr_k=500:142.5218,lwr_k=1000:141.5539'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:494.5597,lwr_k=20:505.8828,lwr_k=50:499.3346,lwr_k=100:495.5636,lwr_k=200:495.6608,lwr_k=500:495.7785,lwr_k=1000:494.5846'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:3210529.9429,lwr_k=20:497.2387,lwr_k=50:492.7057,lwr_k=100:490.9499,lwr_k=200:490.9668,lwr_k=500:490.9919,lwr_k=1000:491.3442'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:138.005,lwr_k=20:9.7718,lwr_k=50:51.9124,lwr_k=100:84.4782,lwr_k=200:104.5682,lwr_k=500:118.8143,lwr_k=1000:124.9461'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:133.5212,lwr_k=20:299.7319,lwr_k=50:224.9769,lwr_k=100:164.9457,lwr_k=200:139.7483,lwr_k=500:132.5694,lwr_k=1000:130.897'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:144.1267,lwr_k=20:1.836,lwr_k=50:41.6712,lwr_k=100:82.6873,lwr_k=200:105.5721,lwr_k=500:121.6169,lwr_k=1000:129.5988'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:148.065,lwr_k=20:372.0047,lwr_k=50:286.6443,lwr_k=100:174.6264,lwr_k=200:148.8178,lwr_k=500:141.9171,lwr_k=1000:140.6735'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:140.1637,lwr_k=20:51.5675,lwr_k=50:88.5078,lwr_k=100:107.2356,lwr_k=200:117.0914,lwr_k=500:125.4472,lwr_k=1000:130.3468'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:144.012,lwr_k=20:320.5234,lwr_k=50:173.7126,lwr_k=100:159.9936,lwr_k=200:147.7382,lwr_k=500:144.1301,lwr_k=1000:144.5704'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_99'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:158.1887,lwr_k=20:1.8101,lwr_k=50:44.9112,lwr_k=100:83.7665,lwr_k=200:109.6639,lwr_k=500:130.0423,lwr_k=1000:139.655'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:193.6554,lwr_k=20:1724.8417,lwr_k=50:1528.9619,lwr_k=100:1246.1644,lwr_k=200:646.127,lwr_k=500:597.7519,lwr_k=1000:479.3823'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.6916,lwr_k=20:23.1447,lwr_k=50:67.2072,lwr_k=100:89.9477,lwr_k=200:105.2807,lwr_k=500:118.0496,lwr_k=1000:125.7681'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:142.312,lwr_k=20:618.4201,lwr_k=50:222.2316,lwr_k=100:170.5115,lwr_k=200:230.6575,lwr_k=500:158.6248,lwr_k=1000:138.0195'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135.0555,lwr_k=20:2.2388,lwr_k=50:60.3287,lwr_k=100:85.8595,lwr_k=200:99.5599,lwr_k=500:110.5842,lwr_k=1000:116.5163'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:138.32,lwr_k=20:1185.3386,lwr_k=50:404.0993,lwr_k=100:293.5524,lwr_k=200:270.105,lwr_k=500:131.9826,lwr_k=1000:131.3817'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.2032,lwr_k=20:4.0421,lwr_k=50:42.7264,lwr_k=100:74.193,lwr_k=200:95.9305,lwr_k=500:113.7488,lwr_k=1000:122.1522'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:145.2364,lwr_k=20:2287.8357,lwr_k=50:4402.9315,lwr_k=100:1528.0398,lwr_k=200:708.1248,lwr_k=500:146.0529,lwr_k=1000:138.4449'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.1946,lwr_k=20:7.2094,lwr_k=50:47.7066,lwr_k=100:78.3756,lwr_k=200:98.2014,lwr_k=500:114.7623,lwr_k=1000:123.7573'\n",
      "Tested (test) on 1666 instances with mean losses of: lr:270.7218,lwr_k=20:2252.835,lwr_k=50:2062.8648,lwr_k=100:881.754,lwr_k=200:377.3976,lwr_k=500:227.9404,lwr_k=1000:159.6204'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training DeepLWR with a train loss of lr:139.9783,lwr_k=20:15.763,lwr_k=50:61.8517,lwr_k=100:83.6071,lwr_k=200:97.5506,lwr_k=500:109.841,lwr_k=1000:115.9243'\n",
      "Tested (test) on 1667 instances with mean losses of: lr:148.0003,lwr_k=20:777.0529,lwr_k=50:221.4978,lwr_k=100:164.8656,lwr_k=200:155.7213,lwr_k=500:152.4031,lwr_k=1000:135.6986'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "for deep_name,deep_model in deep_models.items():\n",
    "    logging.getLogger().info(f\"Running model {deep_name}\")\n",
    "    temp_dict = {deep_name:deep_model}\n",
    "\n",
    "    lwr_scheme = DeepLWRScheme_1_to_n(lwr_models = setup_pls_models_slim(nrow),n_neighbours=500,loss_fun_sk = mean_squared_error)\n",
    "    lwr_scores, lwr_preds, _ , _, _= eval.evaluate(temp_dict,dataset,lwr_scheme,logger_name=\"log\",load_fun=load_fun_cv)\n",
    "    lwr_scores_final, lwr_preds_final, _ , _, _= eval.build(temp_dict,dataset,lwr_scheme,logger_name=\"test_log\",load_fun=load_fun_build)\n",
    "\n",
    "    #scores\n",
    "    for k,v in ut.flip_dicts(lwr_scores).items():\n",
    "        dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "        all_scores.append({**dict1,**v})\n",
    "\n",
    "    for k,v in ut.flip_dicts(lwr_scores_final).items():\n",
    "        dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "        all_scores_final.append({**dict1,**v})\n",
    "\n",
    "    lwr_preds['deep'] = deep_preds[deep_name]\n",
    "    lwr_preds_final['deep'] = deep_preds_final[deep_name]\n",
    "\n",
    "    lwr_preds.to_csv(log_dir/deep_name/ f\"predictions.csv\",index=False)\n",
    "    lwr_preds_final.to_csv(log_dir/deep_name/ f\"predictions_test.csv\",index=False)\n",
    "\n",
    "    #preds\n",
    "    # todo save predictions - appending solns\n",
    "    plot_preds_and_res(lwr_preds,name_lambda=lambda x:f\"{deep_name} with {x} predictor\",save_lambda= lambda x:f\"deep_lwr{x}\",save_loc=log_dir/deep_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save scores\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank - model_num - predictor - fold_0 - fold_1 - fold_2 - fold_3 - fold_4 - MSE - R2'\n",
      "0 - random_92 - lwr_k=1000 - 128.29367541273874 - 132.2878162759214 - 136.0747958140062 - 128.33914162337337 - 130.0257629017867 - 131.00467565172946 - 0.7309442832804487'\n",
      "1 - random_94 - lwr_k=1000 - 130.09853270787394 - 139.0962646936272 - 136.2580112112038 - 130.52548236122166 - 131.10428544044666 - 133.41713969938297 - 0.7259895956697016'\n",
      "2 - random_94 - lwr_k=500 - 129.68211801527363 - 141.07412367090282 - 135.87839881474693 - 131.68507334033166 - 130.61272884707176 - 133.7871215839738 - 0.7252297316370889'\n",
      "3 - random_92 - lwr_k=500 - 126.94063624136948 - 134.74239306019643 - 140.0427737964531 - 129.02357136835803 - 140.53516584957904 - 134.25678266764442 - 0.7242651477483565'\n",
      "4 - random_77 - lwr_k=1000 - 127.1304633160302 - 135.56033500747424 - 137.33713764814289 - 131.87186512620235 - 140.30056046450233 - 134.43967722295096 - 0.7238895212646658'\n",
      "5 - random_77 - lwr_k=200 - 126.94529779202357 - 135.4621242825837 - 146.8502000383659 - 131.26199651589314 - 132.39180637608203 - 134.5829463194956 - 0.7235952770381691'\n",
      "6 - random_13 - lwr_k=100 - 130.11715434444025 - 143.77432716505407 - 139.30655226120535 - 130.55370518991717 - 129.6743401621759 - 134.68631295479938 - 0.7233829839729927'\n",
      "7 - random_77 - lwr_k=500 - 133.5697958363202 - 134.85700676028134 - 137.59514513035603 - 129.50314427602467 - 141.50732118186735 - 135.4064589359998 - 0.7219039574256527'\n",
      "8 - random_94 - lwr_k=200 - 135.46912750778966 - 149.64456265038973 - 139.30310729225988 - 136.173021451786 - 130.29077337691285 - 138.17730511634397 - 0.7162132292034474'\n",
      "9 - random_26 - lwr_k=500 - 137.3021272952275 - 134.83910929618537 - 137.43848578072289 - 141.95591433595013 - 142.89154469564542 - 138.88458705640087 - 0.7147606226582375'\n",
      "10 - random_26 - lwr_k=1000 - 137.2161378067891 - 135.60488590649192 - 137.05070094911827 - 143.40136697720072 - 142.86548035735353 - 139.2267769916701 - 0.7140578373734372'\n",
      "11 - random_92 - lr - 130.10545519551644 - 136.0788169382303 - 141.79341204715868 - 138.80929172176303 - 151.44188818168058 - 139.64445760814908 - 0.7132000102991931'\n",
      "12 - random_13 - lwr_k=500 - 126.48314900079954 - 136.4657508917983 - 132.42773161503868 - 128.09304797588098 - 176.1540661478548 - 139.92182129525665 - 0.712630364328502'\n",
      "13 - random_94 - lr - 139.90949070577778 - 145.36653102019295 - 145.8823933394144 - 136.2966843469217 - 132.27408827525932 - 139.94719610015005 - 0.7125782498808058'\n",
      "14 - random_55 - lr - 140.93765135266312 - 137.38659843873282 - 145.6252094192975 - 138.25847383327854 - 140.50245936155252 - 140.54235727910893 - 0.711355915511656'\n",
      "15 - random_82 - lwr_k=100 - 136.91158492435187 - 136.41399594957207 - 135.9881293758878 - 140.84962547396023 - 154.26115217639898 - 140.88329659809608 - 0.7106556987264794'\n",
      "16 - random_77 - lwr_k=100 - 125.59314984991366 - 134.95076867810312 - 153.13165043828363 - 137.57648299436994 - 153.69780425857087 - 140.9888558778618 - 0.710438902436328'\n",
      "17 - random_46 - lwr_k=500 - 133.07395563678972 - 152.94479462828804 - 137.71869804822643 - 142.75941597745071 - 141.48810175769114 - 141.59686678087417 - 0.7091901774693032'\n",
      "18 - random_46 - lwr_k=1000 - 133.5587133908686 - 152.44363140468428 - 136.67267508695952 - 141.59384310958237 - 144.04642135880388 - 141.662779160984 - 0.7090548074713783'\n",
      "19 - random_78 - lwr_k=200 - 134.365521573624 - 138.22845804174597 - 137.71305292734905 - 136.62611956311062 - 161.5227165563893 - 141.68940168292326 - 0.7090001304784723'\n",
      "20 - random_77 - lr - 137.86147761740222 - 143.10248535355922 - 141.8117838625977 - 134.47831549759755 - 153.25336034306522 - 142.1010610730934 - 0.7081546697213235'\n",
      "21 - random_94 - lwr_k=100 - 142.62108864214133 - 150.72529012450153 - 143.65283929637104 - 141.39132253248314 - 132.33991833437256 - 142.1473591497931 - 0.7080595833272906'\n",
      "22 - random_9 - lwr_k=1000 - 126.7562802770332 - 135.90928590800536 - 134.402355940997 - 125.27825791428504 - 189.71481029852234 - 142.4085776823039 - 0.7075230960673093'\n",
      "23 - random_77 - lwr_k=50 - 130.12551193016665 - 138.79814523473328 - 151.39116279695483 - 150.58734110829306 - 144.41582053196578 - 143.06253116153644 - 0.706180014828561'\n",
      "24 - random_65 - lwr_k=500 - 135.20082990073385 - 135.47720031545882 - 134.0419856418013 - 134.4593787515597 - 181.07333849219748 - 144.04725469379278 - 0.7041576023121849'\n",
      "25 - random_78 - lwr_k=50 - 143.61314189605167 - 146.58176473351557 - 143.93272278413076 - 155.992502186601 - 133.56824419103842 - 144.7376649103302 - 0.7027396466955869'\n",
      "26 - random_48 - lwr_k=200 - 142.79344545989093 - 152.8761284298709 - 137.83434729729836 - 154.4915500229182 - 136.94611432712287 - 144.9881417767908 - 0.7022252205310858'\n",
      "27 - random_26 - lwr_k=200 - 140.72032734575967 - 134.2468315054462 - 139.22589233479425 - 141.7422896902749 - 170.53688026152034 - 145.29184128966193 - 0.7016014863804044'\n",
      "28 - random_36 - lwr_k=500 - 135.14536375029064 - 147.36018158400753 - 145.05930682581717 - 140.53516898384623 - 158.64607046641552 - 145.3482003450196 - 0.7014857368778966'\n",
      "29 - random_46 - lwr_k=200 - 136.74872717579007 - 155.13386210708998 - 138.93677454837632 - 146.13837095442395 - 150.1718816851384 - 145.4252682592362 - 0.7013274557876037'\n",
      "30 - random_34 - lwr_k=500 - 131.29227178381973 - 143.42891258909134 - 135.2634348093683 - 128.7425984864739 - 189.46076735176823 - 145.63436549422428 - 0.7008980145776322'\n",
      "31 - random_66 - lwr_k=1000 - 141.47164862125422 - 150.11139452916916 - 144.64769097636287 - 135.93729364352404 - 156.65089892952898 - 145.7636580602495 - 0.7006324751696273'\n",
      "32 - random_13 - lwr_k=200 - 127.00804674214461 - 136.5708836844879 - 135.1082620862166 - 127.62515780294568 - 202.82972493869886 - 145.8237590983438 - 0.7005090404311373'\n",
      "33 - random_16 - lwr_k=100 - 137.59753580388818 - 148.3141337646751 - 148.98095788105078 - 138.83341516636122 - 155.42384689966522 - 145.82966621390935 - 0.700496908473218'\n",
      "34 - random_11 - lwr_k=500 - 141.8347343656436 - 149.40452819765136 - 148.27283795233834 - 146.79631433943203 - 144.04982243776996 - 146.07180312377045 - 0.6999996108042391'\n",
      "35 - random_23 - lwr_k=500 - 141.7762769956737 - 143.3705634254175 - 141.40990572333186 - 135.01840306424177 - 172.10895687678686 - 146.73518270544903 - 0.6986371703576084'\n",
      "36 - random_34 - lwr_k=200 - 139.08464968627422 - 152.64281839350951 - 140.38558936717533 - 133.02634921439738 - 168.78480297951464 - 146.78385291241307 - 0.6985372121129698'\n",
      "37 - random_17 - lwr_k=200 - 138.86477926978048 - 152.14612943376224 - 135.11738930777435 - 153.12866020688173 - 156.0371823668552 - 147.05702226241587 - 0.6979761804178402'\n",
      "38 - random_9 - lr - 125.62876241640157 - 145.54231284623845 - 135.20959795947914 - 138.63476279169723 - 190.60411684858494 - 147.11971147749702 - 0.6978474301147662'\n",
      "39 - random_78 - lwr_k=500 - 133.34334263853728 - 136.50581297384883 - 136.28833896166833 - 132.0998242168706 - 197.4158396824001 - 147.12640099737592 - 0.6978336912649383'\n",
      "40 - random_23 - lwr_k=1000 - 140.3322934059746 - 143.3940607280212 - 141.97277143843735 - 135.90513570106012 - 174.75248798477256 - 147.26941598342057 - 0.6975399689273161'\n",
      "41 - random_92 - lwr_k=100 - 141.58360767759416 - 148.21474084894217 - 149.2013508777171 - 133.5452357746028 - 164.07444818793644 - 147.3235200274188 - 0.6974288507381146'\n",
      "42 - random_40 - lwr_k=50 - 145.49990666187873 - 150.06572121905202 - 146.5354641483355 - 139.66316784682076 - 155.40383660351094 - 147.43359532305763 - 0.6972027795126876'\n",
      "43 - random_23 - lwr_k=200 - 146.39580224924674 - 145.47819735755667 - 143.37511630983926 - 141.79451454345937 - 160.74066448427394 - 147.55596837792478 - 0.6969514513076398'\n",
      "44 - random_26 - lr - 159.4791938896581 - 137.99443615871948 - 141.3093725824544 - 151.1594677724282 - 147.99374652415582 - 147.58676591908144 - 0.6968881997140008'\n",
      "45 - random_84 - lwr_k=1000 - 139.30637133975387 - 143.7159936728415 - 144.76728314726384 - 139.7478357051424 - 171.96256183086078 - 147.89809981728865 - 0.6962487861609769'\n",
      "46 - random_16 - lwr_k=200 - 136.11171263759869 - 147.50437409888414 - 147.9441378602466 - 137.21176832936658 - 171.89050941113254 - 148.13095993260765 - 0.6957705410532289'\n",
      "47 - random_82 - lwr_k=50 - 146.74364761188696 - 146.55508416262333 - 143.89580949672913 - 152.54530326322933 - 151.43850739360497 - 148.23476885316717 - 0.6955573396282868'\n",
      "48 - random_36 - lwr_k=50 - 138.6104692502527 - 150.0487266123696 - 148.92939900316577 - 143.15700317298857 - 161.84492209791154 - 148.51714810303474 - 0.6949773927593534'\n",
      "49 - random_64 - lwr_k=1000 - 143.7010601228294 - 148.61869804862934 - 145.82515331503623 - 156.41627156169486 - 149.22164184817933 - 148.75558996625915 - 0.6944876839295988'\n",
      "50 - random_64 - lr - 145.62247796897032 - 148.91646570917365 - 148.29411115849695 - 155.84833987764426 - 145.62862374527396 - 148.86155331914821 - 0.6942700577592675'\n",
      "51 - random_64 - lwr_k=500 - 143.52763751586284 - 148.8284883502631 - 145.33365259063913 - 156.7715786065402 - 150.39302369067212 - 148.96976936452455 - 0.6940478050380999'\n",
      "52 - random_46 - lwr_k=100 - 137.41825992551586 - 157.88804889229553 - 142.9782908257448 - 145.97748521310186 - 162.4441070730453 - 149.34006964532935 - 0.6932872870874411'\n",
      "53 - random_64 - lwr_k=100 - 144.39648794015756 - 152.55806369890402 - 145.2320667588573 - 158.39670601417353 - 147.61198933935637 - 149.63825504959934 - 0.6926748777420337'\n",
      "54 - random_64 - lwr_k=200 - 143.966525730698 - 152.7911481558094 - 144.74149529235012 - 156.63819666674453 - 151.29625310578987 - 149.885744430841 - 0.6921665872362242'\n",
      "55 - random_20 - lwr_k=50 - 139.50526149685282 - 148.98059402825788 - 155.8880362190966 - 155.29614648538052 - 150.98091030563106 - 150.12946767687734 - 0.6916660315704259'\n",
      "56 - random_46 - lwr_k=50 - 139.0827783342891 - 159.5171337359671 - 145.4055179568654 - 151.6990832489948 - 155.58950884889623 - 150.25799187451074 - 0.6914020702275347'\n",
      "57 - random_92 - deep - 149.7863853948876 - 145.93155431032324 - 156.71636297435336 - 140.0897447968445 - 161.52492996710404 - 150.80979685544548 - 0.69026877974023'\n",
      "58 - random_34 - lwr_k=1000 - 127.39517920578369 - 140.08154912207684 - 135.75699004396648 - 130.1537065885555 - 220.8091316603375 - 150.83339698169826 - 0.6902203106243125'\n",
      "59 - random_21 - lwr_k=50 - 158.84596399641842 - 149.17817347479334 - 146.3256467417875 - 142.59782676500623 - 157.46204593184615 - 150.88213586895785 - 0.6901202113249669'\n",
      "60 - random_17 - lwr_k=500 - 131.22501659323538 - 145.21994206995666 - 134.59651679770263 - 139.75240654801178 - 204.0542880295164 - 150.9646097155254 - 0.6899508276003903'\n",
      "61 - random_16 - lwr_k=50 - 138.53294307808295 - 150.01634976404839 - 149.62043035249297 - 139.9898358125406 - 177.19618398327262 - 151.06934327916278 - 0.6897357271553958'\n",
      "62 - random_21 - lwr_k=100 - 157.61726630070083 - 148.42801454911074 - 145.58959998299818 - 142.147667221145 - 164.1046334945353 - 151.5770646034582 - 0.6886929756343335'\n",
      "63 - random_64 - lwr_k=50 - 145.3670568948248 - 155.83596472004245 - 148.54983946387827 - 160.4968079384433 - 147.71186286149126 - 151.59170346465376 - 0.6886629105296238'\n",
      "64 - random_77 - deep - 149.30344492472355 - 154.05581730028507 - 150.71130586199655 - 142.0959010679467 - 162.0004903122443 - 151.63329248307116 - 0.6885774950164161'\n",
      "65 - random_26 - lwr_k=100 - 141.87571559261315 - 136.20835230939971 - 138.23976149694366 - 140.96495305656222 - 201.9229240640436 - 151.8376367323881 - 0.688157815949707'\n",
      "66 - random_36 - lwr_k=20 - 148.19783199049766 - 154.95186443798755 - 153.73332518457036 - 147.29714347467535 - 157.83575739640145 - 152.40314531143378 - 0.6869963817086064'\n",
      "67 - random_52 - lr - 136.12485908296026 - 153.390828906037 - 141.04711665628278 - 138.61425354169472 - 194.1215036452002 - 152.65642227493683 - 0.686476204740839'\n",
      "68 - random_55 - deep - 151.6615390651728 - 143.59295324772935 - 155.42177226175858 - 139.12322030863126 - 174.6377567872852 - 152.8864898324671 - 0.6860036944255515'\n",
      "69 - random_16 - lwr_k=500 - 135.89812720874698 - 147.64750975638094 - 146.8498583478378 - 136.8011626162465 - 197.57631073361944 - 152.95117740160694 - 0.6858708404554161'\n",
      "70 - random_48 - lwr_k=500 - 139.5531952243969 - 146.44277310174542 - 132.56760925774145 - 157.1381825228098 - 190.02730179578666 - 153.14090732114673 - 0.6854811755886396'\n",
      "71 - random_78 - lwr_k=100 - 136.92080332743987 - 139.059737665334 - 139.59983382592986 - 140.79702631710398 - 209.86039866994997 - 153.24226027255622 - 0.6852730182015276'\n",
      "72 - random_9 - lwr_k=500 - 128.7426129498137 - 136.7105132988891 - 139.90760871382477 - 129.47467178400808 - 231.56987225384395 - 153.27451764665727 - 0.6852067684217769'\n",
      "73 - random_26 - lwr_k=50 - 145.23910271293786 - 139.96738001966915 - 143.20015300391503 - 146.34903635042318 - 193.84157107922593 - 153.71551827080015 - 0.6843010470159396'\n",
      "74 - random_65 - lwr_k=200 - 137.19881654842814 - 148.65914058883104 - 141.3480733716168 - 138.80534145901774 - 203.16811618013787 - 153.83178126546616 - 0.6840622675738914'\n",
      "75 - random_94 - lwr_k=50 - 155.55315084047567 - 164.36649980531556 - 156.89489112885732 - 145.39152503052713 - 148.80166154571174 - 154.2032509269595 - 0.6832993479642253'\n",
      "76 - random_84 - lwr_k=500 - 140.86160440536153 - 141.0623766764568 - 146.63068137341304 - 144.4054442265593 - 198.7285947045025 - 154.33360508484574 - 0.6830316282725197'\n",
      "77 - random_96 - lwr_k=500 - 141.87557792050134 - 153.60677528083326 - 132.34320939480037 - 156.400930308297 - 189.8758874649711 - 154.81607959414637 - 0.6820407283351473'\n",
      "78 - random_48 - lwr_k=1000 - 137.50944270289997 - 141.57870028798104 - 133.79476146710826 - 141.58228954649974 - 220.5900217139471 - 155.00478486635936 - 0.6816531678758626'\n",
      "79 - random_96 - lwr_k=1000 - 143.13087981576328 - 156.97667293678248 - 132.64005814499305 - 156.0080007375321 - 186.55574398771282 - 155.05837826454518 - 0.6815430984444582'\n",
      "80 - random_11 - lwr_k=200 - 150.81222689068485 - 158.34714054112132 - 165.30820169793577 - 153.01796644276425 - 148.4919506215302 - 155.19656301072774 - 0.6812592963912956'\n",
      "81 - random_16 - lwr_k=1000 - 136.21961337647795 - 147.76394088926213 - 146.5037661273556 - 137.01080411164094 - 208.83877066184252 - 155.2631410857931 - 0.6811225591976389'\n",
      "82 - random_19 - lwr_k=200 - 155.50559278411203 - 140.92914997772414 - 143.3321899759505 - 150.14643899774916 - 187.64356240519632 - 155.50817463232897 - 0.6806193124535393'\n",
      "83 - random_16 - lwr_k=20 - 145.05072893423326 - 152.7510120962623 - 152.34901732952167 - 148.01121805491036 - 180.2586721106271 - 155.68210142828923 - 0.6802621038385719'\n",
      "84 - random_31 - lwr_k=500 - 132.1094209830233 - 147.29892265631563 - 142.56259742267798 - 138.55709372063387 - 219.52512397263288 - 156.00510421545235 - 0.679598724871598'\n",
      "85 - random_26 - deep - 152.9179603082374 - 155.69807050323945 - 162.92541409282535 - 149.69173822483094 - 159.67401021382673 - 156.18179803007624 - 0.679235832851175'\n",
      "86 - random_19 - lwr_k=100 - 156.7185323471171 - 141.20716556432833 - 144.4103154097232 - 151.06491995964464 - 190.69760321753566 - 156.81633239164412 - 0.6779326348844847'\n",
      "87 - random_21 - lwr_k=200 - 156.1173724396196 - 147.8364813547706 - 144.93218033855908 - 141.3670671909517 - 194.5643137873264 - 156.960842386828 - 0.6776358421163342'\n",
      "88 - random_9 - deep - 135.08368860895789 - 143.48132591041607 - 139.16667028837884 - 133.93162227049024 - 234.30959293278468 - 157.1881187495395 - 0.6771690643062189'\n",
      "89 - random_36 - deep - 153.42598242550892 - 159.2710147313036 - 153.72097502229596 - 142.94842591577645 - 177.15910488646142 - 157.3044410172413 - 0.6769301631295719'\n",
      "90 - random_55 - lwr_k=20 - 151.07146350643143 - 148.37878608945704 - 159.21084090045596 - 145.71068874660793 - 183.01011308586502 - 157.4747262342861 - 0.6765804340845172'\n",
      "91 - random_19 - lwr_k=50 - 159.22644500222603 - 142.39898346395705 - 145.61396896231426 - 153.83833490210083 - 186.35691097133437 - 157.48390197269265 - 0.6765615890710768'\n",
      "92 - random_84 - lwr_k=200 - 148.3670890225187 - 152.516272444127 - 158.16643823058803 - 160.91812503217884 - 169.81043881101348 - 157.95389457074847 - 0.6755963243223668'\n",
      "93 - random_34 - lwr_k=100 - 157.7717742883633 - 174.52226813169565 - 145.49419511599893 - 138.14681785108326 - 174.38808549459617 - 158.0650595159619 - 0.6753680151886684'\n",
      "94 - random_34 - deep - 145.80088764046508 - 155.46356770287179 - 161.82697319369439 - 135.26978923893776 - 192.22862609093931 - 158.11661613941757 - 0.6752621283141851'\n",
      "95 - random_64 - lwr_k=20 - 152.93583511248454 - 159.80542215937032 - 157.18570617438039 - 166.57326271088465 - 159.45958934258186 - 159.1910451921216 - 0.6730554802992994'\n",
      "96 - random_16 - lr - 139.93083951648214 - 150.73329803021625 - 147.53401090466167 - 139.0112776362211 - 218.84946460424163 - 159.20704548674283 - 0.6730226191001427'\n",
      "97 - random_23 - lwr_k=100 - 159.02397080257583 - 149.88243100171806 - 151.62997523220642 - 152.18026320277187 - 186.71482235133988 - 159.88399772626857 - 0.6716323033035164'\n",
      "98 - random_46 - lr - 133.91687104820414 - 228.3835014195728 - 137.51828853816124 - 150.3766927473219 - 151.0941707061574 - 160.26019037686254 - 0.670859683679624'\n",
      "99 - random_21 - lwr_k=20 - 162.79969639885175 - 154.79476451422897 - 150.60473608656125 - 149.03793889077068 - 184.14549869718599 - 160.27501121084114 - 0.6708292448415547'\n",
      "100 - random_23 - lr - 146.06145429333014 - 156.90945771644527 - 147.93761741862173 - 142.54861537114618 - 210.54313481867248 - 160.79627677587615 - 0.6697586763331866'\n",
      "101 - random_11 - lwr_k=1000 - 137.36886424291833 - 150.05882949245924 - 142.72826165782183 - 139.24680217104117 - 234.61704654903903 - 160.79768986056848 - 0.669755774158033'\n",
      "102 - random_92 - lwr_k=200 - 130.60795351792626 - 137.7313104413974 - 143.4984859249668 - 132.1530605422051 - 260.0461150760566 - 160.79891463304165 - 0.6697532587360914'\n",
      "103 - random_78 - lwr_k=1000 - 132.2443920659454 - 135.8903235533635 - 135.3187338696065 - 132.36741788737615 - 268.80771917494866 - 160.916198085186 - 0.6695123834916082'\n",
      "104 - random_36 - lwr_k=1000 - 135.19604555319572 - 148.01917823202183 - 145.0230557147615 - 140.00019757369213 - 238.06558106351167 - 161.25414606216808 - 0.6688183102861407'\n",
      "105 - random_52 - deep - 153.21061247726652 - 161.08887334776696 - 159.56217066713916 - 135.80882096490942 - 196.99144260937712 - 161.33116722925163 - 0.6686601246486275'\n",
      "106 - random_42 - lwr_k=20 - 152.54276797879695 - 147.94004028892908 - 156.19348248587988 - 154.15660399589146 - 196.99413739329663 - 161.5620439026339 - 0.6681859536642811'\n",
      "107 - random_94 - deep - 158.4758079771375 - 176.224615986074 - 165.35579195577512 - 164.8231157575335 - 145.5462805575111 - 162.08677923773507 - 0.6671082584283258'\n",
      "108 - random_21 - lwr_k=500 - 156.1799133944278 - 147.3427692840331 - 143.8109332190699 - 142.00736451254576 - 221.266351009318 - 162.11678240256919 - 0.6670466388730381'\n",
      "109 - random_90 - lwr_k=100 - 159.91459692698422 - 163.4335192182847 - 150.71597163562814 - 158.86496634421871 - 178.41287128976106 - 162.26685609371964 - 0.6667384194577206'\n",
      "110 - random_55 - lwr_k=200 - 137.52251089696117 - 133.90063713828607 - 140.23841216031107 - 138.23234439115762 - 263.13153113406025 - 162.59594833445442 - 0.6660625340493773'\n",
      "111 - random_20 - lwr_k=200 - 127.98746020111926 - 134.42556920595345 - 138.3114810001209 - 143.126460270886 - 269.9560974852369 - 162.75090604470088 - 0.6657442838985017'\n",
      "112 - random_70 - lwr_k=100 - 158.34405334026684 - 150.26453575268303 - 159.62640431829385 - 158.50564304812028 - 187.28444092821465 - 162.80259377428504 - 0.6656381283047438'\n",
      "113 - random_97 - lwr_k=100 - 144.1011943943955 - 140.52178938200046 - 145.81701121950508 - 140.1760512878024 - 243.6352897816438 - 162.84329363732923 - 0.6655545394498631'\n",
      "114 - random_84 - lr - 141.91733322770267 - 147.858151098482 - 149.41685149807117 - 143.8696681232429 - 233.29460294330593 - 163.26524653977017 - 0.664687938009698'\n",
      "115 - random_70 - lwr_k=50 - 158.89326201818443 - 153.0548045284573 - 160.3109957230634 - 160.38962243184557 - 185.9295847065764 - 163.71338724303487 - 0.663767552401259'\n",
      "116 - random_13 - lwr_k=50 - 154.50599691373418 - 151.97329474527024 - 145.12630367300284 - 135.51713178698733 - 232.92324507132085 - 164.00434360547192 - 0.6631699899689246'\n",
      "117 - random_65 - lwr_k=100 - 142.37923041085247 - 159.3150348063108 - 168.7623845640123 - 147.09541131642146 - 202.5570398379343 - 164.01922702608624 - 0.6631394225912284'\n",
      "118 - random_55 - lwr_k=500 - 136.44344382341222 - 134.3940660716269 - 139.52290240641008 - 137.172835888852 - 273.25942001734705 - 164.14867942472623 - 0.6628735549210565'\n",
      "119 - random_48 - lr - 140.91970959479332 - 145.83853860314892 - 160.6518506954399 - 160.05285745011864 - 213.45029861231558 - 164.1772342320033 - 0.6628149094253939'\n",
      "120 - random_70 - lwr_k=20 - 162.3765214382194 - 154.9408475448003 - 163.13877625656409 - 165.27375587555048 - 176.35694080512135 - 164.41583280743856 - 0.6623248787421177'\n",
      "121 - random_42 - lr - 143.86653815087328 - 145.65265019596512 - 153.53271213846125 - 149.33873019857987 - 230.06722479903155 - 164.4855201170065 - 0.6621817558426579'\n",
      "122 - random_20 - lwr_k=500 - 127.01232573840507 - 132.8382912337332 - 135.1153117225054 - 141.04434897477745 - 286.48104824678234 - 164.48644124626063 - 0.6621798640392513'\n",
      "123 - random_9 - lwr_k=200 - 145.37527018470502 - 155.0080483799355 - 150.1069788517665 - 145.14259646591935 - 227.2988878619227 - 164.5811638885558 - 0.661985323895661'\n",
      "124 - random_21 - lwr_k=1000 - 156.2976988128734 - 146.86793174057883 - 144.06007004238415 - 141.5861019309633 - 236.2519053544002 - 165.00700384383475 - 0.6611107392764066'\n",
      "125 - random_42 - deep - 148.80899055174316 - 146.7499676929238 - 157.94440538238177 - 149.12542068829484 - 223.2633259465285 - 165.17337648413496 - 0.6607690447199865'\n",
      "126 - random_48 - lwr_k=100 - 151.30159666906556 - 171.6819842224954 - 141.37297706416658 - 165.90647146689963 - 195.72106209858026 - 165.19307008667792 - 0.6607285988216753'\n",
      "127 - random_90 - lwr_k=500 - 158.3669281825186 - 160.19348296125796 - 143.4677392416246 - 155.31156181215854 - 210.39064994087963 - 165.54191905352516 - 0.660012137303527'\n",
      "128 - random_31 - lwr_k=1000 - 129.8801715275206 - 141.61769206938536 - 141.3195826802736 - 130.61407087788126 - 285.04439294354495 - 165.68506944324426 - 0.659718136875581'\n",
      "129 - random_19 - lwr_k=20 - 165.03270420283746 - 146.29153401730673 - 149.98202387255475 - 157.40893129127207 - 209.86703816630813 - 165.7121449687817 - 0.6596625295097156'\n",
      "130 - random_61 - lwr_k=200 - 138.72981772627426 - 138.3984019457739 - 142.6350332480336 - 130.98913799045707 - 278.5487351854406 - 165.85088675492884 - 0.6593775834150433'\n",
      "131 - random_40 - deep - 162.62642228252957 - 159.25255746275062 - 164.4742793933889 - 139.0744205488592 - 204.4171004804815 - 165.9675687698637 - 0.6591379428227044'\n",
      "132 - random_46 - lwr_k=20 - 143.69419084309675 - 163.76748543583784 - 153.20190583874754 - 156.48395169155302 - 214.81228767528015 - 166.3873426347438 - 0.6582758172336916'\n",
      "133 - random_90 - lwr_k=200 - 159.52593848875316 - 162.87270456640337 - 144.08732640349575 - 157.08479826191734 - 210.40048051374114 - 166.79018187061328 - 0.657448471195923'\n",
      "134 - random_97 - lwr_k=500 - 142.5470160580701 - 141.1817321221658 - 144.68958803044796 - 138.4700512696565 - 269.42176224910867 - 167.25322546327527 - 0.6564974782250517'\n",
      "135 - random_70 - lwr_k=200 - 157.2481965225731 - 151.12459733675863 - 159.99696341326325 - 157.78041925366557 - 211.55325504411172 - 167.53657587345646 - 0.6559155367995658'\n",
      "136 - random_90 - lwr_k=1000 - 159.86562380272005 - 160.37935567111774 - 142.94571294883045 - 154.65312235004123 - 220.04554153503497 - 167.57312592117185 - 0.655840470781996'\n",
      "137 - random_17 - lwr_k=1000 - 132.11074503383472 - 143.5250846708998 - 135.2495126722752 - 135.80937660263027 - 293.5302607932151 - 168.03380554949644 - 0.6548943328906549'\n",
      "138 - random_5 - lwr_k=1000 - 132.16171570537253 - 135.3713573878484 - 142.0350191626698 - 127.93838547182284 - 303.43171074867826 - 168.1762378607854 - 0.6546018072429463'\n",
      "139 - random_52 - lwr_k=100 - 166.47064255254062 - 163.90219708753884 - 157.6646233144972 - 155.20318811936522 - 197.7189205324388 - 168.18992964828814 - 0.6545736872259973'\n",
      "140 - random_96 - lwr_k=200 - 147.2970404630276 - 159.44163048121416 - 134.4914435705513 - 156.13265178787216 - 244.42609724971754 - 168.3501112195829 - 0.6542447083765358'\n",
      "141 - random_78 - lwr_k=20 - 166.71205270506977 - 160.17599598656992 - 154.00932408406902 - 193.03686692219375 - 169.3421445402155 - 168.65226851235815 - 0.6536241416176378'\n",
      "142 - random_70 - lwr_k=500 - 157.710061585655 - 152.7509846793934 - 160.4720818195237 - 156.97826137918543 - 216.1517873381828 - 168.80837461659877 - 0.6533035329099577'\n",
      "143 - random_16 - deep - 158.86163848162985 - 155.60942034043447 - 158.81493945198997 - 143.75058613533304 - 227.8219571245246 - 168.96767053558645 - 0.6529763724196127'\n",
      "144 - random_34 - lwr_k=50 - 182.59133278069808 - 212.04868730574438 - 151.48502304043012 - 141.68420251048317 - 157.83324374127344 - 169.1331468076231 - 0.6526365199641073'\n",
      "145 - random_60 - lwr_k=50 - 131.90145000517276 - 138.24634109446797 - 138.74140717494083 - 134.31113532566766 - 305.0835665666407 - 169.6447698159502 - 0.6515857552145985'\n",
      "146 - random_97 - lwr_k=1000 - 143.27213362517753 - 142.11767775064212 - 144.7661975787546 - 138.50602430484952 - 280.8761882335352 - 169.89809588578234 - 0.6510654773928846'\n",
      "147 - random_21 - deep - 158.18040412303282 - 152.2558104778809 - 148.6747021472018 - 144.51008519863024 - 246.91926980755625 - 170.1019042426271 - 0.6506468978266708'\n",
      "148 - random_66 - lr - 149.01021100708186 - 161.9964535125165 - 165.87209533678623 - 145.7965139111319 - 229.5957937430359 - 170.45007527090323 - 0.6499318292361353'\n",
      "149 - random_42 - lwr_k=1000 - 144.19518593021024 - 144.05887391936673 - 151.71654501829164 - 149.02435960501538 - 266.9840347275772 - 171.1869654713592 - 0.6484184136267995'\n",
      "150 - random_21 - lr - 156.3859688666141 - 151.38700810548963 - 147.0146578135489 - 159.76691919104874 - 241.47390946124543 - 171.19863287200351 - 0.648394451269525'\n",
      "151 - random_97 - lr - 148.19618448273 - 146.3303260177137 - 157.74687136650743 - 137.9507017623882 - 267.974127704253 - 171.63212450061584 - 0.6475041517420617'\n",
      "152 - random_55 - lwr_k=1000 - 138.59571852886606 - 134.7975807827653 - 140.2690758265454 - 137.41260329932916 - 308.86062624153243 - 171.97484456623258 - 0.6468002776823768'\n",
      "153 - random_66 - deep - 169.7480188059678 - 157.94708465228342 - 172.1579510105822 - 144.3814846876861 - 215.68400258663036 - 171.98177548740998 - 0.6467860424530909'\n",
      "154 - random_90 - lr - 164.72228133166755 - 166.80803940854392 - 148.99841338574893 - 168.78913832672944 - 212.32384629191952 - 172.32396881827012 - 0.6460832507870478'\n",
      "155 - random_20 - lwr_k=20 - 160.11017093648647 - 174.15939267204402 - 174.9397801834859 - 173.68260683416463 - 179.103425923373 - 172.3981167257109 - 0.6459309667690882'\n",
      "156 - random_11 - lwr_k=100 - 164.9231757549723 - 162.70193800199146 - 201.7754485252398 - 173.3524155222416 - 160.31345835933809 - 172.61467457232027 - 0.6454862030509929'\n",
      "157 - random_70 - lwr_k=1000 - 158.74398837588174 - 154.1703483183178 - 161.96151323546084 - 173.5281062546314 - 217.02085120033482 - 173.07963577975727 - 0.644531271707578'\n",
      "158 - random_55 - lwr_k=100 - 138.17613776366156 - 137.15708159753964 - 141.95564865365813 - 139.74450635607744 - 315.14216976292835 - 174.4223863428578 - 0.6417735478833457'\n",
      "159 - random_5 - lwr_k=500 - 131.30236415235464 - 134.3688717382235 - 141.7999930103338 - 127.23303203610665 - 338.8528397909264 - 174.69742002179973 - 0.6412086872534362'\n",
      "160 - random_96 - lwr_k=50 - 190.44629410561683 - 183.26208107610563 - 138.99860784201144 - 157.51549881301426 - 203.6051872994318 - 174.76414301738868 - 0.6410716524238734'\n",
      "161 - random_5 - deep - 142.38259364118386 - 148.51142285580968 - 165.21929353486297 - 148.18707119688696 - 269.9363155433682 - 174.8391254620477 - 0.6409176538416927'\n",
      "162 - random_64 - deep - 159.2419239815367 - 159.41147379654927 - 227.0186110338052 - 167.5663627267313 - 160.98837305918462 - 174.8478872887742 - 0.6408996589147034'\n",
      "163 - random_94 - lwr_k=20 - 202.83758856644437 - 185.83659998650268 - 165.492963817323 - 161.3464565858946 - 159.54977003731247 - 175.01617143351774 - 0.6405540397066329'\n",
      "164 - random_80 - deep - 137.50296336873677 - 147.37458099086055 - 149.60479576600548 - 130.12670464303886 - 311.89796791900966 - 175.29043426358467 - 0.6399907616322429'\n",
      "165 - random_42 - lwr_k=500 - 144.3403073558717 - 143.79804169886742 - 151.87756645529475 - 148.7090382147296 - 289.0720484618567 - 175.5490005470322 - 0.6394597221312298'\n",
      "166 - random_20 - lwr_k=100 - 131.11791639838424 - 138.6778350215663 - 147.64286588252756 - 145.55320417659487 - 315.41273076902047 - 175.66775742981235 - 0.6392158207738712'\n",
      "167 - random_92 - lwr_k=50 - 165.0104146900735 - 185.4294307566179 - 154.41433385400242 - 139.10726062665722 - 238.63822000685633 - 176.51696719425058 - 0.6374717246896704'\n",
      "168 - random_52 - lwr_k=200 - 146.34617701058252 - 152.4480744022515 - 148.07782985181896 - 141.6729051464756 - 294.1088869402654 - 176.5208478440762 - 0.6374637546610056'\n",
      "169 - random_5 - lwr_k=100 - 141.00896588026447 - 140.33383392806033 - 149.28296256488514 - 134.46167617911382 - 320.51587516073323 - 177.10857391195563 - 0.6362566904272948'\n",
      "170 - random_52 - lwr_k=1000 - 134.16693277113006 - 143.9752287197046 - 136.82969252208096 - 130.25503032636374 - 343.0981609737597 - 177.65084571529295 - 0.6351429795770684'\n",
      "171 - random_99 - deep - 171.31697564734338 - 140.44501968937573 - 142.80990916379713 - 140.83560296066668 - 294.21924052289984 - 177.9158444864283 - 0.6345987278986303'\n",
      "172 - random_97 - lwr_k=20 - 152.45395107936477 - 147.75575448914552 - 153.1767965034017 - 150.23285563024257 - 286.43202617691225 - 178.0005990693144 - 0.634424660640182'\n",
      "173 - random_99 - lr - 193.65544912578164 - 142.3120336177474 - 138.32004477445543 - 145.23636683770508 - 270.72177467099533 - 178.0419503331303 - 0.6343397339467804'\n",
      "174 - random_97 - deep - 161.51337971541435 - 157.3633552395661 - 168.72589442682752 - 138.04114374936987 - 267.4361848682344 - 178.61020017314692 - 0.6331726691237629'\n",
      "175 - random_38 - lwr_k=1000 - 124.53137780730044 - 129.2665027417004 - 132.6654614764033 - 122.97550075491598 - 385.54897522898494 - 178.97949935743762 - 0.6324142078276569'\n",
      "176 - random_77 - lwr_k=20 - 161.55738215911424 - 146.60287872753918 - 171.91418772474432 - 180.74482920619963 - 234.1571578632798 - 178.98845749345404 - 0.6323958097232045'\n",
      "177 - random_30 - deep - 163.6281234063856 - 155.99928597425657 - 157.55278792492845 - 145.60852684579692 - 272.8559521449571 - 179.12170722210843 - 0.6321221425283443'\n",
      "178 - random_65 - lwr_k=50 - 152.9083633486667 - 175.2997143667107 - 186.06631529487316 - 164.7819151925756 - 217.16650376268893 - 179.24174716519366 - 0.6318756066554245'\n",
      "179 - random_52 - lwr_k=500 - 134.51536405587527 - 145.11578877945857 - 140.46845409414104 - 132.315687072243 - 348.2698883893196 - 180.12259852038855 - 0.63006652547938'\n",
      "180 - random_36 - lwr_k=200 - 134.5904233251591 - 147.74049175305058 - 145.7077067000249 - 140.17576459287253 - 332.71665537494846 - 180.1727054087012 - 0.629963616597079'\n",
      "181 - random_66 - lwr_k=20 - 165.7390420965927 - 203.17152032676032 - 178.63266896591537 - 190.41779157712173 - 163.33149240751345 - 180.25931523392688 - 0.6297857384527674'\n",
      "182 - random_23 - lwr_k=50 - 186.10314962661243 - 161.80421126473388 - 187.7939111881187 - 178.57040080527193 - 189.59319154909264 - 180.7721787374103 - 0.6287324259902729'\n",
      "183 - random_66 - lwr_k=500 - 139.64505478539095 - 149.49320850876245 - 144.2392417653887 - 135.9695368427319 - 334.6265118053456 - 180.7816294230114 - 0.6287130162938231'\n",
      "184 - random_68 - deep - 152.28878877315967 - 158.76786555683248 - 164.76657075658844 - 146.39325884467556 - 284.26055697547577 - 181.287239810944 - 0.6276745995620525'\n",
      "185 - random_97 - lwr_k=200 - 142.82528376452643 - 140.00538412327896 - 144.9087110833493 - 138.82518050772885 - 340.011530812667 - 181.3012727474732 - 0.6276457795222647'\n",
      "186 - random_90 - deep - 166.30364513424033 - 203.31624028892952 - 151.02671336155132 - 182.46845625457215 - 204.77184634878427 - 181.57449136825358 - 0.6270846460098155'\n",
      "187 - random_65 - lwr_k=1000 - 135.45607280537658 - 131.85336503636984 - 130.96667103053426 - 132.63091769278145 - 379.1115291000725 - 181.98598222092724 - 0.6262395320184384'\n",
      "188 - random_11 - deep - 150.246572578032 - 168.31497453484766 - 161.318343228327 - 149.46659742998762 - 280.70716747544964 - 182.00279238235169 - 0.6262050068981584'\n",
      "189 - random_55 - lwr_k=50 - 141.73282408906132 - 140.7154637091074 - 148.94055283052947 - 141.9963298904309 - 337.6082839921738 - 182.18486548139438 - 0.625831068137876'\n",
      "190 - random_80 - lwr_k=1000 - 126.04651991648221 - 133.22313808560185 - 133.85718841935787 - 124.56340047806206 - 394.7775743451123 - 182.47504104643613 - 0.6252351092971827'\n",
      "191 - random_42 - lwr_k=100 - 147.06812626511146 - 143.84795913858161 - 148.89186615763288 - 149.05228548768432 - 326.5715857301402 - 183.07322989339085 - 0.6240065567424715'\n",
      "192 - random_17 - lr - 138.9116804919707 - 149.87907395948278 - 140.82417206540677 - 141.12002814370945 - 346.9649544391551 - 183.5254606368245 - 0.6230777710621754'\n",
      "193 - random_60 - lwr_k=100 - 130.26427002671173 - 137.00024698843455 - 135.9420817905806 - 130.85875621393077 - 383.8713090073977 - 183.5696254491636 - 0.6229870659390295'\n",
      "194 - random_82 - deep - 150.7267212012462 - 156.0526095403478 - 160.02760284620626 - 138.75441317884577 - 313.3207926023193 - 183.76628572813843 - 0.622583166956062'\n",
      "195 - random_31 - lr - 130.42797855555824 - 141.9007789192207 - 137.9796882819407 - 138.91082473880255 - 370.8809403957502 - 184.0030312961258 - 0.6220969425888152'\n",
      "196 - random_23 - deep - 157.37273060982287 - 171.5841320749522 - 175.0059230852499 - 166.32887121523413 - 250.12640403756717 - 184.07781604390775 - 0.6219433500021035'\n",
      "197 - random_40 - lwr_k=100 - 141.39160411465534 - 147.93634724618633 - 143.33376212239887 - 133.82139182239104 - 354.1007726686199 - 184.1024123867258 - 0.6218928349840542'\n",
      "198 - random_44 - lwr_k=1000 - 130.96969768586666 - 140.5008982286618 - 134.98648995155415 - 128.0508870193369 - 387.9721408456385 - 184.47837832254996 - 0.6211206809840382'\n",
      "199 - random_44 - lwr_k=500 - 134.90545214875476 - 142.63668391819672 - 136.27615900810994 - 130.8618034396581 - 380.4746874554838 - 185.01400356671473 - 0.6200206207514938'\n",
      "200 - random_78 - lr - 137.00392159448788 - 138.28117264347446 - 152.95909136916643 - 154.65260169571908 - 346.2369662006877 - 185.81124175236977 - 0.6183832632268826'\n",
      "201 - random_61 - lwr_k=500 - 137.94791834013574 - 135.49780653770037 - 139.9242639916375 - 131.80603305990775 - 384.4496879308439 - 185.9078126264256 - 0.6181849272086903'\n",
      "202 - random_20 - lwr_k=1000 - 127.98102250807675 - 132.75102311245098 - 134.83935016566477 - 141.49853516867663 - 394.7030488359291 - 186.33497608631419 - 0.6173076243927034'\n",
      "203 - random_15 - lwr_k=1000 - 139.88095680678487 - 130.93774231684398 - 136.85437639787315 - 125.22110489682223 - 399.2596056968061 - 186.4125621916871 - 0.6171482790480831'\n",
      "204 - random_11 - lr - 135.5366657146944 - 153.51281344161117 - 148.91516253859055 - 137.79768116512338 - 359.83601973898084 - 187.10486060381967 - 0.6157264454796743'\n",
      "205 - random_90 - lwr_k=50 - 163.96423971979365 - 163.9389009892884 - 160.58799662509156 - 172.69095946884585 - 278.5579150418617 - 187.93895966289526 - 0.6140133835676607'\n",
      "206 - random_78 - deep - 154.28851613557904 - 156.12273463962603 - 163.61934436576124 - 151.5997953380571 - 314.39089120450427 - 187.9934664540372 - 0.6139014375738111'\n",
      "207 - random_80 - lr - 130.39793133218814 - 143.67463150611192 - 140.26829569187572 - 132.8318818568603 - 394.7578835143486 - 188.36802595442663 - 0.6131321727405366'\n",
      "208 - random_42 - lwr_k=200 - 145.15890466520764 - 143.65550932448335 - 149.91015137047424 - 149.87080474867594 - 355.03203913751895 - 188.71018701185605 - 0.612429446764672'\n",
      "209 - random_84 - lwr_k=100 - 155.95008850150006 - 169.97156947833886 - 188.37799138855107 - 202.01961305140668 - 227.42607746633195 - 188.74283402131988 - 0.6123623967568281'\n",
      "210 - random_84 - deep - 196.34108279662428 - 187.40922349702117 - 167.20757233517287 - 148.71272484824007 - 248.008639071168 - 189.53373056473086 - 0.6107380629623808'\n",
      "211 - random_74 - lwr_k=100 - 166.589243939849 - 189.27749761111517 - 169.48502056818447 - 170.92210132449648 - 251.80540284272058 - 189.61063355276664 - 0.6105801212484102'\n",
      "212 - random_80 - lwr_k=500 - 128.28630460676203 - 134.28606429425878 - 137.71229660372728 - 124.38860249046779 - 425.6383639614684 - 190.04193729813278 - 0.6096943151673981'\n",
      "213 - random_70 - lr - 161.82102724464855 - 163.6737613040718 - 235.54459598528956 - 179.08733663446276 - 213.02190059756614 - 190.62842232650362 - 0.6084897997646571'\n",
      "214 - random_56 - deep - 155.08388417226223 - 161.9522273161487 - 202.8427267658117 - 156.53116104840373 - 277.92443090212157 - 190.86055787376594 - 0.6080130421078316'\n",
      "215 - random_48 - deep - 161.37601716030696 - 171.15596397093262 - 233.16371645066434 - 163.30684113244908 - 226.3117655723178 - 191.06196081665223 - 0.6075994033352532'\n",
      "216 - random_96 - lwr_k=100 - 162.7345879493086 - 167.3496502583723 - 136.39522042237604 - 157.48880239344018 - 336.18053528460615 - 192.01660555717393 - 0.6056387669125245'\n",
      "217 - random_89 - lwr_k=20 - 157.9309140098462 - 156.79356950371067 - 155.9142742705474 - 142.71056529618988 - 347.875253282419 - 192.2321832446975 - 0.6051960162325443'\n",
      "218 - random_31 - deep - 148.09073104812632 - 159.72553895516674 - 151.03450052596597 - 140.84368365266027 - 362.49360062781216 - 192.42339932060653 - 0.6048032984539331'\n",
      "219 - random_92 - lwr_k=20 - 210.11466559478453 - 236.71496008026344 - 166.1569577212781 - 149.97477268462393 - 201.24965191387412 - 192.84633696181126 - 0.6039346752329808'\n",
      "220 - random_5 - lwr_k=200 - 135.0970692030692 - 136.5792238618669 - 143.273079574393 - 129.6942661294683 - 419.94960115262154 - 192.89899040942316 - 0.6038265362599671'\n",
      "221 - random_13 - lwr_k=20 - 187.41816978781878 - 162.81077350716808 - 155.46635521454985 - 151.23227680643492 - 310.14529042868674 - 193.40562698057246 - 0.6027860125909548'\n",
      "222 - random_42 - lwr_k=50 - 148.6727010662452 - 146.43014665097664 - 148.33802199372894 - 149.8227950640589 - 382.76367177291576 - 195.1884055632491 - 0.5991245648836264'\n",
      "223 - random_76 - deep - 133.880234313855 - 141.99406415485092 - 135.5620665055374 - 135.611008661277 - 435.4072392980019 - 196.46955995737872 - 0.5964933458014821'\n",
      "224 - random_1 - lwr_k=20 - 169.15952256095687 - 165.52012186224619 - 166.01140105226764 - 163.8010993512691 - 318.0071855603643 - 196.48920862479184 - 0.5964529922981959'\n",
      "225 - random_76 - lr - 132.92870882789012 - 144.80943454854628 - 130.19065388549126 - 137.02877307370593 - 441.15482645309265 - 197.20042983886708 - 0.5949922953227087'\n",
      "226 - random_41 - lwr_k=20 - 137.61789229561847 - 163.77819923869882 - 154.49149186302714 - 147.15140004369704 - 384.61232879202834 - 197.5138574059392 - 0.5943485818195171'\n",
      "227 - random_26 - lwr_k=20 - 162.5393339700974 - 148.06055870562653 - 154.60661285902833 - 160.0306430466326 - 362.49036689055833 - 197.53021088225034 - 0.5943149952603515'\n",
      "228 - random_13 - lwr_k=1000 - 127.81345517126968 - 136.13097369760476 - 135.27731110466567 - 127.95451502296925 - 466.8307528454757 - 198.7777387261155 - 0.591752838631293'\n",
      "229 - random_96 - deep - 181.49778007045074 - 185.4669863924554 - 182.77085104028694 - 181.8149196812514 - 263.5614571084782 - 199.0167195915836 - 0.5912620221199383'\n",
      "230 - random_34 - lwr_k=20 - 225.5723799697291 - 265.25685192383827 - 161.21128910730627 - 158.59320197855624 - 185.58511615722452 - 199.25028519412777 - 0.5907823287773368'\n",
      "231 - random_61 - deep - 147.3838644365243 - 145.65950736015517 - 160.11769451377057 - 157.88225113043265 - 397.7634706233873 - 201.7431076697085 - 0.5856626013664661'\n",
      "232 - random_29 - lwr_k=1000 - 126.92556311988427 - 158.5259166398322 - 135.2885119285005 - 135.92153744896675 - 455.24380067645825 - 202.35869668321325 - 0.5843983132687718'\n",
      "233 - random_82 - lwr_k=1000 - 130.47161389641718 - 130.34166013199857 - 130.117645794627 - 133.48869033736432 - 490.4870541253558 - 202.9551702411981 - 0.5831732835524698'\n",
      "234 - random_96 - lwr_k=20 - 247.49813541057054 - 246.2643475627266 - 141.1131167342013 - 164.7511722424582 - 215.64308210243064 - 203.0570565763812 - 0.5829640307086286'\n",
      "235 - random_44 - lwr_k=200 - 145.93521455727793 - 147.6517796716055 - 150.2742214569203 - 140.4026646921448 - 434.674380747735 - 203.7675512121774 - 0.5815048259702592'\n",
      "236 - random_30 - lwr_k=200 - 138.8589461383058 - 151.76825850819614 - 138.4995800751441 - 135.79994487539878 - 456.05882676753663 - 204.1750946463596 - 0.5806678185105427'\n",
      "237 - random_44 - lr - 134.32535141102989 - 154.32999665065654 - 150.0423050732746 - 136.5163874456682 - 445.9383330369589 - 204.20959463578984 - 0.580596962876293'\n",
      "238 - random_54 - lwr_k=200 - 143.73786960924568 - 412.07194305991743 - 169.44382839508046 - 147.34464429784995 - 149.58416434044173 - 204.44992377840967 - 0.5801033779764069'\n",
      "239 - random_30 - lwr_k=50 - 142.75619392413793 - 153.25766174817917 - 140.53593178010297 - 138.14741045312834 - 450.8953079674958 - 205.09704363037852 - 0.5787743315533785'\n",
      "240 - random_97 - lwr_k=50 - 144.1298600654796 - 141.67033574742328 - 146.85332207178928 - 141.75171229503368 - 452.9132923265006 - 205.44165510779527 - 0.5780665729364827'\n",
      "241 - random_31 - lwr_k=100 - 163.2514336308604 - 170.86978538531716 - 186.77702136165027 - 160.75388996320473 - 347.3606020956144 - 205.79096489617564 - 0.5773491649890008'\n",
      "242 - random_31 - lwr_k=200 - 142.52410588234926 - 154.55463474294186 - 181.50165415548653 - 147.17537043851704 - 404.13629664039985 - 205.96168912192869 - 0.5769985337715053'\n",
      "243 - random_66 - lwr_k=50 - 152.1128386582688 - 165.23970811012327 - 159.16837443440846 - 153.9393655900509 - 400.1722463325137 - 206.1094829122838 - 0.5766949967870971'\n",
      "244 - random_60 - lwr_k=200 - 126.82697239465891 - 136.0408957591243 - 133.83211612050846 - 128.59201744895813 - 507.3758864964366 - 206.506828484132 - 0.5758789335657877'\n",
      "245 - random_70 - deep - 180.8046941774365 - 174.35519977608482 - 248.9629844180395 - 184.11739881499474 - 245.522826239413 - 206.75068489688746 - 0.5753781036915183'\n",
      "246 - random_54 - lwr_k=500 - 142.06031653720618 - 410.40293938485576 - 163.43525256272153 - 142.27556753566523 - 177.96580052956045 - 207.2392815121565 - 0.5743746309640817'\n",
      "247 - random_30 - lwr_k=1000 - 138.7374822902848 - 147.19026101989664 - 138.73471034085037 - 134.42892210706256 - 477.49724479124325 - 207.29404827659275 - 0.5742621516881743'\n",
      "248 - random_30 - lwr_k=500 - 139.07185606545787 - 146.81885332746188 - 138.67497139369436 - 134.82328115714225 - 481.76334948049066 - 208.20644623947945 - 0.5723882804952822'\n",
      "249 - random_11 - lwr_k=50 - 196.94470019503436 - 170.4827535339196 - 272.1926273775601 - 173.05482063850104 - 229.14215241874274 - 208.36515448433062 - 0.5720623275447078'\n",
      "250 - random_19 - lwr_k=500 - 155.35441997431406 - 140.41957969746196 - 143.0133441730144 - 147.59768556553973 - 458.2557490174671 - 208.9055951283517 - 0.5709523775059164'\n",
      "251 - random_98 - lwr_k=1000 - 140.56488383191945 - 141.55385204068497 - 491.3441845590173 - 130.89702331243478 - 140.67346077652522 - 209.0242547523966 - 0.5707086758972965'\n",
      "252 - random_99 - lwr_k=1000 - 479.3822642186359 - 138.0194752533074 - 131.38167624034278 - 138.44488660054708 - 159.62041778198218 - 209.384225500261 - 0.5699693726084413'\n",
      "253 - random_60 - deep - 126.8915058724095 - 136.1960248918539 - 135.15860425632158 - 129.4184220899053 - 520.779684648365 - 209.6611498165668 - 0.5694006282894422'\n",
      "254 - random_52 - lwr_k=50 - 221.86367138705424 - 185.37137487210657 - 182.2383343199133 - 185.1888527612915 - 275.8822991322675 - 210.10400389775418 - 0.5684911009997881'\n",
      "255 - random_54 - lwr_k=1000 - 143.0154177173121 - 409.3639698010903 - 160.6540180487102 - 143.45745968971576 - 194.5075160695021 - 210.20956878617946 - 0.5682742931906439'\n",
      "256 - random_98 - lwr_k=500 - 143.70288893738962 - 142.52183129092933 - 490.9918729227161 - 132.56938004063963 - 141.9171454984157 - 210.35816780641323 - 0.5679691024354749'\n",
      "257 - random_54 - lwr_k=100 - 148.21731627350715 - 415.27537114337383 - 178.62163486461685 - 156.35471229624164 - 155.70579597172016 - 210.84811976691245 - 0.5669628454050716'\n",
      "258 - random_40 - lr - 142.49365599494274 - 144.90662026513377 - 141.7135195349326 - 133.1375289104875 - 496.4021999905151 - 211.70597455170412 - 0.5652009942893372'\n",
      "259 - random_49 - deep - 132.0663671979807 - 138.4653013672168 - 140.09601620706744 - 138.06579609993412 - 512.934586719877 - 212.29846885912264 - 0.5639841363751394'\n",
      "260 - random_49 - lwr_k=1000 - 131.08002647956903 - 134.98918591985742 - 137.60010088621584 - 135.76392949055315 - 524.2334350516468 - 212.70519075656676 - 0.5631488169084946'\n",
      "261 - random_17 - lwr_k=50 - 201.72224178558005 - 164.89313563095337 - 150.19541274030968 - 214.80156697568415 - 332.09867024110906 - 212.7276349927559 - 0.5631027212250844'\n",
      "262 - random_76 - lwr_k=1000 - 134.28874655843728 - 135.6243609505473 - 131.7037301525767 - 126.36641103103095 - 538.1848389789085 - 213.20504630965814 - 0.5621222200070924'\n",
      "263 - random_3 - lwr_k=200 - 145.16289641474683 - 150.2838852026448 - 146.90812035203052 - 146.92446214119641 - 477.54525949976124 - 213.34119498822298 - 0.5618425996033973'\n",
      "264 - random_3 - lwr_k=500 - 145.20811985087352 - 147.95801688708016 - 148.36735312083152 - 147.18433055060635 - 478.9208415939302 - 213.50384548030638 - 0.5615085501161972'\n",
      "265 - random_76 - lwr_k=20 - 184.41903824431563 - 214.92298583452808 - 187.53785087033657 - 171.1077511503239 - 310.1321992452532 - 213.61748576734846 - 0.5612751571573107'\n",
      "266 - random_5 - lr - 135.1426519347556 - 141.91729517192132 - 140.70637351553293 - 141.4529906179185 - 510.27950537534963 - 213.87289029185266 - 0.5607506106321425'\n",
      "267 - random_75 - lr - 154.23372354531122 - 151.30999420554207 - 148.34437627326076 - 167.08210262215206 - 450.97482086222834 - 214.36628912314603 - 0.5597372744628661'\n",
      "268 - random_54 - lr - 147.05030618565064 - 410.94211494925287 - 168.1815540590392 - 152.66400128028585 - 193.17923708470644 - 214.41339874767547 - 0.5596405213223457'\n",
      "269 - random_30 - lwr_k=20 - 145.6790998750195 - 158.1556788841152 - 144.68140836935422 - 142.61250488162037 - 481.0562525533385 - 214.41361260408405 - 0.5596400821068064'\n",
      "270 - random_3 - lwr_k=1000 - 145.2528054010813 - 149.0776748833246 - 148.08598377061742 - 147.92377619109837 - 485.84237100757235 - 215.2121261025692 - 0.558000105361119'\n",
      "271 - random_31 - lwr_k=50 - 195.57221769996534 - 198.67397357001332 - 193.4099930431608 - 196.14208192980416 - 294.4855342997463 - 215.64964213229746 - 0.5571015405704409'\n",
      "272 - random_82 - lwr_k=200 - 134.4361877361572 - 130.43834704183203 - 130.91177924148818 - 134.23395558644685 - 549.3059670289963 - 215.83502898689505 - 0.5567207954345441'\n",
      "273 - random_56 - lwr_k=1000 - 133.71721525076438 - 138.54959581966042 - 137.92223932807605 - 137.99105196128932 - 531.8160786815132 - 215.9706980277463 - 0.5564421601046119'\n",
      "274 - random_29 - lwr_k=500 - 127.91067250021453 - 157.9423658240919 - 139.70639751649847 - 135.71174868919405 - 522.1121437772205 - 216.6497281166048 - 0.5550475768477696'\n",
      "275 - random_98 - lwr_k=200 - 153.8595200973971 - 152.32811853360772 - 490.9668395737222 - 139.748292062392 - 148.81779421684445 - 217.16160025302864 - 0.5539963004421822'\n",
      "276 - random_61 - lwr_k=1000 - 138.6087080546795 - 135.0003670038082 - 139.64545175524876 - 131.8879072057116 - 541.8223425855634 - 217.3642832534217 - 0.5535800327046657'\n",
      "277 - random_49 - lr - 131.69531010556142 - 160.88585143010002 - 143.90148531886283 - 167.70678760509688 - 483.6260417328354 - 217.53714940399462 - 0.5532250024295434'\n",
      "278 - random_56 - lr - 142.637530232948 - 160.5682614576065 - 175.24300168513582 - 168.4428088144428 - 441.59071780567024 - 217.67550628901762 - 0.5529408468398458'\n",
      "279 - random_98 - deep - 146.95205192588801 - 157.6339220643115 - 491.4059035559221 - 138.19423991520435 - 154.56955822032182 - 217.76826442135973 - 0.5527503406311729'\n",
      "280 - random_72 - deep - 152.35761471973183 - 149.5084848220862 - 186.3274456589395 - 147.53969998033392 - 455.2436059766314 - 218.17541082884404 - 0.5519141485783756'\n",
      "281 - random_48 - lwr_k=50 - 174.5045564007732 - 193.19012770017136 - 154.93177464859176 - 179.02716467276412 - 391.81266137242557 - 218.6772419208884 - 0.5508834950922409'\n",
      "282 - random_51 - lwr_k=20 - 226.01838249414496 - 174.16086576442913 - 166.9857590202708 - 154.65009714663063 - 372.61933413836334 - 218.87614780446833 - 0.5504749847486208'\n",
      "283 - random_50 - lwr_k=20 - 138.4255407732025 - 145.96759540646005 - 142.18801525881017 - 135.56239978805888 - 533.0000261118333 - 219.00105376180906 - 0.550218454501073'\n",
      "284 - random_53 - lwr_k=50 - 168.58567966583868 - 142.7597132071031 - 151.88800688324264 - 135.17581822223573 - 498.24642572864883 - 219.3077566081523 - 0.5495885521427619'\n",
      "285 - random_38 - lwr_k=100 - 136.66132301551718 - 149.7635709796786 - 145.7160505419793 - 144.33510167225992 - 521.1890875339376 - 219.50585068534693 - 0.5491817090766473'\n",
      "286 - random_49 - lwr_k=500 - 131.54994658653632 - 134.78428553503682 - 137.07614473812714 - 136.29102885897112 - 559.6415544785534 - 219.83784736174684 - 0.5484998585757175'\n",
      "287 - random_19 - lwr_k=1000 - 155.74729182941564 - 140.68219790269342 - 142.96925358000553 - 153.56055555800612 - 506.81118813430834 - 219.92764071675157 - 0.5483154421389203'\n",
      "288 - random_17 - lwr_k=100 - 169.59208198219167 - 159.32546637781599 - 139.40223578522975 - 163.60682841004112 - 471.7561732192135 - 220.71328943771144 - 0.5467018869077345'\n",
      "289 - random_60 - lwr_k=1000 - 123.61746067618681 - 135.26794920042477 - 132.71772109978014 - 128.14042636738705 - 585.9782394733513 - 221.11173846493642 - 0.5458835574239744'\n",
      "290 - random_1 - lr - 141.9141262237495 - 152.9471550737346 - 146.31587105476697 - 148.12151168997755 - 517.4257937625993 - 221.31814758852698 - 0.5454596370225931'\n",
      "291 - random_3 - lwr_k=100 - 149.1585436608493 - 159.52285116379377 - 160.74960239879803 - 159.13432418830698 - 480.03772066969333 - 221.69711977737964 - 0.5446813088187998'\n",
      "292 - random_90 - lwr_k=20 - 183.6024514394869 - 170.20964994995785 - 236.02779949918175 - 279.85100135762934 - 240.52075288284126 - 222.0331762085641 - 0.5439911204457457'\n",
      "293 - random_15 - lr - 146.89752140515586 - 144.11322376828159 - 153.01043246991748 - 143.0509550228992 - 523.5141055235193 - 222.09056690289285 - 0.5438732521763971'\n",
      "294 - random_28 - lwr_k=1000 - 142.72473249188573 - 138.6240920160884 - 146.57107550442603 - 165.5554944724017 - 517.712343187482 - 222.20889125909483 - 0.5436302391365577'\n",
      "295 - random_3 - lr - 151.76925269638988 - 154.53620958890596 - 154.3357722184766 - 154.22394900286943 - 496.4261920449787 - 222.23353808994403 - 0.5435796197925837'\n",
      "296 - random_20 - deep - 129.49101607901076 - 135.24797391748456 - 144.49241930178417 - 148.49018596085895 - 554.5057173221767 - 222.41449726751782 - 0.5432079673964223'\n",
      "297 - random_38 - lwr_k=500 - 125.17378512209461 - 129.51037562598805 - 132.19126183847445 - 125.35527085820088 - 600.2135753710564 - 222.4551814796272 - 0.5431244114515785'\n",
      "298 - random_69 - lr - 136.4973394580545 - 146.34809236980362 - 141.43490849930228 - 447.9521050967438 - 244.56172021708736 - 223.3293364092427 - 0.5413290833082007'\n",
      "299 - random_79 - deep - 145.84581074317057 - 144.88329673771668 - 152.487231605841 - 167.33218684202197 - 512.9608515891708 - 224.67416727197522 - 0.538567086217225'\n",
      "300 - random_1 - lwr_k=50 - 164.41362356852463 - 157.228304702997 - 156.2294630573744 - 162.5685161133105 - 483.4132719548828 - 224.74706207450856 - 0.5384173765841302'\n",
      "301 - random_28 - lwr_k=500 - 142.85180096046858 - 139.04008793726516 - 145.81009181501278 - 165.95316114632462 - 532.1656845066045 - 225.1344292218803 - 0.5376218069225803'\n",
      "302 - random_40 - lwr_k=20 - 152.12041384902955 - 156.2937244122927 - 152.54002419171567 - 149.3756785761265 - 515.7732496366261 - 225.1948521794864 - 0.5374977110299404'\n",
      "303 - random_80 - lwr_k=100 - 218.981724847307 - 193.00827973910972 - 188.81884991870788 - 197.94953725537724 - 329.6578540044281 - 225.6740998798606 - 0.5365134382712093'\n",
      "304 - random_15 - lwr_k=500 - 141.53414213295392 - 131.49917496286267 - 147.3525700755749 - 124.4832186622484 - 584.9287017947603 - 225.92866115397646 - 0.5359906236028354'\n",
      "305 - random_22 - lwr_k=50 - 136.3691674599475 - 176.15092969031164 - 492.4057725780542 - 143.65256551511874 - 181.10743567827507 - 225.9524285161757 - 0.5359418105002555'\n",
      "306 - random_3 - lwr_k=50 - 160.68890450908964 - 175.29550093249208 - 161.33956937799644 - 152.2367807708801 - 482.7428126178924 - 226.4388657878233 - 0.5349427718925788'\n",
      "307 - random_20 - lr - 130.5968253619118 - 156.85407734359782 - 161.67898751747563 - 179.43198547281392 - 509.2973753955344 - 227.54381881775888 - 0.5326734335813179'\n",
      "308 - random_75 - lwr_k=1000 - 150.70340917127552 - 137.23689633159867 - 151.02374234864186 - 135.34863392620485 - 563.7133471641591 - 227.57594242950003 - 0.5326074585209803'\n",
      "309 - random_60 - lwr_k=500 - 125.23913724074052 - 135.15448895973466 - 132.33937539497916 - 128.33240347541675 - 617.0540658681674 - 227.58907615337014 - 0.5325804846479373'\n",
      "310 - random_10 - lwr_k=200 - 146.79441453644378 - 135.5310603199632 - 146.57408069443215 - 133.82112461446937 - 579.2614470356144 - 228.36566944345236 - 0.5309855273441374'\n",
      "311 - random_59 - lwr_k=200 - 255.77138242394315 - 161.65228106714716 - 251.94865070439013 - 281.99961429352317 - 192.59953822872816 - 228.79225199399215 - 0.5301094175922942'\n",
      "312 - random_0 - lwr_k=100 - 162.98076138833068 - 178.19977125829794 - 171.58817429573338 - 151.91350714325642 - 479.8408394025248 - 228.88373644764056 - 0.5299215279988685'\n",
      "313 - random_28 - lr - 144.54402095213604 - 156.83432443314408 - 152.3549673597449 - 193.0933199086108 - 500.2958028525231 - 229.396341157567 - 0.5288687470432503'\n",
      "314 - random_54 - lwr_k=50 - 167.37449222216796 - 417.5400878420283 - 208.27971146437247 - 181.12850881024957 - 179.38607112792806 - 230.75389105425756 - 0.5260806285381701'\n",
      "315 - random_49 - lwr_k=200 - 132.37017423995897 - 133.9068376030229 - 139.43878559876183 - 137.91226884388675 - 611.8344177416784 - 231.05798802195346 - 0.525456078099885'\n",
      "316 - random_15 - lwr_k=200 - 145.26102143398006 - 135.1812658065055 - 152.1568469994935 - 129.55325571252715 - 595.9305293674297 - 231.5851125310516 - 0.5243734765676094'\n",
      "317 - random_29 - lwr_k=200 - 135.07397229714218 - 160.1385618803012 - 147.88532968412304 - 145.1148631022528 - 570.2786142715786 - 231.66802740454025 - 0.5242031870676185'\n",
      "318 - random_82 - lwr_k=500 - 130.18697633383746 - 127.96026408451733 - 130.50966348546814 - 131.98340808621919 - 638.7502298346702 - 231.84126960084902 - 0.5238473844746039'\n",
      "319 - random_68 - lwr_k=20 - 152.78947866536214 - 152.8596642190122 - 155.73364694761426 - 149.9664861102525 - 554.2968832847359 - 233.1006701142417 - 0.5212608439096804'\n",
      "320 - random_0 - lwr_k=20 - 219.21023704421427 - 214.18408675972142 - 241.92092131564343 - 202.0815798966286 - 289.02147372525394 - 233.28071534242108 - 0.5208910693373704'\n",
      "321 - random_22 - lwr_k=100 - 133.36515896203804 - 172.42068286386174 - 492.5447639661058 - 132.7793154258976 - 240.12034464919566 - 234.25752472583446 - 0.5188849107980267'\n",
      "322 - random_75 - deep - 167.78613886836052 - 154.61777004054298 - 147.44215998452225 - 143.37032176151712 - 559.8314303309977 - 234.5814831158803 - 0.5182195684178807'\n",
      "323 - random_44 - deep - 166.29720439579077 - 151.2912598867651 - 170.35099978295358 - 188.57869342194886 - 496.76316344179884 - 234.63034812288302 - 0.5181192100952616'\n",
      "324 - random_15 - deep - 149.3637763002209 - 133.85709063936724 - 138.28012660941323 - 132.38092832347783 - 626.4354971434032 - 236.02907423598904 - 0.5152465244020583'\n",
      "325 - random_57 - deep - 139.98353556522582 - 154.67450660220433 - 173.81577398738392 - 148.11466300387343 - 564.1975607763247 - 236.12840766009103 - 0.5150425146937953'\n",
      "326 - random_98 - lwr_k=100 - 183.28952839181633 - 168.27038666578602 - 490.9499185460227 - 164.9456720184634 - 174.62642898632754 - 236.43237884210063 - 0.5144182234061347'\n",
      "327 - random_76 - lwr_k=100 - 138.47999956182997 - 151.30389647614012 - 143.0209410450078 - 139.30188310330675 - 612.4213420235839 - 236.8722616679136 - 0.5135147977201207'\n",
      "328 - random_10 - lr - 151.78696893786872 - 144.31729868814327 - 161.0017579182936 - 164.01381152118282 - 563.4225311977149 - 236.8780381077692 - 0.5135029341422925'\n",
      "329 - random_60 - lr - 126.32955960908241 - 161.57668059545412 - 153.4563241662839 - 154.75704158927107 - 592.3306289304276 - 237.65744076466768 - 0.5119022069970842'\n",
      "330 - random_29 - lr - 124.8811442129263 - 158.03212442419934 - 142.82294912799114 - 138.08221464891068 - 627.9072366682634 - 238.31041652572438 - 0.5105611337833413'\n",
      "331 - random_31 - lwr_k=20 - 238.32989443733732 - 238.166311378038 - 233.0562376871828 - 233.85562037719765 - 249.59046051806695 - 238.598955249043 - 0.5099685366671115'\n",
      "332 - random_76 - lwr_k=500 - 131.86818352207015 - 136.09516291679762 - 131.2982364356882 - 129.83158927537198 - 666.0503055083601 - 238.99055506559253 - 0.509164274004082'\n",
      "333 - random_10 - deep - 161.4848898308107 - 149.04517999979717 - 162.82251217755717 - 158.83335788539048 - 563.1731231925296 - 239.042555793301 - 0.509057474755163'\n",
      "334 - random_10 - lwr_k=500 - 145.37177724311428 - 135.908056445161 - 146.5395947865066 - 133.6475504877067 - 635.605546670448 - 239.37965284206734 - 0.5083651499987547'\n",
      "335 - random_10 - lwr_k=1000 - 147.89189342668965 - 137.87127544580682 - 144.30033620554894 - 135.89843716565852 - 631.1339349810721 - 239.3845907790177 - 0.5083550085274011'\n",
      "336 - random_17 - deep - 165.4745911779558 - 234.77857519697844 - 194.3703353392127 - 183.59267999344513 - 419.2359934253853 - 239.47557721294814 - 0.5081681409353285'\n",
      "337 - random_4 - lwr_k=1000 - 142.5350549495 - 138.6762319226351 - 137.85602166971083 - 133.00016084352245 - 646.7251789470848 - 239.72250323177835 - 0.5076610082811224'\n",
      "338 - random_9 - lwr_k=100 - 186.2018024854182 - 190.5809700135699 - 274.4748779590546 - 193.40671296425444 - 354.5171891329193 - 239.82812002969501 - 0.507444093860933'\n",
      "339 - random_17 - lwr_k=20 - 266.7071287244534 - 183.93353990312474 - 161.72219852264894 - 341.4145612243602 - 246.3962183215709 - 240.0217998635485 - 0.5070463167109776'\n",
      "340 - random_15 - lwr_k=100 - 158.46932991903404 - 149.95975320503766 - 176.86333846291532 - 145.1886435361797 - 571.7830242084502 - 240.42448880931963 - 0.5062192793370787'\n",
      "341 - random_4 - lwr_k=200 - 155.6195242117148 - 149.1981554782392 - 143.79166155585298 - 134.85196695034654 - 619.3829956927256 - 240.53608779792611 - 0.5059900787706461'\n",
      "342 - random_24 - lwr_k=20 - 162.89307748126842 - 169.4773286138708 - 173.40105820515757 - 196.16338155071028 - 503.936070568122 - 241.1480521083126 - 0.5047332343464398'\n",
      "343 - random_56 - lwr_k=500 - 133.8441300413365 - 138.94349135386727 - 136.28876609251392 - 134.8813889297881 - 662.0309677576593 - 241.1600053022096 - 0.5047086850306612'\n",
      "344 - random_61 - lr - 143.48074738296913 - 155.47890005857943 - 158.01345266014454 - 177.3551780239949 - 573.0754300553989 - 241.4486440573374 - 0.5041158824703893'\n",
      "345 - random_72 - lwr_k=50 - 173.38858107682492 - 149.333553392335 - 160.1093480099143 - 145.6964356568704 - 581.2929939197099 - 241.93501391662062 - 0.5031169823133588'\n",
      "346 - random_54 - deep - 179.38633024127597 - 440.31702519664526 - 185.52628141516473 - 178.67115905619755 - 226.73836260196828 - 242.13729584248856 - 0.5027015374632349'\n",
      "347 - random_75 - lwr_k=500 - 165.609710753181 - 143.70096465107756 - 154.84265890017892 - 137.63295192127245 - 616.6874221001669 - 243.66270867697284 - 0.4995686650513478'\n",
      "348 - random_81 - deep - 149.65683873113073 - 156.44098853264015 - 181.35425271284245 - 189.98949414971065 - 543.0795551222197 - 244.0748409192113 - 0.4987222323157259'\n",
      "349 - random_28 - lwr_k=200 - 143.9754146276334 - 142.08289363757342 - 153.2917949129048 - 167.3772003074329 - 618.1089059528254 - 244.93177427427122 - 0.4969622744614961'\n",
      "350 - random_89 - lwr_k=100 - 144.9639869986168 - 139.8037982534333 - 146.94541037723428 - 128.2519643422047 - 670.5429524626236 - 246.0648300145039 - 0.4946352191655313'\n",
      "351 - random_1 - deep - 153.5711752348627 - 158.42495175815301 - 152.24852410060743 - 158.7359144707688 - 607.7040765983861 - 246.10402777892463 - 0.4945547144534975'\n",
      "352 - random_10 - lwr_k=50 - 160.70508519382756 - 150.90728000741927 - 155.05452072248124 - 219.13296373458354 - 548.1949649241719 - 246.76611400220108 - 0.4931949311376794'\n",
      "353 - random_73 - lwr_k=50 - 261.18501894670896 - 171.57610767099396 - 201.72347732952164 - 291.6034373370788 - 315.7428441364885 - 248.35290288191368 - 0.48993600455975583'\n",
      "354 - random_23 - lwr_k=20 - 332.2822786186763 - 197.70407796396827 - 227.98494958358611 - 251.1237510857022 - 233.2203394350841 - 248.4645892459782 - 0.48970662454273206'\n",
      "355 - random_5 - lwr_k=20 - 282.6680061769389 - 249.03247687686493 - 215.45543517150296 - 231.8410421167295 - 264.53941449596107 - 248.70739906376198 - 0.48920794486412245'\n",
      "356 - random_82 - lwr_k=20 - 198.92286323210885 - 183.41969290150115 - 172.10798956712196 - 177.50781868658467 - 512.656004847867 - 248.89979475477222 - 0.48881280507021063'\n",
      "357 - random_72 - lwr_k=20 - 181.7195051253104 - 157.89430065205815 - 175.29994038013385 - 151.3927625112228 - 581.6353775308421 - 249.56031395111444 - 0.4874562392461683'\n",
      "358 - random_4 - lwr_k=100 - 166.37644382710863 - 155.38709565800917 - 156.2765054950089 - 140.72907515937345 - 629.2217600793429 - 249.56568420611697 - 0.4874452098855636'\n",
      "359 - random_24 - lwr_k=1000 - 161.36020221681477 - 164.02428651276776 - 165.8321817797799 - 198.50294509107997 - 567.7777999433664 - 251.46788803150068 - 0.48353848815186096'\n",
      "360 - random_28 - lwr_k=20 - 153.93988573730482 - 150.6705052746735 - 200.65032112064188 - 182.4213445773549 - 569.9594664636451 - 251.4983845337074 - 0.4834758548281429'\n",
      "361 - random_99 - lwr_k=500 - 597.7519350041233 - 158.62478419773336 - 131.98264266779472 - 146.05293211143186 - 227.94040603478877 - 252.48625436077197 - 0.4814469804919851'\n",
      "362 - random_89 - lwr_k=50 - 151.33846808517615 - 144.93026377089205 - 151.02560098955624 - 132.24602177785934 - 691.6570502971282 - 254.2016285768133 - 0.4779239670053046'\n",
      "363 - random_10 - lwr_k=100 - 148.21368319342193 - 139.75226896034357 - 150.17942364423595 - 136.8366066280583 - 698.0781101216432 - 254.57293406459513 - 0.4771613845734941'\n",
      "364 - random_13 - deep - 150.93966173196026 - 161.76387051157275 - 164.63843959380426 - 146.8804772275121 - 649.4548780113852 - 254.7010411493357 - 0.476898279014099'\n",
      "365 - random_59 - lwr_k=100 - 270.6552682153509 - 175.36893465195254 - 270.41900763105025 - 314.4357383381636 - 246.1113305897687 - 255.39208553158414 - 0.47547902183372037'\n",
      "366 - random_4 - lwr_k=500 - 148.65831210877042 - 141.06849915353948 - 139.28568709306035 - 131.19998759890683 - 720.2069578398581 - 256.0431784302633 - 0.47414181561849467'\n",
      "367 - random_30 - lwr_k=100 - 139.55167637897296 - 153.31506360138437 - 139.88842320194127 - 137.17071380828224 - 713.2428602199312 - 256.59328829423924 - 0.47301200706021074'\n",
      "368 - random_29 - deep - 125.6509166779315 - 161.0055048530089 - 134.58651798731134 - 148.37213310617216 - 715.7620608889613 - 257.03344389627296 - 0.4721080202642741'\n",
      "369 - random_75 - lwr_k=50 - 210.07328485078835 - 175.5072861058129 - 181.0636693894018 - 195.56373425431295 - 528.3616491497779 - 258.0890000489623 - 0.4699401335093558'\n",
      "370 - random_22 - lwr_k=200 - 132.6639698927016 - 172.51780636932259 - 491.79988026430976 - 131.18942374522757 - 363.2374304528102 - 258.28435863714503 - 0.46953890855536584'\n",
      "371 - random_24 - lr - 170.32492162184172 - 170.0193114044644 - 169.1593820164609 - 200.44945923787137 - 582.2336022808701 - 258.4054370294631 - 0.46929023931159797'\n",
      "372 - random_79 - lr - 134.4327923389991 - 153.8903964175843 - 143.91381419872732 - 137.61987710927303 - 723.2114912793865 - 258.57244013704667 - 0.4689472504787051'\n",
      "373 - random_28 - lwr_k=100 - 142.62445103619717 - 141.2352942063405 - 160.8874770479984 - 169.1003028668498 - 680.2200437564766 - 258.7737089922939 - 0.4685338870942879'\n",
      "374 - random_49 - lwr_k=100 - 133.92704826477294 - 136.84373215216115 - 140.1734782046315 - 139.9307535933701 - 743.9750193129657 - 258.92608865763896 - 0.46822093169884926'\n",
      "375 - random_51 - lwr_k=1000 - 122.90320424850447 - 132.27685485470894 - 130.0023241888863 - 130.25740229395382 - 780.4388703125691 - 259.12864791916445 - 0.46780491809462643'\n",
      "376 - random_18 - lwr_k=50 - 150.246705030617 - 592.2070579550881 - 163.68520992085908 - 225.79236122306193 - 169.48506347730745 - 260.29831481891966 - 0.4654026712704489'\n",
      "377 - random_37 - lwr_k=200 - 145.4063475994428 - 156.24842545249268 - 138.83536380167007 - 138.32668759713073 - 724.5963834555351 - 260.6416530071645 - 0.4646975277184662'\n",
      "378 - random_40 - lwr_k=200 - 140.93278852726235 - 145.53927714303197 - 141.68375538577763 - 133.4105358806279 - 744.70884776645 - 261.2123661174251 - 0.46352540447814283'\n",
      "379 - random_71 - lwr_k=500 - 270.65967814962033 - 249.78149576897056 - 247.92799943552845 - 268.3022141768468 - 270.2668325400821 - 261.3857486873539 - 0.46316931358759406'\n",
      "380 - random_39 - lwr_k=500 - 260.937955624019 - 246.1052558309944 - 261.23232051240296 - 254.25345715734537 - 285.98230369431946 - 261.70023873377613 - 0.4625234179779881'\n",
      "381 - random_24 - deep - 188.54569229052748 - 174.620287808817 - 177.2723108164622 - 208.1893043014325 - 562.3247900112193 - 262.1609455723309 - 0.46157722329932815'\n",
      "382 - random_79 - lwr_k=1000 - 136.4296709299135 - 134.00475377323215 - 139.12241294305224 - 136.02196970798568 - 766.0879692451658 - 262.28806032067223 - 0.4613161575685505'\n",
      "383 - random_37 - lr - 131.73524992048863 - 150.3281671307837 - 134.02663875433248 - 163.45224934374428 - 736.3764773319974 - 263.1389393579418 - 0.45956863315329366'\n",
      "384 - random_71 - lwr_k=1000 - 279.5989263522937 - 249.93739721722437 - 251.84608499530526 - 267.64134581341153 - 268.786706564814 - 263.56097567978924 - 0.4587018603874252'\n",
      "385 - random_46 - deep - 144.69916220918415 - 158.11897099454316 - 151.3290360947891 - 153.18679978094752 - 712.0133274188277 - 263.82896067477606 - 0.458151475344855'\n",
      "386 - random_22 - lwr_k=20 - 161.8783955374307 - 178.56180035284646 - 500.48331033266317 - 171.6464706230724 - 306.6918694786234 - 263.8582934697067 - 0.4580912329372082'\n",
      "387 - random_71 - lwr_k=200 - 281.38781905932956 - 256.0632379353131 - 253.6980115009302 - 253.07624886765245 - 281.3496374358542 - 265.11448743114875 - 0.4555112779474102'\n",
      "388 - random_61 - lwr_k=100 - 140.4443472977017 - 140.65190071119918 - 161.35593409464087 - 133.47858327916836 - 750.6085627358024 - 265.2654473571998 - 0.4552012383942604'\n",
      "389 - random_3 - lwr_k=20 - 217.5581334754488 - 253.5481141377482 - 204.3595583025642 - 164.99815391878067 - 486.52280096763116 - 265.3828644308575 - 0.4549600887196329'\n",
      "390 - random_84 - lwr_k=50 - 168.39683751232107 - 204.45828358826606 - 244.2131129996624 - 472.8957659014792 - 237.0682910285105 - 265.3849592092258 - 0.4549557864907816'\n",
      "391 - random_82 - lr - 129.963045651106 - 134.171179436676 - 136.71203323544233 - 133.9574788522084 - 796.0429764788197 - 266.1216214096134 - 0.4534428391450518'\n",
      "392 - random_4 - deep - 143.02104360240622 - 142.0542047643061 - 140.1916418275793 - 136.3491377263796 - 770.6154013490047 - 266.40142064606084 - 0.45286819015656465'\n",
      "393 - random_24 - lwr_k=200 - 159.7696785867394 - 164.30797711431626 - 165.09328424432522 - 191.98727188752883 - 651.2874275602915 - 266.45189081591485 - 0.45276453608921874'\n",
      "394 - random_57 - lr - 133.4747919898768 - 161.7005714586917 - 163.50138274761966 - 150.69855809463374 - 724.0709316339767 - 266.64827862677436 - 0.45236119733094216'\n",
      "395 - random_50 - lwr_k=100 - 133.09723479340494 - 135.63740623683606 - 137.1717623295714 - 133.23212354439863 - 794.7495620631181 - 266.7302847261406 - 0.4521927742595472'\n",
      "396 - random_51 - deep - 127.37798145479546 - 135.79317484319603 - 131.42524441202457 - 131.69070179951865 - 809.0818861174841 - 267.0250309825082 - 0.45158742727177936'\n",
      "397 - random_0 - lwr_k=50 - 193.78624601420415 - 194.7409507494363 - 210.29587323677023 - 160.1852937455613 - 577.4296381920407 - 267.2632346452333 - 0.45109820857520244'\n",
      "398 - random_50 - lwr_k=50 - 137.24357733830786 - 137.93283234729617 - 140.61553821603908 - 134.02167944753103 - 788.1900885290356 - 267.5543000841233 - 0.45050042212305297'\n",
      "399 - random_37 - lwr_k=1000 - 128.66078972216548 - 134.11126109054194 - 126.20595260726913 - 131.88806702666935 - 819.1905221708214 - 267.9615098168871 - 0.44966410001501456'\n",
      "400 - random_76 - lwr_k=200 - 132.89947987280166 - 140.45359270836937 - 137.25006977139935 - 131.04591521679404 - 801.2101108681499 - 268.5244183078425 - 0.4485080058013686'\n",
      "401 - random_76 - lwr_k=50 - 151.3360041990825 - 171.00519305048573 - 159.82542490352122 - 147.61981316044546 - 714.1885910305976 - 268.75609750527764 - 0.4480321860475711'\n",
      "402 - random_0 - lwr_k=200 - 147.5972838919076 - 168.23049424380216 - 147.14121949709306 - 141.8455189078252 - 740.8333098308814 - 269.0882332572384 - 0.44735004991504446'\n",
      "403 - random_57 - lwr_k=1000 - 127.70241171393387 - 139.72792386719536 - 134.83683111532503 - 129.6765702910722 - 814.3971621332317 - 269.21951339276126 - 0.4470804284623868'\n",
      "404 - random_74 - deep - 134.91774018281365 - 144.44731315997237 - 141.3060120947002 - 133.83881963429903 - 792.8704180494219 - 269.429506620306 - 0.4466491461460921'\n",
      "405 - random_28 - lwr_k=50 - 145.0420538319804 - 143.71766729973396 - 158.14389233750242 - 171.67339035969772 - 734.7428697641635 - 270.62016236883926 - 0.44420379362278006'\n",
      "406 - random_75 - lwr_k=200 - 160.94112603081558 - 151.08529819181894 - 144.72688869054656 - 150.25727091111523 - 746.5867266138519 - 270.67681177281514 - 0.44408744780601705'\n",
      "407 - random_24 - lwr_k=500 - 160.69815380324744 - 164.10998414742846 - 164.99637376928794 - 191.92148213843737 - 673.6418835888635 - 271.03476399122326 - 0.4433522901469792'\n",
      "408 - random_37 - deep - 131.4303429871887 - 138.69875242471267 - 129.29902018253577 - 138.73114922238426 - 819.0773573001894 - 271.39754777272833 - 0.4426072085507149'\n",
      "409 - random_68 - lwr_k=100 - 143.81215563912397 - 139.00071776195088 - 142.75546093962464 - 138.76827299066062 - 794.7576515715746 - 271.77206332252854 - 0.4418380342699709'\n",
      "410 - random_93 - lr - 133.2007967327195 - 142.92135846031184 - 139.6942439535334 - 140.95246683302148 - 804.5162807072932 - 272.20891285005246 - 0.44094083833294173'\n",
      "411 - random_13 - lr - 132.90408830051518 - 150.7226802457194 - 163.3797118989211 - 142.65375785566752 - 775.9368839283744 - 273.0747404433324 - 0.4391626127657505'\n",
      "412 - random_51 - lr - 127.53806934881712 - 141.2232218135041 - 138.28333070574718 - 141.4899055621442 - 822.0925439033446 - 274.0755724785281 - 0.4371071168133669'\n",
      "413 - random_22 - lwr_k=500 - 132.67230934082613 - 171.6357617513247 - 491.697423001666 - 130.5192348844137 - 446.3219046236668 - 274.5660022890741 - 0.43609987838068776'\n",
      "414 - random_28 - deep - 155.88654113202017 - 184.40051148190923 - 205.740754835178 - 199.0909954588525 - 627.9086990768598 - 274.5721673641392 - 0.4360872156828062'\n",
      "415 - random_56 - lwr_k=200 - 133.69403992214188 - 141.16253349706588 - 141.6044965194406 - 131.54254952544977 - 832.0275618063582 - 275.9568473618768 - 0.4332433786714436'\n",
      "416 - random_5 - lwr_k=50 - 160.82474570786732 - 160.35161266098768 - 158.6035705481964 - 158.88679202578987 - 742.0387501774712 - 276.09925534805683 - 0.43295090298233063'\n",
      "417 - random_68 - lwr_k=50 - 144.62508488231364 - 143.0134236137775 - 148.51436408597127 - 142.05369878938455 - 803.4349500581394 - 276.28116255541494 - 0.4325773043011485'\n",
      "418 - random_39 - lwr_k=1000 - 267.5123991309458 - 261.37049397444304 - 263.79813835787087 - 301.0279666673192 - 288.36547406380043 - 276.4105066251409 - 0.43231165911550595'\n",
      "419 - random_89 - lwr_k=200 - 143.05551680407652 - 137.34809451189298 - 144.29629059529194 - 128.03221945249493 - 830.3355858240683 - 276.56492260612356 - 0.43199452156121976'\n",
      "420 - random_24 - lwr_k=100 - 159.34318465620902 - 164.4997525325145 - 166.48593696857483 - 192.53054841089173 - 708.7341535448894 - 278.27735829575755 - 0.4284775431822536'\n",
      "421 - random_37 - lwr_k=500 - 135.83320769240555 - 136.18159492768513 - 126.45687632917014 - 131.5452370318629 - 862.4817780055067 - 278.44729339501697 - 0.4281285326625939'\n",
      "422 - random_37 - lwr_k=100 - 169.99626700161198 - 172.10933811875708 - 170.60825040167072 - 151.25499451734552 - 730.1168759653793 - 278.77829513734076 - 0.427448725544464'\n",
      "423 - random_71 - lwr_k=100 - 291.75323095839553 - 265.9057403408571 - 270.3137132518245 - 267.88952915257624 - 300.63576934252757 - 279.2984054289558 - 0.42638052972177665'\n",
      "424 - random_29 - lwr_k=50 - 177.06501988186812 - 168.44344309346786 - 280.5510372171203 - 191.95433945496075 - 579.04854062686 - 279.387013685004 - 0.4261985472259633'\n",
      "425 - random_4 - lr - 144.2651103721287 - 160.58982165936018 - 156.55513348750495 - 174.00964161325552 - 762.9134443820393 - 279.6213177113073 - 0.42571733663241995'\n",
      "426 - random_93 - deep - 146.04375152038685 - 156.76708404504402 - 157.23236683534876 - 139.8676726397346 - 799.179665683412 - 279.7725668553131 - 0.42540670212317655'\n",
      "427 - random_12 - deep - 146.1845122956915 - 144.8794102065207 - 147.18671098925356 - 139.8315604440018 - 827.7249466162198 - 281.1128125730926 - 0.4226541227134073'\n",
      "428 - random_22 - lwr_k=1000 - 132.82293220048862 - 172.27833970567576 - 492.1308834966896 - 130.61083509862164 - 477.7544272069765 - 281.1139481648487 - 0.42265179141827325'\n",
      "429 - random_51 - lwr_k=500 - 129.7332237861672 - 136.65922027004268 - 132.9131258855278 - 132.97682274272964 - 877.7122607008221 - 281.94532558620347 - 0.4209443191707809'\n",
      "430 - random_81 - lwr_k=1000 - 135.72129722160204 - 143.135812764517 - 153.30482693391718 - 171.0808639952491 - 807.2067330875806 - 282.0402118787585 - 0.4207494429243931'\n",
      "431 - random_56 - lwr_k=50 - 149.70230181284958 - 151.2116894225091 - 157.6392399767717 - 142.73122333584882 - 824.0699477802149 - 285.0232794323753 - 0.4146228571772178'\n",
      "432 - random_24 - lwr_k=50 - 158.3597468176894 - 165.4783280648776 - 168.4577552869693 - 192.81328471195843 - 751.3459513434501 - 287.2466622057995 - 0.41005650225385715'\n",
      "433 - random_87 - lwr_k=500 - 259.2489930305432 - 360.76558464492183 - 272.5901475166397 - 291.0171430529562 - 253.10057366452017 - 287.34815707986974 - 0.40984805338781105'\n",
      "434 - random_91 - lwr_k=1000 - 150.91010289335773 - 325.8143697762436 - 350.8922535821418 - 238.66380884922407 - 370.60851572766245 - 287.3736679955297 - 0.40979565939757445'\n",
      "435 - random_39 - lwr_k=100 - 268.5366590708464 - 249.44374564212438 - 268.27536400385117 - 317.0729659117054 - 334.6191359122145 - 287.5803921864386 - 0.4093710919149899'\n",
      "436 - random_22 - deep - 151.65693170608128 - 192.0852394790512 - 491.7424895773409 - 140.84323570736888 - 461.9413773627127 - 287.65056331415377 - 0.4092269743649214'\n",
      "437 - random_75 - lwr_k=20 - 304.5727939655373 - 201.50892748604429 - 212.1448174944327 - 264.320287075892 - 456.7392680405109 - 287.8397767007 - 0.408838371338084'\n",
      "438 - random_84 - lwr_k=20 - 195.17596060710022 - 266.15719636441725 - 329.3556748218409 - 347.47281349693145 - 307.87150970727663 - 289.1973989028848 - 0.4060501043329102'\n",
      "439 - random_12 - lwr_k=50 - 142.9854048558004 - 144.83312057331574 - 146.5139652663138 - 139.34455239404002 - 876.785457571414 - 290.04018463839293 - 0.4043192018366437'\n",
      "440 - random_12 - lwr_k=200 - 136.7556199632085 - 136.88687417814356 - 140.7561339442372 - 132.85064670182905 - 907.7308860392232 - 290.94099922780157 - 0.4024691204271138'\n",
      "441 - random_91 - lwr_k=500 - 151.24090014041644 - 330.6940594899739 - 355.7716819903543 - 247.36877244493493 - 372.69946013573144 - 291.5505396689274 - 0.401217254114398'\n",
      "442 - random_38 - lr - 127.05719836046369 - 154.70486920025112 - 155.45678130279228 - 130.86063905790354 - 897.0551899111563 - 292.97391001055087 - 0.3982939544266757'\n",
      "443 - random_29 - lwr_k=100 - 152.07225510670466 - 165.7402211743794 - 180.88087018013147 - 165.53699275105927 - 801.9701425046399 - 293.19437128127225 - 0.3978411739063794'\n",
      "444 - random_0 - lwr_k=500 - 140.79367850616802 - 154.28334104574668 - 151.25381959293748 - 131.98930125299472 - 889.4540605032196 - 293.5027180535608 - 0.3972078952741205'\n",
      "445 - random_91 - lwr_k=200 - 158.38614180283307 - 334.9147635960766 - 360.1026910648356 - 240.32734822435322 - 376.02148657978614 - 293.94707237354606 - 0.3962952860909269'\n",
      "446 - random_89 - deep - 144.37288171485577 - 138.71839223654598 - 141.94716794861242 - 129.97228088012548 - 916.2114479996864 - 294.18951569147816 - 0.39579735811134'\n",
      "447 - random_22 - lr - 138.5360110019672 - 181.95748208606818 - 492.4343565109645 - 159.14243249081625 - 503.95924883238075 - 295.19718305123956 - 0.3937278248709948'\n",
      "448 - random_79 - lwr_k=200 - 141.8782309553167 - 146.27867266312595 - 144.61195325118095 - 187.0737681312255 - 856.5081823092338 - 295.21579429202785 - 0.3936896013442053'\n",
      "449 - random_52 - lwr_k=20 - 341.0507079506964 - 223.2592036450379 - 243.75612232501007 - 277.0140719107723 - 391.770026605987 - 295.3606608274094 - 0.3933920763183858'\n",
      "450 - random_87 - deep - 269.6983164448043 - 401.118226580514 - 274.6075012445021 - 277.7707325361785 - 255.29056727671536 - 295.7040687725717 - 0.3926867884816697'\n",
      "451 - random_66 - lwr_k=200 - 142.33506122549292 - 150.31012159204616 - 147.15501709876028 - 136.27539468731285 - 904.0541001831573 - 295.9721434915005 - 0.39213622109314183'\n",
      "452 - random_40 - lwr_k=1000 - 138.83336511982472 - 142.21012653226254 - 140.2150548189869 - 130.96884711170307 - 928.3385259805685 - 296.0571319499587 - 0.3919616728910291'\n",
      "453 - random_0 - lwr_k=1000 - 138.8586841255339 - 151.4646016464105 - 130.07870062052754 - 124.56698520291704 - 937.28226757278 - 296.3939717317367 - 0.3912698756826083'\n",
      "454 - random_32 - lwr_k=500 - 313.56661051926505 - 272.67231828483654 - 299.23549941734655 - 287.98359278496076 - 308.56673317822754 - 296.40450196805784 - 0.3912482488187845'\n",
      "455 - random_71 - lwr_k=50 - 316.5045856318324 - 278.6231926816917 - 290.91295473613343 - 288.5973513865919 - 308.17257929332186 - 296.5616952485918 - 0.39092540728242586'\n",
      "456 - random_12 - lwr_k=1000 - 134.70368899032758 - 138.99205499301834 - 140.18303510523523 - 133.96587088704214 - 942.7927092435967 - 298.0698091009612 - 0.3878280624630498'\n",
      "457 - random_57 - lwr_k=50 - 146.55647006393238 - 150.51044856319655 - 167.633301405815 - 149.59892613920152 - 876.3769355570143 - 298.0836496316828 - 0.3877996369591923'\n",
      "458 - random_32 - lwr_k=1000 - 314.90523112986216 - 278.3800993183672 - 301.43517863518184 - 285.7887703115269 - 312.7666007212938 - 298.65502661499164 - 0.38662615026494707'\n",
      "459 - random_39 - lr - 329.66405329138786 - 309.01335448818855 - 302.1824967608055 - 331.6215311745024 - 224.9214078890706 - 299.48565910821173 - 0.3849202079412699'\n",
      "460 - random_1 - lwr_k=1000 - 140.42165930395356 - 149.1152154110659 - 142.38279733184694 - 144.20891573753877 - 921.9733824976183 - 299.56435883378106 - 0.38475857545782355'\n",
      "461 - random_91 - lwr_k=100 - 159.98342697164858 - 331.35752541745927 - 358.27343274809976 - 273.68526118969146 - 377.0931123572098 - 300.0724769414212 - 0.38371500902823474'\n",
      "462 - random_6 - lwr_k=500 - 314.8820511916138 - 281.8170666091648 - 306.90987662425414 - 295.5087046771791 - 306.8662629121574 - 301.1967946370292 - 0.3814058998158546'\n",
      "463 - random_93 - lwr_k=200 - 147.8222460810306 - 160.9331549104781 - 155.55554174212617 - 154.75082516164227 - 888.507840047388 - 301.4610917766967 - 0.38086308975211913'\n",
      "464 - random_87 - lwr_k=100 - 277.8075131895243 - 368.4657393041115 - 288.2609924679343 - 308.76668903047806 - 270.3706272227817 - 302.73747212634925 - 0.37824167621802907'\n",
      "465 - random_37 - lwr_k=50 - 203.66572356112965 - 233.61897777595843 - 385.8630829088817 - 194.2651334990451 - 497.138959712696 - 302.9001050796582 - 0.37790766275173804'\n",
      "466 - random_59 - lwr_k=500 - 262.8470663862479 - 153.0318740955775 - 252.98728963556076 - 290.5317170768482 - 556.7492392783902 - 303.2005374887207 - 0.37729063853680866'\n",
      "467 - random_32 - lwr_k=200 - 323.07675962866057 - 279.4454949115106 - 307.54747506895893 - 292.4528987863181 - 314.64448415339217 - 303.43339484411104 - 0.37681239909736663'\n",
      "468 - random_6 - lwr_k=200 - 323.599755671735 - 285.2152937344621 - 304.9127581859341 - 294.1410221895763 - 311.90157994023207 - 303.954305820754 - 0.3757425588380744'\n",
      "469 - random_89 - lwr_k=500 - 142.23784270759694 - 134.82562788933603 - 144.16187822866226 - 126.5219797608666 - 976.8942951677942 - 304.8690952266189 - 0.37386377613037347'\n",
      "470 - random_74 - lwr_k=1000 - 123.05281775652536 - 138.16025994102736 - 134.14458574430412 - 124.86756619105951 - 1009.3317175948744 - 305.8487017574633 - 0.37185187284563737'\n",
      "471 - random_11 - lwr_k=20 - 218.03095801852538 - 191.60972826026781 - 371.0575530547389 - 195.60776215488704 - 557.2201671021378 - 306.68850295346226 - 0.3701270999582015'\n",
      "472 - random_98 - lwr_k=50 - 310.1014763428018 - 219.013933819768 - 492.70572408069427 - 224.97688237344582 - 286.64428085202803 - 306.7006706728862 - 0.3701021100526568'\n",
      "473 - random_63 - lwr_k=20 - 502.00205658630125 - 146.75549552668997 - 144.22926177783165 - 141.25456107834654 - 603.4934223501024 - 307.53140035374986 - 0.3683959681262482'\n",
      "474 - random_6 - lwr_k=1000 - 320.1126156909488 - 287.6303776419779 - 310.74362840399516 - 303.833129088982 - 315.5254264035785 - 307.5685289674852 - 0.3683197138572333'\n",
      "475 - random_54 - lwr_k=20 - 200.18900505976413 - 429.034930974418 - 308.4393467317627 - 239.14803078884776 - 368.63008059599525 - 309.0895266936252 - 0.36519590830373283'\n",
      "476 - random_6 - lwr_k=100 - 330.96288705080826 - 291.0516140355656 - 310.2684092364999 - 298.61658602145343 - 316.47828007773325 - 309.4760180522592 - 0.3644021373258203'\n",
      "477 - random_56 - lwr_k=100 - 137.4428248729517 - 143.13283762952233 - 154.85151280366082 - 134.61179961300368 - 978.5861478255661 - 309.66577243105525 - 0.3640124222249381'\n",
      "478 - random_91 - lr - 164.95991248674719 - 333.773884891518 - 367.47624033697923 - 261.5585433348212 - 422.39529555685715 - 310.02510842011867 - 0.36327442259553855'\n",
      "479 - random_74 - lwr_k=200 - 132.74265956707075 - 150.41551221918945 - 147.05971371400483 - 141.07416541113147 - 979.6006800764375 - 310.11850566557445 - 0.36308260453491803'\n",
      "480 - random_89 - lr - 142.4466477430175 - 152.45255079489905 - 180.74454122704995 - 173.67228831232305 - 903.2396077328184 - 310.4564182166572 - 0.3623886040867065'\n",
      "481 - random_91 - lwr_k=50 - 190.87174350856796 - 327.38098859521443 - 354.99886387922334 - 305.0630214944822 - 374.8452871829555 - 310.62494332896694 - 0.3620424893800964'\n",
      "482 - random_89 - lwr_k=1000 - 141.62096167295536 - 134.0864792915143 - 142.23559823060899 - 126.40843074552784 - 1010.3782152779169 - 310.88414719947855 - 0.361510139806999'\n",
      "483 - random_50 - lwr_k=200 - 131.40417052422842 - 136.32590959150477 - 136.74131118578254 - 129.40964541008057 - 1023.2384370228344 - 311.3603161685904 - 0.36053219010690896'\n",
      "484 - random_39 - lwr_k=200 - 260.9974602630121 - 244.50824323426028 - 261.9531358062252 - 293.81572783935184 - 499.2665500936231 - 312.0879587369814 - 0.3590377671652838'\n",
      "485 - random_74 - lr - 126.5857209458445 - 143.21326495539134 - 142.40315321010996 - 140.77728023447744 - 1008.0792777087273 - 312.14880492403614 - 0.35891280204944953'\n",
      "486 - random_87 - lwr_k=200 - 264.1509821492667 - 360.1037719226531 - 276.65140867126706 - 403.97104978752714 - 260.8195690692815 - 313.13473470638854 - 0.35688791215215154'\n",
      "487 - random_61 - lwr_k=50 - 154.82016450924183 - 145.51076823776057 - 156.64745597613003 - 139.39026584122362 - 971.4497916596614 - 313.50564140140847 - 0.35612614875578263'\n",
      "488 - random_25 - deep - 125.03777915300118 - 131.546553044814 - 131.53376288948905 - 125.55317647688959 - 1056.9687573763788 - 314.0614864120914 - 0.3549845603448816'\n",
      "489 - random_32 - lwr_k=100 - 330.27114030787027 - 291.4827301519864 - 316.971829502208 - 304.98434612399 - 332.32284728870343 - 315.20575135753137 - 0.35263448480965964'\n",
      "490 - random_6 - lwr_k=50 - 334.85682403426847 - 294.2608566667723 - 315.47633430814125 - 305.03558257976823 - 326.41962250138073 - 315.20971975105016 - 0.35262633457412706'\n",
      "491 - random_74 - lwr_k=500 - 124.91333371027737 - 141.33369474767608 - 136.52198404307734 - 127.2835062719954 - 1046.4079152101567 - 315.22691131987085 - 0.35259102675135223'\n",
      "492 - random_40 - lwr_k=500 - 138.97802831331006 - 142.90574356918748 - 140.0420031652186 - 132.41477815393574 - 1026.138772134772 - 316.03269912222845 - 0.3509361101339976'\n",
      "493 - random_71 - lwr_k=20 - 339.08127968418654 - 297.0942251666239 - 313.7439816336038 - 298.6686860655271 - 335.71521394670714 - 316.8605977906997 - 0.3492357825044031'\n",
      "494 - random_65 - lwr_k=20 - 175.98760749313064 - 221.2962291842101 - 227.94877484468705 - 262.24214282100564 - 700.3350612243922 - 317.5226671483083 - 0.34787603297910386'\n",
      "495 - random_71 - lr - 340.11964013218676 - 305.97043657750044 - 311.1225431736462 - 311.55645511542565 - 329.30247797849387 - 319.6141149501964 - 0.3435806444021764'\n",
      "496 - random_63 - lwr_k=50 - 509.37678857634603 - 140.7049673621136 - 140.27046859218154 - 137.90917982653272 - 672.5158595371223 - 320.13503826622207 - 0.3425107788004186'\n",
      "497 - random_50 - lwr_k=500 - 129.1534858920307 - 134.9305433318915 - 134.66970479416665 - 127.48710702584799 - 1077.3552161816065 - 320.65160027262374 - 0.3414498704002332'\n",
      "498 - random_87 - lwr_k=50 - 299.5120668751053 - 377.9226618583964 - 306.4350309708254 - 336.07129987410804 - 283.4275020677295 - 320.67633426883657 - 0.34139907203715736'\n",
      "499 - random_75 - lwr_k=100 - 174.89013458368564 - 161.65227149071998 - 156.28639705236458 - 162.27071703646058 - 950.5038374861492 - 321.0642052858507 - 0.3406024675346211'\n",
      "500 - random_19 - lr - 160.97925503485092 - 144.18748458794852 - 144.55697765825644 - 153.1869600127766 - 1003.2388974711942 - 321.1682365625603 - 0.34038880943747984'\n",
      "501 - random_44 - lwr_k=20 - 311.0290756714738 - 349.45382971816724 - 284.86057821269355 - 342.34503374097284 - 324.96199251391937 - 322.52743224597896 - 0.3375973108367999'\n",
      "502 - random_6 - lwr_k=20 - 340.9305745047269 - 305.68984690745236 - 317.7862286617526 - 317.4774112256381 - 332.25054341544535 - 322.82643202991596 - 0.3369832289289143'\n",
      "503 - random_51 - lwr_k=200 - 138.61400067129085 - 138.99398664424638 - 140.52038192096663 - 138.47474217419554 - 1070.3609303629962 - 325.32583966929235 - 0.33184997768851965'\n",
      "504 - random_85 - lwr_k=1000 - 387.81286749643084 - 348.6300765893698 - 140.4144361707268 - 352.83803512086797 - 397.2824410535383 - 325.38365128935465 - 0.331731244927317'\n",
      "505 - random_2 - lwr_k=500 - 330.67161100183245 - 309.1922555116725 - 311.858184506236 - 310.0737993401885 - 368.59196090286747 - 326.0743808490147 - 0.33031263344792383'\n",
      "506 - random_83 - lwr_k=1000 - 346.737352981269 - 306.7344766444951 - 326.8871976424006 - 312.47891862009976 - 341.95074829192095 - 326.9576771308601 - 0.32849853091299275'\n",
      "507 - random_43 - lwr_k=1000 - 348.3128502921257 - 285.9290193592661 - 318.5045054514263 - 324.88425965102346 - 357.52620636026853 - 327.0279663591996 - 0.3283541718005072'\n",
      "508 - random_33 - lwr_k=1000 - 341.5161103322805 - 310.01583278492427 - 330.5291239369347 - 316.2730863359422 - 338.89687375195484 - 327.44617212116736 - 0.3274952661892173'\n",
      "509 - random_65 - lr - 140.88085922786786 - 137.62479600481475 - 133.45063539603558 - 132.97839228763237 - 1092.8709499089891 - 327.49263657478036 - 0.32739983809242124'\n",
      "510 - random_65 - deep - 156.57644029055518 - 144.64520517908747 - 148.5340109449271 - 177.9367005369958 - 1010.3479159596731 - 327.5441080169668 - 0.32729412557835524'\n",
      "511 - random_93 - lwr_k=1000 - 133.40097908803338 - 139.9631150472708 - 139.11846308978187 - 129.55709691541097 - 1096.515804472352 - 327.64261089718366 - 0.32709182275935766'\n",
      "512 - random_81 - lwr_k=500 - 134.33542664765662 - 144.7775306586659 - 148.92152751129169 - 172.16000793979413 - 1043.8041791110818 - 328.7327279272437 - 0.32485295443369033'\n",
      "513 - random_59 - lwr_k=1000 - 276.0997596617 - 155.29919653197564 - 256.0855708958691 - 301.3940103308482 - 658.394847547034 - 329.4185700087391 - 0.323444380794046'\n",
      "514 - random_43 - lwr_k=500 - 348.64578082579595 - 294.4654798518746 - 322.96054500985156 - 325.77949335393373 - 356.0761749845745 - 329.58277253486784 - 0.3231071437592994'\n",
      "515 - random_12 - lwr_k=500 - 134.67693840447754 - 137.66826724456203 - 140.1141733190693 - 133.44981355349125 - 1102.901194601732 - 329.69285543339004 - 0.3228810569191687'\n",
      "516 - random_85 - lwr_k=500 - 394.9876098264755 - 354.29216768572377 - 145.1373290040152 - 359.89429997191536 - 399.1999414277213 - 330.69054634997286 - 0.3208320121557634'\n",
      "517 - random_33 - lwr_k=500 - 346.54020996972616 - 313.22676430681673 - 329.8429530715619 - 319.2185709014256 - 344.7285865712468 - 330.7111140332129 - 0.32078977051264745'\n",
      "518 - random_2 - lwr_k=1000 - 335.81005554701767 - 306.590514695445 - 319.1311022837993 - 318.9588212141354 - 375.9819390584418 - 331.2906041900147 - 0.31959962108710527'\n",
      "519 - random_83 - lwr_k=500 - 355.5213081264839 - 311.022224697498 - 331.5311711404595 - 317.9422891534837 - 347.0477452601643 - 332.6129759800626 - 0.3168837509246776'\n",
      "520 - random_32 - lwr_k=50 - 341.17025481631595 - 303.2346699716895 - 328.03819099393127 - 343.2734338925891 - 347.62821745354194 - 332.6658856535633 - 0.3167750857182312'\n",
      "521 - random_93 - lwr_k=20 - 219.79240140559173 - 233.95903620883078 - 489.23235574277874 - 300.7740762909725 - 426.59851390167125 - 334.06416882124074 - 0.31390330974546754'\n",
      "522 - random_2 - lwr_k=200 - 341.54107888711036 - 312.0873653745102 - 322.0919107951413 - 312.0367997313766 - 384.35200445166663 - 334.4185262988805 - 0.3131755349187524'\n",
      "523 - random_85 - lwr_k=200 - 398.85485916379395 - 358.4300717746218 - 150.2488445142635 - 365.76907297535405 - 399.90614866677186 - 334.63023196152625 - 0.3127407365536303'\n",
      "524 - random_43 - lwr_k=200 - 351.8183862118462 - 314.16787162613645 - 327.3780429755052 - 326.3832511488971 - 358.85199488723913 - 335.7182538524286 - 0.3105061711977988'\n",
      "525 - random_0 - lr - 137.96209414500817 - 168.85915556815172 - 142.8966887027866 - 149.6721059971517 - 1096.7471514687734 - 339.15928072454267 - 0.30343903449659315'\n",
      "526 - random_43 - lwr_k=50 - 350.1495052424483 - 348.5046012740141 - 322.8841674046618 - 325.54276207311204 - 352.3324832904898 - 339.88293068550036 - 0.3019528115207265'\n",
      "527 - random_83 - lwr_k=20 - 368.3785960565837 - 317.36291685557535 - 332.44172967010275 - 322.89784146299127 - 359.87255285401193 - 340.19044069563876 - 0.3013212514198017'\n",
      "528 - random_43 - lwr_k=100 - 350.5009728740063 - 339.6335316528516 - 327.02693435000316 - 326.27295972687796 - 358.22892771143756 - 340.3322048577897 - 0.30103009800819336'\n",
      "529 - random_50 - deep - 129.36024596266356 - 139.00330842034717 - 135.6857042078065 - 131.20331501130727 - 1169.2733567221826 - 340.8309610621669 - 0.3000057577606682'\n",
      "530 - random_83 - lwr_k=200 - 363.6286144163827 - 318.78630179615874 - 341.1487620170192 - 324.67211463876106 - 356.16541133445463 - 340.88035159967063 - 0.29990432128480116'\n",
      "531 - random_36 - lwr_k=100 - 135.86792328703842 - 148.1375616891273 - 147.11752135275384 - 141.60403713940988 - 1133.7726074875345 - 341.22879413162104 - 0.2991886944974128'\n",
      "532 - random_85 - lwr_k=100 - 396.1672129836264 - 355.16522362425263 - 194.67063580367065 - 363.9791457362995 - 396.6541618328622 - 341.31791817116004 - 0.29900565269210455'\n",
      "533 - random_33 - lwr_k=200 - 359.0928344510073 - 321.9133576974141 - 338.13139628981276 - 329.612377808599 - 358.3695497666869 - 341.4232870835188 - 0.2987892473760835'\n",
      "534 - random_38 - lwr_k=200 - 133.09830498745484 - 135.63868968220973 - 136.734832776959 - 132.1081585606239 - 1170.7246321493662 - 341.5865793443375 - 0.2984538798325148'\n",
      "535 - random_32 - lwr_k=20 - 352.7197567515138 - 318.46631071617537 - 333.6107309151516 - 344.62656392291626 - 360.4277472860173 - 341.9676881529196 - 0.29767116346662126'\n",
      "536 - random_83 - lwr_k=50 - 367.3829187567373 - 321.1427677748211 - 339.22900527702143 - 326.47612109177294 - 356.98467657570535 - 342.2432209479085 - 0.2971052777585984'\n",
      "537 - random_43 - lwr_k=20 - 348.3393604566588 - 360.5108718924127 - 322.00411216918445 - 326.3619798344644 - 355.4599439334663 - 342.5356435028568 - 0.2965047040789557'\n",
      "538 - random_83 - lwr_k=100 - 368.2438832205958 - 321.06326687339555 - 343.1543405518302 - 325.7681810315912 - 360.68517814116507 - 343.78310347874674 - 0.2939426868362711'\n",
      "539 - random_27 - lwr_k=20 - 165.27391487647378 - 175.65520950530242 - 165.48358311777503 - 486.0776999422851 - 727.3341332426423 - 343.9018477724518 - 0.29369881133419273'\n",
      "540 - random_57 - lwr_k=500 - 128.29012649048073 - 138.79816948971595 - 135.89693309916834 - 128.1071612181587 - 1190.5159668263143 - 344.2460708265202 - 0.2929918504561705'\n",
      "541 - random_2 - lwr_k=100 - 353.8839069051023 - 323.4194411695748 - 330.4951235694658 - 321.5038426799486 - 392.87785342969016 - 344.43297227282426 - 0.2926079946713209'\n",
      "542 - random_63 - lwr_k=200 - 505.3931444910546 - 136.52212941235481 - 137.08473383542722 - 132.6186163185643 - 811.430528132591 - 344.5792496767388 - 0.2923075720218673'\n",
      "543 - random_33 - lwr_k=100 - 363.1668864046493 - 324.03155390459955 - 341.87376438170696 - 336.1417654410229 - 362.9772756517336 - 345.6373080139632 - 0.29013454542692496'\n",
      "544 - random_33 - lwr_k=50 - 364.46250996987067 - 324.0530843774306 - 343.9637729565338 - 335.5050514110647 - 364.09518597982344 - 346.41510869899344 - 0.28853710839092095'\n",
      "545 - random_33 - lwr_k=20 - 361.02504406799727 - 331.1235068846739 - 340.66905066766554 - 333.2284327434028 - 367.2163755740412 - 346.6516251719625 - 0.2880513539028915'\n",
      "546 - random_50 - lr - 129.62924817463195 - 144.204996599086 - 137.12783516809992 - 135.86322236185507 - 1188.2673208499652 - 346.9429103868838 - 0.28745311607755764'\n",
      "547 - random_60 - lwr_k=20 - 137.06392964396284 - 147.66620603086992 - 145.8022101947848 - 138.6281944472111 - 1171.7732338288029 - 348.1130685314403 - 0.2850498603411299'\n",
      "548 - random_25 - lwr_k=50 - 148.76871274925324 - 161.32188206407886 - 161.2722579465732 - 139.37993400219537 - 1130.837117437602 - 348.24714787585077 - 0.2847744899092871'\n",
      "549 - random_2 - lwr_k=50 - 358.4371645587134 - 328.328374775101 - 335.4160061311585 - 328.05182239497964 - 393.38035205830255 - 348.71986546613203 - 0.28380362860661734'\n",
      "550 - random_66 - lwr_k=100 - 141.65901757292056 - 154.8264049348747 - 150.78196974953352 - 141.7837610520751 - 1158.260711667324 - 349.39023574264803 - 0.28242683076090547'\n",
      "551 - random_44 - lwr_k=100 - 171.29561933851997 - 169.06333913749776 - 186.68534862506442 - 179.902421494809 - 1041.379066192112 - 349.60252231176224 - 0.281990839337555'\n",
      "552 - random_49 - lwr_k=50 - 138.74148061399447 - 141.33435253575453 - 143.81014903944515 - 141.91687407002203 - 1182.591240519732 - 349.6037982978419 - 0.28198821873376756'\n",
      "553 - random_1 - lwr_k=100 - 149.96525791757836 - 153.8030065773673 - 150.54091703908463 - 152.6790846559976 - 1142.421968508078 - 349.8106036467752 - 0.281563484569877'\n",
      "554 - random_87 - lwr_k=20 - 344.37125456781 - 424.64799247853546 - 348.5289389132234 - 304.9724811732127 - 328.86621888620215 - 350.28538345056836 - 0.2805883879196389'\n",
      "555 - random_59 - lr - 319.48178587689006 - 178.06650326867347 - 284.8001986695862 - 362.57044492655064 - 611.0344121798217 - 351.15812086008293 - 0.2787959710607998'\n",
      "556 - random_83 - lr - 363.7696299337611 - 326.03591516921193 - 350.7869737051994 - 342.58495124871183 - 377.3195164733075 - 352.0975125498749 - 0.2768666604990202'\n",
      "557 - random_9 - lwr_k=20 - 302.2082114835133 - 330.15901281884965 - 372.56053872067787 - 361.5174183833389 - 394.55339726329754 - 352.1935149198015 - 0.27666949206729174'\n",
      "558 - random_51 - lwr_k=100 - 146.57026879680944 - 145.4279017252395 - 144.1165855920299 - 140.02234333000533 - 1189.70500201549 - 353.09361043894927 - 0.2748208874750083'\n",
      "559 - random_41 - lwr_k=50 - 132.90323169606268 - 150.32490701676286 - 148.5446457236356 - 138.50403496613987 - 1199.8731618132224 - 353.95435515300585 - 0.27305310105974545'\n",
      "560 - random_68 - lwr_k=200 - 138.19531284046795 - 138.53177798604725 - 137.39600832904765 - 136.5084003079874 - 1222.9306285134267 - 354.6344207738869 - 0.27165639104056327'\n",
      "561 - random_2 - lwr_k=20 - 371.6861839709122 - 339.8461296528244 - 348.5742280863377 - 337.8040716233937 - 388.3931313193794 - 357.25934778991405 - 0.2662653497199372'\n",
      "562 - random_88 - lwr_k=1000 - 178.68510533758408 - 148.84869035489433 - 492.1284611879276 - 478.8966399096694 - 506.04469307095354 - 360.8891447216314 - 0.2588105194999385'\n",
      "563 - random_63 - lwr_k=500 - 506.8090748262198 - 135.92304625616188 - 134.61041908999258 - 131.6234251808756 - 897.099883273127 - 361.1764126187107 - 0.25822053239028253'\n",
      "564 - random_88 - lwr_k=500 - 179.5254695420315 - 149.3686706246555 - 491.7716649749638 - 479.23614476060214 - 507.03092041193815 - 361.35495352797113 - 0.25785384736880634'\n",
      "565 - random_50 - lwr_k=1000 - 128.79299679322784 - 135.36357172762987 - 133.6993894665904 - 127.38014588507737 - 1282.9537400394224 - 361.55551853057636 - 0.25744192954788614'\n",
      "566 - random_88 - deep - 181.05102338373268 - 150.60943463696788 - 491.704580726921 - 479.05541186201043 - 506.2174563917364 - 361.6961627104525 - 0.25715307509520313'\n",
      "567 - random_88 - lwr_k=200 - 181.16989055027975 - 150.36914564579834 - 491.7443775380599 - 478.9012550950064 - 508.1314555362665 - 362.0316748597754 - 0.2564640058074864'\n",
      "568 - random_88 - lwr_k=100 - 183.05232184345073 - 152.37638814940993 - 491.7254831271572 - 479.02315850316785 - 506.02861157633026 - 362.40997106486424 - 0.2556870659304469'\n",
      "569 - random_6 - lr - 361.2560824060956 - 339.2104608002439 - 357.32993985200454 - 390.50060898261523 - 364.83957585334207 - 362.6237231723227 - 0.25524806460330773'\n",
      "570 - random_88 - lr - 179.0364098649815 - 160.52913773672384 - 492.43333932192013 - 478.87366086597996 - 506.15858221433734 - 363.3752383863545 - 0.2537046123293253'\n",
      "571 - random_49 - lwr_k=20 - 152.02195732803983 - 145.95525346189334 - 152.63066353184792 - 155.98035754643402 - 1212.214074197141 - 363.6835773165972 - 0.2530713498029592'\n",
      "572 - random_32 - lr - 377.80050930634576 - 337.81394324452486 - 348.2771486394862 - 348.6844889878183 - 406.49960387412557 - 363.81183222036765 - 0.25280794153233777'\n",
      "573 - random_88 - lwr_k=50 - 186.49016915365186 - 154.3174185153996 - 493.5330178780925 - 479.00713937506407 - 507.6364336188908 - 364.16584448038145 - 0.2520808757091396'\n",
      "574 - random_10 - lwr_k=20 - 209.34193436074477 - 220.51231706373008 - 204.89929183255745 - 389.56701373528733 - 796.8345828066507 - 364.17607301672166 - 0.25205986847285355'\n",
      "575 - random_63 - lwr_k=1000 - 503.06878503641076 - 135.2261306932298 - 133.78878604553918 - 131.15623776811952 - 918.6689918560809 - 364.3432573398706 - 0.251716507461765'\n",
      "576 - random_88 - lwr_k=20 - 189.4518076912326 - 157.88819364948154 - 498.11927351671096 - 486.0776999422851 - 506.0283231933062 - 367.48220877609776 - 0.24526976940283363'\n",
      "577 - random_91 - lwr_k=20 - 279.9652896387064 - 323.5126283904213 - 357.3204325560207 - 509.0837847447084 - 367.6447553630108 - 367.48837132424126 - 0.24525711284077334'\n",
      "578 - random_41 - lwr_k=200 - 126.59862112827332 - 139.16395727157578 - 142.766669648049 - 133.98576185805808 - 1311.4237231325149 - 370.7032831501428 - 0.23865436831119913'\n",
      "579 - random_98 - lwr_k=20 - 389.62485871837896 - 301.8785420850148 - 497.23874324425077 - 299.7318523974394 - 372.0047434987443 - 372.1044429245729 - 0.23577668440051103'\n",
      "580 - random_25 - lr - 125.88123898515036 - 139.78349250036214 - 139.5960496598232 - 141.98382921097016 - 1316.3613920981775 - 372.63564873038695 - 0.23468570075356976'\n",
      "581 - random_63 - lr - 502.90202578708556 - 170.1815872467879 - 153.10330732557222 - 139.0544017206541 - 902.5346599307984 - 373.51985754836375 - 0.232869724063677'\n",
      "582 - random_63 - deep - 502.37852482604063 - 137.50337131851506 - 134.736380187494 - 131.43993798080757 - 970.2705804795063 - 375.22363784997236 - 0.22937052071636999'\n",
      "583 - random_62 - lwr_k=1000 - 358.7297927307389 - 315.0959417169643 - 339.64657676045584 - 322.28816865075976 - 544.3717208164271 - 376.0126867438299 - 0.2277499835467155'\n",
      "584 - random_25 - lwr_k=1000 - 128.71611882880768 - 127.20380812512312 - 134.38379700982793 - 122.81927285523183 - 1385.4934986273333 - 379.63343155376685 - 0.2203137444579213'\n",
      "585 - random_35 - lwr_k=500 - 506.8090748262198 - 455.1068698386729 - 141.87597274146714 - 143.31595655134007 - 656.2459532962357 - 380.6661788218484 - 0.2181927014110111'\n",
      "586 - random_63 - lwr_k=100 - 518.0748256705018 - 136.83620295431535 - 138.17835147804416 - 134.95687661813633 - 985.264052902169 - 382.61947260438 - 0.2141810517808862'\n",
      "587 - random_85 - lwr_k=50 - 390.8235230685272 - 352.1415211488103 - 422.7847249597311 - 360.41414456172873 - 391.4482675115713 - 383.52425821820367 - 0.2123228147325229'\n",
      "588 - random_80 - lwr_k=20 - 298.2049696476442 - 312.6418692221631 - 322.87278306859406 - 523.3568501180441 - 469.3773651658871 - 385.2641080564436 - 0.20874953352799164'\n",
      "589 - random_79 - lwr_k=100 - 158.89204968038257 - 158.144007841239 - 159.54083413758522 - 177.95454015680744 - 1279.5950628006317 - 386.74322775986946 - 0.20571173651853814'\n",
      "590 - random_80 - lwr_k=200 - 147.9959330810613 - 147.561721344052 - 156.28589693782223 - 143.7031029834643 - 1340.854230849016 - 387.19497399339076 - 0.20478394591846405'\n",
      "591 - random_33 - lr - 365.1234926727854 - 346.91556931154247 - 344.72237661079686 - 416.97095315890635 - 462.9219185209349 - 387.3182338121551 - 0.2045307964891373'\n",
      "592 - random_39 - lwr_k=50 - 287.1211620113395 - 265.9595812982055 - 276.752033329628 - 336.4576864464018 - 770.834620929902 - 387.3851221344563 - 0.20439342211370082'\n",
      "593 - random_12 - lr - 136.57123694935464 - 142.08565676045583 - 142.12060359851762 - 138.13151412397013 - 1387.6324220174918 - 389.2186254199757 - 0.200627796664541'\n",
      "594 - random_58 - lwr_k=500 - 424.0407953308702 - 394.38839303749006 - 422.4408142622013 - 300.9225268817869 - 405.2221740202966 - 389.4116603969779 - 0.200231343913287'\n",
      "595 - random_58 - lwr_k=1000 - 438.46281780445076 - 394.03281582060197 - 420.4686196991951 - 305.13033897510576 - 409.1482253638327 - 393.45727810874746 - 0.19192250632716001'\n",
      "596 - random_85 - lr - 381.9382379505777 - 341.10451418745873 - 170.12979279811918 - 357.9108176409926 - 720.6052415512747 - 394.3029385602891 - 0.19018569977610378'\n",
      "597 - random_7 - lwr_k=1000 - 415.23525796381335 - 290.5462469325465 - 418.7868484758653 - 401.3315092645584 - 448.8778590940942 - 394.94830826317224 - 0.18886024778674182'\n",
      "598 - random_0 - deep - 136.28516573983177 - 152.67779687871172 - 135.28449751105077 - 130.58168735023307 - 1420.5389389459397 - 394.98229409856634 - 0.1887904467544882'\n",
      "599 - random_41 - deep - 130.45087478971797 - 142.14357168315482 - 138.29830419223467 - 133.88729113776859 - 1430.8512620227534 - 395.03333530934606 - 0.18868561897255376'\n",
      "600 - random_35 - lwr_k=1000 - 503.06878503641076 - 455.3520703457946 - 140.271770850242 - 142.9939549140997 - 737.2263455544299 - 395.7719462990592 - 0.18716867058951125'\n",
      "601 - random_8 - lwr_k=500 - 423.0308519360984 - 396.7453456100343 - 376.333856915671 - 397.2951975131929 - 386.0272679738392 - 395.88751809543044 - 0.1869313107216245'\n",
      "602 - random_58 - lwr_k=50 - 430.65406048984295 - 398.84632408681455 - 412.3282397354926 - 318.09152862452163 - 421.4926451997109 - 396.2889175950469 - 0.1861069215956418'\n",
      "603 - random_7 - lwr_k=500 - 416.9623802894702 - 293.8770074243559 - 417.53575753065735 - 403.8000051308611 - 451.82766593631004 - 396.7931197792465 - 0.1850713976392142'\n",
      "604 - random_72 - lwr_k=200 - 152.87247478930084 - 145.5989830240087 - 155.79893752372334 - 141.3533076234521 - 1389.7287867981124 - 396.98206148243855 - 0.1846833516010279'\n",
      "605 - random_58 - lwr_k=200 - 459.9265861195462 - 396.4964999202076 - 419.3977610427825 - 302.8461929863924 - 412.55447113344025 - 398.25403318255474 - 0.18207099249461278'\n",
      "606 - random_8 - lwr_k=1000 - 423.7372957026688 - 396.63928612075443 - 380.4269780394322 - 398.0764258653468 - 392.7966152202633 - 398.33601592943796 - 0.18190261738424696'\n",
      "607 - random_25 - lwr_k=500 - 130.9617752735062 - 127.26955988819934 - 137.4976408140944 - 124.4933456648279 - 1472.0845573308488 - 398.3654133376281 - 0.18184224136567395'\n",
      "608 - random_2 - lr - 414.5059341798812 - 375.2302119300226 - 384.14512578532685 - 403.89216620725733 - 421.1719434184346 - 399.78601786700494 - 0.17892462206754578'\n",
      "609 - random_41 - lr - 130.83890838628056 - 141.95250765149174 - 137.41440862418943 - 132.04598058951586 - 1460.9081701961072 - 400.5369884699794 - 0.17738228830874336'\n",
      "610 - random_8 - lwr_k=200 - 426.4041483559863 - 410.67103098817694 - 378.545213560786 - 397.2603329648874 - 391.3082375120927 - 400.83936558108724 - 0.17676127008978315'\n",
      "611 - random_7 - lwr_k=100 - 419.6604971784067 - 296.6342300188223 - 417.0480046367426 - 412.79488300376585 - 458.5491418313758 - 400.92901468169646 - 0.17657714992080686'\n",
      "612 - random_58 - lwr_k=100 - 470.2135897601471 - 398.8522073315812 - 414.6755484101702 - 307.69545159882364 - 418.81334078098666 - 402.0593389003275 - 0.17425570458875073'\n",
      "613 - random_7 - lwr_k=200 - 426.34445281860235 - 293.83865295180857 - 416.47369178519045 - 408.9335768103856 - 465.7109849026725 - 402.25185663496256 - 0.173860314143213'\n",
      "614 - random_48 - lwr_k=20 - 207.13244002947445 - 257.6612614809367 - 168.80744314307572 - 226.73382052294903 - 1158.0911389722503 - 403.6159235157044 - 0.17105881114016674'\n",
      "615 - random_62 - lwr_k=500 - 342.75140407981434 - 305.725776091624 - 326.1992633835045 - 307.3726326612833 - 736.7520775721872 - 403.7318371120907 - 0.17082074928780855'\n",
      "616 - random_74 - lwr_k=50 - 302.3504502915065 - 334.3079262919369 - 272.9229195599922 - 313.6432691033548 - 800.2475348710774 - 404.6578783262343 - 0.1689188577610844'\n",
      "617 - random_18 - lwr_k=20 - 177.04086462255853 - 1213.9018713392113 - 191.87766995002923 - 256.38241360184713 - 188.4820333546189 - 405.5809174708318 - 0.16702313184615525'\n",
      "618 - random_45 - lwr_k=50 - 408.624076928554 - 370.13687906664825 - 393.2458414381149 - 389.7328743251329 - 468.44225973767544 - 406.03085379454916 - 0.1660990584155415'\n",
      "619 - random_45 - lwr_k=100 - 410.0495349547751 - 374.3084697761769 - 401.30400938129344 - 394.59297272747665 - 454.33860651924084 - 406.9145072063056 - 0.16428422241179574'\n",
      "620 - random_45 - lwr_k=200 - 414.39071193622823 - 377.7520168876763 - 406.5451317414861 - 396.5459038223676 - 447.7952718311866 - 408.60255156622196 - 0.16081733863186776'\n",
      "621 - random_45 - lwr_k=500 - 415.80734878974675 - 375.455785532299 - 407.44938645641224 - 397.0341451725001 - 448.7972572445034 - 408.90542284464385 - 0.1601953054984383'\n",
      "622 - random_45 - lwr_k=1000 - 419.55451471137195 - 375.8806682902378 - 407.16011848614716 - 400.0487135491093 - 444.6801847321165 - 409.46174392375053 - 0.159052740426462'\n",
      "623 - random_27 - lr - 147.74184521970074 - 153.46894379194447 - 150.26454724179848 - 478.87366086597996 - 1118.6067569723386 - 409.697799310348 - 0.15856793291168803'\n",
      "624 - random_8 - lwr_k=100 - 436.0497242132598 - 411.27031430894306 - 379.62681868642767 - 433.52150330515224 - 391.7129035994627 - 410.43572937356004 - 0.15705238164560764'\n",
      "625 - random_81 - lwr_k=200 - 135.64132484030503 - 143.8188585600466 - 149.2846600808839 - 170.6956985994389 - 1456.8069366324123 - 411.1528914411957 - 0.1555794834215415'\n",
      "626 - random_4 - lwr_k=50 - 176.34498303756118 - 164.91576781387568 - 165.3467251336417 - 152.7882962596432 - 1398.6346299261613 - 411.51869164678703 - 0.15482820766743655'\n",
      "627 - random_38 - deep - 127.12060904774611 - 134.3938507035455 - 134.63969293009683 - 125.80516670474343 - 1540.7844388052767 - 412.44774074024815 - 0.15292013717575947'\n",
      "628 - random_45 - lwr_k=20 - 405.5812978208128 - 365.16876428874707 - 391.92333694738545 - 388.40107917130103 - 511.71612249377813 - 412.54911966902074 - 0.15271192785779808'\n",
      "629 - random_7 - lwr_k=50 - 438.7671825931752 - 312.0310544868676 - 428.53865511741685 - 420.5928119723832 - 463.7284920886945 - 412.72457600611074 - 0.15235157789094467'\n",
      "630 - random_80 - lwr_k=50 - 659.1143757719644 - 321.3845435600415 - 258.33131524051095 - 327.69085943515506 - 505.8488880326757 - 414.47344537546996 - 0.14875977248948913'\n",
      "631 - random_29 - lwr_k=20 - 231.59984417124733 - 170.96288025720773 - 417.0571984346971 - 291.9521945634975 - 964.605002457825 - 415.1842915697105 - 0.1472998457249115'\n",
      "632 - random_35 - lwr_k=50 - 509.37678857634603 - 455.2948315128755 - 145.54478577015354 - 146.32742709958544 - 861.9200337135984 - 423.67346913264646 - 0.12986488210859493'\n",
      "633 - random_1 - lwr_k=500 - 143.65637130134502 - 148.68037488611998 - 143.2461898791527 - 146.0772267284606 - 1539.9435259407344 - 424.22024821432024 - 0.12874191426813342'\n",
      "634 - random_12 - lwr_k=100 - 139.59128074151096 - 139.43483126001377 - 143.6520209810902 - 135.1686008055016 - 1566.4697090483517 - 424.76105507002757 - 0.12763121210849426'\n",
      "635 - random_51 - lwr_k=50 - 151.43361424822572 - 156.9825564960746 - 153.68472538041647 - 145.08154329684436 - 1525.47282038607 - 426.4329489662352 - 0.12419749794306212'\n",
      "636 - random_25 - lwr_k=200 - 135.0537113655326 - 138.21670004274642 - 141.74061828740219 - 128.56410404638657 - 1589.6933467517 - 426.5498979397951 - 0.12395730964639085'\n",
      "637 - random_27 - lwr_k=50 - 152.11447026392028 - 165.97022117301597 - 161.3496784328873 - 479.00713937506407 - 1179.8111810850621 - 427.55411213963345 - 0.12189486744779521'\n",
      "638 - random_93 - lwr_k=500 - 141.0969499506055 - 146.9368464830506 - 142.82581254583573 - 136.36886355189048 - 1579.2027738850263 - 429.1834052728569 - 0.11854864618107441'\n",
      "639 - random_15 - lwr_k=50 - 192.6019193562681 - 193.77350569559115 - 289.4956395026566 - 171.67245489468357 - 1311.6637916172983 - 431.76710084019436 - 0.11324228547908577'\n",
      "640 - random_35 - deep - 503.1885410942714 - 455.0202202021754 - 155.97544216323055 - 150.92488532278145 - 900.9542764569817 - 433.1904198958213 - 0.11031908962928783'\n",
      "641 - random_59 - lwr_k=50 - 365.98581406027216 - 237.33751164094096 - 289.5793597173892 - 339.35913748172936 - 935.4395263209427 - 433.4913417122358 - 0.10970106176843308'\n",
      "642 - random_25 - lwr_k=100 - 140.26817594532275 - 151.2344352489459 - 148.83565737931198 - 132.5320187740533 - 1617.4996459311521 - 437.96911641798033 - 0.10050466571028316'\n",
      "643 - random_47 - lwr_k=1000 - 483.05087352481155 - 455.3520703457946 - 285.3585624206935 - 478.8966399096694 - 493.7786785148533 - 439.27607242083894 - 0.09782045629317149'\n",
      "644 - random_47 - lwr_k=200 - 482.61799534957885 - 455.0246171719786 - 291.42940560613454 - 478.9012550950064 - 493.92312400584797 - 440.36823110535045 - 0.09557739484386929'\n",
      "645 - random_47 - lwr_k=100 - 482.82265767174664 - 455.04217765473294 - 298.4769806238237 - 479.02315850316785 - 494.499016254802 - 441.9620485222529 - 0.09230403314672797'\n",
      "646 - random_47 - lwr_k=500 - 482.40411572443696 - 455.1068698386729 - 307.37371830774777 - 479.23614476060214 - 494.05585383543803 - 443.6250175223476 - 0.08888864881806213'\n",
      "647 - random_15 - lwr_k=20 - 264.3109553169571 - 421.2414577431724 - 483.1175657629544 - 312.9967032319342 - 736.5689444950094 - 443.6276519634188 - 0.08888323823689737'\n",
      "648 - random_99 - lwr_k=200 - 646.1269851907447 - 230.6575466805258 - 270.1050127439968 - 708.1247537293159 - 377.39756973792987 - 446.45926578304113 - 0.0830677062192704'\n",
      "649 - random_35 - lwr_k=20 - 502.00205658630125 - 455.09519515867817 - 150.91491845866733 - 152.02460324700476 - 973.8429644281125 - 446.7480685798901 - 0.08247456675222287'\n",
      "650 - random_25 - lwr_k=20 - 164.41502123176247 - 163.4777371273097 - 174.40053399025695 - 144.98211435024106 - 1590.5623460578502 - 447.4666973942412 - 0.0809986561426308'\n",
      "651 - random_27 - deep - 149.65844713518845 - 167.3473240395256 - 157.30258439584057 - 478.89473113464135 - 1286.4686380777898 - 447.8299936916708 - 0.08025252133984395'\n",
      "652 - random_47 - lwr_k=50 - 485.75927339451727 - 455.2948315128755 - 329.1024952340285 - 479.00713937506407 - 496.1541703029807 - 449.0543374966245 - 0.0777379813345419'\n",
      "653 - random_27 - lwr_k=1000 - 143.34608683987136 - 150.425565184399 - 149.9934194276001 - 478.8966399096694 - 1340.5342430865749 - 452.5294882013694 - 0.07060076154507977'\n",
      "654 - random_41 - lwr_k=1000 - 127.65082116015596 - 138.2092596960786 - 134.76940877274154 - 130.3714471316874 - 1742.8148226763076 - 454.6475080657172 - 0.06625079960827607'\n",
      "655 - random_45 - lr - 437.3539032840532 - 385.3729214818108 - 475.64680778616105 - 532.6446896404603 - 447.1307689383473 - 455.62159599862224 - 0.06425023034895916'\n",
      "656 - random_86 - lwr_k=1000 - 493.6592992665988 - 321.42307119062406 - 492.1284611879276 - 478.8966399096694 - 506.04468846045245 - 458.4222620205314 - 0.05849825851995283'\n",
      "657 - random_41 - lwr_k=100 - 129.39639298465883 - 147.32289983139592 - 143.8270731863171 - 136.03759299106642 - 1738.436611227334 - 458.88933353579847 - 0.05753899305347776'\n",
      "658 - random_79 - lwr_k=500 - 134.72711970979006 - 134.72300634144372 - 136.5674502206272 - 140.39712017332636 - 1748.6169184868625 - 458.88979815829435 - 0.05753803881777575'\n",
      "659 - random_86 - lwr_k=500 - 495.88667563842836 - 324.589333541981 - 491.7716649749638 - 479.23614476060214 - 507.0309163967701 - 459.69492340155875 - 0.055884482955759096'\n",
      "660 - random_86 - lwr_k=200 - 494.65960872690505 - 332.32088694410163 - 491.7443775380599 - 478.9012550950064 - 508.1314540365908 - 461.1437485962744 - 0.052908904418380254'\n",
      "661 - random_86 - lwr_k=50 - 494.0701485337385 - 333.7788824332519 - 493.5330178780925 - 479.00713937506407 - 507.6364336188908 - 461.5975120644045 - 0.05197697084783004'\n",
      "662 - random_86 - lwr_k=100 - 496.21026988993447 - 335.4819008606392 - 491.7254831271572 - 479.02315850316785 - 506.02861157633026 - 461.68648481538713 - 0.051794239757011695'\n",
      "663 - random_93 - lwr_k=100 - 165.58238950654786 - 177.23530693139105 - 182.86253424918593 - 181.748255467306 - 1614.889267000648 - 464.3594212152944 - 0.04630459738169146'\n",
      "664 - random_41 - lwr_k=500 - 129.10741769134071 - 138.36010062677167 - 137.70028622094534 - 132.0085248225299 - 1799.7106217614594 - 467.257749715053 - 0.040352047612671194'\n",
      "665 - random_35 - lr - 502.90202578708556 - 455.12912961330176 - 140.04705229450158 - 144.4020254392004 - 1104.3591443300406 - 469.3306709543904 - 0.03609470865145881'\n",
      "666 - random_7 - lwr_k=20 - 529.1042094821139 - 349.04382073177896 - 461.30120833032356 - 440.9045885379532 - 566.6498533680049 - 469.3924854036403 - 0.03596775493119031'\n",
      "667 - random_47 - lwr_k=20 - 502.3653255157837 - 455.09519515867817 - 395.9211152051607 - 486.0776999422851 - 511.04512414502824 - 470.0940611953432 - 0.03452686760002732'\n",
      "668 - random_47 - deep - 483.0658774556124 - 455.7006447923062 - 321.6050875342815 - 478.8849877109047 - 612.4235587423445 - 470.31795271849137 - 0.03406704045092557'\n",
      "669 - random_86 - lwr_k=20 - 534.6772764444208 - 334.2444316559527 - 498.11927351671096 - 486.0776999422851 - 506.0283231933062 - 471.82358705143105 - 0.03097478965716216'\n",
      "670 - random_73 - lr - 141.47530768244877 - 469.83802473814166 - 156.21016407226898 - 155.3269708143483 - 1451.1985580992464 - 474.7309732177661 - 0.025003637369106713'\n",
      "671 - random_57 - lwr_k=200 - 132.90915328992492 - 141.0191107995816 - 137.88243630136162 - 129.03916798466332 - 1838.088877887348 - 475.6658780720446 - 0.023083541812355612'\n",
      "672 - random_85 - lwr_k=20 - 390.50705398013145 - 351.6427096098022 - 902.116610218165 - 360.52352694069674 - 388.185368314238 - 478.62007255884095 - 0.01701625519819705'\n",
      "673 - random_27 - lwr_k=500 - 143.90781513181622 - 152.2265728593852 - 151.0846435679802 - 479.23614476060214 - 1495.7540950712737 - 484.3211166649538 - 0.005307524190016899'\n",
      "674 - random_14 - deep - 503.1889845419588 - 455.020245044619 - 491.7593038338133 - 479.13298014518307 - 506.2174688478907 - 487.06244997811933 - -0.0003225925636465288'\n",
      "675 - random_67 - lwr_k=1000 - 503.06878503641076 - 455.3520703457946 - 492.1284611879276 - 478.8966399096694 - 506.04469307095354 - 487.0968404497935 - -0.00039322159352250807'\n",
      "676 - random_14 - lwr_k=1000 - 503.06878503641076 - 455.3520703457946 - 492.1284611879276 - 478.8966399096694 - 506.04469307095354 - 487.0968404497935 - -0.00039322159352250807'\n",
      "677 - random_14 - lr - 502.90202578708556 - 455.12912961330176 - 492.43333932192013 - 478.87366086597996 - 506.15858221433734 - 487.09804748276673 - -0.00039570058230742333'\n",
      "678 - random_95 - lr - 502.90202578708556 - 455.12912961330176 - 492.4382479520691 - 478.87210458301945 - 506.16117127231894 - 487.0992359250617 - -0.0003981413897966579'\n",
      "679 - random_95 - lwr_k=1000 - 503.06878503641076 - 455.3520703457946 - 492.14157877167634 - 478.8966399096694 - 506.04469307095354 - 487.09946459621244 - -0.0003986110316629432'\n",
      "680 - random_67 - deep - 502.38034176611944 - 456.0576754125493 - 491.71913287478003 - 479.2117388337171 - 506.21319481161606 - 487.1150739468552 - -0.00043067099350557747'\n",
      "681 - random_67 - lwr_k=200 - 505.3931444910546 - 455.0246171719786 - 491.7443775380599 - 478.9012550950064 - 508.1314555362665 - 487.8376073394843 - -0.0019145990973126192'\n",
      "682 - random_95 - lwr_k=200 - 505.3931444910546 - 455.0246171719786 - 491.7443775380599 - 478.9012550950064 - 508.1314555362665 - 487.8376073394843 - -0.0019145990973126192'\n",
      "683 - random_14 - lwr_k=200 - 505.3931444910546 - 455.0246171719786 - 491.7443775380599 - 478.9012550950064 - 508.1314555362665 - 487.8376073394843 - -0.0019145990973126192'\n",
      "684 - random_14 - lwr_k=500 - 506.8090748262198 - 455.1068698386729 - 491.7716649749638 - 479.23614476060214 - 507.03092041193815 - 487.9897006896787 - -0.0022269664623799645'\n",
      "685 - random_67 - lwr_k=500 - 506.8090748262198 - 455.1068698386729 - 491.7716649749638 - 479.23614476060214 - 507.03092041193815 - 487.9897006896787 - -0.0022269664623799645'\n",
      "686 - random_95 - lwr_k=500 - 506.8090748262198 - 455.1068698386729 - 491.7716649749638 - 479.23614476060214 - 507.03092041193815 - 487.9897006896787 - -0.0022269664623799645'\n",
      "687 - random_18 - lwr_k=1000 - 132.6075848945416 - 176.41350677135074 - 157.62264130468648 - 1424.7570674670899 - 549.3881244184913 - 488.0380406268251 - -0.0023262464031179597'\n",
      "688 - random_67 - lwr_k=50 - 509.37678857634603 - 455.2948315128755 - 493.5330178780925 - 479.00713937506407 - 507.6364336188908 - 488.9685976358385 - -0.004237412411223662'\n",
      "689 - random_95 - lwr_k=50 - 509.37678857634603 - 455.2948315128755 - 493.5330178780925 - 479.00713937506407 - 507.6364336188908 - 488.9685976358385 - -0.004237412411223662'\n",
      "690 - random_14 - lwr_k=50 - 509.37678857634603 - 455.2948315128755 - 493.5330178780925 - 479.00713937506407 - 507.6364336188908 - 488.9685976358385 - -0.004237412411223662'\n",
      "691 - random_95 - lwr_k=20 - 502.00205658630125 - 455.09519515867817 - 498.11927351671096 - 486.0776999422851 - 506.0283231933062 - 489.46292837575095 - -0.00525266252242762'\n",
      "692 - random_14 - lwr_k=20 - 502.00205658630125 - 455.09519515867817 - 498.11927351671096 - 486.0776999422851 - 506.0283231933062 - 489.46292837575095 - -0.00525266252242762'\n",
      "693 - random_67 - lwr_k=20 - 502.00205658630125 - 455.09519515867817 - 498.11927351671096 - 486.0776999422851 - 506.0283231933062 - 489.46292837575095 - -0.00525266252242762'\n",
      "694 - random_27 - lwr_k=200 - 145.98636703847995 - 154.90065263077977 - 152.28702057377646 - 478.9012550950064 - 1517.518926762733 - 489.7968496412018 - -0.0059384657195793444'\n",
      "695 - random_67 - lwr_k=100 - 518.0748256705018 - 455.04217765473294 - 491.7254831271572 - 479.02315850316785 - 506.02861157633026 - 489.9782399938295 - -0.006311002891168593'\n",
      "696 - random_95 - lwr_k=100 - 518.0748256705018 - 455.04217765473294 - 491.7254831271572 - 479.02315850316785 - 506.02861157633026 - 489.9782399938295 - -0.006311002891168593'\n",
      "697 - random_14 - lwr_k=100 - 518.0748256705018 - 455.04217765473294 - 491.7254831271572 - 479.02315850316785 - 506.02861157633026 - 489.9782399938295 - -0.006311002891168593'\n",
      "698 - random_56 - lwr_k=20 - 168.50550915356317 - 162.01784198317054 - 174.32379990399124 - 165.9556565180054 - 1844.057995001152 - 502.8516673725913 - -0.032750282350459514'\n",
      "699 - random_73 - lwr_k=1000 - 138.4975887516996 - 140.35875686166844 - 138.6793974706533 - 131.8530001580415 - 1967.8632957748944 - 503.31926470002816 - -0.033710627723201325'\n",
      "700 - random_27 - lwr_k=100 - 148.50229495617828 - 162.10607628619883 - 156.50529033953634 - 479.02315850316785 - 1582.7862232807763 - 505.6585748120845 - -0.038515072722568044'\n",
      "701 - random_73 - lwr_k=20 - 683.1898165077962 - 228.25689982036462 - 314.61104005562584 - 530.1841147091911 - 775.8217175452345 - 506.3775346727043 - -0.039991663230726004'\n",
      "702 - random_73 - lwr_k=100 - 202.04716596217378 - 148.7779598506604 - 173.72452908167847 - 168.09367006864787 - 1861.1889401007156 - 510.6455182108861 - -0.048757192889113954'\n",
      "703 - random_35 - lwr_k=100 - 518.0748256705018 - 455.04217765473294 - 143.99455993654166 - 144.500161482754 - 1298.231091374959 - 511.91830591843643 - -0.05137122790109472'\n",
      "704 - random_1 - lwr_k=200 - 148.03139398226176 - 150.49236953989126 - 146.44690104062425 - 147.9091644822479 - 2067.395017642902 - 531.9168205024181 - -0.09244391975694866'\n",
      "705 - random_81 - lwr_k=50 - 138.49359188853322 - 147.5076966272748 - 149.6962456719083 - 173.77584400424726 - 2054.5249477563702 - 532.6601354331108 - -0.09397053039455328'\n",
      "706 - random_81 - lwr_k=100 - 137.87944236301774 - 145.8163208672473 - 145.93162054022582 - 173.42145838691 - 2061.4901493869065 - 532.7675011756373 - -0.09419103677467211'\n",
      "707 - random_72 - lwr_k=1000 - 147.1441829964498 - 143.90910914642478 - 156.12700578415348 - 141.9589618475572 - 2083.8789783375782 - 534.4648463929909 - -0.09767702253589494'\n",
      "708 - random_35 - lwr_k=200 - 505.3931444910546 - 455.0246171719786 - 143.2474986455911 - 143.44808484489604 - 1425.5257910863038 - 534.4678346616892 - -0.09768315980368625'\n",
      "709 - random_57 - lwr_k=100 - 137.69474722157253 - 143.28593403609037 - 141.7217827763555 - 133.77723057472232 - 2136.624158225312 - 538.4775856576942 - -0.10591833479060919'\n",
      "710 - random_19 - deep - 165.86234132873133 - 152.53186328352464 - 1531.186771454608 - 674.0291101792279 - 188.8618256178509 - 542.5210723651202 - -0.11422279761674647'\n",
      "711 - random_8 - lr - 432.5056033128271 - 395.7437614059816 - 417.786886902991 - 412.0856608128268 - 1083.6015492519716 - 548.2968106830066 - -0.12608493276639'\n",
      "712 - random_7 - deep - 470.1459769722081 - 542.4177439414461 - 578.873384875027 - 659.3377955185981 - 493.5292805720921 - 548.8542182305022 - -0.12722973110428448'\n",
      "713 - random_73 - deep - 149.02476092305952 - 142.9179646698529 - 156.2664387570789 - 149.768539712638 - 2190.3048012631566 - 557.5095500598453 - -0.14500594024423386'\n",
      "714 - random_72 - lwr_k=100 - 163.20879406137635 - 147.87723303442843 - 157.65503815411358 - 143.35543032860124 - 2203.6056137106766 - 562.993934374301 - -0.1562696962399439'\n",
      "715 - random_53 - deep - 178.34847153341548 - 157.65196705322174 - 552.3969789538186 - 150.2634126404468 - 1797.0478820434423 - 567.0441751124724 - -0.1645880304919931'\n",
      "716 - random_79 - lwr_k=50 - 183.0385862233487 - 204.55645775986713 - 219.53408841513556 - 227.79830902052183 - 2040.6121352386087 - 574.9737266103159 - -0.18087363934485357'\n",
      "717 - random_73 - lwr_k=500 - 143.0001274017286 - 140.16773367036078 - 138.49605641697502 - 134.17126294294744 - 2337.6221902133702 - 578.5337385590658 - -0.18818514606502168'\n",
      "718 - random_72 - lwr_k=500 - 153.61048314535964 - 143.22984341926912 - 155.52080306526378 - 140.63748006395434 - 2362.688059199894 - 590.9788013328457 - -0.21374465581199265'\n",
      "719 - random_69 - deep - 144.72874913390126 - 149.25021298001752 - 147.47462885924708 - 143.83003361256613 - 2391.357864498949 - 595.1669731740268 - -0.22234627128502016'\n",
      "720 - random_69 - lwr_k=200 - 135.0785145845866 - 149.6143829385449 - 142.48248758417972 - 315.95678254815755 - 2234.7334474027007 - 595.4099712074905 - -0.22284533546787122'\n",
      "721 - random_79 - lwr_k=20 - 374.03790669973023 - 404.3443847716894 - 390.0694402501206 - 341.8487438524386 - 1501.945599949887 - 602.3725445283189 - -0.2371449789403537'\n",
      "722 - random_69 - lwr_k=1000 - 133.39173422339755 - 145.64318456789223 - 139.89839007679282 - 347.36826575193345 - 2292.3661265270252 - 611.563581353635 - -0.2560214120762616'\n",
      "723 - random_44 - lwr_k=50 - 247.98591748552866 - 207.95658811551993 - 356.61520233776395 - 281.3124424811635 - 2002.450529790537 - 619.1387028607527 - -0.27157909912976463'\n",
      "724 - random_69 - lwr_k=20 - 191.43009224900993 - 181.50942687972704 - 183.5238586076098 - 368.88598802982517 - 2185.195779601294 - 621.9518391407579 - -0.2773566822143463'\n",
      "725 - random_68 - lwr_k=500 - 133.6821216389252 - 137.90343786840387 - 136.34296471554026 - 137.43731461069495 - 2577.3288766039 - 624.363053455303 - -0.2823088031393204'\n",
      "726 - random_61 - lwr_k=20 - 187.1944311881203 - 174.53925778628036 - 186.35416718036763 - 173.66235295227722 - 2401.6798620824593 - 624.5268914506024 - -0.2826452915053417'\n",
      "727 - random_69 - lwr_k=500 - 132.50795229906998 - 146.8711442022648 - 140.24808779757282 - 320.8488289690836 - 2423.6863717110905 - 632.6550054673526 - -0.2993387074576759'\n",
      "728 - random_68 - lwr_k=1000 - 132.31871102215638 - 135.51546059339708 - 135.81954335214598 - 132.55111725605917 - 2720.4090840959534 - 651.1367380659557 - -0.33729625199414515'\n",
      "729 - random_38 - lwr_k=20 - 209.71336860393797 - 204.40583521271415 - 206.7166714052997 - 224.1998685257318 - 2481.7096110192874 - 665.184038991599 - -0.36614641783533886'\n",
      "730 - random_12 - lwr_k=20 - 164.82405672569587 - 167.8886590472942 - 164.6495535824322 - 155.2801758575724 - 2687.5161528292706 - 667.8509044291094 - -0.3716235917462265'\n",
      "731 - random_4 - lwr_k=20 - 197.07825833997293 - 182.80013536546966 - 198.38919467698886 - 192.19261045359056 - 2622.346471935762 - 678.3864371887884 - -0.3932613333274013'\n",
      "732 - random_62 - lr - 419.2758122890797 - 374.24999261170854 - 404.01152278618787 - 386.2515473934395 - 1925.3843176758198 - 701.725678202277 - -0.4411951661263809'\n",
      "733 - random_73 - lwr_k=200 - 142.1695628476818 - 140.08468112931618 - 143.75518651676637 - 143.21622057856376 - 2966.3969653051595 - 706.921071440704 - -0.45186539789063485'\n",
      "734 - random_38 - lwr_k=50 - 171.98097436377265 - 162.0115050732822 - 152.31604534901524 - 169.81824024244577 - 2880.9517639878513 - 707.2193853193394 - -0.45247807109504'\n",
      "735 - random_3 - deep - 158.37796250144808 - 159.46525433682794 - 228.4738366613863 - 227.08670705220564 - 2807.970946972539 - 716.0826354164541 - -0.47068130253476803'\n",
      "736 - random_74 - lwr_k=20 - 345.3012300029885 - 404.53248300601956 - 427.21949294593986 - 350.70703790401876 - 2161.0353945311217 - 737.6347758026932 - -0.5149448085995785'\n",
      "737 - random_69 - lwr_k=50 - 150.39988129154713 - 157.76996529661923 - 151.46354136506451 - 365.4811322044281 - 2907.2025933736736 - 746.2498433374718 - -0.5326383234197622'\n",
      "738 - random_62 - lwr_k=20 - 356.87038919697295 - 327.7084465921732 - 341.62464693985055 - 328.5583245608039 - 2436.2084264618256 - 758.0442353189654 - -0.5568614938681842'\n",
      "739 - random_18 - deep - 147.18839603279906 - 296.425105128663 - 2726.1706203959557 - 302.3886218122503 - 508.2705925074803 - 796.1824651219785 - -0.6351893021116934'\n",
      "740 - random_99 - lwr_k=100 - 1246.164422711426 - 170.51150699310713 - 293.55238535598136 - 1528.0397522719636 - 881.7539696051873 - 823.9129895419669 - -0.6921418935083299'\n",
      "741 - random_8 - lwr_k=20 - 2347.4479171179005 - 532.6613963151747 - 384.09129016921565 - 489.30863205541704 - 397.86184413561926 - 830.3670250257152 - -0.705397108516302'\n",
      "742 - random_69 - lwr_k=100 - 141.2984203303717 - 152.61319692362986 - 146.7885838026411 - 326.3224165670325 - 3386.6853506711273 - 830.495400861658 - -0.7056607651558626'\n",
      "743 - random_59 - deep - 400.4573701836781 - 156.1778003959221 - 478.44895774873345 - 2849.870403825593 - 588.9633785376028 - 894.5856697814711 - -0.8372885376532075'\n",
      "744 - random_18 - lwr_k=500 - 132.21706938998867 - 713.2096244139417 - 165.07894872051855 - 264.19653252125437 - 3366.5632011640055 - 928.0401562951995 - -0.9059969283869829'\n",
      "745 - random_67 - lr - 502.90202578708556 - 455.13354427700506 - 492.43333932192013 - 478.87107469987996 - 2834.8003860744298 - 952.659105435795 - -0.956559009266557'\n",
      "746 - random_18 - lwr_k=100 - 143.3629492881272 - 791.6848580797717 - 157.7796612433904 - 238.1511077195366 - 3538.020425677811 - 973.5803629923198 - -0.9995268187629871'\n",
      "747 - random_58 - lwr_k=20 - 3824.585308196234 - 407.81006426781914 - 410.0442837948741 - 344.3409764422192 - 439.62389374442154 - 1085.4473035778922 - -1.229277701521478'\n",
      "748 - random_58 - deep - 502.36658298833396 - 948.5503583243312 - 2912.357280106479 - 429.4099433596681 - 644.8838971929104 - 1087.6457111866227 - -1.2337927665206188'\n",
      "749 - random_9 - lwr_k=50 - 322.84494817368955 - 320.0197462189366 - 533.6758211692527 - 368.3681525486948 - 4036.9187844776993 - 1116.1047733742498 - -1.292241618403311'\n",
      "750 - random_81 - lwr_k=20 - 145.34149861172824 - 149.65455977671206 - 152.03151997215178 - 184.02335967022347 - 5126.965220312031 - 1151.2422833766404 - -1.3644065841986275'\n",
      "751 - random_57 - lwr_k=20 - 181.5774408323599 - 178.3324827754665 - 177.4521261204018 - 170.0770819219421 - 5562.272916954626 - 1253.555458421375 - -1.574536066253878'\n",
      "752 - random_37 - lwr_k=20 - 304.06585133339604 - 312.45177804958024 - 537.9363745183085 - 259.2715564920578 - 4856.266611518718 - 1253.6855169098035 - -1.5748031787034567'\n",
      "753 - random_86 - deep - 496.1046033652156 - 2863.278013196189 - 491.86648182906146 - 479.30872820319536 - 2049.232905613417 - 1275.960992707826 - -1.6205522685908473'\n",
      "754 - random_62 - lwr_k=50 - 340.1150818835791 - 308.93053946423277 - 343.4796739539632 - 311.4184842853421 - 5089.556490939785 - 1278.3588114716335 - -1.6254768735096938'\n",
      "755 - random_39 - lwr_k=20 - 303.6297832297058 - 286.9765990849504 - 293.237536511726 - 329.6173805219322 - 5237.4677528179445 - 1289.827390474957 - -1.649030893457021'\n",
      "756 - random_18 - lwr_k=200 - 133.97908568198747 - 463.4151076580387 - 152.17173250463813 - 729.9211942198206 - 5321.153995392565 - 1359.728508853629 - -1.7925929107003609'\n",
      "757 - random_62 - lwr_k=100 - 336.98559316692246 - 307.6108128783261 - 329.9014892559574 - 307.0022916441466 - 5931.424418588256 - 1442.1825141862823 - -1.9619358856041882'\n",
      "758 - random_99 - lwr_k=20 - 1724.8417011682297 - 618.4201385289807 - 1185.33855763439 - 2287.8356687649225 - 2252.834969480786 - 1613.6966453461093 - -2.3141894006574817'\n",
      "759 - random_8 - deep - 780.578552355935 - 1311.9957604182289 - 2913.611722382086 - 445.37969996348147 - 2848.3102757704646 - 1659.9783451928695 - -2.4092421658402112'\n",
      "760 - random_99 - lwr_k=50 - 1528.9618674674082 - 222.23157140487436 - 404.0993467515566 - 4402.931468657079 - 2062.864794442125 - 1723.855711983465 - -2.5404326738828162'\n",
      "761 - random_53 - lwr_k=20 - 175.04296982552185 - 147.17331324415935 - 153.52196173857317 - 135.9003423181355 - 8180.207794185984 - 1757.7933288745019 - -2.6101333146496097'\n",
      "762 - random_91 - deep - 163.55087788575554 - 2867.0713804504726 - 2915.894576797531 - 380.9081322714633 - 2850.5447636085682 - 1835.646710299475 - -2.770027593710397'\n",
      "763 - random_62 - lwr_k=200 - 334.1612316923726 - 303.2142828973384 - 322.66566841417045 - 300.29545486384933 - 7945.297578767893 - 1840.5792207005825 - -2.780157913761995'\n",
      "764 - random_53 - lwr_k=100 - 164.01278652455355 - 140.92577533740476 - 148.57783701605612 - 133.74857395457406 - 8759.141121360311 - 1868.662674825903 - -2.837835350388273'\n",
      "765 - random_87 - lr - 260.3258756242779 - 364.5362870597241 - 271.0569889572548 - 8339.018260006638 - 251.85484037055278 - 1896.7828886372702 - -2.895588283584628'\n",
      "766 - random_53 - lwr_k=1000 - 164.45156333602225 - 142.2044822476553 - 144.6233470957251 - 131.698647110533 - 9433.780976594975 - 2002.6847234717316 - -3.1130881089271245'\n",
      "767 - random_93 - lwr_k=50 - 195.63821300615834 - 204.16999650799826 - 317.55861144278015 - 257.3876834178569 - 10079.919149626483 - 2210.224849920447 - -3.5393313494216345'\n",
      "768 - random_85 - deep - 2817.2383118591124 - 2873.3193108936807 - 188.67033292865352 - 2853.3544833949204 - 2856.6673406667355 - 2317.7210401258058 - -3.760105649290172'\n",
      "769 - random_39 - deep - 2801.3367929441456 - 2857.01990602856 - 2905.7142402085988 - 2837.4308791876124 - 214.21484048483896 - 2323.3346894965225 - -3.771634890134977'\n",
      "770 - random_43 - deep - 2788.4330230877654 - 322.1948002550369 - 2892.623697282028 - 2824.17059773128 - 2827.614353944703 - 2330.8884983341823 - -3.787148805528285'\n",
      "771 - random_45 - deep - 2783.855895153977 - 2839.1569835935156 - 2887.921557631833 - 2819.556277491465 - 839.4297203256302 - 2434.1291704416844 - -3.999183169469151'\n",
      "772 - random_53 - lwr_k=500 - 163.63375351776642 - 139.86719551316233 - 144.40808101181784 - 131.85505017208402 - 12611.223613929675 - 2637.3015009570136 - -4.416455878505663'\n",
      "773 - random_32 - deep - 2786.4240709475293 - 2841.785205312453 - 2890.5706172730297 - 2822.2725515010693 - 2825.632830964417 - 2833.3393141485794 - -4.8190758258390405'\n",
      "774 - random_71 - deep - 2787.0943188315464 - 2842.4599874458704 - 2891.298395643137 - 2822.811051275979 - 2826.2078096863747 - 2833.9765939427207 - -4.820384662880148'\n",
      "775 - random_33 - deep - 2788.855815555639 - 2844.2301730571853 - 2893.004397313897 - 2824.6564472468676 - 2828.0574070448492 - 2835.763098833028 - -4.824053763636284'\n",
      "776 - random_2 - deep - 2797.6633287600293 - 2853.2999184831 - 2902.1253081414966 - 2833.5765183026338 - 2836.9280435807136 - 2844.7209013088395 - -4.842451183097955'\n",
      "777 - random_6 - deep - 2800.7681579406776 - 2856.423672443246 - 2905.2261484714777 - 2836.576686533989 - 2840.001410915929 - 2847.8015018429332 - -4.848778080835722'\n",
      "778 - random_83 - deep - 2813.9780122588763 - 2869.929057596684 - 2918.796074915876 - 2850.0938959568202 - 2853.3819751533424 - 2861.2380673917696 - -4.876373926266974'\n",
      "779 - random_87 - lwr_k=1000 - 260.7425965221717 - 355.6379397547679 - 15444.929881695756 - 284.2500885508129 - 288.25922823394154 - 3327.4936983708008 - -5.833963730233679'\n",
      "780 - random_59 - lwr_k=20 - 7718.255489063622 - 6730.62122266693 - 399.293651262539 - 427.0992387196878 - 3501.845218133339 - 3755.852809339568 - -6.713722159020186'\n",
      "781 - random_53 - lwr_k=200 - 163.0396159037221 - 139.04407489987813 - 148.9679674763766 - 133.62567247597102 - 18474.303827072235 - 3810.4780583943407 - -6.825910792458643'\n",
      "782 - random_58 - lr - 448.3626844706692 - 19475.172748484183 - 442.83928426137425 - 687.9120627230493 - 394.43074538854034 - 4290.6431983575385 - -7.812067776809272'\n",
      "783 - random_68 - lr - 137.93304938312784 - 139.44161009090666 - 141.07775542327386 - 132.56235439045574 - 24824.6509284832 - 5073.356234837553 - -9.419593736995003'\n",
      "784 - random_62 - deep - 2792.6447794913674 - 2848.0882246890465 - 2896.8468760837677 - 2828.461788621699 - 22694.458610983456 - 6810.67184116784 - -12.987670192114582'\n",
      "785 - random_8 - lwr_k=50 - 61701.393849633896 - 452.1164118959484 - 379.52718528806355 - 419.3307296228785 - 392.00384157086796 - 12671.817691042148 - -25.0252160775288'\n",
      "786 - random_96 - lr - 149.8694672774325 - 163.9016254089808 - 6522.76005925326 - 68040.94698723959 - 217.20805870786586 - 15014.350622444723 - -29.83628006178859'\n",
      "787 - random_36 - lr - 161.1317437144016 - 151.16532302646004 - 145.30783242605304 - 83610.1405055788 - 830.8898017524064 - 16973.669009831403 - -33.860302947823335'\n",
      "788 - random_7 - lr - 149985.96590899257 - 290.95490482015185 - 402.67129159092025 - 394.8627145765992 - 457.2151300186347 - 30313.505547678327 - -61.25748753498796'\n",
      "789 - random_95 - deep - 503.19130660562223 - 209012.48177336273 - 491.7031228397875 - 479.4458337167875 - 506.21734813310087 - 42208.61248296456 - -85.68750520466152'\n",
      "790 - random_34 - lr - 130.3268606371313 - 140.39854939391952 - 140.23699859772756 - 138.67869486625986 - 236773.18743459394 - 47447.52709790769 - -96.4471204664164'\n",
      "791 - random_18 - lr - 169.97623939635236 - 751.076242683079 - 480.6633578082195 - 201192.39293006135 - 114024.17389878692 - 63301.027318127184 - -129.00683517159462'\n",
      "792 - random_30 - lr - 513036.00874592277 - 147.64410691304434 - 144.00475977058755 - 139.3611738351832 - 293.26426859201484 - 102776.6661739228 - -210.08139417087904'\n",
      "793 - random_47 - lr - 483.11166472701484 - 31785.14211755662 - 279.036804237354 - 950950.3346408763 - 493.9580765123603 - 196731.37226387855 - -403.04436026692247'\n",
      "794 - random_98 - lr - 142.91846955467778 - 151.13488784087122 - 3210529.942875008 - 133.52115593700242 - 148.0649610973413 - 642375.2219117241 - -1318.301962884239'\n",
      "795 - random_43 - lr - 388.1370504105614 - 3470272.9537143284 - 603.3269532844857 - 397.09041741192215 - 1096.4771171952655 - 694718.1168665066 - -1425.803126847842'\n",
      "796 - random_72 - lr - 144.1389585057595 - 149.667741718644 - 1695708826.5568273 - 167.33949986893896 - 22625.679654604373 - 339227778.32904243 - -696700.64500191'\n",
      "797 - random_53 - lr - 167.98545100747606 - 144.38762025565006 - 166.48582598026888 - 132.41188579033215 - 6070716641.049677 - 1213706341.3950245 - -2492693.462594868'\n",
      "798 - random_81 - lr - 137.3873574670042 - 19048.189067130163 - 14280.262733901236 - 7817.723236233355 - 118478223863.6559 - 23687122257.138065 - -48648305.8196794'\n",
      "799 - random_86 - lr - 1956927.3336650005 - 406.46351918219364 - 492.4333458821891 - 2512254.1245088237 - 3877194717197632.0 - 775159775147050.1 - -1592013169275.5464'\n"
     ]
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(all_scores)\n",
    "scores_df.to_csv(log_dir/f\"scores.csv\",index=False)\n",
    "scores_df_final = pd.DataFrame(all_scores_final)\n",
    "scores_df_final.to_csv(log_dir/f\"test_scores.csv\",index=False)\n",
    "\n",
    "scores_df_sorted = pd.DataFrame(scores_df).sort_values(by='MSE')\n",
    "\n",
    "best_5 = []\n",
    "summary_logger.info(f\"Rank - \" +\" - \".join(list(scores_df_sorted.columns)))\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    if i < 5:\n",
    "        best_5.append((row[\"model_num\"],row[\"predictor\"],row[\"MSE\"]))\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    summary_logger.info(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save scores\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      " Best 5 on Test Sest \n",
      " ---------------------'\n",
      "Rank -  Deep Model - Predictor - Val Set - Test Set'\n",
      "0 - random_92 - lwr_k=1000 - 131.00467565172946 - 131.77165925399106 - 0.7257886623181209'\n",
      "1 - random_94 - lwr_k=1000 - 133.41713969938297 - 135.67105866292707 - 0.7176741744674423'\n",
      "2 - random_94 - lwr_k=500 - 133.7871215839738 - 138.2341076131809 - 0.7123405762933572'\n",
      "3 - random_92 - lwr_k=500 - 134.25678266764442 - 133.14681035855597 - 0.7229270301125901'\n",
      "4 - random_77 - lwr_k=1000 - 134.43967722295096 - 127.09110594277932 - 0.7355286989225385'\n"
     ]
    }
   ],
   "source": [
    "summary_logger.info(\"-----------------------\\n Best 5 on Test Sest \\n ---------------------\")\n",
    "summary_logger.info(f\"Rank -  Deep Model - Predictor - Val Set - Test Set\")\n",
    "for i, (j,k,v) in enumerate(best_5):\n",
    "\n",
    "    row = scores_df_final.loc[(scores_df_final['model_num']==j) & (scores_df_final['predictor'] == k)].iloc[0]\n",
    "    #print(row)\n",
    "    s = f\"{i} - {j} - {k} - {v} - {row['MSE']} - {row['R2']}\"\n",
    "    summary_logger.info(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote Summary Graph'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#take 1 is a scatter plot - lets, for each dataset\n",
    "#graph our deep models by rank - plot - then overlay our knn moels\n",
    "#plot points\n",
    "\n",
    "deep_set = scores_df[scores_df[\"predictor\"]==\"deep\"].sort_values(\"R2\")\n",
    "deep_set[\"order\"] = [i for i in range(0,100)]\n",
    "deep_ordering = {row[\"model_num\"]:row[\"order\"] for index, row in deep_set.iterrows()}\n",
    "\n",
    "def order_models(x):\n",
    "    x = [deep_ordering[i] for i in x]\n",
    "    return x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df[scores_df[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    if knn_model == \"deep\":\n",
    "        s=10\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot.png\", bbox_inches='tight')\n",
    "logging.getLogger().info(\"Wrote Summary Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (lazydeep)",
   "language": "python",
   "name": "pycharm-12fcba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
