{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# set seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import utils as ut\n",
    "import experiment as exp\n",
    "from evaluation import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import random\n",
    "#define fixed_hyperparams and create a config gen\n",
    "from configurations import RandomConfigGen, Configuration\n",
    "from torch import nn\n",
    "from deep_net import RandomNet\n",
    "from experiment import run_experiment\n",
    "import regex as re\n",
    "from pathlib import *\n",
    "from plot import *\n",
    "from sk_models import setup_pls_models_slim\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "random_state = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\workspace\\lazydeep\\experiments\\2.01\\mango_513_1050\n"
     ]
    }
   ],
   "source": [
    "#setup input and output formats, load data\n",
    "\n",
    "file_name = \"mango_513_1050.csv\"\n",
    "id_cols =['Set','Season','Region','Date','Type','Cultivar','Pop','Temp','FruitID']#\n",
    "output_cols = ['DM']\n",
    "n_comps = [i for i in range(1,101)]\n",
    "\n",
    "data_path = Path('D:/workspace/lazydeep/data/soil_data/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/2.01\")\n",
    "model_path = Path('D:/workspace/lazydeep/experiments/2.00/')\n",
    "data_file = data_path / file_name\n",
    "\n",
    "log_dir = log_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "model_dir = model_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)/\"models\"\n",
    "\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "print(log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% load data\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is (11691, 190)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data = data.sample(frac=1)\n",
    "nrow, ncol = data.shape\n",
    "data = ut.sample_data(data,random_state)\n",
    "n_features = ncol - 1-len(id_cols)\n",
    "dataset = ut.TabularDataset(data,id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "eval = MangoesSplitter(preprocessing=None,tensorboard=None,time=True,random_state=random_state)\n",
    "print(f\"Dataset shape is {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% load models\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 models\n"
     ]
    }
   ],
   "source": [
    "n_models = 100\n",
    "model_names = [f\"random_{i}\" for i in range(0,n_models)]\n",
    "deep_models = {name:torch.load(model_dir/name/\"_model\") for name in model_names}\n",
    "#for each model, load state\n",
    "print(f\"Loaded {len(deep_models)} models\")\n",
    "#print(deep_models)\n",
    "for name in model_names:\n",
    "    sub_path = log_dir / name\n",
    "    if not sub_path.exists():\n",
    "        sub_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup logging and tensorboard outputs\n"
    }
   },
   "outputs": [],
   "source": [
    "# set logging, in this case the root logger\n",
    "ut.setup_logger(logger_name=\"\",file_name=log_dir/\"log.txt\")\n",
    "ut.setup_logger(logger_name=\"summary\",file_name=log_dir/\"summary.txt\")\n",
    "summary_logger = logging.getLogger(\"summary\")\n",
    "tb = SummaryWriter(log_dir/\"tb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup experiment\n"
    }
   },
   "outputs": [],
   "source": [
    "fixed_hyperparams = {'bs': 32,'loss': nn.MSELoss(),'epochs': 100}\n",
    "preprocessing = None#Preprocess_Std()\n",
    "eval = CrossValEvaluation(preprocessing=preprocessing,tensorboard=None,time=True)\n",
    "scores={} #->model->knn:{fold_0:number,...,fold_n:number,mean:number,median:number\n",
    "preds={} #model-> foldsxknn_models\n",
    "deep_scores_dict={}\n",
    "deep_preds_dict={}\n",
    "actual_y = None\n",
    "\n",
    "device = \"cpu\" #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_fun_cv = lambda name,model, fold : model.load_state(model_dir/name/f\"_fold_{fold}\")\n",
    "load_fun_build = lambda name,model : model.load_state(model_dir/name/f\"_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% deep experiment\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Tested (test) on 1949 instances with mean losses of: random_0:4.6742,random_1:4.9521,random_2:5.1038,random_3:1.6768,random_4:6.0408,random_5:0.6398,random_6:5.4773,random_7:70.3993,random_8:5.2345,random_9:3.0102,random_10:1.5758,random_11:2.8468,random_12:1.195,random_13:2.7394,random_14:6.3428,random_15:3.8803,random_16:1.2451,random_17:2.7659,random_18:1.2486,random_19:4.1118,random_20:4.3596,random_21:6.0672,random_22:10.9483,random_23:2.9532,random_24:6.0758,random_25:3.6459,random_26:0.6934,random_27:5.3205,random_28:6.6927,random_29:3.8216,random_30:0.8512,random_31:2.5595,random_32:5.2996,random_33:268.0037,random_34:2.7018,random_35:3.4595,random_36:0.8048,random_37:4.134,random_38:4.2124,random_39:5.3565,random_40:0.6489,random_41:4.3224,random_42:0.6699,random_43:4.7179,random_44:6.7839,random_45:269.0776,random_46:4.6872,random_47:3.9091,random_48:0.6969,random_49:4.4173,random_50:3.856,random_51:6.4728,random_52:2.0029,random_53:0.9578,random_54:0.8537,random_55:0.9667,random_56:0.7636,random_57:0.7537,random_58:4.6712,random_59:3.0856,random_60:3.9477,random_61:1.6743,random_62:275.509,random_63:4.349,random_64:0.8492,random_65:2.5655,random_66:0.8163,random_67:5.7679,random_68:1.3533,random_69:0.9665,random_70:2.2117,random_71:266.193,random_72:0.8173,random_73:6.0939,random_74:1.86,random_75:6.0685,random_76:4.2449,random_77:0.6829,random_78:1.0661,random_79:2.9353,random_80:2.0229,random_81:4.1304,random_82:0.9507,random_83:4.8706,random_84:1.537,random_85:5.9824,random_86:6.0673,random_87:6.7441,random_88:6.0673,random_89:4.408,random_90:267.4229,random_91:9.8373,random_92:2.1947,random_93:5.498,random_94:0.7482,random_95:5.7169,random_96:4.9295,random_97:0.83,random_98:2.8052,random_99:4.7573'\n",
      "Testing (test) took 0:00:03.588999'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Tested (test) on 1949 instances with mean losses of: random_0:4.0171,random_1:4.2727,random_2:5.8809,random_3:3.3732,random_4:3.9242,random_5:0.672,random_6:7.8373,random_7:7.2288,random_8:5.435,random_9:2.3319,random_10:2.7638,random_11:3.0219,random_12:1.2074,random_13:3.2146,random_14:6.3858,random_15:5.6766,random_16:0.7045,random_17:1.9056,random_18:2.8033,random_19:4.364,random_20:4.5467,random_21:6.1991,random_22:3.2019,random_23:1.5619,random_24:6.1965,random_25:5.2662,random_26:0.6765,random_27:4.6206,random_28:6.6606,random_29:5.5761,random_30:1.0004,random_31:2.7811,random_32:5.0165,random_33:270.6656,random_34:2.8263,random_35:4.2324,random_36:0.777,random_37:4.1589,random_38:4.4088,random_39:9.1081,random_40:0.6583,random_41:4.4264,random_42:0.7055,random_43:5.0826,random_44:6.0689,random_45:271.7428,random_46:5.143,random_47:3.7935,random_48:0.868,random_49:6.3301,random_50:6.008,random_51:4.0079,random_52:3.1433,random_53:0.9483,random_54:1.1658,random_55:0.805,random_56:0.8063,random_57:0.8076,random_58:4.4964,random_59:3.2128,random_60:4.8855,random_61:1.8313,random_62:4.7768,random_63:4.9651,random_64:0.9358,random_65:2.727,random_66:0.9721,random_67:5.6621,random_68:0.9248,random_69:1.0276,random_70:3.6169,random_71:268.8438,random_72:4.9641,random_73:6.2113,random_74:2.9913,random_75:5.5022,random_76:5.1928,random_77:0.7521,random_78:1.1341,random_79:2.3351,random_80:1.991,random_81:5.5859,random_82:1.641,random_83:5.1231,random_84:1.5717,random_85:5.3178,random_86:3.6719,random_87:6.3289,random_88:6.2116,random_89:3.9317,random_90:270.0808,random_91:5.3477,random_92:2.2373,random_93:5.2904,random_94:0.8514,random_95:7.381,random_96:1.415,random_97:0.6974,random_98:3.3622,random_99:5.8945'\n",
      "Testing (test) took 0:00:03.491004'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Tested (test) on 1948 instances with mean losses of: random_0:6.1501,random_1:4.5512,random_2:4.4428,random_3:5.3042,random_4:5.2584,random_5:0.6883,random_6:5.4191,random_7:7.7095,random_8:4.5378,random_9:2.3466,random_10:3.2771,random_11:2.7858,random_12:1.0552,random_13:3.0003,random_14:5.9209,random_15:3.9527,random_16:0.7456,random_17:1.5256,random_18:2.5502,random_19:4.0153,random_20:4.4762,random_21:5.9308,random_22:3.1693,random_23:2.1567,random_24:5.0961,random_25:3.7271,random_26:0.7315,random_27:4.3909,random_28:4.1918,random_29:5.9223,random_30:0.9538,random_31:2.9597,random_32:5.4597,random_33:264.9743,random_34:2.935,random_35:2.7836,random_36:0.7064,random_37:3.8429,random_38:4.7931,random_39:3.8354,random_40:0.6965,random_41:5.1551,random_42:0.7279,random_43:4.8962,random_44:4.1493,random_45:266.0397,random_46:4.1836,random_47:4.0651,random_48:0.9231,random_49:6.4786,random_50:5.9228,random_51:4.0526,random_52:2.4532,random_53:1.799,random_54:1.3685,random_55:0.8476,random_56:1.0517,random_57:0.8937,random_58:5.2033,random_59:3.272,random_60:4.3605,random_61:1.1819,random_62:6.7157,random_63:5.9222,random_64:0.9427,random_65:2.4422,random_66:0.9806,random_67:5.935,random_68:1.1068,random_69:0.8881,random_70:1.1186,random_71:263.1718,random_72:0.8677,random_73:4.1473,random_74:2.2637,random_75:6.1806,random_76:4.0262,random_77:0.7412,random_78:1.1032,random_79:2.5019,random_80:2.0775,random_81:4.7746,random_82:0.7611,random_83:4.7836,random_84:1.4001,random_85:4.8412,random_86:3.7998,random_87:5.0388,random_88:4.1634,random_89:3.9282,random_90:264.3964,random_91:4.9712,random_92:2.8177,random_93:4.4785,random_94:0.8586,random_95:5.2351,random_96:3.0748,random_97:1.176,random_98:2.7206,random_99:5.1726'\n",
      "Testing (test) took 0:00:03.382998'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Tested (test) on 1948 instances with mean losses of: random_0:6.2698,random_1:3.8899,random_2:4.9205,random_3:3.735,random_4:4.6248,random_5:0.6968,random_6:5.5831,random_7:4.1998,random_8:6.4707,random_9:3.1566,random_10:2.6425,random_11:3.0087,random_12:0.9958,random_13:2.5385,random_14:5.9526,random_15:4.7779,random_16:2.2732,random_17:3.8634,random_18:2.3529,random_19:4.0789,random_20:4.4416,random_21:5.8594,random_22:3.2731,random_23:2.287,random_24:5.8714,random_25:5.2186,random_26:0.7256,random_27:3.9388,random_28:3.9997,random_29:3.7689,random_30:1.1192,random_31:2.6019,random_32:3.4902,random_33:267.0208,random_34:3.2392,random_35:2.9718,random_36:0.6925,random_37:3.9028,random_38:3.7614,random_39:3.448,random_40:0.615,random_41:3.9417,random_42:0.7085,random_43:267.4926,random_44:3.9799,random_45:268.0914,random_46:4.2313,random_47:5.8717,random_48:0.7904,random_49:3.7719,random_50:5.6835,random_51:3.7677,random_52:3.2401,random_53:1.4685,random_54:0.8022,random_55:2.1345,random_56:0.8263,random_57:0.8252,random_58:6.2739,random_59:3.4835,random_60:4.7884,random_61:1.3536,random_62:4.83,random_63:4.0179,random_64:0.9912,random_65:2.8682,random_66:1.0972,random_67:5.8172,random_68:1.7343,random_69:0.9999,random_70:1.4843,random_71:265.2078,random_72:0.7645,random_73:5.8869,random_74:1.6514,random_75:3.8978,random_76:4.0098,random_77:0.7339,random_78:0.8989,random_79:3.5421,random_80:2.1122,random_81:4.3382,random_82:1.4132,random_83:4.8621,random_84:1.4606,random_85:5.4268,random_86:5.6792,random_87:4.8913,random_88:5.8713,random_89:6.3785,random_90:266.4396,random_91:5.0062,random_92:2.2074,random_93:3.9002,random_94:1.2999,random_95:6.4749,random_96:5.1165,random_97:1.2027,random_98:2.9618,random_99:5.3147'\n",
      "Testing (test) took 0:00:03.431001'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Tested (test) on 1948 instances with mean losses of: random_0:6.6998,random_1:5.2702,random_2:279.8546,random_3:4.0395,random_4:7.0522,random_5:0.7224,random_6:6.1606,random_7:96.4766,random_8:9.2974,random_9:2.6112,random_10:3.6474,random_11:3.4899,random_12:1.2983,random_13:3.4602,random_14:6.2993,random_15:5.4457,random_16:1.5127,random_17:2.0618,random_18:2.4734,random_19:3.752,random_20:4.0652,random_21:6.1613,random_22:6.3389,random_23:1.6361,random_24:5.5002,random_25:4.1862,random_26:0.7668,random_27:5.4083,random_28:6.7643,random_29:4.0765,random_30:1.2094,random_31:2.6845,random_32:4.7223,random_33:270.1058,random_34:2.8905,random_35:3.0932,random_36:0.7815,random_37:4.3626,random_38:4.1046,random_39:5.7163,random_40:0.6902,random_41:6.1613,random_42:0.7036,random_43:4.8369,random_44:6.6789,random_45:271.1818,random_46:5.3114,random_47:4.8301,random_48:0.9026,random_49:6.8794,random_50:5.5083,random_51:4.7955,random_52:3.4706,random_53:1.2934,random_54:1.2397,random_55:1.5551,random_56:1.0286,random_57:0.8647,random_58:5.4261,random_59:3.3465,random_60:4.1313,random_61:1.7229,random_62:9.225,random_63:5.1454,random_64:1.0096,random_65:2.4097,random_66:0.9604,random_67:6.1613,random_68:1.6022,random_69:0.9873,random_70:2.246,random_71:268.2838,random_72:0.8169,random_73:6.179,random_74:2.3264,random_75:5.2132,random_76:4.6052,random_77:0.7028,random_78:1.1892,random_79:3.6323,random_80:2.1015,random_81:4.12,random_82:0.9202,random_83:5.0385,random_84:1.7074,random_85:5.5215,random_86:6.1613,random_87:274.1358,random_88:6.1612,random_89:4.5557,random_90:3.2867,random_91:5.3791,random_92:2.3324,random_93:5.2171,random_94:0.8472,random_95:4.6674,random_96:2.3186,random_97:1.5032,random_98:3.2117,random_99:5.2279'\n",
      "Testing (test) took 0:00:03.530003'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Tested (test) on 1949 instances with mean losses of: random_0:6.6217,random_1:4.0656,random_2:5.4668,random_3:2.6543,random_4:6.757,random_5:0.7058,random_6:5.3314,random_7:7.1233,random_8:4.9604,random_9:2.0845,random_10:3.0198,random_11:2.8367,random_12:1.016,random_13:3.2517,random_14:6.0988,random_15:4.4079,random_16:1.1031,random_17:2.3778,random_18:1.1685,random_19:5.1546,random_20:5.0892,random_21:6.0852,random_22:6.1776,random_23:3.3247,random_24:5.8717,random_25:4.6932,random_26:0.7201,random_27:6.0876,random_28:4.2988,random_29:6.0855,random_30:1.5265,random_31:2.3144,random_32:5.4701,random_33:267.6907,random_34:2.4571,random_35:3.116,random_36:0.7075,random_37:3.8057,random_38:3.8277,random_39:5.0294,random_40:0.6802,random_41:4.209,random_42:0.7277,random_43:5.0362,random_44:6.3446,random_45:268.7633,random_46:4.1028,random_47:4.4197,random_48:0.9498,random_49:3.7486,random_50:6.0864,random_51:3.8527,random_52:3.0491,random_53:1.0493,random_54:1.4508,random_55:0.7269,random_56:0.8141,random_57:0.7999,random_58:5.6376,random_59:3.2823,random_60:5.265,random_61:1.3454,random_62:4.7337,random_63:6.0857,random_64:0.9159,random_65:2.9803,random_66:0.8567,random_67:6.0869,random_68:1.1755,random_69:0.9439,random_70:1.3719,random_71:265.8806,random_72:3.7099,random_73:6.1011,random_74:2.1974,random_75:4.3324,random_76:4.1403,random_77:0.702,random_78:0.9254,random_79:2.0064,random_80:2.1166,random_81:4.2174,random_82:0.7614,random_83:4.7788,random_84:1.3029,random_85:20.8841,random_86:6.0875,random_87:5.4097,random_88:6.0855,random_89:6.0693,random_90:4.4705966863511716e+19,random_91:5.5533,random_92:2.0454,random_93:4.271,random_94:0.7864,random_95:6.0896,random_96:2.8396,random_97:0.7418,random_98:2.603,random_99:5.4263'\n",
      "Testing (test) took 0:00:03.407001'\n"
     ]
    }
   ],
   "source": [
    "deep_scheme = DeepScheme(None, fixed_hyperparams=fixed_hyperparams,loss_eval=loss_target,device=device,tensorboard=tb,adaptive_lr=True,update=False)\n",
    "deep_scores, deep_preds, _ , _, _ = eval.evaluate(deep_models,dataset,deep_scheme,logger_name=\"log\",load_fun=load_fun_cv)\n",
    "deep_scores_final, deep_preds_final, _ ,_, _ = eval.build(deep_models,dataset,deep_scheme,logger_name=\"test_log\",load_fun=load_fun_build)\n",
    "\n",
    "all_scores = []\n",
    "for k,v in ut.flip_dicts(deep_scores).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores.append({**dict1,**v})\n",
    "\n",
    "all_scores_final = []\n",
    "for k,v in ut.flip_dicts(deep_scores_final).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores_final.append({**dict1,**v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% lwr part\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_0'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6502,lwr_k=20:3.5438,lwr_k=50:3.798,lwr_k=100:3.8895,lwr_k=200:3.9173,lwr_k=500:3.9454,lwr_k=1000:3.9641'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.6118,lwr_k=20:3.9947,lwr_k=50:4.004,lwr_k=100:3.9969,lwr_k=200:3.9542,lwr_k=500:3.9595,lwr_k=1000:3.9627'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6953,lwr_k=20:3.299,lwr_k=50:3.4635,lwr_k=100:3.5315,lwr_k=200:3.5918,lwr_k=500:3.6623,lwr_k=1000:3.6958'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.8403,lwr_k=20:3.6831,lwr_k=50:3.7075,lwr_k=100:3.7314,lwr_k=200:3.7567,lwr_k=500:3.8074,lwr_k=1000:3.8169'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7136,lwr_k=20:4.0108,lwr_k=50:4.2372,lwr_k=100:4.2768,lwr_k=200:4.2892,lwr_k=500:4.2689,lwr_k=1000:4.238'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.806,lwr_k=20:4.5428,lwr_k=50:4.501,lwr_k=100:4.4776,lwr_k=200:4.4379,lwr_k=500:4.3765,lwr_k=1000:4.3322'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.0602,lwr_k=20:4.1015,lwr_k=50:4.3334,lwr_k=100:4.3654,lwr_k=200:4.3755,lwr_k=500:4.3359,lwr_k=1000:4.2961'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.039,lwr_k=20:4.613,lwr_k=50:4.5191,lwr_k=100:4.4383,lwr_k=200:4.3777,lwr_k=500:4.2398,lwr_k=1000:4.169'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7853,lwr_k=20:4.0676,lwr_k=50:4.2423,lwr_k=100:4.3034,lwr_k=200:4.3236,lwr_k=500:4.2856,lwr_k=1000:4.2433'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.8464,lwr_k=20:4.7364,lwr_k=50:4.6519,lwr_k=100:4.6268,lwr_k=200:4.5921,lwr_k=500:4.5483,lwr_k=1000:4.4815'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.6924,lwr_k=20:4.0165,lwr_k=50:4.2924,lwr_k=100:4.3481,lwr_k=200:4.3525,lwr_k=500:4.3466,lwr_k=1000:4.2993'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:8.3852,lwr_k=20:4.4289,lwr_k=50:4.4071,lwr_k=100:4.3662,lwr_k=200:4.3757,lwr_k=500:4.3039,lwr_k=1000:4.2614'\n",
      "Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.'\n",
      "NumExpr defaulting to 8 threads.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_1'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9302,lwr_k=20:3.3972,lwr_k=50:3.6034,lwr_k=100:3.6907,lwr_k=200:3.7274,lwr_k=500:3.7694,lwr_k=1000:3.7962'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.8946,lwr_k=20:3.7669,lwr_k=50:3.8294,lwr_k=100:3.8286,lwr_k=200:3.8267,lwr_k=500:3.8401,lwr_k=1000:3.8325'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9109,lwr_k=20:3.7251,lwr_k=50:3.9189,lwr_k=100:3.9655,lwr_k=200:3.996,lwr_k=500:4.0277,lwr_k=1000:4.0228'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.0011,lwr_k=20:4.3996,lwr_k=50:4.2533,lwr_k=100:4.2023,lwr_k=200:4.1975,lwr_k=500:4.183,lwr_k=1000:4.1732'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7139,lwr_k=20:3.4724,lwr_k=50:3.6307,lwr_k=100:3.6836,lwr_k=200:3.719,lwr_k=500:3.7396,lwr_k=1000:3.7463'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.7378,lwr_k=20:3.9443,lwr_k=50:3.8704,lwr_k=100:3.8458,lwr_k=200:3.8227,lwr_k=500:3.8064,lwr_k=1000:3.7994'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7813,lwr_k=20:3.5551,lwr_k=50:3.7139,lwr_k=100:3.7603,lwr_k=200:3.7819,lwr_k=500:3.7959,lwr_k=1000:3.8001'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.5939,lwr_k=20:3.7584,lwr_k=50:3.7015,lwr_k=100:3.6605,lwr_k=200:3.6675,lwr_k=500:3.6437,lwr_k=1000:3.6377'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.0467,lwr_k=20:3.9352,lwr_k=50:4.1767,lwr_k=100:4.2924,lwr_k=200:4.3159,lwr_k=500:4.308,lwr_k=1000:4.2753'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.2553,lwr_k=20:4.5398,lwr_k=50:4.5353,lwr_k=100:4.5769,lwr_k=200:4.577,lwr_k=500:4.5451,lwr_k=1000:4.5034'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.6277,lwr_k=20:3.4275,lwr_k=50:3.6218,lwr_k=100:3.6834,lwr_k=200:3.697,lwr_k=500:3.7005,lwr_k=1000:3.6848'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.688,lwr_k=20:3.7454,lwr_k=50:3.772,lwr_k=100:3.7488,lwr_k=200:3.7678,lwr_k=500:3.7406,lwr_k=1000:3.7375'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_2'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.4861,lwr_k=20:2.3289,lwr_k=50:3.0786,lwr_k=100:3.5007,lwr_k=200:3.7431,lwr_k=500:3.9553,lwr_k=1000:4.0999'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.4171,lwr_k=20:4.0132,lwr_k=50:3.8221,lwr_k=100:3.8614,lwr_k=200:3.9786,lwr_k=500:4.0869,lwr_k=1000:4.1948'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.7859,lwr_k=20:2.6326,lwr_k=50:3.4492,lwr_k=100:3.809,lwr_k=200:4.0999,lwr_k=500:4.2581,lwr_k=1000:4.4133'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.9669,lwr_k=20:4.325,lwr_k=50:4.2962,lwr_k=100:4.3184,lwr_k=200:4.3986,lwr_k=500:4.4749,lwr_k=1000:4.5839'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9326,lwr_k=20:3.287,lwr_k=50:3.543,lwr_k=100:3.6455,lwr_k=200:3.7225,lwr_k=500:3.7974,lwr_k=1000:3.8292'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.0339,lwr_k=20:4.0824,lwr_k=50:4.0161,lwr_k=100:3.9659,lwr_k=200:3.9644,lwr_k=500:3.9581,lwr_k=1000:3.9367'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.4279,lwr_k=20:1.921,lwr_k=50:2.7642,lwr_k=100:3.1668,lwr_k=200:3.4425,lwr_k=500:3.7224,lwr_k=1000:3.8774'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.3361,lwr_k=20:3.9591,lwr_k=50:3.5378,lwr_k=100:3.5543,lwr_k=200:3.5367,lwr_k=500:3.706,lwr_k=1000:3.7981'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.6243,lwr_k=20:3.7379,lwr_k=50:4.2763,lwr_k=100:4.4882,lwr_k=200:4.6796,lwr_k=500:4.8339,lwr_k=1000:4.8524'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.7741,lwr_k=20:4.3907,lwr_k=50:4.6969,lwr_k=100:4.836,lwr_k=200:4.9043,lwr_k=500:5.0234,lwr_k=1000:4.9972'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.3932,lwr_k=20:2.1882,lwr_k=50:3.0296,lwr_k=100:3.3185,lwr_k=200:3.51,lwr_k=500:3.7318,lwr_k=1000:3.8274'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.4629,lwr_k=20:3.6078,lwr_k=50:3.6437,lwr_k=100:3.5956,lwr_k=200:3.6336,lwr_k=500:3.7912,lwr_k=1000:3.8971'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_3'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3305,lwr_k=20:0.4992,lwr_k=50:0.7829,lwr_k=100:0.9324,lwr_k=200:1.0481,lwr_k=500:1.1328,lwr_k=1000:1.1929'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.2145,lwr_k=20:0.9509,lwr_k=50:0.9417,lwr_k=100:0.9463,lwr_k=200:0.9754,lwr_k=500:1.0459,lwr_k=1000:1.0944'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.4109,lwr_k=20:0.7191,lwr_k=50:1.0556,lwr_k=100:1.2214,lwr_k=200:1.3555,lwr_k=500:1.5255,lwr_k=1000:1.6782'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.3479,lwr_k=20:1.4137,lwr_k=50:1.412,lwr_k=100:1.4077,lwr_k=200:1.4335,lwr_k=500:1.5368,lwr_k=1000:1.6622'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.3551,lwr_k=20:2.0195,lwr_k=50:2.8241,lwr_k=100:3.1707,lwr_k=200:3.4487,lwr_k=500:3.6796,lwr_k=1000:3.8926'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.4611,lwr_k=20:3.5244,lwr_k=50:3.6058,lwr_k=100:3.748,lwr_k=200:3.8633,lwr_k=500:4.0005,lwr_k=1000:4.0956'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.2073,lwr_k=20:1.7487,lwr_k=50:2.1955,lwr_k=100:2.4042,lwr_k=200:2.5743,lwr_k=500:2.7268,lwr_k=1000:2.8269'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.056,lwr_k=20:2.6171,lwr_k=50:2.6245,lwr_k=100:2.6363,lwr_k=200:2.699,lwr_k=500:2.7567,lwr_k=1000:2.7815'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.0824,lwr_k=20:1.4202,lwr_k=50:2.0631,lwr_k=100:2.3605,lwr_k=200:2.5864,lwr_k=500:2.7644,lwr_k=1000:2.9'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.1821,lwr_k=20:2.6459,lwr_k=50:2.6395,lwr_k=100:2.6831,lwr_k=200:2.7811,lwr_k=500:2.9309,lwr_k=1000:3.0094'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:2.0165,lwr_k=20:0.725,lwr_k=50:1.0739,lwr_k=100:1.2551,lwr_k=200:1.3884,lwr_k=500:1.5467,lwr_k=1000:1.6539'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.0309,lwr_k=20:1.3161,lwr_k=50:1.4256,lwr_k=100:1.4646,lwr_k=200:1.5338,lwr_k=500:1.6141,lwr_k=1000:1.709'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_4'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9489,lwr_k=20:3.9905,lwr_k=50:4.3284,lwr_k=100:4.3861,lwr_k=200:4.328,lwr_k=500:4.2977,lwr_k=1000:4.3162'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.8945,lwr_k=20:4.4796,lwr_k=50:4.5172,lwr_k=100:4.4962,lwr_k=200:4.3923,lwr_k=500:4.3033,lwr_k=1000:4.2994'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.64,lwr_k=20:3.2305,lwr_k=50:3.4616,lwr_k=100:3.5452,lwr_k=200:3.5883,lwr_k=500:3.6234,lwr_k=1000:3.6544'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.7827,lwr_k=20:3.7813,lwr_k=50:3.7334,lwr_k=100:3.7068,lwr_k=200:3.7173,lwr_k=500:3.7444,lwr_k=1000:3.7613'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6676,lwr_k=20:3.8269,lwr_k=50:4.1379,lwr_k=100:4.1615,lwr_k=200:4.0997,lwr_k=500:4.0596,lwr_k=1000:4.0626'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.788,lwr_k=20:4.3034,lwr_k=50:4.3526,lwr_k=100:4.2915,lwr_k=200:4.2352,lwr_k=500:4.1863,lwr_k=1000:4.1645'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7464,lwr_k=20:3.7257,lwr_k=50:3.9502,lwr_k=100:4.0201,lwr_k=200:4.0606,lwr_k=500:4.0962,lwr_k=1000:4.1165'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.7326,lwr_k=20:3.971,lwr_k=50:4.0293,lwr_k=100:4.0281,lwr_k=200:4.0052,lwr_k=500:3.9849,lwr_k=1000:3.9815'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9497,lwr_k=20:4.1327,lwr_k=50:4.3641,lwr_k=100:4.4026,lwr_k=200:4.4038,lwr_k=500:4.3954,lwr_k=1000:4.4036'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.9079,lwr_k=20:4.8779,lwr_k=50:4.8202,lwr_k=100:4.7273,lwr_k=200:4.6445,lwr_k=500:4.5939,lwr_k=1000:4.5822'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.0009,lwr_k=20:4.1211,lwr_k=50:4.3777,lwr_k=100:4.4201,lwr_k=200:4.3919,lwr_k=500:4.4036,lwr_k=1000:4.4188'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.1026,lwr_k=20:4.533,lwr_k=50:4.5048,lwr_k=100:4.4526,lwr_k=200:4.4059,lwr_k=500:4.3703,lwr_k=1000:4.3944'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_5'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6279,lwr_k=20:0.5529,lwr_k=50:0.583,lwr_k=100:0.5986,lwr_k=200:0.6079,lwr_k=500:0.615,lwr_k=1000:0.6195'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5995,lwr_k=20:0.6223,lwr_k=50:0.5987,lwr_k=100:0.5996,lwr_k=200:0.6016,lwr_k=500:0.5978,lwr_k=1000:0.6003'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.618,lwr_k=20:0.42,lwr_k=50:0.5093,lwr_k=100:0.554,lwr_k=200:0.5816,lwr_k=500:0.6033,lwr_k=1000:0.6122'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6232,lwr_k=20:0.5774,lwr_k=50:0.6009,lwr_k=100:0.6037,lwr_k=200:0.6083,lwr_k=500:0.6139,lwr_k=1000:0.6183'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6009,lwr_k=20:0.4755,lwr_k=50:0.5394,lwr_k=100:0.5638,lwr_k=200:0.5752,lwr_k=500:0.5874,lwr_k=1000:0.5957'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6357,lwr_k=20:0.6074,lwr_k=50:0.6172,lwr_k=100:0.618,lwr_k=200:0.6222,lwr_k=500:0.6294,lwr_k=1000:0.6313'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6403,lwr_k=20:0.5352,lwr_k=50:0.5764,lwr_k=100:0.6066,lwr_k=200:0.6216,lwr_k=500:0.6334,lwr_k=1000:0.6391'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.649,lwr_k=20:0.6565,lwr_k=50:0.6452,lwr_k=100:0.6375,lwr_k=200:0.6327,lwr_k=500:0.6372,lwr_k=1000:0.6402'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6136,lwr_k=20:0.5276,lwr_k=50:0.5675,lwr_k=100:0.5828,lwr_k=200:0.5956,lwr_k=500:0.6051,lwr_k=1000:0.6105'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6221,lwr_k=20:0.6273,lwr_k=50:0.6088,lwr_k=100:0.6113,lwr_k=200:0.6115,lwr_k=500:0.6152,lwr_k=1000:0.6183'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.5962,lwr_k=20:0.4482,lwr_k=50:0.5124,lwr_k=100:0.5375,lwr_k=200:0.5576,lwr_k=500:0.5743,lwr_k=1000:0.5854'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6793,lwr_k=20:0.6288,lwr_k=50:0.6441,lwr_k=100:0.6467,lwr_k=200:0.6562,lwr_k=500:0.6607,lwr_k=1000:0.6681'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_6'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.6549,lwr_k=20:4.5022,lwr_k=50:4.8311,lwr_k=100:4.8595,lwr_k=200:4.8109,lwr_k=500:4.7008,lwr_k=1000:4.6339'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.531,lwr_k=20:5.1956,lwr_k=50:5.1004,lwr_k=100:5.0122,lwr_k=200:4.8853,lwr_k=500:4.721,lwr_k=1000:4.6282'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.9143,lwr_k=20:3.0682,lwr_k=50:3.8524,lwr_k=100:4.2182,lwr_k=200:4.3896,lwr_k=500:4.535,lwr_k=1000:4.5711'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.0416,lwr_k=20:4.7743,lwr_k=50:4.7097,lwr_k=100:4.6539,lwr_k=200:4.7636,lwr_k=500:4.7898,lwr_k=1000:4.7927'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.4256,lwr_k=20:4.5362,lwr_k=50:4.6799,lwr_k=100:4.7325,lwr_k=200:4.6856,lwr_k=500:4.5549,lwr_k=1000:4.4803'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.5426,lwr_k=20:5.1074,lwr_k=50:4.9722,lwr_k=100:4.8194,lwr_k=200:4.7376,lwr_k=500:4.6344,lwr_k=1000:4.5452'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.9635,lwr_k=20:4.2175,lwr_k=50:4.6972,lwr_k=100:4.871,lwr_k=200:4.9807,lwr_k=500:5.0238,lwr_k=1000:5.0623'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.8278,lwr_k=20:5.0732,lwr_k=50:4.8834,lwr_k=100:4.8459,lwr_k=200:4.9202,lwr_k=500:4.9485,lwr_k=1000:4.8665'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.4034,lwr_k=20:3.6935,lwr_k=50:4.0491,lwr_k=100:4.2603,lwr_k=200:4.4202,lwr_k=500:4.5717,lwr_k=1000:4.6033'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.5838,lwr_k=20:4.2869,lwr_k=50:4.4424,lwr_k=100:4.5423,lwr_k=200:4.6477,lwr_k=500:4.7665,lwr_k=1000:4.7708'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.997,lwr_k=20:3.4266,lwr_k=50:3.8893,lwr_k=100:4.0602,lwr_k=200:4.2152,lwr_k=500:4.4341,lwr_k=1000:4.5372'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.0805,lwr_k=20:4.3248,lwr_k=50:4.2836,lwr_k=100:4.3587,lwr_k=200:4.4155,lwr_k=500:4.6117,lwr_k=1000:4.7012'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_7'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.3636,lwr_k=20:3.404,lwr_k=50:3.9879,lwr_k=100:4.4211,lwr_k=200:13.8943,lwr_k=500:45.9534,lwr_k=1000:5.7647'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.394,lwr_k=20:5.1149,lwr_k=50:4.8351,lwr_k=100:4.8172,lwr_k=200:5.277,lwr_k=500:5.465,lwr_k=1000:5.3372'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.6452,lwr_k=20:5.251,lwr_k=50:5.491,lwr_k=100:5.4802,lwr_k=200:5.422,lwr_k=500:5.2814,lwr_k=1000:5.1335'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.7593,lwr_k=20:6.044,lwr_k=50:5.8604,lwr_k=100:5.7292,lwr_k=200:5.6031,lwr_k=500:5.4395,lwr_k=1000:5.2683'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.0498,lwr_k=20:3.5507,lwr_k=50:3.9868,lwr_k=100:4.1896,lwr_k=200:4.4015,lwr_k=500:36.9867,lwr_k=1000:9.8965'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.0878,lwr_k=20:4.9445,lwr_k=50:4.5978,lwr_k=100:4.5739,lwr_k=200:4.6637,lwr_k=500:5.5213,lwr_k=1000:5.0746'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8153,lwr_k=20:3.008,lwr_k=50:3.3184,lwr_k=100:3.4514,lwr_k=200:3.5413,lwr_k=500:3.6407,lwr_k=1000:3.7022'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.6686,lwr_k=20:3.6159,lwr_k=50:3.6134,lwr_k=100:3.6254,lwr_k=200:3.6535,lwr_k=500:3.6311,lwr_k=1000:3.6351'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.3111,lwr_k=20:3.625,lwr_k=50:4.1628,lwr_k=100:6.1745,lwr_k=200:4.6775,lwr_k=500:10.0376,lwr_k=1000:8.6146'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:797.4063,lwr_k=20:21.0102,lwr_k=50:8.5181,lwr_k=100:91.0528,lwr_k=200:69.0002,lwr_k=500:45.5232,lwr_k=1000:23.2794'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:5.0363,lwr_k=20:3.8275,lwr_k=50:4.2512,lwr_k=100:4.4225,lwr_k=200:4.5374,lwr_k=500:5.1478,lwr_k=1000:4.97'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.0497,lwr_k=20:4.7243,lwr_k=50:4.6647,lwr_k=100:4.6438,lwr_k=200:4.696,lwr_k=500:4.7298,lwr_k=1000:4.7521'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_8'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.9147,lwr_k=20:4.5075,lwr_k=50:4.7094,lwr_k=100:4.7887,lwr_k=200:4.8301,lwr_k=500:4.86,lwr_k=1000:4.866'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.8512,lwr_k=20:5.066,lwr_k=50:4.9457,lwr_k=100:4.9206,lwr_k=200:4.9014,lwr_k=500:4.8757,lwr_k=1000:4.8642'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.9895,lwr_k=20:4.0767,lwr_k=50:4.3543,lwr_k=100:4.5331,lwr_k=200:4.6949,lwr_k=500:4.7427,lwr_k=1000:4.7739'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.1238,lwr_k=20:4.8595,lwr_k=50:4.8664,lwr_k=100:4.854,lwr_k=200:4.8951,lwr_k=500:4.919,lwr_k=1000:4.9326'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.0858,lwr_k=20:3.65,lwr_k=50:3.8816,lwr_k=100:4.0505,lwr_k=200:4.1482,lwr_k=500:4.2003,lwr_k=1000:4.2326'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.2282,lwr_k=20:4.3182,lwr_k=50:4.2913,lwr_k=100:4.2912,lwr_k=200:4.2629,lwr_k=500:4.2853,lwr_k=1000:4.3046'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.6376,lwr_k=20:4.5586,lwr_k=50:4.9974,lwr_k=100:5.1973,lwr_k=200:5.3344,lwr_k=500:5.4153,lwr_k=1000:5.4827'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.4067,lwr_k=20:5.4047,lwr_k=50:5.34,lwr_k=100:5.2954,lwr_k=200:5.2353,lwr_k=500:5.2253,lwr_k=1000:5.2621'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.9478,lwr_k=20:4.9095,lwr_k=50:5.2259,lwr_k=100:5.2881,lwr_k=200:5.2904,lwr_k=500:5.264,lwr_k=1000:5.1964'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.9931,lwr_k=20:5.564,lwr_k=50:5.6095,lwr_k=100:5.5225,lwr_k=200:5.4881,lwr_k=500:5.3864,lwr_k=1000:5.2935'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.7354,lwr_k=20:3.9238,lwr_k=50:4.1731,lwr_k=100:4.2618,lwr_k=200:4.3306,lwr_k=500:4.41,lwr_k=1000:4.4443'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.8014,lwr_k=20:4.4569,lwr_k=50:4.4315,lwr_k=100:4.4373,lwr_k=200:4.437,lwr_k=500:4.4468,lwr_k=1000:4.4641'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_9'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.848,lwr_k=20:0.1143,lwr_k=50:0.435,lwr_k=100:0.8958,lwr_k=200:1.4089,lwr_k=500:1.967,lwr_k=1000:2.273'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.8753,lwr_k=20:2.0118,lwr_k=50:1.9744,lwr_k=100:1.942,lwr_k=200:2.069,lwr_k=500:2.3171,lwr_k=1000:2.457'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.0038,lwr_k=20:0.1641,lwr_k=50:0.4415,lwr_k=100:0.6923,lwr_k=200:0.9768,lwr_k=500:1.2826,lwr_k=1000:1.5224'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.9583,lwr_k=20:1.4656,lwr_k=50:1.2642,lwr_k=100:1.2103,lwr_k=200:1.3086,lwr_k=500:1.4321,lwr_k=1000:1.5623'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.7694,lwr_k=20:0.1655,lwr_k=50:0.4099,lwr_k=100:0.645,lwr_k=200:0.8643,lwr_k=500:1.1125,lwr_k=1000:1.2877'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.9326,lwr_k=20:1.2874,lwr_k=50:1.1523,lwr_k=100:1.1861,lwr_k=200:1.243,lwr_k=500:1.3769,lwr_k=1000:1.5306'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.9255,lwr_k=20:0.1088,lwr_k=50:0.4642,lwr_k=100:0.9661,lwr_k=200:1.4612,lwr_k=500:2.0137,lwr_k=1000:2.3486'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.9166,lwr_k=20:2.2071,lwr_k=50:2.2094,lwr_k=100:2.1267,lwr_k=200:2.1266,lwr_k=500:2.2739,lwr_k=1000:2.4423'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.2441,lwr_k=20:0.2399,lwr_k=50:0.5852,lwr_k=100:0.9234,lwr_k=200:1.25,lwr_k=500:1.5903,lwr_k=1000:1.8201'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.3616,lwr_k=20:1.6243,lwr_k=50:1.5678,lwr_k=100:1.63,lwr_k=200:1.7392,lwr_k=500:1.9099,lwr_k=1000:2.0188'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:1.6107,lwr_k=20:0.1089,lwr_k=50:0.3246,lwr_k=100:0.5521,lwr_k=200:0.7849,lwr_k=500:1.0525,lwr_k=1000:1.2223'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.7437,lwr_k=20:0.9031,lwr_k=50:0.8643,lwr_k=100:0.9697,lwr_k=200:1.1423,lwr_k=500:1.3425,lwr_k=1000:1.4598'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_10'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4854,lwr_k=20:0.6193,lwr_k=50:0.9431,lwr_k=100:1.0764,lwr_k=200:1.1793,lwr_k=500:1.2916,lwr_k=1000:1.3613'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.3524,lwr_k=20:1.1267,lwr_k=50:1.0961,lwr_k=100:1.1155,lwr_k=200:1.1327,lwr_k=500:1.2011,lwr_k=1000:1.2518'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.0397,lwr_k=20:1.0423,lwr_k=50:1.4251,lwr_k=100:1.5416,lwr_k=200:1.6383,lwr_k=500:1.7365,lwr_k=1000:1.8294'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.1002,lwr_k=20:1.6668,lwr_k=50:1.6943,lwr_k=100:1.742,lwr_k=200:1.7485,lwr_k=500:1.795,lwr_k=1000:1.8667'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.6522,lwr_k=20:1.0651,lwr_k=50:1.606,lwr_k=100:1.8773,lwr_k=200:2.0549,lwr_k=500:2.1949,lwr_k=1000:2.2915'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.617,lwr_k=20:2.0775,lwr_k=50:2.0937,lwr_k=100:2.2076,lwr_k=200:2.2887,lwr_k=500:2.355,lwr_k=1000:2.4019'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.2959,lwr_k=20:0.8466,lwr_k=50:1.3722,lwr_k=100:1.618,lwr_k=200:1.7982,lwr_k=500:1.9806,lwr_k=1000:2.0714'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.247,lwr_k=20:1.839,lwr_k=50:1.7592,lwr_k=100:1.8255,lwr_k=200:1.9073,lwr_k=500:2.0212,lwr_k=1000:2.0666'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.095,lwr_k=20:1.0911,lwr_k=50:1.6066,lwr_k=100:1.8768,lwr_k=200:2.0672,lwr_k=500:2.2597,lwr_k=1000:2.4402'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.2344,lwr_k=20:2.1713,lwr_k=50:2.1079,lwr_k=100:2.1907,lwr_k=200:2.2653,lwr_k=500:2.3456,lwr_k=1000:2.4948'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:2.4993,lwr_k=20:0.9268,lwr_k=50:1.5201,lwr_k=100:1.7652,lwr_k=200:1.9407,lwr_k=500:2.0933,lwr_k=1000:2.1837'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.5886,lwr_k=20:1.8853,lwr_k=50:1.9684,lwr_k=100:2.0844,lwr_k=200:2.1784,lwr_k=500:2.2698,lwr_k=1000:2.334'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_11'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.5851,lwr_k=20:0.9782,lwr_k=50:1.3898,lwr_k=100:1.6651,lwr_k=200:1.9058,lwr_k=500:2.1716,lwr_k=1000:2.3305'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.5301,lwr_k=20:2.1935,lwr_k=50:2.3139,lwr_k=100:2.2964,lwr_k=200:2.3278,lwr_k=500:2.3725,lwr_k=1000:2.4019'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.4898,lwr_k=20:2.2354,lwr_k=50:2.4085,lwr_k=100:2.4656,lwr_k=200:2.5008,lwr_k=500:2.5264,lwr_k=1000:2.5424'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.499,lwr_k=20:2.5641,lwr_k=50:2.5163,lwr_k=100:2.517,lwr_k=200:2.5052,lwr_k=500:2.4738,lwr_k=1000:2.4928'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.5476,lwr_k=20:0.2837,lwr_k=50:0.721,lwr_k=100:1.2328,lwr_k=200:1.6917,lwr_k=500:2.1337,lwr_k=1000:2.3011'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.6826,lwr_k=20:2.3852,lwr_k=50:2.4554,lwr_k=100:2.5339,lwr_k=200:2.5445,lwr_k=500:2.5948,lwr_k=1000:2.6421'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.8328,lwr_k=20:0.2366,lwr_k=50:0.7121,lwr_k=100:1.316,lwr_k=200:1.8497,lwr_k=500:2.3199,lwr_k=1000:2.5457'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.8544,lwr_k=20:2.3491,lwr_k=50:2.4452,lwr_k=100:2.5602,lwr_k=200:2.6994,lwr_k=500:2.7198,lwr_k=1000:2.7554'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.7381,lwr_k=20:2.5875,lwr_k=50:2.7079,lwr_k=100:2.7697,lwr_k=200:2.7904,lwr_k=500:2.8161,lwr_k=1000:2.8231'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.9116,lwr_k=20:2.9619,lwr_k=50:2.9546,lwr_k=100:2.9587,lwr_k=200:2.9869,lwr_k=500:2.9879,lwr_k=1000:3.0143'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:2.3714,lwr_k=20:0.1868,lwr_k=50:0.5513,lwr_k=100:1.0052,lwr_k=200:1.4507,lwr_k=500:1.8482,lwr_k=1000:2.0635'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.543,lwr_k=20:1.5328,lwr_k=50:1.8146,lwr_k=100:2.045,lwr_k=200:2.211,lwr_k=500:2.2981,lwr_k=1000:2.3986'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_12'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0525,lwr_k=20:0.9457,lwr_k=50:0.9657,lwr_k=100:0.9719,lwr_k=200:0.9774,lwr_k=500:0.9787,lwr_k=1000:0.9812'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.0725,lwr_k=20:1.0188,lwr_k=50:0.9988,lwr_k=100:0.9903,lwr_k=200:0.9888,lwr_k=500:0.9903,lwr_k=1000:0.9939'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.989,lwr_k=20:0.8812,lwr_k=50:0.9005,lwr_k=100:0.9074,lwr_k=200:0.9098,lwr_k=500:0.9126,lwr_k=1000:0.9147'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.0117,lwr_k=20:0.9394,lwr_k=50:0.9296,lwr_k=100:0.9385,lwr_k=200:0.9239,lwr_k=500:0.9225,lwr_k=1000:0.9242'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8726,lwr_k=20:0.7648,lwr_k=50:0.7978,lwr_k=100:0.8087,lwr_k=200:0.8199,lwr_k=500:0.8257,lwr_k=1000:0.8375'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9171,lwr_k=20:0.8834,lwr_k=50:0.8637,lwr_k=100:0.8553,lwr_k=200:0.8564,lwr_k=500:0.8629,lwr_k=1000:0.8759'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.904,lwr_k=20:0.7976,lwr_k=50:0.833,lwr_k=100:0.8417,lwr_k=200:0.849,lwr_k=500:0.8581,lwr_k=1000:0.8705'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8997,lwr_k=20:0.8763,lwr_k=50:0.8608,lwr_k=100:0.8582,lwr_k=200:0.859,lwr_k=500:0.8605,lwr_k=1000:0.8754'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0965,lwr_k=20:0.9951,lwr_k=50:0.9974,lwr_k=100:1.008,lwr_k=200:1.013,lwr_k=500:1.014,lwr_k=1000:1.017'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0496,lwr_k=20:0.9975,lwr_k=50:0.9724,lwr_k=100:0.9609,lwr_k=200:0.9574,lwr_k=500:0.9636,lwr_k=1000:0.964'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.8852,lwr_k=20:0.7742,lwr_k=50:0.8031,lwr_k=100:0.8168,lwr_k=200:0.8256,lwr_k=500:0.8344,lwr_k=1000:0.8409'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9377,lwr_k=20:0.9295,lwr_k=50:0.9143,lwr_k=100:0.9118,lwr_k=200:0.9042,lwr_k=500:0.9075,lwr_k=1000:0.9138'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_13'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.3068,lwr_k=20:1.3877,lwr_k=50:1.6721,lwr_k=100:1.8422,lwr_k=200:1.9554,lwr_k=500:2.0735,lwr_k=1000:2.1428'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.1402,lwr_k=20:1.8597,lwr_k=50:1.8679,lwr_k=100:1.9063,lwr_k=200:1.9112,lwr_k=500:1.942,lwr_k=1000:2.0015'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.5402,lwr_k=20:1.3611,lwr_k=50:1.7359,lwr_k=100:1.9411,lwr_k=200:2.0809,lwr_k=500:2.2452,lwr_k=1000:2.3167'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.5549,lwr_k=20:2.0755,lwr_k=50:2.0875,lwr_k=100:2.1796,lwr_k=200:2.2565,lwr_k=500:2.3147,lwr_k=1000:2.3515'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.5197,lwr_k=20:1.4741,lwr_k=50:1.7795,lwr_k=100:1.9655,lwr_k=200:2.1009,lwr_k=500:2.2532,lwr_k=1000:2.3358'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.6437,lwr_k=20:2.2613,lwr_k=50:2.3607,lwr_k=100:2.4059,lwr_k=200:2.4321,lwr_k=500:2.467,lwr_k=1000:2.5211'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.0492,lwr_k=20:1.1573,lwr_k=50:1.3763,lwr_k=100:1.505,lwr_k=200:1.6213,lwr_k=500:1.7612,lwr_k=1000:1.8582'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.1511,lwr_k=20:1.7077,lwr_k=50:1.7356,lwr_k=100:1.7615,lwr_k=200:1.7898,lwr_k=500:1.8567,lwr_k=1000:1.9361'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.7503,lwr_k=20:1.6143,lwr_k=50:2.0324,lwr_k=100:2.2436,lwr_k=200:2.3904,lwr_k=500:2.5409,lwr_k=1000:2.6188'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.8015,lwr_k=20:2.5291,lwr_k=50:2.5183,lwr_k=100:2.5554,lwr_k=200:2.6154,lwr_k=500:2.6508,lwr_k=1000:2.704'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:2.9913,lwr_k=20:1.6427,lwr_k=50:2.1292,lwr_k=100:2.3842,lwr_k=200:2.5648,lwr_k=500:2.7349,lwr_k=1000:2.8191'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.0905,lwr_k=20:2.4912,lwr_k=50:2.6048,lwr_k=100:2.7222,lwr_k=200:2.7684,lwr_k=500:2.8602,lwr_k=1000:2.8906'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_14'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9936,lwr_k=20:5.995,lwr_k=50:5.994,lwr_k=100:6.0111,lwr_k=200:6.0357,lwr_k=500:5.9961,lwr_k=1000:5.9955'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0673,lwr_k=20:6.0678,lwr_k=50:6.0672,lwr_k=100:6.0815,lwr_k=200:6.1044,lwr_k=500:6.0686,lwr_k=1000:6.0681'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9804,lwr_k=20:6.0234,lwr_k=50:6.1347,lwr_k=100:6.0663,lwr_k=200:5.9876,lwr_k=500:5.9849,lwr_k=1000:5.9808'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.2011,lwr_k=20:6.2838,lwr_k=50:6.2803,lwr_k=100:6.2309,lwr_k=200:6.1921,lwr_k=500:6.1928,lwr_k=1000:6.1978'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0284,lwr_k=20:6.0468,lwr_k=50:6.191,lwr_k=100:6.1085,lwr_k=200:6.0326,lwr_k=500:6.03,lwr_k=1000:6.0284'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.9286,lwr_k=20:5.9193,lwr_k=50:6.1735,lwr_k=100:6.0665,lwr_k=200:5.946,lwr_k=500:5.9385,lwr_k=1000:5.9268'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.1385,lwr_k=20:6.139,lwr_k=50:6.3221,lwr_k=100:6.2163,lwr_k=200:6.1406,lwr_k=500:6.1387,lwr_k=1000:6.1401'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.8637,lwr_k=20:5.8611,lwr_k=50:6.1076,lwr_k=100:5.9808,lwr_k=200:5.8723,lwr_k=500:5.8657,lwr_k=1000:5.8597'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0621,lwr_k=20:6.0621,lwr_k=50:6.0622,lwr_k=100:6.0666,lwr_k=200:6.1173,lwr_k=500:6.0709,lwr_k=1000:6.0621'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:6.1622,lwr_k=20:6.1627,lwr_k=50:6.1629,lwr_k=100:6.1578,lwr_k=200:6.1863,lwr_k=500:6.1833,lwr_k=1000:6.1627'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:6.0857,lwr_k=20:6.8304,lwr_k=50:6.5014,lwr_k=100:6.2754,lwr_k=200:6.1001,lwr_k=500:6.0893,lwr_k=1000:6.0857'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0856,lwr_k=20:6.8685,lwr_k=50:6.5298,lwr_k=100:6.2946,lwr_k=200:6.1054,lwr_k=500:6.0919,lwr_k=1000:6.0854'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_15'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.4815,lwr_k=20:2.9401,lwr_k=50:3.1509,lwr_k=100:3.2446,lwr_k=200:3.3056,lwr_k=500:3.3293,lwr_k=1000:3.381'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.5053,lwr_k=20:3.4802,lwr_k=50:3.4197,lwr_k=100:3.4,lwr_k=200:3.4042,lwr_k=500:3.3446,lwr_k=1000:3.3386'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.4682,lwr_k=20:3.332,lwr_k=50:3.5604,lwr_k=100:3.6469,lwr_k=200:3.7281,lwr_k=500:3.7876,lwr_k=1000:3.8115'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.6851,lwr_k=20:3.9249,lwr_k=50:3.957,lwr_k=100:3.9479,lwr_k=200:3.9304,lwr_k=500:3.959,lwr_k=1000:3.9823'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.5188,lwr_k=20:2.943,lwr_k=50:3.1382,lwr_k=100:3.2006,lwr_k=200:3.2524,lwr_k=500:3.3042,lwr_k=1000:3.3655'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.633,lwr_k=20:3.5008,lwr_k=50:3.5174,lwr_k=100:3.5075,lwr_k=200:3.4915,lwr_k=500:3.4964,lwr_k=1000:3.507'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8113,lwr_k=20:3.4154,lwr_k=50:3.64,lwr_k=100:3.738,lwr_k=200:3.8006,lwr_k=500:3.8297,lwr_k=1000:3.8394'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.7613,lwr_k=20:3.7906,lwr_k=50:3.7864,lwr_k=100:3.7583,lwr_k=200:3.7424,lwr_k=500:3.7394,lwr_k=1000:3.7355'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8206,lwr_k=20:3.2271,lwr_k=50:3.5058,lwr_k=100:3.6373,lwr_k=200:3.6944,lwr_k=500:3.7482,lwr_k=1000:3.8029'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.8602,lwr_k=20:3.9357,lwr_k=50:3.9272,lwr_k=100:3.9126,lwr_k=200:3.9151,lwr_k=500:3.8426,lwr_k=1000:3.8556'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.6242,lwr_k=20:3.0843,lwr_k=50:3.3155,lwr_k=100:3.4127,lwr_k=200:3.4744,lwr_k=500:3.5195,lwr_k=1000:3.5801'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.7236,lwr_k=20:3.6021,lwr_k=50:3.6514,lwr_k=100:3.6644,lwr_k=200:3.6859,lwr_k=500:3.6889,lwr_k=1000:3.6821'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_16'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2253,lwr_k=20:1.1437,lwr_k=50:1.1715,lwr_k=100:1.1844,lwr_k=200:1.195,lwr_k=500:1.2003,lwr_k=1000:1.2069'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.2028,lwr_k=20:1.2286,lwr_k=50:1.1984,lwr_k=100:1.1864,lwr_k=200:1.1765,lwr_k=500:1.1789,lwr_k=1000:1.1822'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.637,lwr_k=20:0.5993,lwr_k=50:0.6151,lwr_k=100:0.6221,lwr_k=200:0.6237,lwr_k=500:0.6289,lwr_k=1000:0.6313'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6538,lwr_k=20:0.6771,lwr_k=50:0.6531,lwr_k=100:0.6442,lwr_k=200:0.6436,lwr_k=500:0.646,lwr_k=1000:0.6505'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7005,lwr_k=20:0.6587,lwr_k=50:0.6777,lwr_k=100:0.686,lwr_k=200:0.6899,lwr_k=500:0.6934,lwr_k=1000:0.6958'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7364,lwr_k=20:0.755,lwr_k=50:0.7377,lwr_k=100:0.7373,lwr_k=200:0.7345,lwr_k=500:0.7362,lwr_k=1000:0.7363'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.3014,lwr_k=20:2.1519,lwr_k=50:2.219,lwr_k=100:2.2377,lwr_k=200:2.2479,lwr_k=500:2.258,lwr_k=1000:2.2724'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.2441,lwr_k=20:2.3168,lwr_k=50:2.2292,lwr_k=100:2.2184,lwr_k=200:2.2087,lwr_k=500:2.1974,lwr_k=1000:2.198'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0281,lwr_k=20:0.8606,lwr_k=50:0.8954,lwr_k=100:0.9064,lwr_k=200:0.9166,lwr_k=500:0.9293,lwr_k=1000:0.9409'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0723,lwr_k=20:1.0197,lwr_k=50:0.9905,lwr_k=100:0.984,lwr_k=200:0.9831,lwr_k=500:0.9858,lwr_k=1000:0.9944'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:1.1095,lwr_k=20:1.0196,lwr_k=50:1.0454,lwr_k=100:1.0587,lwr_k=200:1.0639,lwr_k=500:1.0693,lwr_k=1000:1.0762'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.0941,lwr_k=20:1.1166,lwr_k=50:1.0923,lwr_k=100:1.0794,lwr_k=200:1.0684,lwr_k=500:1.0695,lwr_k=1000:1.0712'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_17'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9837,lwr_k=20:0.2143,lwr_k=50:0.3889,lwr_k=100:0.5086,lwr_k=200:0.6079,lwr_k=500:0.7127,lwr_k=1000:0.7873'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9105,lwr_k=20:0.6654,lwr_k=50:0.6481,lwr_k=100:0.6588,lwr_k=200:0.6989,lwr_k=500:0.7535,lwr_k=1000:0.7776'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9223,lwr_k=20:0.2123,lwr_k=50:0.3636,lwr_k=100:0.4707,lwr_k=200:0.5691,lwr_k=500:0.6839,lwr_k=1000:0.7543'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9293,lwr_k=20:0.6648,lwr_k=50:0.6487,lwr_k=100:0.6647,lwr_k=200:0.6849,lwr_k=500:0.7341,lwr_k=1000:0.7823'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0484,lwr_k=20:0.1771,lwr_k=50:0.3579,lwr_k=100:0.5016,lwr_k=200:0.6418,lwr_k=500:0.7962,lwr_k=1000:0.8931'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1705,lwr_k=20:0.774,lwr_k=50:0.7504,lwr_k=100:0.7836,lwr_k=200:0.8336,lwr_k=500:0.9424,lwr_k=1000:1.0396'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.8616,lwr_k=20:0.5982,lwr_k=50:1.1345,lwr_k=100:1.5244,lwr_k=200:1.879,lwr_k=500:2.2605,lwr_k=1000:2.4661'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.8402,lwr_k=20:2.3103,lwr_k=50:2.1354,lwr_k=100:2.1998,lwr_k=200:2.3083,lwr_k=500:2.4665,lwr_k=1000:2.5846'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0652,lwr_k=20:0.2848,lwr_k=50:0.4631,lwr_k=100:0.5641,lwr_k=200:0.6658,lwr_k=500:0.793,lwr_k=1000:0.882'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1292,lwr_k=20:0.7437,lwr_k=50:0.7845,lwr_k=100:0.8063,lwr_k=200:0.844,lwr_k=500:0.9255,lwr_k=1000:0.9833'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:1.0679,lwr_k=20:0.0742,lwr_k=50:0.2457,lwr_k=100:0.4258,lwr_k=200:0.5891,lwr_k=500:0.7668,lwr_k=1000:0.8804'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.2073,lwr_k=20:0.5587,lwr_k=50:0.6359,lwr_k=100:0.7409,lwr_k=200:0.8165,lwr_k=500:0.9353,lwr_k=1000:1.0242'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_18'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0943,lwr_k=20:0.9593,lwr_k=50:1.0139,lwr_k=100:1.0424,lwr_k=200:1.063,lwr_k=500:1.0903,lwr_k=1000:1.1149'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1135134.863,lwr_k=20:1.0825,lwr_k=50:1.066,lwr_k=100:1.0823,lwr_k=200:1.0834,lwr_k=500:1.0789,lwr_k=1000:1.0827'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.4856,lwr_k=20:2.1279,lwr_k=50:2.2693,lwr_k=100:2.3246,lwr_k=200:2.3622,lwr_k=500:2.4271,lwr_k=1000:2.4699'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.5438,lwr_k=20:2.4758,lwr_k=50:2.4926,lwr_k=100:2.5001,lwr_k=200:2.5195,lwr_k=500:2.5472,lwr_k=1000:2.5615'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.3521,lwr_k=20:1.9585,lwr_k=50:2.061,lwr_k=100:2.1063,lwr_k=200:2.1468,lwr_k=500:2.2061,lwr_k=1000:2.2341'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.3688,lwr_k=20:2.312,lwr_k=50:2.2982,lwr_k=100:2.3016,lwr_k=200:2.3199,lwr_k=500:2.3419,lwr_k=1000:2.3599'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.2817,lwr_k=20:2.071,lwr_k=50:2.1996,lwr_k=100:2.2442,lwr_k=200:2.2714,lwr_k=500:2.3148,lwr_k=1000:2.341'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:6989051.6722,lwr_k=20:2.274,lwr_k=50:2.2797,lwr_k=100:2.2803,lwr_k=200:2.2801,lwr_k=500:2.2784,lwr_k=1000:2.3037'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.2469,lwr_k=20:1.8844,lwr_k=50:1.9935,lwr_k=100:2.044,lwr_k=200:2.0613,lwr_k=500:2.084,lwr_k=1000:2.1151'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.2752,lwr_k=20:2.1507,lwr_k=50:2.1264,lwr_k=100:2.0997,lwr_k=200:2.0969,lwr_k=500:2.0935,lwr_k=1000:2.1086'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:1.3105,lwr_k=20:0.8631,lwr_k=50:0.9138,lwr_k=100:0.9395,lwr_k=200:0.9609,lwr_k=500:0.9875,lwr_k=1000:1.0073'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.3933,lwr_k=20:1.0298,lwr_k=50:1.0293,lwr_k=100:1.0263,lwr_k=200:1.0285,lwr_k=500:1.042,lwr_k=1000:1.0533'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_19'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6799,lwr_k=20:3.7283,lwr_k=50:3.6479,lwr_k=100:3.6022,lwr_k=200:3.6021,lwr_k=500:3.5979,lwr_k=1000:3.594'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.7191,lwr_k=20:3.9553,lwr_k=50:3.7569,lwr_k=100:3.6702,lwr_k=200:3.6533,lwr_k=500:3.6442,lwr_k=1000:3.6431'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.2758,lwr_k=20:4.0208,lwr_k=50:4.1082,lwr_k=100:4.1541,lwr_k=200:4.1777,lwr_k=500:4.1789,lwr_k=1000:4.1917'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.2316,lwr_k=20:4.3194,lwr_k=50:4.2029,lwr_k=100:4.1873,lwr_k=200:4.1834,lwr_k=500:4.1463,lwr_k=1000:4.1396'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6645,lwr_k=20:3.4585,lwr_k=50:3.533,lwr_k=100:3.5711,lwr_k=200:3.5724,lwr_k=500:3.5909,lwr_k=1000:3.5972'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.878,lwr_k=20:3.9441,lwr_k=50:3.8475,lwr_k=100:3.7971,lwr_k=200:3.7997,lwr_k=500:3.7971,lwr_k=1000:3.7845'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.2233,lwr_k=20:4.0198,lwr_k=50:4.1243,lwr_k=100:4.1654,lwr_k=200:4.1988,lwr_k=500:4.2026,lwr_k=1000:4.2056'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.9755,lwr_k=20:4.1862,lwr_k=50:4.025,lwr_k=100:3.9957,lwr_k=200:3.9732,lwr_k=500:3.9604,lwr_k=1000:3.9657'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.2248,lwr_k=20:2.9021,lwr_k=50:3.011,lwr_k=100:3.0391,lwr_k=200:3.0651,lwr_k=500:3.0817,lwr_k=1000:3.0883'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.3092,lwr_k=20:3.2572,lwr_k=50:3.1842,lwr_k=100:3.13,lwr_k=200:3.1258,lwr_k=500:3.1273,lwr_k=1000:3.1386'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.5857,lwr_k=20:4.1487,lwr_k=50:4.3338,lwr_k=100:4.4042,lwr_k=200:4.4511,lwr_k=500:4.4921,lwr_k=1000:4.5402'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.5704,lwr_k=20:4.5778,lwr_k=50:4.5297,lwr_k=100:4.4762,lwr_k=200:4.473,lwr_k=500:4.4889,lwr_k=1000:4.5128'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_20'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.3247,lwr_k=20:3.4932,lwr_k=50:3.7291,lwr_k=100:3.8332,lwr_k=200:3.9057,lwr_k=500:3.989,lwr_k=1000:4.0595'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.1734,lwr_k=20:3.9206,lwr_k=50:3.8806,lwr_k=100:3.8489,lwr_k=200:3.8668,lwr_k=500:3.933,lwr_k=1000:3.9821'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.2745,lwr_k=20:3.6846,lwr_k=50:3.8786,lwr_k=100:3.9508,lwr_k=200:4.0495,lwr_k=500:4.116,lwr_k=1000:4.156'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.3293,lwr_k=20:4.156,lwr_k=50:4.1487,lwr_k=100:4.1769,lwr_k=200:4.1982,lwr_k=500:4.1989,lwr_k=1000:4.2311'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.0173,lwr_k=20:3.5077,lwr_k=50:3.667,lwr_k=100:3.7593,lwr_k=200:3.8231,lwr_k=500:3.8946,lwr_k=1000:3.9469'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.2187,lwr_k=20:4.0255,lwr_k=50:4.0009,lwr_k=100:4.0095,lwr_k=200:4.0073,lwr_k=500:4.0574,lwr_k=1000:4.1046'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.3973,lwr_k=20:3.5829,lwr_k=50:3.7958,lwr_k=100:3.878,lwr_k=200:3.9267,lwr_k=500:4.0267,lwr_k=1000:4.1202'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.261,lwr_k=20:3.9079,lwr_k=50:3.8705,lwr_k=100:3.9026,lwr_k=200:3.9065,lwr_k=500:3.9715,lwr_k=1000:4.0384'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9175,lwr_k=20:3.2933,lwr_k=50:3.5119,lwr_k=100:3.6209,lwr_k=200:3.6897,lwr_k=500:3.7438,lwr_k=1000:3.7842'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.0,lwr_k=20:3.828,lwr_k=50:3.7746,lwr_k=100:3.7752,lwr_k=200:3.7899,lwr_k=500:3.8245,lwr_k=1000:3.8547'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.5747,lwr_k=20:3.5456,lwr_k=50:3.8423,lwr_k=100:3.9681,lwr_k=200:4.0555,lwr_k=500:4.1435,lwr_k=1000:4.2064'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.6313,lwr_k=20:4.0102,lwr_k=50:4.073,lwr_k=100:4.0972,lwr_k=200:4.1296,lwr_k=500:4.2124,lwr_k=1000:4.2947'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_21'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9936,lwr_k=20:5.995,lwr_k=50:5.994,lwr_k=100:6.0111,lwr_k=200:6.0357,lwr_k=500:5.9961,lwr_k=1000:5.9955'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0673,lwr_k=20:6.0678,lwr_k=50:6.0672,lwr_k=100:6.0815,lwr_k=200:6.1044,lwr_k=500:6.0686,lwr_k=1000:6.0681'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9804,lwr_k=20:6.0234,lwr_k=50:6.1347,lwr_k=100:6.0663,lwr_k=200:5.9876,lwr_k=500:5.9849,lwr_k=1000:5.9808'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.2011,lwr_k=20:6.2838,lwr_k=50:6.2803,lwr_k=100:6.2309,lwr_k=200:6.1921,lwr_k=500:6.1928,lwr_k=1000:6.1978'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0284,lwr_k=20:6.0468,lwr_k=50:6.191,lwr_k=100:6.1085,lwr_k=200:6.0326,lwr_k=500:6.03,lwr_k=1000:6.0284'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.9286,lwr_k=20:5.9193,lwr_k=50:6.1735,lwr_k=100:6.0665,lwr_k=200:5.946,lwr_k=500:5.9385,lwr_k=1000:5.9268'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.1385,lwr_k=20:6.139,lwr_k=50:6.3221,lwr_k=100:6.2163,lwr_k=200:6.1406,lwr_k=500:6.1387,lwr_k=1000:6.1401'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.8637,lwr_k=20:5.8611,lwr_k=50:6.1076,lwr_k=100:5.9808,lwr_k=200:5.8723,lwr_k=500:5.8657,lwr_k=1000:5.8597'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0621,lwr_k=20:6.0621,lwr_k=50:6.0622,lwr_k=100:6.0666,lwr_k=200:6.1173,lwr_k=500:6.0709,lwr_k=1000:6.0621'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:6.1622,lwr_k=20:6.1627,lwr_k=50:6.1629,lwr_k=100:6.1578,lwr_k=200:6.1863,lwr_k=500:6.1833,lwr_k=1000:6.1627'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:6.0857,lwr_k=20:6.8304,lwr_k=50:6.5014,lwr_k=100:6.2754,lwr_k=200:6.1001,lwr_k=500:6.0893,lwr_k=1000:6.0857'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0856,lwr_k=20:6.8685,lwr_k=50:6.5298,lwr_k=100:6.2946,lwr_k=200:6.1054,lwr_k=500:6.0919,lwr_k=1000:6.0854'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_22'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9936,lwr_k=20:5.995,lwr_k=50:5.994,lwr_k=100:6.0111,lwr_k=200:6.0357,lwr_k=500:5.9961,lwr_k=1000:5.9955'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0673,lwr_k=20:6.0678,lwr_k=50:6.0672,lwr_k=100:6.0815,lwr_k=200:6.1044,lwr_k=500:6.0686,lwr_k=1000:6.0681'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.1153,lwr_k=20:1.8651,lwr_k=50:2.3812,lwr_k=100:2.6267,lwr_k=200:2.7628,lwr_k=500:2.8972,lwr_k=1000:2.9637'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.0913,lwr_k=20:2.8704,lwr_k=50:2.8587,lwr_k=100:2.9445,lwr_k=200:2.9279,lwr_k=500:2.9463,lwr_k=1000:2.9725'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.8586,lwr_k=20:1.987,lwr_k=50:2.3748,lwr_k=100:2.5519,lwr_k=200:2.6536,lwr_k=500:2.7369,lwr_k=1000:2.772'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.9863,lwr_k=20:2.7892,lwr_k=50:2.8457,lwr_k=100:2.8376,lwr_k=200:2.8864,lwr_k=500:2.8958,lwr_k=1000:2.9171'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.1979,lwr_k=20:1.9686,lwr_k=50:2.491,lwr_k=100:2.7166,lwr_k=200:2.8589,lwr_k=500:3.0025,lwr_k=1000:3.0762'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.1737,lwr_k=20:2.9315,lwr_k=50:2.9432,lwr_k=100:2.913,lwr_k=200:2.9462,lwr_k=500:3.0468,lwr_k=1000:3.0937'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0621,lwr_k=20:6.0621,lwr_k=50:6.0622,lwr_k=100:6.0666,lwr_k=200:6.1173,lwr_k=500:6.0709,lwr_k=1000:6.0621'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:6.1622,lwr_k=20:6.1627,lwr_k=50:6.1629,lwr_k=100:6.1578,lwr_k=200:6.1863,lwr_k=500:6.1833,lwr_k=1000:6.1627'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:6.0857,lwr_k=20:6.8304,lwr_k=50:6.5014,lwr_k=100:6.2754,lwr_k=200:6.1001,lwr_k=500:6.0893,lwr_k=1000:6.0857'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0856,lwr_k=20:6.8685,lwr_k=50:6.5298,lwr_k=100:6.2946,lwr_k=200:6.1054,lwr_k=500:6.0919,lwr_k=1000:6.0854'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_23'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.5781,lwr_k=20:0.8815,lwr_k=50:1.0168,lwr_k=100:1.0926,lwr_k=200:1.1644,lwr_k=500:1.2484,lwr_k=1000:1.3202'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.4384,lwr_k=20:1.0679,lwr_k=50:1.1112,lwr_k=100:1.1227,lwr_k=200:1.1392,lwr_k=500:1.1872,lwr_k=1000:1.2284'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0609,lwr_k=20:0.4226,lwr_k=50:0.578,lwr_k=100:0.6596,lwr_k=200:0.7329,lwr_k=500:0.8169,lwr_k=1000:0.8688'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.0742,lwr_k=20:0.7269,lwr_k=50:0.7524,lwr_k=100:0.7872,lwr_k=200:0.8084,lwr_k=500:0.8432,lwr_k=1000:0.8856'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3647,lwr_k=20:0.3442,lwr_k=50:0.5953,lwr_k=100:0.7643,lwr_k=200:0.9153,lwr_k=500:1.0532,lwr_k=1000:1.1418'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.4676,lwr_k=20:1.04,lwr_k=50:0.9787,lwr_k=100:1.0618,lwr_k=200:1.1244,lwr_k=500:1.2266,lwr_k=1000:1.2912'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.7061,lwr_k=20:0.4315,lwr_k=50:0.8182,lwr_k=100:1.056,lwr_k=200:1.2445,lwr_k=500:1.4201,lwr_k=1000:1.5457'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.7073,lwr_k=20:1.4565,lwr_k=50:1.3511,lwr_k=100:1.4118,lwr_k=200:1.4363,lwr_k=500:1.5019,lwr_k=1000:1.5725'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.122,lwr_k=20:0.3064,lwr_k=50:0.5288,lwr_k=100:0.6803,lwr_k=200:0.8043,lwr_k=500:0.9267,lwr_k=1000:0.9944'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1356,lwr_k=20:0.8416,lwr_k=50:0.827,lwr_k=100:0.8744,lwr_k=200:0.9293,lwr_k=500:0.9716,lwr_k=1000:1.0289'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:1.133,lwr_k=20:0.5109,lwr_k=50:0.6434,lwr_k=100:0.7222,lwr_k=200:0.7821,lwr_k=500:0.843,lwr_k=1000:0.8956'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.1991,lwr_k=20:0.8149,lwr_k=50:0.8446,lwr_k=100:0.8879,lwr_k=200:0.9305,lwr_k=500:0.9786,lwr_k=1000:1.0194'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_24'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9283,lwr_k=20:5.8888,lwr_k=50:5.8079,lwr_k=100:5.8186,lwr_k=200:5.8398,lwr_k=500:5.8506,lwr_k=1000:5.8709'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0173,lwr_k=20:6.211,lwr_k=50:6.0481,lwr_k=100:5.996,lwr_k=200:5.9321,lwr_k=500:5.9601,lwr_k=1000:5.9804'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0485,lwr_k=20:5.9564,lwr_k=50:6.0491,lwr_k=100:5.9981,lwr_k=200:5.9364,lwr_k=500:5.9193,lwr_k=1000:5.9191'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.3068,lwr_k=20:6.1375,lwr_k=50:6.2011,lwr_k=100:6.1317,lwr_k=200:6.09,lwr_k=500:6.0986,lwr_k=1000:6.0982'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.9381,lwr_k=20:4.5151,lwr_k=50:4.6918,lwr_k=100:4.7565,lwr_k=200:4.7923,lwr_k=500:4.8132,lwr_k=1000:4.8241'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.9006,lwr_k=20:4.8907,lwr_k=50:4.7667,lwr_k=100:4.7003,lwr_k=200:4.6931,lwr_k=500:4.7247,lwr_k=1000:4.7279'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9693,lwr_k=20:5.9814,lwr_k=50:5.9247,lwr_k=100:5.8578,lwr_k=200:5.9009,lwr_k=500:5.9417,lwr_k=1000:5.9541'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.7332,lwr_k=20:6.0894,lwr_k=50:5.8058,lwr_k=100:5.6899,lwr_k=200:5.6813,lwr_k=500:5.6746,lwr_k=1000:5.6867'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.1356,lwr_k=20:4.6693,lwr_k=50:4.8408,lwr_k=100:4.9295,lwr_k=200:4.995,lwr_k=500:5.0129,lwr_k=1000:5.034'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.3254,lwr_k=20:5.4801,lwr_k=50:5.3416,lwr_k=100:5.2449,lwr_k=200:5.2455,lwr_k=500:5.2497,lwr_k=1000:5.2466'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:5.518,lwr_k=20:5.0148,lwr_k=50:5.2077,lwr_k=100:5.283,lwr_k=200:5.3529,lwr_k=500:5.3931,lwr_k=1000:5.4177'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.4747,lwr_k=20:5.5433,lwr_k=50:5.4085,lwr_k=100:5.3203,lwr_k=200:5.335,lwr_k=500:5.3171,lwr_k=1000:5.3174'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_25'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.653,lwr_k=20:3.2125,lwr_k=50:3.3523,lwr_k=100:3.4255,lwr_k=200:3.484,lwr_k=500:3.5384,lwr_k=1000:3.5775'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.6018,lwr_k=20:3.6163,lwr_k=50:3.5811,lwr_k=100:3.5761,lwr_k=200:3.5803,lwr_k=500:3.5851,lwr_k=1000:3.5924'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.1769,lwr_k=20:3.9061,lwr_k=50:4.273,lwr_k=100:4.3839,lwr_k=200:4.3846,lwr_k=500:4.3875,lwr_k=1000:4.3533'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.3387,lwr_k=20:4.4747,lwr_k=50:4.6036,lwr_k=100:4.6066,lwr_k=200:4.5564,lwr_k=500:4.489,lwr_k=1000:4.4488'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.5846,lwr_k=20:3.2572,lwr_k=50:3.4148,lwr_k=100:3.4621,lwr_k=200:3.4912,lwr_k=500:3.5302,lwr_k=1000:3.5302'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.6963,lwr_k=20:3.7497,lwr_k=50:3.7117,lwr_k=100:3.7081,lwr_k=200:3.703,lwr_k=500:3.6608,lwr_k=1000:3.6319'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.43,lwr_k=20:4.2232,lwr_k=50:4.6054,lwr_k=100:4.7413,lwr_k=200:4.7123,lwr_k=500:4.5908,lwr_k=1000:4.522'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.2656,lwr_k=20:4.4832,lwr_k=50:4.6235,lwr_k=100:4.6466,lwr_k=200:4.5859,lwr_k=500:4.4569,lwr_k=1000:4.3911'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8342,lwr_k=20:3.4942,lwr_k=50:3.6872,lwr_k=100:3.7259,lwr_k=200:3.7651,lwr_k=500:3.7795,lwr_k=1000:3.7797'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.9718,lwr_k=20:4.0663,lwr_k=50:4.002,lwr_k=100:3.9908,lwr_k=200:3.9602,lwr_k=500:3.9173,lwr_k=1000:3.91'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.0969,lwr_k=20:3.7425,lwr_k=50:3.9941,lwr_k=100:4.0855,lwr_k=200:4.1383,lwr_k=500:4.1794,lwr_k=1000:4.195'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.1764,lwr_k=20:4.2748,lwr_k=50:4.2651,lwr_k=100:4.3092,lwr_k=200:4.3127,lwr_k=500:4.3533,lwr_k=1000:4.3491'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_26'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6666,lwr_k=20:0.6148,lwr_k=50:0.6337,lwr_k=100:0.6391,lwr_k=200:0.6458,lwr_k=500:0.6538,lwr_k=1000:0.6571'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6497,lwr_k=20:0.6697,lwr_k=50:0.6497,lwr_k=100:0.6475,lwr_k=200:0.6453,lwr_k=500:0.6412,lwr_k=1000:0.644'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6447,lwr_k=20:0.5054,lwr_k=50:0.571,lwr_k=100:0.6014,lwr_k=200:0.6165,lwr_k=500:0.6266,lwr_k=1000:0.6327'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6432,lwr_k=20:0.6318,lwr_k=50:0.6286,lwr_k=100:0.6282,lwr_k=200:0.6409,lwr_k=500:0.6365,lwr_k=1000:0.6341'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6657,lwr_k=20:0.5337,lwr_k=50:0.5874,lwr_k=100:0.6153,lwr_k=200:0.6345,lwr_k=500:0.6507,lwr_k=1000:0.6567'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6965,lwr_k=20:0.7017,lwr_k=50:0.6826,lwr_k=100:0.6835,lwr_k=200:0.6805,lwr_k=500:0.6877,lwr_k=1000:0.6889'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6894,lwr_k=20:0.5687,lwr_k=50:0.6225,lwr_k=100:0.6378,lwr_k=200:0.6514,lwr_k=500:0.6671,lwr_k=1000:0.6766'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.688,lwr_k=20:0.6914,lwr_k=50:0.6718,lwr_k=100:0.6695,lwr_k=200:0.6697,lwr_k=500:0.6785,lwr_k=1000:0.6808'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6846,lwr_k=20:0.5928,lwr_k=50:0.6386,lwr_k=100:0.6545,lwr_k=200:0.6637,lwr_k=500:0.671,lwr_k=1000:0.6748'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7126,lwr_k=20:0.7055,lwr_k=50:0.6969,lwr_k=100:0.6969,lwr_k=200:0.6964,lwr_k=500:0.7,lwr_k=1000:0.7022'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6217,lwr_k=20:0.5875,lwr_k=50:0.6063,lwr_k=100:0.6119,lwr_k=200:0.6152,lwr_k=500:0.6172,lwr_k=1000:0.6187'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7324,lwr_k=20:0.735,lwr_k=50:0.7214,lwr_k=100:0.7149,lwr_k=200:0.7151,lwr_k=500:0.714,lwr_k=1000:0.7136'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_27'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7801,lwr_k=20:3.453,lwr_k=50:3.6225,lwr_k=100:3.6617,lwr_k=200:3.688,lwr_k=500:3.7196,lwr_k=1000:3.7283'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.7487,lwr_k=20:3.81,lwr_k=50:3.8063,lwr_k=100:3.7999,lwr_k=200:3.7942,lwr_k=500:3.7581,lwr_k=1000:3.7353'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.1691,lwr_k=20:3.8878,lwr_k=50:4.0237,lwr_k=100:4.0725,lwr_k=200:4.0966,lwr_k=500:4.1298,lwr_k=1000:4.1353'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.3083,lwr_k=20:4.2895,lwr_k=50:4.2174,lwr_k=100:4.2441,lwr_k=200:4.2494,lwr_k=500:4.2635,lwr_k=1000:4.2734'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7258,lwr_k=20:3.4695,lwr_k=50:3.6023,lwr_k=100:3.649,lwr_k=200:3.6781,lwr_k=500:3.7063,lwr_k=1000:3.7237'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.7452,lwr_k=20:3.8563,lwr_k=50:3.8087,lwr_k=100:3.7718,lwr_k=200:3.7623,lwr_k=500:3.7631,lwr_k=1000:3.7559'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8724,lwr_k=20:3.4457,lwr_k=50:3.61,lwr_k=100:3.6841,lwr_k=200:3.7199,lwr_k=500:3.7468,lwr_k=1000:3.7741'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.6822,lwr_k=20:3.6369,lwr_k=50:3.61,lwr_k=100:3.6072,lwr_k=200:3.6003,lwr_k=500:3.6041,lwr_k=1000:3.6236'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.1323,lwr_k=20:3.5627,lwr_k=50:3.8288,lwr_k=100:3.9028,lwr_k=200:3.9393,lwr_k=500:3.9736,lwr_k=1000:4.0072'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.3788,lwr_k=20:4.236,lwr_k=50:4.2924,lwr_k=100:4.3111,lwr_k=200:4.2973,lwr_k=500:4.2994,lwr_k=1000:4.3229'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:6.0857,lwr_k=20:6.8304,lwr_k=50:6.5014,lwr_k=100:6.2754,lwr_k=200:6.1001,lwr_k=500:6.0893,lwr_k=1000:6.0857'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0856,lwr_k=20:6.8685,lwr_k=50:6.5298,lwr_k=100:6.2946,lwr_k=200:6.1054,lwr_k=500:6.0919,lwr_k=1000:6.0854'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_28'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.5997,lwr_k=20:4.9096,lwr_k=50:5.2039,lwr_k=100:5.3097,lwr_k=200:5.3921,lwr_k=500:5.4335,lwr_k=1000:5.4723'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.6825,lwr_k=20:5.6185,lwr_k=50:5.5562,lwr_k=100:5.5416,lwr_k=200:5.5536,lwr_k=500:5.5705,lwr_k=1000:5.5975'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.6233,lwr_k=20:5.0175,lwr_k=50:5.2575,lwr_k=100:5.3562,lwr_k=200:5.3998,lwr_k=500:5.4802,lwr_k=1000:5.5275'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.8404,lwr_k=20:5.7489,lwr_k=50:5.7248,lwr_k=100:5.7073,lwr_k=200:5.7236,lwr_k=500:5.7103,lwr_k=1000:5.7236'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.0068,lwr_k=20:3.555,lwr_k=50:3.6786,lwr_k=100:3.7508,lwr_k=200:3.8067,lwr_k=500:3.8697,lwr_k=1000:3.8887'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.0588,lwr_k=20:3.9448,lwr_k=50:3.8866,lwr_k=100:3.8575,lwr_k=200:3.8786,lwr_k=500:3.9102,lwr_k=1000:3.9186'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.052,lwr_k=20:3.587,lwr_k=50:3.7489,lwr_k=100:3.826,lwr_k=200:3.8726,lwr_k=500:3.9214,lwr_k=1000:3.936'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.8635,lwr_k=20:3.8679,lwr_k=50:3.8572,lwr_k=100:3.8201,lwr_k=200:3.8151,lwr_k=500:3.8119,lwr_k=1000:3.8147'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.7231,lwr_k=20:5.0736,lwr_k=50:5.3073,lwr_k=100:5.4202,lwr_k=200:5.5251,lwr_k=500:5.5786,lwr_k=1000:5.6196'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.791,lwr_k=20:5.8803,lwr_k=50:5.6982,lwr_k=100:5.6684,lwr_k=200:5.668,lwr_k=500:5.6941,lwr_k=1000:5.7065'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.0244,lwr_k=20:3.553,lwr_k=50:3.7265,lwr_k=100:3.7892,lwr_k=200:3.836,lwr_k=500:3.8655,lwr_k=1000:3.8921'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.0828,lwr_k=20:3.9833,lwr_k=50:3.9274,lwr_k=100:3.9586,lwr_k=200:3.9932,lwr_k=500:3.9939,lwr_k=1000:3.9993'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_29'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6201,lwr_k=20:3.2031,lwr_k=50:3.433,lwr_k=100:3.4761,lwr_k=200:3.4803,lwr_k=500:3.4608,lwr_k=1000:3.4603'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.5014,lwr_k=20:3.6665,lwr_k=50:3.6399,lwr_k=100:3.6017,lwr_k=200:3.5386,lwr_k=500:3.4624,lwr_k=1000:3.4209'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.2058,lwr_k=20:3.8758,lwr_k=50:4.1412,lwr_k=100:4.2144,lwr_k=200:4.1798,lwr_k=500:4.1325,lwr_k=1000:4.0832'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.3609,lwr_k=20:4.4168,lwr_k=50:4.4945,lwr_k=100:4.48,lwr_k=200:4.3814,lwr_k=500:4.2845,lwr_k=1000:4.2132'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0284,lwr_k=20:6.0468,lwr_k=50:6.191,lwr_k=100:6.1085,lwr_k=200:6.0326,lwr_k=500:6.03,lwr_k=1000:6.0284'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.9286,lwr_k=20:5.9193,lwr_k=50:6.1735,lwr_k=100:6.0665,lwr_k=200:5.946,lwr_k=500:5.9385,lwr_k=1000:5.9268'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6856,lwr_k=20:3.2483,lwr_k=50:3.4335,lwr_k=100:3.5119,lwr_k=200:3.5471,lwr_k=500:3.5785,lwr_k=1000:3.5969'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.5642,lwr_k=20:3.5311,lwr_k=50:3.5749,lwr_k=100:3.5875,lwr_k=200:3.5588,lwr_k=500:3.5282,lwr_k=1000:3.53'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7086,lwr_k=20:3.253,lwr_k=50:3.4516,lwr_k=100:3.5278,lwr_k=200:3.5504,lwr_k=500:3.5678,lwr_k=1000:3.5753'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.8272,lwr_k=20:3.7855,lwr_k=50:3.7561,lwr_k=100:3.7588,lwr_k=200:3.7426,lwr_k=500:3.7115,lwr_k=1000:3.7102'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:6.0857,lwr_k=20:6.8304,lwr_k=50:6.5014,lwr_k=100:6.2754,lwr_k=200:6.1001,lwr_k=500:6.0893,lwr_k=1000:6.0857'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0856,lwr_k=20:6.8685,lwr_k=50:6.5298,lwr_k=100:6.2946,lwr_k=200:6.1054,lwr_k=500:6.0919,lwr_k=1000:6.0854'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_30'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8785,lwr_k=20:0.8131,lwr_k=50:0.8396,lwr_k=100:0.8492,lwr_k=200:0.8591,lwr_k=500:0.8662,lwr_k=1000:0.8711'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8357,lwr_k=20:0.8629,lwr_k=50:0.835,lwr_k=100:0.8284,lwr_k=200:0.8309,lwr_k=500:0.8318,lwr_k=1000:0.8319'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8039,lwr_k=20:0.7573,lwr_k=50:0.7797,lwr_k=100:0.7876,lwr_k=200:0.7961,lwr_k=500:0.7989,lwr_k=1000:0.801'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7914,lwr_k=20:0.8314,lwr_k=50:0.8063,lwr_k=100:0.7968,lwr_k=200:0.7898,lwr_k=500:0.7875,lwr_k=1000:0.7876'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8052,lwr_k=20:0.7398,lwr_k=50:0.7575,lwr_k=100:0.7675,lwr_k=200:0.7694,lwr_k=500:0.7723,lwr_k=1000:0.7769'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.828,lwr_k=20:0.8297,lwr_k=50:0.8134,lwr_k=100:0.8115,lwr_k=200:0.7982,lwr_k=500:0.7925,lwr_k=1000:0.796'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9601,lwr_k=20:0.8926,lwr_k=50:0.9074,lwr_k=100:0.916,lwr_k=200:0.9235,lwr_k=500:0.9281,lwr_k=1000:0.9321'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9303,lwr_k=20:0.9423,lwr_k=50:0.9249,lwr_k=100:0.9164,lwr_k=200:0.9171,lwr_k=500:0.9124,lwr_k=1000:0.9099'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.876,lwr_k=20:0.7825,lwr_k=50:0.8056,lwr_k=100:0.8212,lwr_k=200:0.8282,lwr_k=500:0.8335,lwr_k=1000:0.8349'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9193,lwr_k=20:0.9183,lwr_k=50:0.889,lwr_k=100:0.8894,lwr_k=200:0.886,lwr_k=500:0.8853,lwr_k=1000:0.885'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:1.1186,lwr_k=20:1.0709,lwr_k=50:1.0696,lwr_k=100:1.0773,lwr_k=200:1.078,lwr_k=500:1.0759,lwr_k=1000:1.0787'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.2097,lwr_k=20:1.2564,lwr_k=50:1.2069,lwr_k=100:1.194,lwr_k=200:1.1905,lwr_k=500:1.1782,lwr_k=1000:1.1801'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_31'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.4835,lwr_k=20:0.5252,lwr_k=50:1.027,lwr_k=100:1.4178,lwr_k=200:1.7565,lwr_k=500:2.116,lwr_k=1000:2.286'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.4041,lwr_k=20:2.0425,lwr_k=50:2.0694,lwr_k=100:2.1498,lwr_k=200:2.2194,lwr_k=500:2.2746,lwr_k=1000:2.3336'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.6329,lwr_k=20:0.575,lwr_k=50:1.1236,lwr_k=100:1.5675,lwr_k=200:1.9792,lwr_k=500:2.3294,lwr_k=1000:2.4698'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.6251,lwr_k=20:2.5066,lwr_k=50:2.4967,lwr_k=100:2.3875,lwr_k=200:2.3789,lwr_k=500:2.456,lwr_k=1000:2.5366'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.6925,lwr_k=20:0.4553,lwr_k=50:1.0303,lwr_k=100:1.5334,lwr_k=200:1.9844,lwr_k=500:2.3278,lwr_k=1000:2.4746'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.9216,lwr_k=20:2.6686,lwr_k=50:2.6675,lwr_k=100:2.6788,lwr_k=200:2.7091,lwr_k=500:2.8085,lwr_k=1000:2.8656'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.5224,lwr_k=20:0.7327,lwr_k=50:1.2388,lwr_k=100:1.6155,lwr_k=200:1.9274,lwr_k=500:2.2217,lwr_k=1000:2.3343'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.4854,lwr_k=20:2.3043,lwr_k=50:2.3033,lwr_k=100:2.3237,lwr_k=200:2.3393,lwr_k=500:2.4166,lwr_k=1000:2.4371'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.3875,lwr_k=20:1.4644,lwr_k=50:1.7345,lwr_k=100:1.897,lwr_k=200:2.0173,lwr_k=500:2.1528,lwr_k=1000:2.2425'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.5402,lwr_k=20:2.3404,lwr_k=50:2.331,lwr_k=100:2.3099,lwr_k=200:2.3544,lwr_k=500:2.4329,lwr_k=1000:2.4731'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:2.0917,lwr_k=20:0.7864,lwr_k=50:1.158,lwr_k=100:1.3962,lwr_k=200:1.624,lwr_k=500:1.8287,lwr_k=1000:1.9226'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.2388,lwr_k=20:1.762,lwr_k=50:1.8501,lwr_k=100:1.9198,lwr_k=200:2.035,lwr_k=500:2.1115,lwr_k=1000:2.1232'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_32'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5357,lwr_k=20:2.7422,lwr_k=50:3.3272,lwr_k=100:3.6603,lwr_k=200:3.8763,lwr_k=500:4.1048,lwr_k=1000:4.2697'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.4802,lwr_k=20:4.0683,lwr_k=50:4.026,lwr_k=100:3.9571,lwr_k=200:4.022,lwr_k=500:4.1269,lwr_k=1000:4.2671'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.2277,lwr_k=20:2.961,lwr_k=50:3.4075,lwr_k=100:3.6092,lwr_k=200:3.7726,lwr_k=500:3.9726,lwr_k=1000:4.0903'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.3138,lwr_k=20:3.8276,lwr_k=50:3.8163,lwr_k=100:3.848,lwr_k=200:3.9142,lwr_k=500:4.0303,lwr_k=1000:4.1357'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.3736,lwr_k=20:2.9209,lwr_k=50:3.4894,lwr_k=100:3.7558,lwr_k=200:3.9604,lwr_k=500:4.1914,lwr_k=1000:4.3476'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.6124,lwr_k=20:4.1498,lwr_k=50:4.0926,lwr_k=100:4.1727,lwr_k=200:4.2336,lwr_k=500:4.3852,lwr_k=1000:4.4464'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.5247,lwr_k=20:2.6439,lwr_k=50:2.9222,lwr_k=100:3.06,lwr_k=200:3.2017,lwr_k=500:3.3139,lwr_k=1000:3.3945'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.427,lwr_k=20:3.5277,lwr_k=50:3.34,lwr_k=100:3.3087,lwr_k=200:3.3243,lwr_k=500:3.3541,lwr_k=1000:3.3662'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.08,lwr_k=20:2.4871,lwr_k=50:3.0416,lwr_k=100:3.3376,lwr_k=200:3.5457,lwr_k=500:3.7298,lwr_k=1000:3.8619'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.2043,lwr_k=20:3.925,lwr_k=50:3.8913,lwr_k=100:3.9139,lwr_k=200:3.9431,lwr_k=500:3.9647,lwr_k=1000:4.0519'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.629,lwr_k=20:2.4463,lwr_k=50:3.1636,lwr_k=100:3.5032,lwr_k=200:3.7697,lwr_k=500:4.0266,lwr_k=1000:4.1989'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.6475,lwr_k=20:3.7318,lwr_k=50:3.8626,lwr_k=100:3.9346,lwr_k=200:4.0203,lwr_k=500:4.1677,lwr_k=1000:4.2814'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_33'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9742,lwr_k=20:3.6389,lwr_k=50:4.0974,lwr_k=100:4.3623,lwr_k=200:4.5939,lwr_k=500:4.8793,lwr_k=1000:5.0095'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.9684,lwr_k=20:3.9667,lwr_k=50:4.2976,lwr_k=100:4.4302,lwr_k=200:4.6314,lwr_k=500:4.889,lwr_k=1000:5.0136'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9558,lwr_k=20:3.6912,lwr_k=50:4.1723,lwr_k=100:4.4492,lwr_k=200:4.6461,lwr_k=500:4.9047,lwr_k=1000:5.0258'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.1572,lwr_k=20:4.0993,lwr_k=50:4.3885,lwr_k=100:4.5587,lwr_k=200:4.7798,lwr_k=500:5.0621,lwr_k=1000:5.1785'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9205,lwr_k=20:3.706,lwr_k=50:4.1688,lwr_k=100:4.4126,lwr_k=200:4.613,lwr_k=500:4.8928,lwr_k=1000:5.0194'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.0831,lwr_k=20:4.0759,lwr_k=50:4.3002,lwr_k=100:4.4672,lwr_k=200:4.6407,lwr_k=500:4.8698,lwr_k=1000:4.988'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.0083,lwr_k=20:3.6614,lwr_k=50:4.2193,lwr_k=100:4.4483,lwr_k=200:4.6634,lwr_k=500:4.9682,lwr_k=1000:5.0918'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.8893,lwr_k=20:4.0504,lwr_k=50:4.2483,lwr_k=100:4.3791,lwr_k=200:4.4928,lwr_k=500:4.7649,lwr_k=1000:4.885'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.007,lwr_k=20:3.6084,lwr_k=50:4.1259,lwr_k=100:4.3838,lwr_k=200:4.6215,lwr_k=500:4.9088,lwr_k=1000:5.0325'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.1005,lwr_k=20:4.2578,lwr_k=50:4.586,lwr_k=100:4.7034,lwr_k=200:4.842,lwr_k=500:5.094,lwr_k=1000:5.1932'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.0222,lwr_k=20:3.5237,lwr_k=50:4.0897,lwr_k=100:4.3527,lwr_k=200:4.5819,lwr_k=500:4.8539,lwr_k=1000:4.9974'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.1652,lwr_k=20:3.8802,lwr_k=50:4.1787,lwr_k=100:4.3836,lwr_k=200:4.558,lwr_k=500:4.8391,lwr_k=1000:4.9928'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_34'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.697,lwr_k=20:0.8501,lwr_k=50:1.3073,lwr_k=100:1.6805,lwr_k=200:1.9992,lwr_k=500:2.3282,lwr_k=1000:2.4921'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.6331,lwr_k=20:2.5129,lwr_k=50:2.406,lwr_k=100:2.4393,lwr_k=200:2.532,lwr_k=500:2.5212,lwr_k=1000:2.5514'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.6997,lwr_k=20:1.063,lwr_k=50:1.5616,lwr_k=100:1.9057,lwr_k=200:2.1892,lwr_k=500:2.447,lwr_k=1000:2.5603'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.7452,lwr_k=20:2.4494,lwr_k=50:2.5532,lwr_k=100:2.607,lwr_k=200:2.6516,lwr_k=500:2.6541,lwr_k=1000:2.6979'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.7829,lwr_k=20:1.088,lwr_k=50:1.5707,lwr_k=100:1.8738,lwr_k=200:2.1421,lwr_k=500:2.3963,lwr_k=1000:2.5712'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.9371,lwr_k=20:2.6664,lwr_k=50:2.7133,lwr_k=100:2.7471,lwr_k=200:2.8239,lwr_k=500:2.8551,lwr_k=1000:2.8563'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.0878,lwr_k=20:0.4703,lwr_k=50:1.0989,lwr_k=100:1.6684,lwr_k=200:2.1297,lwr_k=500:2.5748,lwr_k=1000:2.8088'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.0747,lwr_k=20:2.9344,lwr_k=50:2.9179,lwr_k=100:2.7704,lwr_k=200:2.7482,lwr_k=500:2.8706,lwr_k=1000:2.977'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.5908,lwr_k=20:0.8365,lwr_k=50:1.2829,lwr_k=100:1.5894,lwr_k=200:1.8721,lwr_k=500:2.1971,lwr_k=1000:2.3645'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.6706,lwr_k=20:2.3757,lwr_k=50:2.2921,lwr_k=100:2.3201,lwr_k=200:2.4088,lwr_k=500:2.5069,lwr_k=1000:2.6273'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:2.1901,lwr_k=20:0.6678,lwr_k=50:1.085,lwr_k=100:1.3906,lwr_k=200:1.6492,lwr_k=500:1.887,lwr_k=1000:2.0113'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.3341,lwr_k=20:1.7563,lwr_k=50:1.8716,lwr_k=100:2.0248,lwr_k=200:2.0918,lwr_k=500:2.1655,lwr_k=1000:2.2263'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_35'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.2985,lwr_k=20:2.4771,lwr_k=50:2.8452,lwr_k=100:3.0074,lwr_k=200:3.1041,lwr_k=500:3.1929,lwr_k=1000:3.245'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.3148,lwr_k=20:3.206,lwr_k=50:3.2729,lwr_k=100:3.2248,lwr_k=200:3.2427,lwr_k=500:3.2404,lwr_k=1000:3.242'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.1131,lwr_k=20:2.927,lwr_k=50:3.0115,lwr_k=100:3.0529,lwr_k=200:3.0603,lwr_k=500:3.071,lwr_k=1000:3.0753'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.1097,lwr_k=20:3.1789,lwr_k=50:3.1258,lwr_k=100:3.1039,lwr_k=200:3.0788,lwr_k=500:3.0784,lwr_k=1000:3.0827'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.6302,lwr_k=20:2.3281,lwr_k=50:2.4398,lwr_k=100:2.477,lwr_k=200:2.5129,lwr_k=500:2.5567,lwr_k=1000:2.5852'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.7321,lwr_k=20:2.7037,lwr_k=50:2.6952,lwr_k=100:2.678,lwr_k=200:2.6947,lwr_k=500:2.7069,lwr_k=1000:2.7204'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.8221,lwr_k=20:2.3412,lwr_k=50:2.4438,lwr_k=100:2.5195,lwr_k=200:2.5651,lwr_k=500:2.6184,lwr_k=1000:2.6652'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.716,lwr_k=20:2.547,lwr_k=50:2.4965,lwr_k=100:2.5104,lwr_k=200:2.5152,lwr_k=500:2.5613,lwr_k=1000:2.602'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.7732,lwr_k=20:2.4475,lwr_k=50:2.5597,lwr_k=100:2.6031,lwr_k=200:2.6404,lwr_k=500:2.678,lwr_k=1000:2.6953'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.884,lwr_k=20:2.8973,lwr_k=50:2.8625,lwr_k=100:2.8403,lwr_k=200:2.8271,lwr_k=500:2.834,lwr_k=1000:2.8273'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:2.8148,lwr_k=20:2.3065,lwr_k=50:2.4397,lwr_k=100:2.5257,lwr_k=200:2.5837,lwr_k=500:2.6451,lwr_k=1000:2.6864'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.7506,lwr_k=20:2.6058,lwr_k=50:2.6264,lwr_k=100:2.6067,lwr_k=200:2.6236,lwr_k=500:2.6451,lwr_k=1000:2.6564'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_36'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7441,lwr_k=20:0.6979,lwr_k=50:0.722,lwr_k=100:0.7301,lwr_k=200:0.7344,lwr_k=500:0.7381,lwr_k=1000:0.7397'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7395,lwr_k=20:0.7436,lwr_k=50:0.7287,lwr_k=100:0.7199,lwr_k=200:0.7229,lwr_k=500:0.7264,lwr_k=1000:0.7317'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7336,lwr_k=20:0.6797,lwr_k=50:0.7086,lwr_k=100:0.7174,lwr_k=200:0.7187,lwr_k=500:0.7265,lwr_k=1000:0.729'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.736,lwr_k=20:0.751,lwr_k=50:0.7317,lwr_k=100:0.7291,lwr_k=200:0.7241,lwr_k=500:0.7292,lwr_k=1000:0.7334'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6653,lwr_k=20:0.613,lwr_k=50:0.6369,lwr_k=100:0.6455,lwr_k=200:0.6521,lwr_k=500:0.657,lwr_k=1000:0.6614'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.695,lwr_k=20:0.7276,lwr_k=50:0.7057,lwr_k=100:0.6987,lwr_k=200:0.694,lwr_k=500:0.6914,lwr_k=1000:0.6927'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6608,lwr_k=20:0.6094,lwr_k=50:0.6327,lwr_k=100:0.6421,lwr_k=200:0.6489,lwr_k=500:0.6539,lwr_k=1000:0.6574'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6538,lwr_k=20:0.6576,lwr_k=50:0.6417,lwr_k=100:0.6378,lwr_k=200:0.6427,lwr_k=500:0.6473,lwr_k=1000:0.6503'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6918,lwr_k=20:0.6505,lwr_k=50:0.6678,lwr_k=100:0.6756,lwr_k=200:0.6826,lwr_k=500:0.6869,lwr_k=1000:0.6902'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7124,lwr_k=20:0.7488,lwr_k=50:0.7262,lwr_k=100:0.7227,lwr_k=200:0.7167,lwr_k=500:0.7138,lwr_k=1000:0.7128'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6104,lwr_k=20:0.5775,lwr_k=50:0.5926,lwr_k=100:0.5983,lwr_k=200:0.6033,lwr_k=500:0.6062,lwr_k=1000:0.6082'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7048,lwr_k=20:0.7386,lwr_k=50:0.7179,lwr_k=100:0.7082,lwr_k=200:0.7036,lwr_k=500:0.7022,lwr_k=1000:0.7026'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_37'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6208,lwr_k=20:3.0772,lwr_k=50:3.2668,lwr_k=100:3.3053,lwr_k=200:3.3502,lwr_k=500:3.3967,lwr_k=1000:3.4363'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.559,lwr_k=20:3.6057,lwr_k=50:3.5405,lwr_k=100:3.4857,lwr_k=200:3.4479,lwr_k=500:3.4128,lwr_k=1000:3.3965'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.5145,lwr_k=20:3.0567,lwr_k=50:3.2528,lwr_k=100:3.3094,lwr_k=200:3.3182,lwr_k=500:3.3516,lwr_k=1000:3.3564'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.6187,lwr_k=20:3.6722,lwr_k=50:3.6051,lwr_k=100:3.5163,lwr_k=200:3.4823,lwr_k=500:3.5157,lwr_k=1000:3.5228'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.4386,lwr_k=20:2.7452,lwr_k=50:2.9355,lwr_k=100:3.0118,lwr_k=200:3.0634,lwr_k=500:3.1388,lwr_k=1000:3.2015'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.5744,lwr_k=20:3.3672,lwr_k=50:3.3704,lwr_k=100:3.361,lwr_k=200:3.3239,lwr_k=500:3.3237,lwr_k=1000:3.3586'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.5742,lwr_k=20:3.0448,lwr_k=50:3.2172,lwr_k=100:3.2577,lwr_k=200:3.2758,lwr_k=500:3.29,lwr_k=1000:3.3277'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.5726,lwr_k=20:3.5285,lwr_k=50:3.462,lwr_k=100:3.402,lwr_k=200:3.3385,lwr_k=500:3.3094,lwr_k=1000:3.3145'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.5014,lwr_k=20:3.1099,lwr_k=50:3.2716,lwr_k=100:3.3519,lwr_k=200:3.3779,lwr_k=500:3.4121,lwr_k=1000:3.4619'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.5767,lwr_k=20:3.6995,lwr_k=50:3.707,lwr_k=100:3.6541,lwr_k=200:3.5854,lwr_k=500:3.5213,lwr_k=1000:3.5032'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.4305,lwr_k=20:2.7901,lwr_k=50:3.0436,lwr_k=100:3.1893,lwr_k=200:3.2607,lwr_k=500:3.3275,lwr_k=1000:3.355'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.5331,lwr_k=20:3.3233,lwr_k=50:3.4111,lwr_k=100:3.4621,lwr_k=200:3.4942,lwr_k=500:3.4662,lwr_k=1000:3.4671'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_38'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7121,lwr_k=20:3.4865,lwr_k=50:3.7198,lwr_k=100:3.7851,lwr_k=200:3.8488,lwr_k=500:3.8908,lwr_k=1000:3.9243'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.6526,lwr_k=20:3.9274,lwr_k=50:3.868,lwr_k=100:3.8679,lwr_k=200:3.8501,lwr_k=500:3.856,lwr_k=1000:3.8681'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6315,lwr_k=20:3.5223,lwr_k=50:3.7334,lwr_k=100:3.7872,lwr_k=200:3.8258,lwr_k=500:3.8616,lwr_k=1000:3.8604'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.7363,lwr_k=20:3.999,lwr_k=50:4.0157,lwr_k=100:3.9672,lwr_k=200:3.9491,lwr_k=500:3.9415,lwr_k=1000:3.9472'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7592,lwr_k=20:3.693,lwr_k=50:3.8641,lwr_k=100:3.9342,lwr_k=200:3.9931,lwr_k=500:4.0677,lwr_k=1000:4.1508'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.8175,lwr_k=20:4.1578,lwr_k=50:4.177,lwr_k=100:4.1718,lwr_k=200:4.1828,lwr_k=500:4.1825,lwr_k=1000:4.2673'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7836,lwr_k=20:3.1327,lwr_k=50:3.3437,lwr_k=100:3.4658,lwr_k=200:3.5479,lwr_k=500:3.6315,lwr_k=1000:3.6727'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.6643,lwr_k=20:3.5506,lwr_k=50:3.5357,lwr_k=100:3.5044,lwr_k=200:3.5222,lwr_k=500:3.5184,lwr_k=1000:3.5262'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7318,lwr_k=20:3.1894,lwr_k=50:3.3764,lwr_k=100:3.4851,lwr_k=200:3.5352,lwr_k=500:3.5722,lwr_k=1000:3.6078'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.8195,lwr_k=20:3.7272,lwr_k=50:3.7361,lwr_k=100:3.7756,lwr_k=200:3.7512,lwr_k=500:3.7072,lwr_k=1000:3.7076'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.6809,lwr_k=20:2.9559,lwr_k=50:3.1848,lwr_k=100:3.2876,lwr_k=200:3.3684,lwr_k=500:3.4539,lwr_k=1000:3.5307'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.7602,lwr_k=20:3.4606,lwr_k=50:3.5451,lwr_k=100:3.6188,lwr_k=200:3.6238,lwr_k=500:3.6735,lwr_k=1000:3.7037'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_39'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:21.9045,lwr_k=20:2.3597,lwr_k=50:3.012,lwr_k=100:3.3486,lwr_k=200:3.6027,lwr_k=500:3.8824,lwr_k=1000:4.1037'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:21.1677,lwr_k=20:4.0227,lwr_k=50:3.7219,lwr_k=100:3.7305,lwr_k=200:3.774,lwr_k=500:3.9573,lwr_k=1000:4.8638'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.9952,lwr_k=20:2.6211,lwr_k=50:3.4497,lwr_k=100:3.7222,lwr_k=200:3.9333,lwr_k=500:4.3811,lwr_k=1000:4.8478'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:7.48,lwr_k=20:4.6457,lwr_k=50:4.3344,lwr_k=100:4.1495,lwr_k=200:4.2045,lwr_k=500:4.3537,lwr_k=1000:4.5091'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.4841,lwr_k=20:1.8257,lwr_k=50:2.4369,lwr_k=100:2.7627,lwr_k=200:2.957,lwr_k=500:3.1496,lwr_k=1000:3.2444'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.6018,lwr_k=20:3.2504,lwr_k=50:3.2364,lwr_k=100:3.2575,lwr_k=200:3.3214,lwr_k=500:3.387,lwr_k=1000:3.4603'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.4506,lwr_k=20:2.0227,lwr_k=50:2.4576,lwr_k=100:2.7073,lwr_k=200:2.9062,lwr_k=500:3.115,lwr_k=1000:3.2412'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.3739,lwr_k=20:3.0509,lwr_k=50:3.0021,lwr_k=100:3.0407,lwr_k=200:3.1236,lwr_k=500:3.1748,lwr_k=1000:3.2432'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.0558,lwr_k=20:2.657,lwr_k=50:3.4108,lwr_k=100:3.7007,lwr_k=200:3.9047,lwr_k=500:4.1214,lwr_k=1000:4.2753'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.9961,lwr_k=20:4.1921,lwr_k=50:4.909,lwr_k=100:4.6114,lwr_k=200:4.5706,lwr_k=500:4.712,lwr_k=1000:4.841'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.0538,lwr_k=20:1.6625,lwr_k=50:2.4544,lwr_k=100:2.823,lwr_k=200:3.0886,lwr_k=500:3.3261,lwr_k=1000:3.4649'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.2043,lwr_k=20:3.2702,lwr_k=50:3.4634,lwr_k=100:3.5448,lwr_k=200:3.5927,lwr_k=500:3.5841,lwr_k=1000:3.6593'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_40'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.5817,lwr_k=20:0.4664,lwr_k=50:0.5075,lwr_k=100:0.5286,lwr_k=200:0.5422,lwr_k=500:0.5597,lwr_k=1000:0.565'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.5948,lwr_k=20:0.5783,lwr_k=50:0.5695,lwr_k=100:0.5707,lwr_k=200:0.5715,lwr_k=500:0.5747,lwr_k=1000:0.5771'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6111,lwr_k=20:0.5457,lwr_k=50:0.5726,lwr_k=100:0.5879,lwr_k=200:0.5961,lwr_k=500:0.6043,lwr_k=1000:0.6083'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6056,lwr_k=20:0.6141,lwr_k=50:0.6069,lwr_k=100:0.6048,lwr_k=200:0.6006,lwr_k=500:0.6056,lwr_k=1000:0.6009'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6113,lwr_k=20:0.529,lwr_k=50:0.5597,lwr_k=100:0.5772,lwr_k=200:0.5883,lwr_k=500:0.5977,lwr_k=1000:0.6014'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6506,lwr_k=20:0.6413,lwr_k=50:0.635,lwr_k=100:0.6363,lwr_k=200:0.6361,lwr_k=500:0.6404,lwr_k=1000:0.6431'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.5803,lwr_k=20:0.5171,lwr_k=50:0.5414,lwr_k=100:0.5584,lwr_k=200:0.5621,lwr_k=500:0.5712,lwr_k=1000:0.5765'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.5697,lwr_k=20:0.5819,lwr_k=50:0.5756,lwr_k=100:0.5753,lwr_k=200:0.5685,lwr_k=500:0.5661,lwr_k=1000:0.5636'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6186,lwr_k=20:0.5665,lwr_k=50:0.5938,lwr_k=100:0.6047,lwr_k=200:0.6095,lwr_k=500:0.6162,lwr_k=1000:0.6209'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6228,lwr_k=20:0.6342,lwr_k=50:0.6215,lwr_k=100:0.616,lwr_k=200:0.616,lwr_k=500:0.6195,lwr_k=1000:0.6211'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.5951,lwr_k=20:0.5518,lwr_k=50:0.5732,lwr_k=100:0.583,lwr_k=200:0.5875,lwr_k=500:0.5949,lwr_k=1000:0.5968'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6707,lwr_k=20:0.7096,lwr_k=50:0.6887,lwr_k=100:0.6736,lwr_k=200:0.6736,lwr_k=500:0.669,lwr_k=1000:0.6678'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_41'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7624,lwr_k=20:3.5692,lwr_k=50:3.7474,lwr_k=100:3.8014,lwr_k=200:3.8251,lwr_k=500:3.823,lwr_k=1000:3.8296'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.738,lwr_k=20:3.9908,lwr_k=50:3.9167,lwr_k=100:3.8804,lwr_k=200:3.8534,lwr_k=500:3.8247,lwr_k=1000:3.7838'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.84,lwr_k=20:3.5597,lwr_k=50:3.694,lwr_k=100:3.7439,lwr_k=200:3.7675,lwr_k=500:3.7961,lwr_k=1000:3.8014'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.9303,lwr_k=20:4.0219,lwr_k=50:3.9512,lwr_k=100:3.948,lwr_k=200:3.9422,lwr_k=500:3.916,lwr_k=1000:3.8947'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5035,lwr_k=20:4.4284,lwr_k=50:4.762,lwr_k=100:4.9199,lwr_k=200:4.9809,lwr_k=500:5.0359,lwr_k=1000:5.0679'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.5017,lwr_k=20:4.7368,lwr_k=50:4.8513,lwr_k=100:4.9224,lwr_k=200:4.8814,lwr_k=500:4.9228,lwr_k=1000:4.9542'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8576,lwr_k=20:3.5725,lwr_k=50:3.7358,lwr_k=100:3.7931,lwr_k=200:3.8149,lwr_k=500:3.8483,lwr_k=1000:3.8702'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.6961,lwr_k=20:3.8015,lwr_k=50:3.7361,lwr_k=100:3.7174,lwr_k=200:3.688,lwr_k=500:3.6984,lwr_k=1000:3.6992'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.8537,lwr_k=20:4.2534,lwr_k=50:4.7271,lwr_k=100:4.9544,lwr_k=200:5.0774,lwr_k=500:5.2404,lwr_k=1000:5.3565'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.0419,lwr_k=20:4.8336,lwr_k=50:4.9971,lwr_k=100:5.1443,lwr_k=200:5.2633,lwr_k=500:5.3764,lwr_k=1000:5.4934'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.7707,lwr_k=20:3.4701,lwr_k=50:3.5945,lwr_k=100:3.6457,lwr_k=200:3.681,lwr_k=500:3.7151,lwr_k=1000:3.7281'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.8509,lwr_k=20:3.8639,lwr_k=50:3.8354,lwr_k=100:3.8307,lwr_k=200:3.8394,lwr_k=500:3.8369,lwr_k=1000:3.8317'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_42'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6706,lwr_k=20:0.6304,lwr_k=50:0.6482,lwr_k=100:0.655,lwr_k=200:0.6562,lwr_k=500:0.66,lwr_k=1000:0.6622'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6528,lwr_k=20:0.668,lwr_k=50:0.6444,lwr_k=100:0.637,lwr_k=200:0.6413,lwr_k=500:0.6442,lwr_k=1000:0.6456'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6456,lwr_k=20:0.6086,lwr_k=50:0.6277,lwr_k=100:0.6306,lwr_k=200:0.6337,lwr_k=500:0.6381,lwr_k=1000:0.6413'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6615,lwr_k=20:0.6743,lwr_k=50:0.657,lwr_k=100:0.6585,lwr_k=200:0.6553,lwr_k=500:0.6545,lwr_k=1000:0.6571'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6926,lwr_k=20:0.6546,lwr_k=50:0.6689,lwr_k=100:0.6771,lwr_k=200:0.6809,lwr_k=500:0.6851,lwr_k=1000:0.6877'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7189,lwr_k=20:0.7471,lwr_k=50:0.7266,lwr_k=100:0.721,lwr_k=200:0.716,lwr_k=500:0.7168,lwr_k=1000:0.7173'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.704,lwr_k=20:0.6616,lwr_k=50:0.677,lwr_k=100:0.6815,lwr_k=200:0.6874,lwr_k=500:0.6939,lwr_k=1000:0.6971'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6988,lwr_k=20:0.7102,lwr_k=50:0.6928,lwr_k=100:0.6876,lwr_k=200:0.6856,lwr_k=500:0.6886,lwr_k=1000:0.6924'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6632,lwr_k=20:0.6233,lwr_k=50:0.6442,lwr_k=100:0.6471,lwr_k=200:0.6515,lwr_k=500:0.6564,lwr_k=1000:0.6588'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6799,lwr_k=20:0.7026,lwr_k=50:0.6864,lwr_k=100:0.6783,lwr_k=200:0.6717,lwr_k=500:0.6724,lwr_k=1000:0.6736'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6408,lwr_k=20:0.5963,lwr_k=50:0.612,lwr_k=100:0.6203,lwr_k=200:0.6214,lwr_k=500:0.6276,lwr_k=1000:0.6321'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7023,lwr_k=20:0.721,lwr_k=50:0.6992,lwr_k=100:0.6936,lwr_k=200:0.6913,lwr_k=500:0.6929,lwr_k=1000:0.6956'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_43'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.295,lwr_k=20:3.5828,lwr_k=50:3.8227,lwr_k=100:3.951,lwr_k=200:4.0398,lwr_k=500:4.1051,lwr_k=1000:4.1495'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.3224,lwr_k=20:4.2681,lwr_k=50:4.1933,lwr_k=100:4.2192,lwr_k=200:4.1795,lwr_k=500:4.1739,lwr_k=1000:4.1962'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.4593,lwr_k=20:3.809,lwr_k=50:4.0354,lwr_k=100:4.1448,lwr_k=200:4.2058,lwr_k=500:4.2692,lwr_k=1000:4.309'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.6876,lwr_k=20:4.696,lwr_k=50:4.6089,lwr_k=100:4.5277,lwr_k=200:4.5038,lwr_k=500:4.48,lwr_k=1000:4.4851'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5815,lwr_k=20:3.8194,lwr_k=50:4.1582,lwr_k=100:4.323,lwr_k=200:4.4411,lwr_k=500:4.5094,lwr_k=1000:4.4939'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.5931,lwr_k=20:4.4634,lwr_k=50:4.5152,lwr_k=100:4.5014,lwr_k=200:4.506,lwr_k=500:4.5304,lwr_k=1000:4.5304'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8526,lwr_k=20:3.6402,lwr_k=50:4.208,lwr_k=100:4.575,lwr_k=200:4.8629,lwr_k=500:5.1394,lwr_k=1000:5.2178'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.7593,lwr_k=20:3.9987,lwr_k=50:4.2161,lwr_k=100:4.4248,lwr_k=200:4.6539,lwr_k=500:4.9068,lwr_k=1000:4.9738'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.0551,lwr_k=20:3.4247,lwr_k=50:3.693,lwr_k=100:3.7924,lwr_k=200:3.8703,lwr_k=500:3.9488,lwr_k=1000:3.9858'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.3202,lwr_k=20:4.2942,lwr_k=50:4.26,lwr_k=100:4.2545,lwr_k=200:4.2484,lwr_k=500:4.2721,lwr_k=1000:4.2732'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:6.2206,lwr_k=20:3.6568,lwr_k=50:3.9009,lwr_k=100:3.982,lwr_k=200:4.0153,lwr_k=500:4.0552,lwr_k=1000:4.0886'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.5834,lwr_k=20:4.1064,lwr_k=50:4.1243,lwr_k=100:4.1515,lwr_k=200:4.1529,lwr_k=500:4.1557,lwr_k=1000:4.1727'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_44'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.4428,lwr_k=20:2.8026,lwr_k=50:2.9891,lwr_k=100:3.0703,lwr_k=200:3.0953,lwr_k=500:3.1609,lwr_k=1000:3.2196'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.3882,lwr_k=20:3.3476,lwr_k=50:3.3326,lwr_k=100:3.2656,lwr_k=200:3.2042,lwr_k=500:3.2024,lwr_k=1000:3.2066'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6495,lwr_k=20:3.2626,lwr_k=50:3.4726,lwr_k=100:3.5467,lwr_k=200:3.5817,lwr_k=500:3.6347,lwr_k=1000:3.6687'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.7568,lwr_k=20:3.8062,lwr_k=50:3.7722,lwr_k=100:3.7547,lwr_k=200:3.7285,lwr_k=500:3.7288,lwr_k=1000:3.7605'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.5067,lwr_k=20:2.5692,lwr_k=50:2.8005,lwr_k=100:2.9026,lwr_k=200:2.9855,lwr_k=500:3.075,lwr_k=1000:3.1386'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.607,lwr_k=20:3.2946,lwr_k=50:3.2753,lwr_k=100:3.2459,lwr_k=200:3.2689,lwr_k=500:3.246,lwr_k=1000:3.3066'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6408,lwr_k=20:2.8832,lwr_k=50:3.0774,lwr_k=100:3.1083,lwr_k=200:3.137,lwr_k=500:3.1613,lwr_k=1000:3.2061'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.4982,lwr_k=20:3.3065,lwr_k=50:3.2765,lwr_k=100:3.2416,lwr_k=200:3.1718,lwr_k=500:3.1238,lwr_k=1000:3.1625'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7391,lwr_k=20:3.4055,lwr_k=50:3.6533,lwr_k=100:3.6979,lwr_k=200:3.7166,lwr_k=500:3.7242,lwr_k=1000:3.7579'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.8784,lwr_k=20:4.1517,lwr_k=50:4.1739,lwr_k=100:4.1452,lwr_k=200:4.0662,lwr_k=500:4.0038,lwr_k=1000:3.9537'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.5734,lwr_k=20:3.3482,lwr_k=50:3.6029,lwr_k=100:3.6674,lwr_k=200:3.6643,lwr_k=500:3.6619,lwr_k=1000:3.6612'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.7635,lwr_k=20:3.8307,lwr_k=50:3.856,lwr_k=100:3.798,lwr_k=200:3.746,lwr_k=500:3.6952,lwr_k=1000:3.7337'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_45'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.545,lwr_k=20:3.7479,lwr_k=50:4.2758,lwr_k=100:4.6131,lwr_k=200:4.8819,lwr_k=500:5.208,lwr_k=1000:5.3362'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.5374,lwr_k=20:4.1377,lwr_k=50:4.4639,lwr_k=100:4.7424,lwr_k=200:4.9408,lwr_k=500:5.2315,lwr_k=1000:5.3709'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5766,lwr_k=20:3.7535,lwr_k=50:4.316,lwr_k=100:4.6493,lwr_k=200:4.9177,lwr_k=500:5.2198,lwr_k=1000:5.3361'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.6859,lwr_k=20:4.2986,lwr_k=50:4.6336,lwr_k=100:4.9182,lwr_k=200:5.1493,lwr_k=500:5.4481,lwr_k=1000:5.5592'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.566,lwr_k=20:3.7521,lwr_k=50:4.3069,lwr_k=100:4.6374,lwr_k=200:4.9151,lwr_k=500:5.2283,lwr_k=1000:5.3487'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.5713,lwr_k=20:4.1478,lwr_k=50:4.4546,lwr_k=100:4.6946,lwr_k=200:4.9122,lwr_k=500:5.202,lwr_k=1000:5.2989'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.6404,lwr_k=20:3.8087,lwr_k=50:4.3868,lwr_k=100:4.7363,lwr_k=200:5.0256,lwr_k=500:5.3551,lwr_k=1000:5.4727'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.451,lwr_k=20:4.0596,lwr_k=50:4.3482,lwr_k=100:4.573,lwr_k=200:4.7874,lwr_k=500:5.0542,lwr_k=1000:5.1801'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5739,lwr_k=20:3.7806,lwr_k=50:4.3357,lwr_k=100:4.6712,lwr_k=200:4.941,lwr_k=500:5.2695,lwr_k=1000:5.388'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.7743,lwr_k=20:4.3038,lwr_k=50:4.6721,lwr_k=100:4.9084,lwr_k=200:5.1765,lwr_k=500:5.4552,lwr_k=1000:5.5596'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.6208,lwr_k=20:3.6339,lwr_k=50:4.2385,lwr_k=100:4.6159,lwr_k=200:4.8765,lwr_k=500:5.2311,lwr_k=1000:5.3742'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.7764,lwr_k=20:4.0326,lwr_k=50:4.3017,lwr_k=100:4.5458,lwr_k=200:4.8292,lwr_k=500:5.2042,lwr_k=1000:5.3365'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_46'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7886,lwr_k=20:3.525,lwr_k=50:3.6925,lwr_k=100:3.7522,lwr_k=200:3.7754,lwr_k=500:3.8062,lwr_k=1000:3.8033'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.7455,lwr_k=20:3.9741,lwr_k=50:3.8831,lwr_k=100:3.8485,lwr_k=200:3.835,lwr_k=500:3.8159,lwr_k=1000:3.7914'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7779,lwr_k=20:3.5574,lwr_k=50:3.6933,lwr_k=100:3.7529,lwr_k=200:3.7784,lwr_k=500:3.7899,lwr_k=1000:3.8044'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.8906,lwr_k=20:3.9609,lwr_k=50:3.9265,lwr_k=100:3.9438,lwr_k=200:3.9409,lwr_k=500:3.9203,lwr_k=1000:3.9083'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8343,lwr_k=20:3.3874,lwr_k=50:3.5605,lwr_k=100:3.6275,lwr_k=200:3.6624,lwr_k=500:3.7023,lwr_k=1000:3.7218'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.8383,lwr_k=20:3.8611,lwr_k=50:3.8231,lwr_k=100:3.8066,lwr_k=200:3.8017,lwr_k=500:3.7929,lwr_k=1000:3.7895'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.0598,lwr_k=20:3.6785,lwr_k=50:3.8936,lwr_k=100:3.9614,lwr_k=200:4.0198,lwr_k=500:4.0327,lwr_k=1000:4.0496'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.8668,lwr_k=20:3.8952,lwr_k=50:3.8571,lwr_k=100:3.8213,lwr_k=200:3.8326,lwr_k=500:3.846,lwr_k=1000:3.8607'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.4651,lwr_k=20:3.9529,lwr_k=50:4.2757,lwr_k=100:4.4136,lwr_k=200:4.4366,lwr_k=500:4.4603,lwr_k=1000:4.4683'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.6946,lwr_k=20:4.7272,lwr_k=50:4.7205,lwr_k=100:4.6919,lwr_k=200:4.7054,lwr_k=500:4.7252,lwr_k=1000:4.7326'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.6683,lwr_k=20:3.5049,lwr_k=50:3.6725,lwr_k=100:3.7264,lwr_k=200:3.7348,lwr_k=500:3.7454,lwr_k=1000:3.7443'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.785,lwr_k=20:3.8709,lwr_k=50:3.8296,lwr_k=100:3.8288,lwr_k=200:3.8233,lwr_k=500:3.8021,lwr_k=1000:3.7828'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_47'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8157,lwr_k=20:3.3418,lwr_k=50:3.5248,lwr_k=100:3.6006,lwr_k=200:3.6659,lwr_k=500:3.7339,lwr_k=1000:3.7672'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.8237,lwr_k=20:3.96,lwr_k=50:3.796,lwr_k=100:3.7691,lwr_k=200:3.729,lwr_k=500:3.7459,lwr_k=1000:3.7909'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6545,lwr_k=20:3.2633,lwr_k=50:3.4196,lwr_k=100:3.4754,lwr_k=200:3.5362,lwr_k=500:3.5919,lwr_k=1000:3.6195'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.7234,lwr_k=20:3.7685,lwr_k=50:3.7186,lwr_k=100:3.6619,lwr_k=200:3.671,lwr_k=500:3.6866,lwr_k=1000:3.6796'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7637,lwr_k=20:3.3894,lwr_k=50:3.5201,lwr_k=100:3.5644,lwr_k=200:3.5873,lwr_k=500:3.627,lwr_k=1000:3.6549'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.8276,lwr_k=20:3.8583,lwr_k=50:3.7722,lwr_k=100:3.7309,lwr_k=200:3.7168,lwr_k=500:3.7281,lwr_k=1000:3.7367'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.2451,lwr_k=20:6.139,lwr_k=50:6.3221,lwr_k=100:6.2163,lwr_k=200:6.1406,lwr_k=500:6.1387,lwr_k=1000:6.1401'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.9245,lwr_k=20:5.8611,lwr_k=50:6.1076,lwr_k=100:5.9808,lwr_k=200:5.8723,lwr_k=500:5.8657,lwr_k=1000:5.8597'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.1594,lwr_k=20:3.2401,lwr_k=50:3.6481,lwr_k=100:3.8343,lwr_k=200:3.9548,lwr_k=500:4.0617,lwr_k=1000:4.1325'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.3813,lwr_k=20:4.1892,lwr_k=50:4.2288,lwr_k=100:4.3055,lwr_k=200:4.299,lwr_k=500:4.3137,lwr_k=1000:4.3861'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.1538,lwr_k=20:3.9086,lwr_k=50:4.083,lwr_k=100:4.1235,lwr_k=200:4.1383,lwr_k=500:4.1635,lwr_k=1000:4.1704'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.264,lwr_k=20:4.5372,lwr_k=50:4.3346,lwr_k=100:4.3095,lwr_k=200:4.319,lwr_k=500:4.2999,lwr_k=1000:4.28'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_48'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6697,lwr_k=20:0.4011,lwr_k=50:0.502,lwr_k=100:0.551,lwr_k=200:0.5919,lwr_k=500:0.6278,lwr_k=1000:0.6463'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6532,lwr_k=20:0.5904,lwr_k=50:0.5884,lwr_k=100:0.6001,lwr_k=200:0.6116,lwr_k=500:0.6275,lwr_k=1000:0.6352'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7801,lwr_k=20:0.132,lwr_k=50:0.2762,lwr_k=100:0.3981,lwr_k=200:0.5152,lwr_k=500:0.6371,lwr_k=1000:0.7083'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7719,lwr_k=20:0.6204,lwr_k=50:0.6016,lwr_k=100:0.6177,lwr_k=200:0.6609,lwr_k=500:0.7088,lwr_k=1000:0.7342'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7564,lwr_k=20:0.0755,lwr_k=50:0.2091,lwr_k=100:0.3504,lwr_k=200:0.4764,lwr_k=500:0.5992,lwr_k=1000:0.6667'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8508,lwr_k=20:0.6213,lwr_k=50:0.6307,lwr_k=100:0.6761,lwr_k=200:0.6877,lwr_k=500:0.7345,lwr_k=1000:0.7681'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7185,lwr_k=20:0.1974,lwr_k=50:0.3385,lwr_k=100:0.4327,lwr_k=200:0.5155,lwr_k=500:0.6074,lwr_k=1000:0.6588'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7355,lwr_k=20:0.6026,lwr_k=50:0.611,lwr_k=100:0.6145,lwr_k=200:0.6559,lwr_k=500:0.685,lwr_k=1000:0.6922'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7586,lwr_k=20:0.1042,lwr_k=50:0.2482,lwr_k=100:0.3768,lwr_k=200:0.4798,lwr_k=500:0.5939,lwr_k=1000:0.66'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7843,lwr_k=20:0.5942,lwr_k=50:0.5951,lwr_k=100:0.6303,lwr_k=200:0.6466,lwr_k=500:0.6982,lwr_k=1000:0.7201'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7212,lwr_k=20:0.0608,lwr_k=50:0.1786,lwr_k=100:0.3109,lwr_k=200:0.4423,lwr_k=500:0.5701,lwr_k=1000:0.6383'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8469,lwr_k=20:0.4336,lwr_k=50:0.5256,lwr_k=100:0.6043,lwr_k=200:0.6867,lwr_k=500:0.7183,lwr_k=1000:0.7558'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_49'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.341,lwr_k=20:3.838,lwr_k=50:4.0391,lwr_k=100:4.097,lwr_k=200:4.1317,lwr_k=500:4.1748,lwr_k=1000:4.1674'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.2082,lwr_k=20:4.1785,lwr_k=50:4.1512,lwr_k=100:4.1481,lwr_k=200:4.1351,lwr_k=500:4.1115,lwr_k=1000:4.128'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.3048,lwr_k=20:4.7819,lwr_k=50:5.0394,lwr_k=100:5.0938,lwr_k=200:5.1546,lwr_k=500:5.1864,lwr_k=1000:5.2046'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.5332,lwr_k=20:5.4676,lwr_k=50:5.4518,lwr_k=100:5.45,lwr_k=200:5.4942,lwr_k=500:5.4679,lwr_k=1000:5.4677'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.2198,lwr_k=20:4.9369,lwr_k=50:5.3226,lwr_k=100:5.4468,lwr_k=200:5.453,lwr_k=500:5.3456,lwr_k=1000:5.2624'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.1749,lwr_k=20:5.4708,lwr_k=50:5.547,lwr_k=100:5.5887,lwr_k=200:5.5218,lwr_k=500:5.3821,lwr_k=1000:5.271'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.91,lwr_k=20:3.4731,lwr_k=50:3.6265,lwr_k=100:3.6908,lwr_k=200:3.7169,lwr_k=500:3.7661,lwr_k=1000:3.804'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.7691,lwr_k=20:3.7816,lwr_k=50:3.7329,lwr_k=100:3.7285,lwr_k=200:3.707,lwr_k=500:3.6963,lwr_k=1000:3.7086'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.1861,lwr_k=20:4.8456,lwr_k=50:5.3524,lwr_k=100:5.5241,lwr_k=200:5.5079,lwr_k=500:5.3512,lwr_k=1000:5.207'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.228,lwr_k=20:5.4895,lwr_k=50:5.6773,lwr_k=100:5.7261,lwr_k=200:5.6382,lwr_k=500:5.4473,lwr_k=1000:5.282'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.6713,lwr_k=20:3.1375,lwr_k=50:3.3384,lwr_k=100:3.4114,lwr_k=200:3.4822,lwr_k=500:3.5569,lwr_k=1000:3.592'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.743,lwr_k=20:3.565,lwr_k=50:3.5928,lwr_k=100:3.6229,lwr_k=200:3.6526,lwr_k=500:3.6682,lwr_k=1000:3.6785'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_50'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8979,lwr_k=20:3.6505,lwr_k=50:3.7781,lwr_k=100:3.8065,lwr_k=200:3.8324,lwr_k=500:3.8799,lwr_k=1000:3.8868'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.8261,lwr_k=20:3.8576,lwr_k=50:3.8005,lwr_k=100:3.8075,lwr_k=200:3.7919,lwr_k=500:3.8142,lwr_k=1000:3.8084'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.0668,lwr_k=20:5.1159,lwr_k=50:5.438,lwr_k=100:5.5593,lwr_k=200:5.6048,lwr_k=500:5.6313,lwr_k=1000:5.6349'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.2928,lwr_k=20:5.8512,lwr_k=50:5.9422,lwr_k=100:5.9342,lwr_k=200:5.9327,lwr_k=500:5.8916,lwr_k=1000:5.8548'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.281,lwr_k=20:4.8472,lwr_k=50:5.1163,lwr_k=100:5.2111,lwr_k=200:5.2608,lwr_k=500:5.3,lwr_k=1000:5.3273'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.2137,lwr_k=20:5.3794,lwr_k=50:5.3273,lwr_k=100:5.302,lwr_k=200:5.2817,lwr_k=500:5.2911,lwr_k=1000:5.3234'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.159,lwr_k=20:5.3032,lwr_k=50:5.6196,lwr_k=100:5.7216,lwr_k=200:5.7758,lwr_k=500:5.7932,lwr_k=1000:5.7585'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.9911,lwr_k=20:5.6186,lwr_k=50:5.5407,lwr_k=100:5.5465,lwr_k=200:5.5435,lwr_k=500:5.5103,lwr_k=1000:5.4585'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.3133,lwr_k=20:4.8141,lwr_k=50:5.128,lwr_k=100:5.2123,lwr_k=200:5.2387,lwr_k=500:5.2465,lwr_k=1000:5.2552'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.4487,lwr_k=20:5.3797,lwr_k=50:5.4207,lwr_k=100:5.4237,lwr_k=200:5.4281,lwr_k=500:5.424,lwr_k=1000:5.429'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:5.2277,lwr_k=20:4.5334,lwr_k=50:4.8365,lwr_k=100:5.0043,lwr_k=200:5.1034,lwr_k=500:5.2312,lwr_k=1000:5.2995'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.31,lwr_k=20:4.9961,lwr_k=50:5.0434,lwr_k=100:5.1129,lwr_k=200:5.1662,lwr_k=500:5.2564,lwr_k=1000:5.2934'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_51'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.3128,lwr_k=20:4.3516,lwr_k=50:4.658,lwr_k=100:4.7232,lwr_k=200:4.6857,lwr_k=500:4.627,lwr_k=1000:4.5912'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.1728,lwr_k=20:4.9393,lwr_k=50:4.946,lwr_k=100:4.9163,lwr_k=200:4.7788,lwr_k=500:4.6435,lwr_k=1000:4.5759'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.5206,lwr_k=20:3.3752,lwr_k=50:3.5605,lwr_k=100:3.6298,lwr_k=200:3.6711,lwr_k=500:3.7006,lwr_k=1000:3.7068'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.584,lwr_k=20:3.7532,lwr_k=50:3.7796,lwr_k=100:3.7912,lwr_k=200:3.8206,lwr_k=500:3.7838,lwr_k=1000:3.7728'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.4559,lwr_k=20:3.4624,lwr_k=50:3.6533,lwr_k=100:3.7222,lwr_k=200:3.7549,lwr_k=500:3.773,lwr_k=1000:3.7823'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.5379,lwr_k=20:4.0493,lwr_k=50:3.9886,lwr_k=100:4.0066,lwr_k=200:3.9507,lwr_k=500:3.9294,lwr_k=1000:3.9007'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.5764,lwr_k=20:3.3974,lwr_k=50:3.5489,lwr_k=100:3.6245,lwr_k=200:3.6697,lwr_k=500:3.718,lwr_k=1000:3.7201'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.4594,lwr_k=20:3.656,lwr_k=50:3.6327,lwr_k=100:3.6396,lwr_k=200:3.631,lwr_k=500:3.6271,lwr_k=1000:3.6109'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6983,lwr_k=20:3.701,lwr_k=50:3.9464,lwr_k=100:4.0194,lwr_k=200:4.0687,lwr_k=500:4.1231,lwr_k=1000:4.1471'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.7249,lwr_k=20:4.3761,lwr_k=50:4.4067,lwr_k=100:4.3742,lwr_k=200:4.3359,lwr_k=500:4.3317,lwr_k=1000:4.3215'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.4998,lwr_k=20:3.1659,lwr_k=50:3.3797,lwr_k=100:3.4402,lwr_k=200:3.4836,lwr_k=500:3.507,lwr_k=1000:3.5107'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.5971,lwr_k=20:3.5734,lwr_k=50:3.6683,lwr_k=100:3.6857,lwr_k=200:3.6623,lwr_k=500:3.6339,lwr_k=1000:3.632'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_52'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.9749,lwr_k=20:1.0059,lwr_k=50:1.3199,lwr_k=100:1.4899,lwr_k=200:1.6391,lwr_k=500:1.7803,lwr_k=1000:1.8519'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.8247,lwr_k=20:1.6922,lwr_k=50:1.7122,lwr_k=100:1.7135,lwr_k=200:1.709,lwr_k=500:1.7287,lwr_k=1000:1.7387'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.0261,lwr_k=20:0.7485,lwr_k=50:1.4402,lwr_k=100:1.9201,lwr_k=200:2.3305,lwr_k=500:2.6932,lwr_k=1000:2.8318'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.9898,lwr_k=20:2.892,lwr_k=50:2.9319,lwr_k=100:2.8689,lwr_k=200:2.8818,lwr_k=500:2.9035,lwr_k=1000:2.929'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.9292,lwr_k=20:0.9586,lwr_k=50:1.1387,lwr_k=100:1.2528,lwr_k=200:1.3422,lwr_k=500:1.4933,lwr_k=1000:1.6035'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.0892,lwr_k=20:1.5988,lwr_k=50:1.6042,lwr_k=100:1.6063,lwr_k=200:1.6363,lwr_k=500:1.7013,lwr_k=1000:1.7877'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.1627,lwr_k=20:0.6793,lwr_k=50:1.3692,lwr_k=100:1.9236,lwr_k=200:2.3503,lwr_k=500:2.7634,lwr_k=1000:2.9611'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.1833,lwr_k=20:2.8176,lwr_k=50:2.8546,lwr_k=100:2.7669,lwr_k=200:2.9171,lwr_k=500:2.9676,lwr_k=1000:3.0589'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.0327,lwr_k=20:1.4653,lwr_k=50:1.9427,lwr_k=100:2.2307,lwr_k=200:2.4349,lwr_k=500:2.6442,lwr_k=1000:2.7714'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.1953,lwr_k=20:2.7374,lwr_k=50:2.8012,lwr_k=100:2.8923,lwr_k=200:2.9124,lwr_k=500:2.9304,lwr_k=1000:3.0004'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:2.7897,lwr_k=20:1.7241,lwr_k=50:1.9727,lwr_k=100:2.1184,lwr_k=200:2.2626,lwr_k=500:2.4141,lwr_k=1000:2.5133'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.9029,lwr_k=20:2.4624,lwr_k=50:2.4849,lwr_k=100:2.5068,lwr_k=200:2.5424,lwr_k=500:2.5901,lwr_k=1000:2.6669'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_53'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9357,lwr_k=20:0.8001,lwr_k=50:0.843,lwr_k=100:0.8569,lwr_k=200:0.8681,lwr_k=500:0.8882,lwr_k=1000:0.9049'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.89,lwr_k=20:0.8613,lwr_k=50:0.8455,lwr_k=100:0.8446,lwr_k=200:0.8456,lwr_k=500:0.8529,lwr_k=1000:0.8622'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8829,lwr_k=20:0.7945,lwr_k=50:0.8274,lwr_k=100:0.8415,lwr_k=200:0.8503,lwr_k=500:0.8652,lwr_k=1000:0.873'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8673,lwr_k=20:0.8669,lwr_k=50:0.855,lwr_k=100:0.8513,lwr_k=200:0.8528,lwr_k=500:0.8568,lwr_k=1000:0.8571'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.5987,lwr_k=20:1.3392,lwr_k=50:1.4063,lwr_k=100:1.441,lwr_k=200:1.4711,lwr_k=500:1.5068,lwr_k=1000:1.5433'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.7042,lwr_k=20:1.6524,lwr_k=50:1.6397,lwr_k=100:1.6406,lwr_k=200:1.6575,lwr_k=500:1.6533,lwr_k=1000:1.669'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3894,lwr_k=20:1.2206,lwr_k=50:1.2723,lwr_k=100:1.2918,lwr_k=200:1.3041,lwr_k=500:1.3265,lwr_k=1000:1.3427'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.3539,lwr_k=20:1.3133,lwr_k=50:1.3095,lwr_k=100:1.3116,lwr_k=200:1.3041,lwr_k=500:1.3146,lwr_k=1000:1.3218'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0377,lwr_k=20:0.8865,lwr_k=50:0.938,lwr_k=100:0.9566,lwr_k=200:0.969,lwr_k=500:0.9796,lwr_k=1000:0.9915'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.058,lwr_k=20:0.9888,lwr_k=50:0.9954,lwr_k=100:1.0028,lwr_k=200:1.0002,lwr_k=500:1.0028,lwr_k=1000:1.01'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.9081,lwr_k=20:0.7928,lwr_k=50:0.8366,lwr_k=100:0.8477,lwr_k=200:0.8564,lwr_k=500:0.8708,lwr_k=1000:0.8823'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.0112,lwr_k=20:0.993,lwr_k=50:0.9945,lwr_k=100:0.988,lwr_k=200:0.9831,lwr_k=500:0.983,lwr_k=1000:0.9916'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_54'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8399,lwr_k=20:0.3948,lwr_k=50:0.5705,lwr_k=100:0.6639,lwr_k=200:0.729,lwr_k=500:0.7783,lwr_k=1000:0.806'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7999,lwr_k=20:0.7442,lwr_k=50:0.725,lwr_k=100:0.7334,lwr_k=200:0.7438,lwr_k=500:0.7508,lwr_k=1000:0.7678'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1002,lwr_k=20:0.1591,lwr_k=50:0.4886,lwr_k=100:0.7147,lwr_k=200:0.8556,lwr_k=500:0.9899,lwr_k=1000:1.0468'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.0943,lwr_k=20:1.0664,lwr_k=50:1.0231,lwr_k=100:1.0264,lwr_k=200:0.9833,lwr_k=500:1.0359,lwr_k=1000:1.0467'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2389,lwr_k=20:0.1572,lwr_k=50:0.557,lwr_k=100:0.7989,lwr_k=200:0.9562,lwr_k=500:1.0938,lwr_k=1000:1.1644'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.3407,lwr_k=20:1.3052,lwr_k=50:1.1582,lwr_k=100:1.1743,lwr_k=200:1.2326,lwr_k=500:1.2628,lwr_k=1000:1.2916'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7674,lwr_k=20:0.2499,lwr_k=50:0.4268,lwr_k=100:0.5375,lwr_k=200:0.6121,lwr_k=500:0.684,lwr_k=1000:0.7166'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7501,lwr_k=20:0.6215,lwr_k=50:0.6253,lwr_k=100:0.6562,lwr_k=200:0.6848,lwr_k=500:0.6993,lwr_k=1000:0.7176'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.122,lwr_k=20:0.1735,lwr_k=50:0.4978,lwr_k=100:0.6949,lwr_k=200:0.8473,lwr_k=500:0.9749,lwr_k=1000:1.0253'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1758,lwr_k=20:1.0775,lwr_k=50:1.0292,lwr_k=100:1.0093,lwr_k=200:1.0525,lwr_k=500:1.0969,lwr_k=1000:1.1204'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:1.1184,lwr_k=20:0.1061,lwr_k=50:0.4632,lwr_k=100:0.6927,lwr_k=200:0.8546,lwr_k=500:0.9928,lwr_k=1000:1.0426'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.3583,lwr_k=20:0.9082,lwr_k=50:1.0611,lwr_k=100:1.0924,lwr_k=200:1.1715,lwr_k=500:1.2482,lwr_k=1000:1.2886'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_55'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6825,lwr_k=20:0.57,lwr_k=50:0.6131,lwr_k=100:0.6402,lwr_k=200:0.6563,lwr_k=500:0.666,lwr_k=1000:0.6735'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6665,lwr_k=20:0.6629,lwr_k=50:0.6552,lwr_k=100:0.6566,lwr_k=200:0.6595,lwr_k=500:0.6606,lwr_k=1000:0.6575'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6838,lwr_k=20:0.6081,lwr_k=50:0.6422,lwr_k=100:0.6577,lwr_k=200:0.6702,lwr_k=500:0.6771,lwr_k=1000:0.6809'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6864,lwr_k=20:0.6887,lwr_k=50:0.6837,lwr_k=100:0.6789,lwr_k=200:0.674,lwr_k=500:0.6802,lwr_k=1000:0.6827'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6754,lwr_k=20:0.5752,lwr_k=50:0.6154,lwr_k=100:0.6393,lwr_k=200:0.6538,lwr_k=500:0.6621,lwr_k=1000:0.6693'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7232,lwr_k=20:0.7262,lwr_k=50:0.7154,lwr_k=100:0.7063,lwr_k=200:0.7122,lwr_k=500:0.7152,lwr_k=1000:0.7186'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2903,lwr_k=20:1.0659,lwr_k=50:1.1074,lwr_k=100:1.1545,lwr_k=200:1.1979,lwr_k=500:1.2391,lwr_k=1000:1.2565'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2999,lwr_k=20:1.2209,lwr_k=50:1.1915,lwr_k=100:1.2179,lwr_k=200:1.2441,lwr_k=500:1.2679,lwr_k=1000:1.2745'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9888,lwr_k=20:0.9181,lwr_k=50:0.9491,lwr_k=100:0.9609,lwr_k=200:0.9679,lwr_k=500:0.9719,lwr_k=1000:0.9752'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0084,lwr_k=20:1.0774,lwr_k=50:1.0595,lwr_k=100:1.0477,lwr_k=200:1.0291,lwr_k=500:1.0123,lwr_k=1000:1.0096'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6142,lwr_k=20:0.5561,lwr_k=50:0.5815,lwr_k=100:0.5935,lwr_k=200:0.6006,lwr_k=500:0.6085,lwr_k=1000:0.6135'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6867,lwr_k=20:0.7039,lwr_k=50:0.6966,lwr_k=100:0.6946,lwr_k=200:0.6873,lwr_k=500:0.6858,lwr_k=1000:0.6886'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_56'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7554,lwr_k=20:0.5221,lwr_k=50:0.6128,lwr_k=100:0.6561,lwr_k=200:0.6836,lwr_k=500:0.7108,lwr_k=1000:0.7264'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7284,lwr_k=20:0.676,lwr_k=50:0.6786,lwr_k=100:0.6758,lwr_k=200:0.68,lwr_k=500:0.6952,lwr_k=1000:0.7068'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.756,lwr_k=20:0.5853,lwr_k=50:0.6425,lwr_k=100:0.6747,lwr_k=200:0.6945,lwr_k=500:0.7102,lwr_k=1000:0.7242'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.76,lwr_k=20:0.7347,lwr_k=50:0.7231,lwr_k=100:0.7311,lwr_k=200:0.7267,lwr_k=500:0.7297,lwr_k=1000:0.735'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8057,lwr_k=20:0.6421,lwr_k=50:0.6842,lwr_k=100:0.7115,lwr_k=200:0.7279,lwr_k=500:0.7476,lwr_k=1000:0.7613'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8449,lwr_k=20:0.8236,lwr_k=50:0.7845,lwr_k=100:0.7848,lwr_k=200:0.7869,lwr_k=500:0.7994,lwr_k=1000:0.8116'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7367,lwr_k=20:0.5417,lwr_k=50:0.6277,lwr_k=100:0.6575,lwr_k=200:0.681,lwr_k=500:0.7071,lwr_k=1000:0.719'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7264,lwr_k=20:0.7073,lwr_k=50:0.7126,lwr_k=100:0.7,lwr_k=200:0.703,lwr_k=500:0.7115,lwr_k=1000:0.714'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.835,lwr_k=20:0.7064,lwr_k=50:0.7536,lwr_k=100:0.7732,lwr_k=200:0.7892,lwr_k=500:0.8111,lwr_k=1000:0.8197'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8446,lwr_k=20:0.8399,lwr_k=50:0.8278,lwr_k=100:0.82,lwr_k=200:0.8238,lwr_k=500:0.831,lwr_k=1000:0.8346'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6776,lwr_k=20:0.52,lwr_k=50:0.5778,lwr_k=100:0.6019,lwr_k=200:0.6238,lwr_k=500:0.6447,lwr_k=1000:0.6574'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7588,lwr_k=20:0.7491,lwr_k=50:0.7296,lwr_k=100:0.7295,lwr_k=200:0.731,lwr_k=500:0.7414,lwr_k=1000:0.7487'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_57'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7342,lwr_k=20:0.4323,lwr_k=50:0.5471,lwr_k=100:0.6005,lwr_k=200:0.6459,lwr_k=500:0.6885,lwr_k=1000:0.7095'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7026,lwr_k=20:0.6761,lwr_k=50:0.6524,lwr_k=100:0.6604,lwr_k=200:0.6677,lwr_k=500:0.6829,lwr_k=1000:0.6845'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7582,lwr_k=20:0.4906,lwr_k=50:0.5799,lwr_k=100:0.6339,lwr_k=200:0.6658,lwr_k=500:0.6994,lwr_k=1000:0.7201'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7298,lwr_k=20:0.6831,lwr_k=50:0.6718,lwr_k=100:0.6791,lwr_k=200:0.6758,lwr_k=500:0.6974,lwr_k=1000:0.7106'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7721,lwr_k=20:0.5554,lwr_k=50:0.6407,lwr_k=100:0.6841,lwr_k=200:0.7188,lwr_k=500:0.7421,lwr_k=1000:0.7557'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8166,lwr_k=20:0.7934,lwr_k=50:0.7662,lwr_k=100:0.7713,lwr_k=200:0.7761,lwr_k=500:0.795,lwr_k=1000:0.8023'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8182,lwr_k=20:0.591,lwr_k=50:0.6692,lwr_k=100:0.7173,lwr_k=200:0.746,lwr_k=500:0.7769,lwr_k=1000:0.7905'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8145,lwr_k=20:0.7446,lwr_k=50:0.7612,lwr_k=100:0.7592,lwr_k=200:0.7641,lwr_k=500:0.7816,lwr_k=1000:0.7913'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7697,lwr_k=20:0.5154,lwr_k=50:0.615,lwr_k=100:0.664,lwr_k=200:0.6943,lwr_k=500:0.7296,lwr_k=1000:0.7424'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7972,lwr_k=20:0.7549,lwr_k=50:0.7608,lwr_k=100:0.7578,lwr_k=200:0.7735,lwr_k=500:0.7732,lwr_k=1000:0.7792'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6814,lwr_k=20:0.4662,lwr_k=50:0.5559,lwr_k=100:0.6018,lwr_k=200:0.6339,lwr_k=500:0.6567,lwr_k=1000:0.6661'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7854,lwr_k=20:0.7166,lwr_k=50:0.7385,lwr_k=100:0.7593,lwr_k=200:0.7712,lwr_k=500:0.776,lwr_k=1000:0.7841'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_58'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.306,lwr_k=20:3.6533,lwr_k=50:3.8726,lwr_k=100:3.949,lwr_k=200:4.0363,lwr_k=500:4.1606,lwr_k=1000:4.2587'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.2173,lwr_k=20:4.1924,lwr_k=50:4.1471,lwr_k=100:4.1068,lwr_k=200:4.1097,lwr_k=500:4.1527,lwr_k=1000:4.2153'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.2307,lwr_k=20:3.4094,lwr_k=50:3.7099,lwr_k=100:3.8494,lwr_k=200:3.9674,lwr_k=500:4.1087,lwr_k=1000:4.1703'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.332,lwr_k=20:4.1469,lwr_k=50:4.1819,lwr_k=100:4.1941,lwr_k=200:4.2254,lwr_k=500:4.2839,lwr_k=1000:4.3402'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.6367,lwr_k=20:4.0109,lwr_k=50:4.3383,lwr_k=100:4.4375,lwr_k=200:4.513,lwr_k=500:4.569,lwr_k=1000:4.6326'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.7464,lwr_k=20:4.7531,lwr_k=50:4.6287,lwr_k=100:4.626,lwr_k=200:4.6309,lwr_k=500:4.657,lwr_k=1000:4.7023'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.1112,lwr_k=20:4.8362,lwr_k=50:5.1442,lwr_k=100:5.2304,lwr_k=200:5.3001,lwr_k=500:5.3245,lwr_k=1000:5.3503'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.929,lwr_k=20:5.1949,lwr_k=50:5.1304,lwr_k=100:5.1443,lwr_k=200:5.1611,lwr_k=500:5.1447,lwr_k=1000:5.1282'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.0746,lwr_k=20:3.7176,lwr_k=50:4.1362,lwr_k=100:4.3252,lwr_k=200:4.5054,lwr_k=500:4.6537,lwr_k=1000:4.7413'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.2973,lwr_k=20:4.8175,lwr_k=50:4.6256,lwr_k=100:4.6648,lwr_k=200:4.6978,lwr_k=500:4.8059,lwr_k=1000:4.9207'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:5.0359,lwr_k=20:3.7358,lwr_k=50:4.2239,lwr_k=100:4.4973,lwr_k=200:4.6343,lwr_k=500:4.725,lwr_k=1000:4.9151'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.1082,lwr_k=20:5.025,lwr_k=50:4.9586,lwr_k=100:4.9403,lwr_k=200:4.8941,lwr_k=500:4.8849,lwr_k=1000:4.8799'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_59'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.0949,lwr_k=20:0.9034,lwr_k=50:1.7834,lwr_k=100:2.1998,lwr_k=200:2.5299,lwr_k=500:2.8101,lwr_k=1000:2.943'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.0457,lwr_k=20:2.9157,lwr_k=50:2.6404,lwr_k=100:2.69,lwr_k=200:2.7813,lwr_k=500:2.8648,lwr_k=1000:2.937'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.1112,lwr_k=20:0.9948,lwr_k=50:1.8305,lwr_k=100:2.2713,lwr_k=200:2.5584,lwr_k=500:2.8125,lwr_k=1000:2.95'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.1754,lwr_k=20:3.3022,lwr_k=50:2.9618,lwr_k=100:2.9377,lwr_k=200:2.9109,lwr_k=500:3.027,lwr_k=1000:3.0823'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.1397,lwr_k=20:1.0948,lwr_k=50:1.8432,lwr_k=100:2.229,lwr_k=200:2.5165,lwr_k=500:2.7751,lwr_k=1000:2.9407'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.208,lwr_k=20:2.9053,lwr_k=50:2.7334,lwr_k=100:2.8725,lwr_k=200:2.8937,lwr_k=500:2.987,lwr_k=1000:3.0918'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.474,lwr_k=20:1.3354,lwr_k=50:2.0906,lwr_k=100:2.4669,lwr_k=200:2.6817,lwr_k=500:2.935,lwr_k=1000:3.0813'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.4312,lwr_k=20:3.3497,lwr_k=50:3.0393,lwr_k=100:2.9946,lwr_k=200:2.9879,lwr_k=500:3.0632,lwr_k=1000:3.1392'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.2635,lwr_k=20:1.2136,lwr_k=50:1.9492,lwr_k=100:2.3005,lwr_k=200:2.5939,lwr_k=500:2.893,lwr_k=1000:3.0531'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.3135,lwr_k=20:2.9614,lwr_k=50:2.9193,lwr_k=100:2.9205,lwr_k=200:2.9588,lwr_k=500:3.1152,lwr_k=1000:3.1949'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.1299,lwr_k=20:1.0066,lwr_k=50:1.7839,lwr_k=100:2.2054,lwr_k=200:2.504,lwr_k=500:2.7851,lwr_k=1000:2.9416'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.2174,lwr_k=20:2.6204,lwr_k=50:2.6382,lwr_k=100:2.7114,lwr_k=200:2.8452,lwr_k=500:2.9738,lwr_k=1000:3.0695'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_60'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8911,lwr_k=20:3.4811,lwr_k=50:3.6921,lwr_k=100:3.7755,lwr_k=200:3.8178,lwr_k=500:3.8481,lwr_k=1000:3.864'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.8373,lwr_k=20:3.8856,lwr_k=50:3.8307,lwr_k=100:3.8499,lwr_k=200:3.8389,lwr_k=500:3.8229,lwr_k=1000:3.8196'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.2856,lwr_k=20:3.8428,lwr_k=50:4.1142,lwr_k=100:4.183,lwr_k=200:4.209,lwr_k=500:4.2139,lwr_k=1000:4.2223'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.3337,lwr_k=20:4.3482,lwr_k=50:4.3212,lwr_k=100:4.3273,lwr_k=200:4.3252,lwr_k=500:4.2858,lwr_k=1000:4.2941'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.0902,lwr_k=20:3.6805,lwr_k=50:3.8907,lwr_k=100:3.9633,lwr_k=200:4.0049,lwr_k=500:4.0399,lwr_k=1000:4.0551'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.1585,lwr_k=20:4.2395,lwr_k=50:4.1976,lwr_k=100:4.1897,lwr_k=200:4.1662,lwr_k=500:4.1745,lwr_k=1000:4.1677'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5036,lwr_k=20:4.065,lwr_k=50:4.3735,lwr_k=100:4.4484,lwr_k=200:4.4791,lwr_k=500:4.5543,lwr_k=1000:4.6045'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.3516,lwr_k=20:4.3216,lwr_k=50:4.3445,lwr_k=100:4.314,lwr_k=200:4.2806,lwr_k=500:4.3444,lwr_k=1000:4.4186'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8961,lwr_k=20:3.568,lwr_k=50:3.7344,lwr_k=100:3.7974,lwr_k=200:3.8155,lwr_k=500:3.8528,lwr_k=1000:3.8717'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.9809,lwr_k=20:4.0644,lwr_k=50:3.9932,lwr_k=100:3.9608,lwr_k=200:3.9711,lwr_k=500:3.9644,lwr_k=1000:3.9675'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.7053,lwr_k=20:4.1964,lwr_k=50:4.4865,lwr_k=100:4.5648,lwr_k=200:4.6034,lwr_k=500:4.6451,lwr_k=1000:4.6915'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.7436,lwr_k=20:4.5806,lwr_k=50:4.6776,lwr_k=100:4.6458,lwr_k=200:4.6494,lwr_k=500:4.655,lwr_k=1000:4.732'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_61'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0254,lwr_k=20:0.6848,lwr_k=50:0.7636,lwr_k=100:0.7936,lwr_k=200:0.8137,lwr_k=500:0.8497,lwr_k=1000:0.8929'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.0302,lwr_k=20:0.8403,lwr_k=50:0.825,lwr_k=100:0.8162,lwr_k=200:0.8102,lwr_k=500:0.8266,lwr_k=1000:0.8696'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9054,lwr_k=20:0.7339,lwr_k=50:0.7969,lwr_k=100:0.8279,lwr_k=200:0.8425,lwr_k=500:0.8577,lwr_k=1000:0.8699'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9277,lwr_k=20:0.8918,lwr_k=50:0.8844,lwr_k=100:0.8721,lwr_k=200:0.8686,lwr_k=500:0.8784,lwr_k=1000:0.8871'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.828,lwr_k=20:0.5684,lwr_k=50:0.6506,lwr_k=100:0.6894,lwr_k=200:0.7203,lwr_k=500:0.7533,lwr_k=1000:0.7734'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8428,lwr_k=20:0.7491,lwr_k=50:0.7511,lwr_k=100:0.7641,lwr_k=200:0.7724,lwr_k=500:0.7814,lwr_k=1000:0.7964'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.874,lwr_k=20:0.603,lwr_k=50:0.6759,lwr_k=100:0.7185,lwr_k=200:0.7522,lwr_k=500:0.789,lwr_k=1000:0.816'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8775,lwr_k=20:0.7769,lwr_k=50:0.7701,lwr_k=100:0.772,lwr_k=200:0.771,lwr_k=500:0.7886,lwr_k=1000:0.812'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8413,lwr_k=20:0.586,lwr_k=50:0.6594,lwr_k=100:0.6878,lwr_k=200:0.714,lwr_k=500:0.7495,lwr_k=1000:0.7722'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8434,lwr_k=20:0.8044,lwr_k=50:0.7679,lwr_k=100:0.7559,lwr_k=200:0.7594,lwr_k=500:0.7742,lwr_k=1000:0.7944'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.748,lwr_k=20:0.5381,lwr_k=50:0.6034,lwr_k=100:0.6362,lwr_k=200:0.6645,lwr_k=500:0.6884,lwr_k=1000:0.6974'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7983,lwr_k=20:0.7375,lwr_k=50:0.7433,lwr_k=100:0.7536,lwr_k=200:0.7593,lwr_k=500:0.7636,lwr_k=1000:0.7701'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_62'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5246,lwr_k=20:3.8158,lwr_k=50:4.2816,lwr_k=100:4.5077,lwr_k=200:4.6361,lwr_k=500:4.6667,lwr_k=1000:4.6402'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.432,lwr_k=20:4.4061,lwr_k=50:4.5171,lwr_k=100:4.6052,lwr_k=200:4.6988,lwr_k=500:4.6642,lwr_k=1000:4.5935'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9679,lwr_k=20:3.4087,lwr_k=50:3.6265,lwr_k=100:3.7201,lwr_k=200:3.8148,lwr_k=500:3.8452,lwr_k=1000:3.8758'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.0482,lwr_k=20:3.9802,lwr_k=50:3.9645,lwr_k=100:3.9427,lwr_k=200:3.9171,lwr_k=500:3.902,lwr_k=1000:3.9088'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.7548,lwr_k=20:3.5627,lwr_k=50:4.0139,lwr_k=100:4.1789,lwr_k=200:4.3878,lwr_k=500:4.5792,lwr_k=1000:4.6421'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.9471,lwr_k=20:4.667,lwr_k=50:4.6212,lwr_k=100:4.5817,lwr_k=200:4.619,lwr_k=500:4.6678,lwr_k=1000:4.6697'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.0745,lwr_k=20:3.568,lwr_k=50:3.7756,lwr_k=100:3.8825,lwr_k=200:4.0165,lwr_k=500:4.0751,lwr_k=1000:4.099'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.9589,lwr_k=20:3.9705,lwr_k=50:3.9106,lwr_k=100:3.8971,lwr_k=200:3.9506,lwr_k=500:3.9623,lwr_k=1000:3.9308'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.9858,lwr_k=20:3.6042,lwr_k=50:4.1133,lwr_k=100:4.3119,lwr_k=200:4.4285,lwr_k=500:4.6446,lwr_k=1000:4.8516'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.1364,lwr_k=20:4.7985,lwr_k=50:4.7847,lwr_k=100:4.7573,lwr_k=200:4.7238,lwr_k=500:4.7768,lwr_k=1000:4.9289'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.9767,lwr_k=20:3.0638,lwr_k=50:3.3619,lwr_k=100:3.5251,lwr_k=200:3.5922,lwr_k=500:3.6329,lwr_k=1000:3.6884'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.0884,lwr_k=20:3.704,lwr_k=50:3.8225,lwr_k=100:3.8653,lwr_k=200:3.893,lwr_k=500:3.862,lwr_k=1000:3.8674'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_63'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.95,lwr_k=20:3.5362,lwr_k=50:3.7068,lwr_k=100:3.7765,lwr_k=200:3.8121,lwr_k=500:3.8338,lwr_k=1000:3.8499'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.0043,lwr_k=20:3.9236,lwr_k=50:3.9263,lwr_k=100:3.8962,lwr_k=200:3.8894,lwr_k=500:3.8825,lwr_k=1000:3.871'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5493,lwr_k=20:4.0106,lwr_k=50:4.2739,lwr_k=100:4.3668,lwr_k=200:4.3967,lwr_k=500:4.4237,lwr_k=1000:4.4513'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.7272,lwr_k=20:4.5616,lwr_k=50:4.6201,lwr_k=100:4.6483,lwr_k=200:4.6369,lwr_k=500:4.6166,lwr_k=1000:4.6198'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0284,lwr_k=20:6.0468,lwr_k=50:6.191,lwr_k=100:6.1085,lwr_k=200:6.0326,lwr_k=500:6.03,lwr_k=1000:6.0284'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.9286,lwr_k=20:5.9193,lwr_k=50:6.1735,lwr_k=100:6.0665,lwr_k=200:5.946,lwr_k=500:5.9385,lwr_k=1000:5.9268'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9394,lwr_k=20:3.6524,lwr_k=50:3.8249,lwr_k=100:3.8568,lwr_k=200:3.8777,lwr_k=500:3.8894,lwr_k=1000:3.8945'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.6965,lwr_k=20:3.7634,lwr_k=50:3.6903,lwr_k=100:3.6868,lwr_k=200:3.6803,lwr_k=500:3.6705,lwr_k=1000:3.6713'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.3984,lwr_k=20:4.0262,lwr_k=50:4.1828,lwr_k=100:4.2513,lwr_k=200:4.2835,lwr_k=500:4.3189,lwr_k=1000:4.3359'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.6185,lwr_k=20:4.7079,lwr_k=50:4.6351,lwr_k=100:4.6173,lwr_k=200:4.5949,lwr_k=500:4.5597,lwr_k=1000:4.5589'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:6.0857,lwr_k=20:6.8304,lwr_k=50:6.5014,lwr_k=100:6.2754,lwr_k=200:6.1001,lwr_k=500:6.0893,lwr_k=1000:6.0857'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0856,lwr_k=20:6.8685,lwr_k=50:6.5298,lwr_k=100:6.2946,lwr_k=200:6.1054,lwr_k=500:6.0919,lwr_k=1000:6.0854'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_64'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7512,lwr_k=20:0.6717,lwr_k=50:0.6963,lwr_k=100:0.7087,lwr_k=200:0.7215,lwr_k=500:0.7357,lwr_k=1000:0.7443'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7401,lwr_k=20:0.7549,lwr_k=50:0.732,lwr_k=100:0.7284,lwr_k=200:0.7245,lwr_k=500:0.7288,lwr_k=1000:0.7307'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8109,lwr_k=20:0.7629,lwr_k=50:0.786,lwr_k=100:0.7987,lwr_k=200:0.8051,lwr_k=500:0.8081,lwr_k=1000:0.8086'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8203,lwr_k=20:0.8554,lwr_k=50:0.8366,lwr_k=100:0.827,lwr_k=200:0.8223,lwr_k=500:0.8205,lwr_k=1000:0.819'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8511,lwr_k=20:0.7365,lwr_k=50:0.775,lwr_k=100:0.7838,lwr_k=200:0.7953,lwr_k=500:0.811,lwr_k=1000:0.8234'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8705,lwr_k=20:0.8702,lwr_k=50:0.8555,lwr_k=100:0.84,lwr_k=200:0.8397,lwr_k=500:0.8398,lwr_k=1000:0.8498'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.872,lwr_k=20:0.7941,lwr_k=50:0.8242,lwr_k=100:0.8356,lwr_k=200:0.8442,lwr_k=500:0.8531,lwr_k=1000:0.8592'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8655,lwr_k=20:0.8703,lwr_k=50:0.8562,lwr_k=100:0.8448,lwr_k=200:0.8439,lwr_k=500:0.8499,lwr_k=1000:0.8549'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8219,lwr_k=20:0.7691,lwr_k=50:0.7862,lwr_k=100:0.7911,lwr_k=200:0.7956,lwr_k=500:0.8071,lwr_k=1000:0.8139'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8722,lwr_k=20:0.8931,lwr_k=50:0.888,lwr_k=100:0.8738,lwr_k=200:0.8709,lwr_k=500:0.8675,lwr_k=1000:0.8678'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6938,lwr_k=20:0.6315,lwr_k=50:0.6568,lwr_k=100:0.664,lwr_k=200:0.6679,lwr_k=500:0.6738,lwr_k=1000:0.6812'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8176,lwr_k=20:0.8274,lwr_k=50:0.8162,lwr_k=100:0.8096,lwr_k=200:0.8057,lwr_k=500:0.8051,lwr_k=1000:0.8089'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_65'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.7868,lwr_k=20:0.1849,lwr_k=50:0.4153,lwr_k=100:0.6356,lwr_k=200:0.878,lwr_k=500:1.1818,lwr_k=1000:1.404'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.7142,lwr_k=20:1.0867,lwr_k=50:1.0185,lwr_k=100:1.0756,lwr_k=200:1.1267,lwr_k=500:1.2347,lwr_k=1000:1.3967'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.178,lwr_k=20:0.1454,lwr_k=50:0.4084,lwr_k=100:0.7473,lwr_k=200:1.1208,lwr_k=500:1.5506,lwr_k=1000:1.7982'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.178,lwr_k=20:1.4102,lwr_k=50:1.3116,lwr_k=100:1.4504,lwr_k=200:1.5312,lwr_k=500:1.7335,lwr_k=1000:1.9056'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.7351,lwr_k=20:0.4523,lwr_k=50:0.7317,lwr_k=100:0.8999,lwr_k=200:1.0501,lwr_k=500:1.2529,lwr_k=1000:1.412'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.8152,lwr_k=20:1.2584,lwr_k=50:1.3289,lwr_k=100:1.2968,lwr_k=200:1.376,lwr_k=500:1.4908,lwr_k=1000:1.595'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.5226,lwr_k=20:0.3276,lwr_k=50:0.706,lwr_k=100:1.0587,lwr_k=200:1.4488,lwr_k=500:1.8915,lwr_k=1000:2.1598'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.493,lwr_k=20:1.8136,lwr_k=50:1.7279,lwr_k=100:1.913,lwr_k=200:2.0515,lwr_k=500:2.1659,lwr_k=1000:2.2725'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3469,lwr_k=20:0.3087,lwr_k=50:0.5068,lwr_k=100:0.6388,lwr_k=200:0.7674,lwr_k=500:0.9358,lwr_k=1000:1.0458'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.3936,lwr_k=20:0.9196,lwr_k=50:0.8943,lwr_k=100:0.9437,lwr_k=200:0.9849,lwr_k=500:1.0957,lwr_k=1000:1.1594'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:1.5744,lwr_k=20:0.5586,lwr_k=50:0.7531,lwr_k=100:0.8627,lwr_k=200:0.9614,lwr_k=500:1.0828,lwr_k=1000:1.1972'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.6981,lwr_k=20:1.1104,lwr_k=50:1.1637,lwr_k=100:1.1567,lwr_k=200:1.225,lwr_k=500:1.2952,lwr_k=1000:1.3867'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_66'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8514,lwr_k=20:0.3308,lwr_k=50:0.5575,lwr_k=100:0.6692,lwr_k=200:0.7424,lwr_k=500:0.7965,lwr_k=1000:0.8257'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7729,lwr_k=20:0.7376,lwr_k=50:0.6893,lwr_k=100:0.6959,lwr_k=200:0.71,lwr_k=500:0.7437,lwr_k=1000:0.7523'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8208,lwr_k=20:0.3095,lwr_k=50:0.5335,lwr_k=100:0.6389,lwr_k=200:0.6949,lwr_k=500:0.7447,lwr_k=1000:0.7735'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8488,lwr_k=20:0.7732,lwr_k=50:0.7335,lwr_k=100:0.746,lwr_k=200:0.7628,lwr_k=500:0.7823,lwr_k=1000:0.8075'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8825,lwr_k=20:0.3209,lwr_k=50:0.577,lwr_k=100:0.6829,lwr_k=200:0.7628,lwr_k=500:0.8263,lwr_k=1000:0.8465'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9485,lwr_k=20:0.7561,lwr_k=50:0.7751,lwr_k=100:0.8064,lwr_k=200:0.8643,lwr_k=500:0.9157,lwr_k=1000:0.9324'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1112,lwr_k=20:0.4179,lwr_k=50:0.7166,lwr_k=100:0.8705,lwr_k=200:0.9641,lwr_k=500:1.0379,lwr_k=1000:1.0685'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0735,lwr_k=20:0.9219,lwr_k=50:0.9666,lwr_k=100:1.0034,lwr_k=200:1.0141,lwr_k=500:1.0357,lwr_k=1000:1.0485'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.888,lwr_k=20:0.3162,lwr_k=50:0.5419,lwr_k=100:0.6654,lwr_k=200:0.74,lwr_k=500:0.8107,lwr_k=1000:0.8439'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8999,lwr_k=20:0.7568,lwr_k=50:0.7449,lwr_k=100:0.7918,lwr_k=200:0.816,lwr_k=500:0.8426,lwr_k=1000:0.8634'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6467,lwr_k=20:0.2355,lwr_k=50:0.4178,lwr_k=100:0.5082,lwr_k=200:0.5611,lwr_k=500:0.6033,lwr_k=1000:0.6228'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7984,lwr_k=20:0.5756,lwr_k=50:0.6514,lwr_k=100:0.704,lwr_k=200:0.7322,lwr_k=500:0.7665,lwr_k=1000:0.779'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_67'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.6125,lwr_k=20:5.1964,lwr_k=50:5.38,lwr_k=100:5.4517,lwr_k=200:5.5097,lwr_k=500:5.5449,lwr_k=1000:5.554'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.6979,lwr_k=20:5.8546,lwr_k=50:5.6967,lwr_k=100:5.6497,lwr_k=200:5.6446,lwr_k=500:5.6435,lwr_k=1000:5.635'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.4256,lwr_k=20:5.1087,lwr_k=50:5.2742,lwr_k=100:5.3355,lwr_k=200:5.3805,lwr_k=500:5.4129,lwr_k=1000:5.4174'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.6372,lwr_k=20:5.8311,lwr_k=50:5.656,lwr_k=100:5.6094,lwr_k=200:5.6163,lwr_k=500:5.638,lwr_k=1000:5.643'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0284,lwr_k=20:6.0468,lwr_k=50:6.191,lwr_k=100:6.1085,lwr_k=200:6.0326,lwr_k=500:6.03,lwr_k=1000:6.0284'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.9286,lwr_k=20:5.9193,lwr_k=50:6.1735,lwr_k=100:6.0665,lwr_k=200:5.946,lwr_k=500:5.9385,lwr_k=1000:5.9268'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9706,lwr_k=20:5.9751,lwr_k=50:6.1589,lwr_k=100:6.0239,lwr_k=200:5.9639,lwr_k=500:5.9685,lwr_k=1000:5.9714'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.6729,lwr_k=20:5.7259,lwr_k=50:5.9636,lwr_k=100:5.7775,lwr_k=200:5.6871,lwr_k=500:5.6691,lwr_k=1000:5.67'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0621,lwr_k=20:6.0621,lwr_k=50:6.0622,lwr_k=100:6.0666,lwr_k=200:6.1173,lwr_k=500:6.0709,lwr_k=1000:6.0621'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:6.1622,lwr_k=20:6.1627,lwr_k=50:6.1629,lwr_k=100:6.1578,lwr_k=200:6.1863,lwr_k=500:6.1833,lwr_k=1000:6.1627'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:6.0857,lwr_k=20:6.8304,lwr_k=50:6.5014,lwr_k=100:6.2754,lwr_k=200:6.1001,lwr_k=500:6.0893,lwr_k=1000:6.0857'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0856,lwr_k=20:6.8685,lwr_k=50:6.5298,lwr_k=100:6.2946,lwr_k=200:6.1054,lwr_k=500:6.0919,lwr_k=1000:6.0854'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_68'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8968,lwr_k=20:0.8011,lwr_k=50:0.8456,lwr_k=100:0.8686,lwr_k=200:0.8941,lwr_k=500:0.925,lwr_k=1000:0.9428'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.847,lwr_k=20:0.8921,lwr_k=50:0.8705,lwr_k=100:0.8729,lwr_k=200:0.8764,lwr_k=500:0.8872,lwr_k=1000:0.8991'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6708,lwr_k=20:0.5472,lwr_k=50:0.5908,lwr_k=100:0.6134,lwr_k=200:0.633,lwr_k=500:0.6507,lwr_k=1000:0.6626'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6973,lwr_k=20:0.6637,lwr_k=50:0.6747,lwr_k=100:0.6798,lwr_k=200:0.6749,lwr_k=500:0.687,lwr_k=1000:0.6918'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6753,lwr_k=20:0.571,lwr_k=50:0.6173,lwr_k=100:0.639,lwr_k=200:0.6615,lwr_k=500:0.6779,lwr_k=1000:0.6885'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.712,lwr_k=20:0.739,lwr_k=50:0.718,lwr_k=100:0.7151,lwr_k=200:0.7183,lwr_k=500:0.7337,lwr_k=1000:0.7441'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.799,lwr_k=20:0.6087,lwr_k=50:0.6993,lwr_k=100:0.7358,lwr_k=200:0.755,lwr_k=500:0.781,lwr_k=1000:0.7934'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.781,lwr_k=20:0.7655,lwr_k=50:0.773,lwr_k=100:0.7804,lwr_k=200:0.7833,lwr_k=500:0.7863,lwr_k=1000:0.7836'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7487,lwr_k=20:0.7154,lwr_k=50:0.7653,lwr_k=100:0.7837,lwr_k=200:0.7992,lwr_k=500:0.8088,lwr_k=1000:0.8059'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7705,lwr_k=20:0.8773,lwr_k=50:0.8579,lwr_k=100:0.8446,lwr_k=200:0.8435,lwr_k=500:0.834,lwr_k=1000:0.82'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6965,lwr_k=20:0.5502,lwr_k=50:0.6008,lwr_k=100:0.6257,lwr_k=200:0.6452,lwr_k=500:0.6723,lwr_k=1000:0.6851'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7771,lwr_k=20:0.7419,lwr_k=50:0.7515,lwr_k=100:0.7473,lwr_k=200:0.7505,lwr_k=500:0.7592,lwr_k=1000:0.7666'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_69'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.873,lwr_k=20:0.7848,lwr_k=50:0.8189,lwr_k=100:0.8271,lwr_k=200:0.8339,lwr_k=500:0.8393,lwr_k=1000:0.8476'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8673,lwr_k=20:0.8636,lwr_k=50:0.8341,lwr_k=100:0.8307,lwr_k=200:0.8292,lwr_k=500:0.8343,lwr_k=1000:0.8426'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9552,lwr_k=20:0.8753,lwr_k=50:0.8956,lwr_k=100:0.908,lwr_k=200:0.9113,lwr_k=500:0.9119,lwr_k=1000:0.9172'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.952,lwr_k=20:0.9248,lwr_k=50:0.8992,lwr_k=100:0.8909,lwr_k=200:0.8913,lwr_k=500:0.8961,lwr_k=1000:0.9044'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8251,lwr_k=20:0.7678,lwr_k=50:0.7941,lwr_k=100:0.8049,lwr_k=200:0.8124,lwr_k=500:0.8161,lwr_k=1000:0.8163'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8629,lwr_k=20:0.8821,lwr_k=50:0.8662,lwr_k=100:0.8599,lwr_k=200:0.8654,lwr_k=500:0.86,lwr_k=1000:0.8603'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9431,lwr_k=20:0.8415,lwr_k=50:0.8858,lwr_k=100:0.8961,lwr_k=200:0.904,lwr_k=500:0.9154,lwr_k=1000:0.9266'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.952,lwr_k=20:0.9442,lwr_k=50:0.929,lwr_k=100:0.9211,lwr_k=200:0.9267,lwr_k=500:0.9294,lwr_k=1000:0.9375'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9414,lwr_k=20:0.8868,lwr_k=50:0.8965,lwr_k=100:0.9076,lwr_k=200:0.9141,lwr_k=500:0.9154,lwr_k=1000:0.92'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.9163,lwr_k=20:0.939,lwr_k=50:0.9101,lwr_k=100:0.9013,lwr_k=200:0.9011,lwr_k=500:0.8985,lwr_k=1000:0.8999'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.8631,lwr_k=20:0.7951,lwr_k=50:0.8142,lwr_k=100:0.8173,lwr_k=200:0.818,lwr_k=500:0.823,lwr_k=1000:0.8274'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9184,lwr_k=20:0.9238,lwr_k=50:0.8971,lwr_k=100:0.8903,lwr_k=200:0.886,lwr_k=500:0.888,lwr_k=1000:0.8905'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_70'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.996,lwr_k=20:1.8378,lwr_k=50:1.9161,lwr_k=100:1.9372,lwr_k=200:1.9483,lwr_k=500:1.9572,lwr_k=1000:1.9622'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.9356,lwr_k=20:1.9959,lwr_k=50:1.952,lwr_k=100:1.9212,lwr_k=200:1.9196,lwr_k=500:1.9264,lwr_k=1000:1.9189'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6728,lwr_k=20:3.1209,lwr_k=50:3.2242,lwr_k=100:3.2585,lwr_k=200:3.2891,lwr_k=500:3.2967,lwr_k=1000:3.3078'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.6113,lwr_k=20:3.3673,lwr_k=50:3.3279,lwr_k=100:3.2835,lwr_k=200:3.2692,lwr_k=500:3.2582,lwr_k=1000:3.265'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0245,lwr_k=20:0.9669,lwr_k=50:1.0021,lwr_k=100:1.0071,lwr_k=200:1.0129,lwr_k=500:1.0192,lwr_k=1000:1.022'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.101,lwr_k=20:1.135,lwr_k=50:1.1039,lwr_k=100:1.103,lwr_k=200:1.1006,lwr_k=500:1.1004,lwr_k=1000:1.0996'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4427,lwr_k=20:1.3539,lwr_k=50:1.4026,lwr_k=100:1.4215,lwr_k=200:1.4308,lwr_k=500:1.4354,lwr_k=1000:1.4382'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.4341,lwr_k=20:1.5242,lwr_k=50:1.4668,lwr_k=100:1.437,lwr_k=200:1.4314,lwr_k=500:1.4258,lwr_k=1000:1.4278'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.0275,lwr_k=20:1.8709,lwr_k=50:1.9465,lwr_k=100:1.9773,lwr_k=200:1.9905,lwr_k=500:2.0037,lwr_k=1000:2.0052'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.1148,lwr_k=20:2.1963,lwr_k=50:2.1574,lwr_k=100:2.1352,lwr_k=200:2.103,lwr_k=500:2.0958,lwr_k=1000:2.095'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:1.2298,lwr_k=20:1.1582,lwr_k=50:1.1929,lwr_k=100:1.2044,lwr_k=200:1.2141,lwr_k=500:1.219,lwr_k=1000:1.2244'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.2954,lwr_k=20:1.3467,lwr_k=50:1.313,lwr_k=100:1.3048,lwr_k=200:1.2992,lwr_k=500:1.2941,lwr_k=1000:1.2931'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_71'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6345,lwr_k=20:3.5692,lwr_k=50:3.9884,lwr_k=100:4.1811,lwr_k=200:4.2835,lwr_k=500:4.2436,lwr_k=1000:4.1909'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.6319,lwr_k=20:4.0034,lwr_k=50:4.2226,lwr_k=100:4.3258,lwr_k=200:4.325,lwr_k=500:4.2356,lwr_k=1000:4.1362'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6772,lwr_k=20:3.6222,lwr_k=50:4.0805,lwr_k=100:4.2853,lwr_k=200:4.3383,lwr_k=500:4.2896,lwr_k=1000:4.2282'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.755,lwr_k=20:3.9831,lwr_k=50:4.2773,lwr_k=100:4.457,lwr_k=200:4.5176,lwr_k=500:4.4304,lwr_k=1000:4.3574'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6381,lwr_k=20:3.6116,lwr_k=50:4.0679,lwr_k=100:4.2615,lwr_k=200:4.3037,lwr_k=500:4.2408,lwr_k=1000:4.1828'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.7646,lwr_k=20:3.9601,lwr_k=50:4.1914,lwr_k=100:4.3601,lwr_k=200:4.3705,lwr_k=500:4.2924,lwr_k=1000:4.2442'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7134,lwr_k=20:3.6135,lwr_k=50:4.0638,lwr_k=100:4.2788,lwr_k=200:4.3501,lwr_k=500:4.2967,lwr_k=1000:4.2361'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.5273,lwr_k=20:3.9852,lwr_k=50:4.146,lwr_k=100:4.2451,lwr_k=200:4.2469,lwr_k=500:4.1757,lwr_k=1000:4.1172'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6668,lwr_k=20:3.583,lwr_k=50:4.0139,lwr_k=100:4.2188,lwr_k=200:4.303,lwr_k=500:4.2472,lwr_k=1000:4.1908'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.8887,lwr_k=20:4.1589,lwr_k=50:4.4574,lwr_k=100:4.5562,lwr_k=200:4.5469,lwr_k=500:4.4685,lwr_k=1000:4.3768'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.7162,lwr_k=20:3.4937,lwr_k=50:3.9556,lwr_k=100:4.1888,lwr_k=200:4.2874,lwr_k=500:4.2557,lwr_k=1000:4.1785'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.7128,lwr_k=20:3.7812,lwr_k=50:4.0843,lwr_k=100:4.2459,lwr_k=200:4.3023,lwr_k=500:4.2681,lwr_k=1000:4.207'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_72'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.778,lwr_k=20:0.7491,lwr_k=50:0.7563,lwr_k=100:0.7571,lwr_k=200:0.7594,lwr_k=500:0.7634,lwr_k=1000:0.7688'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7833,lwr_k=20:0.7978,lwr_k=50:0.7668,lwr_k=100:0.7604,lwr_k=200:0.7586,lwr_k=500:0.7607,lwr_k=1000:0.7711'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5328,lwr_k=20:4.0792,lwr_k=50:4.2414,lwr_k=100:4.3026,lwr_k=200:4.3561,lwr_k=500:4.4418,lwr_k=1000:4.4951'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.6181,lwr_k=20:4.7002,lwr_k=50:4.5736,lwr_k=100:4.5157,lwr_k=200:4.5061,lwr_k=500:4.5239,lwr_k=1000:4.5605'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7767,lwr_k=20:0.734,lwr_k=50:0.75,lwr_k=100:0.7554,lwr_k=200:0.7591,lwr_k=500:0.7603,lwr_k=1000:0.7677'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7951,lwr_k=20:0.813,lwr_k=50:0.7902,lwr_k=100:0.781,lwr_k=200:0.7773,lwr_k=500:0.7791,lwr_k=1000:0.7867'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.727,lwr_k=20:0.6835,lwr_k=50:0.6968,lwr_k=100:0.7025,lwr_k=200:0.7055,lwr_k=500:0.7066,lwr_k=1000:0.71'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.69,lwr_k=20:0.6873,lwr_k=50:0.6819,lwr_k=100:0.6757,lwr_k=200:0.675,lwr_k=500:0.6761,lwr_k=1000:0.6781'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7528,lwr_k=20:0.7099,lwr_k=50:0.72,lwr_k=100:0.7293,lwr_k=200:0.7299,lwr_k=500:0.7355,lwr_k=1000:0.7408'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7358,lwr_k=20:0.7568,lwr_k=50:0.7339,lwr_k=100:0.7356,lwr_k=200:0.7316,lwr_k=500:0.7298,lwr_k=1000:0.7305'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.7039,lwr_k=20:3.5669,lwr_k=50:3.5506,lwr_k=100:3.5997,lwr_k=200:3.619,lwr_k=500:3.6367,lwr_k=1000:3.6472'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.689,lwr_k=20:3.872,lwr_k=50:3.7283,lwr_k=100:3.6942,lwr_k=200:3.7106,lwr_k=500:3.6981,lwr_k=1000:3.6936'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_73'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9936,lwr_k=20:5.995,lwr_k=50:5.994,lwr_k=100:6.0111,lwr_k=200:6.0357,lwr_k=500:5.9961,lwr_k=1000:5.9955'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0673,lwr_k=20:6.0678,lwr_k=50:6.0672,lwr_k=100:6.0815,lwr_k=200:6.1044,lwr_k=500:6.0686,lwr_k=1000:6.0681'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9804,lwr_k=20:6.0234,lwr_k=50:6.1347,lwr_k=100:6.0663,lwr_k=200:5.9876,lwr_k=500:5.9849,lwr_k=1000:5.9808'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.2011,lwr_k=20:6.2838,lwr_k=50:6.2803,lwr_k=100:6.2309,lwr_k=200:6.1921,lwr_k=500:6.1928,lwr_k=1000:6.1978'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.5053,lwr_k=20:2.8842,lwr_k=50:3.0381,lwr_k=100:3.0609,lwr_k=200:3.0663,lwr_k=500:3.0915,lwr_k=1000:3.1584'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.6804,lwr_k=20:3.4267,lwr_k=50:3.3827,lwr_k=100:3.3389,lwr_k=200:3.2741,lwr_k=500:3.2574,lwr_k=1000:3.328'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.1385,lwr_k=20:6.139,lwr_k=50:6.3221,lwr_k=100:6.2163,lwr_k=200:6.1406,lwr_k=500:6.1387,lwr_k=1000:6.1401'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.8637,lwr_k=20:5.8611,lwr_k=50:6.1076,lwr_k=100:5.9808,lwr_k=200:5.8723,lwr_k=500:5.8657,lwr_k=1000:5.8597'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0621,lwr_k=20:6.0621,lwr_k=50:6.0622,lwr_k=100:6.0666,lwr_k=200:6.1173,lwr_k=500:6.0709,lwr_k=1000:6.0621'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:6.1622,lwr_k=20:6.1627,lwr_k=50:6.1629,lwr_k=100:6.1578,lwr_k=200:6.1863,lwr_k=500:6.1833,lwr_k=1000:6.1627'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:6.0857,lwr_k=20:6.8304,lwr_k=50:6.5014,lwr_k=100:6.2754,lwr_k=200:6.1001,lwr_k=500:6.0893,lwr_k=1000:6.0857'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0856,lwr_k=20:6.8685,lwr_k=50:6.5298,lwr_k=100:6.2946,lwr_k=200:6.1054,lwr_k=500:6.0919,lwr_k=1000:6.0854'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_74'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.8151,lwr_k=20:0.3734,lwr_k=50:0.7229,lwr_k=100:0.9847,lwr_k=200:1.1859,lwr_k=500:1.4174,lwr_k=1000:1.5629'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.6816,lwr_k=20:1.2221,lwr_k=50:1.2275,lwr_k=100:1.2492,lwr_k=200:1.2898,lwr_k=500:1.3895,lwr_k=1000:1.4578'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.7388,lwr_k=20:0.2072,lwr_k=50:0.7263,lwr_k=100:1.2427,lwr_k=200:1.7023,lwr_k=500:2.1714,lwr_k=1000:2.4449'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.8019,lwr_k=20:2.4722,lwr_k=50:2.2011,lwr_k=100:2.0603,lwr_k=200:2.2054,lwr_k=500:2.426,lwr_k=1000:2.5824'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.0168,lwr_k=20:0.231,lwr_k=50:0.6019,lwr_k=100:0.8899,lwr_k=200:1.154,lwr_k=500:1.4706,lwr_k=1000:1.6419'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.1146,lwr_k=20:1.4578,lwr_k=50:1.3803,lwr_k=100:1.4847,lwr_k=200:1.5702,lwr_k=500:1.7443,lwr_k=1000:1.8483'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4945,lwr_k=20:0.3216,lwr_k=50:0.582,lwr_k=100:0.7864,lwr_k=200:0.9622,lwr_k=500:1.1391,lwr_k=1000:1.2521'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.5449,lwr_k=20:1.0179,lwr_k=50:1.0967,lwr_k=100:1.1372,lwr_k=200:1.2172,lwr_k=500:1.3066,lwr_k=1000:1.3756'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.0604,lwr_k=20:0.2516,lwr_k=50:0.6366,lwr_k=100:0.9677,lwr_k=200:1.2451,lwr_k=500:1.5374,lwr_k=1000:1.7274'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.1702,lwr_k=20:1.791,lwr_k=50:1.5804,lwr_k=100:1.5588,lwr_k=200:1.6337,lwr_k=500:1.7684,lwr_k=1000:1.9165'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:1.8699,lwr_k=20:0.1024,lwr_k=50:0.3998,lwr_k=100:0.7533,lwr_k=200:1.0622,lwr_k=500:1.381,lwr_k=1000:1.5705'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.9933,lwr_k=20:1.1417,lwr_k=50:1.2418,lwr_k=100:1.2967,lwr_k=200:1.4566,lwr_k=500:1.6301,lwr_k=1000:1.7418'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_75'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.2375,lwr_k=20:4.674,lwr_k=50:5.0076,lwr_k=100:5.089,lwr_k=200:5.0426,lwr_k=500:4.9071,lwr_k=1000:4.7772'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.1292,lwr_k=20:5.2057,lwr_k=50:5.2712,lwr_k=100:5.2123,lwr_k=200:5.1194,lwr_k=500:4.941,lwr_k=1000:4.766'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7151,lwr_k=20:3.3652,lwr_k=50:3.5481,lwr_k=100:3.6327,lwr_k=200:3.6901,lwr_k=500:3.7485,lwr_k=1000:3.7827'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.829,lwr_k=20:3.8885,lwr_k=50:3.8464,lwr_k=100:3.8242,lwr_k=200:3.8294,lwr_k=500:3.8487,lwr_k=1000:3.8495'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9396,lwr_k=20:4.6484,lwr_k=50:4.9754,lwr_k=100:4.9853,lwr_k=200:4.9075,lwr_k=500:4.7869,lwr_k=1000:4.6933'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.1532,lwr_k=20:5.1048,lwr_k=50:5.2262,lwr_k=100:5.1574,lwr_k=200:5.0209,lwr_k=500:4.8913,lwr_k=1000:4.804'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7272,lwr_k=20:3.2263,lwr_k=50:3.4018,lwr_k=100:3.4854,lwr_k=200:3.5485,lwr_k=500:3.6032,lwr_k=1000:3.6536'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.5502,lwr_k=20:3.4944,lwr_k=50:3.4956,lwr_k=100:3.4928,lwr_k=200:3.4808,lwr_k=500:3.49,lwr_k=1000:3.5052'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7061,lwr_k=20:3.3692,lwr_k=50:3.5767,lwr_k=100:3.6301,lwr_k=200:3.6235,lwr_k=500:3.6463,lwr_k=1000:3.6753'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.7727,lwr_k=20:3.9328,lwr_k=50:3.9734,lwr_k=100:3.9532,lwr_k=200:3.8946,lwr_k=500:3.8642,lwr_k=1000:3.8628'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.8069,lwr_k=20:3.4165,lwr_k=50:3.6023,lwr_k=100:3.7042,lwr_k=200:3.7732,lwr_k=500:3.8127,lwr_k=1000:3.8363'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.8857,lwr_k=20:3.8981,lwr_k=50:3.9392,lwr_k=100:3.9819,lwr_k=200:3.9767,lwr_k=500:3.978,lwr_k=1000:3.9563'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_76'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.684,lwr_k=20:3.2699,lwr_k=50:3.4484,lwr_k=100:3.5028,lwr_k=200:3.5334,lwr_k=500:3.5672,lwr_k=1000:3.5882'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.6267,lwr_k=20:3.6936,lwr_k=50:3.6529,lwr_k=100:3.6423,lwr_k=200:3.6186,lwr_k=500:3.591,lwr_k=1000:3.5808'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.1207,lwr_k=20:3.5571,lwr_k=50:3.7749,lwr_k=100:3.8409,lwr_k=200:3.893,lwr_k=500:3.9394,lwr_k=1000:3.9752'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.3432,lwr_k=20:4.1143,lwr_k=50:4.1103,lwr_k=100:4.1456,lwr_k=200:4.1646,lwr_k=500:4.1785,lwr_k=1000:4.171'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6086,lwr_k=20:3.1672,lwr_k=50:3.3383,lwr_k=100:3.3699,lwr_k=200:3.4037,lwr_k=500:3.4454,lwr_k=1000:3.4919'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.6782,lwr_k=20:3.6234,lwr_k=50:3.5692,lwr_k=100:3.5594,lwr_k=200:3.5461,lwr_k=500:3.5578,lwr_k=1000:3.6035'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8872,lwr_k=20:3.3348,lwr_k=50:3.5052,lwr_k=100:3.5867,lwr_k=200:3.6536,lwr_k=500:3.6998,lwr_k=1000:3.7015'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.7174,lwr_k=20:3.7062,lwr_k=50:3.6724,lwr_k=100:3.6628,lwr_k=200:3.6269,lwr_k=500:3.6338,lwr_k=1000:3.6022'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8595,lwr_k=20:3.1627,lwr_k=50:3.3292,lwr_k=100:3.3829,lwr_k=200:3.4346,lwr_k=500:3.4935,lwr_k=1000:3.5388'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.9727,lwr_k=20:3.6879,lwr_k=50:3.6936,lwr_k=100:3.7074,lwr_k=200:3.6926,lwr_k=500:3.6854,lwr_k=1000:3.7008'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.7592,lwr_k=20:3.234,lwr_k=50:3.4321,lwr_k=100:3.4997,lwr_k=200:3.5507,lwr_k=500:3.5941,lwr_k=1000:3.6007'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.8023,lwr_k=20:3.6687,lwr_k=50:3.6877,lwr_k=100:3.7182,lwr_k=200:3.7422,lwr_k=500:3.7171,lwr_k=1000:3.6935'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_77'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6787,lwr_k=20:0.605,lwr_k=50:0.6353,lwr_k=100:0.6465,lwr_k=200:0.6568,lwr_k=500:0.6689,lwr_k=1000:0.6728'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6574,lwr_k=20:0.6767,lwr_k=50:0.6621,lwr_k=100:0.6605,lwr_k=200:0.6537,lwr_k=500:0.6549,lwr_k=1000:0.6534'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6793,lwr_k=20:0.5957,lwr_k=50:0.6353,lwr_k=100:0.6513,lwr_k=200:0.6624,lwr_k=500:0.6694,lwr_k=1000:0.6746'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7077,lwr_k=20:0.7272,lwr_k=50:0.702,lwr_k=100:0.7006,lwr_k=200:0.6978,lwr_k=500:0.6967,lwr_k=1000:0.7004'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6638,lwr_k=20:0.6035,lwr_k=50:0.6312,lwr_k=100:0.6478,lwr_k=200:0.6575,lwr_k=500:0.6635,lwr_k=1000:0.6667'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6969,lwr_k=20:0.7054,lwr_k=50:0.6973,lwr_k=100:0.6965,lwr_k=200:0.6924,lwr_k=500:0.6973,lwr_k=1000:0.702'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6852,lwr_k=20:0.5709,lwr_k=50:0.6145,lwr_k=100:0.635,lwr_k=200:0.651,lwr_k=500:0.6676,lwr_k=1000:0.6794'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6924,lwr_k=20:0.6676,lwr_k=50:0.6689,lwr_k=100:0.6652,lwr_k=200:0.668,lwr_k=500:0.677,lwr_k=1000:0.6797'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6632,lwr_k=20:0.5963,lwr_k=50:0.6246,lwr_k=100:0.6378,lwr_k=200:0.6509,lwr_k=500:0.6595,lwr_k=1000:0.6631'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6563,lwr_k=20:0.6875,lwr_k=50:0.6653,lwr_k=100:0.6616,lwr_k=200:0.6582,lwr_k=500:0.6536,lwr_k=1000:0.6578'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6138,lwr_k=20:0.5538,lwr_k=50:0.5754,lwr_k=100:0.5864,lwr_k=200:0.5931,lwr_k=500:0.6011,lwr_k=1000:0.6063'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6831,lwr_k=20:0.7025,lwr_k=50:0.6829,lwr_k=100:0.6737,lwr_k=200:0.6713,lwr_k=500:0.679,lwr_k=1000:0.6766'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_78'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7937,lwr_k=20:0.476,lwr_k=50:0.5763,lwr_k=100:0.6256,lwr_k=200:0.6666,lwr_k=500:0.7163,lwr_k=1000:0.7495'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7356,lwr_k=20:0.6576,lwr_k=50:0.6552,lwr_k=100:0.6604,lwr_k=200:0.6597,lwr_k=500:0.6852,lwr_k=1000:0.6973'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.9783,lwr_k=20:0.2449,lwr_k=50:0.4928,lwr_k=100:0.641,lwr_k=200:0.7498,lwr_k=500:0.8494,lwr_k=1000:0.8973'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.9846,lwr_k=20:0.7806,lwr_k=50:0.7491,lwr_k=100:0.795,lwr_k=200:0.8287,lwr_k=500:0.8712,lwr_k=1000:0.9237'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7537,lwr_k=20:0.411,lwr_k=50:0.533,lwr_k=100:0.5983,lwr_k=200:0.6371,lwr_k=500:0.6811,lwr_k=1000:0.7017'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7947,lwr_k=20:0.6832,lwr_k=50:0.7028,lwr_k=100:0.7077,lwr_k=200:0.723,lwr_k=500:0.7439,lwr_k=1000:0.7636'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8082,lwr_k=20:0.4097,lwr_k=50:0.5374,lwr_k=100:0.622,lwr_k=200:0.6778,lwr_k=500:0.7368,lwr_k=1000:0.7684'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8008,lwr_k=20:0.6747,lwr_k=50:0.6832,lwr_k=100:0.7009,lwr_k=200:0.7271,lwr_k=500:0.7489,lwr_k=1000:0.7692'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0956,lwr_k=20:0.2171,lwr_k=50:0.4863,lwr_k=100:0.6594,lwr_k=200:0.7921,lwr_k=500:0.9161,lwr_k=1000:0.9815'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1366,lwr_k=20:0.8285,lwr_k=50:0.862,lwr_k=100:0.913,lwr_k=200:0.9557,lwr_k=500:0.9931,lwr_k=1000:1.0448'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.7167,lwr_k=20:0.1835,lwr_k=50:0.3715,lwr_k=100:0.4961,lwr_k=200:0.5834,lwr_k=500:0.6514,lwr_k=1000:0.6854'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.8779,lwr_k=20:0.5597,lwr_k=50:0.6682,lwr_k=100:0.7226,lwr_k=200:0.7836,lwr_k=500:0.8201,lwr_k=1000:0.852'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_79'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.1167,lwr_k=20:0.4323,lwr_k=50:0.8136,lwr_k=100:1.1113,lwr_k=200:1.3615,lwr_k=500:1.6422,lwr_k=1000:1.7978'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.0406,lwr_k=20:1.3824,lwr_k=50:1.4099,lwr_k=100:1.4636,lwr_k=200:1.5092,lwr_k=500:1.6145,lwr_k=1000:1.709'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.954,lwr_k=20:0.3957,lwr_k=50:0.7611,lwr_k=100:1.0669,lwr_k=200:1.3237,lwr_k=500:1.5796,lwr_k=1000:1.7236'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.8763,lwr_k=20:1.3657,lwr_k=50:1.4459,lwr_k=100:1.4769,lwr_k=200:1.558,lwr_k=500:1.6524,lwr_k=1000:1.7413'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.0622,lwr_k=20:0.4109,lwr_k=50:0.8032,lwr_k=100:1.1078,lwr_k=200:1.368,lwr_k=500:1.6311,lwr_k=1000:1.7788'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.1908,lwr_k=20:1.5769,lwr_k=50:1.5694,lwr_k=100:1.6423,lwr_k=200:1.764,lwr_k=500:1.9109,lwr_k=1000:2.03'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.002,lwr_k=20:1.3643,lwr_k=50:1.7849,lwr_k=100:2.0534,lwr_k=200:2.2636,lwr_k=500:2.4846,lwr_k=1000:2.6316'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.994,lwr_k=20:2.3102,lwr_k=50:2.432,lwr_k=100:2.4624,lwr_k=200:2.5223,lwr_k=500:2.6142,lwr_k=1000:2.7087'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.4058,lwr_k=20:2.0345,lwr_k=50:2.1471,lwr_k=100:2.2137,lwr_k=200:2.2611,lwr_k=500:2.295,lwr_k=1000:2.3181'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.4649,lwr_k=20:2.5266,lwr_k=50:2.4662,lwr_k=100:2.4441,lwr_k=200:2.4385,lwr_k=500:2.4256,lwr_k=1000:2.4151'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:1.7448,lwr_k=20:0.1968,lwr_k=50:0.5572,lwr_k=100:0.8883,lwr_k=200:1.1665,lwr_k=500:1.4243,lwr_k=1000:1.5464'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.8986,lwr_k=20:1.0405,lwr_k=50:1.1703,lwr_k=100:1.3739,lwr_k=200:1.5277,lwr_k=500:1.6925,lwr_k=1000:1.7709'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_80'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.8208,lwr_k=20:0.048,lwr_k=50:0.2273,lwr_k=100:0.5477,lwr_k=200:0.8871,lwr_k=500:1.259,lwr_k=1000:1.4721'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.7972,lwr_k=20:1.2799,lwr_k=50:1.1864,lwr_k=100:1.2629,lwr_k=200:1.2785,lwr_k=500:1.3915,lwr_k=1000:1.5196'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.8099,lwr_k=20:0.1562,lwr_k=50:0.4254,lwr_k=100:0.6721,lwr_k=200:0.9193,lwr_k=500:1.242,lwr_k=1000:1.4381'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.7985,lwr_k=20:1.3655,lwr_k=50:1.2285,lwr_k=100:1.2544,lwr_k=200:1.2826,lwr_k=500:1.4323,lwr_k=1000:1.5052'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.8117,lwr_k=20:0.0974,lwr_k=50:0.3474,lwr_k=100:0.6488,lwr_k=200:0.9356,lwr_k=500:1.2552,lwr_k=1000:1.4514'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.9403,lwr_k=20:1.4142,lwr_k=50:1.3005,lwr_k=100:1.3346,lwr_k=200:1.4389,lwr_k=500:1.5513,lwr_k=1000:1.6854'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.8417,lwr_k=20:0.05,lwr_k=50:0.2315,lwr_k=100:0.539,lwr_k=200:0.8746,lwr_k=500:1.2173,lwr_k=1000:1.4487'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.857,lwr_k=20:1.3555,lwr_k=50:1.2905,lwr_k=100:1.205,lwr_k=200:1.2903,lwr_k=500:1.3983,lwr_k=1000:1.577'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.7844,lwr_k=20:0.0401,lwr_k=50:0.2081,lwr_k=100:0.5269,lwr_k=200:0.8545,lwr_k=500:1.1984,lwr_k=1000:1.3752'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.8465,lwr_k=20:1.4152,lwr_k=50:1.4052,lwr_k=100:1.3067,lwr_k=200:1.3125,lwr_k=500:1.4177,lwr_k=1000:1.5479'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:1.5536,lwr_k=20:0.0323,lwr_k=50:0.1636,lwr_k=100:0.4128,lwr_k=200:0.7327,lwr_k=500:1.0411,lwr_k=1000:1.1954'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.7764,lwr_k=20:0.8868,lwr_k=50:0.8398,lwr_k=100:1.0342,lwr_k=200:1.1329,lwr_k=500:1.3243,lwr_k=1000:1.4492'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_81'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9623,lwr_k=20:3.8175,lwr_k=50:3.9435,lwr_k=100:3.921,lwr_k=200:3.9364,lwr_k=500:3.9465,lwr_k=1000:3.95'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.9497,lwr_k=20:4.1027,lwr_k=50:4.0389,lwr_k=100:3.9847,lwr_k=200:3.9642,lwr_k=500:3.9656,lwr_k=1000:3.958'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5672,lwr_k=20:4.1672,lwr_k=50:4.3127,lwr_k=100:4.3867,lwr_k=200:4.4499,lwr_k=500:4.4789,lwr_k=1000:4.5015'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.7072,lwr_k=20:4.596,lwr_k=50:4.5709,lwr_k=100:4.554,lwr_k=200:4.5764,lwr_k=500:4.5798,lwr_k=1000:4.5922'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.6516,lwr_k=20:4.3835,lwr_k=50:4.4289,lwr_k=100:4.5034,lwr_k=200:4.5465,lwr_k=500:4.5649,lwr_k=1000:4.5869'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.7656,lwr_k=20:4.9393,lwr_k=50:4.7673,lwr_k=100:4.7467,lwr_k=200:4.6994,lwr_k=500:4.7132,lwr_k=1000:4.7077'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5345,lwr_k=20:4.2987,lwr_k=50:4.4285,lwr_k=100:4.456,lwr_k=200:4.478,lwr_k=500:4.4941,lwr_k=1000:4.5041'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.3212,lwr_k=20:4.438,lwr_k=50:4.3492,lwr_k=100:4.2937,lwr_k=200:4.2853,lwr_k=500:4.3002,lwr_k=1000:4.2941'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7852,lwr_k=20:3.472,lwr_k=50:3.5883,lwr_k=100:3.6439,lwr_k=200:3.6793,lwr_k=500:3.6976,lwr_k=1000:3.7107'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.858,lwr_k=20:3.9398,lwr_k=50:3.8281,lwr_k=100:3.7966,lwr_k=200:3.7948,lwr_k=500:3.7743,lwr_k=1000:3.7839'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.0295,lwr_k=20:3.7316,lwr_k=50:3.8298,lwr_k=100:3.8718,lwr_k=200:3.8949,lwr_k=500:3.9002,lwr_k=1000:3.903'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.9471,lwr_k=20:3.933,lwr_k=50:3.8814,lwr_k=100:3.8656,lwr_k=200:3.8602,lwr_k=500:3.8451,lwr_k=1000:3.8434'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_82'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7143,lwr_k=20:0.5091,lwr_k=50:0.5829,lwr_k=100:0.6209,lwr_k=200:0.6446,lwr_k=500:0.6738,lwr_k=1000:0.6935'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7129,lwr_k=20:0.6673,lwr_k=50:0.6776,lwr_k=100:0.6768,lwr_k=200:0.6791,lwr_k=500:0.6857,lwr_k=1000:0.6965'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7037,lwr_k=20:0.5191,lwr_k=50:0.5913,lwr_k=100:0.6282,lwr_k=200:0.6564,lwr_k=500:0.683,lwr_k=1000:0.6942'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7247,lwr_k=20:0.6781,lwr_k=50:0.6805,lwr_k=100:0.6836,lwr_k=200:0.6906,lwr_k=500:0.703,lwr_k=1000:0.7121'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6326,lwr_k=20:0.4954,lwr_k=50:0.5489,lwr_k=100:0.5763,lwr_k=200:0.5977,lwr_k=500:0.6133,lwr_k=1000:0.6241'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6656,lwr_k=20:0.6369,lwr_k=50:0.6333,lwr_k=100:0.6345,lwr_k=200:0.643,lwr_k=500:0.6565,lwr_k=1000:0.6588'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.0635,lwr_k=20:0.8561,lwr_k=50:0.951,lwr_k=100:0.9872,lwr_k=200:1.0253,lwr_k=500:1.0538,lwr_k=1000:1.075'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.06,lwr_k=20:1.0793,lwr_k=50:1.0481,lwr_k=100:1.0532,lwr_k=200:1.0724,lwr_k=500:1.08,lwr_k=1000:1.0973'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6391,lwr_k=20:0.4842,lwr_k=50:0.5491,lwr_k=100:0.5791,lwr_k=200:0.5974,lwr_k=500:0.6168,lwr_k=1000:0.6289'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.6451,lwr_k=20:0.6307,lwr_k=50:0.6216,lwr_k=100:0.6231,lwr_k=200:0.6351,lwr_k=500:0.6407,lwr_k=1000:0.6435'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6532,lwr_k=20:0.5361,lwr_k=50:0.5796,lwr_k=100:0.6003,lwr_k=200:0.6187,lwr_k=500:0.6347,lwr_k=1000:0.6435'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7398,lwr_k=20:0.7224,lwr_k=50:0.7118,lwr_k=100:0.7145,lwr_k=200:0.7212,lwr_k=500:0.7225,lwr_k=1000:0.7238'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_83'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.4076,lwr_k=20:3.9039,lwr_k=50:4.0982,lwr_k=100:4.1841,lwr_k=200:4.2733,lwr_k=500:4.3197,lwr_k=1000:4.3302'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.4338,lwr_k=20:4.5934,lwr_k=50:4.5167,lwr_k=100:4.4496,lwr_k=200:4.4086,lwr_k=500:4.3767,lwr_k=1000:4.3723'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5509,lwr_k=20:4.248,lwr_k=50:4.4615,lwr_k=100:4.5074,lwr_k=200:4.5455,lwr_k=500:4.5689,lwr_k=1000:4.5706'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.7196,lwr_k=20:4.9156,lwr_k=50:4.868,lwr_k=100:4.827,lwr_k=200:4.806,lwr_k=500:4.7789,lwr_k=1000:4.7796'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.0185,lwr_k=20:3.3835,lwr_k=50:3.614,lwr_k=100:3.7133,lwr_k=200:3.7972,lwr_k=500:3.8429,lwr_k=1000:3.8964'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.0726,lwr_k=20:4.1794,lwr_k=50:4.05,lwr_k=100:4.0029,lwr_k=200:3.9947,lwr_k=500:3.9653,lwr_k=1000:3.9637'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.4944,lwr_k=20:4.1581,lwr_k=50:4.3806,lwr_k=100:4.4086,lwr_k=200:4.4042,lwr_k=500:4.4362,lwr_k=1000:4.4305'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.3195,lwr_k=20:4.4767,lwr_k=50:4.4333,lwr_k=100:4.3834,lwr_k=200:4.3183,lwr_k=500:4.2585,lwr_k=1000:4.2159'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.0903,lwr_k=20:3.33,lwr_k=50:3.6055,lwr_k=100:3.7545,lwr_k=200:3.8516,lwr_k=500:3.9217,lwr_k=1000:3.9716'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.3133,lwr_k=20:4.2555,lwr_k=50:4.2048,lwr_k=100:4.1903,lwr_k=200:4.2119,lwr_k=500:4.203,lwr_k=1000:4.206'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.2674,lwr_k=20:3.4865,lwr_k=50:3.7474,lwr_k=100:3.9074,lwr_k=200:4.0286,lwr_k=500:4.1338,lwr_k=1000:4.1722'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.3903,lwr_k=20:4.1969,lwr_k=50:4.2303,lwr_k=100:4.2887,lwr_k=200:4.3502,lwr_k=500:4.3456,lwr_k=1000:4.3607'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_84'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.3339,lwr_k=20:0.1082,lwr_k=50:0.3619,lwr_k=100:0.6357,lwr_k=200:0.8845,lwr_k=500:1.1019,lwr_k=1000:1.1925'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.2135,lwr_k=20:1.2808,lwr_k=50:1.0835,lwr_k=100:1.0479,lwr_k=200:1.0227,lwr_k=500:1.0835,lwr_k=1000:1.1294'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1852,lwr_k=20:0.2898,lwr_k=50:0.4862,lwr_k=100:0.6444,lwr_k=200:0.7826,lwr_k=500:0.9613,lwr_k=1000:1.0457'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.168,lwr_k=20:0.9974,lwr_k=50:0.9104,lwr_k=100:0.93,lwr_k=200:0.964,lwr_k=500:1.0627,lwr_k=1000:1.0837'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8402,lwr_k=20:0.5299,lwr_k=50:0.6221,lwr_k=100:0.6822,lwr_k=200:0.727,lwr_k=500:0.7722,lwr_k=1000:0.8002'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8979,lwr_k=20:0.8148,lwr_k=50:0.818,lwr_k=100:0.8285,lwr_k=200:0.8513,lwr_k=500:0.8655,lwr_k=1000:0.8747'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.016,lwr_k=20:0.2233,lwr_k=50:0.402,lwr_k=100:0.5238,lwr_k=200:0.6577,lwr_k=500:0.7888,lwr_k=1000:0.868'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.0397,lwr_k=20:0.7665,lwr_k=50:0.7914,lwr_k=100:0.8462,lwr_k=200:0.879,lwr_k=500:0.9001,lwr_k=1000:0.9346'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.4714,lwr_k=20:0.112,lwr_k=50:0.367,lwr_k=100:0.6754,lwr_k=200:0.9354,lwr_k=500:1.1527,lwr_k=1000:1.2959'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.5327,lwr_k=20:1.3582,lwr_k=50:1.3224,lwr_k=100:1.2799,lwr_k=200:1.3553,lwr_k=500:1.3911,lwr_k=1000:1.4571'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.9814,lwr_k=20:0.0608,lwr_k=50:0.2051,lwr_k=100:0.3778,lwr_k=200:0.549,lwr_k=500:0.7182,lwr_k=1000:0.8096'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.1257,lwr_k=20:0.6114,lwr_k=50:0.7134,lwr_k=100:0.7727,lwr_k=200:0.8448,lwr_k=500:0.9079,lwr_k=1000:0.9684'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_85'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.4525,lwr_k=20:3.5286,lwr_k=50:3.9885,lwr_k=100:4.1296,lwr_k=200:4.2365,lwr_k=500:4.3849,lwr_k=1000:4.519'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.3746,lwr_k=20:4.367,lwr_k=50:4.2829,lwr_k=100:4.2697,lwr_k=200:4.2822,lwr_k=500:4.3381,lwr_k=1000:4.4321'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5171,lwr_k=20:2.822,lwr_k=50:3.545,lwr_k=100:3.8853,lwr_k=200:4.0977,lwr_k=500:4.2744,lwr_k=1000:4.3617'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.6402,lwr_k=20:4.074,lwr_k=50:4.2005,lwr_k=100:4.2995,lwr_k=200:4.2574,lwr_k=500:4.3982,lwr_k=1000:4.4552'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.297,lwr_k=20:2.8047,lwr_k=50:3.3529,lwr_k=100:3.5927,lwr_k=200:3.7576,lwr_k=500:3.9336,lwr_k=1000:4.0581'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.4014,lwr_k=20:4.0225,lwr_k=50:4.0165,lwr_k=100:4.0652,lwr_k=200:4.1185,lwr_k=500:4.2118,lwr_k=1000:4.2808'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5776,lwr_k=20:3.4635,lwr_k=50:3.8975,lwr_k=100:4.1065,lwr_k=200:4.2641,lwr_k=500:4.4245,lwr_k=1000:4.5393'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.4811,lwr_k=20:4.232,lwr_k=50:4.1998,lwr_k=100:4.2435,lwr_k=200:4.317,lwr_k=500:4.4355,lwr_k=1000:4.5272'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.8273,lwr_k=20:3.3679,lwr_k=50:3.8144,lwr_k=100:4.0049,lwr_k=200:4.1468,lwr_k=500:4.2543,lwr_k=1000:4.3299'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.897,lwr_k=20:4.4565,lwr_k=50:4.4952,lwr_k=100:4.4837,lwr_k=200:4.5156,lwr_k=500:4.4884,lwr_k=1000:4.4928'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.8023,lwr_k=20:2.752,lwr_k=50:3.6866,lwr_k=100:4.0313,lwr_k=200:4.2517,lwr_k=500:4.4383,lwr_k=1000:4.5626'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.9314,lwr_k=20:4.9253,lwr_k=50:4.5328,lwr_k=100:4.4768,lwr_k=200:4.4965,lwr_k=500:4.6558,lwr_k=1000:4.7178'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_86'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:135232.8101,lwr_k=20:5.995,lwr_k=50:5.994,lwr_k=100:6.0111,lwr_k=200:6.0357,lwr_k=500:5.9961,lwr_k=1000:5.9955'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:135155.9286,lwr_k=20:6.0678,lwr_k=50:6.0672,lwr_k=100:6.0815,lwr_k=200:6.1044,lwr_k=500:6.0686,lwr_k=1000:6.0681'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.4917,lwr_k=20:3.1497,lwr_k=50:3.3449,lwr_k=100:3.3983,lwr_k=200:3.4561,lwr_k=500:3.4738,lwr_k=1000:3.4827'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.619,lwr_k=20:3.7831,lwr_k=50:3.6557,lwr_k=100:3.6157,lwr_k=200:3.6211,lwr_k=500:3.6085,lwr_k=1000:3.6057'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.5562,lwr_k=20:3.214,lwr_k=50:3.3924,lwr_k=100:3.476,lwr_k=200:3.5175,lwr_k=500:3.5512,lwr_k=1000:3.5708'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.6249,lwr_k=20:3.7873,lwr_k=50:3.7502,lwr_k=100:3.6927,lwr_k=200:3.7054,lwr_k=500:3.6856,lwr_k=1000:3.6741'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.7635,lwr_k=20:5.3514,lwr_k=50:5.5617,lwr_k=100:5.6137,lwr_k=200:5.6624,lwr_k=500:5.7253,lwr_k=1000:5.7333'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.5292,lwr_k=20:5.5928,lwr_k=50:5.5475,lwr_k=100:5.5417,lwr_k=200:5.4985,lwr_k=500:5.5449,lwr_k=1000:5.512'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0621,lwr_k=20:6.0621,lwr_k=50:6.0622,lwr_k=100:6.0666,lwr_k=200:6.1173,lwr_k=500:6.0709,lwr_k=1000:6.0621'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:6.1622,lwr_k=20:6.1627,lwr_k=50:6.1629,lwr_k=100:6.1578,lwr_k=200:6.1863,lwr_k=500:6.1833,lwr_k=1000:6.1627'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:252.8213,lwr_k=20:6.8304,lwr_k=50:6.5014,lwr_k=100:6.2754,lwr_k=200:6.1001,lwr_k=500:6.0893,lwr_k=1000:6.0857'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:62252.474,lwr_k=20:6.8685,lwr_k=50:6.5298,lwr_k=100:6.2946,lwr_k=200:6.1054,lwr_k=500:6.0919,lwr_k=1000:6.0854'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_87'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.0365,lwr_k=20:3.1385,lwr_k=50:3.6897,lwr_k=100:3.964,lwr_k=200:4.1534,lwr_k=500:4.4299,lwr_k=1000:4.554'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.0316,lwr_k=20:4.2388,lwr_k=50:4.186,lwr_k=100:4.2574,lwr_k=200:4.3099,lwr_k=500:4.4228,lwr_k=1000:4.5197'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5491,lwr_k=20:4.3029,lwr_k=50:4.6636,lwr_k=100:4.7939,lwr_k=200:4.8636,lwr_k=500:4.8364,lwr_k=1000:4.8319'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.7536,lwr_k=20:4.9037,lwr_k=50:5.0067,lwr_k=100:5.0607,lwr_k=200:5.0438,lwr_k=500:4.987,lwr_k=1000:4.9654'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.6696,lwr_k=20:2.964,lwr_k=50:3.5849,lwr_k=100:3.8011,lwr_k=200:3.9966,lwr_k=500:4.1353,lwr_k=1000:4.2437'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.9371,lwr_k=20:3.8905,lwr_k=50:3.9944,lwr_k=100:4.076,lwr_k=200:4.1816,lwr_k=500:4.2365,lwr_k=1000:4.3358'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.9894,lwr_k=20:4.2441,lwr_k=50:4.5485,lwr_k=100:4.6531,lwr_k=200:4.7215,lwr_k=500:4.792,lwr_k=1000:4.8439'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.7263,lwr_k=20:4.6374,lwr_k=50:4.5725,lwr_k=100:4.5527,lwr_k=200:4.5477,lwr_k=500:4.551,lwr_k=1000:4.5767'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5711,lwr_k=20:3.7939,lwr_k=50:4.2522,lwr_k=100:4.5309,lwr_k=200:4.8415,lwr_k=500:5.2187,lwr_k=1000:5.4145'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.822,lwr_k=20:4.3375,lwr_k=50:4.6572,lwr_k=100:4.9009,lwr_k=200:5.1284,lwr_k=500:5.42,lwr_k=1000:5.5735'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.4843,lwr_k=20:4.226,lwr_k=50:4.5639,lwr_k=100:4.7383,lwr_k=200:4.8439,lwr_k=500:4.93,lwr_k=1000:4.9825'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.5829,lwr_k=20:4.7687,lwr_k=50:4.8575,lwr_k=100:4.9458,lwr_k=200:4.9644,lwr_k=500:4.997,lwr_k=1000:5.0085'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_88'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9936,lwr_k=20:5.995,lwr_k=50:5.994,lwr_k=100:6.0111,lwr_k=200:6.0357,lwr_k=500:5.9961,lwr_k=1000:5.9955'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0673,lwr_k=20:6.0678,lwr_k=50:6.0672,lwr_k=100:6.0815,lwr_k=200:6.1044,lwr_k=500:6.0686,lwr_k=1000:6.0681'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9804,lwr_k=20:6.0234,lwr_k=50:6.1347,lwr_k=100:6.0663,lwr_k=200:5.9876,lwr_k=500:5.9849,lwr_k=1000:5.9808'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.2011,lwr_k=20:6.2838,lwr_k=50:6.2803,lwr_k=100:6.2309,lwr_k=200:6.1921,lwr_k=500:6.1928,lwr_k=1000:6.1978'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.0356,lwr_k=20:3.8827,lwr_k=50:3.9504,lwr_k=100:3.9974,lwr_k=200:4.0029,lwr_k=500:4.0153,lwr_k=1000:4.025'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.1196,lwr_k=20:4.2812,lwr_k=50:4.1326,lwr_k=100:4.1203,lwr_k=200:4.1211,lwr_k=500:4.133,lwr_k=1000:4.1313'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.1385,lwr_k=20:6.139,lwr_k=50:6.3221,lwr_k=100:6.2163,lwr_k=200:6.1406,lwr_k=500:6.1387,lwr_k=1000:6.1401'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.8637,lwr_k=20:5.8611,lwr_k=50:6.1076,lwr_k=100:5.9808,lwr_k=200:5.8723,lwr_k=500:5.8657,lwr_k=1000:5.8597'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0621,lwr_k=20:6.0621,lwr_k=50:6.0622,lwr_k=100:6.0666,lwr_k=200:6.1173,lwr_k=500:6.0709,lwr_k=1000:6.0621'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:6.1622,lwr_k=20:6.1627,lwr_k=50:6.1629,lwr_k=100:6.1578,lwr_k=200:6.1863,lwr_k=500:6.1833,lwr_k=1000:6.1627'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:6.0857,lwr_k=20:6.8304,lwr_k=50:6.5014,lwr_k=100:6.2754,lwr_k=200:6.1001,lwr_k=500:6.0893,lwr_k=1000:6.0857'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0856,lwr_k=20:6.8685,lwr_k=50:6.5298,lwr_k=100:6.2946,lwr_k=200:6.1054,lwr_k=500:6.0919,lwr_k=1000:6.0854'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_89'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.3533,lwr_k=20:3.9699,lwr_k=50:4.1945,lwr_k=100:4.2723,lwr_k=200:4.3039,lwr_k=500:4.3065,lwr_k=1000:4.3099'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.2023,lwr_k=20:4.3277,lwr_k=50:4.2636,lwr_k=100:4.2373,lwr_k=200:4.2374,lwr_k=500:4.2281,lwr_k=1000:4.2278'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8218,lwr_k=20:3.4962,lwr_k=50:3.6569,lwr_k=100:3.7084,lwr_k=200:3.7575,lwr_k=500:3.7773,lwr_k=1000:3.7992'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.9031,lwr_k=20:3.9126,lwr_k=50:3.8585,lwr_k=100:3.8367,lwr_k=200:3.8618,lwr_k=500:3.8727,lwr_k=1000:3.889'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8508,lwr_k=20:3.5717,lwr_k=50:3.6989,lwr_k=100:3.7483,lwr_k=200:3.7718,lwr_k=500:3.8001,lwr_k=1000:3.7966'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.9351,lwr_k=20:3.9519,lwr_k=50:3.9248,lwr_k=100:3.9162,lwr_k=200:3.9271,lwr_k=500:3.9108,lwr_k=1000:3.9097'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.3685,lwr_k=20:5.3141,lwr_k=50:5.5869,lwr_k=100:5.6837,lwr_k=200:5.6894,lwr_k=500:5.6081,lwr_k=1000:5.5171'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.1935,lwr_k=20:5.5062,lwr_k=50:5.4988,lwr_k=100:5.5165,lwr_k=200:5.475,lwr_k=500:5.3932,lwr_k=1000:5.3241'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.3154,lwr_k=20:3.9728,lwr_k=50:4.1738,lwr_k=100:4.2204,lwr_k=200:4.2453,lwr_k=500:4.2597,lwr_k=1000:4.268'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.4405,lwr_k=20:4.4627,lwr_k=50:4.415,lwr_k=100:4.4215,lwr_k=200:4.4092,lwr_k=500:4.4198,lwr_k=1000:4.4114'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:5.5928,lwr_k=20:5.0987,lwr_k=50:5.4957,lwr_k=100:5.654,lwr_k=200:5.7266,lwr_k=500:5.6919,lwr_k=1000:5.6342'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.6483,lwr_k=20:5.542,lwr_k=50:5.5862,lwr_k=100:5.6432,lwr_k=200:5.6679,lwr_k=500:5.6344,lwr_k=1000:5.5834'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_90'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.0916,lwr_k=20:3.7752,lwr_k=50:4.2172,lwr_k=100:4.5196,lwr_k=200:4.73,lwr_k=500:4.8309,lwr_k=1000:4.7753'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.0763,lwr_k=20:4.3753,lwr_k=50:4.5041,lwr_k=100:4.6633,lwr_k=200:4.8459,lwr_k=500:4.8818,lwr_k=1000:4.7853'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.065,lwr_k=20:3.8013,lwr_k=50:4.2906,lwr_k=100:4.5854,lwr_k=200:4.7751,lwr_k=500:4.8607,lwr_k=1000:4.7971'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:5.288,lwr_k=20:4.3653,lwr_k=50:4.5778,lwr_k=100:4.7866,lwr_k=200:4.9539,lwr_k=500:5.0302,lwr_k=1000:4.9561'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.0655,lwr_k=20:3.8434,lwr_k=50:4.3324,lwr_k=100:4.6007,lwr_k=200:4.7908,lwr_k=500:4.8618,lwr_k=1000:4.7908'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:5.0807,lwr_k=20:4.2021,lwr_k=50:4.4051,lwr_k=100:4.6305,lwr_k=200:4.8069,lwr_k=500:4.8421,lwr_k=1000:4.7816'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.182,lwr_k=20:3.9415,lwr_k=50:4.3951,lwr_k=100:4.6794,lwr_k=200:4.8867,lwr_k=500:4.9457,lwr_k=1000:4.8701'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.9285,lwr_k=20:4.069,lwr_k=50:4.328,lwr_k=100:4.526,lwr_k=200:4.6694,lwr_k=500:4.7247,lwr_k=1000:4.6467'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.9822,lwr_k=20:0.8587,lwr_k=50:1.2013,lwr_k=100:1.3888,lwr_k=200:1.5181,lwr_k=500:1.65,lwr_k=1000:1.733'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.0997,lwr_k=20:1.5378,lwr_k=50:1.6112,lwr_k=100:1.6773,lwr_k=200:1.7238,lwr_k=500:1.7796,lwr_k=1000:1.8411'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:6.0857,lwr_k=20:6.8304,lwr_k=50:6.5014,lwr_k=100:6.2754,lwr_k=200:6.1001,lwr_k=500:6.0893,lwr_k=1000:6.0857'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0856,lwr_k=20:6.8685,lwr_k=50:6.5298,lwr_k=100:6.2946,lwr_k=200:6.1054,lwr_k=500:6.0919,lwr_k=1000:6.0854'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_91'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.8572,lwr_k=20:2.8753,lwr_k=50:3.5924,lwr_k=100:3.9749,lwr_k=200:4.058,lwr_k=500:4.241,lwr_k=1000:4.3781'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.8311,lwr_k=20:4.4437,lwr_k=50:4.0968,lwr_k=100:4.12,lwr_k=200:4.0061,lwr_k=500:4.1428,lwr_k=1000:4.2821'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5935,lwr_k=20:3.6529,lwr_k=50:4.0315,lwr_k=100:4.1764,lwr_k=200:4.3213,lwr_k=500:4.42,lwr_k=1000:4.4709'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.705,lwr_k=20:4.4504,lwr_k=50:4.4474,lwr_k=100:4.477,lwr_k=200:4.4964,lwr_k=500:4.5116,lwr_k=1000:4.5548'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.6082,lwr_k=20:2.9302,lwr_k=50:3.4976,lwr_k=100:3.8019,lwr_k=200:3.9864,lwr_k=500:4.1309,lwr_k=1000:4.2408'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.6777,lwr_k=20:4.2208,lwr_k=50:4.2254,lwr_k=100:4.2545,lwr_k=200:4.3239,lwr_k=500:4.3511,lwr_k=1000:4.4304'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.7742,lwr_k=20:3.3182,lwr_k=50:3.747,lwr_k=100:3.9662,lwr_k=200:4.1271,lwr_k=500:4.3644,lwr_k=1000:4.5045'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.5345,lwr_k=20:4.0746,lwr_k=50:4.1607,lwr_k=100:4.1638,lwr_k=200:4.1795,lwr_k=500:4.2824,lwr_k=1000:4.3847'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5247,lwr_k=20:3.2955,lwr_k=50:3.7829,lwr_k=100:4.003,lwr_k=200:4.1561,lwr_k=500:4.2994,lwr_k=1000:4.4081'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.7018,lwr_k=20:4.3147,lwr_k=50:4.396,lwr_k=100:4.4592,lwr_k=200:4.4963,lwr_k=500:4.5699,lwr_k=1000:4.6158'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:4.7347,lwr_k=20:3.0599,lwr_k=50:3.5938,lwr_k=100:3.8765,lwr_k=200:4.0735,lwr_k=500:4.2837,lwr_k=1000:4.3655'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.8183,lwr_k=20:4.0332,lwr_k=50:4.1459,lwr_k=100:4.1541,lwr_k=200:4.2872,lwr_k=500:4.4257,lwr_k=1000:4.4746'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_92'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.1663,lwr_k=20:0.787,lwr_k=50:1.2334,lwr_k=100:1.4828,lwr_k=200:1.7142,lwr_k=500:1.928,lwr_k=1000:2.0196'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.0548,lwr_k=20:1.7614,lwr_k=50:1.7743,lwr_k=100:1.8209,lwr_k=200:1.8715,lwr_k=500:1.9147,lwr_k=1000:1.9431'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.1072,lwr_k=20:0.8584,lwr_k=50:1.2517,lwr_k=100:1.507,lwr_k=200:1.6952,lwr_k=500:1.8889,lwr_k=1000:1.9919'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.0833,lwr_k=20:1.7705,lwr_k=50:1.8098,lwr_k=100:1.8398,lwr_k=200:1.8785,lwr_k=500:1.9601,lwr_k=1000:2.0173'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.6504,lwr_k=20:0.4088,lwr_k=50:1.0897,lwr_k=100:1.5997,lwr_k=200:1.9761,lwr_k=500:2.2931,lwr_k=1000:2.4516'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.814,lwr_k=20:2.559,lwr_k=50:2.4586,lwr_k=100:2.4648,lwr_k=200:2.5041,lwr_k=500:2.6539,lwr_k=1000:2.7203'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.1408,lwr_k=20:0.6181,lwr_k=50:1.0882,lwr_k=100:1.4245,lwr_k=200:1.694,lwr_k=500:1.9168,lwr_k=1000:2.031'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.1782,lwr_k=20:1.8845,lwr_k=50:1.9485,lwr_k=100:1.9973,lwr_k=200:2.037,lwr_k=500:2.0509,lwr_k=1000:2.111'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.105,lwr_k=20:1.1455,lwr_k=50:1.4619,lwr_k=100:1.6338,lwr_k=200:1.7677,lwr_k=500:1.8928,lwr_k=1000:1.9631'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.1892,lwr_k=20:1.913,lwr_k=50:1.9445,lwr_k=100:2.0019,lwr_k=200:2.0274,lwr_k=500:2.0795,lwr_k=1000:2.1246'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:1.8111,lwr_k=20:0.2932,lwr_k=50:0.6794,lwr_k=100:1.0094,lwr_k=200:1.2649,lwr_k=500:1.5296,lwr_k=1000:1.6419'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.9142,lwr_k=20:1.247,lwr_k=50:1.4228,lwr_k=100:1.5046,lwr_k=200:1.6174,lwr_k=500:1.7133,lwr_k=1000:1.7733'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_93'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.1181,lwr_k=20:3.753,lwr_k=50:4.0627,lwr_k=100:4.1545,lwr_k=200:4.2072,lwr_k=500:4.2108,lwr_k=1000:4.2277'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:4.1383,lwr_k=20:4.1769,lwr_k=50:4.2416,lwr_k=100:4.2606,lwr_k=200:4.2446,lwr_k=500:4.2351,lwr_k=1000:4.2279'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.5762,lwr_k=20:3.2277,lwr_k=50:3.3965,lwr_k=100:3.4472,lwr_k=200:3.4855,lwr_k=500:3.5173,lwr_k=1000:3.5298'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.7462,lwr_k=20:3.7386,lwr_k=50:3.7075,lwr_k=100:3.6752,lwr_k=200:3.6679,lwr_k=500:3.6559,lwr_k=1000:3.6522'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.4785,lwr_k=20:3.2339,lwr_k=50:3.4239,lwr_k=100:3.4693,lwr_k=200:3.4846,lwr_k=500:3.4858,lwr_k=1000:3.4911'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.6245,lwr_k=20:3.7407,lwr_k=50:3.705,lwr_k=100:3.7113,lwr_k=200:3.6737,lwr_k=500:3.6531,lwr_k=1000:3.62'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.4931,lwr_k=20:3.26,lwr_k=50:3.4159,lwr_k=100:3.4885,lwr_k=200:3.528,lwr_k=500:3.5502,lwr_k=1000:3.5542'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.4775,lwr_k=20:3.6251,lwr_k=50:3.5964,lwr_k=100:3.5603,lwr_k=200:3.5569,lwr_k=500:3.5176,lwr_k=1000:3.4948'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.677,lwr_k=20:3.0719,lwr_k=50:3.2567,lwr_k=100:3.3268,lwr_k=200:3.3851,lwr_k=500:3.4584,lwr_k=1000:3.5266'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.9134,lwr_k=20:3.7586,lwr_k=50:3.742,lwr_k=100:3.7623,lwr_k=200:3.7425,lwr_k=500:3.7698,lwr_k=1000:3.8025'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:3.4128,lwr_k=20:3.0675,lwr_k=50:3.2116,lwr_k=100:3.2713,lwr_k=200:3.3127,lwr_k=500:3.3531,lwr_k=1000:3.3852'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.5995,lwr_k=20:3.481,lwr_k=50:3.502,lwr_k=100:3.5285,lwr_k=200:3.5454,lwr_k=500:3.5489,lwr_k=1000:3.5544'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_94'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7392,lwr_k=20:0.1016,lwr_k=50:0.2787,lwr_k=100:0.4313,lwr_k=200:0.5589,lwr_k=500:0.6492,lwr_k=1000:0.6898'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6939,lwr_k=20:0.7237,lwr_k=50:0.6217,lwr_k=100:0.6133,lwr_k=200:0.6379,lwr_k=500:0.6445,lwr_k=1000:0.6528'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7452,lwr_k=20:0.1042,lwr_k=50:0.2894,lwr_k=100:0.4333,lwr_k=200:0.5487,lwr_k=500:0.6508,lwr_k=1000:0.6934'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7601,lwr_k=20:0.6522,lwr_k=50:0.6516,lwr_k=100:0.6569,lwr_k=200:0.6701,lwr_k=500:0.7079,lwr_k=1000:0.7288'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7544,lwr_k=20:0.0876,lwr_k=50:0.2726,lwr_k=100:0.4327,lwr_k=200:0.554,lwr_k=500:0.6546,lwr_k=1000:0.7044'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8218,lwr_k=20:0.7456,lwr_k=50:0.7149,lwr_k=100:0.7356,lwr_k=200:0.744,lwr_k=500:0.7591,lwr_k=1000:0.7852'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.2038,lwr_k=20:0.1306,lwr_k=50:0.4062,lwr_k=100:0.6295,lwr_k=200:0.8121,lwr_k=500:0.9791,lwr_k=1000:1.0823'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.2548,lwr_k=20:0.9884,lwr_k=50:0.9461,lwr_k=100:0.9819,lwr_k=200:1.0132,lwr_k=500:1.0884,lwr_k=1000:1.1521'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7133,lwr_k=20:0.213,lwr_k=50:0.3614,lwr_k=100:0.4632,lwr_k=200:0.5348,lwr_k=500:0.6157,lwr_k=1000:0.6536'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.7304,lwr_k=20:0.5362,lwr_k=50:0.5742,lwr_k=100:0.5996,lwr_k=200:0.6203,lwr_k=500:0.666,lwr_k=1000:0.6857'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6015,lwr_k=20:0.2434,lwr_k=50:0.3704,lwr_k=100:0.4437,lwr_k=200:0.4984,lwr_k=500:0.5451,lwr_k=1000:0.5739'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7124,lwr_k=20:0.5287,lwr_k=50:0.5765,lwr_k=100:0.6143,lwr_k=200:0.6468,lwr_k=500:0.6784,lwr_k=1000:0.6944'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_95'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.8036,lwr_k=20:2.992,lwr_k=50:3.2131,lwr_k=100:3.2812,lwr_k=200:3.2884,lwr_k=500:3.3151,lwr_k=1000:3.343'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.7215,lwr_k=20:3.5418,lwr_k=50:3.474,lwr_k=100:3.4309,lwr_k=200:3.3537,lwr_k=500:3.2956,lwr_k=1000:3.3048'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9804,lwr_k=20:6.0234,lwr_k=50:6.1347,lwr_k=100:6.0663,lwr_k=200:5.9876,lwr_k=500:5.9849,lwr_k=1000:5.9808'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.2011,lwr_k=20:6.2838,lwr_k=50:6.2803,lwr_k=100:6.2309,lwr_k=200:6.1921,lwr_k=500:6.1928,lwr_k=1000:6.1978'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.7063,lwr_k=20:3.0365,lwr_k=50:3.1978,lwr_k=100:3.2392,lwr_k=200:3.2587,lwr_k=500:3.2661,lwr_k=1000:3.3146'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.849,lwr_k=20:3.6285,lwr_k=50:3.5938,lwr_k=100:3.5528,lwr_k=200:3.5214,lwr_k=500:3.4887,lwr_k=1000:3.5116'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.4283,lwr_k=20:3.7415,lwr_k=50:3.991,lwr_k=100:4.0782,lwr_k=200:4.1459,lwr_k=500:4.1925,lwr_k=1000:4.22'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.2702,lwr_k=20:4.3375,lwr_k=50:4.2472,lwr_k=100:4.1775,lwr_k=200:4.1238,lwr_k=500:4.0892,lwr_k=1000:4.1032'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9006,lwr_k=20:3.045,lwr_k=50:3.1982,lwr_k=100:3.2383,lwr_k=200:3.3084,lwr_k=500:3.3615,lwr_k=1000:3.4244'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.0097,lwr_k=20:3.6238,lwr_k=50:3.553,lwr_k=100:3.5157,lwr_k=200:3.4726,lwr_k=500:3.4529,lwr_k=1000:3.4487'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:6.0857,lwr_k=20:6.8304,lwr_k=50:6.5014,lwr_k=100:6.2754,lwr_k=200:6.1001,lwr_k=500:6.0893,lwr_k=1000:6.0857'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:6.0856,lwr_k=20:6.8685,lwr_k=50:6.5298,lwr_k=100:6.2946,lwr_k=200:6.1054,lwr_k=500:6.0919,lwr_k=1000:6.0854'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_96'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.9818,lwr_k=20:0.3108,lwr_k=50:0.8217,lwr_k=100:1.1773,lwr_k=200:1.4153,lwr_k=500:1.6471,lwr_k=1000:1.767'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.9673,lwr_k=20:1.8109,lwr_k=50:1.6346,lwr_k=100:1.617,lwr_k=200:1.6104,lwr_k=500:1.7089,lwr_k=1000:1.7778'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.091,lwr_k=20:0.3556,lwr_k=50:0.5548,lwr_k=100:0.6881,lwr_k=200:0.7939,lwr_k=500:0.9049,lwr_k=1000:0.9822'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.1032,lwr_k=20:0.7947,lwr_k=50:0.8209,lwr_k=100:0.8677,lwr_k=200:0.9232,lwr_k=500:0.9631,lwr_k=1000:1.0065'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.7582,lwr_k=20:0.1503,lwr_k=50:0.5549,lwr_k=100:0.8491,lwr_k=200:1.0909,lwr_k=500:1.2791,lwr_k=1000:1.401'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.8605,lwr_k=20:1.4202,lwr_k=50:1.2657,lwr_k=100:1.2252,lwr_k=200:1.3197,lwr_k=500:1.4456,lwr_k=1000:1.543'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.6185,lwr_k=20:1.5915,lwr_k=50:2.2186,lwr_k=100:2.5496,lwr_k=200:2.8146,lwr_k=500:3.0732,lwr_k=1000:3.2563'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.4133,lwr_k=20:2.8956,lwr_k=50:3.0478,lwr_k=100:3.0577,lwr_k=200:3.1459,lwr_k=500:3.1992,lwr_k=1000:3.2532'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.6772,lwr_k=20:0.3732,lwr_k=50:0.7136,lwr_k=100:0.9594,lwr_k=200:1.1365,lwr_k=500:1.3193,lwr_k=1000:1.444'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.6681,lwr_k=20:1.1761,lwr_k=50:1.188,lwr_k=100:1.2783,lwr_k=200:1.3554,lwr_k=500:1.3769,lwr_k=1000:1.4377'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:1.4962,lwr_k=20:0.3071,lwr_k=50:0.6168,lwr_k=100:0.8368,lwr_k=200:1.0246,lwr_k=500:1.1812,lwr_k=1000:1.2732'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:1.6606,lwr_k=20:0.9972,lwr_k=50:1.1408,lwr_k=100:1.2234,lwr_k=200:1.3113,lwr_k=500:1.4027,lwr_k=1000:1.4614'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_97'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.7969,lwr_k=20:0.744,lwr_k=50:0.7629,lwr_k=100:0.7708,lwr_k=200:0.7702,lwr_k=500:0.7728,lwr_k=1000:0.7779'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7917,lwr_k=20:0.8016,lwr_k=50:0.773,lwr_k=100:0.7678,lwr_k=200:0.7616,lwr_k=500:0.7609,lwr_k=1000:0.767'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.6456,lwr_k=20:0.6059,lwr_k=50:0.6266,lwr_k=100:0.6316,lwr_k=200:0.6347,lwr_k=500:0.64,lwr_k=1000:0.6422'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.6465,lwr_k=20:0.6603,lwr_k=50:0.651,lwr_k=100:0.6437,lwr_k=200:0.6393,lwr_k=500:0.6427,lwr_k=1000:0.6437'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:0.8189,lwr_k=20:0.7491,lwr_k=50:0.7791,lwr_k=100:0.7878,lwr_k=200:0.7908,lwr_k=500:0.799,lwr_k=1000:0.8002'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:0.8199,lwr_k=20:0.8462,lwr_k=50:0.8152,lwr_k=100:0.8091,lwr_k=200:0.8105,lwr_k=500:0.8097,lwr_k=1000:0.8094'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1631,lwr_k=20:1.0928,lwr_k=50:1.1229,lwr_k=100:1.1343,lwr_k=200:1.1409,lwr_k=500:1.149,lwr_k=1000:1.158'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1656,lwr_k=20:1.2045,lwr_k=50:1.1697,lwr_k=100:1.1613,lwr_k=200:1.1478,lwr_k=500:1.1508,lwr_k=1000:1.1537'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:1.1222,lwr_k=20:0.9229,lwr_k=50:0.9629,lwr_k=100:0.9759,lwr_k=200:0.9859,lwr_k=500:1.0077,lwr_k=1000:1.0319'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:1.1468,lwr_k=20:1.0562,lwr_k=50:1.0365,lwr_k=100:1.0276,lwr_k=200:1.0327,lwr_k=500:1.0437,lwr_k=1000:1.0618'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:0.6843,lwr_k=20:0.6435,lwr_k=50:0.6594,lwr_k=100:0.666,lwr_k=200:0.6692,lwr_k=500:0.6749,lwr_k=1000:0.6796'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:0.7295,lwr_k=20:0.7504,lwr_k=50:0.7306,lwr_k=100:0.7247,lwr_k=200:0.7224,lwr_k=500:0.7212,lwr_k=1000:0.7254'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_98'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.3509,lwr_k=20:1.0422,lwr_k=50:1.3754,lwr_k=100:1.5827,lwr_k=200:1.7823,lwr_k=500:1.9702,lwr_k=1000:2.0955'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.2744,lwr_k=20:1.8183,lwr_k=50:1.846,lwr_k=100:1.857,lwr_k=200:1.8944,lwr_k=500:1.9618,lwr_k=1000:2.0546'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.7549,lwr_k=20:0.4177,lwr_k=50:1.0172,lwr_k=100:1.5257,lwr_k=200:1.9897,lwr_k=500:2.3281,lwr_k=1000:2.499'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.8169,lwr_k=20:2.5877,lwr_k=50:2.3796,lwr_k=100:2.4125,lwr_k=200:2.5045,lwr_k=500:2.5903,lwr_k=1000:2.643'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.4518,lwr_k=20:0.519,lwr_k=50:1.0632,lwr_k=100:1.4788,lwr_k=200:1.8257,lwr_k=500:2.1058,lwr_k=1000:2.2283'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.6055,lwr_k=20:2.5845,lwr_k=50:2.3366,lwr_k=100:2.371,lwr_k=200:2.4142,lwr_k=500:2.4538,lwr_k=1000:2.5023'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.3771,lwr_k=20:0.6137,lwr_k=50:1.1388,lwr_k=100:1.4854,lwr_k=200:1.7712,lwr_k=500:2.0608,lwr_k=1000:2.1968'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.3817,lwr_k=20:2.0688,lwr_k=50:2.1406,lwr_k=100:2.1445,lwr_k=200:2.1081,lwr_k=500:2.1949,lwr_k=1000:2.2609'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:2.7607,lwr_k=20:0.4714,lwr_k=50:1.0255,lwr_k=100:1.5126,lwr_k=200:1.8867,lwr_k=500:2.2589,lwr_k=1000:2.4465'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:2.867,lwr_k=20:2.547,lwr_k=50:2.5055,lwr_k=100:2.3599,lwr_k=200:2.4263,lwr_k=500:2.537,lwr_k=1000:2.6775'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:2.3873,lwr_k=20:0.6588,lwr_k=50:1.0706,lwr_k=100:1.3565,lwr_k=200:1.5871,lwr_k=500:1.8383,lwr_k=1000:1.9786'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:2.3666,lwr_k=20:1.6493,lwr_k=50:1.7898,lwr_k=100:1.8537,lwr_k=200:1.9621,lwr_k=500:2.0736,lwr_k=1000:2.114'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_99'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9359,lwr_k=20:3.3793,lwr_k=50:3.7376,lwr_k=100:3.9059,lwr_k=200:4.0357,lwr_k=500:4.1841,lwr_k=1000:4.2745'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.9578,lwr_k=20:4.0911,lwr_k=50:4.1188,lwr_k=100:4.0981,lwr_k=200:4.0893,lwr_k=500:4.1546,lwr_k=1000:4.2412'\n",
      "-----------------------------------Fold 1 - Train 5844 - Val 1949 - Test 1949-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.5143,lwr_k=20:4.1355,lwr_k=50:4.4916,lwr_k=100:4.5219,lwr_k=200:4.4792,lwr_k=500:4.48,lwr_k=1000:4.5266'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:3.7758,lwr_k=20:4.8382,lwr_k=50:4.8965,lwr_k=100:4.8417,lwr_k=200:4.7185,lwr_k=500:4.6331,lwr_k=1000:4.6287'\n",
      "-----------------------------------Fold 2 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.7234,lwr_k=20:3.5205,lwr_k=50:3.8326,lwr_k=100:3.959,lwr_k=200:4.009,lwr_k=500:4.1109,lwr_k=1000:4.1809'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:4.6348,lwr_k=20:4.1353,lwr_k=50:4.2033,lwr_k=100:4.2432,lwr_k=200:4.2675,lwr_k=500:4.2818,lwr_k=1000:4.3265'\n",
      "-----------------------------------Fold 3 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.2686,lwr_k=20:3.3501,lwr_k=50:3.6883,lwr_k=100:3.8343,lwr_k=200:3.9581,lwr_k=500:4.0704,lwr_k=1000:4.1731'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:3.0703,lwr_k=20:3.9131,lwr_k=50:3.9036,lwr_k=100:3.8661,lwr_k=200:3.9232,lwr_k=500:3.9834,lwr_k=1000:4.0375'\n",
      "-----------------------------------Fold 4 - Train 5846 - Val 1948 - Test 1948-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.425,lwr_k=20:3.4343,lwr_k=50:3.9454,lwr_k=100:4.116,lwr_k=200:4.2364,lwr_k=500:4.3767,lwr_k=1000:4.4637'\n",
      "Tested (test) on 1948 instances with mean losses of: lr:9008.5007,lwr_k=20:4.4902,lwr_k=50:4.5628,lwr_k=100:4.5943,lwr_k=200:4.5992,lwr_k=500:4.6569,lwr_k=1000:4.6905'\n",
      "Building final model - Train 7793 - Test 1949'\n",
      "Finished training DeepLWR with a train loss of lr:7.9365,lwr_k=20:2.8451,lwr_k=50:3.3158,lwr_k=100:3.482,lwr_k=200:3.6219,lwr_k=500:3.7598,lwr_k=1000:3.8127'\n",
      "Tested (test) on 1949 instances with mean losses of: lr:7.8614,lwr_k=20:3.6081,lwr_k=50:3.6866,lwr_k=100:3.6633,lwr_k=200:3.7219,lwr_k=500:3.7418,lwr_k=1000:3.796'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "for deep_name,deep_model in deep_models.items():\n",
    "    logging.getLogger().info(f\"Running model {deep_name}\")\n",
    "    temp_dict = {deep_name:deep_model}\n",
    "\n",
    "    lwr_scheme = DeepLWRScheme_1_to_n(lwr_models = setup_pls_models_slim(nrow),n_neighbours=500,loss_fun_sk = mean_squared_error)\n",
    "    lwr_scores, lwr_preds, _ , _, _= eval.evaluate(temp_dict,dataset,lwr_scheme,logger_name=\"log\",load_fun=load_fun_cv)\n",
    "    lwr_scores_final, lwr_preds_final, _ , _, _= eval.build(temp_dict,dataset,lwr_scheme,logger_name=\"test_log\",load_fun=load_fun_build)\n",
    "\n",
    "    #scores\n",
    "    for k,v in ut.flip_dicts(lwr_scores).items():\n",
    "        dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "        all_scores.append({**dict1,**v})\n",
    "\n",
    "    for k,v in ut.flip_dicts(lwr_scores_final).items():\n",
    "        dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "        all_scores_final.append({**dict1,**v})\n",
    "\n",
    "    lwr_preds['deep'] = deep_preds[deep_name]\n",
    "    lwr_preds_final['deep'] = deep_preds_final[deep_name]\n",
    "\n",
    "    lwr_preds.to_csv(log_dir/deep_name/ f\"predictions.csv\",index=False)\n",
    "    lwr_preds_final.to_csv(log_dir/deep_name/ f\"predictions_test.csv\",index=False)\n",
    "\n",
    "    #preds\n",
    "    # todo save predictions - appending solns\n",
    "    plot_preds_and_res(lwr_preds,name_lambda=lambda x:f\"{deep_name} with {x} predictor\",save_lambda= lambda x:f\"deep_lwr{x}\",save_loc=log_dir/deep_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save scores\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank - model_num - predictor - fold_0 - fold_1 - fold_2 - fold_3 - fold_4 - MSE - R2'\n",
      "0 - random_40 - lwr_k=200 - 0.5714793329300526 - 0.6005597678574872 - 0.6360888443625959 - 0.5685027817591387 - 0.6160427992490463 - 0.5985321359122558 - 0.9009457068634159'\n",
      "1 - random_40 - lwr_k=100 - 0.5707113631009726 - 0.6048032638886474 - 0.6362876321735245 - 0.5752987319689485 - 0.6160037618670771 - 0.6006183097381823 - 0.9006004547686854'\n",
      "2 - random_40 - lwr_k=1000 - 0.5771497722348048 - 0.6008554909724153 - 0.6430830315204967 - 0.5635915237895266 - 0.6211482260614023 - 0.6011631118971884 - 0.9005102925375842'\n",
      "3 - random_40 - lwr_k=500 - 0.574659427290459 - 0.6056373023883805 - 0.6403716480807086 - 0.5660842475872923 - 0.6194557745072314 - 0.6012394025503398 - 0.9004976667882427'\n",
      "4 - random_40 - lwr_k=50 - 0.5694746912170977 - 0.606915130953072 - 0.6350106898999671 - 0.5756403654226816 - 0.6215140446111811 - 0.6017082096161734 - 0.9004200813926769'\n",
      "5 - random_48 - lwr_k=50 - 0.5883890901051408 - 0.6015823128538194 - 0.6307461281497239 - 0.6110079944767587 - 0.5950637057823719 - 0.6053557169069453 - 0.8998164358493224'\n",
      "6 - random_48 - lwr_k=20 - 0.5904332822160845 - 0.62038234585588 - 0.6212916507633568 - 0.6026247724638519 - 0.5941939353108736 - 0.6057851198464835 - 0.8997453716539439'\n",
      "7 - random_40 - lr - 0.5948179459400983 - 0.6055504454968151 - 0.6505638966622319 - 0.5697035690468947 - 0.6227783193353132 - 0.6086810905540047 - 0.8992661019302881'\n",
      "8 - random_40 - lwr_k=20 - 0.5782666571424646 - 0.6141001041308335 - 0.6412561485404553 - 0.5819470321650869 - 0.6341813771762229 - 0.6099474375359614 - 0.8990565273767478'\n",
      "9 - random_5 - lwr_k=100 - 0.5996000705125714 - 0.6036653119112153 - 0.6180417229900035 - 0.637520912312916 - 0.6112957858167846 - 0.6140222166582984 - 0.8983821703265025'\n",
      "10 - random_5 - lwr_k=50 - 0.5986796824187319 - 0.6009148299687375 - 0.6171943745086643 - 0.6451990442462652 - 0.6087716202087299 - 0.6141489633077793 - 0.8983611943437299'\n",
      "11 - random_5 - lwr_k=200 - 0.6016424044364984 - 0.6082507938393308 - 0.6221803455627107 - 0.632662634142025 - 0.6114900660915075 - 0.6152431345360987 - 0.8981801140790481'\n",
      "12 - random_5 - lwr_k=20 - 0.6223236676108621 - 0.5774306258409406 - 0.6073614668357258 - 0.6564798589628122 - 0.6273018763681228 - 0.6181757417119913 - 0.8976947811897579'\n",
      "13 - random_5 - lwr_k=500 - 0.5978237048831564 - 0.6139114715269316 - 0.6293938030302956 - 0.6371662233085701 - 0.6152399906137688 - 0.6187044027763285 - 0.8976072902349791'\n",
      "14 - random_5 - lwr_k=1000 - 0.6003131208284861 - 0.6182889240212431 - 0.631262099737083 - 0.6402257849588213 - 0.6183173519639928 - 0.6216789146402795 - 0.8971150223141248'\n",
      "15 - random_5 - lr - 0.5994563838617211 - 0.6231528175103316 - 0.6357256337345369 - 0.6489898557280682 - 0.6220835529311904 - 0.6258786561339812 - 0.8964199845708615'\n",
      "16 - random_48 - lwr_k=100 - 0.6000960160568415 - 0.617717088909073 - 0.6761432137967157 - 0.6144848794632813 - 0.6303074791127955 - 0.6277458670253302 - 0.8961109698264859'\n",
      "17 - random_48 - lwr_k=200 - 0.6115611701684964 - 0.6608564616824787 - 0.6877416284106443 - 0.6558814987739343 - 0.6465895922338224 - 0.6525227203761645 - 0.8920105154856758'\n",
      "18 - random_40 - deep - 0.6489405148820794 - 0.6582865173722487 - 0.6965300473833965 - 0.6149988380056143 - 0.6901702678913453 - 0.6617835579104037 - 0.8904778898628994'\n",
      "19 - random_26 - lwr_k=100 - 0.6475365613451098 - 0.628192407661458 - 0.6835068569323208 - 0.6694791703836811 - 0.6969123358150542 - 0.6651198698391602 - 0.8899257456617614'\n",
      "20 - random_26 - lwr_k=50 - 0.6496954678000588 - 0.6286241790956913 - 0.6825966483278502 - 0.6717520191474823 - 0.6968997279353155 - 0.6659081159987436 - 0.8897952945773995'\n",
      "21 - random_26 - lwr_k=200 - 0.6453019167158276 - 0.640853425145207 - 0.6804554153253393 - 0.6696635189872436 - 0.6963832867426938 - 0.6665266975880554 - 0.8896929221926934'\n",
      "22 - random_26 - lwr_k=500 - 0.6412024524540115 - 0.6364704448019421 - 0.6876833001647764 - 0.678490729491138 - 0.7000274676512496 - 0.6687687326530701 - 0.889321875785613'\n",
      "23 - random_26 - lwr_k=1000 - 0.6440230915258248 - 0.634148518516336 - 0.6889379510864823 - 0.6808033781026062 - 0.7022270075539436 - 0.6700216370301373 - 0.8891145259208492'\n",
      "24 - random_42 - lwr_k=200 - 0.641348186548947 - 0.655326581442082 - 0.7160408273630416 - 0.6856468551026751 - 0.6717329206332949 - 0.6740138018529449 - 0.8884538411540985'\n",
      "25 - random_77 - lwr_k=200 - 0.6536733355101109 - 0.6978122736583152 - 0.6923835299306892 - 0.668023746899675 - 0.6582355609456351 - 0.6740260419068885 - 0.8884518154819273'\n",
      "26 - random_42 - lwr_k=500 - 0.644171319188009 - 0.6544753738914034 - 0.7168026480099764 - 0.6886350042700063 - 0.6723622918893428 - 0.6752839967207577 - 0.8882436297932914'\n",
      "27 - random_77 - lwr_k=500 - 0.654930028013486 - 0.6967390060136379 - 0.6972696668125645 - 0.6769839956025704 - 0.6536097060033014 - 0.6759064657152513 - 0.8881406140610534'\n",
      "28 - random_42 - lwr_k=100 - 0.6370119852519777 - 0.6584722148844381 - 0.7209864073895378 - 0.6876499692379748 - 0.678320409905857 - 0.6764822958563825 - 0.8880453168427853'\n",
      "29 - random_77 - lwr_k=100 - 0.6604535961551933 - 0.7006129930858525 - 0.6965347420122928 - 0.6651744578972577 - 0.6615953451264669 - 0.6768749780497804 - 0.8879803297606212'\n",
      "30 - random_42 - lwr_k=1000 - 0.6456077880503394 - 0.6571179046263427 - 0.7173105641089275 - 0.6924499798424998 - 0.6735671648940988 - 0.677205373830624 - 0.8879256507909167'\n",
      "31 - random_26 - lr - 0.649749078660079 - 0.6431658432194753 - 0.6964748980738186 - 0.688012579874922 - 0.7126015263273657 - 0.6779943094922097 - 0.8877950855971707'\n",
      "32 - random_77 - lwr_k=1000 - 0.6534084779353623 - 0.7004155549112815 - 0.7019708282187433 - 0.679723925397346 - 0.6577991264788541 - 0.6786632229976451 - 0.887684383513732'\n",
      "33 - random_77 - lwr_k=50 - 0.6620856789441288 - 0.7020407123181456 - 0.6972957659426848 - 0.668905022013958 - 0.6652981709435956 - 0.6791256732198561 - 0.8876078501463096'\n",
      "34 - random_26 - lwr_k=20 - 0.6697354547094785 - 0.6318321413174228 - 0.7016707108455661 - 0.6914202332229165 - 0.7055080895427613 - 0.6800273210974269 - 0.8874586316034576'\n",
      "35 - random_42 - lwr_k=50 - 0.6443908424986716 - 0.6569505328952155 - 0.7266065221638632 - 0.692811704314513 - 0.686395603896497 - 0.6814247261561218 - 0.8872273675459253'\n",
      "36 - random_77 - lr - 0.6573879546493119 - 0.7077314264614184 - 0.6969177255438153 - 0.6924304969266376 - 0.6562894363141563 - 0.6821514917981145 - 0.8871070912021434'\n",
      "37 - random_42 - lr - 0.6527651625471477 - 0.6614884318408419 - 0.7189177538115419 - 0.6987748947019965 - 0.6799447567969837 - 0.6823730159112184 - 0.8870704299886185'\n",
      "38 - random_5 - deep - 0.6397743970537993 - 0.6720053308006432 - 0.6883496344701465 - 0.6967656480825413 - 0.7223730948916206 - 0.6838478768423392 - 0.8868263473921348'\n",
      "39 - random_48 - lwr_k=500 - 0.6275095409761254 - 0.7087991700911113 - 0.7345405623604724 - 0.6850263959481814 - 0.6981745319375406 - 0.6908053891264248 - 0.8856749113219005'\n",
      "40 - random_77 - lwr_k=20 - 0.6767192941700442 - 0.7272481048018796 - 0.7053911300013211 - 0.6676025703539794 - 0.6875323712375676 - 0.69290055923416 - 0.8853281703842459'\n",
      "41 - random_36 - lwr_k=200 - 0.7229445205956775 - 0.7241384075494907 - 0.6940422359110368 - 0.6426839732038763 - 0.716667515643442 - 0.700100143993452 - 0.8841366724906171'\n",
      "42 - random_42 - lwr_k=20 - 0.6680192876358728 - 0.6742625051356846 - 0.7470671804036326 - 0.7101708493640381 - 0.7026070671538132 - 0.7004193659325412 - 0.8840838427399105'\n",
      "43 - random_36 - lwr_k=500 - 0.726440712242672 - 0.7291745676512389 - 0.6914426747747803 - 0.6473006398495661 - 0.7137793140831132 - 0.7016329563986208 - 0.883882999145119'\n",
      "44 - random_36 - lwr_k=100 - 0.7198719619895034 - 0.729060455789618 - 0.6987414258321333 - 0.6378038056548851 - 0.722719160557629 - 0.7016440482400411 - 0.8838811634967961'\n",
      "45 - random_94 - lwr_k=50 - 0.6216604986897047 - 0.6516449431404667 - 0.7148729147445618 - 0.9461212287324143 - 0.5742087268787298 - 0.7016883081071567 - 0.8838738386940188'\n",
      "46 - random_42 - deep - 0.6698673098071408 - 0.705489228480042 - 0.7278844705597332 - 0.708470471952975 - 0.7035771536141695 - 0.7030545697160058 - 0.8836477287831727'\n",
      "47 - random_36 - lwr_k=1000 - 0.7317233144144712 - 0.7333688528361655 - 0.6926907836726192 - 0.6503066526910266 - 0.7128318943955443 - 0.7041901221813173 - 0.8834598000655041'\n",
      "48 - random_36 - lwr_k=50 - 0.7287499087630275 - 0.7316666601186894 - 0.7056828950937097 - 0.6416881961751265 - 0.7262031083463711 - 0.7068029597208878 - 0.8830273875682729'\n",
      "49 - random_36 - lr - 0.7395119118045957 - 0.7360291708866917 - 0.6950273498376427 - 0.653772633919054 - 0.7123843714537422 - 0.7073513338241896 - 0.8829366341969537'\n",
      "50 - random_48 - lwr_k=1000 - 0.6352432494536979 - 0.7341998989337808 - 0.7681205504166866 - 0.6921895079094081 - 0.7200882183650691 - 0.7099631019504806 - 0.8825043986826615'\n",
      "51 - random_94 - lwr_k=100 - 0.6132603560199845 - 0.656933915489 - 0.735598990390318 - 0.9819398692574758 - 0.5996482300908709 - 0.7174593600884757 - 0.8812638027205136'\n",
      "52 - random_26 - deep - 0.6934498894392007 - 0.6764748279959071 - 0.7315417744785364 - 0.7255506372304913 - 0.7668250309613206 - 0.7187614909019658 - 0.8810483061600491'\n",
      "53 - random_57 - lwr_k=50 - 0.6523501496724473 - 0.6717930036897842 - 0.7662266684379271 - 0.7611795415802319 - 0.7607938248204169 - 0.7224562383256555 - 0.880436842542479'\n",
      "54 - random_77 - deep - 0.6829371911369879 - 0.7520558714805474 - 0.7412079096574803 - 0.7339195823277781 - 0.7027930039032774 - 0.72258167120723 - 0.8804160840337428'\n",
      "55 - random_78 - lwr_k=20 - 0.6576126598962254 - 0.780608557260134 - 0.6832492146143746 - 0.6746626755470272 - 0.828523487386697 - 0.7249301239685323 - 0.8800274259398393'\n",
      "56 - random_57 - lwr_k=100 - 0.6603634046656816 - 0.6790974011668871 - 0.7713422786069255 - 0.7591813231532959 - 0.7578012158196266 - 0.7255456636433196 - 0.8799255569778818'\n",
      "57 - random_36 - lwr_k=20 - 0.7436366110340519 - 0.7509533638193124 - 0.727605504857132 - 0.6576162672759228 - 0.7487845967385578 - 0.7257236981678411 - 0.8798960930896087'\n",
      "58 - random_94 - lwr_k=20 - 0.723725828533782 - 0.6521657951868697 - 0.7456390329906235 - 0.9883756279526578 - 0.536196205052955 - 0.7292120243884437 - 0.8793187912752543'\n",
      "59 - random_57 - lwr_k=20 - 0.6761464064425221 - 0.6831023651417257 - 0.7933501695769358 - 0.7445514694321336 - 0.7549357824538271 - 0.7304068110067155 - 0.8791210596300827'\n",
      "60 - random_78 - lwr_k=50 - 0.6552467124284457 - 0.7490679158942626 - 0.7028272662916938 - 0.6832329669608529 - 0.8620063476452312 - 0.7304704280630085 - 0.8791105313022546'\n",
      "61 - random_57 - lwr_k=200 - 0.6676903634239877 - 0.6757795897254847 - 0.7761486285337312 - 0.7641246903140714 - 0.773455095363894 - 0.7314274162977524 - 0.8789521541869003'\n",
      "62 - random_82 - lwr_k=50 - 0.677598658393613 - 0.6805483429581513 - 0.6333174100111496 - 1.0480590420748257 - 0.6215764079052901 - 0.7322090614758339 - 0.8788227955343688'\n",
      "63 - random_82 - lwr_k=100 - 0.676801020810403 - 0.6836265711017033 - 0.6344787159404911 - 1.0532493976658734 - 0.6231219300423568 - 0.7342444325256009 - 0.8784859510635233'\n",
      "64 - random_94 - lwr_k=200 - 0.6379393229310448 - 0.6701218893218653 - 0.7439773359070826 - 1.0131691685315527 - 0.6202686426267332 - 0.7370782189657421 - 0.8780169725477743'\n",
      "65 - random_82 - lwr_k=20 - 0.6672556325608943 - 0.678084127675965 - 0.6369362629367729 - 1.0793141884203972 - 0.6307396276137882 - 0.7384524601249297 - 0.8777895420082009'\n",
      "66 - random_56 - lwr_k=100 - 0.675823490478598 - 0.7311116212855299 - 0.7847905068693014 - 0.6999991956122694 - 0.8199985097506699 - 0.7423366834589089 - 0.8771467210573334'\n",
      "67 - random_82 - lwr_k=200 - 0.679115595900308 - 0.690621942248184 - 0.64304433395539 - 1.0723862885014965 - 0.6350668592106656 - 0.7440348548696163 - 0.8768656815631782'\n",
      "68 - random_56 - lwr_k=200 - 0.6800072607484652 - 0.7267434876044044 - 0.7868508970757919 - 0.7029788811843208 - 0.8237944173085193 - 0.744066633289616 - 0.8768604223820229'\n",
      "69 - random_56 - lwr_k=50 - 0.6786128522180119 - 0.7230878857654107 - 0.784500131430043 - 0.7125861486486312 - 0.8277765538304729 - 0.745303586407792 - 0.8766557123766406'\n",
      "70 - random_57 - lwr_k=500 - 0.6829025817111906 - 0.6973876242254583 - 0.7949608134448855 - 0.7816299584052587 - 0.7731751711179528 - 0.7459997606520613 - 0.8765404987673314'\n",
      "71 - random_36 - deep - 0.8048308287112147 - 0.7770185491376929 - 0.7063617424798453 - 0.6924539838728229 - 0.7814674813155031 - 0.7524344161818183 - 0.8754755931679297'\n",
      "72 - random_82 - lwr_k=500 - 0.6856804959031046 - 0.7029817723975498 - 0.6564778252432171 - 1.0799537184968946 - 0.6406685204490097 - 0.7531403906752601 - 0.8753587576091566'\n",
      "73 - random_56 - lwr_k=500 - 0.6952126658364656 - 0.7296788943493396 - 0.7993576773890233 - 0.711539619421581 - 0.8309694790172509 - 0.7533432693609933 - 0.8753251821274037'\n",
      "74 - random_57 - lwr_k=1000 - 0.6845105227954392 - 0.7106084687581588 - 0.8022910578220531 - 0.7913236613377104 - 0.7791902980803947 - 0.7535732999509126 - 0.8752871131314099'\n",
      "75 - random_78 - lwr_k=100 - 0.6603987726251891 - 0.7950440153420069 - 0.7076584449358713 - 0.7009164754772528 - 0.9129536985628695 - 0.7553886002374564 - 0.8749866893514233'\n",
      "76 - random_56 - lwr_k=20 - 0.6760261747007058 - 0.7346704255452814 - 0.8235691518305587 - 0.7073057964537114 - 0.8398543975733614 - 0.7562747320478438 - 0.8748400386457431'\n",
      "77 - random_48 - lr - 0.6531900535649185 - 0.7719432447576554 - 0.8508388510391628 - 0.7354828421005116 - 0.7843152618317221 - 0.7591444864211638 - 0.8743651076038341'\n",
      "78 - random_56 - lwr_k=1000 - 0.7067916361874493 - 0.7349840682897879 - 0.8115686204016699 - 0.7139635820649007 - 0.8346065687756924 - 0.7603747869437554 - 0.8741614985721735'\n",
      "79 - random_68 - lr - 0.8470439910487544 - 0.6973053403367453 - 0.711979083336657 - 0.7809736608017093 - 0.770519358797114 - 0.7615664651394636 - 0.8739642813565227'\n",
      "80 - random_82 - lwr_k=1000 - 0.6965069324130186 - 0.7120718228561869 - 0.6588109279630814 - 1.097276196040063 - 0.6434610119469081 - 0.7616136073547919 - 0.8739564795384813'\n",
      "81 - random_82 - lr - 0.712931323907177 - 0.7246686770194853 - 0.6656298278181824 - 1.060002036883446 - 0.6451242774773364 - 0.7616624273014461 - 0.8739484000636852'\n",
      "82 - random_57 - lr - 0.7025805863818697 - 0.729785824053246 - 0.8165501767597032 - 0.814450656922797 - 0.7971761150402533 - 0.7720971905204234 - 0.8722214951363031'\n",
      "83 - random_94 - lwr_k=500 - 0.6444930560067103 - 0.7078769280674969 - 0.7590927358475689 - 1.0883803870235569 - 0.6660103032833011 - 0.7731507712081147 - 0.8720471324178793'\n",
      "84 - random_68 - lwr_k=100 - 0.8729194820644571 - 0.679771923434792 - 0.7150891032068177 - 0.7803908610683841 - 0.844568597248877 - 0.7785475412817637 - 0.8711539919951831'\n",
      "85 - random_68 - lwr_k=50 - 0.8704963405937137 - 0.6747323055361832 - 0.717987676217212 - 0.7730185668752743 - 0.8579269262928374 - 0.7788310865602319 - 0.8711070665663787'\n",
      "86 - random_78 - lwr_k=200 - 0.6597410329163895 - 0.8287240230687366 - 0.7230206946928401 - 0.7271061464035851 - 0.9557155846703581 - 0.7788543871390581 - 0.8711032104286264'\n",
      "87 - random_68 - lwr_k=200 - 0.8764138090212554 - 0.6749450707736785 - 0.7183417134849974 - 0.7833218960150202 - 0.8435145254710615 - 0.7793066581445277 - 0.8710283616743741'\n",
      "88 - random_56 - lr - 0.7283564507824974 - 0.7599923856430841 - 0.8448803489759174 - 0.7264403286048348 - 0.8446334958308217 - 0.7808530704166705 - 0.8707724376139536'\n",
      "89 - random_66 - lwr_k=50 - 0.6892624947972512 - 0.7334803845712209 - 0.7751208662701632 - 0.9665964864394098 - 0.7448990154839867 - 0.7818573760141868 - 0.8706062296944682'\n",
      "90 - random_68 - lwr_k=500 - 0.8872401940192485 - 0.6869713029815864 - 0.7337239571158672 - 0.7862784113833154 - 0.8339839442584365 - 0.7856398629548829 - 0.8699802456449436'\n",
      "91 - random_68 - lwr_k=20 - 0.8920601360474424 - 0.6636541979628425 - 0.7390420306386182 - 0.7654920059020386 - 0.8772582531700382 - 0.7874993448308848 - 0.8696725100167689'\n",
      "92 - random_68 - lwr_k=1000 - 0.8990600287882415 - 0.6918262910379248 - 0.7441460007002225 - 0.7835829809422914 - 0.8199895790301568 - 0.7877225614382632 - 0.8696355687032895'\n",
      "93 - random_66 - lwr_k=20 - 0.7375631675874824 - 0.7731532755523655 - 0.75612417658635 - 0.9218870875423038 - 0.7567903833691495 - 0.7890966903105403 - 0.8694081567466792'\n",
      "94 - random_61 - lwr_k=100 - 0.8162137292841338 - 0.8720984294481455 - 0.7640963565916054 - 0.771990797700801 - 0.755898830582751 - 0.7960695027618578 - 0.8682541886184909'\n",
      "95 - random_61 - lwr_k=200 - 0.8102227589291406 - 0.8686208960883598 - 0.7724064290775463 - 0.7709558206849774 - 0.7593703502579954 - 0.7963241006435104 - 0.8682120538496322'\n",
      "96 - random_61 - lwr_k=50 - 0.8249580476931386 - 0.8844188843003656 - 0.7511081133096223 - 0.7701189352113095 - 0.767852352240201 - 0.7997025572919345 - 0.8676529349400147'\n",
      "97 - random_94 - lwr_k=1000 - 0.652813625799694 - 0.7287515366797074 - 0.7852184903189844 - 1.152133529343584 - 0.6857474749864146 - 0.8009103179273838 - 0.8674530561551601'\n",
      "98 - random_78 - lwr_k=500 - 0.6852450873624879 - 0.871199568928321 - 0.7439390677535455 - 0.7488624795533388 - 0.9931400413729172 - 0.8084710377601149 - 0.8662017920814383'\n",
      "99 - random_66 - lwr_k=100 - 0.6959380401588796 - 0.7459508841812658 - 0.8063520229298233 - 1.0034013912086455 - 0.7918006923362053 - 0.8086705925838235 - 0.8661687666834381'\n",
      "100 - random_61 - lwr_k=500 - 0.8266146537136833 - 0.8783858499348274 - 0.7813926752200316 - 0.7885935909001701 - 0.7741805171162104 - 0.8098422167271072 - 0.8659748683204741'\n",
      "101 - random_61 - lwr_k=20 - 0.8402911006890658 - 0.8918477479082622 - 0.7490780196169704 - 0.776937962456568 - 0.8044190700612022 - 0.8125257747356465 - 0.8655307519135551'\n",
      "102 - random_64 - lwr_k=200 - 0.7244558403018109 - 0.8222549182054023 - 0.8396676853635292 - 0.8438973295850228 - 0.8708881981752763 - 0.8202231705497615 - 0.8642568685986726'\n",
      "103 - random_64 - lwr_k=500 - 0.7288235283154217 - 0.8204672358976408 - 0.8397770597977249 - 0.8499183536771678 - 0.8675290803590378 - 0.8212934729459819 - 0.8640797385150248'\n",
      "104 - random_64 - lwr_k=100 - 0.7283921942246965 - 0.8270113488698483 - 0.8399790317867591 - 0.8447697810053142 - 0.8737975113253534 - 0.8227807169854254 - 0.8638336065227565'\n",
      "105 - random_64 - lwr_k=1000 - 0.7307094927701608 - 0.8189563088286599 - 0.8498184398931743 - 0.8548882998059102 - 0.8678121143028752 - 0.8244267475787229 - 0.8635611960921089'\n",
      "106 - random_57 - deep - 0.7537026506867269 - 0.8075889679882818 - 0.8937332763564171 - 0.8252163640772293 - 0.8647060104219331 - 0.8289795228058783 - 0.8628077329620837'\n",
      "107 - random_61 - lwr_k=1000 - 0.8695891355037876 - 0.8870837642167558 - 0.7963579371003944 - 0.8119571927238409 - 0.7943818006459501 - 0.8318835046305955 - 0.8623271373765502'\n",
      "108 - random_66 - lwr_k=200 - 0.7100487876327047 - 0.762794197662912 - 0.8643330900104073 - 1.0140530992761672 - 0.815968811891367 - 0.8334196798024828 - 0.8620729075087532'\n",
      "109 - random_64 - lwr_k=50 - 0.7319899766050794 - 0.8366131516776019 - 0.8554851359050536 - 0.8561831658089133 - 0.8880374482591938 - 0.8336516421649213 - 0.8620345188133649'\n",
      "110 - random_64 - lr - 0.740056089161282 - 0.8202506149323384 - 0.8705005046281438 - 0.8655382292340147 - 0.8721864965679426 - 0.8336953926458943 - 0.8620272783116322'\n",
      "111 - random_48 - deep - 0.6969288313401057 - 0.8679616872074055 - 0.9230728631636446 - 0.7904456971362386 - 0.9026173407047436 - 0.836194245870105 - 0.8616137297496982'\n",
      "112 - random_78 - lwr_k=1000 - 0.6972743195201776 - 0.9236538257007618 - 0.7636138001678001 - 0.7692169658765364 - 1.0448213371535207 - 0.8397100443507531 - 0.86103188134405'\n",
      "113 - random_30 - lwr_k=500 - 0.8318438898252938 - 0.7875361136231529 - 0.7925273716063322 - 0.9124047287239128 - 0.885337571992121 - 0.8419233164037151 - 0.8606655950820918'\n",
      "114 - random_30 - lwr_k=1000 - 0.831862369280653 - 0.7876213059617271 - 0.7959519288386105 - 0.909905538245446 - 0.8849909875823867 - 0.8420597898519432 - 0.8606430093592292'\n",
      "115 - random_30 - lwr_k=200 - 0.8308539099754638 - 0.7898111417724994 - 0.798201836914213 - 0.9171170192955973 - 0.8860320205131365 - 0.8443961911017329 - 0.8602563457861386'\n",
      "116 - random_30 - lwr_k=100 - 0.8283523767382397 - 0.7967829248791154 - 0.8115117902215436 - 0.91643673029914 - 0.8893747448755597 - 0.8484843383128831 - 0.8595797763791817'\n",
      "117 - random_64 - lwr_k=20 - 0.754903725239213 - 0.8553844944733288 - 0.870159532868757 - 0.8702760662785233 - 0.8930766351815981 - 0.8487511365933482 - 0.8595356225008921'\n",
      "118 - random_94 - lr - 0.6939292543029939 - 0.7600834866115233 - 0.8218095315522334 - 1.2547984286740765 - 0.7303987102806296 - 0.8521781796540662 - 0.8589684627653322'\n",
      "119 - random_30 - lwr_k=50 - 0.8349632436629775 - 0.8062740372945761 - 0.813402260003275 - 0.9249096844658039 - 0.8889753557450473 - 0.8536981237326411 - 0.8587169190682158'\n",
      "120 - random_30 - lr - 0.8357345203551669 - 0.7914260903200159 - 0.82802638529166 - 0.9303337516121293 - 0.9192666016926472 - 0.8609477434809885 - 0.8575171406159074'\n",
      "121 - random_55 - lwr_k=50 - 0.6551528395059042 - 0.683744808084417 - 0.715370129183054 - 1.1914743952637779 - 1.0594736413133108 - 0.8610038289934607 - 0.8575078587236584'\n",
      "122 - random_55 - lwr_k=100 - 0.6565997046486476 - 0.6789205579828315 - 0.7062538700609098 - 1.2178553313195404 - 1.0476868325128363 - 0.8614234927009726 - 0.8574384063260202'\n",
      "123 - random_55 - lwr_k=200 - 0.6595401824082604 - 0.6739784928186435 - 0.7121558175264476 - 1.244118019697759 - 1.029086184334491 - 0.8637352925491253 - 0.8570558141708253'\n",
      "124 - random_66 - lwr_k=500 - 0.7437101953018853 - 0.7822712879720813 - 0.9156879782153295 - 1.0356712480120642 - 0.8425537628557132 - 0.863958161941578 - 0.8570189303198061'\n",
      "125 - random_55 - lwr_k=500 - 0.6605687929375657 - 0.6802164112046355 - 0.7152036598692671 - 1.2679381523945918 - 1.0123181466953786 - 0.8672086186538438 - 0.8564809948060951'\n",
      "126 - random_55 - lwr_k=1000 - 0.6574876811015116 - 0.682687774054102 - 0.7185931454890873 - 1.2744559615724158 - 1.0096210345412622 - 0.8685283717861298 - 0.8562625817823163'\n",
      "127 - random_55 - lwr_k=20 - 0.6628621146426529 - 0.6886877995503711 - 0.7262156886739599 - 1.220879357417442 - 1.0773549802965168 - 0.8751590468246632 - 0.8551652358094735'\n",
      "128 - random_55 - lr - 0.6664847942931205 - 0.686380382426962 - 0.7231764213405966 - 1.2998731387225237 - 1.0083666417095587 - 0.8768151293862264 - 0.8548911618246883'\n",
      "129 - random_30 - lwr_k=20 - 0.8629478281758127 - 0.8313630369855632 - 0.8297080997298257 - 0.9423392288201177 - 0.9183463726626889 - 0.8769347984152874 - 0.8548713571552766'\n",
      "130 - random_97 - lwr_k=200 - 0.7615511459055463 - 0.6392712943402139 - 0.8104860534012683 - 1.147752494219447 - 1.0327187011671861 - 0.8783194063516546 - 0.8546422109621501'\n",
      "131 - random_66 - lwr_k=1000 - 0.7522837221544934 - 0.8074575664040949 - 0.9324272273860599 - 1.0484840547611007 - 0.863352486024969 - 0.8807802906795316 - 0.8542349460168566'\n",
      "132 - random_69 - lwr_k=100 - 0.8307350131577217 - 0.8909130551293047 - 0.8599144175063437 - 0.921051871968096 - 0.9013230912362239 - 0.8807833913688964 - 0.8542344328671444'\n",
      "133 - random_97 - lwr_k=500 - 0.7609123768814361 - 0.6427217808140735 - 0.8096876784134568 - 1.1508107124578018 - 1.0436705068432401 - 0.881523710336316 - 0.8541119135108501'\n",
      "134 - random_97 - lwr_k=100 - 0.7677539049776014 - 0.6436796463274621 - 0.8091393787183045 - 1.1613334357167697 - 1.0276496412478096 - 0.8818750292715897 - 0.8540537718561068'\n",
      "135 - random_69 - lwr_k=200 - 0.8292440530146761 - 0.8913465950174739 - 0.8653616058956917 - 0.9266872086779073 - 0.9010953906488038 - 0.8827423614029872 - 0.8539102324101265'\n",
      "136 - random_69 - lwr_k=500 - 0.8342734748022549 - 0.8961030054644021 - 0.8599751724243448 - 0.9293730162085628 - 0.8985207579666614 - 0.8836452954234936 - 0.8537608010165826'\n",
      "137 - random_97 - lwr_k=1000 - 0.7669510158151768 - 0.6436933578527803 - 0.8094121034374232 - 1.1537327631499419 - 1.06177542781452 - 0.8870756125819873 - 0.8531930994330226'\n",
      "138 - random_69 - lwr_k=50 - 0.8340899729265367 - 0.89917148863469 - 0.8661940434649342 - 0.9290003763287833 - 0.9100804014419364 - 0.8877029296191629 - 0.8530892813722009'\n",
      "139 - random_69 - lwr_k=1000 - 0.8425749315049751 - 0.9043949596764057 - 0.8603260604844507 - 0.9375157658953251 - 0.899920916933573 - 0.888943352688043 - 0.852883997106067'\n",
      "140 - random_97 - lwr_k=50 - 0.7729633348435879 - 0.6509710381191348 - 0.8151889571190193 - 1.1697255793764558 - 1.0365294319605294 - 0.8890393085050959 - 0.852868116863286'\n",
      "141 - random_78 - lr - 0.7356445002114835 - 0.9846294087136366 - 0.7946676546447875 - 0.800796730765066 - 1.1365579670308363 - 0.8904530272068901 - 0.8526341529734662'\n",
      "142 - random_56 - deep - 0.7636206532637849 - 0.8063023266821656 - 1.0517447173473038 - 0.8263460871375317 - 1.0286368151220209 - 0.895307456626832 - 0.8518307674780178'\n",
      "143 - random_61 - lr - 1.0301903100297451 - 0.9277164163861152 - 0.8428498859892487 - 0.8775308806917975 - 0.843377180022893 - 0.9043482539482431 - 0.8503345573790886'\n",
      "144 - random_66 - lr - 0.7729405371182196 - 0.8487915441134551 - 0.9484720072671523 - 1.0734880187811615 - 0.8999163478672254 - 0.9087016015918709 - 0.8496140985302748'\n",
      "145 - random_69 - lr - 0.8672510685002811 - 0.951960915807535 - 0.8628940739274568 - 0.9519803487877472 - 0.9162631560527863 - 0.9100698173738428 - 0.8493876651626913'\n",
      "146 - random_69 - lwr_k=20 - 0.8636058193747476 - 0.924832480512821 - 0.882052868297191 - 0.944218605415083 - 0.939001460060658 - 0.9107388545956214 - 0.8492769426047716'\n",
      "147 - random_54 - lwr_k=50 - 0.725041833904584 - 1.0230668238947653 - 1.15816625435046 - 0.6252642635148341 - 1.0291669136158605 - 0.9121333987452497 - 0.849046152014424'\n",
      "148 - random_97 - lwr_k=20 - 0.8016271777749011 - 0.6602876906373155 - 0.8461923768787684 - 1.2045412426134687 - 1.0561679533836343 - 0.9137257588275107 - 0.8487826238044861'\n",
      "149 - random_97 - lr - 0.791664001281184 - 0.6464949497678788 - 0.8199451714434843 - 1.1656202097978114 - 1.1467701018766077 - 0.9140588500008517 - 0.8487274987598216'\n",
      "150 - random_12 - lwr_k=200 - 0.9887850652775503 - 0.9239103930376429 - 0.8564253296929724 - 0.8590049799164088 - 0.957428036314149 - 0.9171188160660386 - 0.8482210885649086'\n",
      "151 - random_54 - lwr_k=100 - 0.7333849800309866 - 1.026364478817657 - 1.1743486322317183 - 0.6562176975545017 - 1.009320122541534 - 0.9199189596007463 - 0.8477576777940087'\n",
      "152 - random_12 - lwr_k=500 - 0.9902574251072039 - 0.9224539060944058 - 0.8628581538217345 - 0.8604600428718133 - 0.9635841152227508 - 0.9199302081836264 - 0.8477558162057011'\n",
      "153 - random_12 - lwr_k=100 - 0.9903270907408018 - 0.938546456171219 - 0.8553020265136936 - 0.8582053380514786 - 0.9609390692124339 - 0.9206729825426305 - 0.8476328904934851'\n",
      "154 - random_94 - deep - 0.7482111680623872 - 0.8513611184443616 - 0.8586207109310299 - 1.2998937916706719 - 0.8472179943041634 - 0.9210360591482144 - 0.8475728030645199'\n",
      "155 - random_12 - lwr_k=50 - 0.9987909658077507 - 0.9295578710262519 - 0.8636721388190348 - 0.8607599535637857 - 0.9723556130326735 - 0.9250353452205763 - 0.8469109396982939'\n",
      "156 - random_12 - lwr_k=1000 - 0.9939292277268996 - 0.9241841052235733 - 0.8758861664954988 - 0.8753872655308094 - 0.9640219644018525 - 0.9266883923385884 - 0.8466373680653413'\n",
      "157 - random_54 - lwr_k=200 - 0.743844125948293 - 0.9833305590062711 - 1.2326292868029225 - 0.6848182002477056 - 1.0525204985113266 - 0.9394129641604532 - 0.8445315104318837'\n",
      "158 - random_12 - lwr_k=20 - 1.018838644787453 - 0.9393860443349105 - 0.8833540031973826 - 0.876340121210443 - 0.9974504773822874 - 0.9430812567631519 - 0.8439244250157854'\n",
      "159 - random_64 - deep - 0.8491937992143411 - 0.9357797590630552 - 0.9426514809870867 - 0.9912043544301262 - 1.0095747766798282 - 0.9456699141645558 - 0.843496014286751'\n",
      "160 - random_54 - lwr_k=20 - 0.7442462836209548 - 1.066377684005701 - 1.3051814308714504 - 0.6215427409052413 - 1.0775045958340783 - 0.9629587099373982 - 0.8406347986859818'\n",
      "161 - random_66 - deep - 0.8162890110889296 - 0.972063220666579 - 0.9805959950237548 - 1.0972488123533417 - 0.9603943420876223 - 0.9653036754550189 - 0.8402467178351296'\n",
      "162 - random_54 - lwr_k=500 - 0.7508284118726716 - 1.0359384578290027 - 1.2628197563794767 - 0.6992646536149764 - 1.0968624729044136 - 0.9691271973861175 - 0.8396139426161177'\n",
      "163 - random_69 - deep - 0.9665308238421421 - 1.0276234974428102 - 0.8881358439427871 - 0.9998955381479596 - 0.9873153613822906 - 0.9739049694808966 - 0.8388232435581345'\n",
      "164 - random_84 - lwr_k=50 - 1.0835026680842577 - 0.9103926690865444 - 0.8179679592271069 - 0.791387412192636 - 1.3224424277849043 - 0.9851410516317539 - 0.8369637239937272'\n",
      "165 - random_84 - lwr_k=100 - 1.047916184223329 - 0.9299903474572806 - 0.8284913029410766 - 0.8462266359599697 - 1.2799135775713069 - 0.9865081117156285 - 0.8367374818888199'\n",
      "166 - random_54 - lwr_k=1000 - 0.7678346885354056 - 1.0467235496832417 - 1.2916432876727484 - 0.7175627406205621 - 1.1204056661105273 - 0.9888172435831265 - 0.8363553312720522'\n",
      "167 - random_12 - lr - 1.072472010245729 - 1.0117333078510955 - 0.9171108972440501 - 0.8997223723042337 - 1.0495733451777598 - 0.9901330579405712 - 0.8361375700972458'\n",
      "168 - random_17 - lwr_k=50 - 0.6480688193415984 - 0.6487446540810834 - 0.7503948941230804 - 2.1354267388255943 - 0.7844914332388061 - 0.9933544767639111 - 0.835604440219505'\n",
      "169 - random_23 - lwr_k=50 - 1.111163616425662 - 0.7524213859810756 - 0.9786744635512586 - 1.3510734801117386 - 0.8270451797865032 - 1.0040607856877806 - 0.833832595737104'\n",
      "170 - random_84 - lwr_k=200 - 1.0227142391942532 - 0.9640466694095824 - 0.8512934651242334 - 0.8789550633887734 - 1.3552804371454128 - 1.0144536477080146 - 0.8321126252638207'\n",
      "171 - random_17 - lwr_k=100 - 0.6587633408875312 - 0.664739867437857 - 0.7835980419499151 - 2.199809704318677 - 0.806324328864137 - 1.0225729660628966 - 0.8307689157248701'\n",
      "172 - random_23 - lwr_k=20 - 1.067906254704972 - 0.7269103965736564 - 1.0400038839953085 - 1.4565469625393879 - 0.8416173299223754 - 1.0265704435516756 - 0.8301073517365357'\n",
      "173 - random_30 - deep - 0.8512261978108312 - 1.0003587288878526 - 0.9537654623113864 - 1.1191648298710033 - 1.20942239582661 - 1.0267667856541662 - 0.8300748581022362'\n",
      "174 - random_17 - lwr_k=20 - 0.6653900286612288 - 0.6647866360233805 - 0.7740113234689764 - 2.310279209979543 - 0.7437201218603179 - 1.0315622126885566 - 0.82928123709091'\n",
      "175 - random_54 - lr - 0.7998797283862417 - 1.0942622361974843 - 1.3407122030414764 - 0.7500599728687023 - 1.175819747830397 - 1.0321293118887624 - 0.8291873848028802'\n",
      "176 - random_84 - lwr_k=20 - 1.2808476772380724 - 0.9974220153871255 - 0.8148095268650953 - 0.7664681129949077 - 1.3581858265819438 - 1.0435662557539953 - 0.8272946236255931'\n",
      "177 - random_23 - lwr_k=100 - 1.1227293704341756 - 0.7872047926135171 - 1.0618229078369568 - 1.411769831055748 - 0.874442799488804 - 1.0515741031150825 - 0.8259693620192314'\n",
      "178 - random_84 - lwr_k=500 - 1.0835343348208288 - 1.0626552427863054 - 0.8654870886466549 - 0.9000622377735117 - 1.3911389769812348 - 1.0605781463541608 - 0.8244792346143616'\n",
      "179 - random_17 - lwr_k=200 - 0.6989037570318053 - 0.6848605075429385 - 0.8335668005865241 - 2.308320790255174 - 0.8439587992798605 - 1.0738436994059712 - 0.8222838470958449'\n",
      "180 - random_78 - deep - 1.0660747612605284 - 1.1341138227344354 - 1.1031842579342257 - 0.8989165134008905 - 1.1891663094076044 - 1.0782956058601252 - 0.8215470772978121'\n",
      "181 - random_97 - deep - 0.8299770711812684 - 0.6974072558504303 - 1.1759559569662357 - 1.2027120771349333 - 1.5032163356608679 - 1.0817884181555821 - 0.82096903305912'\n",
      "182 - random_54 - deep - 0.8536718349202344 - 1.165765182368874 - 1.3685260085844162 - 0.8022464184545638 - 1.2396704430942418 - 1.0859603173004857 - 0.820278603095777'\n",
      "183 - random_23 - lwr_k=200 - 1.139150518009329 - 0.8084352465787056 - 1.1243779036702297 - 1.4362805242445191 - 0.9293486956156722 - 1.0874952301190044 - 0.8200245820641505'\n",
      "184 - random_84 - lwr_k=1000 - 1.1293781868573725 - 1.0837063133091973 - 0.8747365240308973 - 0.9346329365543193 - 1.457078559226649 - 1.095908687478768 - 0.8186321938837967'\n",
      "185 - random_53 - lwr_k=50 - 0.8455496771999828 - 0.8549515627222853 - 1.639729911053683 - 1.3094713653169285 - 0.9954477603264824 - 1.128972822838682 - 0.8131602327981036'\n",
      "186 - random_53 - lwr_k=100 - 0.8445557846377165 - 0.8513496768858163 - 1.6405720936180561 - 1.3116065113872726 - 1.0028101319745941 - 1.1301208996249492 - 0.8129702314135382'\n",
      "187 - random_53 - lwr_k=200 - 0.845589405469259 - 0.8528091387812693 - 1.6575315957416434 - 1.3040771009777496 - 1.0002261421109722 - 1.1319886089905389 - 0.8126611341739871'\n",
      "188 - random_53 - lwr_k=500 - 0.8529320965980446 - 0.8568433118334006 - 1.653295525043486 - 1.3146266890940181 - 1.0028075095129079 - 1.1360432942623577 - 0.8119901025628287'\n",
      "189 - random_53 - lwr_k=20 - 0.8613267157234268 - 0.8668630384405681 - 1.6524446767394938 - 1.3133224037905948 - 0.988760767260217 - 1.1364875875960936 - 0.8119165740762564'\n",
      "190 - random_82 - deep - 0.950664484910686 - 1.6410066046550862 - 0.7611415965111593 - 1.4131797297534512 - 0.9202217104743393 - 1.1372753790931567 - 0.811786198317552'\n",
      "191 - random_53 - lwr_k=1000 - 0.8621852120807929 - 0.8570861356065373 - 1.6689580319612416 - 1.3217833392394374 - 1.010007387521012 - 1.143945641411667 - 0.8106823007523183'\n",
      "192 - random_23 - lwr_k=500 - 1.1871761672516061 - 0.8431832051762075 - 1.2266359163910014 - 1.5019076269608347 - 0.9715637195760397 - 1.146066450938751 - 0.8103313166096499'\n",
      "193 - random_16 - lwr_k=500 - 1.1788705471942529 - 0.6459584682708542 - 0.7362468563179752 - 2.1973624718935785 - 0.9858096984084764 - 1.1488010690820483 - 0.8098787499871911'\n",
      "194 - random_16 - lwr_k=200 - 1.176513498694927 - 0.6436230721286403 - 0.7345048635567925 - 2.2087096310086474 - 0.9831360673615284 - 1.1492483136079723 - 0.8098047330919962'\n",
      "195 - random_12 - deep - 1.195018396064402 - 1.2073949767480208 - 1.0552378185475877 - 0.9957845198789906 - 1.2983462678333573 - 1.15036683512459 - 0.8096196230495643'\n",
      "196 - random_16 - lwr_k=1000 - 1.1822027089648146 - 0.6505209596967261 - 0.7363109938030387 - 2.1979523206450664 - 0.9944349740936607 - 1.1522359573291625 - 0.8093102919096604'\n",
      "197 - random_16 - lwr_k=100 - 1.186389228613563 - 0.6441778378613809 - 0.7372979742466264 - 2.218364058119413 - 0.9840441981441688 - 1.1540056404838381 - 0.8090174175534741'\n",
      "198 - random_16 - lwr_k=50 - 1.1984491215219855 - 0.6531129318540758 - 0.7376820703579047 - 2.2291549925887453 - 0.9905378683596293 - 1.1617389456184124 - 0.8077375914125648'\n",
      "199 - random_17 - lwr_k=500 - 0.7534694944854846 - 0.73413491427647 - 0.9424334932184252 - 2.4664975254345647 - 0.9254530276457172 - 1.1643113441661808 - 0.8073118713809638'\n",
      "200 - random_84 - lr - 1.21354785201592 - 1.1680345977951905 - 0.8979082335640184 - 1.0397010250004186 - 1.5326583896390964 - 1.1703742120080414 - 0.8063084948662832'\n",
      "201 - random_53 - lr - 0.8900358403917699 - 0.8673390991706454 - 1.7041631515587965 - 1.353937215349934 - 1.057988080881043 - 1.1746319085918318 - 0.8056038658243444'\n",
      "202 - random_16 - lr - 1.202775771373129 - 0.6538165434689964 - 0.7364433921137582 - 2.2440559768403143 - 1.072329496622448 - 1.1818321752997705 - 0.8044122550713767'\n",
      "203 - random_16 - lwr_k=20 - 1.228562798306975 - 0.6771424832054147 - 0.7549725067883886 - 2.3167875080518106 - 1.0196573620427891 - 1.1993739112949815 - 0.8015091791041259'\n",
      "204 - random_23 - lwr_k=1000 - 1.2283715197550558 - 0.8856377745724602 - 1.2912332505202184 - 1.572470727328969 - 1.0288732124004099 - 1.201287670011347 - 0.8011924609105494'\n",
      "205 - random_17 - lwr_k=1000 - 0.7775903256078349 - 0.7822919427184264 - 1.0396470703561906 - 2.5845667869177773 - 0.9833324900445487 - 1.2333926119425531 - 0.7958792418895863'\n",
      "206 - random_65 - lwr_k=50 - 1.0184536757750533 - 1.311618477872566 - 1.3288556285947144 - 1.727906169783209 - 0.8943442901413445 - 1.2562169254665103 - 0.7921019238363167'\n",
      "207 - random_55 - deep - 0.9666587145527917 - 0.8050322399927201 - 0.8475557844741634 - 2.1345425266504776 - 1.5550651557636457 - 1.2616937081969595 - 0.7911955417799269'\n",
      "208 - random_80 - lwr_k=100 - 1.2628635995215132 - 1.2544222968759056 - 1.3346293985319753 - 1.2049663671205981 - 1.3066853409746009 - 1.272710511988124 - 0.7893723117467413'\n",
      "209 - random_80 - lwr_k=50 - 1.186443107505546 - 1.2284640554226598 - 1.3004919172408336 - 1.2904818808248937 - 1.4052105705348388 - 1.282202957357932 - 0.7878013560539264'\n",
      "210 - random_53 - deep - 0.9578022238167204 - 0.9482777828800795 - 1.7989697825982096 - 1.4685437457762216 - 1.2933523804255336 - 1.293319304001128 - 0.7859616523225456'\n",
      "211 - random_16 - deep - 1.2451008906298384 - 0.7045353824141822 - 0.7456180275832848 - 2.27324836381407 - 1.5127147546294288 - 1.296177504483307 - 0.7854886333962495'\n",
      "212 - random_65 - lwr_k=20 - 1.086664446193059 - 1.4102389643908027 - 1.2583944450918079 - 1.8135745491503663 - 0.919581361290496 - 1.2976806446115363 - 0.7852398705825437'\n",
      "213 - random_80 - lwr_k=200 - 1.2785191064550376 - 1.2825950183100916 - 1.4388951308225717 - 1.2902903076681336 - 1.312499532585792 - 1.3205516067362197 - 0.7814548324021606'\n",
      "214 - random_65 - lwr_k=100 - 1.0756086136969838 - 1.450351752383567 - 1.2967609435180902 - 1.9130138455622885 - 0.9437366182664524 - 1.3358793856500328 - 0.7789181560658976'\n",
      "215 - random_68 - deep - 1.353345391473873 - 0.9247778654710154 - 1.106766298566266 - 1.7343130809325702 - 1.6021817925039992 - 1.3442347516257964 - 0.7775353818361102'\n",
      "216 - random_23 - lr - 1.4384387650053456 - 1.074248704735232 - 1.4676183922470867 - 1.7073367440826295 - 1.1356015958966625 - 1.3646266057176524 - 0.7741606244438072'\n",
      "217 - random_80 - lwr_k=20 - 1.2799046596579626 - 1.3655113573362292 - 1.4141737172693436 - 1.355452902508011 - 1.41523652506938 - 1.366046933205001 - 0.7739255668306226'\n",
      "218 - random_17 - lr - 0.910539040987059 - 0.9293057273067287 - 1.1704968255709087 - 2.8401736763475625 - 1.1291780405267784 - 1.395840937598844 - 0.7689947972564172'\n",
      "219 - random_65 - lwr_k=200 - 1.1266635231148336 - 1.5311925168230605 - 1.376019035284987 - 2.0515395254735505 - 0.9848778628279177 - 1.4140410157036922 - 0.7659827687227134'\n",
      "220 - random_80 - lwr_k=500 - 1.3915318097451979 - 1.4322844462476214 - 1.5513083613074543 - 1.3983411892225375 - 1.4176729027373034 - 1.4382223385233726 - 0.7619808719233707'\n",
      "221 - random_72 - lwr_k=200 - 0.7586371261842442 - 4.5061406920109315 - 0.7772809472872733 - 0.6750486523361214 - 0.7315762094300893 - 1.4899713081193375 - 0.7534166574120444'\n",
      "222 - random_72 - lwr_k=100 - 0.7603509215692738 - 4.515702217929544 - 0.7810409773715962 - 0.6756979347779852 - 0.7355645209437168 - 1.4939062468229256 - 0.7527654433026706'\n",
      "223 - random_72 - lwr_k=500 - 0.760711206716857 - 4.523865937317589 - 0.7790700821564773 - 0.6761018962341689 - 0.7298164878550462 - 1.4941488796930553 - 0.7527252886877379'\n",
      "224 - random_74 - lwr_k=50 - 1.2274665210158275 - 2.201059326304482 - 1.3803492837002795 - 1.096697222048821 - 1.5803770045251069 - 1.4972344358901086 - 0.7522146434446608'\n",
      "225 - random_74 - lwr_k=100 - 1.2492148512022254 - 2.0603089442321645 - 1.4846908240600714 - 1.1371942938636899 - 1.5588496644549872 - 1.498083887638619 - 0.7520740631191382'\n",
      "226 - random_72 - lwr_k=1000 - 0.7710647155975218 - 4.560453401346181 - 0.7867462359078239 - 0.6780893391524504 - 0.730457217495313 - 1.505600407495541 - 0.7508301139364603'\n",
      "227 - random_72 - lwr_k=50 - 0.7667549222982991 - 4.573643812989846 - 0.7902194515059121 - 0.6819074057357503 - 0.7338879865698106 - 1.5095210481237264 - 0.7501812660922663'\n",
      "228 - random_72 - lr - 0.7832953701468782 - 4.6180951654993905 - 0.7951437145014333 - 0.6899664107543177 - 0.7358390946363791 - 1.52470942663975 - 0.7476676598754463'\n",
      "229 - random_84 - deep - 1.5370069807648599 - 1.5717346632768094 - 1.4001075682943607 - 1.4605798016338623 - 1.7073676160228815 - 1.535363229154189 - 0.7459045050698503'\n",
      "230 - random_65 - lwr_k=500 - 1.2346634026228087 - 1.7335397603135783 - 1.490779153746139 - 2.165916882566589 - 1.0956770075147304 - 1.5441029207492205 - 0.7444581265267746'\n",
      "231 - random_72 - lwr_k=20 - 0.7977688094719472 - 4.700166910197275 - 0.8130342337033893 - 0.687270406333267 - 0.7567873992737388 - 1.5512514894489804 - 0.7432750715544401'\n",
      "232 - random_61 - deep - 1.6742533606832122 - 1.8312583411272028 - 1.1818964841184676 - 1.3535550191417123 - 1.7229222443559087 - 1.5528181352940027 - 0.7430157990422879'\n",
      "233 - random_80 - lwr_k=1000 - 1.5195565998112497 - 1.5052480897056078 - 1.6854227149877012 - 1.5770088888789782 - 1.5479008914161563 - 1.5670162226113034 - 0.7406660813161787'\n",
      "234 - random_74 - lwr_k=200 - 1.2897867998952712 - 2.2054412939254493 - 1.570162853540625 - 1.2171935583939755 - 1.6336707910642019 - 1.5832848025352342 - 0.7379737067751779'\n",
      "235 - random_96 - lwr_k=50 - 1.6346259911198169 - 0.8209169248593207 - 1.2656660256709933 - 3.0477600697175316 - 1.188019779104096 - 1.5913231068317557 - 0.7366434046872288'\n",
      "236 - random_74 - lwr_k=20 - 1.222128324102777 - 2.472168988534414 - 1.4577569634260852 - 1.0179041551023758 - 1.7909605217918927 - 1.5922361340252447 - 0.7364923029203576'\n",
      "237 - random_96 - lwr_k=100 - 1.6169665048716533 - 0.8676669362268067 - 1.225197371406033 - 3.0577428316794615 - 1.278308807555249 - 1.6091011752647368 - 0.733701216797386'\n",
      "238 - random_9 - lwr_k=100 - 1.94199023017489 - 1.2103279892169847 - 1.1861313830400726 - 2.126652102966395 - 1.6300310068158153 - 1.6190177419023373 - 0.7320600710013758'\n",
      "239 - random_96 - lwr_k=20 - 1.8109284824358378 - 0.7947355164584828 - 1.4201744620975298 - 2.8956160864336775 - 1.1760930076635694 - 1.6194444981844034 - 0.7319894448155367'\n",
      "240 - random_9 - lwr_k=50 - 1.9744203240245162 - 1.264220252983681 - 1.1522675785803067 - 2.2094340369535646 - 1.5678140209701574 - 1.6336283047114375 - 0.7296420906047556'\n",
      "241 - random_72 - deep - 0.8173410930102638 - 4.964104306459305 - 0.867748778948304 - 0.7645192393532034 - 0.8168967886382305 - 1.6463775783691845 - 0.7275321450494319'\n",
      "242 - random_65 - lwr_k=1000 - 1.3967408786094102 - 1.9055678223316928 - 1.5949991339290688 - 2.272470159555706 - 1.1593510410315095 - 1.6658227950905289 - 0.7243140517308981'\n",
      "243 - random_96 - lwr_k=200 - 1.6103748098100483 - 0.9231515785321579 - 1.3197453094863065 - 3.1459171482395147 - 1.3553753746562924 - 1.6708298735741445 - 0.7234854034593763'\n",
      "244 - random_9 - lwr_k=200 - 2.069017840941759 - 1.308606702706557 - 1.2430416764513617 - 2.126589558727097 - 1.7391922570965666 - 1.697287866816087 - 0.7191067282619308'\n",
      "245 - random_9 - lwr_k=20 - 2.0117513322623024 - 1.465613229110777 - 1.287353640498802 - 2.2070933267370045 - 1.6243291260670674 - 1.7192321248070346 - 0.7154750553186107'\n",
      "246 - random_74 - lwr_k=500 - 1.3894661553170988 - 2.4259922355555923 - 1.7443323265825013 - 1.3065592734629028 - 1.7684433637668429 - 1.7269957825207487 - 0.7141902059665968'\n",
      "247 - random_96 - lwr_k=500 - 1.7088608337729398 - 0.9630576964255696 - 1.445636558696936 - 3.199160093004403 - 1.3769264125178917 - 1.7386456317446066 - 0.7122622099396863'\n",
      "248 - random_10 - lwr_k=50 - 1.0961149376295776 - 1.6942529598565355 - 2.0936927837352126 - 1.7591582758220818 - 2.107853604334075 - 1.7501416256888547 - 0.7103596762481339'\n",
      "249 - random_10 - lwr_k=20 - 1.1267186197444459 - 1.6668460856682084 - 2.0775353010742976 - 1.83903965583817 - 2.1713430739460726 - 1.7762186342600799 - 0.7060440522470893'\n",
      "250 - random_96 - lwr_k=1000 - 1.7778104873777583 - 1.0065483520586318 - 1.5430280102607323 - 3.253185830402634 - 1.4376966931175406 - 1.8035694003147946 - 0.7015176272888628'\n",
      "251 - random_10 - lwr_k=100 - 1.1155325153015163 - 1.7420428594352164 - 2.2076215095949756 - 1.8254635033273738 - 2.190651707001121 - 1.816182871666271 - 0.6994301562680885'\n",
      "252 - random_79 - lwr_k=20 - 1.382448680937587 - 1.3656594582791353 - 1.576858444541824 - 2.3102189497853334 - 2.526577953520988 - 1.832258610238306 - 0.6967696960766329'\n",
      "253 - random_74 - lwr_k=1000 - 1.4577711473521893 - 2.58239059057598 - 1.8482935143171877 - 1.3755848967012756 - 1.916544092403254 - 1.8361546154678206 - 0.6961249252766861'\n",
      "254 - random_80 - lr - 1.797235848762979 - 1.798481873919068 - 1.9402749982794463 - 1.8569625402050867 - 1.8464507611195706 - 1.84787093503758 - 0.6941859287157479'\n",
      "255 - random_9 - lwr_k=500 - 2.3171353999192927 - 1.4321376687886997 - 1.3768950575081096 - 2.2739235485396083 - 1.9099192963637377 - 1.8620047880116397 - 0.6918468415863526'\n",
      "256 - random_79 - lwr_k=50 - 1.4099338864035973 - 1.4458551232525865 - 1.5694239959592364 - 2.4319988980759164 - 2.4661859981073104 - 1.8645899098453522 - 0.6914190159099248'\n",
      "257 - random_10 - lwr_k=200 - 1.1327191270614447 - 1.748505184595942 - 2.2887041928944 - 1.907267239837287 - 2.265317781170995 - 1.868414860614111 - 0.6907860042937579'\n",
      "258 - random_79 - lwr_k=100 - 1.4636314175808247 - 1.4768767194729164 - 1.6422924826272582 - 2.4624356332369195 - 2.444094956477953 - 1.8977784545309189 - 0.6859264656577146'\n",
      "259 - random_65 - lr - 1.714170746052081 - 2.1779843695576386 - 1.815246687870829 - 2.4930304338461964 - 1.3935580208447218 - 1.9188036520256235 - 0.6824468929648955'\n",
      "260 - random_10 - lwr_k=500 - 1.2011458443396246 - 1.7950328760908105 - 2.354993353254879 - 2.0211762652119623 - 2.3456410290077097 - 1.943506412174024 - 0.6783587007055226'\n",
      "261 - random_79 - lwr_k=200 - 1.5092296014344937 - 1.5579733545882248 - 1.7640384425847904 - 2.5223420075931 - 2.4384820996018464 - 1.958325888755821 - 0.6759061460482414'\n",
      "262 - random_70 - lwr_k=1000 - 1.9188698243159883 - 3.2650200103847995 - 1.0995576141726076 - 1.4278242339306046 - 2.094984239274331 - 1.9613806637285252 - 0.6754005949550635'\n",
      "263 - random_70 - lwr_k=500 - 1.926396857829009 - 3.2582330824701904 - 1.100388643679857 - 1.4258111006655527 - 2.095839383336377 - 1.961463351916163 - 0.6753869104434296'\n",
      "264 - random_70 - lwr_k=200 - 1.91961207032144 - 3.2692351389722574 - 1.1006352896362377 - 1.4314286765357993 - 2.1029597859594467 - 1.964903457202376 - 0.674817588970119'\n",
      "265 - random_70 - lwr_k=100 - 1.921222233799165 - 3.283513824213381 - 1.102965736381166 - 1.4369694859340156 - 2.1351701713279 - 1.976096888101332 - 0.6729651280595961'\n",
      "266 - random_92 - lwr_k=20 - 1.7613944944696973 - 1.7704703156709423 - 2.558950829340538 - 1.8845148330834118 - 1.9130251958686635 - 1.9776276644342146 - 0.6727117916746201'\n",
      "267 - random_92 - lwr_k=50 - 1.7742986608374078 - 1.8097891958288828 - 2.4586091690129104 - 1.948530988677676 - 1.944538456438371 - 1.9871132388591468 - 0.6711419730913222'\n",
      "268 - random_70 - lwr_k=50 - 1.9520377948503036 - 3.327871740770867 - 1.1038967440724803 - 1.4667587827801447 - 2.157434116504072 - 2.001730887926966 - 0.6687228199517423'\n",
      "269 - random_9 - lwr_k=1000 - 2.4569533842461913 - 1.5623202505465814 - 1.530612098522962 - 2.442316402667281 - 2.01880194901971 - 2.002202343586543 - 0.6686447962261934'\n",
      "270 - random_96 - lr - 1.9673349777054217 - 1.1032222449799802 - 1.8605477975970333 - 3.4132645810193196 - 1.6680673111659015 - 2.002391466096251 - 0.6686134973277862'\n",
      "271 - random_10 - lwr_k=1000 - 1.2517858544308422 - 1.866738524519598 - 2.401904283200793 - 2.066551993268222 - 2.4948396423703745 - 2.0162702180736543 - 0.6663166282304498'\n",
      "272 - random_92 - lwr_k=100 - 1.8208649830708752 - 1.8397697226873675 - 2.46482732587385 - 1.9972600906807443 - 2.0019101181298793 - 2.024886495492524 - 0.6648906742707781'\n",
      "273 - random_70 - lr - 1.9355581588203974 - 3.611295698276257 - 1.1010465091470465 - 1.4340702974130546 - 2.114760662206272 - 2.0394969694763163 - 0.6624727085743345'\n",
      "274 - random_79 - lwr_k=500 - 1.6145450717120677 - 1.6524343964718402 - 1.9108525735623922 - 2.6141563282209623 - 2.4256097931013993 - 2.0434354548476636 - 0.6618209075078921'\n",
      "275 - random_70 - lwr_k=20 - 1.9959322929191172 - 3.3672863545055822 - 1.1349916162749818 - 1.5242336561465402 - 2.196313902919653 - 2.0438825146166444 - 0.6617469211891147'\n",
      "276 - random_18 - lwr_k=50 - 1.0659624512791226 - 2.492619800441927 - 2.298170263064776 - 2.2797090677796654 - 2.126390572394185 - 2.052514327665076 - 0.6603183961547882'\n",
      "277 - random_18 - lwr_k=100 - 1.0822763132133866 - 2.5000510784877488 - 2.3016018788198584 - 2.2802825613322084 - 2.09973820336805 - 2.052736296038052 - 0.6602816614183145'\n",
      "278 - random_18 - lwr_k=20 - 1.082513340027524 - 2.4757751450533596 - 2.312008906734542 - 2.274045774574512 - 2.1506983919925644 - 2.0589508565196257 - 0.6592531804751507'\n",
      "279 - random_18 - lwr_k=200 - 1.083401423933031 - 2.5194631773240537 - 2.319932793390755 - 2.280135775755314 - 2.0969042916494645 - 2.059914416000796 - 0.6590937158489834'\n",
      "280 - random_80 - deep - 2.0228701070860877 - 1.9909643232669507 - 2.0775480928851837 - 2.1121834073468158 - 2.1014657331443174 - 2.0609952194998145 - 0.6589148480285205'\n",
      "281 - random_74 - lr - 1.681555878901095 - 2.801946620936314 - 2.1145918020299987 - 1.544936976916536 - 2.1701664256294797 - 2.062676311917182 - 0.6586366348815639'\n",
      "282 - random_92 - lwr_k=200 - 1.871540391222618 - 1.878513554802319 - 2.5040846842069473 - 2.0370429210563 - 2.0274471718664064 - 2.0636870054045544 - 0.6584693697959276'\n",
      "283 - random_18 - lwr_k=500 - 1.0788957503347427 - 2.5471512762425 - 2.3419366998266433 - 2.2784006818328186 - 2.093501277161575 - 2.0679247959538523 - 0.6577680351103943'\n",
      "284 - random_18 - lwr_k=1000 - 1.0826632966030223 - 2.5614977281482996 - 2.3598833984772214 - 2.3037487195055455 - 2.1086156898824933 - 2.0832281427799066 - 0.6552354021713652'\n",
      "285 - random_13 - lwr_k=20 - 1.8597497507829879 - 2.0754923676919272 - 2.261303386309157 - 1.7076831375664572 - 2.5290777277378513 - 2.0866368354599305 - 0.6546712793387207'\n",
      "286 - random_13 - lwr_k=50 - 1.8679265404229433 - 2.0874566687975324 - 2.360650574721946 - 1.735634486762326 - 2.518305360696623 - 2.1139667437055114 - 0.6501483062511895'\n",
      "287 - random_23 - deep - 2.9531603625274547 - 1.561908031500811 - 2.156712887468279 - 2.2869796610955584 - 1.6361349933690847 - 2.11900762728194 - 0.6493140635447021'\n",
      "288 - random_79 - lwr_k=1000 - 1.709012681314362 - 1.7413453689100942 - 2.0299991024805477 - 2.708650501522465 - 2.4151012033736063 - 2.1207405473883307 - 0.6490272731513961'\n",
      "289 - random_92 - lwr_k=500 - 1.9146894868707278 - 1.9601111788599133 - 2.6539466714234172 - 2.050875035056749 - 2.079541328353627 - 2.131792823790315 - 0.6471981726555971'\n",
      "290 - random_70 - deep - 2.2117071572544025 - 3.616942878378667 - 1.1186342611449944 - 1.4843236805232398 - 2.2460330609668206 - 2.135688093856662 - 0.6465535236740784'\n",
      "291 - random_13 - lwr_k=100 - 1.9062918458828602 - 2.1795870440129934 - 2.4059338103714136 - 1.761542814237072 - 2.5554119160120523 - 2.161729093978221 - 0.642243858752152'\n",
      "292 - random_92 - lwr_k=1000 - 1.9431039962536394 - 2.017348751535624 - 2.7203345160351677 - 2.110962784005353 - 2.1246088486821275 - 2.18323009476011 - 0.6386855428215745'\n",
      "293 - random_13 - lwr_k=200 - 1.9112258946953373 - 2.2564537398607287 - 2.432061975975445 - 1.7898273358143244 - 2.6154169303435544 - 2.2009731233243155 - 0.6357491538675364'\n",
      "294 - random_74 - deep - 1.8599767809100125 - 2.9913473550083087 - 2.26366183743095 - 1.6513905836081848 - 2.326351714574826 - 2.2185881853503577 - 0.6328339429404369'\n",
      "295 - random_98 - lwr_k=100 - 1.8570097930675342 - 2.412537625535303 - 2.370984685209977 - 2.1445358241920527 - 2.3598757733089006 - 2.2289693982321723 - 0.6311159001872999'\n",
      "296 - random_3 - lwr_k=20 - 0.9508861171729086 - 1.4136678603158506 - 3.524382413050746 - 2.617118512429253 - 2.645874988744379 - 2.230170805074387 - 0.6309170729257634'\n",
      "297 - random_98 - lwr_k=50 - 1.8460325317313089 - 2.379625941063045 - 2.336618815721511 - 2.1405927416820125 - 2.505487865732243 - 2.2416451282842 - 0.629018125640274'\n",
      "298 - random_3 - lwr_k=50 - 0.9416653229304187 - 1.4119506708335632 - 3.6057531997971335 - 2.6244797142853837 - 2.6395480165865504 - 2.2444601544641083 - 0.6285522518606035'\n",
      "299 - random_13 - lwr_k=500 - 1.942030651755061 - 2.314723550821297 - 2.4669802428020726 - 1.8567327366981903 - 2.650835608298503 - 2.2462363569958237 - 0.628258298577747'\n",
      "300 - random_92 - lr - 2.0547649573720994 - 2.083324088622653 - 2.8140253412877008 - 2.178171477356736 - 2.1892200433907907 - 2.2638611781860396 - 0.6253414723959838'\n",
      "301 - random_98 - lwr_k=200 - 1.8944097982327284 - 2.5045118341294623 - 2.414234366539767 - 2.108117124723602 - 2.4262516363336775 - 2.2694905721651564 - 0.6244098337955953'\n",
      "302 - random_3 - lwr_k=100 - 0.9462741258827675 - 1.4076675559970524 - 3.748033938646753 - 2.6363118788453868 - 2.6830767302546183 - 2.2840455205290966 - 0.6220010573317682'\n",
      "303 - random_18 - deep - 1.2485689190854288 - 2.803332379562785 - 2.5502324123891715 - 2.352928801238904 - 2.4734418636964333 - 2.285647553942279 - 0.6217359283934463'\n",
      "304 - random_13 - lwr_k=1000 - 2.0015352406965135 - 2.351472945906581 - 2.521149536454494 - 1.936073713918885 - 2.704004202623633 - 2.3028211901178 - 0.618893771076469'\n",
      "305 - random_10 - lr - 1.352409389966194 - 2.1001888259066144 - 2.617045083952324 - 2.2469602141032716 - 3.2344109866576725 - 2.3100830266226184 - 0.6176919708076132'\n",
      "306 - random_79 - lr - 2.040626283626419 - 1.8762929611182426 - 2.1908456687569053 - 2.99402767618109 - 2.46489046787496 - 2.313263756453191 - 0.6171655747695031'\n",
      "307 - random_98 - lwr_k=20 - 1.818282100932094 - 2.587725073063546 - 2.584527802017795 - 2.0688006031258377 - 2.5469525833123026 - 2.3212333553304934 - 0.6158466431098519'\n",
      "308 - random_98 - lwr_k=500 - 1.9617757567932934 - 2.5902906533817807 - 2.4537717884813426 - 2.1948640038588043 - 2.5369722776096904 - 2.3475202169671014 - 0.6114962893995624'\n",
      "309 - random_52 - lwr_k=20 - 1.6922473139072285 - 2.8919638223885915 - 1.598828714132891 - 2.8175795990253154 - 2.7373563771957063 - 2.3475837735013316 - 0.611485771087855'\n",
      "310 - random_3 - lwr_k=200 - 0.9754030415744371 - 1.4334525147435382 - 3.8632793391217235 - 2.6990277106868605 - 2.7811470614987206 - 2.350226656547974 - 0.6110483861985226'\n",
      "311 - random_92 - deep - 2.194671611898431 - 2.2373364489160483 - 2.8177102943710235 - 2.2073630978194596 - 2.332420898414001 - 2.3578713420783406 - 0.6097832263593663'\n",
      "312 - random_52 - lwr_k=100 - 1.71347833649609 - 2.8689035000662355 - 1.6062758440487768 - 2.766911346493175 - 2.8923245721920106 - 2.369562627105905 - 0.6078483727308974'\n",
      "313 - random_31 - lwr_k=100 - 2.149769446724674 - 2.3874542540028907 - 2.678823365052875 - 2.323683713917475 - 2.309932095408687 - 2.3699117742156015 - 0.6077905905032166'\n",
      "314 - random_31 - lwr_k=20 - 2.0425377067693122 - 2.5066085180955415 - 2.668580357819716 - 2.3042563822327327 - 2.3404080006588974 - 2.3724580935297985 - 0.6073691864638437'\n",
      "315 - random_31 - lwr_k=50 - 2.0694149252135174 - 2.496653346409852 - 2.66753926828232 - 2.303278437771552 - 2.331027922816642 - 2.373564190765111 - 0.6071861325003048'\n",
      "316 - random_52 - lwr_k=50 - 1.7121786554461604 - 2.9319302510565235 - 1.6042035169083613 - 2.8546235937592686 - 2.801234998297298 - 2.3808221358075765 - 0.6059849762504239'\n",
      "317 - random_31 - lwr_k=200 - 2.2193779020666238 - 2.3788536060582666 - 2.7091165493177494 - 2.3392961975073345 - 2.354440922703738 - 2.4001962797759755 - 0.6027786452603741'\n",
      "318 - random_9 - lr - 2.8752546625028996 - 1.9583283210833105 - 1.9326296687220956 - 2.916584569092214 - 2.361621408223875 - 2.40888534936275 - 0.6013406445344469'\n",
      "319 - random_52 - lwr_k=200 - 1.7090413846325403 - 2.8818162718237774 - 1.6363424297952471 - 2.9170990536867873 - 2.912412444521831 - 2.4113185202406995 - 0.6009379660366108'\n",
      "320 - random_17 - deep - 2.7658983012111813 - 1.9055874653508444 - 1.525558185528436 - 3.8633726235532664 - 2.0618496413593173 - 2.4244350265460684 - 0.5987672452364375'\n",
      "321 - random_98 - lwr_k=1000 - 2.054636213092652 - 2.642969152061729 - 2.502274061713154 - 2.260878202364494 - 2.677488826983114 - 2.4276331042981165 - 0.5982379780248364'\n",
      "322 - random_52 - lwr_k=500 - 1.7287037288343383 - 2.903508388525331 - 1.7012953217248667 - 2.967582219611415 - 2.9304380153053073 - 2.4462788052834954 - 0.5951522009707308'\n",
      "323 - random_3 - lwr_k=500 - 1.0458660461738565 - 1.5368305972956324 - 4.000456803766733 - 2.7567357789888067 - 2.930938097961005 - 2.4539267423689037 - 0.593886502846112'\n",
      "324 - random_13 - lr - 2.140217395292584 - 2.5549151432946715 - 2.6437101995232575 - 2.1511430855534432 - 2.8014905020082153 - 2.4582725328421247 - 0.5931672946739586'\n",
      "325 - random_31 - lwr_k=500 - 2.274610405441417 - 2.4559982873580224 - 2.8084570449646065 - 2.4166324105745307 - 2.432892486280245 - 2.477695048750797 - 0.5899529583520913'\n",
      "326 - random_11 - lwr_k=20 - 2.1935473885512673 - 2.564128340077125 - 2.3851822153901043 - 2.349105632604443 - 2.961897586083006 - 2.490749252789962 - 0.5877925481151548'\n",
      "327 - random_52 - lwr_k=1000 - 1.738744311386009 - 2.929046802834397 - 1.7876731863867632 - 3.058916361189046 - 3.0004008281668026 - 2.502921590388234 - 0.5857780826850254'\n",
      "328 - random_3 - lwr_k=1000 - 1.0943981370777305 - 1.662170309730421 - 4.095574154851104 - 2.78148621792382 - 3.0094249782265154 - 2.528374601373424 - 0.5815657273910313'\n",
      "329 - random_31 - lwr_k=1000 - 2.3336208650956483 - 2.5365890451258113 - 2.865585837501552 - 2.4371460309189152 - 2.4731183130721357 - 2.5291926984776447 - 0.5814303361137488'\n",
      "330 - random_11 - lwr_k=50 - 2.313893307796894 - 2.5163202863715974 - 2.4554329469512344 - 2.445160214562457 - 2.954645105730308 - 2.537065329462708 - 0.5801274521906292'\n",
      "331 - random_11 - lwr_k=100 - 2.2963931183141844 - 2.5169893341735157 - 2.5338847814982746 - 2.560214838697782 - 2.958689876474624 - 2.573200199077501 - 0.5741472988245604'\n",
      "332 - random_34 - lwr_k=50 - 2.406046758544815 - 2.5531906208235635 - 2.713291496093819 - 2.9178700029165503 - 2.2920812207955454 - 2.5764761312431625 - 0.5736051472414405'\n",
      "333 - random_34 - lwr_k=100 - 2.439287971045109 - 2.6069657077106516 - 2.7470832702808883 - 2.7703820345157495 - 2.3201267098080876 - 2.5767581260875567 - 0.573558478402286'\n",
      "334 - random_34 - lwr_k=20 - 2.512921446937677 - 2.4493577784426637 - 2.6663986889535796 - 2.9344358998470157 - 2.3756812258761495 - 2.5877371194063423 - 0.5717415059169474'\n",
      "335 - random_98 - lr - 2.274353891732786 - 2.816867770358871 - 2.6054967748185747 - 2.381749866243691 - 2.867032663299933 - 2.589091265070232 - 0.5715174010886642'\n",
      "336 - random_31 - lr - 2.4041150520001233 - 2.6251188835142183 - 2.9216171847705805 - 2.485353791019438 - 2.5402480532483267 - 2.595274030885254 - 0.5704941820153848'\n",
      "337 - random_65 - deep - 2.5654943534935235 - 2.7269697204010495 - 2.442199824037493 - 2.8682097825671122 - 2.409717077836853 - 2.602527114777529 - 0.5692938304489505'\n",
      "338 - random_11 - lwr_k=200 - 2.3277558529027376 - 2.505176815971733 - 2.544536722294158 - 2.699401680784571 - 2.9868894416260603 - 2.6127118059044623 - 0.5676083111076018'\n",
      "339 - random_11 - lwr_k=500 - 2.372536797124953 - 2.473820142400974 - 2.5948025735390674 - 2.7197973930515 - 2.98787000304551 - 2.629722970230662 - 0.5647930422913439'\n",
      "340 - random_34 - lwr_k=200 - 2.5319957823346013 - 2.651590662291216 - 2.8239206568708037 - 2.748194294332981 - 2.4087796155682604 - 2.6328877639753294 - 0.5642692836015564'\n",
      "341 - random_52 - lr - 1.824730842148998 - 2.989815090794728 - 2.0891806657123912 - 3.183268773083267 - 3.1953307039170964 - 2.6564140567965273 - 0.5603757912296286'\n",
      "342 - random_11 - lwr_k=1000 - 2.4019135368629847 - 2.4927585443101123 - 2.6421456827082266 - 2.755383862076258 - 3.014341992550161 - 2.6612647958257294 - 0.5595730164128757'\n",
      "343 - random_34 - lwr_k=500 - 2.5212490177403777 - 2.6540634918011183 - 2.8551415929314135 - 2.870619549762807 - 2.5068513148374856 - 2.681565710158914 - 0.5562133092248314'\n",
      "344 - random_9 - deep - 3.0102009588538103 - 2.3318857054272453 - 2.3466203056076957 - 3.1566305106670214 - 2.6111832947701643 - 2.6913000117791515 - 0.5546023276360059'\n",
      "345 - random_11 - lr - 2.5300701388673508 - 2.499010282430703 - 2.682573023440988 - 2.8544033073051227 - 2.91160369918882 - 2.695494933219375 - 0.5539080873972801'\n",
      "346 - random_31 - deep - 2.5595165927205836 - 2.781088881152541 - 2.9597198615573515 - 2.601915436358912 - 2.6845382503415527 - 2.717346152028606 - 0.5502918122009377'\n",
      "347 - random_34 - lwr_k=1000 - 2.551368254238608 - 2.697904906318519 - 2.8562962269011467 - 2.97695974147399 - 2.627310021227495 - 2.7419437423190067 - 0.546221024871577'\n",
      "348 - random_10 - deep - 1.575821356690193 - 2.7637810550511586 - 3.277126548226609 - 2.642548733668161 - 3.6474442981351816 - 2.781218863469722 - 0.5397211746358439'\n",
      "349 - random_34 - lr - 2.6330767309160086 - 2.745203865866611 - 2.9370712852294654 - 3.074662076172815 - 2.670595043347627 - 2.8120965526156994 - 0.5346110600617635'\n",
      "350 - random_3 - lr - 1.2144844739267944 - 2.3478673243885355 - 4.461116849249627 - 3.0560493083685416 - 3.1820569195756883 - 2.852095073833936 - 0.5279914902708409'\n",
      "351 - random_59 - lwr_k=50 - 2.6403510972059423 - 2.96181544901536 - 2.7334394530510355 - 3.0393101317024565 - 2.919286327824984 - 2.8588286343962417 - 0.5268771172208877'\n",
      "352 - random_52 - deep - 2.0028709184212095 - 3.1432921992870035 - 2.45315157118764 - 3.240050268124261 - 3.4706064763744755 - 2.861934966378571 - 0.5263630338858174'\n",
      "353 - random_35 - lwr_k=100 - 3.2248353601553323 - 3.1039143977872254 - 2.6779896108242744 - 2.5104398019524408 - 2.840256318193828 - 2.8715472266639974 - 0.5247722491759084'\n",
      "354 - random_35 - lwr_k=200 - 3.2427307073110816 - 3.0787543495068843 - 2.69465613975091 - 2.515163173174879 - 2.827091186314972 - 2.8717384549639924 - 0.5247406017789731'\n",
      "355 - random_59 - lwr_k=100 - 2.6899897324215893 - 2.937662502732561 - 2.872455089832793 - 2.9946351653478636 - 2.9204720820407415 - 2.883028704498329 - 0.5228721178332368'\n",
      "356 - random_35 - lwr_k=500 - 3.2404062377466536 - 3.0783541698068237 - 2.706911028667437 - 2.5612925775189175 - 2.8339903916609126 - 2.884247376527223 - 0.5226704332633625'\n",
      "357 - random_35 - lwr_k=50 - 3.272929739657237 - 3.125844751099003 - 2.695186936822825 - 2.496516145759279 - 2.8625033839020757 - 2.890659585218137 - 0.5216092424580356'\n",
      "358 - random_35 - lwr_k=1000 - 3.241970347216864 - 3.0826757315424254 - 2.720352881701386 - 2.6020173087968255 - 2.8273074085061083 - 2.8949196438474925 - 0.5209042225085085'\n",
      "359 - random_59 - lwr_k=200 - 2.781288409301831 - 2.9108641375764113 - 2.8936625217608 - 2.987910107121915 - 2.9587979264081175 - 2.9064922146963905 - 0.5189890156943189'\n",
      "360 - random_35 - lwr_k=20 - 3.2059544945613108 - 3.178915448271818 - 2.7037183818085406 - 2.547044355979349 - 2.89734606364656 - 2.906654430689394 - 0.5189621696996624'\n",
      "361 - random_34 - deep - 2.701781349955246 - 2.826335175212314 - 2.935042893862088 - 3.239170051942861 - 2.890456863986883 - 2.9185255632255167 - 0.5169975525188195'\n",
      "362 - random_35 - lr - 3.314836806924202 - 3.1096511459734657 - 2.732083628855202 - 2.7159508052236703 - 2.884046924999207 - 2.951367430474405 - 0.5115623755666874'\n",
      "363 - random_79 - deep - 2.9352770857226242 - 2.3351205132936075 - 2.5019308463259153 - 3.542054329075118 - 3.6323338558541676 - 2.989270626488014 - 0.5052895725944524'\n",
      "364 - random_13 - deep - 2.739381949066076 - 3.2146234169808823 - 3.000262426399842 - 2.5384943088711656 - 3.46019118963081 - 2.990587856533069 - 0.5050715771300047'\n",
      "365 - random_59 - lwr_k=500 - 2.8647685626913257 - 3.0270432805288077 - 2.9869896719385034 - 3.063158953128939 - 3.1152413231707317 - 3.011426904291111 - 0.501622811142128'\n",
      "366 - random_98 - deep - 2.805234050432678 - 3.3621764263781357 - 2.720554539310369 - 2.961818291176516 - 3.211707349675392 - 3.0123127993313257 - 0.5014761998356734'\n",
      "367 - random_11 - deep - 2.8468194505751225 - 3.0218668576079555 - 2.785843569640017 - 3.0086691056433645 - 3.489941560756989 - 3.0306083277931495 - 0.4984483747117926'\n",
      "368 - random_59 - lwr_k=20 - 2.9157072246689757 - 3.3022112679723397 - 2.905301131152602 - 3.3497209586028474 - 2.961412299957568 - 3.0868751112008703 - 0.48913648274728216'\n",
      "369 - random_59 - lwr_k=1000 - 2.9369522078432504 - 3.082304456844789 - 3.09176012608961 - 3.139230288509231 - 3.194917199866016 - 3.089016554347622 - 0.48878208383623556'\n",
      "370 - random_59 - lr - 3.0457484899001943 - 3.1754112029548165 - 3.207962221600418 - 3.4311807933453036 - 3.313507184729431 - 3.234736484329872 - 0.4646661111185729'\n",
      "371 - random_59 - deep - 3.0855785848667465 - 3.212802388351229 - 3.272004132887666 - 3.483487815093211 - 3.3464601221025845 - 3.2800397407637725 - 0.4571686324811468'\n",
      "372 - random_35 - deep - 3.4594646197456527 - 4.232440178549675 - 2.783623196016347 - 2.9717834098627924 - 3.093151717704914 - 3.3082030414669017 - 0.45250773680828993'\n",
      "373 - random_96 - deep - 4.929512500885268 - 1.4149888047442918 - 3.0747542890435127 - 5.116531088122107 - 2.318560069101792 - 3.3708285769009785 - 0.4421435010891933'\n",
      "374 - random_37 - lwr_k=500 - 3.412820342049545 - 3.515732286003668 - 3.3237164501277348 - 3.3093900121170035 - 3.5213144066998368 - 3.4166044882754814 - 0.4345677997763816'\n",
      "375 - random_37 - lwr_k=1000 - 3.3965236566526174 - 3.5227773840439314 - 3.35856875447412 - 3.3144944927298976 - 3.5031648656775833 - 3.4191141544047357 - 0.43415246166915833'\n",
      "376 - random_37 - lwr_k=200 - 3.4479097298283636 - 3.4823254333218 - 3.3239474860382057 - 3.3384837683683783 - 3.585415684793447 - 3.4356224769596935 - 0.43142041083439453'\n",
      "377 - random_44 - lwr_k=500 - 3.202426059979433 - 3.7287721943614973 - 3.24600598297702 - 3.1238395051376795 - 4.00378427132735 - 3.4609665540036527 - 0.4272260836025539'\n",
      "378 - random_44 - lwr_k=1000 - 3.206630921823382 - 3.7604632361112196 - 3.306583748473147 - 3.162544281484291 - 3.9537441576598926 - 3.4779944092889656 - 0.4244080525099577'\n",
      "379 - random_37 - lwr_k=100 - 3.4857055910856785 - 3.5162868895560635 - 3.360965131487282 - 3.4020178666663337 - 3.654117551290585 - 3.48382213252803 - 0.42344359133668874'\n",
      "380 - random_44 - lwr_k=200 - 3.2042101398827216 - 3.728458885467603 - 3.268913717144712 - 3.171765487964866 - 4.06623532419952 - 3.487912280178804 - 0.42276669086624996'\n",
      "381 - random_51 - lr - 3.1727680621448666 - 3.5839824055209615 - 3.537893035690251 - 3.4593905288238864 - 3.7249281852112035 - 3.4957683381180114 - 0.42146654970537123'\n",
      "382 - random_44 - lwr_k=100 - 3.265600696361411 - 3.7546964298372694 - 3.245886181294257 - 3.2416277067644597 - 4.145226726563661 - 3.5306033480030403 - 0.4157015170972084'\n",
      "383 - random_37 - lwr_k=50 - 3.5404914786850323 - 3.605062702379101 - 3.370394107447057 - 3.46204508424878 - 3.7069594058662743 - 3.5369979025810907 - 0.4146432479656994'\n",
      "384 - random_44 - lwr_k=50 - 3.332618838229979 - 3.772154682900445 - 3.2753284289854845 - 3.276528137625035 - 4.1739486431326345 - 3.566112927659912 - 0.40982484631974436'\n",
      "385 - random_37 - lwr_k=20 - 3.6056753191116915 - 3.6721909178042305 - 3.367219374954874 - 3.528460981238708 - 3.6995441801008786 - 3.574631358288929 - 0.40841508555008377'\n",
      "386 - random_37 - lr - 3.559021085184842 - 3.61865452681476 - 3.5743800175298444 - 3.57257602375685 - 3.5767093019926226 - 3.580269950369055 - 0.40748192470662936'\n",
      "387 - random_44 - lwr_k=20 - 3.3476312052766826 - 3.806225666906447 - 3.2945637024672365 - 3.3065214471749864 - 4.1516705342965805 - 3.5813216091354656 - 0.4073078800572658'\n",
      "388 - random_3 - deep - 1.6767919721696363 - 3.3731530354902524 - 5.304186209026549 - 3.734996678648054 - 4.0395087892269945 - 3.625501353204409 - 0.39999633753122266'\n",
      "389 - random_44 - lr - 3.388239753758528 - 3.7567983892941124 - 3.607033127908777 - 3.4982058210966795 - 3.8784095725833145 - 3.6257264073973023 - 0.3999590918472645'\n",
      "390 - random_15 - lwr_k=500 - 3.3446295918430775 - 3.9590271101358745 - 3.496446715231278 - 3.739406594296385 - 3.8426452332761647 - 3.6764259981049916 - 0.3915685446760421'\n",
      "391 - random_15 - lwr_k=1000 - 3.338642608257086 - 3.982342495906913 - 3.5069744159276137 - 3.7355057540551666 - 3.8555875757266276 - 3.6838057828636384 - 0.39034722451809645'\n",
      "392 - random_15 - lr - 3.5053446013872285 - 3.6851246847599834 - 3.6329760539167015 - 3.7612928752906045 - 3.860172752001544 - 3.688962947412826 - 0.38949373769866236'\n",
      "393 - random_15 - lwr_k=200 - 3.4041549253135726 - 3.9303718963355827 - 3.4915235565803404 - 3.7424231250540827 - 3.9150688163505314 - 3.696702418955953 - 0.38821289104573087'\n",
      "394 - random_15 - lwr_k=100 - 3.400002955010692 - 3.947882287010864 - 3.5074714787756314 - 3.758282948949558 - 3.912582621275382 - 3.7052380320419958 - 0.3868002866591065'\n",
      "395 - random_90 - lwr_k=20 - 4.3753389534138005 - 4.365295712576507 - 4.202059341425435 - 4.068998144741588 - 1.5378080586549128 - 3.7100356236222782 - 0.38600630749870835'\n",
      "396 - random_71 - lr - 3.6318941622629604 - 3.7549516174413022 - 3.764643720104656 - 3.527298450733984 - 3.8887343529427367 - 3.7135003380178326 - 0.38543291333191276'\n",
      "397 - random_15 - lwr_k=50 - 3.419662392210188 - 3.9570307746369036 - 3.5173743865747005 - 3.7863883868534196 - 3.9271787645190166 - 3.7215201291424767 - 0.3841056750880649'\n",
      "398 - random_15 - lwr_k=20 - 3.480198863190705 - 3.924859113962759 - 3.5008036602598502 - 3.790559099582946 - 3.9356778175255056 - 3.7264148062190054 - 0.38329562872821754'\n",
      "399 - random_76 - lwr_k=500 - 3.5910320543318246 - 4.178483813441334 - 3.557827252234399 - 3.6338455072731772 - 3.6854041441707754 - 3.72935046547478 - 0.3828097907338591'\n",
      "400 - random_76 - lwr_k=200 - 3.61856356725986 - 4.164646935424358 - 3.5460817712263353 - 3.6269382751905184 - 3.6925980925822306 - 3.7297989534491642 - 0.3827355680537099'\n",
      "401 - random_76 - lwr_k=1000 - 3.5807734046633266 - 4.171036972241944 - 3.6034586456432915 - 3.6021798352554764 - 3.7007640280854575 - 3.7316721938092425 - 0.38242555546021784'\n",
      "402 - random_19 - lwr_k=1000 - 3.6431134765960698 - 4.139572615080494 - 3.7845380837228735 - 3.9657226093795934 - 3.138595110138243 - 3.7343406176750693 - 0.3819839436837418'\n",
      "403 - random_19 - lwr_k=500 - 3.6442266863354953 - 4.146332986781837 - 3.7971202723100865 - 3.9604168427417683 - 3.12731937359716 - 3.7351161201800416 - 0.38185560161512655'\n",
      "404 - random_38 - lr - 3.6526013340939816 - 3.7363327549653036 - 3.8175495021735113 - 3.664279467886453 - 3.819530928394516 - 3.73804984826174 - 0.3813700832211231'\n",
      "405 - random_76 - lwr_k=50 - 3.6528945350252635 - 4.110334197783975 - 3.5692008283573418 - 3.6723555251096505 - 3.693609345294869 - 3.739708025193319 - 0.3810956626278117'\n",
      "406 - random_76 - lwr_k=100 - 3.642334824669216 - 4.145610264810206 - 3.5594437977848634 - 3.662791494714011 - 3.7073861647837845 - 3.7435441981299538 - 0.38046079379489783'\n",
      "407 - random_19 - lwr_k=200 - 3.653295084878867 - 4.183383220813384 - 3.7996594603106506 - 3.9732149916775303 - 3.125757488835443 - 3.747097211919382 - 0.37987278648785505'\n",
      "408 - random_19 - lwr_k=100 - 3.6701800143666197 - 4.187343763020711 - 3.7970814680285314 - 3.9956613753861445 - 3.1299518237333905 - 3.7560791473755226 - 0.3783863178185489'\n",
      "409 - random_39 - lwr_k=100 - 3.730454459001868 - 4.149542518192844 - 3.2574709074911268 - 3.0406938082087382 - 4.611423435107921 - 3.7579544063155472 - 0.3780759711594358'\n",
      "410 - random_93 - lwr_k=1000 - 4.227926445531373 - 3.6521985306967215 - 3.6199718548044006 - 3.4947620398609818 - 3.80248235309216 - 3.759505320190952 - 0.37781930210454917'\n",
      "411 - random_76 - lwr_k=20 - 3.693589532202545 - 4.114301768091866 - 3.623356472004913 - 3.7062234031119408 - 3.6879223561595245 - 3.7651072152330314 - 0.3768922144507295'\n",
      "412 - random_93 - lwr_k=500 - 4.235147538879922 - 3.6559339080202284 - 3.653098546519222 - 3.517627151162689 - 3.7697851678617202 - 3.7663552562191938 - 0.37668566945460935'\n",
      "413 - random_93 - lwr_k=200 - 4.244568645106323 - 3.667929588206632 - 3.6737005318588674 - 3.5568512159937313 - 3.7424575625330414 - 3.777138287144137 - 0.374901127836786'\n",
      "414 - random_93 - lr - 4.138284573306712 - 3.746151976370352 - 3.624477006859312 - 3.4775305183562795 - 3.913442617705266 - 3.7800106460408975 - 0.37442576575832454'\n",
      "415 - random_93 - lwr_k=100 - 4.260632425992544 - 3.675228257868067 - 3.711302759920036 - 3.5602965566876894 - 3.7622717562464794 - 3.793982069674022 - 0.37211355993167894'\n",
      "416 - random_93 - lwr_k=50 - 4.241597125686346 - 3.707451765188973 - 3.7049784994700374 - 3.596421089261725 - 3.742019008249664 - 3.798529636135887 - 0.37136095876902775'\n",
      "417 - random_39 - lwr_k=200 - 3.7740145083290617 - 4.204532134206086 - 3.32144177343071 - 3.123604363137169 - 4.570608698330476 - 3.7988793907496405 - 0.3713030760022423'\n",
      "418 - random_19 - lwr_k=50 - 3.756943323548413 - 4.202913408846232 - 3.84746423443927 - 4.024986671732153 - 3.1841859191119997 - 3.8033349730126544 - 0.3705656977979759'\n",
      "419 - random_93 - lwr_k=20 - 4.176934017855997 - 3.7385679882002134 - 3.740701746750672 - 3.6250709119529194 - 3.7586193256489615 - 3.8080095458142407 - 0.3697920776750214'\n",
      "420 - random_4 - lr - 3.894505832145533 - 3.7827412476043154 - 3.787953970685581 - 3.732589351335473 - 3.907881176690885 - 3.821137906171557 - 0.36761939491128925'\n",
      "421 - random_19 - lr - 3.7190919315955906 - 4.231567012607046 - 3.878006080201355 - 3.9754612122544506 - 3.3092153699259925 - 3.8226996621402876 - 0.3673609315402313'\n",
      "422 - random_0 - lr - 3.611776335247112 - 3.8402968234824133 - 3.8060154864615248 - 4.038988132756225 - 3.8464351333304307 - 3.8286813053097624 - 0.3663709973321966'\n",
      "423 - random_39 - lwr_k=20 - 4.022680173028723 - 4.645685316188679 - 3.2504042271058537 - 3.0508714350674 - 4.192136784885336 - 3.8324586106913214 - 0.3657458708066825'\n",
      "424 - random_32 - lwr_k=50 - 4.025960320114425 - 3.816284804474683 - 4.092636169443353 - 3.3399529562839883 - 3.8913441451396142 - 3.833253721974235 - 0.3656142835762427'\n",
      "425 - random_32 - lwr_k=100 - 3.957051681111115 - 3.848034852048099 - 4.172721235666758 - 3.3087233003464522 - 3.9139035666747843 - 3.840099749246923 - 0.3644812978072224'\n",
      "426 - random_39 - lwr_k=50 - 3.7219077014794535 - 4.334355619229826 - 3.2363975680692607 - 3.00214194368106 - 4.908963017095393 - 3.8407916380880556 - 0.3643667934122612'\n",
      "427 - random_38 - lwr_k=500 - 3.856025075044595 - 3.94153857623141 - 4.1825070094622925 - 3.5184152570366862 - 3.7072498892049484 - 3.84115899359969 - 0.3643059977784907'\n",
      "428 - random_38 - lwr_k=200 - 3.850118984090685 - 3.949131937737623 - 4.18283557650803 - 3.52215483087682 - 3.7512303463155137 - 3.851104298383461 - 0.36266009595254645'\n",
      "429 - random_38 - lwr_k=100 - 3.867900545452178 - 3.9671983672511724 - 4.171775306922723 - 3.5044363820958337 - 3.7755940839729862 - 3.8573932895346292 - 0.36161929707869533'\n",
      "430 - random_38 - lwr_k=1000 - 3.8680968711084236 - 3.947165925942505 - 4.26726770276379 - 3.5262342872425387 - 3.7075978481486622 - 3.86328163376906 - 0.36064480341178895'\n",
      "431 - random_38 - lwr_k=50 - 3.8679936345174313 - 4.01567144585657 - 4.177001784521685 - 3.5357194367409974 - 3.736077480412705 - 3.8665082234153747 - 0.36011081778682263'\n",
      "432 - random_76 - lr - 3.626705989947086 - 4.343154028209787 - 3.6781856637918735 - 3.7173836901081234 - 3.9726924668043186 - 3.8676484502278536 - 0.3599221155365193'\n",
      "433 - random_38 - lwr_k=20 - 3.927409900738936 - 3.999044968082133 - 4.157811999444383 - 3.550590078737892 - 3.727220906231268 - 3.872434214018666 - 0.3591300938204338'\n",
      "434 - random_90 - lwr_k=50 - 4.504098143627268 - 4.577799116960688 - 4.405128432800605 - 4.327963867017407 - 1.6112312145112546 - 3.8853787689180184 - 0.35698783000770007'\n",
      "435 - random_75 - lr - 4.129161187924441 - 3.828965913380573 - 4.153222162865366 - 3.5501945280282796 - 3.7727454051475053 - 3.886876768993188 - 0.35673991794139415'\n",
      "436 - random_32 - lwr_k=200 - 4.022018279304783 - 3.914244747867985 - 4.23360453775937 - 3.3243190960814735 - 3.9430815458595734 - 3.8874702042718265 - 0.3566417071545026'\n",
      "437 - random_1 - lr - 3.8945800134245045 - 4.00113946483529 - 3.7378346718720454 - 3.5939347483933037 - 4.25527719065535 - 3.8965637508932316 - 0.3551367673548793'\n",
      "438 - random_32 - lwr_k=20 - 4.068308089161067 - 3.8276275991851927 - 4.1498297716099835 - 3.5277471275661227 - 3.9249722778905096 - 3.899706882930879 - 0.3546165935771597'\n",
      "439 - random_39 - lwr_k=500 - 3.9573001575930116 - 4.353729317128781 - 3.3870231104066235 - 3.1747834717717835 - 4.711974015981468 - 3.9170109886520437 - 0.3517528443183864'\n",
      "440 - random_19 - lwr_k=20 - 3.9553280806066615 - 4.319404250483706 - 3.944061804482014 - 4.186169481277324 - 3.257177335930649 - 3.9324702636365445 - 0.3491944059921638'\n",
      "441 - random_20 - lwr_k=50 - 3.880596924897176 - 4.148727077339227 - 4.000919873486927 - 3.8705032733604043 - 3.7746151643384924 - 3.9350888021503523 - 0.34876105001013147'\n",
      "442 - random_27 - lwr_k=500 - 3.758124276068115 - 4.26350259185085 - 3.7631183998946423 - 3.6040898700833996 - 4.299396523657766 - 3.937661353272081 - 0.3483353047282475'\n",
      "443 - random_27 - lwr_k=200 - 3.7942086207523054 - 4.249437451030743 - 3.762265831430047 - 3.6002765250193938 - 4.297259795482241 - 3.9407063011566494 - 0.3478313799725885'\n",
      "444 - random_27 - lwr_k=1000 - 3.735336837089829 - 4.273376480816321 - 3.7559179212422102 - 3.6235793194385515 - 4.322870019524239 - 3.9422288728678327 - 0.34757940141445953'\n",
      "445 - random_20 - lwr_k=100 - 3.8488964937353667 - 4.176936301477467 - 4.009546570513071 - 3.902607792815767 - 3.7752454357450236 - 3.9426609450283 - 0.3475078954753943'\n",
      "446 - random_27 - lwr_k=100 - 3.799927194289472 - 4.244056420052137 - 3.7718355385370304 - 3.6072309292247287 - 4.311054097479355 - 3.9468362682653964 - 0.34681689884037326'\n",
      "447 - random_27 - lwr_k=50 - 3.806262137493349 - 4.2174439724137285 - 3.8087219275247124 - 3.610030377822662 - 4.292358861735635 - 3.946976777015664 - 0.34679364529373446'\n",
      "448 - random_20 - lwr_k=200 - 3.8668135173274205 - 4.1981778326366355 - 4.007281428843304 - 3.9065163576772326 - 3.789949060229815 - 3.95376380605108 - 0.34567042345941157'\n",
      "449 - random_27 - lwr_k=20 - 3.8100358354970405 - 4.289459932441744 - 3.856268035865013 - 3.6368756986480717 - 4.2360380899946115 - 3.9657527659467955 - 0.3436863061887441'\n",
      "450 - random_20 - lwr_k=20 - 3.920634725368782 - 4.155990324921127 - 4.025525792237827 - 3.9078635413286866 - 3.828008784302556 - 3.967619149725311 - 0.34337742832770723'\n",
      "451 - random_32 - lwr_k=500 - 4.1268660483071775 - 4.03025672130686 - 4.385171574584587 - 3.3541010526615542 - 3.964663332441959 - 3.9722335790854224 - 0.34261376166543533'\n",
      "452 - random_27 - lr - 3.748698595761016 - 4.308315933341605 - 3.745214446166935 - 3.682249339710096 - 4.3788219469950524 - 3.972671517640714 - 0.34254128486522895'\n",
      "453 - random_25 - lr - 3.6017593205103 - 4.338710906506552 - 3.6963019259041046 - 4.265585010366084 - 3.9718124699318555 - 3.974832982522832 - 0.3421835724498188'\n",
      "454 - random_1 - lwr_k=1000 - 3.8325169283738143 - 4.1732155980605965 - 3.7994294417842727 - 3.6377123808285248 - 4.503363743764284 - 3.9892504144244736 - 0.33979755432284675'\n",
      "455 - random_25 - lwr_k=1000 - 3.592429635796186 - 4.448829749988617 - 3.631929407283241 - 4.391113310288512 - 3.909999319815514 - 3.994865575007696 - 0.3388682712834795'\n",
      "456 - random_20 - lwr_k=500 - 3.9329623184050857 - 4.198914958653359 - 4.05741017347552 - 3.9715458662331597 - 3.824549307862849 - 3.9970906620874818 - 0.33850002968936765'\n",
      "457 - random_1 - lwr_k=500 - 3.840052197583741 - 4.1830126345490894 - 3.8063512465953524 - 3.643652248483501 - 4.545106275834042 - 4.003636541938535 - 0.3374167169268627'\n",
      "458 - random_46 - lr - 3.7454607819180383 - 3.89064642694924 - 3.838261742422246 - 3.8667587440501707 - 4.694556656670871 - 4.007098052240345 - 0.33684385302272457'\n",
      "459 - random_46 - lwr_k=1000 - 3.791433945466591 - 3.9083362097732595 - 3.7894856343632055 - 3.860697110417015 - 4.73261538102852 - 4.016479447920129 - 0.3352912755386782'\n",
      "460 - random_71 - lwr_k=20 - 4.003448818711747 - 3.983122952108525 - 3.960111671925325 - 3.9851507026910458 - 4.1589114754233725 - 4.018144019832286 - 0.3350157966057342'\n",
      "461 - random_1 - lwr_k=200 - 3.8267140569280524 - 4.1975001886496806 - 3.8227337345872274 - 3.667543734995017 - 4.576997619080015 - 4.01829659590896 - 0.33499054597253064'\n",
      "462 - random_46 - lwr_k=500 - 3.8158700235941554 - 3.920276641974275 - 3.7929277137030737 - 3.846000120725502 - 4.72515618850847 - 4.020014938192798 - 0.3347061682924035'\n",
      "463 - random_25 - lwr_k=500 - 3.585051757676063 - 4.4889749054152155 - 3.660822805373533 - 4.456910673723685 - 3.917297510727297 - 4.0218146514620265 - 0.33440832409150645'\n",
      "464 - random_46 - lwr_k=100 - 3.8484910383563338 - 3.9438090213929335 - 3.806635877220334 - 3.8213225468296184 - 4.691889565110506 - 4.022403685006765 - 0.3343108417711649'\n",
      "465 - random_1 - lwr_k=100 - 3.8285858989436825 - 4.202335924026644 - 3.845838557436665 - 3.660482526280582 - 4.576862577739455 - 4.022819585863973 - 0.3342420121078037'\n",
      "466 - random_46 - lwr_k=200 - 3.834956253345336 - 3.9408835740217083 - 3.8016646162096683 - 3.8325539337221946 - 4.705422429839984 - 4.023068410196461 - 0.33420083283456015'\n",
      "467 - random_51 - lwr_k=1000 - 4.575918845051151 - 3.7728360684531066 - 3.9006513970548085 - 3.610934616492424 - 4.3214961636575895 - 4.0363957511409145 - 0.3319952197063176'\n",
      "468 - random_1 - lwr_k=50 - 3.829447506313644 - 4.253341774331279 - 3.8704129078044742 - 3.7014877232560033 - 4.535274464531662 - 4.037993573618398 - 0.33173078749529905'\n",
      "469 - random_33 - lr - 3.9683644170883743 - 4.15717011841013 - 4.083123483917887 - 3.8893166946423494 - 4.100488195733931 - 4.039697319114312 - 0.33144882551588906'\n",
      "470 - random_46 - lwr_k=50 - 3.8830984970368396 - 3.9265231051565657 - 3.82313244004441 - 3.857056113685784 - 4.720467356718861 - 4.0420273266505555 - 0.33106322007274314'\n",
      "471 - random_20 - lwr_k=1000 - 3.982066241057967 - 4.2310943575463575 - 4.104619520513198 - 4.038426987592933 - 3.854746889074024 - 4.0422040181058065 - 0.3310339784562065'\n",
      "472 - random_32 - lwr_k=1000 - 4.2670912322631125 - 4.135737121261997 - 4.446381104051525 - 3.3661669610850082 - 4.0518923570452205 - 4.053484130920807 - 0.32916717209051705'\n",
      "473 - random_90 - lwr_k=100 - 4.66332067500977 - 4.78662343958727 - 4.6304548481540655 - 4.526005726163294 - 1.6772817727545506 - 4.056874478694899 - 0.3286060852547398'\n",
      "474 - random_51 - lwr_k=500 - 4.643499615052958 - 3.783752761775634 - 3.9294295499170078 - 3.6271072950362684 - 4.331668809007093 - 4.063122510403789 - 0.3275720649786592'\n",
      "475 - random_19 - deep - 4.111822543846393 - 4.3639863786359765 - 4.015325701946596 - 4.078857128625043 - 3.7519748959942767 - 4.064428950387024 - 0.32735585550922064'\n",
      "476 - random_2 - lwr_k=50 - 3.822136488826611 - 4.296210727586418 - 4.016123913223679 - 3.5378045645355156 - 4.696884574809476 - 4.073829044466512 - 0.32580018323682214'\n",
      "477 - random_25 - lwr_k=200 - 3.580266697727327 - 4.55642107061245 - 3.7030071571655623 - 4.585896724090397 - 3.9602182749089203 - 4.0771601745743595 - 0.32524889665021983'\n",
      "478 - random_25 - lwr_k=20 - 3.616276446405612 - 4.474653501622602 - 3.749688837426456 - 4.483159136357924 - 4.0662570137888 - 4.078000306353884 - 0.3251098587363481'\n",
      "479 - random_37 - deep - 4.1340383746918805 - 4.158890154130524 - 3.8428797119696774 - 3.902771136599155 - 4.362556024253736 - 4.080240692608901 - 0.32473908549070907'\n",
      "480 - random_1 - lwr_k=20 - 3.7668673682600993 - 4.399619071948434 - 3.9443124736298127 - 3.758414693791842 - 4.539759539405404 - 4.081794926797941 - 0.3244818666482796'\n",
      "481 - random_46 - lwr_k=20 - 3.9741493057688286 - 3.9608931575093087 - 3.861132030436866 - 3.8952140935929553 - 4.72720045353377 - 4.083693953400017 - 0.3241675865513062'\n",
      "482 - random_33 - lwr_k=20 - 3.9667224013306064 - 4.099250695065353 - 4.075874571283129 - 4.050405820498999 - 4.257763428359633 - 4.089991677942094 - 0.32312534234175594'\n",
      "483 - random_51 - lwr_k=200 - 4.778775350611736 - 3.8205826370875453 - 3.9506746677278244 - 3.630975662901391 - 4.335878053475858 - 4.103417574446991 - 0.3209034187252561'\n",
      "484 - random_95 - lwr_k=500 - 3.2955958781800034 - 6.192798046327015 - 3.488712634742176 - 4.089244627235396 - 3.4529413759171104 - 4.103989971821291 - 0.3208086896139809'\n",
      "485 - random_25 - lwr_k=50 - 3.581131391123404 - 4.603606652713699 - 3.7116948577363322 - 4.623461122765404 - 4.002031801993633 - 4.104382698392476 - 0.320743695187499'\n",
      "486 - random_25 - lwr_k=100 - 3.576144067991345 - 4.606629764236633 - 3.708072031252182 - 4.646575792184254 - 3.9907614391099364 - 4.105633693538561 - 0.32053666129160985'\n",
      "487 - random_2 - lwr_k=100 - 3.861360061804641 - 4.31837166443917 - 3.9659073775358533 - 3.5542934339994434 - 4.8359947413306905 - 4.107181900167536 - 0.3202804402734539'\n",
      "488 - random_95 - lwr_k=1000 - 3.30477424342275 - 6.197818552958097 - 3.511621648019655 - 4.103167191362281 - 3.448700769505382 - 4.113347476725391 - 0.3192600659425302'\n",
      "489 - random_60 - lwr_k=200 - 3.8389296032395324 - 4.325249986097425 - 4.166224944814334 - 4.280596238199014 - 3.971102572769196 - 4.116413621010277 - 0.318752633280905'\n",
      "490 - random_60 - lwr_k=500 - 3.822904631846662 - 4.285762362551135 - 4.174529950546269 - 4.344363161360944 - 3.964360703808421 - 4.118371012635532 - 0.3184286940432304'\n",
      "491 - random_60 - lwr_k=100 - 3.849925838270044 - 4.327335376108878 - 4.189668471646486 - 4.313954184607794 - 3.960754543366862 - 4.128319533123229 - 0.3167822600331974'\n",
      "492 - random_60 - lr - 3.8372588277621786 - 4.333696943128928 - 4.15848631836799 - 4.351631556770099 - 3.9808563009075453 - 4.132376359310579 - 0.3161108741104458'\n",
      "493 - random_95 - lwr_k=200 - 3.3537073064520917 - 6.192088468964143 - 3.5214329118472203 - 4.123786984820452 - 3.472594998979183 - 4.132853560152568 - 0.3160318995838478'\n",
      "494 - random_60 - lwr_k=1000 - 3.819595357405993 - 4.294058609399253 - 4.167713169558288 - 4.41859903667668 - 3.9675318219826146 - 4.133483858373155 - 0.315927588150995'\n",
      "495 - random_60 - lwr_k=50 - 3.8307220149698176 - 4.321156825634503 - 4.197617168213916 - 4.344487677157481 - 3.9931796817406067 - 4.137420049184151 - 0.315276166823651'\n",
      "496 - random_51 - lwr_k=100 - 4.916252551113898 - 3.7911618295226357 - 4.006563320136896 - 3.6396358399345528 - 4.374165630192599 - 4.145598566956988 - 0.31392266005553315'\n",
      "497 - random_51 - lwr_k=50 - 4.945951032073384 - 3.779591475743607 - 3.9885898577085483 - 3.632707416182822 - 4.4067304073719304 - 4.150757572452907 - 0.31306886856795124'\n",
      "498 - random_0 - lwr_k=1000 - 3.9626981003720356 - 3.8169151015956753 - 4.332230122812648 - 4.168995351085095 - 4.48154545780407 - 4.152422901415541 - 0.312793264346664'\n",
      "499 - random_2 - lwr_k=20 - 4.013166968847471 - 4.325030842524434 - 4.08239788665577 - 3.9591306273042033 - 4.390675106246639 - 4.154083369588003 - 0.31251846456361076'\n",
      "500 - random_51 - lwr_k=20 - 4.939256972523416 - 3.7532474081627756 - 4.049274150139384 - 3.656033374793288 - 4.376142082118883 - 4.154830103930796 - 0.31239488349243993'\n",
      "501 - random_2 - lwr_k=200 - 3.9786342879041383 - 4.398613052663775 - 3.964389143274003 - 3.5367453378584828 - 4.904348611248026 - 4.1565526720102755 - 0.3121098064627289'\n",
      "502 - random_75 - lwr_k=1000 - 4.766044832310734 - 3.8494547670875265 - 4.804006092276068 - 3.5052154714930936 - 3.8627669259007527 - 4.157528464083781 - 0.3119483173992518'\n",
      "503 - random_4 - lwr_k=1000 - 4.29939295077099 - 3.7613118098863043 - 4.164540298982596 - 3.9815035827427163 - 4.582246848080471 - 4.157772933707938 - 0.31190785881004457'\n",
      "504 - random_29 - lwr_k=1000 - 3.4208561653392935 - 4.213206383080003 - 5.926803285681351 - 3.5299850806156616 - 3.710219221157092 - 4.160143572903901 - 0.31151552901562174'\n",
      "505 - random_4 - lwr_k=500 - 4.3032888884317995 - 3.744427075539182 - 4.186307550214417 - 3.984926514254939 - 4.5938605962488115 - 4.162533649441432 - 0.3111199824312989'\n",
      "506 - random_22 - lwr_k=20 - 6.067803315626596 - 2.8704048935266044 - 2.7892057481602834 - 2.9315455006428026 - 6.162723979704331 - 4.164399255262988 - 0.31081123331853144'\n",
      "507 - random_60 - lwr_k=20 - 3.8856499558317923 - 4.348240846277508 - 4.239509788129213 - 4.321573092347147 - 4.064405252052757 - 4.171864509903279 - 0.30957576829149236'\n",
      "508 - random_22 - lwr_k=50 - 6.067219355256365 - 2.8586610820198377 - 2.845677533752296 - 2.943182842371062 - 6.162947692272335 - 4.175596703909478 - 0.30895810748942165'\n",
      "509 - random_41 - lr - 3.737997404776893 - 3.9302916302322606 - 4.501672463162876 - 3.696069896513229 - 5.041870731950003 - 4.1815090978978136 - 0.3079796336997612'\n",
      "510 - random_95 - lwr_k=100 - 3.430870400413225 - 6.230934076876381 - 3.552829841745501 - 4.1774561932285215 - 3.515717192608815 - 4.181694848446808 - 0.30794889284521654'\n",
      "511 - random_39 - lwr_k=1000 - 4.863765586948654 - 4.509057209841026 - 3.460314431430141 - 3.2432433833719805 - 4.840994681418165 - 4.18357830974956 - 0.30763718873310597'\n",
      "512 - random_29 - lwr_k=500 - 3.4624182569192175 - 4.284519858925707 - 5.9385404355160425 - 3.528165418128982 - 3.711532790097292 - 4.184971388399896 - 0.3074066406760958'\n",
      "513 - random_0 - lwr_k=500 - 3.9595333556494086 - 3.807380764163938 - 4.376511500465639 - 4.239791016315631 - 4.54825326481318 - 4.186231808875201 - 0.30719804693192554'\n",
      "514 - random_22 - lwr_k=100 - 6.081539429952745 - 2.944485254079433 - 2.837614862896154 - 2.9130099688211493 - 6.15780745050841 - 4.186958344791049 - 0.30707780860675526'\n",
      "515 - random_45 - lwr_k=20 - 4.137663079161592 - 4.298632191192094 - 4.1477574620015805 - 4.059576219201003 - 4.303763152696222 - 4.189484306544263 - 0.3066597736493285'\n",
      "516 - random_20 - lr - 4.173398892820468 - 4.329250475219324 - 4.218654161585586 - 4.261047639048697 - 4.000002223591204 - 4.196481939796839 - 0.30550169779362446'\n",
      "517 - random_4 - lwr_k=200 - 4.3922607238198 - 3.7173311111527356 - 4.235190310117069 - 4.005164484411249 - 4.644499511347518 - 4.198859646295175 - 0.3051081983934292'\n",
      "518 - random_90 - lwr_k=200 - 4.845862190749526 - 4.953903903245718 - 4.80692953965561 - 4.669389893574624 - 1.723844531130978 - 4.200129698190553 - 0.3048980106938972'\n",
      "519 - random_90 - lwr_k=1000 - 4.785262694858019 - 4.9561113751773656 - 4.781584415474393 - 4.646656604464372 - 1.8410709647529369 - 4.202274461987106 - 0.30454306223070604'\n",
      "520 - random_75 - lwr_k=500 - 4.941021300565176 - 3.8487247176164088 - 4.891337664287878 - 3.490022216277551 - 3.8642424873747414 - 4.20710823261993 - 0.30374309560487245'\n",
      "521 - random_32 - lr - 4.480192863683947 - 4.313807732235817 - 4.61238760597927 - 3.4270426534280483 - 4.204289586329624 - 4.207582983057193 - 0.3036645266088941'\n",
      "522 - random_22 - lwr_k=200 - 6.104389571164463 - 2.9278998338694344 - 2.8863695528507693 - 2.946204475809982 - 6.18629354861447 - 4.210294199439868 - 0.30321583286930587'\n",
      "523 - random_0 - lwr_k=200 - 3.9541870085440607 - 3.756674739274762 - 4.43785738099379 - 4.377669753692258 - 4.592061918099993 - 4.223614557721833 - 0.3010113753393271'\n",
      "524 - random_22 - lwr_k=500 - 6.068582670005644 - 2.946266871483463 - 2.8957843585758725 - 3.046773566609264 - 6.183310949352819 - 4.228201018678116 - 0.3002523373182011'\n",
      "525 - random_95 - lwr_k=50 - 3.473982265324551 - 6.280259264986403 - 3.59379224102836 - 4.247219071151416 - 3.5530176107726392 - 4.229787013394308 - 0.2999898625468318'\n",
      "526 - random_85 - lwr_k=20 - 4.366950659481318 - 4.0739929726768365 - 4.022457322665409 - 4.232045557106314 - 4.456515033656301 - 4.230390272473212 - 0.2998900259665487'\n",
      "527 - random_29 - lwr_k=200 - 3.538577009418902 - 4.381431183918572 - 5.946006743268165 - 3.5588229830473948 - 3.7425607879906426 - 4.233423597893986 - 0.2993880246747549'\n",
      "528 - random_29 - lr - 3.501399339795515 - 4.360936096756386 - 5.9285770482321745 - 3.564152856500196 - 3.827157000256954 - 4.2363817960130215 - 0.29889845660303827'\n",
      "529 - random_85 - lwr_k=50 - 4.28290777144225 - 4.2004800279384025 - 4.01650589464484 - 4.1998142069775195 - 4.4951834740165655 - 4.238978832512577 - 0.29846865910466125'\n",
      "530 - random_22 - lwr_k=1000 - 6.068117957627712 - 2.972480131821009 - 2.917111117668904 - 3.0937387983342877 - 6.162680739797699 - 4.242882713389006 - 0.2978225849216689'\n",
      "531 - random_71 - lwr_k=1000 - 4.1362125800478635 - 4.357449476916119 - 4.2442176678789805 - 4.117234379527513 - 4.376845825988633 - 4.246392076205759 - 0.2972418016481969'\n",
      "532 - random_2 - lwr_k=500 - 4.086854842718171 - 4.474908343739034 - 3.958070649644066 - 3.7060260021184086 - 5.02344278679532 - 4.2498668935245 - 0.29666673549446065'\n",
      "533 - random_4 - lwr_k=100 - 4.496164238519514 - 3.7068012025454182 - 4.291490911706139 - 4.028081367058332 - 4.727267934706641 - 4.2499306487864175 - 0.29665618429424256'\n",
      "534 - random_90 - lwr_k=500 - 4.881771508742314 - 5.030169009114536 - 4.8421453823881295 - 4.724664164984173 - 1.7796155034929733 - 4.251817703591517 - 0.29634388547415635'\n",
      "535 - random_0 - lwr_k=100 - 3.9969333888709575 - 3.7314148994665803 - 4.477598761187474 - 4.438297362068308 - 4.6267968741250325 - 4.254128184445461 - 0.29596151160638673'\n",
      "536 - random_38 - deep - 4.212359100564925 - 4.4088136426848346 - 4.793079741436843 - 3.761409507395061 - 4.10455763560301 - 4.256055130479378 - 0.29564261127647695'\n",
      "537 - random_47 - lwr_k=200 - 3.7290266726748924 - 3.670997667184292 - 3.716755695126065 - 5.872314066670136 - 4.298954130287311 - 4.25749517349253 - 0.2954042905316191'\n",
      "538 - random_71 - lwr_k=50 - 4.222564307629855 - 4.277319203779331 - 4.191392186954823 - 4.146035730189862 - 4.457357223858411 - 4.258931884460124 - 0.29516652152842315'\n",
      "539 - random_29 - lwr_k=20 - 3.6665296371522142 - 4.416835947207033 - 5.919281538248397 - 3.5311380701583315 - 3.785518649041705 - 4.263815155966508 - 0.2943583627375478'\n",
      "540 - random_81 - lwr_k=200 - 3.9641850578531934 - 4.576369702486364 - 4.6994289680627634 - 4.285260365849819 - 3.794840006280526 - 4.264018105378564 - 0.29432477555091663'\n",
      "541 - random_91 - lwr_k=50 - 4.096764477365601 - 4.447370271330303 - 4.225405968903694 - 4.160710281186558 - 4.3959704251196685 - 4.265245685538621 - 0.2941216167266414'\n",
      "542 - random_81 - lwr_k=500 - 3.965615104875939 - 4.57976380525552 - 4.7132027217064785 - 4.300180839588627 - 3.7743116896750197 - 4.266616079320059 - 0.2938948229102454'\n",
      "543 - random_81 - lwr_k=1000 - 3.9579846114264967 - 4.592158323085554 - 4.707709869928225 - 4.294095122581278 - 3.7838728745928987 - 4.2671657836665435 - 0.2938038493898477'\n",
      "544 - random_47 - lwr_k=500 - 3.7458517441296895 - 3.6865800003159674 - 3.7280534628376634 - 5.86574229056853 - 4.313658688484946 - 4.267863962505495 - 0.2936883040294137'\n",
      "545 - random_75 - lwr_k=200 - 5.1193930312639235 - 3.829351602799067 - 5.020865131053403 - 3.480790990610958 - 3.8945520573232137 - 4.26903272679702 - 0.2934948789586549'\n",
      "546 - random_85 - lwr_k=100 - 4.269664993970167 - 4.299475786848709 - 4.065178086508842 - 4.243532635280897 - 4.48374408232165 - 4.272321632131491 - 0.29295058037625277'\n",
      "547 - random_81 - lwr_k=100 - 3.9847204573136588 - 4.554002551508326 - 4.746748364581707 - 4.293665653240069 - 3.7965650430095055 - 4.275139227539867 - 0.292484281401184'\n",
      "548 - random_0 - lwr_k=50 - 4.004026558119372 - 3.707501547663544 - 4.500958732952838 - 4.519101398133706 - 4.651939326489942 - 4.276619094798799 - 0.29223937023188473'\n",
      "549 - random_41 - lwr_k=20 - 3.9908396778945767 - 4.021856510020121 - 4.736814079013073 - 3.8015378555959094 - 4.833640935157978 - 4.276882260372796 - 0.29219581754967094'\n",
      "550 - random_4 - lwr_k=20 - 4.479590630356007 - 3.781349542616771 - 4.303411957684122 - 3.971047026581749 - 4.8778659384718 - 4.2826217764952705 - 0.2912459542451864'\n",
      "551 - random_95 - lwr_k=20 - 3.5418393893468556 - 6.2837805497271795 - 3.6285257332650316 - 4.337473440707395 - 3.6237759015194744 - 4.283208284573344 - 0.29114888987786736'\n",
      "552 - random_47 - lwr_k=100 - 3.7691216254327227 - 3.6618565745213485 - 3.7309494779309675 - 5.980782703252276 - 4.305525896470398 - 4.289529382773535 - 0.29010277743628143'\n",
      "553 - random_41 - lwr_k=50 - 3.916691995882946 - 3.951190266684123 - 4.851342458652447 - 3.7361011751291247 - 4.997059560552315 - 4.290403895740672 - 0.28995804959528326'\n",
      "554 - random_47 - lwr_k=1000 - 3.790868838758645 - 3.679624119537758 - 3.7366533239693114 - 5.8597328137764695 - 4.386087750943441 - 4.290479358538934 - 0.2899455608520872'\n",
      "555 - random_4 - lwr_k=50 - 4.517246142292934 - 3.733352440527968 - 4.352634734476343 - 4.029292584184003 - 4.820163354851593 - 4.290503928343173 - 0.28994149466341435'\n",
      "556 - random_99 - lwr_k=20 - 4.091065358378765 - 4.838249131971591 - 4.135256490939422 - 3.9130561686446166 - 4.490211270430305 - 4.293602808187312 - 0.28942864441852567'\n",
      "557 - random_91 - lwr_k=100 - 4.119965543178186 - 4.4769658436879824 - 4.254478961904057 - 4.163773060842192 - 4.459222744295961 - 4.2948819666598625 - 0.28921694962269806'\n",
      "558 - random_22 - lr - 6.067308952531434 - 3.0913357541037856 - 2.9863237482847516 - 3.1736645008916793 - 6.162172469041336 - 4.296219217031436 - 0.28899564088695073'\n",
      "559 - random_85 - lwr_k=200 - 4.282171030229438 - 4.257402694669287 - 4.118504334591401 - 4.31696539900162 - 4.51558449805625 - 4.298119773463395 - 0.2886811076102255'\n",
      "560 - random_29 - lwr_k=100 - 3.6016586163350186 - 4.480006320724994 - 6.066533006723364 - 3.58745070274834 - 3.7588091963440005 - 4.298838589905456 - 0.2885621468221723'\n",
      "561 - random_91 - lwr_k=200 - 4.00607379159859 - 4.496425727827049 - 4.3238548843175035 - 4.179450302802796 - 4.496333671654727 - 4.300417579578559 - 0.28830083135295226'\n",
      "562 - random_91 - lwr_k=20 - 4.443667888545956 - 4.450372116777388 - 4.22075133432068 - 4.074572423637129 - 4.314682911262473 - 4.300839351469544 - 0.2882310300607246'\n",
      "563 - random_2 - lwr_k=1000 - 4.194765262326539 - 4.58393647935193 - 3.9367280788025636 - 3.7980687519900544 - 4.9971850299993825 - 4.3021546252673115 - 0.28801335834603825'\n",
      "564 - random_83 - lwr_k=1000 - 4.3722536002778805 - 4.779554282358462 - 3.963713864737723 - 4.215871604192148 - 4.20596194909033 - 4.30752616850355 - 0.2871243928479582'\n",
      "565 - random_81 - lwr_k=50 - 4.038902018790923 - 4.570855146782638 - 4.767338085725046 - 4.349246516864522 - 3.828075933649498 - 4.31088230756483 - 0.28656896739552784'\n",
      "566 - random_0 - lwr_k=20 - 3.994699044257414 - 3.6830509737468335 - 4.542776820419769 - 4.6130082000180765 - 4.7364058795777 - 4.313890644459101 - 0.2860711015890002'\n",
      "567 - random_83 - lwr_k=500 - 4.376714140258549 - 4.778936809089869 - 3.965291585058209 - 4.258463525995072 - 4.20296390441417 - 4.316527647547799 - 0.2856346898054426'\n",
      "568 - random_99 - lwr_k=200 - 4.089256435759389 - 4.718511893087153 - 4.2674878231294855 - 3.9232240945988046 - 4.599158023584722 - 4.319544972141209 - 0.2851353365763828'\n",
      "569 - random_81 - lr - 3.9497261246804607 - 4.70718795686534 - 4.76562050030032 - 4.321229002886642 - 3.8579662450816223 - 4.320347631139393 - 0.2850025002340639'\n",
      "570 - random_71 - lwr_k=500 - 4.235568429392975 - 4.430356754475696 - 4.292395034954465 - 4.175718968852954 - 4.4685122089554286 - 4.320512835744412 - 0.2849751596379769'\n",
      "571 - random_41 - lwr_k=100 - 3.880365136942116 - 3.947953491861707 - 4.922381422483937 - 3.7173997840858277 - 5.144336845523938 - 4.3224035078030365 - 0.2846622621792053'\n",
      "572 - random_47 - lwr_k=50 - 3.796001697220386 - 3.7186412640332094 - 3.7721826124403104 - 6.107573857083205 - 4.228805093264696 - 4.324524436029018 - 0.2843112583924198'\n",
      "573 - random_75 - lwr_k=20 - 5.205746368914795 - 3.888519950981985 - 5.104826860735672 - 3.494370074104901 - 3.9327974762758924 - 4.3252976976322834 - 0.28418328718264596'\n",
      "574 - random_41 - lwr_k=200 - 3.853406017519496 - 3.9422251523116123 - 4.881449667659866 - 3.687974342348396 - 5.263340829976744 - 4.325591362994419 - 0.284134686926921'\n",
      "575 - random_47 - lwr_k=20 - 3.9600111260816693 - 3.7684660441945255 - 3.858301127674716 - 5.861092012107172 - 4.189217405787696 - 4.327322454079024 - 0.2838481993793823'\n",
      "576 - random_29 - lwr_k=50 - 3.6399463441300197 - 4.494492850379721 - 6.173517658904306 - 3.5749178857339614 - 3.75608413224062 - 4.3277382796817445 - 0.28377938217028986'\n",
      "577 - random_75 - lwr_k=100 - 5.21227070972606 - 3.8242466256920116 - 5.1574447169071105 - 3.4927547472619422 - 3.9532048461020435 - 4.32802339182282 - 0.2837321974329893'\n",
      "578 - random_99 - lwr_k=100 - 4.098089822504158 - 4.841672700481641 - 4.243249156217378 - 3.8660509398354894 - 4.594327221187512 - 4.328706956608867 - 0.2836190706305467'\n",
      "579 - random_89 - lr - 4.202288379853509 - 3.9031169175779556 - 3.9350954842124963 - 5.193452452228312 - 4.440477234961018 - 4.33482816244967 - 0.2826060394475509'\n",
      "580 - random_47 - lr - 3.8237184492753813 - 3.7233592511430484 - 3.8276403469776104 - 5.924475900333056 - 4.381316048758477 - 4.335986506965532 - 0.28241433880134836'\n",
      "581 - random_43 - lr - 4.322373192319882 - 4.687635933909013 - 4.593114120728916 - 3.7593250567578957 - 4.320199448100454 - 4.336564137719576 - 0.2823187435899924'\n",
      "582 - random_99 - lwr_k=50 - 4.118769043157767 - 4.89654298281866 - 4.203272361544207 - 3.903597469497502 - 4.5628099897865475 - 4.337033404804095 - 0.2822410820634673'\n",
      "583 - random_99 - lwr_k=500 - 4.15455600530505 - 4.633131956492334 - 4.281754141289165 - 3.983420653326782 - 4.65691588091078 - 4.341966379949616 - 0.2814246975507875'\n",
      "584 - random_43 - lwr_k=20 - 4.268114797777012 - 4.696038477703131 - 4.463389334993165 - 3.9987058223368868 - 4.294163985343364 - 4.3441108133687765 - 0.2810698037635231'\n",
      "585 - random_41 - lwr_k=500 - 3.8246919493579306 - 3.915958484683739 - 4.92282018102142 - 3.698447670029898 - 5.3764414287338145 - 4.347573945079927 - 0.28049667152365754'\n",
      "586 - random_83 - lwr_k=200 - 4.408580662873322 - 4.806040404554072 - 3.99473476210549 - 4.318312263189454 - 4.211940009619481 - 4.347974872144252 - 0.28043031995358614'\n",
      "587 - random_89 - lwr_k=1000 - 4.227778091228325 - 3.8889875997881687 - 3.9097169602211705 - 5.32412856708719 - 4.411432709435654 - 4.35234842301052 - 0.27970651756510645'\n",
      "588 - random_62 - lwr_k=100 - 4.605201859490418 - 3.942659214446055 - 4.581736222522834 - 3.8970832194042346 - 4.757284560512421 - 4.356776003885682 - 0.27897377346068875'\n",
      "589 - random_43 - lwr_k=50 - 4.193254870081706 - 4.608862006486275 - 4.515158956063429 - 4.216075556399524 - 4.260038001724811 - 4.358686578738324 - 0.27865758218179504'\n",
      "590 - random_62 - lwr_k=50 - 4.5170960631347885 - 3.9645052493267556 - 4.621184258572875 - 3.910604414051301 - 4.784693987813691 - 4.359592402024277 - 0.2785076726282171'\n",
      "591 - random_75 - lwr_k=50 - 5.271214375356724 - 3.8464183710663717 - 5.2261680509636435 - 3.4955987418814765 - 3.9733653305055565 - 4.362593266173858 - 0.2780110435262849'\n",
      "592 - random_33 - lwr_k=50 - 4.297579966111574 - 4.388532724889121 - 4.300231823879775 - 4.2483354960622535 - 4.586010061875178 - 4.364133686567468 - 0.2777561110939776'\n",
      "593 - random_62 - lwr_k=20 - 4.40613124394884 - 3.9802121342521626 - 4.667040171008998 - 3.9705444501455465 - 4.798477442272035 - 4.364445919079114 - 0.2777044380611031'\n",
      "594 - random_89 - lwr_k=500 - 4.228091660984611 - 3.872735519897314 - 3.91084874447922 - 5.393217061956837 - 4.419783253859872 - 4.36487067799172 - 0.277634142430648'\n",
      "595 - random_41 - lwr_k=1000 - 3.783842185406326 - 3.894747328849805 - 4.954200032963951 - 3.6991595590979096 - 5.493419636854837 - 4.364965807967042 - 0.27761839886084405'\n",
      "596 - random_83 - lwr_k=100 - 4.449587124593697 - 4.827039593697948 - 4.002880872695491 - 4.383434407657685 - 4.190332704431329 - 4.370709889992879 - 0.27666777992052505'\n",
      "597 - random_91 - lwr_k=500 - 4.142775473253078 - 4.511591908014552 - 4.351052223037436 - 4.28236639690615 - 4.569855835907611 - 4.371519263610012 - 0.27653383233990536'\n",
      "598 - random_83 - lr - 4.433828540197191 - 4.719615052223052 - 4.072576209766196 - 4.319538429843655 - 4.313266667600736 - 4.371807056874695 - 0.2764862038890802'\n",
      "599 - random_85 - lwr_k=500 - 4.3380710702526795 - 4.3981872830962505 - 4.211797682704054 - 4.435541691521541 - 4.488418432841693 - 4.374401944040665 - 0.27605676209544516'\n",
      "600 - random_20 - deep - 4.359591509514187 - 4.546699875253723 - 4.476211426439226 - 4.441637415171159 - 4.065246366132701 - 4.3778927649015005 - 0.2754790477419625'\n",
      "601 - random_62 - lwr_k=200 - 4.698849764596039 - 3.9171260431995427 - 4.618973801469774 - 3.9506456034004773 - 4.7237945826218715 - 4.381862789676477 - 0.274822026738203'\n",
      "602 - random_89 - lwr_k=200 - 4.237383239529588 - 3.8617982009121006 - 3.9271286213531726 - 5.475040764469814 - 4.409152086254772 - 4.382032319341851 - 0.2747939703646822'\n",
      "603 - random_99 - lwr_k=1000 - 4.2412145533109165 - 4.62868444572994 - 4.326452123448706 - 4.037478599213733 - 4.690477170916955 - 4.384871661447678 - 0.2743240724120235'\n",
      "604 - random_43 - lwr_k=100 - 4.21918716387528 - 4.5277014885016165 - 4.501408744260777 - 4.424757549127805 - 4.254500925806357 - 4.385508697030827 - 0.2742186459769075'\n",
      "605 - random_89 - lwr_k=100 - 4.2373317509173605 - 3.8367116651423214 - 3.916243911776464 - 5.516521951097265 - 4.421451662669587 - 4.38558061564963 - 0.2742067437789777'\n",
      "606 - random_71 - lwr_k=100 - 4.325776298245171 - 4.456963708159581 - 4.36014605896391 - 4.245119039420946 - 4.556220370219575 - 4.3888456133570415 - 0.27366640179799573'\n",
      "607 - random_89 - lwr_k=50 - 4.2635955092665405 - 3.858528817716839 - 3.9248428243565074 - 5.498847743729776 - 4.415033584645238 - 4.392101720674565 - 0.27312753113531607'\n",
      "608 - random_62 - lwr_k=500 - 4.664176796646164 - 3.9020401309122557 - 4.667785515644285 - 3.9622811589276865 - 4.776758305640002 - 4.394585490994075 - 0.2727164786645281'\n",
      "609 - random_71 - lwr_k=200 - 4.325026939547921 - 4.51762741000854 - 4.370451123637473 - 4.2469117856656435 - 4.546913992215356 - 4.401390344020071 - 0.27159030704241294'\n",
      "610 - random_87 - lwr_k=20 - 4.238772617373377 - 4.903715191384497 - 3.8904545270140645 - 4.637406689932125 - 4.337505622372529 - 4.401605762909255 - 0.2715546562151372'\n",
      "611 - random_81 - lwr_k=20 - 4.102675037999084 - 4.596046948730925 - 4.939251989781067 - 4.437991851678493 - 3.9398158793768423 - 4.403145297508325 - 0.27129987037771874'\n",
      "612 - random_62 - lwr_k=1000 - 4.593451563482073 - 3.908783442773577 - 4.669743867069997 - 3.9307662331180526 - 4.928861331253665 - 4.406289424721897 - 0.2707795319029983'\n",
      "613 - random_25 - deep - 3.645877985173828 - 5.266181673497161 - 3.7270528413431845 - 5.218604480461418 - 4.186174266881767 - 4.40878796465361 - 0.270366035444343'\n",
      "614 - random_95 - lr - 3.7215419141762847 - 6.201119603147121 - 3.848954442611813 - 4.27019552622684 - 4.009679726973837 - 4.4104113677587815 - 0.27009736944359153'\n",
      "615 - random_83 - lwr_k=50 - 4.516741767595597 - 4.868007454211557 - 4.0500482129865 - 4.433280853383476 - 4.204760683269478 - 4.414624827099138 - 0.2694000614603156'\n",
      "616 - random_76 - deep - 4.244930474314095 - 5.192832318497291 - 4.0261661888882365 - 4.009778086409677 - 4.605220650745368 - 4.415847770685568 - 0.269197670282446'\n",
      "617 - random_43 - lwr_k=200 - 4.179486904351889 - 4.5038260459294355 - 4.50601410680867 - 4.65385148800802 - 4.248378276127983 - 4.418295627252979 - 0.2687925610561307'\n",
      "618 - random_60 - deep - 3.9476863437582126 - 4.885509302825302 - 4.360485430370856 - 4.7883868589538325 - 4.131311394105946 - 4.422674604565285 - 0.26806786093145085'\n",
      "619 - random_89 - lwr_k=20 - 4.327683949452101 - 3.9126396534363264 - 3.951920044723003 - 5.506165396863737 - 4.462718655348944 - 4.432161474323575 - 0.2664978276610316'\n",
      "620 - random_85 - lwr_k=1000 - 4.432128855791748 - 4.455191023248977 - 4.280813941503827 - 4.527161556372289 - 4.492820396993672 - 4.437624394113808 - 0.26559373976697287'\n",
      "621 - random_91 - lwr_k=1000 - 4.282083482072481 - 4.554798777852058 - 4.4303912900558275 - 4.384651164422272 - 4.615804486382977 - 4.453538633277592 - 0.2629600069787198'\n",
      "622 - random_43 - lwr_k=500 - 4.173936078662612 - 4.480006792063064 - 4.530392508771516 - 4.9068386095600145 - 4.272115075834084 - 4.47262790405245 - 0.2598008211812616'\n",
      "623 - random_87 - lwr_k=50 - 4.186011108953291 - 5.006657864945412 - 3.994444352469096 - 4.572497859711955 - 4.657205321100953 - 4.483386494042488 - 0.2580203244248338'\n",
      "624 - random_83 - lwr_k=20 - 4.5933587008741155 - 4.915559054863531 - 4.1793569828555395 - 4.476659326473126 - 4.25552940402 - 4.484148199090112 - 0.2578942657714317'\n",
      "625 - random_43 - lwr_k=1000 - 4.196237156477418 - 4.48514060881907 - 4.530382185658938 - 4.973807557312953 - 4.2731670528233 - 4.491715900510356 - 0.25664184627734987'\n",
      "626 - random_47 - deep - 3.9090563975706534 - 3.7934571611630483 - 4.065074941216063 - 5.871700252595623 - 4.830069720133129 - 4.493739768072626 - 0.25630690590087013'\n",
      "627 - random_90 - lr - 5.076300927448539 - 5.287971988226122 - 5.08070189457305 - 4.92852834299636 - 2.0997223901277855 - 4.494786248347778 - 0.2561337179472716'\n",
      "628 - random_62 - lr - 4.432024620847712 - 4.048213218403007 - 4.947133936894015 - 3.958948525235311 - 5.136397664092373 - 4.504489307593875 - 0.2545279066345345'\n",
      "629 - random_2 - lr - 4.417109762422943 - 4.966898003703686 - 4.033910239588151 - 4.336074706512628 - 4.774117362740916 - 4.5056602785674835 - 0.2543341163681231'\n",
      "630 - random_33 - lwr_k=100 - 4.430182054790579 - 4.558737183860642 - 4.46721465088882 - 4.379131407541914 - 4.7034217228401545 - 4.507734678099663 - 0.25399081286441105'\n",
      "631 - random_45 - lwr_k=50 - 4.46386647968238 - 4.633595287077434 - 4.454592586225665 - 4.348180438632715 - 4.672099525994305 - 4.514473897811118 - 0.25287550325151487'\n",
      "632 - random_63 - lwr_k=1000 - 3.8709668376660162 - 4.619817388459444 - 5.926803285681351 - 3.6712508749920496 - 4.558921431814727 - 4.529493626656271 - 0.25038980777320563'\n",
      "633 - random_63 - lwr_k=500 - 3.882462249915527 - 4.616625374803995 - 5.9385404355160425 - 3.6705180868797282 - 4.5597015767969316 - 4.533511235250023 - 0.24972491218034487'\n",
      "634 - random_58 - lwr_k=50 - 4.147145364825109 - 4.181873368815292 - 4.628742562118713 - 5.130419672717081 - 4.625589000602244 - 4.542676341459499 - 0.24820812960071348'\n",
      "635 - random_58 - lwr_k=100 - 4.106814428944983 - 4.194067594736854 - 4.625987195814021 - 5.144313030247823 - 4.664775709346217 - 4.54711014025157 - 0.24747435645987936'\n",
      "636 - random_63 - lwr_k=200 - 3.8893631933579145 - 4.636946976201507 - 5.946006743268165 - 3.6803038383079856 - 4.594881234568669 - 4.5494416114064276 - 0.24708850879463962'\n",
      "637 - random_85 - lr - 4.374640114250299 - 4.64021834353846 - 4.401392177082085 - 4.481108495464281 - 4.896985518574697 - 4.558858369383507 - 0.24553007901436352'\n",
      "638 - random_58 - lwr_k=200 - 4.109705746866904 - 4.225401140594748 - 4.630921716781488 - 5.1611185575262475 - 4.6978265704050175 - 4.564913153065408 - 0.24452804039067033'\n",
      "639 - random_87 - lwr_k=100 - 4.257403162892537 - 5.060668473378329 - 4.075965784019998 - 4.55265385707598 - 4.900893434564315 - 4.5695353203118625 - 0.24376309314408884'\n",
      "640 - random_63 - lwr_k=20 - 3.923609055543265 - 4.5615767692007765 - 5.919281538248397 - 3.763395509942332 - 4.70792932221774 - 4.575090164440756 - 0.24284379219822938'\n",
      "641 - random_63 - lwr_k=100 - 3.8962201587299052 - 4.648268119646643 - 6.066533006723364 - 3.686787574455965 - 4.617279523790559 - 4.582953875901995 - 0.24154238441494325'\n",
      "642 - random_1 - deep - 4.952123208190307 - 4.272665955948181 - 4.551212733775928 - 3.8898963859683433 - 5.27018366897865 - 4.587221566623677 - 0.2408361017167192'\n",
      "643 - random_81 - deep - 4.130435996694159 - 5.585878292923404 - 4.7745511595473396 - 4.338155533988373 - 4.12001972619513 - 4.589863232989033 - 0.24039891818268666'\n",
      "644 - random_63 - lr - 4.0043471674621935 - 4.727187074092058 - 5.9285770482321745 - 3.696506319747925 - 4.618538014150916 - 4.594984057604235 - 0.2395514451264389'\n",
      "645 - random_45 - lr - 4.537391973545306 - 4.6859292056999875 - 4.571288524459107 - 4.450989190482615 - 4.77425629674543 - 4.603972616825668 - 0.23806388025469105'\n",
      "646 - random_58 - lwr_k=500 - 4.152726294322047 - 4.283887293819857 - 4.6569814708693285 - 5.144673390080006 - 4.805870484857214 - 4.608747614136699 - 0.23727364034108567'\n",
      "647 - random_63 - lwr_k=50 - 3.9262988679079913 - 4.620082582790523 - 6.173517658904306 - 3.690282112272318 - 4.635140071960093 - 4.608995305054581 - 0.23723264864270388'\n",
      "648 - random_51 - deep - 6.472817523960213 - 4.00788057296933 - 4.05262170435222 - 3.7677486794685193 - 4.795489321499145 - 4.6194390349520695 - 0.23550426010109782'\n",
      "649 - random_58 - lwr_k=20 - 4.192445332548607 - 4.146924489588992 - 4.7531116460847205 - 5.194863413357634 - 4.817495925270342 - 4.620875514428918 - 0.2352665290790552'\n",
      "650 - random_29 - deep - 3.821625274043624 - 5.576061582981225 - 5.922290064715751 - 3.7689453111292157 - 4.076511202406834 - 4.633100199289077 - 0.23324340075028072'\n",
      "651 - random_89 - deep - 4.408011626561157 - 3.9316527778641146 - 3.92818980001571 - 6.37845646625182 - 4.555742147277268 - 4.640313981725417 - 0.2320495532074487'\n",
      "652 - random_87 - lwr_k=200 - 4.30986100580162 - 5.043841832793436 - 4.181633444397301 - 4.547660521752788 - 5.128355432660217 - 4.642277546838867 - 0.23172459195512352'\n",
      "653 - random_58 - lwr_k=1000 - 4.21530447854796 - 4.340212929468639 - 4.702292409656355 - 5.128228747063139 - 4.920747242344507 - 4.661278409936464 - 0.22858003721831088'\n",
      "654 - random_33 - lwr_k=200 - 4.63137500497949 - 4.779844108580034 - 4.640722145689419 - 4.492776774333905 - 4.842049542053031 - 4.677359315997972 - 0.2259187218313088'\n",
      "655 - random_91 - lr - 4.831110023667584 - 4.705000737594912 - 4.677718266207913 - 4.534472720722576 - 4.701838847250664 - 4.69004413782442 - 0.2238194426377743'\n",
      "656 - random_58 - lr - 4.217269467809407 - 4.33201211201529 - 4.7464497765727 - 4.92902594310094 - 5.297291837707446 - 4.704321597295904 - 0.22145658929894985'\n",
      "657 - random_46 - deep - 4.687222046751803 - 5.143028604978167 - 4.183613511326377 - 4.231347272038705 - 5.311407138679551 - 4.711365543021009 - 0.22029084927983866'\n",
      "658 - random_6 - lwr_k=1000 - 4.628186264021979 - 4.79265644943505 - 4.545189454701714 - 4.866474991907617 - 4.770784620706552 - 4.720656254532856 - 0.2187532792690403'\n",
      "659 - random_87 - lwr_k=500 - 4.422814323421325 - 4.9870058687260626 - 4.2364738676685425 - 4.551012931368419 - 5.419973927776028 - 4.723452376342328 - 0.21829053407501853'\n",
      "660 - random_27 - deep - 5.32049735941723 - 4.620595476699524 - 4.3909335562335885 - 3.938784865138467 - 5.408310258168215 - 4.7358725073299865 - 0.21623506032574502'\n",
      "661 - random_15 - deep - 3.880290001462581 - 5.67664634025421 - 3.952692512614037 - 4.777865532242542 - 5.445726918978368 - 4.746650803845534 - 0.21445130223149222'\n",
      "662 - random_45 - lwr_k=100 - 4.742420666517343 - 4.918192328263142 - 4.694575242376784 - 4.57299886069421 - 4.908366651112841 - 4.767323682609041 - 0.21103003631644057'\n",
      "663 - random_49 - lwr_k=1000 - 4.128048770986487 - 5.4676913786837815 - 5.2710245019927795 - 3.7086461541939832 - 5.2819617987980365 - 4.771479939849902 - 0.21034219501538842'\n",
      "664 - random_6 - lwr_k=500 - 4.720955652217091 - 4.789836856394915 - 4.634361961697515 - 4.9485197646034225 - 4.766547034898884 - 4.772040836183746 - 0.21024936927297933'\n",
      "665 - random_6 - lwr_k=100 - 5.012215362404469 - 4.653858620563557 - 4.819378465815302 - 4.845923483902573 - 4.5422801800575625 - 4.774743192527945 - 0.20980214182867551'\n",
      "666 - random_49 - lr - 4.2082468867051945 - 5.5332234985031095 - 5.174888630645121 - 3.7690951618004243 - 5.227971770613282 - 4.782703266024387 - 0.20848478657538805'\n",
      "667 - random_6 - lwr_k=200 - 4.88530000236952 - 4.763601161015432 - 4.737615468803928 - 4.920177618788462 - 4.647660203897832 - 4.79087778477317 - 0.20713194162720783'\n",
      "668 - random_87 - lwr_k=1000 - 4.519749211869931 - 4.9653966578169255 - 4.3358265204899125 - 4.576690201246 - 5.5734607716632745 - 4.794214068688288 - 0.20657980210940008'\n",
      "669 - random_32 - deep - 5.299613992271208 - 5.016533387753216 - 5.459739597915869 - 3.4902381275224 - 4.722264067593052 - 4.797751822033462 - 0.20599432067732992'\n",
      "670 - random_41 - deep - 4.322380521225281 - 4.4264208361575275 - 5.155064934333002 - 3.9416811759956563 - 6.161302920974011 - 4.801282408277268 - 0.20541002502534422'\n",
      "671 - random_49 - lwr_k=500 - 4.111478322349157 - 5.46793153671807 - 5.382101447718992 - 3.696277609205523 - 5.447272353489082 - 4.821005826607238 - 0.2021458904055562'\n",
      "672 - random_6 - lwr_k=50 - 5.100441751429764 - 4.709661024764965 - 4.972238576344033 - 4.883449956253426 - 4.44242070971285 - 4.82165952728639 - 0.20203770597432658'\n",
      "673 - random_87 - lr - 5.031564100745825 - 4.753567293487336 - 4.937118819223356 - 4.726295583882964 - 4.822014553578414 - 4.85411996458451 - 0.19666565411854942'\n",
      "674 - random_93 - deep - 5.498027961274916 - 5.290376886824817 - 4.478535047057228 - 3.9002242308622512 - 5.217074224836283 - 4.876953881878636 - 0.19288674703370845'\n",
      "675 - random_49 - lwr_k=20 - 4.178485764724307 - 5.467602775781397 - 5.470827879199908 - 3.781590919271014 - 5.489535498220956 - 4.877597365571895 - 0.19278025311840918'\n",
      "676 - random_63 - deep - 4.349024604075135 - 4.965090915813025 - 5.922201146824894 - 4.017911302969931 - 5.145364960116282 - 4.879872839929329 - 0.19240367301155692'\n",
      "677 - random_6 - lwr_k=20 - 5.195618601000765 - 4.7743355319582035 - 5.107396260645815 - 5.073191515380434 - 4.286944069749439 - 4.887517208038192 - 0.1911385651879396'\n",
      "678 - random_49 - lwr_k=200 - 4.135114043580263 - 5.494163233392255 - 5.521801329735305 - 3.7070371316508255 - 5.638164831214797 - 4.899238742230143 - 0.18919870563120866'\n",
      "679 - random_6 - lr - 5.531048960111516 - 5.041577542938549 - 4.542605052682573 - 4.827813548243897 - 4.583785448227595 - 4.905444317614114 - 0.18817171168003488'\n",
      "680 - random_49 - lwr_k=50 - 4.151233014682737 - 5.451838000290368 - 5.547042387435018 - 3.732904741018895 - 5.677276951845525 - 4.9120363289474325 - 0.18708076437112375'\n",
      "681 - random_28 - lwr_k=100 - 5.541630354365153 - 5.7072586764124 - 3.857510097163694 - 3.8201403056624796 - 5.668382554847215 - 4.919129226291646 - 0.18590692274998755'\n",
      "682 - random_8 - lr - 4.851243564026947 - 5.123845540081764 - 4.228179016928655 - 5.406738561740573 - 4.993138443745067 - 4.920642762838321 - 0.18565643946968902'\n",
      "683 - random_28 - lwr_k=200 - 5.553584383310796 - 5.723592945331313 - 3.878644857124334 - 3.8150575273574163 - 5.668023981219572 - 4.927926665357179 - 0.1844509873778284'\n",
      "684 - random_49 - lwr_k=100 - 4.148104022448685 - 5.4500007738433895 - 5.588714547165488 - 3.7285475649774837 - 5.726071094100054 - 4.928261068952439 - 0.18439564513342188'\n",
      "685 - random_8 - lwr_k=1000 - 4.864182932013691 - 4.932594599782663 - 4.304561190767972 - 5.262050686644627 - 5.293479383471143 - 4.93136698682741 - 0.1838816301270655'\n",
      "686 - random_83 - deep - 4.870616965198468 - 5.123083513170832 - 4.783567849615516 - 4.862135430870604 - 5.038464481091353 - 4.935586249281304 - 0.18318336210744934'\n",
      "687 - random_33 - lwr_k=500 - 4.88900385267404 - 5.062142328927172 - 4.869786184385304 - 4.764874411887301 - 5.094012220448045 - 4.935971931319297 - 0.18311953316650398'\n",
      "688 - random_8 - lwr_k=500 - 4.875721561927485 - 4.918963861467133 - 4.285254957864551 - 5.22533178026071 - 5.386401679410908 - 4.938326352654133 - 0.18272988735289641'\n",
      "689 - random_28 - lwr_k=500 - 5.570507165844862 - 5.710348944532988 - 3.9102377183080805 - 3.8119227326541014 - 5.694137738041474 - 4.939574772254725 - 0.18252327969784354'\n",
      "690 - random_28 - lwr_k=50 - 5.556174955558894 - 5.724758885455839 - 3.8866166388673364 - 3.857219173119457 - 5.698176301360075 - 4.944732052241574 - 0.18166977377401194'\n",
      "691 - random_28 - lwr_k=1000 - 5.59746388040113 - 5.723599071471941 - 3.9185673152702 - 3.8147400896472576 - 5.706485342965192 - 4.9523165639577105 - 0.1804145722539081'\n",
      "692 - random_50 - lr - 3.826062991568187 - 5.292791417433901 - 5.213718355124119 - 4.9910735604884975 - 5.448743984995444 - 4.954396959302974 - 0.18007027647093288'\n",
      "693 - random_8 - lwr_k=200 - 4.901411955045842 - 4.8951390445188805 - 4.26294635591403 - 5.235304284424006 - 5.488062373013357 - 4.95656083434204 - 0.17971216518572364'\n",
      "694 - random_8 - lwr_k=100 - 4.920596672135302 - 4.854011660059673 - 4.291225899018581 - 5.295358903022121 - 5.52252633132037 - 4.976725531434549 - 0.17637500131938022'\n",
      "695 - random_45 - lwr_k=200 - 4.940805883874584 - 5.149307060759552 - 4.912173992132769 - 4.787384652429017 - 5.17652802028392 - 4.993250559660374 - 0.1736401857735509'\n",
      "696 - random_86 - lwr_k=1000 - 6.068117957627712 - 3.605677723908486 - 3.674125875312672 - 5.512019877686085 - 6.162680739797699 - 5.004490021687697 - 0.17178010692472667'\n",
      "697 - random_8 - lwr_k=50 - 4.945715866862647 - 4.866414418744746 - 4.291319330254505 - 5.3399685484377075 - 5.60954278283371 - 5.010570730373773 - 0.17077377783305514'\n",
      "698 - random_28 - lwr_k=20 - 5.618537866471176 - 5.748927205106302 - 3.944785162693012 - 3.8679207310500616 - 5.8802855305151684 - 5.012229184865485 - 0.17049931130482887'\n",
      "699 - random_86 - lwr_k=100 - 6.081539429952745 - 3.615660752436277 - 3.692695373312039 - 5.541689081606162 - 6.15780745050841 - 5.017843665289185 - 0.1695701408287088'\n",
      "700 - random_86 - lwr_k=500 - 6.068582670005644 - 3.608462525058403 - 3.6855716156968144 - 5.544935272363469 - 6.183310949352819 - 5.018135724949758 - 0.1695218063091467'\n",
      "701 - random_86 - lwr_k=200 - 6.104389571164463 - 3.6211102529175014 - 3.7054393529167924 - 5.498464455546186 - 6.18629354861447 - 5.023106508799283 - 0.16869916463127088'\n",
      "702 - random_86 - lwr_k=50 - 6.067219355256365 - 3.655682439557866 - 3.7501524604657575 - 5.547520709968618 - 6.162947692272335 - 5.036668552519567 - 0.16645470928193096'\n",
      "703 - random_8 - lwr_k=20 - 5.065987491645116 - 4.859458757369796 - 4.318156436157594 - 5.404656723323928 - 5.564018859053002 - 5.042439284688494 - 0.16549967986650538'\n",
      "704 - random_28 - lr - 5.682529901117549 - 5.840368039883017 - 4.05883253653834 - 3.8634829791918666 - 5.79095332389665 - 5.047379982201111 - 0.16468201733787946'\n",
      "705 - random_33 - lwr_k=1000 - 5.01358734910747 - 5.178483705489175 - 4.988044388073034 - 4.884950984802201 - 5.193196772946844 - 5.051661751741969 - 0.16397340433317076'\n",
      "706 - random_86 - deep - 6.067250420338928 - 3.6719009077445 - 3.7997842133657156 - 5.6792463854842605 - 6.161317281899266 - 5.075857464520546 - 0.15996912642440286'\n",
      "707 - random_86 - lwr_k=20 - 6.067803315626596 - 3.7831207811604752 - 3.787315633913718 - 5.592783994681849 - 6.162723979704331 - 5.078718071608109 - 0.15949570885382447'\n",
      "708 - random_50 - lwr_k=1000 - 3.8084423472874986 - 5.8547815071251375 - 5.323448621038031 - 5.458540269876669 - 5.429032248930475 - 5.174778533429341 - 0.1435981478488949'\n",
      "709 - random_50 - lwr_k=500 - 3.814184259384895 - 5.891635726650761 - 5.291107318184144 - 5.5102993381956775 - 5.423956655645472 - 5.18616822876296 - 0.1417132060845011'\n",
      "710 - random_50 - lwr_k=200 - 3.7918683688812855 - 5.932686359591593 - 5.281651306161526 - 5.543540298259107 - 5.428127383035111 - 5.195506318349151 - 0.14016779555813663'\n",
      "711 - random_50 - lwr_k=100 - 3.807524442453468 - 5.934229003667744 - 5.301961524912735 - 5.546494787480019 - 5.4236547753723245 - 5.202704769601377 - 0.13897648525467132'\n",
      "712 - random_50 - lwr_k=50 - 3.800500646938143 - 5.942153803921446 - 5.327284772438722 - 5.540739302574194 - 5.420745310885628 - 5.20621600168915 - 0.13839539262551337'\n",
      "713 - random_58 - deep - 4.6711566219457055 - 4.496372677963046 - 5.203292796743969 - 6.2739007027487 - 5.426085584707084 - 5.2140322749631025 - 0.13710183601415737'\n",
      "714 - random_50 - lwr_k=20 - 3.857580114508606 - 5.851246609663081 - 5.379367065358008 - 5.618609182929801 - 5.3796539809325195 - 5.217216893033444 - 0.13657479611849266'\n",
      "715 - random_99 - deep - 4.757297414581001 - 5.894526404806013 - 5.172583891380984 - 5.314656579763738 - 5.227900829648091 - 5.27340381275213 - 0.1272761218164964'\n",
      "716 - random_45 - lwr_k=500 - 5.2314501759179315 - 5.448062800868422 - 5.201996239950259 - 5.054230838566003 - 5.455219361073148 - 5.278204522282567 - 0.12648162627366832'\n",
      "717 - random_75 - deep - 6.06845769544575 - 5.5021924067302015 - 6.1805573332236285 - 3.897833488805093 - 5.213183562124045 - 5.372529672470525 - 0.1108712516807191'\n",
      "718 - random_4 - deep - 6.040844322535366 - 3.924179222474898 - 5.258399867423996 - 4.624809142745251 - 7.052196106137192 - 5.380004156079265 - 0.10963425930272896'\n",
      "719 - random_22 - deep - 10.948337582822578 - 3.201900847695802 - 3.169260840151589 - 3.273129470539289 - 6.338855560310567 - 5.386643541117089 - 0.10853547186586476'\n",
      "720 - random_45 - lwr_k=1000 - 5.370927210150938 - 5.55923938785743 - 5.298889366981538 - 5.180098929598073 - 5.559574095754646 - 5.393760443418747 - 0.10735765715136669'\n",
      "721 - random_50 - deep - 3.855971836811338 - 6.008011803252688 - 5.92280895558226 - 5.683475714689408 - 5.508291173030218 - 5.395616708702195 - 0.1070504542391989'\n",
      "722 - random_85 - deep - 5.982422089564488 - 5.317786052815421 - 4.84118293687793 - 5.42677841049445 - 5.521459600519106 - 5.4179735025074685 - 0.10335050853310579'\n",
      "723 - random_7 - lwr_k=50 - 4.835091028979825 - 5.860431323825751 - 4.59780016184109 - 3.613417522810092 - 8.518076227727516 - 5.484935085909646 - 0.09226867659036186'\n",
      "724 - random_39 - deep - 5.3565189895903895 - 9.108126920207823 - 3.835367289901514 - 3.447985151709962 - 5.7163095160921005 - 5.493218667036971 - 0.0908977827160643'\n",
      "725 - random_73 - lwr_k=500 - 6.068582670005644 - 6.192798046327015 - 3.257437035876205 - 5.86574229056853 - 6.183310949352819 - 5.51370089030856 - 0.08750806934761646'\n",
      "726 - random_73 - lwr_k=1000 - 6.068117957627712 - 6.197818552958097 - 3.3280431693904493 - 5.8597328137764695 - 6.162680739797699 - 5.523403813946501 - 0.08590228047740045'\n",
      "727 - random_73 - lwr_k=200 - 6.104389571164463 - 6.192088468964143 - 3.274072831987211 - 5.872314066670136 - 6.18629354861447 - 5.525959475620628 - 0.08547933032077948'\n",
      "728 - random_24 - lwr_k=200 - 5.9320553035952885 - 6.090015843835537 - 4.693118197421073 - 5.681311001684762 - 5.245522136193429 - 5.528503579091115 - 0.08505829299326595'\n",
      "729 - random_44 - deep - 6.783943217616622 - 6.068914632420469 - 4.149292426432427 - 3.9798684051639 - 6.678852290833021 - 5.532357799639104 - 0.08442043775896635'\n",
      "730 - random_24 - lwr_k=500 - 5.960117333908456 - 6.098607342088016 - 4.724691696171964 - 5.674559922647599 - 5.249664801734045 - 5.541628370022125 - 0.08288620095303634'\n",
      "731 - random_24 - lwr_k=1000 - 5.980388438314196 - 6.098177239037892 - 4.727926724338632 - 5.68670236491986 - 5.246631145586524 - 5.548066048310132 - 0.0818207950474914'\n",
      "732 - random_24 - lwr_k=100 - 5.996015584865204 - 6.131674025799066 - 4.700291145615172 - 5.689924899817637 - 5.24490477710011 - 5.552667051270662 - 0.081059350392093'\n",
      "733 - random_73 - lwr_k=100 - 6.081539429952745 - 6.230934076876381 - 3.338863515379124 - 5.980782703252276 - 6.15780745050841 - 5.558108254187468 - 0.08015885653988664'\n",
      "734 - random_73 - lwr_k=20 - 6.067803315626596 - 6.2837805497271795 - 3.426688326476121 - 5.861092012107172 - 6.162723979704331 - 5.560543971011989 - 0.07975575669969825'\n",
      "735 - random_0 - deep - 4.674210904132653 - 4.017131820588677 - 6.150129927257248 - 6.269801125144567 - 6.699840732668459 - 5.561973150623129 - 0.07951923449779297'\n",
      "736 - random_49 - deep - 4.41734896249316 - 6.330114533437589 - 6.478629380525749 - 3.7718600384753342 - 6.879411785509552 - 5.575431503322553 - 0.0772919395325562'\n",
      "737 - random_73 - lr - 6.067308952531434 - 6.201119603147121 - 3.680385506899765 - 5.863733180876612 - 6.162172469041336 - 5.59505465289452 - 0.07404439887205982'\n",
      "738 - random_73 - lwr_k=50 - 6.067219355256365 - 6.280259264986403 - 3.3826797940270628 - 6.107573857083205 - 6.162947692272335 - 5.600253751566666 - 0.07318397214972205'\n",
      "739 - random_24 - lwr_k=50 - 6.04811114332694 - 6.201069632192308 - 4.766678048260556 - 5.805842549617851 - 5.341624049898313 - 5.632766075277773 - 0.06780333333318977'\n",
      "740 - random_24 - lr - 6.017259515725955 - 6.306826810293326 - 4.900600226032653 - 5.733243968939961 - 5.325375945438749 - 5.656765046492806 - 0.06383161487886302'\n",
      "741 - random_28 - deep - 6.692711210177457 - 6.660582365287518 - 4.191819804894606 - 3.999671252111635 - 6.7643218079631575 - 5.662029650848496 - 0.06296034767350123'\n",
      "742 - random_88 - lr - 6.067308952531434 - 6.201119603147121 - 4.119599088940896 - 5.863733180876612 - 6.162172469041336 - 5.682879335487018 - 0.05950982114068115'\n",
      "743 - random_88 - lwr_k=1000 - 6.068117957627712 - 6.197818552958097 - 4.1312788123172375 - 5.8597328137764695 - 6.162680739797699 - 5.6840179622139395 - 0.059321383697118146'\n",
      "744 - random_88 - lwr_k=500 - 6.068582670005644 - 6.192798046327015 - 4.132971328698119 - 5.86574229056853 - 6.183310949352819 - 5.688771800020845 - 0.058534645583330436'\n",
      "745 - random_88 - deep - 6.067270569828243 - 6.211563245402415 - 4.1634377468782775 - 5.871256873348165 - 6.161233630758047 - 5.695043694308194 - 0.05749667656737567'\n",
      "746 - random_88 - lwr_k=200 - 6.104389571164463 - 6.192088468964143 - 4.12105720526019 - 5.872314066670136 - 6.18629354861447 - 5.695321573663716 - 0.05745068841633483'\n",
      "747 - random_73 - deep - 6.093933916263179 - 6.211257998181221 - 4.14729499523155 - 5.886871977263652 - 6.179042030898453 - 5.7037723496289 - 0.05605212458666209'\n",
      "748 - random_88 - lwr_k=100 - 6.081539429952745 - 6.230934076876381 - 4.120346673974853 - 5.980782703252276 - 6.15780745050841 - 5.714372798731143 - 0.05429779900704068'\n",
      "749 - random_88 - lwr_k=20 - 6.067803315626596 - 6.2837805497271795 - 4.281247719611318 - 5.861092012107172 - 6.162723979704331 - 5.7314207620022755 - 0.05147644013603103'\n",
      "750 - random_24 - deep - 6.075811008602121 - 6.196509267318671 - 5.096116143330412 - 5.871434177461346 - 5.5001622161826065 - 5.748086267060177 - 0.04871837673587043'\n",
      "751 - random_88 - lwr_k=50 - 6.067219355256365 - 6.280259264986403 - 4.132595768229489 - 6.107573857083205 - 6.162947692272335 - 5.7502061553591455 - 0.04836754464218862'\n",
      "752 - random_24 - lwr_k=20 - 6.210959837449711 - 6.137511564160081 - 4.89070588242779 - 6.089421796221088 - 5.480103578763774 - 5.761825215682338 - 0.046444644035572025'\n",
      "753 - random_67 - lwr_k=1000 - 5.635038880566615 - 5.642993724883982 - 5.926803285681351 - 5.669953589531168 - 6.162680739797699 - 5.807459456175643 - 0.038892388837111325'\n",
      "754 - random_67 - lwr_k=500 - 5.643464970201778 - 5.637969722052401 - 5.9385404355160425 - 5.6691017229110985 - 6.183310949352819 - 5.814441887616378 - 0.03773682881077689'\n",
      "755 - random_67 - lwr_k=200 - 5.644596275331571 - 5.616266582190241 - 5.946006743268165 - 5.6870804915893745 - 6.18629354861447 - 5.816010621588328 - 0.03747721061254272'\n",
      "756 - random_67 - lr - 5.697907154133558 - 5.637236501956767 - 5.92857743774449 - 5.6728563583312415 - 6.162172469041336 - 5.81971874257525 - 0.03686353378353724'\n",
      "757 - random_67 - lwr_k=100 - 5.649706999789871 - 5.609433068811468 - 6.066533006723364 - 5.777544196966892 - 6.15780745050841 - 5.8521592383579355 - 0.03149478215609691'\n",
      "758 - random_67 - deep - 5.767942369137133 - 5.6621382780843295 - 5.9350225352653485 - 5.817210571477056 - 6.161258718071532 - 5.868682959917012 - 0.028760183276152262'\n",
      "759 - random_95 - deep - 5.716943027179262 - 7.381020282218858 - 5.235132998754357 - 6.474923482420998 - 4.66736076255109 - 5.89521035756328 - 0.024370021973507017'\n",
      "760 - random_67 - lwr_k=20 - 5.854646335845529 - 5.831099713388561 - 5.919281538248397 - 5.725873229545821 - 6.162723979704331 - 5.898713493131228 - 0.023790268860348074'\n",
      "761 - random_67 - lwr_k=50 - 5.69667983863347 - 5.656013739639613 - 6.173517658904306 - 5.963622489022021 - 6.162947692272335 - 5.930504095335787 - 0.018529071606570913'\n",
      "762 - random_21 - lwr_k=1000 - 6.068117957627712 - 6.197818552958097 - 5.926803285681351 - 5.8597328137764695 - 6.162680739797699 - 6.043049133853572 - -9.661040366459872e-05'\n",
      "763 - random_14 - lwr_k=1000 - 6.068117957627712 - 6.197818552958097 - 5.926803285681351 - 5.8597328137764695 - 6.162680739797699 - 6.043049133853572 - -9.661040366459872e-05'\n",
      "764 - random_21 - deep - 6.067183011614279 - 6.199149536438145 - 5.930809201156334 - 5.859385713659518 - 6.161271074714112 - 6.043578087190137 - -0.00018414929707044614'\n",
      "765 - random_14 - lr - 6.067308952531434 - 6.201119603147121 - 5.9285770482321745 - 5.863733180876612 - 6.162172469041336 - 6.0446006519209545 - -0.0003533794495222953'\n",
      "766 - random_21 - lr - 6.067308952531434 - 6.201119603147121 - 5.9285770482321745 - 5.863733180876612 - 6.162172469041336 - 6.0446006519209545 - -0.0003533794495222953'\n",
      "767 - random_21 - lwr_k=500 - 6.068582670005644 - 6.192798046327015 - 5.9385404355160425 - 5.86574229056853 - 6.183310949352819 - 6.049811485925312 - -0.0012157483149248804'\n",
      "768 - random_14 - lwr_k=500 - 6.068582670005644 - 6.192798046327015 - 5.9385404355160425 - 5.86574229056853 - 6.183310949352819 - 6.049811485925312 - -0.0012157483149248804'\n",
      "769 - random_14 - lwr_k=20 - 6.067803315626596 - 6.2837805497271795 - 5.919281538248397 - 5.861092012107172 - 6.162723979704331 - 6.05896026915738 - -0.002729829517484017'\n",
      "770 - random_21 - lwr_k=20 - 6.067803315626596 - 6.2837805497271795 - 5.919281538248397 - 5.861092012107172 - 6.162723979704331 - 6.05896026915738 - -0.002729829517484017'\n",
      "771 - random_14 - lwr_k=200 - 6.104389571164463 - 6.192088468964143 - 5.946006743268165 - 5.872314066670136 - 6.18629354861447 - 6.060236550058659 - -0.002941048088609177'\n",
      "772 - random_21 - lwr_k=200 - 6.104389571164463 - 6.192088468964143 - 5.946006743268165 - 5.872314066670136 - 6.18629354861447 - 6.060236550058659 - -0.002941048088609177'\n",
      "773 - random_6 - deep - 5.4772937450731884 - 7.837275288788828 - 5.419054298675036 - 5.58314272314616 - 6.160627297552215 - 6.095593988621641 - -0.008792539785721809'\n",
      "774 - random_14 - lwr_k=100 - 6.081539429952745 - 6.230934076876381 - 6.066533006723364 - 5.980782703252276 - 6.15780745050841 - 6.103530156172541 - -0.010105939150654164'\n",
      "775 - random_21 - lwr_k=100 - 6.081539429952745 - 6.230934076876381 - 6.066533006723364 - 5.980782703252276 - 6.15780745050841 - 6.103530156172541 - -0.010105939150654164'\n",
      "776 - random_91 - deep - 9.837297854514047 - 5.347686806233985 - 4.971180093361856 - 5.006220907646038 - 5.379114131907907 - 6.108604688772975 - -0.01094575033001921'\n",
      "777 - random_14 - lwr_k=50 - 6.067219355256365 - 6.280259264986403 - 6.173517658904306 - 6.107573857083205 - 6.162947692272335 - 6.1583067346072 - -0.019171208885947255'\n",
      "778 - random_21 - lwr_k=50 - 6.067219355256365 - 6.280259264986403 - 6.173517658904306 - 6.107573857083205 - 6.162947692272335 - 6.1583067346072 - -0.019171208885947255'\n",
      "779 - random_14 - deep - 6.342841687356588 - 6.385800657179369 - 5.920892753640239 - 5.952596260047302 - 6.299309492600772 - 6.180325941454364 - -0.022815285076612568'\n",
      "780 - random_8 - deep - 5.234538166629406 - 5.435032917206687 - 4.537836201137096 - 6.4707013821455 - 9.297362042648347 - 6.194917527311679 - -0.025230124874666693'\n",
      "781 - random_39 - lr - 21.167727167021706 - 7.479982757006101 - 3.601811556416842 - 3.3739436217890977 - 4.996134352388815 - 8.125192716847547 - -0.344681718616765'\n",
      "782 - random_7 - lwr_k=20 - 5.114895353406279 - 6.043992443661919 - 4.944458337515744 - 3.615908385444405 - 21.01015712604802 - 8.14535544799362 - -0.3480185571280894'\n",
      "783 - random_7 - lwr_k=1000 - 5.337166558565189 - 5.268250331893391 - 5.074635958938231 - 3.635072552409814 - 23.27936836999706 - 8.518238481252725 - -0.4097289700966602'\n",
      "784 - random_7 - lwr_k=500 - 5.465025160085631 - 5.439513681873739 - 5.521301584381638 - 3.6311288790358716 - 45.52324226111725 - 13.114468966369587 - -1.1703838029439533'\n",
      "785 - random_7 - lwr_k=200 - 5.276973366960637 - 5.603065612837648 - 4.66366980331835 - 3.653481085845385 - 69.00024476012985 - 17.636982415977286 - -1.9188388082358627'\n",
      "786 - random_7 - lwr_k=100 - 4.817171743235164 - 5.72916289339148 - 4.573935783332661 - 3.6254131454997527 - 91.05279941541355 - 21.9562709075525 - -2.6336610253150923'\n",
      "787 - random_7 - deep - 70.39928655296549 - 7.2287714710108375 - 7.709474193486835 - 4.19981887306276 - 96.47661921131048 - 37.20312503581807 - -5.156944682159706'\n",
      "788 - random_43 - deep - 4.717857370870795 - 5.082591608770692 - 4.896194599981915 - 267.4925514863502 - 4.836889324736546 - 57.394437186023794 - -8.49851321569949'\n",
      "789 - random_87 - deep - 6.744128854779968 - 6.328912804957351 - 5.038810583110707 - 4.89134643699599 - 274.13579720687085 - 59.41694078517174 - -8.833228182988767'\n",
      "790 - random_2 - deep - 5.103842550574234 - 5.880895461957842 - 4.4428370424854196 - 4.920464477499897 - 279.8545554785758 - 60.02931990110923 - -8.93457408706825'\n",
      "791 - random_62 - deep - 275.50900177737884 - 4.7768366019991255 - 6.7156885037431975 - 4.830028200051623 - 9.224953547640258 - 60.22771176462717 - -8.967407020535386'\n",
      "792 - random_7 - lr - 5.394000915831102 - 4.759287439859547 - 5.087821337550575 - 3.668621269790466 - 797.4062582920186 - 163.23072268088626 - -26.013927712812563'\n",
      "793 - random_90 - deep - 267.42292174196905 - 270.0807924304882 - 264.3963821066478 - 266.43961658516946 - 3.2867113980914042 - 214.33645803529856 - -34.47168992451174'\n",
      "794 - random_71 - deep - 266.1930262965383 - 268.8438069014258 - 263.1718158761089 - 265.20776752573755 - 268.2838018836427 - 266.34028485570366 - -43.07808212101629'\n",
      "795 - random_33 - deep - 268.003673539766 - 270.6656484276041 - 264.9743244398301 - 267.02076840253824 - 270.1058322037025 - 268.15429055295607 - -43.37829165234874'\n",
      "796 - random_45 - deep - 269.0775572697036 - 271.742846610792 - 266.0397020845198 - 268.09140334237037 - 271.1817662671851 - 269.22689840373016 - -43.55580327795837'\n",
      "797 - random_99 - lr - 3.957797434648527 - 3.775810204388463 - 4.634757193721559 - 3.0702900754609126 - 9008.500711512224 - 1804.4181502150138 - -297.62283688402204'\n",
      "798 - random_86 - lr - 135155.92857902643 - 3.6190195964956846 - 3.6248595507948695 - 5.529195137586971 - 6.162172216989474 - 27043.296477081476 - -4474.540168845812'\n",
      "799 - random_18 - lr - 1135134.8630303163 - 2.54381402201489 - 2.3688152616649623 - 6989051.672180794 - 2.275190184036117 - 1624621.690604641 - -268866.35652368807'\n"
     ]
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(all_scores)\n",
    "scores_df.to_csv(log_dir/f\"scores.csv\",index=False)\n",
    "scores_df_final = pd.DataFrame(all_scores_final)\n",
    "scores_df_final.to_csv(log_dir/f\"test_scores.csv\",index=False)\n",
    "\n",
    "scores_df_sorted = pd.DataFrame(scores_df).sort_values(by='MSE')\n",
    "\n",
    "best_5 = []\n",
    "summary_logger.info(f\"Rank - \" +\" - \".join(list(scores_df_sorted.columns)))\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    if i < 5:\n",
    "        best_5.append((row[\"model_num\"],row[\"predictor\"],row[\"MSE\"],row[\"R2\"]))\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    summary_logger.info(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save scores\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      " Best 5 on Test Sest \n",
      " ---------------------'\n",
      "Rank -  Deep Model - Predictor - Val Set - Test Set'\n",
      "0 - random_40 - lwr_k=200 - 0.5985321359122558 - 0.9009457068634159 - 0.6736427737098073 - 0.8892964741789042'\n",
      "1 - random_40 - lwr_k=100 - 0.6006183097381823 - 0.9006004547686854 - 0.6736494848457566 - 0.8892953712999885'\n",
      "2 - random_40 - lwr_k=1000 - 0.6011631118971884 - 0.9005102925375842 - 0.6677949014277386 - 0.8902574880952434'\n",
      "3 - random_40 - lwr_k=500 - 0.6012394025503398 - 0.9004976667882427 - 0.6690455178969177 - 0.8900519672198013'\n",
      "4 - random_40 - lwr_k=50 - 0.6017082096161734 - 0.9004200813926769 - 0.6887352742843805 - 0.8868162382255651'\n"
     ]
    }
   ],
   "source": [
    "summary_logger.info(\"-----------------------\\n Best 5 on Test Sest \\n ---------------------\")\n",
    "summary_logger.info(f\"Rank -  Deep Model - Predictor - Val Set - Test Set\")\n",
    "for i, (j,k,v,x) in enumerate(best_5):\n",
    "\n",
    "    row = scores_df_final.loc[(scores_df_final['model_num']==j) & (scores_df_final['predictor'] == k)].iloc[0]\n",
    "    #print(row)\n",
    "    s = f\"{i} - {j} - {k} - {v} - {x} - {row['MSE']} - {row['R2']}\"\n",
    "    summary_logger.info(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote Summary Graph'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#take 1 is a scatter plot - lets, for each dataset\n",
    "#graph our deep models by rank - plot - then overlay our knn moels\n",
    "#plot points\n",
    "\n",
    "deep_set = scores_df[scores_df[\"predictor\"]==\"deep\"].sort_values(\"R2\")\n",
    "deep_set[\"order\"] = [i for i in range(0,100)]\n",
    "deep_ordering = {row[\"model_num\"]:row[\"order\"] for index, row in deep_set.iterrows()}\n",
    "\n",
    "def order_models(x):\n",
    "    x = [deep_ordering[i] for i in x]\n",
    "    return x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df[scores_df[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    if knn_model == \"deep\":\n",
    "        s=10\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "#ax.set_ylim(0,600)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "ax.set_ylim(0,1)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot.png\", bbox_inches='tight')\n",
    "logging.getLogger().info(\"Wrote Summary Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (lazydeep)",
   "language": "python",
   "name": "pycharm-12fcba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
