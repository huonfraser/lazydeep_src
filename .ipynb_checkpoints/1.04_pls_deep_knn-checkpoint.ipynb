{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# set seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import utils as ut\n",
    "import experiment as exp\n",
    "from evaluation import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import random\n",
    "#define fixed_hyperparams and create a config gen\n",
    "from configurations import RandomConfigGen, Configuration\n",
    "from torch import nn\n",
    "from deep_net import RandomNet\n",
    "from experiment import run_experiment\n",
    "import regex as re\n",
    "from pathlib import *\n",
    "from plot import *\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sk_models import setup_pls_models_exh, StandardScaler, PLSRegression, CustomWrapper\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "random_state = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up some stuff to manage metadata for each dataset\n",
    "id_col_db = {'A_C_OF_ALPHA':[\"sample_id\"],\n",
    "             'A_C_OF_SIWARE':[],\n",
    "             'A_AL_RT':[],\n",
    "             'PLN7':[\"db_id\", \"sample_id\"],\n",
    "             'mango_684_990': ['Set','Season','Region','Date','Type','Cultivar','Pop','Temp',\"FruitID\"]\n",
    "            }\n",
    "\n",
    "output_col_db= {'A_C_OF_ALPHA':None,\n",
    "             'A_C_OF_SIWARE':None,\n",
    "             'A_AL_RT':None,\n",
    "             'PLN7':None,\n",
    "             'mango_684_990': ['DM']\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\workspace\\lazydeep\\experiments\\1.04\\mango_684_990\n"
     ]
    }
   ],
   "source": [
    "#setup input and output formats, load data\n",
    "\n",
    "file_name = \"mango_684_990.csv\"\n",
    "dataset_name = re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "\n",
    "\n",
    "\n",
    "data_path = Path('D:/workspace/lazydeep/data/soil_data/')\n",
    "model_path = Path('D:/workspace/lazydeep/experiments/1.01/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/1.04\")\n",
    "n_components = 59\n",
    "\n",
    "data_file = data_path / file_name\n",
    "log_dir = log_path / dataset_name\n",
    "model_dir = model_path / dataset_name\n",
    "\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "print(log_dir)\n",
    "\n",
    "id_cols =id_col_db[dataset_name]\n",
    "output_cols = output_col_db[dataset_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% load data\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "if not file_name == 'mango_684_990.csv': \n",
    "    data = data.sample(frac=1)\n",
    "nrow, ncol = data.shape\n",
    "data = ut.sample_data(data,random_state)\n",
    "n_features = ncol - 1-len(id_cols)\n",
    "dataset = TabularDataset(data,id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "#dataset = TabularDataset(data,id_cols = id_cols, cat_cols=None, output_cols=None, ignore_cols= None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% load models\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 models\n"
     ]
    }
   ],
   "source": [
    "n_models = 100\n",
    "\n",
    "model_names = [f\"random_{i}\" for i in range(0,n_models)]\n",
    "deep_models = {name:torch.load(model_dir/\"models\"/name/\"_model\") for name in model_names}\n",
    "#for each model, load state\n",
    "print(f\"Loaded {len(deep_models)} models\")\n",
    "\n",
    "#print(deep_models)\n",
    "for name in model_names:\n",
    "    sub_path = log_dir / name\n",
    "    if not sub_path.exists():\n",
    "        sub_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup logging and tensorboard outputs\n"
    }
   },
   "outputs": [],
   "source": [
    "# set logging, in this case the root logger\n",
    "ut.setup_logger(logger_name=\"\",file_name=log_dir/\"log.txt\")\n",
    "ut.setup_logger(logger_name=\"summary\",file_name=log_dir/\"summary.txt\")\n",
    "summary_logger = logging.getLogger(\"summary\")\n",
    "tb = SummaryWriter(log_dir/\"tb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup experiment\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is (11691, 113)\n"
     ]
    }
   ],
   "source": [
    "fixed_hyperparams = {'bs': 32,'loss': nn.MSELoss(),'epochs': 100}\n",
    "preprocessing = PLSRegression(n_components=n_components)\n",
    "\n",
    "if dataset_name == 'mango_684_990':\n",
    "    eval_ = MangoesSplitter(preprocessing=preprocessing,tensorboard=None,time=True,random_state=random_state)\n",
    "else:\n",
    "    eval_ = CrossValEvaluation(preprocessing=preprocessing,tensorboard=None,time=True,random_state=random_state)\n",
    "    \n",
    "print(f\"Dataset shape is {data.shape}\")\n",
    "scores={} #->model->knn:{fold_0:number,...,fold_n:number,mean:number,median:number\n",
    "preds={} #model-> foldsxknn_models\n",
    "deep_scores_dict={}\n",
    "deep_preds_dict={}\n",
    "actual_y = None\n",
    "\n",
    "device = \"cpu\" #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_fun_cv = lambda name,model, fold : model.load_state(model_dir/'models'/name/f\"_fold_{fold}\")\n",
    "load_fun_pp_cv = lambda fold : preprocessing.from_state(preprocessing.load_state(model_dir/'preprocessing'/f\"_fold_{fold}\"))\n",
    "load_fun_build = lambda name,model : model.load_state(model_dir/'models'/name/f\"_final\")\n",
    "load_fun_pp_build = lambda : preprocessing.from_state(preprocessing.load_state(model_dir/'preprocessing'/f\"_final\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% deep experiment\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5879 - Val 1929 - Test 1905-----------------------------------'\n",
      "Tested (test) on 1905 instances with mean losses of: random_0:0.8233,random_1:0.807,random_2:0.6161,random_3:264.4626,random_4:0.8111,random_5:0.5017,random_6:271.8982,random_7:0.5023,random_8:0.5081,random_9:0.9613,random_10:0.7669,random_11:0.5153,random_12:0.5384,random_13:0.7874,random_14:6.1302,random_15:0.975,random_16:0.5693,random_17:1.1252,random_18:0.5785,random_19:0.5572,random_20:0.8867,random_21:0.4698,random_22:0.9858,random_23:0.7741,random_24:0.8587,random_25:0.7535,random_26:0.5371,random_27:0.8033,random_28:0.8394,random_29:0.7193,random_30:0.562,random_31:0.9906,random_32:0.6003,random_33:273.8991,random_34:0.7762,random_35:0.7732,random_36:0.8258,random_37:0.9836,random_38:6.1238,random_39:0.6793,random_40:0.7944,random_41:0.5056,random_42:0.5355,random_43:0.7195,random_44:0.8293,random_45:280.2945,random_46:0.9234,random_47:6.0263,random_48:0.6994,random_49:0.8373,random_50:0.7393,random_51:0.7148,random_52:0.778,random_53:0.6584,random_54:0.8689,random_55:273.4186,random_56:0.7278,random_57:0.8436,random_58:6.8838,random_59:0.4134,random_60:0.7473,random_61:0.725,random_62:0.5794,random_63:0.8052,random_64:0.6035,random_65:0.8701,random_66:0.7931,random_67:6.1236,random_68:0.6803,random_69:0.5619,random_70:0.7673,random_71:273.2632,random_72:0.6181,random_73:0.8519,random_74:1.05,random_75:0.8066,random_76:0.7017,random_77:0.486,random_78:0.7783,random_79:0.8384,random_80:0.9394,random_81:0.6377,random_82:0.4732,random_83:0.5841,random_84:0.8185,random_85:0.434,random_86:0.4717,random_87:4.3269,random_88:0.8139,random_89:264.5754,random_90:270.2165,random_91:0.5728,random_92:0.6882,random_93:0.5597,random_94:0.6409,random_95:0.588,random_96:0.7434,random_97:0.5466,random_98:0.8587,random_99:0.7637'\n",
      "Testing (test) took 0:00:03.800998'\n",
      "-----------------------------------Fold 1 - Train 5855 - Val 1903 - Test 1955-----------------------------------'\n",
      "Tested (test) on 1955 instances with mean losses of: random_0:0.7404,random_1:0.7755,random_2:0.6009,random_3:262.5446,random_4:0.9456,random_5:0.4824,random_6:269.6083,random_7:0.5154,random_8:0.6012,random_9:0.6951,random_10:0.779,random_11:0.571,random_12:0.643,random_13:0.7999,random_14:5.8446,random_15:0.7685,random_16:0.5991,random_17:0.9216,random_18:0.5979,random_19:0.6741,random_20:0.8948,random_21:0.4829,random_22:0.7879,random_23:1.0789,random_24:0.6761,random_25:0.8572,random_26:0.5406,random_27:0.6925,random_28:0.8148,random_29:0.7344,random_30:0.7124,random_31:0.8559,random_32:0.4716,random_33:271.6738,random_34:0.8813,random_35:0.7995,random_36:0.7161,random_37:1.2464,random_38:5.8493,random_39:0.614,random_40:0.7503,random_41:0.4932,random_42:0.5505,random_43:0.745,random_44:0.7769,random_45:278.0369,random_46:0.7681,random_47:5.8478,random_48:0.726,random_49:0.7618,random_50:0.8083,random_51:0.8029,random_52:0.7879,random_53:0.6669,random_54:0.7673,random_55:271.193,random_56:0.6839,random_57:0.7752,random_58:3.0503,random_59:0.4268,random_60:0.7279,random_61:0.7689,random_62:0.6479,random_63:3.7464,random_64:0.6067,random_65:0.788,random_66:0.6492,random_67:0.7009,random_68:0.6117,random_69:0.5481,random_70:0.7551,random_71:0.6441,random_72:0.5992,random_73:0.8788,random_74:0.7833,random_75:0.7835,random_76:0.737,random_77:0.4911,random_78:0.7281,random_79:0.8646,random_80:0.7668,random_81:0.6102,random_82:0.49,random_83:268.5245,random_84:0.8657,random_85:0.5042,random_86:5.8479,random_87:4.624,random_88:0.9138,random_89:262.3358,random_90:1.1427,random_91:0.6238,random_92:0.6666,random_93:0.5502,random_94:0.633,random_95:0.5624,random_96:0.7657,random_97:0.4833,random_98:0.7793,random_99:0.797'\n",
      "Testing (test) took 0:00:03.498999'\n",
      "-----------------------------------Fold 2 - Train 5821 - Val 1955 - Test 1937-----------------------------------'\n",
      "Tested (test) on 1937 instances with mean losses of: random_0:0.6558,random_1:0.6835,random_2:0.5075,random_3:0.9738,random_4:0.798,random_5:0.4522,random_6:269.2649,random_7:0.4892,random_8:0.4223,random_9:0.7046,random_10:0.8051,random_11:0.6368,random_12:0.6618,random_13:0.7856,random_14:6.1762,random_15:0.7523,random_16:0.5398,random_17:0.7094,random_18:0.5765,random_19:0.7325,random_20:0.8069,random_21:0.4422,random_22:0.9134,random_23:0.7011,random_24:0.6855,random_25:0.8112,random_26:0.4851,random_27:0.7244,random_28:0.7816,random_29:0.7122,random_30:0.5581,random_31:0.9593,random_32:0.4195,random_33:271.3002,random_34:0.7297,random_35:0.7438,random_36:0.6481,random_37:0.8974,random_38:6.176,random_39:0.6235,random_40:0.7361,random_41:0.5074,random_42:0.5036,random_43:0.698,random_44:2.2369,random_45:277.6453,random_46:0.8065,random_47:6.5714,random_48:0.6672,random_49:0.7869,random_50:0.7377,random_51:0.6637,random_52:0.7725,random_53:0.6253,random_54:0.7822,random_55:270.8039,random_56:0.6928,random_57:0.91,random_58:0.7144,random_59:0.3867,random_60:0.7017,random_61:0.5838,random_62:0.5725,random_63:0.7371,random_64:0.5505,random_65:0.6759,random_66:0.7399,random_67:0.8401,random_68:0.7193,random_69:0.5488,random_70:0.7588,random_71:0.5971,random_72:0.5107,random_73:0.7266,random_74:1.0674,random_75:0.8716,random_76:0.7361,random_77:0.4392,random_78:0.7147,random_79:0.7745,random_80:0.6615,random_81:0.6259,random_82:0.4473,random_83:268.1682,random_84:0.8014,random_85:275.1393,random_86:6.176,random_87:4.3096,random_88:0.7102,random_89:5.6602,random_90:267.6176,random_91:0.5358,random_92:1.6703,random_93:0.504,random_94:0.5252,random_95:0.6428,random_96:0.8746,random_97:0.5517,random_98:0.8307,random_99:0.6794'\n",
      "Testing (test) took 0:00:03.223000'\n",
      "-----------------------------------Fold 3 - Train 5787 - Val 1937 - Test 1989-----------------------------------'\n",
      "Tested (test) on 1989 instances with mean losses of: random_0:0.7066,random_1:0.9975,random_2:0.6438,random_3:260.3638,random_4:1.0417,random_5:0.5204,random_6:267.6433,random_7:0.5754,random_8:0.464,random_9:0.9379,random_10:0.8596,random_11:0.6329,random_12:0.799,random_13:0.9147,random_14:6.4061,random_15:0.789,random_16:0.6135,random_17:1.0862,random_18:0.7001,random_19:0.8705,random_20:0.8033,random_21:0.5073,random_22:0.9122,random_23:0.8205,random_24:0.772,random_25:0.7278,random_26:0.5488,random_27:0.9664,random_28:0.9938,random_29:0.7568,random_30:0.6559,random_31:0.9624,random_32:0.5032,random_33:269.6578,random_34:0.8862,random_35:0.8048,random_36:0.8262,random_37:0.8438,random_38:6.4034,random_39:4.7671,random_40:0.8742,random_41:0.646,random_42:0.5816,random_43:0.7231,random_44:0.7742,random_45:275.9956,random_46:1.0199,random_47:9.9144,random_48:0.7344,random_49:0.9226,random_50:0.8697,random_51:0.9098,random_52:0.8685,random_53:0.7651,random_54:0.7684,random_55:269.1788,random_56:0.7884,random_57:0.9352,random_58:1.2457,random_59:0.4572,random_60:0.7988,random_61:0.676,random_62:273.7393,random_63:0.8136,random_64:0.6952,random_65:0.8376,random_66:0.7918,random_67:0.7232,random_68:0.6267,random_69:0.5493,random_70:0.8396,random_71:0.6469,random_72:0.6954,random_73:0.8912,random_74:0.7805,random_75:0.9441,random_76:0.9796,random_77:0.5363,random_78:0.8415,random_79:0.8118,random_80:0.763,random_81:0.7168,random_82:0.5129,random_83:0.6459,random_84:0.8854,random_85:0.58,random_86:4.6641,random_87:5.0035,random_88:0.7846,random_89:260.4029,random_90:266.0062,random_91:0.7484,random_92:0.5931,random_93:0.6018,random_94:0.6342,random_95:0.8044,random_96:0.9894,random_97:0.6002,random_98:0.855,random_99:6.4061'\n",
      "Testing (test) took 0:00:03.461999'\n",
      "-----------------------------------Fold 4 - Train 5797 - Val 1989 - Test 1927-----------------------------------'\n",
      "Tested (test) on 1927 instances with mean losses of: random_0:0.7332,random_1:0.8554,random_2:0.6135,random_3:1.7917,random_4:0.9408,random_5:0.5262,random_6:270.9789,random_7:0.5377,random_8:0.5333,random_9:0.747,random_10:0.8049,random_11:0.5521,random_12:0.7307,random_13:1.0284,random_14:5.7986,random_15:0.9651,random_16:0.5662,random_17:0.8216,random_18:0.6228,random_19:0.6246,random_20:0.819,random_21:0.4895,random_22:0.9501,random_23:0.7698,random_24:0.8942,random_25:0.7917,random_26:0.5457,random_27:0.8672,random_28:0.8769,random_29:0.6746,random_30:0.744,random_31:0.8992,random_32:0.4924,random_33:273.0471,random_34:0.82,random_35:0.8197,random_36:0.8896,random_37:1.0036,random_38:5.8012,random_39:0.7578,random_40:0.8259,random_41:0.6083,random_42:0.5097,random_43:0.825,random_44:0.8816,random_45:279.4056,random_46:0.9935,random_47:5.8152,random_48:0.8881,random_49:0.864,random_50:0.7987,random_51:0.8846,random_52:0.8174,random_53:0.7074,random_54:0.8374,random_55:272.5352,random_56:0.7417,random_57:0.8555,random_58:2.029,random_59:0.4507,random_60:0.7684,random_61:0.7339,random_62:277.1348,random_63:0.766,random_64:0.6608,random_65:0.9564,random_66:0.7348,random_67:0.5814,random_68:0.497,random_69:0.5922,random_70:0.8461,random_71:272.4287,random_72:0.6145,random_73:0.8512,random_74:0.7519,random_75:0.8658,random_76:0.8104,random_77:0.5135,random_78:0.8262,random_79:0.7927,random_80:0.9429,random_81:0.6281,random_82:0.49,random_83:0.595,random_84:0.9434,random_85:0.4887,random_86:5.8002,random_87:4.4985,random_88:0.8787,random_89:263.6673,random_90:1.0107,random_91:0.5723,random_92:0.618,random_93:0.637,random_94:0.6867,random_95:0.635,random_96:0.799,random_97:0.4979,random_98:1.0014,random_99:0.7687'\n",
      "Testing (test) took 0:00:03.306002'\n",
      "Building final model - Train 7413 - Test 1448'\n",
      "Tested (test) on 1448 instances with mean losses of: random_0:0.7685,random_1:0.7583,random_2:0.5721,random_3:0.7352,random_4:0.9395,random_5:0.4787,random_6:268.574,random_7:0.5215,random_8:0.4096,random_9:0.6976,random_10:0.721,random_11:0.5018,random_12:0.6168,random_13:0.8155,random_14:5.8929,random_15:0.7487,random_16:0.8943,random_17:0.6826,random_18:0.5464,random_19:0.7058,random_20:0.7599,random_21:0.4653,random_22:0.7639,random_23:0.7092,random_24:0.6862,random_25:0.7037,random_26:0.4857,random_27:0.8335,random_28:1.1731,random_29:0.6543,random_30:0.6504,random_31:0.7207,random_32:0.5668,random_33:270.5625,random_34:0.7065,random_35:0.6982,random_36:0.6176,random_37:1.026,random_38:0.7917,random_39:0.4505,random_40:0.7275,random_41:0.4609,random_42:0.5744,random_43:0.7258,random_44:0.6989,random_45:276.9312,random_46:0.7984,random_47:0.6308,random_48:0.6628,random_49:0.7918,random_50:0.7511,random_51:0.6939,random_52:0.7636,random_53:0.5972,random_54:276.9572,random_55:270.0935,random_56:0.6652,random_57:0.8751,random_58:0.5744,random_59:0.425,random_60:0.7363,random_61:0.7206,random_62:0.5172,random_63:0.7759,random_64:0.6695,random_65:0.788,random_66:0.6445,random_67:0.4912,random_68:0.5053,random_69:0.5423,random_70:0.7303,random_71:0.589,random_72:0.5599,random_73:0.6972,random_74:0.906,random_75:0.9644,random_76:0.7998,random_77:0.4606,random_78:0.7715,random_79:0.7374,random_80:0.7811,random_81:0.5989,random_82:0.4707,random_83:0.5949,random_84:0.6666,random_85:0.568,random_86:5.865,random_87:4.8651,random_88:1.035,random_89:0.6526,random_90:266.9115,random_91:0.5871,random_92:0.5098,random_93:0.5761,random_94:0.5324,random_95:0.6417,random_96:0.6742,random_97:0.4642,random_98:0.8003,random_99:0.7361'\n",
      "Testing (test) took 0:00:02.522001'\n"
     ]
    }
   ],
   "source": [
    "deep_scheme = DeepScheme(None, fixed_hyperparams=fixed_hyperparams,loss_eval=loss_target,device=device,tensorboard=tb,adaptive_lr=True,update=False)\n",
    "deep_scores, deep_preds, _ , _, _,_ = eval_.evaluate(deep_models,dataset,deep_scheme,logger_name=\"log\",load_fun=load_fun_cv,load_fun_pp = load_fun_pp_cv)\n",
    "deep_scores_final, deep_preds_final, _ ,_, _,_ = eval_.build(deep_models,dataset,deep_scheme,logger_name=\"test_log\",load_fun=load_fun_build,load_fun_pp = load_fun_pp_build)\n",
    "\n",
    "all_scores = []\n",
    "for k,v in ut.flip_dicts(deep_scores).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores.append({**dict1,**v})\n",
    "    \n",
    "all_scores_final = []\n",
    "for k,v in ut.flip_dicts(deep_scores_final).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores_final.append({**dict1,**v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - random_59 - deep - 0.41344394868440204 - 0.4268353875640713 - 0.38668853449156804 - 0.4572330106437476 - 0.45067953918038345 - 0.42715798708023967 - 0.9296530954646005\n",
      "1 - random_21 - deep - 0.46982851644826373 - 0.4829046178351888 - 0.4421578718634937 - 0.5073498061939122 - 0.48945786849971135 - 0.47852009789036615 - 0.9211944791793387\n",
      "2 - random_82 - deep - 0.4732125640228352 - 0.4900174628743125 - 0.4473183443082259 - 0.5129462654654137 - 0.49000114415925466 - 0.4828983874404394 - 0.9204734365526689\n",
      "3 - random_77 - deep - 0.4860427215969156 - 0.4911194901332221 - 0.43916691134255387 - 0.5363065382234411 - 0.5134993734357267 - 0.49345653250734556 - 0.9187346587571994\n",
      "4 - random_5 - deep - 0.5017142913316491 - 0.48238601705912126 - 0.45223166167766826 - 0.5203985189180867 - 0.5261903511747895 - 0.4966379684436345 - 0.9182107210646717\n",
      "5 - random_32 - deep - 0.6002785096018333 - 0.47158061427533476 - 0.41952084913411336 - 0.5031710790293249 - 0.4923633533434727 - 0.49703222356799426 - 0.9181457927982345\n",
      "6 - random_8 - deep - 0.5080500250413349 - 0.6011601694404621 - 0.42232715617336436 - 0.4640228150477057 - 0.5332506147455415 - 0.5056796492422487 - 0.9167216835768623\n",
      "7 - random_7 - deep - 0.5023002931765058 - 0.5153881178487597 - 0.48923106715429304 - 0.575431267240648 - 0.5376530135921326 - 0.5243175672905129 - 0.913652280963928\n",
      "8 - random_26 - deep - 0.5371320825549248 - 0.5405931117894399 - 0.4850721562037963 - 0.5487869446333956 - 0.5457438353002535 - 0.5315419043594639 - 0.9124625343935904\n",
      "9 - random_97 - deep - 0.5465972730181036 - 0.48327337123853775 - 0.551678182771665 - 0.6001728603503044 - 0.49789790622793334 - 0.5361742995292083 - 0.9116996441500913\n",
      "10 - random_42 - deep - 0.5354871283991756 - 0.5505004532196942 - 0.5035576631435735 - 0.5815732258687132 - 0.5096661061527943 - 0.5364561184851363 - 0.911653232537085\n",
      "11 - random_41 - deep - 0.5055569315989187 - 0.4932103213141946 - 0.5073640409301222 - 0.6460074509071189 - 0.608343100510673 - 0.552585427654387 - 0.9089969624761951\n",
      "12 - random_69 - deep - 0.5618994031678347 - 0.5481055722822009 - 0.5488483034955144 - 0.5493316669719431 - 0.5922464039824327 - 0.559967406384735 - 0.9077812545443927\n",
      "13 - random_93 - deep - 0.559697210444553 - 0.5502046555204465 - 0.5040094571964114 - 0.6018472709746862 - 0.6369868177605467 - 0.5706462914208598 - 0.9060225925764506\n",
      "14 - random_16 - deep - 0.5693171352852048 - 0.5991238938573071 - 0.539840969278693 - 0.613539122258556 - 0.5662018288957312 - 0.5778758927114632 - 0.9048319790629461\n",
      "15 - random_11 - deep - 0.5152629307561659 - 0.5710074039981189 - 0.6368289350170909 - 0.6328787176137955 - 0.5520619690016136 - 0.5821118306204367 - 0.904134379746737\n",
      "16 - random_2 - deep - 0.6160685770154938 - 0.6009304374685068 - 0.5074794378302795 - 0.6437977502069142 - 0.6134656500370934 - 0.5965282945829329 - 0.9017601911683147\n",
      "17 - random_72 - deep - 0.6180839566733893 - 0.5992253595605835 - 0.5106962719527359 - 0.6953595492365133 - 0.6145292808648274 - 0.6079915814156575 - 0.8998723492717003\n",
      "18 - random_91 - deep - 0.572838891334734 - 0.6237953310427459 - 0.5358193711823388 - 0.7484457782310958 - 0.5722525782639584 - 0.6115566232353922 - 0.8992852370927339\n",
      "19 - random_18 - deep - 0.578496715183959 - 0.5979342116114429 - 0.5764648697243318 - 0.7000990842022807 - 0.6228058854872907 - 0.6156958838291821 - 0.8986035591687676\n",
      "20 - random_64 - deep - 0.6034875159188519 - 0.6066730947445725 - 0.5504855901910647 - 0.6951898571952256 - 0.660813216926152 - 0.6237104790386219 - 0.8972836682123978\n",
      "21 - random_94 - deep - 0.6408953552483887 - 0.6329989800367819 - 0.5251817057042868 - 0.6341845349278985 - 0.6867205816102139 - 0.6239472078519943 - 0.8972446823108373\n",
      "22 - random_68 - deep - 0.6803233324699202 - 0.6117194662923399 - 0.7193166496954324 - 0.6266901011800214 - 0.4970233093040498 - 0.6269426908553423 - 0.8967513684474719\n",
      "23 - random_81 - deep - 0.6377289477921534 - 0.610160268359172 - 0.6258784995967726 - 0.7167586589530822 - 0.6280942400873913 - 0.6440887686444509 - 0.8939276509146885\n",
      "24 - random_30 - deep - 0.5620471343280762 - 0.7124242669786028 - 0.5580866963948302 - 0.6559213953679863 - 0.7440162215847763 - 0.6468495884324635 - 0.893472982777978\n",
      "25 - random_95 - deep - 0.5880038054752851 - 0.5624079290253428 - 0.6428205031184234 - 0.8043806080305139 - 0.6350276172470416 - 0.6474219420890606 - 0.8933787241915558\n",
      "26 - random_12 - deep - 0.5383620803281078 - 0.6430080079666489 - 0.6617702777446024 - 0.7990284247755585 - 0.7307397198757485 - 0.6755803994895634 - 0.8887414228310988\n",
      "27 - random_53 - deep - 0.6583708469949057 - 0.6669363765765334 - 0.6253329776092849 - 0.7651463695780724 - 0.7074266873497262 - 0.6851039197549816 - 0.8871730331691575\n",
      "28 - random_19 - deep - 0.5571554917675929 - 0.6741122122006038 - 0.73253409199082 - 0.8705187359606579 - 0.6246305387534808 - 0.6932270115939344 - 0.8858352743459337\n",
      "29 - random_61 - deep - 0.7250224621902926 - 0.7688863958544133 - 0.5837713450454964 - 0.6760122379266539 - 0.7338923564462013 - 0.6974060270989713 - 0.8851470493479787\n",
      "30 - random_29 - deep - 0.7192919404800796 - 0.7343873363016816 - 0.7121704001677793 - 0.7567688668715169 - 0.6746345326172978 - 0.7197247486397353 - 0.8814714702389186\n",
      "31 - random_56 - deep - 0.7278380629897431 - 0.6839242734567589 - 0.6928072724535592 - 0.7883631795300138 - 0.7417238810301198 - 0.7271623027228724 - 0.8802466098292149\n",
      "32 - random_0 - deep - 0.8233434692142516 - 0.7404181800534962 - 0.6557550886487247 - 0.7065526181696167 - 0.7332322187663733 - 0.7314378764337999 - 0.8795424830546401\n",
      "33 - random_66 - deep - 0.7931185238943326 - 0.6492050822128725 - 0.7398822985177934 - 0.7917933965999916 - 0.7347713752336061 - 0.7416884826604465 - 0.877854352574897\n",
      "34 - random_43 - deep - 0.7194807369877972 - 0.7449931358437404 - 0.6979676753697964 - 0.7231018133892253 - 0.8249687842278512 - 0.7419952746607352 - 0.8778038282531956\n",
      "35 - random_48 - deep - 0.6994343082110087 - 0.7259562591762494 - 0.667155605711516 - 0.7344379690857374 - 0.8881254496819377 - 0.7429385472443819 - 0.8776484845433747\n",
      "36 - random_60 - deep - 0.747332622482395 - 0.7278605253495218 - 0.7016689527200927 - 0.7987948501751374 - 0.7684493128289568 - 0.7490346467996873 - 0.8766445428018504\n",
      "37 - random_24 - deep - 0.8586748774596087 - 0.6761218462148896 - 0.6855266119132782 - 0.7720447617778231 - 0.894191478686934 - 0.7767078056554252 - 0.8720871632769491\n",
      "38 - random_78 - deep - 0.7783201481100768 - 0.7281411232545858 - 0.7146937582193729 - 0.8415390340571071 - 0.8262488784168939 - 0.7779862374313138 - 0.8718766235684254\n",
      "39 - random_36 - deep - 0.825825823542327 - 0.7160830720306357 - 0.6481307094775344 - 0.826212053370272 - 0.8895648449551088 - 0.7810251167510319 - 0.8713761629429317\n",
      "40 - random_25 - deep - 0.7535487483179788 - 0.8572193084775335 - 0.811197177460345 - 0.7277741305728603 - 0.7916690556880533 - 0.7881964447225924 - 0.8701951462243736\n",
      "41 - random_35 - deep - 0.7732269454815882 - 0.7995107387337843 - 0.7437728562795691 - 0.804796282911852 - 0.8196935088262078 - 0.7883267803179003 - 0.8701736817874252\n",
      "42 - random_50 - deep - 0.7393027552625951 - 0.8083015876352939 - 0.7376816294275735 - 0.8696877841466393 - 0.7987489532051028 - 0.791360949804268 - 0.8696739968051527\n",
      "43 - random_70 - deep - 0.7673272630674006 - 0.7550779571313687 - 0.7587719735375494 - 0.8396021597285915 - 0.8461283373597625 - 0.793589537070376 - 0.8693069798690318\n",
      "44 - random_76 - deep - 0.701677796940791 - 0.7370033334283268 - 0.7360725188046063 - 0.9796149570807672 - 0.8104282268973045 - 0.7941377063339112 - 0.8692167041115428\n",
      "45 - random_51 - deep - 0.7147867902057378 - 0.8029223722570082 - 0.6636983894415596 - 0.9098038227190139 - 0.8846464474459789 - 0.7959723370638586 - 0.8689145662685881\n",
      "46 - random_40 - deep - 0.794378801218168 - 0.7502813647165323 - 0.7361065865824625 - 0.8741588368375077 - 0.825949069249797 - 0.7964826441605335 - 0.8688305258767441\n",
      "47 - random_10 - deep - 0.766873007621665 - 0.7790433095544196 - 0.8051026651830974 - 0.859590848586618 - 0.8049040751780138 - 0.803478114608612 - 0.8676784704155904\n",
      "48 - random_54 - deep - 0.8688877131995254 - 0.7673272242021683 - 0.7822278152437756 - 0.7684475954691329 - 0.8374457244094815 - 0.8043582073651093 - 0.8675335315334995\n",
      "49 - random_52 - deep - 0.7780383690761457 - 0.7879177538025409 - 0.772497841052684 - 0.8684958956120541 - 0.817393148601148 - 0.8052533260139837 - 0.8673861180985534\n",
      "50 - random_9 - deep - 0.9613048807842525 - 0.6950741420926341 - 0.7045960382634854 - 0.937914146107606 - 0.747026353084676 - 0.8092236452731839 - 0.866732262433086\n",
      "51 - random_27 - deep - 0.8033252715125797 - 0.6925073354140572 - 0.7243835840203064 - 0.9663819634416944 - 0.8672045666007223 - 0.8113409249525906 - 0.8663835762888796\n",
      "52 - random_80 - deep - 0.9394110875492646 - 0.7668247296072334 - 0.6614911371306408 - 0.7629655928933003 - 0.9429244764369574 - 0.8138147676008344 - 0.8659761692454081\n",
      "53 - random_79 - deep - 0.8383820106976927 - 0.8646063791516492 - 0.7745218176969746 - 0.811752799409547 - 0.7926765863271841 - 0.8164044150195908 - 0.8655496907871851\n",
      "54 - random_34 - deep - 0.7762347854028536 - 0.8813309729251715 - 0.7296649973664507 - 0.8862377872354364 - 0.8199816894890053 - 0.8193062994151827 - 0.8650717912963087\n",
      "55 - random_88 - deep - 0.8138656954752804 - 0.9138499513611464 - 0.7102155025681085 - 0.7845643726109619 - 0.8786797954371759 - 0.8201783965882758 - 0.8649281691741976\n",
      "56 - random_1 - deep - 0.8070353324019064 - 0.7755137013657318 - 0.6835007956794814 - 0.997473057218986 - 0.8553972409126607 - 0.8246470716750656 - 0.8641922413225873\n",
      "57 - random_65 - deep - 0.8700807731921278 - 0.7879745439190389 - 0.6759321820538993 - 0.8376458130510924 - 0.9564377959521867 - 0.8253276930220057 - 0.8640801525723683\n",
      "58 - random_23 - deep - 0.7740768998626649 - 1.0788724430686678 - 0.701115585598185 - 0.8205011873583269 - 0.7698293947994121 - 0.8295388758749496 - 0.863386630065246\n",
      "59 - random_49 - deep - 0.837267098871116 - 0.7618360541360762 - 0.7869172095944725 - 0.9225614178624209 - 0.864044634941395 - 0.8348224686034406 - 0.8625164967550494\n",
      "60 - random_96 - deep - 0.74337986566889 - 0.7656589961722684 - 0.8745952876160671 - 0.9893884244667579 - 0.7990053924768158 - 0.8354442491625351 - 0.8624140982538963\n",
      "61 - random_73 - deep - 0.85190034203642 - 0.8788203999209587 - 0.726613347931627 - 0.8912010164402309 - 0.8512140958495998 - 0.8402452894936903 - 0.8616234345274494\n",
      "62 - random_20 - deep - 0.8866758864069861 - 0.8947832387731508 - 0.8068812699679806 - 0.8032852250945933 - 0.8189581394133694 - 0.841883500559449 - 0.8613536442368839\n",
      "63 - random_92 - deep - 0.6882339710951477 - 0.6666188739449777 - 1.67031425093029 - 0.5930907487749394 - 0.617952151068394 - 0.8463065578739059 - 0.8606252289899129\n",
      "64 - random_15 - deep - 0.9749696714045808 - 0.7685058674848902 - 0.7523362309771465 - 0.7889830803769267 - 0.9651091604203094 - 0.8489729436980609 - 0.8601861127970764\n",
      "65 - random_75 - deep - 0.8066194851567426 - 0.7835043038858477 - 0.8715980375742383 - 0.9440653817985692 - 0.8658479620090221 - 0.8548215250320912 - 0.8592229338206401\n",
      "66 - random_28 - deep - 0.8394262193694828 - 0.8147656151705691 - 0.7816315061909425 - 0.9938306272059844 - 0.8769058486186722 - 0.8619912104817504 - 0.8580421876023063\n",
      "67 - random_84 - deep - 0.818544678206206 - 0.8657272078497026 - 0.8013893216925303 - 0.8854486511064091 - 0.9433538946204688 - 0.8630820291825881 - 0.8578625451249696\n",
      "68 - random_13 - deep - 0.78737544519069 - 0.7999171947884133 - 0.7855637255069455 - 0.914673299181695 - 1.0284203490600972 - 0.8634280318361843 - 0.8578055633608971\n",
      "69 - random_57 - deep - 0.8435610472999533 - 0.7751739809275283 - 0.9099548465515082 - 0.935205691120863 - 0.8555395831607696 - 0.8641800003021542 - 0.8576817247450004\n",
      "70 - random_98 - deep - 0.8587429223098154 - 0.7793182244995975 - 0.8307030259424346 - 0.8549980344246115 - 1.00139768640489 - 0.8646997385562417 - 0.8575961311743555\n",
      "71 - random_74 - deep - 1.0499723944138355 - 0.7833152449649313 - 1.067382005729439 - 0.780457825082939 - 0.7518961998422837 - 0.8854455111016001 - 0.8541795946120009\n",
      "72 - random_46 - deep - 0.9234007692086728 - 0.768053248044475 - 0.8065461677315928 - 1.0198814096973432 - 0.9934657146476623 - 0.9024868784614203 - 0.8513731214122179\n",
      "73 - random_4 - deep - 0.8111221956768687 - 0.9455630646337329 - 0.7979886372432797 - 1.0417380559498368 - 0.9408044891773139 - 0.9085158843631825 - 0.8503802290505097\n",
      "74 - random_22 - deep - 0.9858015859533795 - 0.7879219267069532 - 0.9134198428431183 - 0.9122395543011664 - 0.9500956116374688 - 0.9093907451698146 - 0.8502361517968767\n",
      "75 - random_17 - deep - 1.1251736619028208 - 0.9215842216825851 - 0.7093729990994616 - 1.0862426303510633 - 0.8216244804469427 - 0.9330809735189204 - 0.8463347048322826\n",
      "76 - random_31 - deep - 0.9906227734458102 - 0.8558928615906659 - 0.9592570120302376 - 0.9623830372092111 - 0.8991748188899228 - 0.9333241511485815 - 0.8462946569015021\n",
      "77 - random_37 - deep - 0.9836027582486471 - 1.2464031951201846 - 0.8973749463682514 - 0.8438296366151462 - 1.0036171448311164 - 0.9946508979621156 - 0.8361950054047647\n",
      "78 - random_44 - deep - 0.829273000821041 - 0.7768584756290211 - 2.236926110429621 - 0.7741821723825791 - 0.8816314481303181 - 1.0985484798639185 - 0.8190845369210464\n",
      "79 - random_63 - deep - 0.8052223052878392 - 3.7464485400168184 - 0.7371213319502237 - 0.8136253690917388 - 0.7660131484316492 - 1.3775834073984792 - 0.7731314141818745\n",
      "80 - random_39 - deep - 0.6792998559205864 - 0.6140030015155178 - 0.6235416495252283 - 4.767111208224309 - 0.7578349238736183 - 1.507708679962723 - 0.7517016144272461\n",
      "81 - random_67 - deep - 6.123643403040768 - 0.7008994242114485 - 0.8401120517693295 - 0.7232451474265036 - 0.5813810195277006 - 1.7730826698858722 - 0.7079982557170293\n",
      "82 - random_99 - deep - 0.7636944109060633 - 0.797005895763407 - 0.6793617197515796 - 6.406122121096496 - 0.7687364130222433 - 1.9100216166034825 - 0.6854463397906339\n",
      "83 - random_58 - deep - 6.883769307674698 - 3.050256757541081 - 0.7144035961003912 - 1.2456768988783842 - 2.0289727890497673 - 2.764142304768172 - 0.544784691573005\n",
      "84 - random_87 - deep - 4.326878597980409 - 4.624034577166028 - 4.309588138996847 - 5.00353510491269 - 4.498466447900476 - 4.555846778516413 - 0.2497161984565709\n",
      "85 - random_86 - deep - 0.47173908185458246 - 5.847892118536907 - 6.175991778405721 - 4.664072764824838 - 5.800216970508063 - 4.607026364493978 - 0.24128764144061898\n",
      "86 - random_38 - deep - 6.123758772602232 - 5.849330421116041 - 6.17597321178966 - 6.403358768373953 - 5.801154817270379 - 6.072188552664382 - -3.93614315497004e-06\n",
      "87 - random_14 - deep - 6.130216883862112 - 5.8446126737862905 - 6.176223538250547 - 6.406108495876261 - 5.798563879762342 - 6.072604607721304 - -7.245455146276392e-05\n",
      "88 - random_47 - deep - 6.026346753838807 - 5.847763544458258 - 6.571396255591633 - 9.914421703421093 - 5.8152021761687855 - 6.853396822071949 - -0.12865793586329977\n",
      "89 - random_85 - deep - 0.4340169454184104 - 0.5041584352703046 - 275.1393340134904 - 0.580030235739555 - 0.4886604629468596 - 55.27155870786766 - -8.102447294786776\n",
      "90 - random_83 - deep - 0.5841125032407405 - 268.52454005092613 - 268.1681733532671 - 0.645906335867608 - 0.5950045787613814 - 107.89161476550726 - -16.76822944587365\n",
      "91 - random_71 - deep - 273.26315836268145 - 0.6440646646577683 - 0.5971360190295041 - 0.6469181903706777 - 272.4287322222042 - 108.02419501393386 - -16.790063545577834\n",
      "92 - random_62 - deep - 0.579430610207435 - 0.6478669851942136 - 0.5725159838941827 - 273.7393272710602 - 277.134766290147 - 111.39561129758225 - -17.34528832570199\n",
      "93 - random_3 - deep - 264.462583446753 - 262.544569229165 - 0.9738436124961156 - 260.36383756289473 - 1.791711052434087 - 158.57906774637374 - -25.115739088290244\n",
      "94 - random_90 - deep - 270.21649384586203 - 1.1426675556870678 - 267.617577910731 - 266.00619965596917 - 1.010737724420501 - 161.26897979435262 - -25.55872971885581\n",
      "95 - random_89 - deep - 264.5753695910997 - 262.33583153922234 - 5.660160948458442 - 260.4028519620363 - 263.6672611761167 - 211.4562389523387 - -33.82386448319069\n",
      "96 - random_6 - deep - 271.89817456823636 - 269.60833304714976 - 269.26493127258647 - 267.6432803208172 - 270.97889889220716 - 269.85846845098087 - -43.441889165996685\n",
      "97 - random_55 - deep - 273.4186484509566 - 271.19296139768323 - 270.80387873691444 - 269.17876420900893 - 272.53522911527085 - 271.40572705058725 - -43.69670086632816\n",
      "98 - random_33 - deep - 273.899119107304 - 271.6738393798204 - 271.3002033302571 - 269.65775947705055 - 273.04705322772406 - 271.89536032642 - -43.77733657104201\n",
      "99 - random_45 - deep - 280.294470551258 - 278.0368955178029 - 277.64529577283804 - 275.9955724195477 - 279.4055767920454 - 278.25509954535113 - -44.82469605216097\n"
     ]
    }
   ],
   "source": [
    "scores_df_sorted = pd.DataFrame(all_scores).sort_values(by='MSE')\n",
    "\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% lwr part\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307f1b39ef1241ea8e4a009914868940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_0'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 5879 - Val 1929 - Test 1905-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of knn_unif_n=5:0.4686,knn_dist_n=5:0.0,knn_unif_n=10:0.5813,knn_dist_n=10:0.0,knn_unif_n=20:0.6474,knn_dist_n=20:0.0,knn_unif_n=50:0.7085,knn_dist_n=50:0.0,knn_unif_n=100:0.7357,knn_dist_n=100:0.0,knn_unif_n=200:0.7602,knn_dist_n=200:0.0,knn_unif_n=500:0.8167,knn_dist_n=500:0.0,knn_unif_n=1000:0.9093,knn_dist_n=1000:0.0'\n",
      "Tested (test) on 1905 instances with mean losses of: knn_unif_n=5:0.736,knn_dist_n=5:0.6635,knn_unif_n=10:0.715,knn_dist_n=10:0.6507,knn_unif_n=20:0.712,knn_dist_n=20:0.6567,knn_unif_n=50:0.7278,knn_dist_n=50:0.6847,knn_unif_n=100:0.7481,knn_dist_n=100:0.712,knn_unif_n=200:0.7664,knn_dist_n=200:0.7364,knn_unif_n=500:0.8262,knn_dist_n=500:0.7894,knn_unif_n=1000:0.9202,knn_dist_n=1000:0.8569'\n",
      "-----------------------------------Fold 1 - Train 5855 - Val 1903 - Test 1955-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of knn_unif_n=5:0.4947,knn_dist_n=5:0.0,knn_unif_n=10:0.6201,knn_dist_n=10:0.0,knn_unif_n=20:0.7049,knn_dist_n=20:0.0,knn_unif_n=50:0.7707,knn_dist_n=50:0.0,knn_unif_n=100:0.8208,knn_dist_n=100:0.0,knn_unif_n=200:0.8791,knn_dist_n=200:0.0,knn_unif_n=500:0.9975,knn_dist_n=500:0.0,knn_unif_n=1000:1.1609,knn_dist_n=1000:0.0'\n",
      "Tested (test) on 1955 instances with mean losses of: knn_unif_n=5:0.7526,knn_dist_n=5:0.6596,knn_unif_n=10:0.75,knn_dist_n=10:0.6547,knn_unif_n=20:0.7681,knn_dist_n=20:0.6833,knn_unif_n=50:0.8021,knn_dist_n=50:0.7373,knn_unif_n=100:0.8394,knn_dist_n=100:0.7847,knn_unif_n=200:0.8906,knn_dist_n=200:0.84,knn_unif_n=500:1.0141,knn_dist_n=500:0.9502,knn_unif_n=1000:1.1751,knn_dist_n=1000:1.077'\n",
      "-----------------------------------Fold 2 - Train 5821 - Val 1955 - Test 1937-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of knn_unif_n=5:0.4956,knn_dist_n=5:0.0,knn_unif_n=10:0.6098,knn_dist_n=10:0.0,knn_unif_n=20:0.6782,knn_dist_n=20:0.0,knn_unif_n=50:0.7353,knn_dist_n=50:0.0,knn_unif_n=100:0.7681,knn_dist_n=100:0.0,knn_unif_n=200:0.7998,knn_dist_n=200:0.0,knn_unif_n=500:0.8661,knn_dist_n=500:0.0,knn_unif_n=1000:0.9693,knn_dist_n=1000:0.0'\n",
      "Tested (test) on 1937 instances with mean losses of: knn_unif_n=5:0.7251,knn_dist_n=5:0.6457,knn_unif_n=10:0.6969,knn_dist_n=10:0.6223,knn_unif_n=20:0.7025,knn_dist_n=20:0.6377,knn_unif_n=50:0.7273,knn_dist_n=50:0.6751,knn_unif_n=100:0.7451,knn_dist_n=100:0.7037,knn_unif_n=200:0.7748,knn_dist_n=200:0.7383,knn_unif_n=500:0.8407,knn_dist_n=500:0.7979,knn_unif_n=1000:0.9451,knn_dist_n=1000:0.8735'\n",
      "-----------------------------------Fold 3 - Train 5787 - Val 1937 - Test 1989-----------------------------------'\n"
     ]
    }
   ],
   "source": [
    "def build_predictors(n):\n",
    "    predictors = {}\n",
    "    for i in [5,10,20,50,100,200,500,1000]:\n",
    "        if i* 2 < n:\n",
    "            predictors[f'knn_unif_n={i}'] = CustomWrapper(KNeighborsRegressor(n_neighbors=i, weights='uniform'))\n",
    "            predictors[f'knn_dist_n={i}'] = CustomWrapper(KNeighborsRegressor(n_neighbors=i, weights='distance'))\n",
    "    return predictors\n",
    "\n",
    "for deep_name,deep_model in tqdm(deep_models.items()):\n",
    "    logging.getLogger().info(f\"Running model {deep_name}\")\n",
    "    temp_dict = {deep_name:deep_model}\n",
    "\n",
    "    lwr_scheme = DeepLWRScheme_1_to_n(lwr_models = build_predictors(nrow),n_neighbours=500,loss_fun_sk = mean_squared_error)\n",
    "    lwr_scores, lwr_preds, _ , _, _,_= eval_.evaluate(temp_dict,dataset,lwr_scheme,logger_name=\"log\")\n",
    "    lwr_scores_final, lwr_preds_final, _ , _, _,_= eval_.build(temp_dict,dataset,lwr_scheme,logger_name=\"test_log\")\n",
    "\n",
    "    #scores\n",
    "    for k,v in ut.flip_dicts(lwr_scores).items():\n",
    "        dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "        all_scores.append({**dict1,**v})\n",
    "\n",
    "    for k,v in ut.flip_dicts(lwr_scores_final).items():\n",
    "        dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "        all_scores_final.append({**dict1,**v})\n",
    "\n",
    "    lwr_preds['deep'] = deep_preds[deep_name]\n",
    "    lwr_preds_final['deep'] = deep_preds_final[deep_name]\n",
    "\n",
    "    lwr_preds.to_csv(log_dir/deep_name/ f\"predictions.csv\",index=False)\n",
    "    lwr_preds_final.to_csv(log_dir/deep_name/ f\"predictions_test.csv\",index=False)\n",
    "\n",
    "    #preds\n",
    "    # todo save predictions - appending solns\n",
    "    plot_preds_and_res(lwr_preds,name_lambda=lambda x:f\"{deep_name} with {x} predictor\",save_lambda= lambda x:f\"deep_lwr{x}\",save_loc=log_dir/deep_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save scores\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(all_scores)\n",
    "scores_df.to_csv(log_dir/f\"scores.csv\",index=False)\n",
    "\n",
    "scores_df_sorted = pd.DataFrame(scores_df).sort_values(by='MSE')\n",
    "\n",
    "best_5 = []\n",
    "summary_logger.info(f\"Rank - \" +\" - \".join(list(scores_df_sorted.columns)))\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    if i < 5:\n",
    "        best_5.append((row[\"model_num\"],row[\"predictor\"],row[\"MSE\"],row[\"R2\"]))\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    summary_logger.info(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save scores\n"
    }
   },
   "outputs": [],
   "source": [
    "scores_df_final = pd.DataFrame(all_scores_final)\n",
    "scores_df_final.to_csv(log_dir/f\"test_scores.csv\",index=False)\n",
    "\n",
    "summary_logger.info(\"-----------------------\\n Best 5 on Test Sest \\n ---------------------\")\n",
    "summary_logger.info(f\"Rank -  Deep Model - Predictor - Val Set - Test Set\")\n",
    "for i, (j,k,v,x) in enumerate(best_5):\n",
    "\n",
    "    row = scores_df_final.loc[(scores_df_final['model_num']==j) & (scores_df_final['predictor'] == k)].iloc[0]\n",
    "    #print(row)\n",
    "    s = f\"{i} - {j} - {k} - {v} - {x} - {row['MSE']} - {row['R2']}\"\n",
    "    summary_logger.info(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#take 1 is a scatter plot - lets, for each dataset\n",
    "#graph our deep models by rank - plot - then overlay our knn moels\n",
    "#plot points\n",
    "\n",
    "deep_set = scores_df[scores_df[\"predictor\"]==\"deep\"].sort_values(\"R2\")\n",
    "deep_set[\"order\"] = [i for i in range(0,100)]\n",
    "deep_ordering = {row[\"model_num\"]:row[\"order\"] for index, row in deep_set.iterrows()}\n",
    "\n",
    "def order_models(x):\n",
    "    x = [deep_ordering[i] for i in x]\n",
    "    return x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df[scores_df[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    if knn_model == \"deep\":\n",
    "        s=10\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot.png\", bbox_inches='tight')\n",
    "logging.getLogger().info(\"Wrote Summary Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df[\"n_features\"] = [deep_models[i].n_features for i in scores_df[\"model_num\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Colormap\n",
    "import seaborn as sns #heatmap of features - pls model - score\n",
    "class nlcmap(Colormap):\n",
    "    def __init__(self, cmap, levels):\n",
    "        self.cmap = cmap\n",
    "        self.N = cmap.N\n",
    "        self.monochrome = self.cmap.monochrome\n",
    "        self.levels = np.asarray(levels, dtype='float64')\n",
    "        self._x = self.levels\n",
    "        self.levmax = self.levels.max()\n",
    "        self.levmin = self.levels.min()\n",
    "        self.transformed_levels = np.linspace(self.levmin, self.levmax, #uniform spacing along levels (colour segments)\n",
    "             len(self.levels))\n",
    "\n",
    "    def __call__(self, xi, alpha=1.0, **kw):\n",
    "        yi = np.interp(xi, self._x, self.transformed_levels)\n",
    "        return self.cmap((yi-self.levmin) / (self.levmax-self.levmin), alpha)\n",
    "    \n",
    "levels = np.concatenate((\n",
    "    [0, 1],\n",
    "    [0.6,0.8,0.9,0.95,0.98]\n",
    "    ))\n",
    "\n",
    "levels = levels[levels <= 1]\n",
    "levels.sort()\n",
    "cmap_nonlin = nlcmap(plt.cm.YlGnBu, levels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df_base = scores_df[scores_df[\"predictor\"]=='deep']\n",
    "scores_df_dist = scores_df[scores_df[\"predictor\"].str.contains('dist')]   #val_eq_list(scores_df[\"predictor\"],'dist')] #np.logical_or(scores_df[\"predictor\"]==\"deep\",'dist' in scores_df[\"predictor\"])]\n",
    "scores_df_unif = scores_df[scores_df[\"predictor\"].str.contains('unif')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_jitter(arr):\n",
    "    stdev = .01 * (max(arr) - min(arr))\n",
    "    return arr + np.random.randn(len(arr)) * stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = scores_df_dist[[\"predictor\",\"n_features\",\"R2\"]]\n",
    "#print(subset)\n",
    "subset = subset[np.logical_not(subset[\"predictor\"]==\"deep\")]\n",
    "trans = subset[\"predictor\"].transform(lambda x: int(x.replace(\"knn_dist_n=\",\"\"))).tolist()\n",
    "subset.loc[:,\"predictor\"]=trans\n",
    "subset=subset.sort_values(\"predictor\",ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sc = ax.scatter(x=rand_jitter(subset[\"n_features\"]), y=rand_jitter(subset[\"predictor\"]), s=20,c=subset[\"R2\"],cmap=cmap_nonlin,vmin=0)\n",
    "ax.set_xlabel(\"Number of Features\")\n",
    "ax.set_ylabel(\"Number of Neighbours\")\n",
    "\n",
    "cbar = fig.colorbar(sc,label=\"R2 Score\")\n",
    "\n",
    "ax.set_title(\"LWR performance as a function of the number of components\")\n",
    "plt.savefig(log_dir/f\"heat_scatter.png\", bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = scores_df_unif[[\"predictor\",\"n_features\",\"R2\"]]\n",
    "#print(subset)\n",
    "subset = subset[np.logical_not(subset[\"predictor\"]==\"deep\")]\n",
    "trans = subset[\"predictor\"].transform(lambda x: int(x.replace(\"knn_unif_n=\",\"\"))).tolist()\n",
    "subset.loc[:,\"predictor\"]=trans\n",
    "subset=subset.sort_values(\"predictor\",ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sc = ax.scatter(x=rand_jitter(subset[\"n_features\"]), y=rand_jitter(subset[\"predictor\"]), s=20,c=subset[\"R2\"],cmap=cmap_nonlin,vmin=0)\n",
    "ax.set_xlabel(\"Number of Features\")\n",
    "ax.set_ylabel(\"Number of Neighbours\")\n",
    "\n",
    "cbar = fig.colorbar(sc,label=\"R2 Score\")\n",
    "\n",
    "ax.set_title(\"LWR performance as a function of the number of components\")\n",
    "plt.savefig(log_dir/f\"heat_scatter.png\", bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "knn_models = scores_df_dist[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df_dist[scores_df_dist[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "ax.scatter(x=order_models(scores_df_base[\"model_num\"].tolist()), y=scores_df_base[\"R2\"], s=10, label='deep')\n",
    "\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot_dist.png\", bbox_inches='tight')\n",
    "logging.getLogger().info(\"Wrote Summary Graph\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "knn_models = scores_df_dist[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df_dist[scores_df_dist[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    y1 = subset[\"R2\"].to_numpy() - scores_df_base[\"R2\"].to_numpy()\n",
    "    \n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=y1, s=s, label=knn_model)\n",
    "\n",
    "ax.set_ylim(-1,1)\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"Difference, KNN R2 - BaseR2\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"improve_plot_dist.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df_unif[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df_unif[scores_df_unif[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "ax.scatter(x=order_models(scores_df_base[\"model_num\"].tolist()), y=scores_df_base[\"R2\"], s=10, label='deep')\n",
    "\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot_unif.png\", bbox_inches='tight')\n",
    "logging.getLogger().info(\"Wrote Summary Graph\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "knn_models = scores_df_unif[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df_unif[scores_df_unif[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    y1 = subset[\"R2\"].to_numpy() - scores_df_base[\"R2\"].to_numpy()\n",
    "    \n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=y1, s=s, label=knn_model)\n",
    "\n",
    "ax.set_ylim(-1,1)\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"Difference, KNN R2 - BaseR2\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"improve_plot_unif.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.colors import Colormap\n",
    "class nlcmap(object):\n",
    "    def __init__(self, cmap, levels):\n",
    "        self.cmap = cmap\n",
    "        self.N = cmap.N\n",
    "        self.monochrome = self.cmap.monochrome\n",
    "        self.levels = np.asarray(levels, dtype='float64')\n",
    "        self._x = self.levels\n",
    "        self.levmax = self.levels.max()\n",
    "        self.levmin = self.levels.min()\n",
    "        self.transformed_levels = np.linspace(self.levmin, self.levmax, #uniform spacing along levels (colour segments)\n",
    "             len(self.levels))\n",
    "\n",
    "    def __call__(self, xi, alpha=1.0, **kw):\n",
    "        yi = np.interp(xi, self._x, self.transformed_levels)\n",
    "        return self.cmap((yi-self.levmin) / (self.levmax-self.levmin), alpha)\n",
    "    \n",
    "levels = np.concatenate((\n",
    "    [0, 1],\n",
    "    [0.6,0.8,0.9,0.95,0.98]\n",
    "    ))\n",
    "\n",
    "levels = levels[levels <= 1]\n",
    "levels.sort()\n",
    "print(levels)\n",
    "cmap_nonlin = nlcmap(plt.cm.YlGnBu, levels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = scores_df_base[[\"model_num\",'predictor' ,\"R2\"]]\n",
    "#subset = subset.sort_values('model_num', key=order_models)\n",
    "#trans = subset[\"predictor\"].transform(lambda x: (x.replace(\"knn_dist_n=\",\"\"))).tolist()\n",
    "#subset.loc[:,\"predictor\"]=trans\n",
    "\n",
    "#trans = subset[\"model_num\"].transform(lambda x: int(x.replace(\"random_\",\"\"))).tolist()\n",
    "#subset.loc[:,\"model_num\"]=trans\n",
    "\n",
    "#subset=subset.sort_values(\"model_num\",ascending=False)\n",
    "wide = subset.pivot(index = \"predictor\",columns= \"model_num\",values=\"R2\")\n",
    "wide = wide.sort_index(axis=1,key=order_models)\n",
    "\n",
    "ax = sns.heatmap(wide, linewidth=0.0,vmin=0,center=0,cbar_kws={'label':\"R2 Score\"},cmap=cmap_nonlin)\n",
    "\n",
    "ax.set_title(\"Grid Search for number of neighbours and deep model \")\n",
    "ax.set_xlabel(\"Deep Model\")\n",
    "ax.set_ylabel(\"Number of Neighbours\")\n",
    "\n",
    "plt.savefig(log_dir/\"pls_heatmap.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# heat map for distance based knn and deep model\n",
    "\n",
    "subset = scores_df_dist[[\"model_num\",\"predictor\",\"R2\"]]\n",
    "subset = subset.sort_values('model_num', key=order_models)\n",
    "\n",
    "trans = subset[\"predictor\"].transform(lambda x: int(x.replace(\"knn_dist_n=\",\"\"))).tolist()\n",
    "subset.loc[:,\"predictor\"]=trans\n",
    "\n",
    "#trans = subset[\"model_num\"].transform(lambda x: int(x.replace(\"random_\",\"\"))).tolist()\n",
    "#subset.loc[:,\"model_num\"]=trans\n",
    "\n",
    "#subset=subset.sort_values(\"model_num\",ascending=False)\n",
    "wide = subset.pivot(index = \"predictor\",columns= \"model_num\",values=\"R2\")\n",
    "wide = wide.sort_index(axis=1,key=order_models)\n",
    "\n",
    "ax = sns.heatmap(wide, linewidth=0.0,vmin=0,center=0,cbar_kws={'label':\"R2 Score\"},cmap=cmap_nonlin)\n",
    "\n",
    "ax.set_title(\"Grid Search for number of neighbours and deep model \")\n",
    "ax.set_xlabel(\"Deep Model\")\n",
    "ax.set_ylabel(\"Number of Neighbours\")\n",
    "\n",
    "#plt.savefig(log_dir/\"pls_heatmap.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heat map for uniform  based knn and deep model\n",
    "\n",
    "subset = scores_df_unif[[\"model_num\",\"predictor\",\"R2\"]]\n",
    "subset = subset.sort_values('model_num', key=order_models)\n",
    "\n",
    "trans = subset[\"predictor\"].transform(lambda x: int(x.replace(\"knn_unif_n=\",\"\"))).tolist()\n",
    "subset.loc[:,\"predictor\"]=trans\n",
    "\n",
    "#trans = subset[\"model_num\"].transform(lambda x: int(x.replace(\"random_\",\"\"))).tolist()\n",
    "#subset.loc[:,\"model_num\"]=trans\n",
    "\n",
    "#subset=subset.sort_values(\"model_num\",ascending=False)\n",
    "wide = subset.pivot(index = \"predictor\",columns= \"model_num\",values=\"R2\")\n",
    "wide = wide.sort_index(axis=1,key=order_models)\n",
    "\n",
    "ax = sns.heatmap(wide, linewidth=0.0,vmin=0,center=0,cbar_kws={'label':\"R2 Score\"},cmap=cmap_nonlin)\n",
    "\n",
    "ax.set_title(\"Grid Search for number of neighbours and deep model \")\n",
    "ax.set_xlabel(\"Deep Model\")\n",
    "ax.set_ylabel(\"Number of Neighbours\")\n",
    "\n",
    "#plt.savefig(log_dir/\"pls_heatmap.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph our deep models by rank on final set - plot - then overlay our knn moels\n",
    "\n",
    "deep_set = scores_df_final[scores_df_final[\"predictor\"]==\"deep\"].sort_values(\"R2\")\n",
    "deep_set[\"order\"] = [i for i in range(0,100)]\n",
    "deep_ordering = {row[\"model_num\"]:row[\"order\"] for index, row in deep_set.iterrows()}\n",
    "\n",
    "def order_models(x):\n",
    "    x = [deep_ordering[i] for i in x]\n",
    "    return x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df_final[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df_final[scores_df_final[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    if knn_model == \"deep\":\n",
    "        s=10\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot_final.png\", bbox_inches='tight')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df_final[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df_final[scores_df_final[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    if knn_model == \"deep\":\n",
    "        pass\n",
    "    else:\n",
    "        y1 = subset[\"R2\"].to_numpy() - scores_df_final[scores_df_final[\"predictor\"]=='deep'][\"R2\"].to_numpy()\n",
    "        ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=y1, s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"improvement_plot_final.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (lazydeep)",
   "language": "python",
   "name": "pycharm-12fcba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
