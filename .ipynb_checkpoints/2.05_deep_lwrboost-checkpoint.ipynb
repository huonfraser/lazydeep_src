{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detected is GeForce GTX 970\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "# set seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import utils as ut\n",
    "import experiment as exp\n",
    "from evaluation import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import random\n",
    "#define fixed_hyperparams and create a config gen\n",
    "from configurations import RandomConfigGen, Configuration\n",
    "from torch import nn\n",
    "from deep_net import RandomNet\n",
    "from experiment import run_experiment\n",
    "import regex as re\n",
    "from pathlib import *\n",
    "from plot import *\n",
    "from sk_models import setup_pls_models_exh, StandardScaler, PLSRegression, DeepKNN,CustomWrapper,LWRBoost\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "random_state = np.random.RandomState(seed)\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"GPU detected is {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col_db = {'A_C_OF_ALPHA':[\"sample_id\"],\n",
    "             'A_C_OF_SIWARE':[],\n",
    "             'A_AL_RT':[],\n",
    "             'PLN7':[\"db_id\", \"sample_id\"],\n",
    "             'mango_684_990': ['Set','Season','Region','Date','Type','Cultivar','Pop','Temp',\"FruitID\"]\n",
    "            }\n",
    "\n",
    "output_col_db= {'A_C_OF_ALPHA':None,\n",
    "             'A_C_OF_SIWARE':None,\n",
    "             'A_AL_RT':None,\n",
    "             'PLN7':None,\n",
    "             'mango_684_990': ['DM']\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\workspace\\lazydeep\\experiments\\2.05_reverse\\PLN7\n"
     ]
    }
   ],
   "source": [
    "#setup input and output formats, load data\n",
    "\n",
    "file_name = \"A_C_OF_SIWARE.csv\"\n",
    "dataset_name = re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "\n",
    "\n",
    "data_path = Path('D:/workspace/lazydeep/data/soil_data/')\n",
    "model_path = Path('D:/workspace/lazydeep/experiments/2.00/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/2.05_reverse\")\n",
    "\n",
    "data_file = data_path / file_name\n",
    "log_dir = log_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "model_dir = model_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "print(log_dir)\n",
    "\n",
    "id_cols =id_col_db[dataset_name]\n",
    "output_cols = output_col_db[dataset_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% load data\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 129)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data = data.sample(frac=1)\n",
    "data = ut.sample_data(data,random_state)\n",
    "nrow, ncol = data.shape\n",
    "n_features = ncol - 1-len(id_cols)\n",
    "\n",
    "dataset = TabularDataset(data,id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup logging and tensorboard outputs\n"
    }
   },
   "outputs": [],
   "source": [
    "# set logging, in this case the root logger\n",
    "ut.setup_logger(logger_name=\"\",file_name=log_dir/\"log.txt\")\n",
    "ut.setup_logger(logger_name=\"summary\",file_name=log_dir/\"summary.txt\")\n",
    "summary_logger = logging.getLogger(\"summary\")\n",
    "tb = SummaryWriter(log_dir/\"tb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% load models\n"
    }
   },
   "outputs": [],
   "source": [
    "if False: \n",
    "    n_models = 100\n",
    "    model_names = [f\"random_{i}\" for i in range(0,n_models)]\n",
    "    deep_models = {name:torch.load(model_dir/\"models\"/name/\"_model\") for name in model_names}\n",
    "    configs =  {name:Configuration().load(model_dir/\"models\"/name/\"_config\") for name in model_names}\n",
    "    #for each model, load state\n",
    "    print(f\"Loaded {len(deep_models)} models\")\n",
    "    #print(deep_models)\n",
    "            \n",
    "n_models = 100\n",
    "epochs = 100\n",
    "bs = 32\n",
    "fixed_hyperparams = {'bs': bs,'loss': nn.MSELoss(),'epochs': epochs}\n",
    "device = \"cpu\"#torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#setup models\n",
    "config_gen = RandomConfigGen(lr= (0,1),\n",
    "                             allow_increase_size=False,\n",
    "                             n_features=50,\n",
    "                             opt=[torch.optim.SGD,\n",
    "                                  torch.optim.Adam],\n",
    "                             lr_update = [None,\n",
    "                                          torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                                          torch.optim.lr_scheduler.ExponentialLR,\n",
    "                                          torch.optim.lr_scheduler.CosineAnnealingLR],\n",
    "                            dropout = [True,False],\n",
    "                            batch_norm = [True,False])\n",
    "configs = {f\"random_{i}\":config_gen.sample() for i in range(n_models)}\n",
    "config_gen.save(log_dir/'config_gen.txt')\n",
    "\n",
    "models = {name:RandomNet(input_size=n_features,\n",
    "                         n_layers=config.n_layers,\n",
    "                         act_function=config.act_function,\n",
    "                         n_features = config.n_features,\n",
    "                         dropout=config.dropout,\n",
    "                         batch_norm=config.batch_norm,\n",
    "                         device=device,dtype=torch.float)\n",
    "          for name, config in configs.items()}\n",
    "preprocessing = StandardScaler()\n",
    "\n",
    "model_names = models.keys()\n",
    "for name in model_names:\n",
    "        sub_path = log_dir / name\n",
    "        if not sub_path.exists():\n",
    "            sub_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == 'mango_684_990':\n",
    "    eval_ = MangoesSplitter(preprocessing=preprocessing,tensorboard=None,time=True,random_state=random_state)\n",
    "else:\n",
    "    eval_ = CrossValEvaluation(preprocessing=preprocessing,tensorboard=None,time=True,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup experiment\n"
    }
   },
   "outputs": [],
   "source": [
    "scores={} #->model->knn:{fold_0:number,...,fold_n:number,mean:number,median:number\n",
    "preds={} #model-> foldsxknn_models\n",
    "deep_scores_dict={}\n",
    "deep_preds_dict={}\n",
    "actual_y = None\n",
    "\n",
    "load_fun_cv = lambda name,model, fold : model.load_state(model_dir/'models'/name/f\"_fold_{fold}\")\n",
    "load_fun_pp_cv = None #lambda fold : preprocessing.from_state(preprocessing.load_state(model_dir/'preprocessing'/f\"_fold_{fold}\"))\n",
    "load_fun_build = lambda name,model : model.load_state(model_dir/'models'/name/f\"_final\")\n",
    "load_fun_pp_build = None #lambda : preprocessing.from_state(preprocessing.load_state(model_dir/'preprocessing'/f\"_final\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% deep experiment\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Tested (test) on 1667 instances with mean losses of: random_0:168.6752,random_1:142.1982,random_2:177.255,random_3:2788.8217,random_4:160.6797,random_5:154.4269,random_6:2779.8074,random_7:401.2411,random_8:2765.041,random_9:149.3919,random_10:167.512,random_11:169.7688,random_12:153.2087,random_13:161.1382,random_14:222.6899,random_15:160.8311,random_16:161.9417,random_17:176.623,random_18:155.8045,random_19:302.548,random_20:160.1394,random_21:155.9266,random_22:155.6808,random_23:160.6616,random_24:466.815,random_25:135.623,random_26:167.997,random_27:155.127,random_28:179.1668,random_29:136.1725,random_30:162.3986,random_31:160.6022,random_32:2757.4355,random_33:2775.6764,random_34:156.4009,random_35:162.9483,random_36:158.9109,random_37:147.8967,random_38:165.4038,random_39:2747.4657,random_40:170.8331,random_41:139.9774,random_42:157.9604,random_43:2772.4607,random_44:183.5971,random_45:2752.1251,random_46:151.0427,random_47:455418.8186,random_48:172.661,random_49:153.9078,random_50:135.8249,random_51:131.5022,random_52:168.7492,random_53:158.8294,random_54:200.3208,random_55:160.3069,random_56:160.2831,random_57:159.7905,random_58:473.1543,random_59:142.4398,random_60:142.1786,random_61:157.9785,random_62:1755495.9501,random_63:139.9983,random_64:168.3735,random_65:153.7564,random_66:174.4618,random_67:466.1579,random_68:163.8287,random_69:151.8311,random_70:186.0737,random_71:2753.8264,random_72:152.0079,random_73:466.8159,random_74:152.5846,random_75:162.6662,random_76:147.5036,random_77:141.4185,random_78:160.6514,random_79:148.5241,random_80:150.4464,random_81:178.4029,random_82:155.2928,random_83:2758.1896,random_84:183.4272,random_85:2775.708,random_86:466.0055,random_87:246.6937,random_88:466.8156,random_89:157.6102,random_90:466.8124,random_91:2761.5697,random_92:162.9657,random_93:164.2251,random_94:173.11,random_95:466.8169,random_96:175.0976,random_97:163.9988,random_98:466.8106,random_99:167.4708'\n",
      "Testing (test) took 0:00:04.423999'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Tested (test) on 1667 instances with mean losses of: random_0:129.7837,random_1:145.8657,random_2:2916.4479,random_3:169.9041,random_4:136.1566,random_5:157.6142,random_6:2920.4468,random_7:394.5629,random_8:2905.4261,random_9:139.6147,random_10:152.235,random_11:172.2804,random_12:163.5037,random_13:160.8778,random_14:514.8747,random_15:139.1824,random_16:171.2828,random_17:189.5887,random_18:183.6983,random_19:152.5679,random_20:134.5814,random_21:145.8322,random_22:147.7791,random_23:179.962,random_24:217.7474,random_25:124.6643,random_26:159.1324,random_27:142.4773,random_28:175.2762,random_29:132.7357,random_30:166.0186,random_31:161.5531,random_32:2897.6139,random_33:2916.1962,random_34:162.7256,random_35:167.5266,random_36:177.5317,random_37:134.2488,random_38:126.2838,random_39:2887.4787,random_40:184.6128,random_41:134.7909,random_42:152.3188,random_43:1088.3178,random_44:164.1074,random_45:2892.1835,random_46:145.6837,random_47:514.8366,random_48:163.9656,random_49:188.3398,random_50:137.8936,random_51:147.3961,random_52:178.5223,random_53:223.1893,random_54:171.0655,random_55:155.2064,random_56:155.6286,random_57:146.0189,random_58:180.1802,random_59:184.232,random_60:128.1376,random_61:157.2373,random_62:2892.3999,random_63:136.8403,random_64:166.6289,random_65:160.8652,random_66:159.1721,random_67:514.7544,random_68:157.4012,random_69:152.1179,random_70:174.3883,random_71:2894.0545,random_72:146.6212,random_73:153.5525,random_74:142.5707,random_75:145.3407,random_76:133.7019,random_77:152.447,random_78:177.0091,random_79:151.2372,random_80:153.1869,random_81:510.6234,random_82:159.1566,random_83:2898.3697,random_84:180.4324,random_85:2916.2729,random_86:200.4193,random_87:251.3475,random_88:513.7797,random_89:138.8195,random_90:164.2016,random_91:2901.8555,random_92:152.2894,random_93:151.9636,random_94:166.2137,random_95:513.7793,random_96:169.0907,random_97:169.9104,random_98:164.6827,random_99:139.7505'\n",
      "Testing (test) took 0:00:04.019000'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Tested (test) on 1667 instances with mean losses of: random_0:151.2626,random_1:166.8958,random_2:193.8949,random_3:2913.8483,random_4:150.1954,random_5:164.7429,random_6:2904.2912,random_7:513.701,random_8:1220.2142,random_9:151.4279,random_10:164.1216,random_11:175.0678,random_12:159.9911,random_13:161.4157,random_14:170.2496,random_15:142.1012,random_16:173.0578,random_17:184.8031,random_18:177.3966,random_19:166.9466,random_20:159.1937,random_21:170.2084,random_22:477.747,random_23:163.8401,random_24:477.6787,random_25:142.1725,random_26:156.0146,random_27:166.2422,random_28:213.8233,random_29:144.0393,random_30:162.5569,random_31:160.7403,random_32:2881.4111,random_33:2900.0478,random_34:167.1478,random_35:477.6798,random_36:173.2915,random_37:144.8687,random_38:151.4955,random_39:2871.2017,random_40:163.184,random_41:143.3331,random_42:163.432,random_43:2896.7712,random_44:164.3843,random_45:2875.9347,random_46:159.1433,random_47:477.6704,random_48:165.8357,random_49:143.9736,random_50:149.6766,random_51:145.6712,random_52:171.271,random_53:177.1728,random_54:162.7656,random_55:158.9924,random_56:160.1342,random_57:151.8008,random_58:400.9486,random_59:143.9285,random_60:142.8526,random_61:163.2594,random_62:2875.9053,random_63:150.8772,random_64:162.5138,random_65:159.2962,random_66:172.9861,random_67:477.1126,random_68:164.2693,random_69:161.8313,random_70:176.7326,random_71:798.4414,random_72:162.6849,random_73:164.3099,random_74:162.3837,random_75:169.111,random_76:142.7053,random_77:159.7828,random_78:178.6427,random_79:173.8417,random_80:149.575,random_81:182.1536,random_82:162.9086,random_83:2882.1166,random_84:165.3816,random_85:2900.0898,random_86:2881.7542,random_87:260.2368,random_88:477.7269,random_89:143.115,random_90:185.8009,random_91:2885.6443,random_92:173.8255,random_93:178.9018,random_94:174.1557,random_95:477.7507,random_96:170.0605,random_97:165.1357,random_98:171.9545,random_99:155.3252'\n",
      "Testing (test) took 0:00:04.450000'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Tested (test) on 1666 instances with mean losses of: random_0:137.5806,random_1:135.7505,random_2:184.8362,random_3:160.1133,random_4:119.132,random_5:128.6304,random_6:2853.7107,random_7:601.337,random_8:2838.7723,random_9:124.4419,random_10:137.0197,random_11:139.2927,random_12:137.0764,random_13:127.5928,random_14:472.3837,random_15:112.9392,random_16:135.3329,random_17:155.5596,random_18:150.2034,random_19:143.7527,random_20:142.3405,random_21:133.5431,random_22:129.3962,random_23:177.5229,random_24:180.264,random_25:179.3938,random_26:141.1121,random_27:140.68,random_28:333.9595,random_29:116.9845,random_30:141.4481,random_31:126.8843,random_32:157.2448,random_33:2849.4901,random_34:128.2169,random_35:130.7988,random_36:131.8871,random_37:121.4262,random_38:117.4127,random_39:2820.891,random_40:128.1076,random_41:127.025,random_42:125.9486,random_43:2846.2375,random_44:187.2067,random_45:2825.6032,random_46:135.7055,random_47:472.5482,random_48:139.7789,random_49:130.5711,random_50:118.1339,random_51:161.4947,random_52:143.6366,random_53:161.7394,random_54:150.1046,random_55:137.1994,random_56:129.6982,random_57:135.7227,random_58:307.9157,random_59:132.7637,random_60:122.9205,random_61:144.9629,random_62:2825.7307,random_63:119.9076,random_64:162.3411,random_65:139.6051,random_66:133.3853,random_67:472.636,random_68:131.8594,random_69:131.7223,random_70:145.0492,random_71:2827.5174,random_72:139.4824,random_73:132.1195,random_74:171.3714,random_75:155.9709,random_76:130.4109,random_77:131.1623,random_78:138.5789,random_79:127.7974,random_80:125.6957,random_81:144.6574,random_82:133.5301,random_83:2831.7393,random_84:153.1978,random_85:2849.5195,random_86:2831.3654,random_87:391.3321,random_88:472.7367,random_89:115.3086,random_90:2815.7636,random_91:2835.2058,random_92:135.4945,random_93:158.2982,random_94:136.4734,random_95:472.5738,random_96:148.4606,random_97:134.1753,random_98:139.7881,random_99:139.3732'\n",
      "Testing (test) took 0:00:03.704999'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Tested (test) on 1666 instances with mean losses of: random_0:159.6227,random_1:144.2742,random_2:2834.6542,random_3:2847.8901,random_4:166.7728,random_5:136.5517,random_6:2838.684,random_7:929.667,random_8:2823.717,random_9:135.5202,random_10:153.9422,random_11:140.7365,random_12:141.9392,random_13:142.1694,random_14:467.9307,random_15:129.9273,random_16:153.9851,random_17:153.525,random_18:169.8029,random_19:140.4964,random_20:167.1936,random_21:139.8431,random_22:143.4443,random_23:160.617,random_24:178.9003,random_25:122.9214,random_26:147.5587,random_27:148.4822,random_28:143.7044,random_29:125.2608,random_30:145.7569,random_31:142.4353,random_32:2816.0118,random_33:2834.4859,random_34:147.0571,random_35:145.566,random_36:145.1523,random_37:171.792,random_38:128.3516,random_39:2805.9582,random_40:141.6007,random_41:133.1388,random_42:136.0565,random_43:2831.23,random_44:149.0587,random_45:2810.6466,random_46:143.4608,random_47:519.9092,random_48:155.1668,random_49:135.7362,random_50:467.9324,random_51:127.2153,random_52:144.0371,random_53:146.6787,random_54:2811.8718,random_55:146.845,random_56:155.2565,random_57:140.4051,random_58:205.7508,random_59:128.5705,random_60:132.1877,random_61:152.0262,random_62:2810.8454,random_63:129.6221,random_64:159.9573,random_65:137.1215,random_66:134.662,random_67:467.8753,random_68:146.9289,random_69:143.3327,random_70:162.1905,random_71:2812.6102,random_72:150.7046,random_73:136.0022,random_74:145.534,random_75:140.587,random_76:135.3764,random_77:137.0297,random_78:154.8747,random_79:141.2425,random_80:133.9536,random_81:146.8192,random_82:141.9439,random_83:2816.7838,random_84:165.3498,random_85:2834.4983,random_86:467.9214,random_87:251.5597,random_88:467.9193,random_89:137.4482,random_90:158.2107,random_91:2820.2008,random_92:142.8631,random_93:130.8483,random_94:146.2958,random_95:467.8905,random_96:155.9877,random_97:153.0086,random_98:154.4616,random_99:223.3366'\n",
      "Testing (test) took 0:00:03.785025'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Tested (test) on 1667 instances with mean losses of: random_0:135.7013,random_1:143.3014,random_2:2881.6263,random_3:141.1135,random_4:131.8869,random_5:163.6865,random_6:2885.7369,random_7:452.717,random_8:861.3313,random_9:136.2518,random_10:154.7518,random_11:152.7285,random_12:149.397,random_13:158.8995,random_14:367.3348,random_15:183.5123,random_16:156.936,random_17:164.01,random_18:519.4505,random_19:1767.855,random_20:135.8382,random_21:153.7441,random_22:481.2294,random_23:165.1057,random_24:211.4781,random_25:126.5041,random_26:166.2477,random_27:271.8957,random_28:145.9399,random_29:135.5702,random_30:163.7972,random_31:145.9694,random_32:715.5797,random_33:2881.533,random_34:148.9012,random_35:151.4471,random_36:162.9087,random_37:144.1007,random_38:129.779,random_39:2852.8809,random_40:156.7432,random_41:134.2822,random_42:152.8337,random_43:626.8925,random_44:137.5509,random_45:2857.5309,random_46:145.3016,random_47:481.2548,random_48:187.6362,random_49:142.8628,random_50:131.2078,random_51:135.8368,random_52:151.2879,random_53:162.4404,random_54:167.1286,random_55:156.5082,random_56:156.1106,random_57:151.9005,random_58:2871.6397,random_59:128.6895,random_60:125.8091,random_61:143.6478,random_62:1970.2414,random_63:137.0899,random_64:163.9724,random_65:152.7942,random_66:143.9938,random_67:481.3118,random_68:161.9204,random_69:144.9665,random_70:163.8552,random_71:2859.5289,random_72:155.9846,random_73:154.3482,random_74:137.2424,random_75:128.9325,random_76:144.2839,random_77:151.2724,random_78:162.2784,random_79:147.9525,random_80:150.182,random_81:152.9371,random_82:152.7163,random_83:2863.6858,random_84:159.7901,random_85:2692.2936,random_86:481.2478,random_87:392.4902,random_88:481.2392,random_89:127.0415,random_90:2847.7452,random_91:2867.1868,random_92:146.7081,random_93:144.0763,random_94:161.8435,random_95:481.2365,random_96:175.0758,random_97:155.5964,random_98:157.5219,random_99:138.8018'\n",
      "Testing (test) took 0:00:03.388999'\n"
     ]
    }
   ],
   "source": [
    "deep_scheme = DeepScheme(configs, fixed_hyperparams=fixed_hyperparams,loss_eval=loss_target,device=device,tensorboard=tb,adaptive_lr=False,update=False)\n",
    "deep_scores, deep_preds, _ , _, _,_ = eval_.evaluate(models,dataset,deep_scheme,logger_name=\"log\",load_fun=load_fun_cv,load_fun_pp=load_fun_pp_cv)\n",
    "deep_scores_final, deep_preds_final, _ ,_, _,_ = eval_.build(models,dataset,deep_scheme,logger_name=\"test_log\",load_fun=load_fun_build,load_fun_pp=load_fun_pp_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "for k,v in ut.flip_dicts(deep_scores).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores.append({**dict1,**v})\n",
    "\n",
    "all_scores_final = []\n",
    "for k,v in ut.flip_dicts(deep_scores_final).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores_final.append({**dict1,**v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - random_29 - deep - 136.1725005096637 - 132.73565888018686 - 144.03927211383896 - 116.98450558812392 - 125.26079097715747 - 131.04092569468253 - 0.7267939682642388\n",
      "1 - random_60 - deep - 142.17859075050833 - 128.13758790600278 - 142.85257588222345 - 122.92048939937303 - 132.18773698749519 - 133.65686071986772 - 0.721340029170626\n",
      "2 - random_63 - deep - 139.99827609551332 - 136.84030156859254 - 150.87722592963098 - 119.90759105155735 - 129.62207239615816 - 135.45165808914675 - 0.7175980724923514\n",
      "3 - random_41 - deep - 139.9773749138112 - 134.79085337107384 - 143.33308914999228 - 127.02502206937463 - 133.13876126622523 - 135.65435717780355 - 0.7171754670097146\n",
      "4 - random_15 - deep - 160.83109276582184 - 139.18237164639825 - 142.10121095516615 - 112.93918198382869 - 129.92729984755132 - 136.99996686917987 - 0.714370017627415\n",
      "5 - random_38 - deep - 165.40380923906773 - 126.28380756343849 - 151.49548406892717 - 117.41265477138121 - 128.35157377007198 - 137.79304447122234 - 0.7127165373626512\n",
      "6 - random_76 - deep - 147.50356340093677 - 133.70192617360317 - 142.70530851715398 - 130.41092553659647 - 135.3764460725086 - 137.9408449354203 - 0.7124083895218285\n",
      "7 - random_89 - deep - 157.6102232449628 - 138.81946500104277 - 143.11499358911178 - 115.3086240660815 - 137.44818125309206 - 138.46319673387768 - 0.7113193430176922\n",
      "8 - random_9 - deep - 149.39190404716908 - 139.6147094616721 - 151.42794304717853 - 124.4418745372905 - 135.52024603634177 - 140.08175967058432 - 0.7079448159017704\n",
      "9 - random_25 - deep - 135.62300222679463 - 124.66425230578884 - 142.172465985166 - 179.39382509595634 - 122.92136841919385 - 140.9525339566914 - 0.706129346528491\n",
      "10 - random_80 - deep - 150.446411732363 - 153.186911635007 - 149.5749560437949 - 125.69569691890428 - 133.9536481699308 - 142.5745847496012 - 0.702747547612958\n",
      "11 - random_51 - deep - 131.50222779235656 - 147.39610368331608 - 145.6711838372682 - 161.49469884389302 - 127.2153420648655 - 142.65550277451575 - 0.7025788423602624\n",
      "12 - random_37 - deep - 147.89674255242946 - 134.24878658301543 - 144.8687223572894 - 121.42620939366958 - 171.7920472693472 - 144.0458850925581 - 0.6996800469366633\n",
      "13 - random_77 - deep - 141.41848580738565 - 152.44696096181156 - 159.7827531583451 - 131.16227073715228 - 137.0297264978379 - 144.37050393806894 - 0.6990032520640805\n",
      "14 - random_59 - deep - 142.4398314436539 - 184.23196019365463 - 143.92848195268783 - 132.76368914875522 - 128.57047085802094 - 146.39065862060264 - 0.6947914499772013\n",
      "15 - random_4 - deep - 160.67967036704354 - 136.15657521266743 - 150.19544177292775 - 119.13196152484431 - 166.77277165443815 - 146.5881570557829 - 0.6943796872896015\n",
      "16 - random_57 - deep - 159.7904615442268 - 146.01889144265874 - 151.80081647645233 - 135.72267977015025 - 140.4050533871691 - 146.74966495924548 - 0.694042960933579\n",
      "17 - random_1 - deep - 142.19819260330064 - 145.8656975392031 - 166.89576993048655 - 135.75048071596802 - 144.2742012729164 - 146.99854487720495 - 0.6935240734607993\n",
      "18 - random_46 - deep - 151.04274122058524 - 145.68367116981878 - 159.143342364242 - 135.70546858880272 - 143.46080453055245 - 147.00898761989248 - 0.6935023014817403\n",
      "19 - random_42 - deep - 157.96039355208794 - 152.31878524807735 - 163.43198521350342 - 125.94857498663528 - 136.05654346699617 - 147.14713041272998 - 0.6932142888319215\n",
      "20 - random_69 - deep - 151.83107552988915 - 152.11785674481314 - 161.83130352956204 - 131.72231268224454 - 143.3326665688248 - 148.16959547555277 - 0.6910825607407058\n",
      "21 - random_5 - deep - 154.4268641434677 - 157.61419849819097 - 164.74289030819935 - 128.63040985437144 - 136.55170075003267 - 148.3970045486921 - 0.6906084376366164\n",
      "22 - random_79 - deep - 148.52410355026163 - 151.23718908867153 - 173.84167050600195 - 127.79742369359853 - 141.24248898472965 - 148.53193713025712 - 0.6903271179270234\n",
      "23 - random_21 - deep - 155.92660446487363 - 145.8321907029727 - 170.20840877905962 - 133.54314423523314 - 139.84305465350204 - 149.07365109995797 - 0.6891977034085193\n",
      "24 - random_0 - deep - 168.67518222925546 - 129.78372706806294 - 151.2625998558223 - 137.58057347694938 - 159.62268727681501 - 149.38514379193106 - 0.6885482751338217\n",
      "25 - random_65 - deep - 153.75635183708496 - 160.86524948733398 - 159.29620025625613 - 139.6050523297698 - 137.12145650801824 - 150.13168580529572 - 0.6869918164937889\n",
      "26 - random_72 - deep - 152.00788059017225 - 146.62118623638554 - 162.68488430075826 - 139.4823624334988 - 150.70464058426106 - 150.30144076009486 - 0.6866378959355947\n",
      "27 - random_31 - deep - 160.60224680909155 - 161.55305201777028 - 160.74028490429234 - 126.8842927857178 - 142.43531239705354 - 150.44682596126827 - 0.6863347836546403\n",
      "28 - random_49 - deep - 153.90777889954236 - 188.33975399134042 - 143.9736438721472 - 130.57105660867862 - 135.7361892755149 - 150.50984892510874 - 0.6862033876516909\n",
      "29 - random_82 - deep - 155.2928008621298 - 159.15661904850475 - 162.9086309397514 - 133.53006583759907 - 141.94385565200201 - 150.56947311104904 - 0.6860790777298105\n",
      "30 - random_27 - deep - 155.12704674412407 - 142.4773250916223 - 166.2422095323367 - 140.68000190798975 - 148.482188711361 - 150.60319946151915 - 0.6860087619690813\n",
      "31 - random_13 - deep - 161.13820124616433 - 160.87779566279127 - 161.41571088858402 - 127.59279784606714 - 142.1694399775291 - 150.6425717124402 - 0.6859266751219562\n",
      "32 - random_12 - deep - 153.20874824363742 - 163.50373993194526 - 159.99108746098986 - 137.0764210164046 - 141.93918210289488 - 151.14662822700683 - 0.6848757722884691\n",
      "33 - random_55 - deep - 160.30691876151138 - 155.20635988158813 - 158.9923972511406 - 137.1994227012094 - 146.84495542601806 - 151.71233610341127 - 0.6836963330925478\n",
      "34 - random_56 - deep - 160.28305502687303 - 155.62859651580425 - 160.13422551238043 - 129.6981688427324 - 155.25649193698476 - 152.20244198233425 - 0.6826745158121748\n",
      "35 - random_34 - deep - 156.40087034091596 - 162.72557486183427 - 167.14783853074357 - 128.21687802318192 - 147.0570878696327 - 152.3131707895507 - 0.6824436583311392\n",
      "36 - random_20 - deep - 160.13944841189232 - 134.58137719990182 - 159.19370320691417 - 142.34051923992254 - 167.19364240905102 - 152.6892396978479 - 0.6816595956915447\n",
      "37 - random_68 - deep - 163.82873350256708 - 157.40117280498978 - 164.26928710022156 - 131.85940239209086 - 146.92890989708872 - 152.86073174757828 - 0.6813020534799593\n",
      "38 - random_92 - deep - 162.96570412327446 - 152.28940947955428 - 173.82554754269788 - 135.49454658572412 - 142.86312173337353 - 153.49110047828447 - 0.6799878034581928\n",
      "39 - random_26 - deep - 167.99702740802547 - 159.13237218279 - 156.01461095243567 - 141.11213291163634 - 147.55869722767036 - 154.36537497169718 - 0.6781650365346013\n",
      "40 - random_75 - deep - 162.6662190305164 - 145.34066615021723 - 169.11095623435128 - 155.9708966899748 - 140.58697367802102 - 154.73669095606428 - 0.6773908832227927\n",
      "41 - random_74 - deep - 152.58459520711824 - 142.570695736341 - 162.38373313725316 - 171.37141614458284 - 145.5339871208493 - 154.88803119720654 - 0.6770753553332787\n",
      "42 - random_66 - deep - 174.46181013774358 - 159.17214336978796 - 172.98608926133474 - 133.38531480631192 - 134.66196891354198 - 154.93848336799127 - 0.6769701680622069\n",
      "43 - random_10 - deep - 167.51197159554906 - 152.23495056848006 - 164.12163580772614 - 137.01967922178636 - 153.94217683716553 - 154.96835975971626 - 0.6769078790453787\n",
      "44 - random_61 - deep - 157.9784927139328 - 157.23725970748234 - 163.25935143629232 - 144.96288218961902 - 152.0262252972478 - 155.09442689375754 - 0.6766450428265324\n",
      "45 - random_30 - deep - 162.3986103467478 - 166.0185969580986 - 162.55688954572443 - 141.44814061488853 - 145.75691172770377 - 155.63871854647797 - 0.6755102541201925\n",
      "46 - random_93 - deep - 164.22512272524133 - 151.96363838804504 - 178.9018144018291 - 158.29820570195852 - 130.84832797559943 - 156.85036780906873 - 0.6729840976150159\n",
      "47 - random_97 - deep - 163.99881366576417 - 169.91042948026606 - 165.13574818987007 - 134.17528977686044 - 153.00864564270532 - 157.24906246536779 - 0.6721528627596127\n",
      "48 - random_36 - deep - 158.91092156934823 - 177.53170906346074 - 173.2915249666055 - 131.8871287406564 - 145.15234813713082 - 157.35924775704075 - 0.6719231384491804\n",
      "49 - random_40 - deep - 170.8331481027403 - 184.61277134831823 - 163.18401065155928 - 128.10755826988998 - 141.60073865361574 - 157.6731207277888 - 0.6712687475529577\n",
      "50 - random_16 - deep - 161.9416997826021 - 171.28276447371658 - 173.05775219620384 - 135.33293053854842 - 153.98510201810217 - 159.12352194888578 - 0.6682448192653642\n",
      "51 - random_94 - deep - 173.10995053186628 - 166.2137028465889 - 174.15565289232498 - 136.47338731635233 - 146.29576947966686 - 159.25397999333703 - 0.6679728284774207\n",
      "52 - random_11 - deep - 169.76883721537553 - 172.28041235014715 - 175.0678099739244 - 139.29272068934995 - 140.73651205477307 - 159.4339181557527 - 0.6675976770424716\n",
      "53 - random_48 - deep - 172.66103014691404 - 163.9655605194879 - 165.8356859725467 - 139.7788889176276 - 155.1667633880945 - 159.48446923941603 - 0.6674922835488407\n",
      "54 - random_52 - deep - 168.74920409899954 - 178.52231781426917 - 171.27102279891923 - 143.63664177829335 - 144.0370792604151 - 161.2474309177359 - 0.6638167008125113\n",
      "55 - random_78 - deep - 160.651448586778 - 177.00912327300165 - 178.6427069820182 - 138.57892798232575 - 154.87469574927138 - 161.95503507917354 - 0.6623414233451\n",
      "56 - random_96 - deep - 175.09764140311586 - 169.0907212997098 - 170.0605180622506 - 148.46060382160678 - 155.98773036283606 - 163.7422064329424 - 0.6586153660770626\n",
      "57 - random_64 - deep - 168.37352717673627 - 166.62892825487637 - 162.5137974602345 - 162.34112123853447 - 159.95731944511203 - 163.96361394859778 - 0.6581537555654762\n",
      "58 - random_99 - deep - 167.47078728175262 - 139.75048356722698 - 155.3251669642878 - 139.3731561960722 - 223.33655178990543 - 165.04731544630062 - 0.6558943561892591\n",
      "59 - random_18 - deep - 155.8044720096508 - 183.6983385000246 - 177.39660853801834 - 150.20344444540513 - 169.8029383994809 - 167.38293104167977 - 0.6510248525201501\n",
      "60 - random_23 - deep - 160.6615539555358 - 179.96197310220572 - 163.8400526555913 - 177.5228658403669 - 160.6170137549649 - 168.5205602583322 - 0.6486530197341664\n",
      "61 - random_70 - deep - 186.07369824634316 - 174.38826862923312 - 176.73255950616516 - 145.04915627139528 - 162.19049057611326 - 168.89049845750642 - 0.6478817389541502\n",
      "62 - random_84 - deep - 183.42716305657783 - 180.43237369676945 - 165.3816182365944 - 153.19778856366764 - 165.34976524179007 - 169.56020971008084 - 0.6464854640670896\n",
      "63 - random_44 - deep - 183.5971289979675 - 164.10738042821123 - 164.3842850921393 - 187.20666533214848 - 149.0586892410773 - 169.6712008443752 - 0.6462540596627202\n",
      "64 - random_17 - deep - 176.62301194546248 - 189.5886936839927 - 184.8031104121583 - 155.55961872664105 - 153.52496484433618 - 172.02407504493908 - 0.6413485736849482\n",
      "65 - random_53 - deep - 158.82935023636753 - 223.18925464174743 - 177.17275106141722 - 161.73941073011235 - 146.6787267412458 - 173.526534332489 - 0.6382161100090396\n",
      "66 - random_19 - deep - 302.54802770677554 - 152.56788962947158 - 166.9465888160106 - 143.7526861696827 - 140.4963695164345 - 181.27170345035432 - 0.622068277501014\n",
      "67 - random_50 - deep - 135.82493018303077 - 137.8936067797427 - 149.6765692264074 - 118.13394207170172 - 467.9323860159298 - 201.8704119786734 - 0.5791222178172186\n",
      "68 - random_28 - deep - 179.16681307522066 - 175.27617884626198 - 213.82331418390393 - 333.95950656263483 - 143.70442574307555 - 209.17893221462558 - 0.5638847505836821\n",
      "69 - random_73 - deep - 466.81589062741654 - 153.55248887966547 - 164.30990221175736 - 132.1194874831036 - 136.00219110738473 - 210.57835200615034 - 0.5609671130139829\n",
      "70 - random_22 - deep - 155.68081592726864 - 147.7791335684279 - 477.74696859029075 - 129.39620777510223 - 143.44430132587703 - 210.82733881179638 - 0.5604480026920396\n",
      "71 - random_35 - deep - 162.94834402641567 - 167.52664016146966 - 477.67976859034934 - 130.79882263879674 - 145.56603006498008 - 216.922814657448 - 0.5477396006527275\n",
      "72 - random_98 - deep - 466.8106262261952 - 164.68271309727314 - 171.95447234100544 - 139.78810834025992 - 154.46160182517832 - 219.55688479562596 - 0.542247851827311\n",
      "73 - random_81 - deep - 178.4029004211975 - 510.6234283721869 - 182.15362840136441 - 144.65735445789645 - 146.81916461958318 - 232.55212169725093 - 0.5151542008435621\n",
      "74 - random_87 - deep - 246.69371180085272 - 251.34746948315416 - 260.2367524282619 - 391.3321171241934 - 251.5597055716818 - 280.22405919766095 - 0.4157634128084715\n",
      "75 - random_24 - deep - 466.8150279703581 - 217.74737660500128 - 477.6787132807813 - 180.2639873820622 - 178.9003048652933 - 304.3110113118685 - 0.36554474586266106\n",
      "76 - random_58 - deep - 473.1543034471719 - 180.18019386845287 - 400.9485527615241 - 307.9156739600137 - 205.7507681050936 - 313.6035218561474 - 0.34617087531644475\n",
      "77 - random_14 - deep - 222.6899476168609 - 514.8746691579653 - 170.24960046595416 - 472.38365043282937 - 467.9306946899854 - 369.6015833748665 - 0.22942102719594182\n",
      "78 - random_67 - deep - 466.15791988086755 - 514.7543943115674 - 477.1126110532288 - 472.63603351496846 - 467.8753117702159 - 479.7095222803321 - -0.00014201115633238892\n",
      "79 - random_95 - deep - 466.8169493878324 - 513.7792816619782 - 477.75070508054154 - 472.5738107743097 - 467.890512454982 - 479.7645378411723 - -0.0002567125977419593\n",
      "80 - random_88 - deep - 466.8156034198434 - 513.7796779328216 - 477.726918157018 - 472.7367103091236 - 467.91925232006867 - 479.79790223828047 - -0.00032627372520566134\n",
      "81 - random_7 - deep - 401.24106469752195 - 394.5628983944422 - 513.700985373604 - 601.3370488820528 - 929.6669825156625 - 568.0544215827933 - -0.18433148657836274\n",
      "82 - random_54 - deep - 200.32080419548416 - 171.065536325108 - 162.7655834433699 - 150.1046372192676 - 2811.8718369427847 - 699.0380503269124 - -0.4574180604240716\n",
      "83 - random_90 - deep - 466.8123918703808 - 164.20157138616221 - 185.80089730650062 - 2815.7636003620196 - 158.21065338977388 - 757.982895699875 - -0.580311631346691\n",
      "84 - random_2 - deep - 177.2550279220279 - 2916.4478767820656 - 193.89492012943847 - 184.83617039345035 - 2834.654243826437 - 1261.358052076406 - -1.6297939073527803\n",
      "85 - random_86 - deep - 466.0055197365068 - 200.4192710102999 - 2881.7542208355203 - 2831.3653680222087 - 467.92142877658875 - 1369.4259254170117 - -1.855103631601072\n",
      "86 - random_3 - deep - 2788.8217141483815 - 169.90405771384786 - 2913.848259644946 - 160.11329687514655 - 2847.890053115973 - 1776.1807838064224 - -2.703143128885559\n",
      "87 - random_32 - deep - 2757.435524613827 - 2897.613933853854 - 2881.4111322999074 - 157.2447661437622 - 2816.011820817194 - 2302.139102491234 - -3.799708834175912\n",
      "88 - random_71 - deep - 2753.826448455426 - 2894.0545353331677 - 798.4414270466219 - 2827.5173858605945 - 2812.6101938822403 - 2417.1933332985786 - -4.039584351436246\n",
      "89 - random_43 - deep - 2772.460707858428 - 1088.317796108747 - 2896.7711831901197 - 2846.2375426733192 - 2831.2300332974987 - 2486.9190374833065 - -4.184954836643862\n",
      "90 - random_8 - deep - 2765.0410170895507 - 2905.426112677855 - 1220.2142310551562 - 2838.7723167391955 - 2823.716979247754 - 2510.557177874353 - -4.234237780118311\n",
      "91 - random_39 - deep - 2747.465662653602 - 2887.478748781494 - 2871.201692449596 - 2820.8909895989646 - 2805.958247849921 - 2826.6022302468104 - -4.893157229524366\n",
      "92 - random_45 - deep - 2752.1250785731527 - 2892.183539708074 - 2875.934712593614 - 2825.603156887755 - 2810.646550099532 - 2831.301765674452 - -4.90295524810811\n",
      "93 - random_83 - deep - 2758.1895940147906 - 2898.3697151682945 - 2882.116613176388 - 2831.7392636742197 - 2816.7837900296836 - 2837.4429557998874 - -4.915758959432725\n",
      "94 - random_91 - deep - 2761.569729901676 - 2901.8554674319043 - 2885.6442817637644 - 2835.20582842512 - 2820.200764925111 - 2840.8983840904616 - -4.922963150384603\n",
      "95 - random_33 - deep - 2775.6764154005136 - 2916.1961660402294 - 2900.0478317178363 - 2849.4900960384152 - 2834.485924618871 - 2855.182460766832 - -4.952743891668841\n",
      "96 - random_85 - deep - 2775.708040691666 - 2916.2728838997828 - 2900.0898062574984 - 2849.5194796668666 - 2834.498315121947 - 2855.2208769741064 - -4.952823985269281\n",
      "97 - random_6 - deep - 2779.807442100447 - 2920.446774121738 - 2904.291163837545 - 2853.7106619991746 - 2838.683992640025 - 2859.3911693867326 - -4.961518589914291\n",
      "98 - random_47 - deep - 455418.8185838998 - 514.8366210424907 - 477.67038373026077 - 472.548207955057 - 519.9091728366151 - 91502.5975978204 - -189.7729318202545\n",
      "99 - random_62 - deep - 1755495.95009792 - 2892.399930609581 - 2875.905308659948 - 2825.730672737845 - 2810.8454285034327 - 353464.26954531274 - -735.9344342686752\n"
     ]
    }
   ],
   "source": [
    "scores_df_sorted = pd.DataFrame(all_scores).sort_values(by='MSE')\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - random_60 - deep - 125.80911623732636 - 0.7385531124617956\n",
      "1 - random_25 - deep - 126.50414113452753 - 0.7371087648535346\n",
      "2 - random_89 - deep - 127.04149021236918 - 0.735992087079102\n",
      "3 - random_59 - deep - 128.68949149600525 - 0.7325673367974703\n",
      "4 - random_75 - deep - 128.9325215528976 - 0.7320622903123423\n",
      "5 - random_38 - deep - 129.77903000569577 - 0.7303031411594194\n",
      "6 - random_50 - deep - 131.2077916805784 - 0.7273339978723203\n",
      "7 - random_4 - deep - 131.8868952787036 - 0.7259227366906511\n",
      "8 - random_41 - deep - 134.28216908942576 - 0.7209450617705464\n",
      "9 - random_29 - deep - 135.5702412752982 - 0.7182682886241107\n",
      "10 - random_0 - deep - 135.7012607060716 - 0.7179960140592205\n",
      "11 - random_51 - deep - 135.83677560040803 - 0.7177143973656219\n",
      "12 - random_20 - deep - 135.83817254590082 - 0.7177114943402922\n",
      "13 - random_9 - deep - 136.25181961887546 - 0.716851884615632\n",
      "14 - random_63 - deep - 137.08992446864116 - 0.7151101991880946\n",
      "15 - random_74 - deep - 137.24237700707667 - 0.7147933839773744\n",
      "16 - random_44 - deep - 137.55086183736813 - 0.7141523143860395\n",
      "17 - random_99 - deep - 138.8017790742297 - 0.7115527538142252\n",
      "18 - random_3 - deep - 141.11350458031498 - 0.7067487025937353\n",
      "19 - random_49 - deep - 142.86275069814494 - 0.7031135530376236\n",
      "20 - random_1 - deep - 143.30142752994624 - 0.7022019283816391\n",
      "21 - random_61 - deep - 143.64778645022048 - 0.7014821517518918\n",
      "22 - random_66 - deep - 143.99378771517965 - 0.7007631183740782\n",
      "23 - random_93 - deep - 144.07627745815108 - 0.7005916944963918\n",
      "24 - random_37 - deep - 144.10074702364852 - 0.7005408437160187\n",
      "25 - random_76 - deep - 144.28386769485635 - 0.7001602963362813\n",
      "26 - random_69 - deep - 144.966516404014 - 0.6987416679758804\n",
      "27 - random_46 - deep - 145.30155520853165 - 0.6980454159453009\n",
      "28 - random_28 - deep - 145.9398626916917 - 0.6967189341309804\n",
      "29 - random_31 - deep - 145.96940739310227 - 0.6966575365911354\n",
      "30 - random_92 - deep - 146.7081318064886 - 0.695122375989069\n",
      "31 - random_79 - deep - 147.9524797155796 - 0.6925364672920171\n",
      "32 - random_34 - deep - 148.90122525298807 - 0.6905648568456542\n",
      "33 - random_12 - deep - 149.39700327285328 - 0.6895345688658936\n",
      "34 - random_80 - deep - 150.18202273281236 - 0.6879032014371926\n",
      "35 - random_77 - deep - 151.2724231908091 - 0.6856372145640658\n",
      "36 - random_52 - deep - 151.28790592412582 - 0.6856050395313074\n",
      "37 - random_35 - deep - 151.44706260633387 - 0.6852742922815158\n",
      "38 - random_57 - deep - 151.90048730851615 - 0.6843320197287474\n",
      "39 - random_82 - deep - 152.71634815759725 - 0.6826365600829283\n",
      "40 - random_11 - deep - 152.72854586952022 - 0.6826112117304979\n",
      "41 - random_65 - deep - 152.79422430974435 - 0.6824747238169944\n",
      "42 - random_42 - deep - 152.83369082502747 - 0.6823927075220599\n",
      "43 - random_81 - deep - 152.9370836943702 - 0.6821778443651461\n",
      "44 - random_21 - deep - 153.74408154925447 - 0.6805008031163109\n",
      "45 - random_73 - deep - 154.34820378947893 - 0.6792453624604736\n",
      "46 - random_10 - deep - 154.75178328700395 - 0.6784066744014692\n",
      "47 - random_97 - deep - 155.59636477261915 - 0.6766515297244337\n",
      "48 - random_72 - deep - 155.9846171306433 - 0.6758446933550144\n",
      "49 - random_56 - deep - 156.11058047867627 - 0.6755829259547491\n",
      "50 - random_55 - deep - 156.50822706895804 - 0.67475656721002\n",
      "51 - random_40 - deep - 156.74320987412975 - 0.6742682439082233\n",
      "52 - random_16 - deep - 156.9360427403904 - 0.6738675133872027\n",
      "53 - random_98 - deep - 157.52191519182188 - 0.6726499980472795\n",
      "54 - random_13 - deep - 158.89949351045044 - 0.6697872200982942\n",
      "55 - random_84 - deep - 159.7901460589189 - 0.6679363340604669\n",
      "56 - random_94 - deep - 161.84348630564517 - 0.6636692393330004\n",
      "57 - random_68 - deep - 161.92043896010367 - 0.6635093222093635\n",
      "58 - random_78 - deep - 162.27839156960533 - 0.6627654524609754\n",
      "59 - random_53 - deep - 162.4403967314234 - 0.6624287857186182\n",
      "60 - random_36 - deep - 162.90870130990518 - 0.6614555909444575\n",
      "61 - random_5 - deep - 163.68645905829732 - 0.6598393142495933\n",
      "62 - random_30 - deep - 163.79717504115408 - 0.6596092327580102\n",
      "63 - random_70 - deep - 163.85521642966074 - 0.6594886155815503\n",
      "64 - random_64 - deep - 163.97244743761152 - 0.659244995062876\n",
      "65 - random_17 - deep - 164.00995390399464 - 0.6591670519917242\n",
      "66 - random_23 - deep - 165.10572593984315 - 0.656889902316151\n",
      "67 - random_26 - deep - 166.2476873671696 - 0.6545167653782841\n",
      "68 - random_54 - deep - 167.12860988590478 - 0.6526860995444095\n",
      "69 - random_96 - deep - 175.07575611099594 - 0.6361709478010207\n",
      "70 - random_15 - deep - 183.5123435193873 - 0.6186386768071839\n",
      "71 - random_48 - deep - 187.63623589419186 - 0.610068718936235\n",
      "72 - random_24 - deep - 211.47813547738932 - 0.5605223058824567\n",
      "73 - random_27 - deep - 271.89569063663635 - 0.43496716153778636\n",
      "74 - random_14 - deep - 367.3347524902215 - 0.23663299929698267\n",
      "75 - random_87 - deep - 392.49023008570225 - 0.18435680883818506\n",
      "76 - random_7 - deep - 452.71702817803924 - 0.05919808124701509\n",
      "77 - random_22 - deep - 481.2294437027849 - -5.424098596673588e-05\n",
      "78 - random_95 - deep - 481.2365184568059 - -6.894319892425393e-05\n",
      "79 - random_88 - deep - 481.2391708452083 - -7.445518973270282e-05\n",
      "80 - random_86 - deep - 481.2477994561343 - -9.238650932119619e-05\n",
      "81 - random_47 - deep - 481.254791668509 - -0.00010691719053923521\n",
      "82 - random_67 - deep - 481.31184127230074 - -0.0002254733158242317\n",
      "83 - random_18 - deep - 519.4505143533979 - -0.07948234809650567\n",
      "84 - random_43 - deep - 626.8925267978044 - -0.3027601246563649\n",
      "85 - random_32 - deep - 715.5797358019918 - -0.48706310246963436\n",
      "86 - random_8 - deep - 861.3312810708283 - -0.7899528214669229\n",
      "87 - random_19 - deep - 1767.85492368205 - -2.6738209538318936\n",
      "88 - random_62 - deep - 1970.2413285690664 - -3.0944049084790404\n",
      "89 - random_85 - deep - 2692.293588831062 - -4.594918716471403\n",
      "90 - random_90 - deep - 2847.7451902864686 - -4.91796635068797\n",
      "91 - random_39 - deep - 2852.8809296283575 - -4.928639051572471\n",
      "92 - random_45 - deep - 2857.5309382664855 - -4.938302344041444\n",
      "93 - random_71 - deep - 2859.5289032005676 - -4.942454362027493\n",
      "94 - random_83 - deep - 2863.6858453287396 - -4.951093001369309\n",
      "95 - random_91 - deep - 2867.186790744814 - -4.958368398493531\n",
      "96 - random_58 - deep - 2871.6396875649916 - -4.967622068251198\n",
      "97 - random_33 - deep - 2881.5329868786084 - -4.9881815665641\n",
      "98 - random_2 - deep - 2881.6262951155363 - -4.988375472608876\n",
      "99 - random_6 - deep - 2885.7368877966996 - -4.996917792073233\n"
     ]
    }
   ],
   "source": [
    "scores_df_sorted_final = pd.DataFrame(all_scores_final).sort_values(by='MSE')\n",
    "\n",
    "n = 30\n",
    "best_n = []\n",
    "for i,(index,row) in enumerate(scores_df_sorted_final.iterrows()):\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    print(s)\n",
    "    if i < n:\n",
    "        best_n.append(row['model_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% lwr part\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7606fceb2bf241d3a4278cb59ac74bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_41'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:45.1988,knn_ttm_n=100:49.8315,knn_tta_r_n=100:49.3822,knn_ttm_r_n=100:49.9464,knn_tta_n=500:76.4518,knn_ttm_n=500:80.315,knn_tta_r_n=500:78.2082,knn_ttm_r_n=500:77.9281,knn_tta_n=1000:80.9944,knn_ttm_n=1000:84.6034,knn_tta_r_n=1000:82.5705,knn_ttm_r_n=1000:82.3121'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1770.0925,knn_ttm_n=100:3147.2647,knn_tta_r_n=100:570.3344,knn_ttm_r_n=100:738.1917,knn_tta_n=500:106.6066,knn_ttm_n=500:136.3864,knn_tta_r_n=500:88.4249,knn_ttm_r_n=500:88.7726,knn_tta_n=1000:90.0039,knn_ttm_n=1000:105.9309,knn_tta_r_n=1000:82.7845,knn_ttm_r_n=1000:83.9355'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:46.2059,knn_ttm_n=100:53.1081,knn_tta_r_n=100:50.4872,knn_ttm_r_n=100:159.466,knn_tta_n=500:77.0703,knn_ttm_n=500:81.8555,knn_tta_r_n=500:78.6872,knn_ttm_r_n=500:78.1898,knn_tta_n=1000:81.5241,knn_ttm_n=1000:86.0067,knn_tta_r_n=1000:82.4383,knn_ttm_r_n=1000:82.3152'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:301.7752,knn_ttm_n=100:1485.1241,knn_tta_r_n=100:256.404,knn_ttm_r_n=100:340.7758,knn_tta_n=500:95.6942,knn_ttm_n=500:127.6119,knn_tta_r_n=500:80.6765,knn_ttm_r_n=500:77.5631,knn_tta_n=1000:89.5275,knn_ttm_n=1000:122.082,knn_tta_r_n=1000:78.2891,knn_ttm_r_n=1000:75.4097'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:46.2326,knn_ttm_n=100:52.3037,knn_tta_r_n=100:50.401,knn_ttm_r_n=100:1297.5533,knn_tta_n=500:76.756,knn_ttm_n=500:81.245,knn_tta_r_n=500:78.5386,knn_ttm_r_n=500:77.9022,knn_tta_n=1000:82.2148,knn_ttm_n=1000:86.6295,knn_tta_r_n=1000:83.2492,knn_ttm_r_n=1000:82.8446'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:160.2995,knn_ttm_n=100:263.7132,knn_tta_r_n=100:109.2438,knn_ttm_r_n=100:119.2406,knn_tta_n=500:88.0996,knn_ttm_n=500:108.0747,knn_tta_r_n=500:80.6038,knn_ttm_r_n=500:81.9714,knn_tta_n=1000:80.7492,knn_ttm_n=1000:93.4309,knn_tta_r_n=1000:77.2761,knn_ttm_r_n=1000:77.5139'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:39.9642,knn_ttm_n=100:44.2139,knn_tta_r_n=100:43.6102,knn_ttm_r_n=100:2032.5271,knn_tta_n=500:67.5254,knn_ttm_n=500:68.8497,knn_tta_r_n=500:69.03,knn_ttm_r_n=500:67.7656,knn_tta_n=1000:71.884,knn_ttm_n=1000:73.4165,knn_tta_r_n=1000:72.8948,knn_ttm_r_n=1000:72.1012'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:213.9012,knn_ttm_n=100:421.8165,knn_tta_r_n=100:157.6399,knn_ttm_r_n=100:233.6793,knn_tta_n=500:123.9801,knn_ttm_n=500:139.0925,knn_tta_r_n=500:117.1145,knn_ttm_r_n=500:117.7341,knn_tta_n=1000:117.7997,knn_ttm_n=1000:126.7232,knn_tta_r_n=1000:114.2926,knn_ttm_r_n=1000:114.4181'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:39.6571,knn_ttm_n=100:44.4107,knn_tta_r_n=100:43.7707,knn_ttm_r_n=100:42.4488,knn_tta_n=500:67.5798,knn_ttm_n=500:69.5852,knn_tta_r_n=500:68.9432,knn_ttm_r_n=500:67.8955,knn_tta_n=1000:71.5351,knn_ttm_n=1000:73.5877,knn_tta_r_n=1000:72.6292,knn_ttm_r_n=1000:71.9754'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:456.2086,knn_ttm_n=100:4870.8535,knn_tta_r_n=100:124.35,knn_ttm_r_n=100:4243.3445,knn_tta_n=500:87.9046,knn_ttm_n=500:100.3768,knn_tta_r_n=500:84.5148,knn_ttm_r_n=500:84.6705,knn_tta_n=1000:83.2464,knn_ttm_n=1000:91.0666,knn_tta_r_n=1000:81.4329,knn_ttm_r_n=1000:82.097'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:40.0102,knn_ttm_n=100:42.9054,knn_tta_r_n=100:43.8147,knn_ttm_r_n=100:41.3683,knn_tta_n=500:66.7918,knn_ttm_n=500:69.1539,knn_tta_r_n=500:68.1714,knn_ttm_r_n=500:66.8074,knn_tta_n=1000:70.9985,knn_ttm_n=1000:73.0321,knn_tta_r_n=1000:71.9609,knn_ttm_r_n=1000:71.2494'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:672.6338,knn_ttm_n=100:713.0248,knn_tta_r_n=100:515.4789,knn_ttm_r_n=100:334.2987,knn_tta_n=500:151.2737,knn_ttm_n=500:168.7969,knn_tta_r_n=500:140.5611,knn_ttm_r_n=500:141.1015,knn_tta_n=1000:141.3768,knn_ttm_n=1000:154.2919,knn_tta_r_n=1000:135.4383,knn_ttm_r_n=1000:135.2097'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_44'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:19.7142,knn_ttm_n=100:15.9751,knn_tta_r_n=100:29.4283,knn_ttm_r_n=100:21.4403,knn_tta_n=500:74.3062,knn_ttm_n=500:62.4721,knn_tta_r_n=500:83.2269,knn_ttm_r_n=500:68.4843,knn_tta_n=1000:87.6345,knn_ttm_n=1000:80.631,knn_tta_r_n=1000:94.1244,knn_ttm_r_n=1000:85.8992'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:302.0417,knn_ttm_n=100:395.3003,knn_tta_r_n=100:203.9057,knn_ttm_r_n=100:231.6413,knn_tta_n=500:140.3139,knn_ttm_n=500:171.7646,knn_tta_r_n=500:113.0881,knn_ttm_r_n=500:118.0225,knn_tta_n=1000:117.9271,knn_ttm_n=1000:142.4397,knn_tta_r_n=1000:109.7565,knn_ttm_r_n=1000:111.1736'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:19.7616,knn_ttm_n=100:16.9067,knn_tta_r_n=100:29.3992,knn_ttm_r_n=100:24.3956,knn_tta_n=500:76.1297,knn_ttm_n=500:62.5912,knn_tta_r_n=500:85.1172,knn_ttm_r_n=500:70.0415,knn_tta_n=1000:89.4164,knn_ttm_n=1000:81.5308,knn_tta_r_n=1000:95.5327,knn_ttm_r_n=1000:86.9842'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:345.7174,knn_ttm_n=100:525.9819,knn_tta_r_n=100:263.7713,knn_ttm_r_n=100:254.2897,knn_tta_n=500:120.2769,knn_ttm_n=500:145.1212,knn_tta_r_n=500:102.6875,knn_ttm_r_n=500:105.9524,knn_tta_n=1000:106.5279,knn_ttm_n=1000:126.1672,knn_tta_r_n=1000:100.4688,knn_ttm_r_n=1000:101.6397'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:20.2386,knn_ttm_n=100:17.074,knn_tta_r_n=100:30.4568,knn_ttm_r_n=100:26.8547,knn_tta_n=500:75.1686,knn_ttm_n=500:64.0631,knn_tta_r_n=500:84.5711,knn_ttm_r_n=500:69.2198,knn_tta_n=1000:89.1198,knn_ttm_n=1000:83.6502,knn_tta_r_n=1000:95.2042,knn_ttm_r_n=1000:85.7243'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:339.3576,knn_ttm_n=100:658.9545,knn_tta_r_n=100:239.8307,knn_ttm_r_n=100:706.2757,knn_tta_n=500:127.6342,knn_ttm_n=500:158.8995,knn_tta_r_n=500:112.7934,knn_ttm_r_n=500:116.0409,knn_tta_n=1000:118.737,knn_ttm_n=1000:140.9865,knn_tta_r_n=1000:110.7931,knn_ttm_r_n=1000:112.2233'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:19.9441,knn_ttm_n=100:15.6254,knn_tta_r_n=100:30.8235,knn_ttm_r_n=100:27.3119,knn_tta_n=500:73.4313,knn_ttm_n=500:62.2912,knn_tta_r_n=500:82.6716,knn_ttm_r_n=500:67.2163,knn_tta_n=1000:86.494,knn_ttm_n=1000:80.1568,knn_tta_r_n=1000:92.3638,knn_ttm_r_n=1000:83.0103'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:579.516,knn_ttm_n=100:690.1833,knn_tta_r_n=100:213.5081,knn_ttm_r_n=100:402.353,knn_tta_n=500:135.9055,knn_ttm_n=500:166.0548,knn_tta_r_n=500:116.4811,knn_ttm_r_n=500:119.094,knn_tta_n=1000:126.5244,knn_ttm_n=1000:144.3577,knn_tta_r_n=1000:114.3899,knn_ttm_r_n=1000:114.9445'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:19.7869,knn_ttm_n=100:17.5734,knn_tta_r_n=100:29.9318,knn_ttm_r_n=100:20.2738,knn_tta_n=500:73.5019,knn_ttm_n=500:61.7052,knn_tta_r_n=500:83.5735,knn_ttm_r_n=500:68.0453,knn_tta_n=1000:86.9039,knn_ttm_n=1000:78.9275,knn_tta_r_n=1000:93.8338,knn_ttm_r_n=1000:84.5122'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:716.4133,knn_ttm_n=100:657.7353,knn_tta_r_n=100:388.7102,knn_ttm_r_n=100:988.8584,knn_tta_n=500:122.7185,knn_ttm_n=500:152.646,knn_tta_r_n=500:106.0927,knn_ttm_r_n=500:108.1098,knn_tta_n=1000:111.3852,knn_ttm_n=1000:131.6775,knn_tta_r_n=1000:104.8401,knn_ttm_r_n=1000:104.4642'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:19.6148,knn_ttm_n=100:17.0681,knn_tta_r_n=100:29.5761,knn_ttm_r_n=100:27.402,knn_tta_n=500:72.9791,knn_ttm_n=500:59.9929,knn_tta_r_n=500:82.5761,knn_ttm_r_n=500:66.6955,knn_tta_n=1000:86.4608,knn_ttm_n=1000:78.1572,knn_tta_r_n=1000:92.8093,knn_ttm_r_n=1000:82.9195'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:457.5535,knn_ttm_n=100:544.7202,knn_tta_r_n=100:782.8857,knn_ttm_r_n=100:940.1382,knn_tta_n=500:158.6445,knn_ttm_n=500:195.3847,knn_tta_r_n=500:134.0833,knn_ttm_r_n=500:138.6413,knn_tta_n=1000:143.4909,knn_ttm_n=1000:166.3523,knn_tta_r_n=1000:131.2572,knn_ttm_r_n=1000:133.1254'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_46'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:56.0561,knn_ttm_n=100:56.242,knn_tta_r_n=100:62.0288,knn_ttm_r_n=100:58.7513,knn_tta_n=500:91.1588,knn_ttm_n=500:96.5718,knn_tta_r_n=500:93.3194,knn_ttm_r_n=500:91.3925,knn_tta_n=1000:97.4751,knn_ttm_n=1000:104.5133,knn_tta_r_n=1000:98.7586,knn_ttm_r_n=1000:98.006'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1399.8803,knn_ttm_n=100:1692.908,knn_tta_r_n=100:547.7816,knn_ttm_r_n=100:2094.4374,knn_tta_n=500:108.8315,knn_ttm_n=500:135.8376,knn_tta_r_n=500:103.0339,knn_ttm_r_n=500:104.2757,knn_tta_n=1000:102.4784,knn_ttm_n=1000:124.014,knn_tta_r_n=1000:100.3332,knn_ttm_r_n=1000:102.3193'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:56.1355,knn_ttm_n=100:57.5017,knn_tta_r_n=100:62.5172,knn_ttm_r_n=100:93.2438,knn_tta_n=500:92.5267,knn_ttm_n=500:98.7543,knn_tta_r_n=500:94.6624,knn_ttm_r_n=500:93.0894,knn_tta_n=1000:98.8301,knn_ttm_n=1000:106.2509,knn_tta_r_n=1000:100.2574,knn_ttm_r_n=1000:99.4228'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1923.2131,knn_ttm_n=100:3082.4262,knn_tta_r_n=100:1053.2986,knn_ttm_r_n=100:1286.3817,knn_tta_n=500:354.0725,knn_ttm_n=500:467.2828,knn_tta_r_n=500:107.8716,knn_ttm_r_n=500:108.5149,knn_tta_n=1000:242.9962,knn_ttm_n=1000:380.2408,knn_tta_r_n=1000:121.1487,knn_ttm_r_n=1000:109.0841'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:55.5828,knn_ttm_n=100:54.3681,knn_tta_r_n=100:62.2691,knn_ttm_r_n=100:14414.5269,knn_tta_n=500:93.7133,knn_ttm_n=500:100.6461,knn_tta_r_n=500:95.8361,knn_ttm_r_n=500:186.0449,knn_tta_n=1000:100.4702,knn_ttm_n=1000:108.0102,knn_tta_r_n=1000:101.9493,knn_ttm_r_n=1000:100.7359'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:18166.0131,knn_ttm_n=100:37720.5368,knn_tta_r_n=100:12028.6778,knn_ttm_r_n=100:60777.7294,knn_tta_n=500:172.0578,knn_ttm_n=500:171.5382,knn_tta_r_n=500:146.5219,knn_ttm_r_n=500:135.8519,knn_tta_n=1000:106.3498,knn_ttm_n=1000:126.2932,knn_tta_r_n=1000:100.7601,knn_ttm_r_n=1000:100.4254'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:52.3311,knn_ttm_n=100:50.7903,knn_tta_r_n=100:57.8703,knn_ttm_r_n=100:101.994,knn_tta_n=500:85.9978,knn_ttm_n=500:90.1289,knn_tta_r_n=500:87.4977,knn_ttm_r_n=500:86.1019,knn_tta_n=1000:91.2744,knn_ttm_n=1000:96.9947,knn_tta_r_n=1000:92.462,knn_ttm_r_n=1000:92.1592'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:4010.7913,knn_ttm_n=100:5025.0459,knn_tta_r_n=100:1233.9624,knn_ttm_r_n=100:1698.5122,knn_tta_n=500:173.407,knn_ttm_n=500:207.5551,knn_tta_r_n=500:136.621,knn_ttm_r_n=500:137.6356,knn_tta_n=1000:143.5627,knn_ttm_n=1000:168.7263,knn_tta_r_n=1000:128.4899,knn_ttm_r_n=1000:129.9214'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:51.7918,knn_ttm_n=100:51.493,knn_tta_r_n=100:57.2351,knn_ttm_r_n=100:2644.9964,knn_tta_n=500:83.4831,knn_ttm_n=500:87.1732,knn_tta_r_n=500:85.4796,knn_ttm_r_n=500:83.9154,knn_tta_n=1000:89.0143,knn_ttm_n=1000:93.327,knn_tta_r_n=1000:90.3309,knn_ttm_r_n=1000:89.6814'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:87115.6306,knn_ttm_n=100:316062.9435,knn_tta_r_n=100:39515.3344,knn_ttm_r_n=100:75812.0033,knn_tta_n=500:165.2511,knn_ttm_n=500:308.3066,knn_tta_r_n=500:119.0171,knn_ttm_r_n=500:116.4258,knn_tta_n=1000:102.1453,knn_ttm_n=1000:114.5398,knn_tta_r_n=1000:100.3463,knn_ttm_r_n=1000:100.9073'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:53.1075,knn_ttm_n=100:50.4167,knn_tta_r_n=100:58.7868,knn_ttm_r_n=100:98.2686,knn_tta_n=500:84.3867,knn_ttm_n=500:88.1008,knn_tta_r_n=500:86.1029,knn_ttm_r_n=500:84.1777,knn_tta_n=1000:89.8463,knn_ttm_n=1000:95.1529,knn_tta_r_n=1000:90.8057,knn_ttm_r_n=1000:90.1396'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:4285.9039,knn_ttm_n=100:4920.1712,knn_tta_r_n=100:895.9396,knn_ttm_r_n=100:1136.331,knn_tta_n=500:175.8863,knn_ttm_n=500:188.1722,knn_tta_r_n=500:151.1362,knn_ttm_r_n=500:145.4741,knn_tta_n=1000:154.3519,knn_ttm_n=1000:178.8489,knn_tta_r_n=1000:144.5691,knn_ttm_r_n=1000:145.3427'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_49'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:120.7012,knn_ttm_n=100:118.7622,knn_tta_r_n=100:123.0442,knn_ttm_r_n=100:120.9853,knn_tta_n=500:128.6183,knn_ttm_n=500:130.2521,knn_tta_r_n=500:130.0228,knn_ttm_r_n=500:129.4231,knn_tta_n=1000:130.1407,knn_ttm_n=1000:131.8011,knn_tta_r_n=1000:131.3326,knn_ttm_r_n=1000:130.8327'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:145.346,knn_ttm_n=100:162.8653,knn_tta_r_n=100:139.2093,knn_ttm_r_n=100:140.4895,knn_tta_n=500:140.5175,knn_ttm_n=500:146.7017,knn_tta_r_n=500:139.014,knn_ttm_r_n=500:138.7812,knn_tta_n=1000:140.3226,knn_ttm_n=1000:144.7428,knn_tta_r_n=1000:139.7339,knn_ttm_r_n=1000:139.3143'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:122.4502,knn_ttm_n=100:118.8764,knn_tta_r_n=100:125.0778,knn_ttm_r_n=100:122.6387,knn_tta_n=500:130.0623,knn_ttm_n=500:130.4024,knn_tta_r_n=500:131.5217,knn_ttm_r_n=500:130.6076,knn_tta_n=1000:131.4494,knn_ttm_n=1000:132.0113,knn_tta_r_n=1000:132.718,knn_ttm_r_n=1000:132.1736'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:132.3237,knn_ttm_n=100:146.4772,knn_tta_r_n=100:127.612,knn_ttm_r_n=100:128.2429,knn_tta_n=500:127.521,knn_ttm_n=500:132.9671,knn_tta_r_n=500:127.5916,knn_ttm_r_n=500:127.7074,knn_tta_n=1000:128.0012,knn_ttm_n=1000:130.8763,knn_tta_r_n=1000:128.3961,knn_ttm_r_n=1000:128.2126'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:125.5538,knn_ttm_n=100:123.3916,knn_tta_r_n=100:128.092,knn_ttm_r_n=100:125.4605,knn_tta_n=500:133.2392,knn_ttm_n=500:133.9415,knn_tta_r_n=500:134.7221,knn_ttm_r_n=500:133.8028,knn_tta_n=1000:134.6868,knn_ttm_n=1000:135.7228,knn_tta_r_n=1000:135.9224,knn_ttm_r_n=1000:135.366'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:145.8916,knn_ttm_n=100:164.642,knn_tta_r_n=100:140.1988,knn_ttm_r_n=100:141.9957,knn_tta_n=500:138.1416,knn_ttm_n=500:143.8646,knn_tta_r_n=500:138.1085,knn_ttm_r_n=500:138.7611,knn_tta_n=1000:137.6329,knn_ttm_n=1000:140.7633,knn_tta_r_n=1000:138.2724,knn_ttm_r_n=1000:138.4823'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:121.1941,knn_ttm_n=100:120.0982,knn_tta_r_n=100:123.8367,knn_ttm_r_n=100:120.998,knn_tta_n=500:129.429,knn_ttm_n=500:131.2655,knn_tta_r_n=500:130.3186,knn_ttm_r_n=500:129.2395,knn_tta_n=1000:130.7293,knn_ttm_n=1000:133.6428,knn_tta_r_n=1000:131.2438,knn_ttm_r_n=1000:130.6356'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:138.6215,knn_ttm_n=100:149.2603,knn_tta_r_n=100:133.1919,knn_ttm_r_n=100:133.6559,knn_tta_n=500:133.9296,knn_ttm_n=500:138.064,knn_tta_r_n=500:133.372,knn_ttm_r_n=500:133.1296,knn_tta_n=1000:134.5652,knn_ttm_n=1000:138.4049,knn_tta_r_n=1000:133.7398,knn_ttm_r_n=1000:133.379'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:124.2095,knn_ttm_n=100:123.3665,knn_tta_r_n=100:126.6413,knn_ttm_r_n=100:123.8839,knn_tta_n=500:131.6203,knn_ttm_n=500:134.4315,knn_tta_r_n=500:132.6554,knn_ttm_r_n=500:131.8017,knn_tta_n=1000:133.2325,knn_ttm_n=1000:136.4519,knn_tta_r_n=1000:133.7922,knn_ttm_r_n=1000:133.2242'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:137.2346,knn_ttm_n=100:157.4627,knn_tta_r_n=100:131.8241,knn_ttm_r_n=100:132.6005,knn_tta_n=500:132.4684,knn_ttm_n=500:139.4016,knn_tta_r_n=500:131.3751,knn_ttm_r_n=500:131.2643,knn_tta_n=1000:132.4301,knn_ttm_n=1000:138.7732,knn_tta_r_n=1000:131.5857,knn_ttm_r_n=1000:131.5074'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:122.7573,knn_ttm_n=100:120.6529,knn_tta_r_n=100:124.8231,knn_ttm_r_n=100:122.0201,knn_tta_n=500:129.6815,knn_ttm_n=500:132.1607,knn_tta_r_n=500:130.7423,knn_ttm_r_n=500:129.8731,knn_tta_n=1000:131.2395,knn_ttm_n=1000:134.0442,knn_tta_r_n=1000:131.8202,knn_ttm_r_n=1000:131.3059'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:147.2799,knn_ttm_n=100:163.8569,knn_tta_r_n=100:142.0876,knn_ttm_r_n=100:142.5966,knn_tta_n=500:141.0574,knn_ttm_n=500:146.3266,knn_tta_r_n=500:140.3642,knn_ttm_r_n=500:140.8291,knn_tta_n=1000:139.7941,knn_ttm_n=1000:143.3307,knn_tta_r_n=1000:140.3673,knn_ttm_r_n=1000:140.5402'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_50'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:75.7404,knn_ttm_n=100:79.1792,knn_tta_r_n=100:77.8376,knn_ttm_r_n=100:79.0053,knn_tta_n=500:88.4366,knn_ttm_n=500:91.0446,knn_tta_r_n=500:88.9239,knn_ttm_r_n=500:88.5711,knn_tta_n=1000:89.8002,knn_ttm_n=1000:93.1573,knn_tta_r_n=1000:90.0705,knn_ttm_r_n=1000:89.9692'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:2545982.7745,knn_ttm_n=100:2585507.518,knn_tta_r_n=100:28518.9427,knn_ttm_r_n=100:1888104.001,knn_tta_n=500:440.9412,knn_ttm_n=500:774.0295,knn_tta_r_n=500:196.0632,knn_ttm_r_n=500:204.1737,knn_tta_n=1000:83.5672,knn_ttm_n=1000:86.7884,knn_tta_r_n=1000:83.5415,knn_ttm_r_n=1000:83.6758'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:76.4173,knn_ttm_n=100:79.9646,knn_tta_r_n=100:78.4311,knn_ttm_r_n=100:78.9922,knn_tta_n=500:88.5743,knn_ttm_n=500:92.7111,knn_tta_r_n=500:89.1124,knn_ttm_r_n=500:88.81,knn_tta_n=1000:90.1025,knn_ttm_n=1000:94.4211,knn_tta_r_n=1000:90.3928,knn_ttm_r_n=1000:90.2395'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:7120453.2183,knn_ttm_n=100:19821066.0586,knn_tta_r_n=100:1022179.745,knn_ttm_r_n=100:1680825.745,knn_tta_n=500:161637.3265,knn_ttm_n=500:276259.3372,knn_tta_r_n=500:59004.5196,knn_ttm_r_n=500:50367.9912,knn_tta_n=1000:84.7872,knn_ttm_n=1000:143.8479,knn_tta_r_n=1000:76.1048,knn_ttm_r_n=1000:76.1897'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:75.7355,knn_ttm_n=100:80.8234,knn_tta_r_n=100:77.6664,knn_ttm_r_n=100:2577.246,knn_tta_n=500:87.6493,knn_ttm_n=500:91.7077,knn_tta_r_n=500:88.1631,knn_ttm_r_n=500:156.9128,knn_tta_n=1000:89.5267,knn_ttm_n=1000:93.3887,knn_tta_r_n=1000:89.6488,knn_ttm_r_n=1000:109.7123'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:4846790.8746,knn_ttm_n=100:7765527.5645,knn_tta_r_n=100:2235132.1723,knn_ttm_r_n=100:1835593.3524,knn_tta_n=500:103.3211,knn_ttm_n=500:204.5935,knn_tta_r_n=500:83.3901,knn_ttm_r_n=500:87.2102,knn_tta_n=1000:85.0603,knn_ttm_n=1000:95.5454,knn_tta_r_n=1000:82.8578,knn_ttm_r_n=1000:82.6772'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:62.9317,knn_ttm_n=100:64.7393,knn_tta_r_n=100:64.2256,knn_ttm_r_n=100:64.0278,knn_tta_n=500:72.4261,knn_ttm_n=500:72.499,knn_tta_r_n=500:72.763,knn_ttm_r_n=500:76.9437,knn_tta_n=1000:73.909,knn_ttm_n=1000:73.9112,knn_tta_r_n=1000:74.1009,knn_ttm_r_n=1000:73.9716'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:134212.8545,knn_ttm_n=100:3982622.4266,knn_tta_r_n=100:454353.5394,knn_ttm_r_n=100:486994.8057,knn_tta_n=500:136.089,knn_ttm_n=500:129.4521,knn_tta_r_n=500:119.1954,knn_ttm_r_n=500:141.2033,knn_tta_n=1000:119.3026,knn_ttm_n=1000:122.5754,knn_tta_r_n=1000:118.3481,knn_ttm_r_n=1000:118.4936'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:65.4195,knn_ttm_n=100:67.5023,knn_tta_r_n=100:66.5558,knn_ttm_r_n=100:111.8753,knn_tta_n=500:75.0008,knn_ttm_n=500:75.9205,knn_tta_r_n=500:75.4807,knn_ttm_r_n=500:88.3013,knn_tta_n=1000:76.4605,knn_ttm_n=1000:77.1376,knn_tta_r_n=1000:76.8159,knn_ttm_r_n=1000:80.0851'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:6171033.2617,knn_ttm_n=100:8395717.696,knn_tta_r_n=100:217902.4132,knn_ttm_r_n=100:8029282.471,knn_tta_n=500:80.1448,knn_ttm_n=500:85.1903,knn_tta_r_n=500:78.8339,knn_ttm_r_n=500:78.9143,knn_tta_n=1000:79.0974,knn_ttm_n=1000:82.2894,knn_tta_r_n=1000:78.5515,knn_ttm_r_n=1000:78.5572'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:63.6695,knn_ttm_n=100:65.7741,knn_tta_r_n=100:65.0709,knn_ttm_r_n=100:65.0506,knn_tta_n=500:73.1834,knn_ttm_n=500:73.7417,knn_tta_r_n=500:73.6415,knn_ttm_r_n=500:76.1768,knn_tta_n=1000:74.7755,knn_ttm_n=1000:75.2526,knn_tta_r_n=1000:75.0899,knn_ttm_r_n=1000:76.7732'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:530831.356,knn_ttm_n=100:3044293.6244,knn_tta_r_n=100:345589.0151,knn_ttm_r_n=100:463026.4248,knn_tta_n=500:1130.5988,knn_ttm_n=500:856.7989,knn_tta_r_n=500:706.111,knn_ttm_r_n=500:470.9457,knn_tta_n=1000:143.0736,knn_ttm_n=1000:145.8915,knn_tta_r_n=1000:134.4084,knn_ttm_r_n=1000:131.702'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_51'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:29.4222,knn_ttm_n=100:30.9317,knn_tta_r_n=100:37.5551,knn_ttm_r_n=100:51.9144,knn_tta_n=500:87.5217,knn_ttm_n=500:90.5191,knn_tta_r_n=500:91.686,knn_ttm_r_n=500:88.2182,knn_tta_n=1000:97.9895,knn_ttm_n=1000:101.9561,knn_tta_r_n=1000:101.3694,knn_ttm_r_n=1000:100.0527'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:460.6546,knn_ttm_n=100:577.5423,knn_tta_r_n=100:319.0736,knn_ttm_r_n=100:390.5624,knn_tta_n=500:271.9159,knn_ttm_n=500:424.8677,knn_tta_r_n=500:146.9255,knn_ttm_r_n=500:154.5191,knn_tta_n=1000:130.2617,knn_ttm_n=1000:189.6144,knn_tta_r_n=1000:126.4501,knn_ttm_r_n=1000:115.7302'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:28.9589,knn_ttm_n=100:29.7831,knn_tta_r_n=100:37.2349,knn_ttm_r_n=100:49.0565,knn_tta_n=500:87.453,knn_ttm_n=500:89.9722,knn_tta_r_n=500:92.2189,knn_ttm_r_n=500:89.3346,knn_tta_n=1000:99.5014,knn_ttm_n=1000:101.9239,knn_tta_r_n=1000:102.7124,knn_ttm_r_n=1000:101.1327'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1790.1107,knn_ttm_n=100:1624.0781,knn_tta_r_n=100:719.0622,knn_ttm_r_n=100:1709.7979,knn_tta_n=500:130.2316,knn_ttm_n=500:176.0149,knn_tta_r_n=500:113.3778,knn_ttm_r_n=500:116.5267,knn_tta_n=1000:119.5317,knn_ttm_n=1000:147.7924,knn_tta_r_n=1000:115.1152,knn_ttm_r_n=1000:116.2011'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:28.9858,knn_ttm_n=100:30.2631,knn_tta_r_n=100:37.6585,knn_ttm_r_n=100:49.7696,knn_tta_n=500:86.7605,knn_ttm_n=500:90.887,knn_tta_r_n=500:91.9211,knn_ttm_r_n=500:87.2465,knn_tta_n=1000:98.3845,knn_ttm_n=1000:102.4451,knn_tta_r_n=1000:101.5068,knn_ttm_r_n=1000:99.4785'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:481.4648,knn_ttm_n=100:992.2244,knn_tta_r_n=100:321.2009,knn_ttm_r_n=100:387.6683,knn_tta_n=500:143.1887,knn_ttm_n=500:183.4842,knn_tta_r_n=500:127.6464,knn_ttm_r_n=500:127.4172,knn_tta_n=1000:129.1306,knn_ttm_n=1000:155.0938,knn_tta_r_n=1000:121.689,knn_ttm_r_n=1000:121.2912'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:29.1669,knn_ttm_n=100:32.4811,knn_tta_r_n=100:37.5193,knn_ttm_r_n=100:39.5415,knn_tta_n=500:84.9748,knn_ttm_n=500:88.4761,knn_tta_r_n=500:89.4008,knn_ttm_r_n=500:85.0081,knn_tta_n=1000:94.6952,knn_ttm_n=1000:98.0499,knn_tta_r_n=1000:97.7724,knn_ttm_r_n=1000:95.1478'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:527.4514,knn_ttm_n=100:594.4483,knn_tta_r_n=100:221.2575,knn_ttm_r_n=100:273.1595,knn_tta_n=500:138.7846,knn_ttm_n=500:185.3323,knn_tta_r_n=500:123.2445,knn_ttm_r_n=500:125.4814,knn_tta_n=1000:124.8884,knn_ttm_n=1000:147.0199,knn_tta_r_n=1000:119.6087,knn_ttm_r_n=1000:119.5283'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:29.2778,knn_ttm_n=100:30.6476,knn_tta_r_n=100:38.0597,knn_ttm_r_n=100:32.8717,knn_tta_n=500:86.8732,knn_ttm_n=500:92.5853,knn_tta_r_n=500:91.813,knn_ttm_r_n=500:87.3009,knn_tta_n=1000:96.8041,knn_ttm_n=1000:101.5659,knn_tta_r_n=1000:100.556,knn_ttm_r_n=1000:97.8793'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:3614.9226,knn_ttm_n=100:8548.8304,knn_tta_r_n=100:744.276,knn_ttm_r_n=100:1022.1836,knn_tta_n=500:132.314,knn_ttm_n=500:178.5574,knn_tta_r_n=500:117.65,knn_ttm_r_n=500:117.9532,knn_tta_n=1000:115.2079,knn_ttm_n=1000:142.9547,knn_tta_r_n=1000:110.1792,knn_ttm_r_n=1000:110.9766'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:28.1685,knn_ttm_n=100:29.6078,knn_tta_r_n=100:37.3094,knn_ttm_r_n=100:43.977,knn_tta_n=500:85.1527,knn_ttm_n=500:87.155,knn_tta_r_n=500:90.4086,knn_ttm_r_n=500:85.1219,knn_tta_n=1000:96.3187,knn_ttm_n=1000:98.7107,knn_tta_r_n=1000:99.5001,knn_ttm_r_n=1000:96.5822'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:703.1508,knn_ttm_n=100:1126.0059,knn_tta_r_n=100:316.6372,knn_ttm_r_n=100:353.2211,knn_tta_n=500:175.5629,knn_ttm_n=500:227.1006,knn_tta_r_n=500:140.8148,knn_ttm_r_n=500:144.4401,knn_tta_n=1000:147.7079,knn_ttm_n=1000:179.6601,knn_tta_r_n=1000:136.9009,knn_ttm_r_n=1000:138.1453'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_59'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:44.8219,knn_ttm_n=100:27.9334,knn_tta_r_n=100:55.6413,knn_ttm_r_n=100:37.321,knn_tta_n=500:78.7566,knn_ttm_n=500:64.452,knn_tta_r_n=500:84.3899,knn_ttm_r_n=500:73.8146,knn_tta_n=1000:85.2069,knn_ttm_n=1000:76.8665,knn_tta_r_n=1000:88.5918,knn_ttm_r_n=1000:82.6704'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:240.7736,knn_ttm_n=100:331.4459,knn_tta_r_n=100:102.4715,knn_ttm_r_n=100:108.3479,knn_tta_n=500:119.6391,knn_ttm_n=500:187.4471,knn_tta_r_n=500:93.4132,knn_ttm_r_n=500:93.5874,knn_tta_n=1000:106.3515,knn_ttm_n=1000:147.7095,knn_tta_r_n=1000:92.9385,knn_ttm_r_n=1000:95.2008'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:45.4972,knn_ttm_n=100:27.6128,knn_tta_r_n=100:56.095,knn_ttm_r_n=100:38.5414,knn_tta_n=500:79.3741,knn_ttm_n=500:64.3497,knn_tta_r_n=500:84.7273,knn_ttm_r_n=500:74.1058,knn_tta_n=1000:85.6992,knn_ttm_n=1000:76.838,knn_tta_r_n=1000:89.1195,knn_ttm_r_n=1000:82.8402'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:144.8841,knn_ttm_n=100:208.8345,knn_tta_r_n=100:98.2086,knn_ttm_r_n=100:108.1161,knn_tta_n=500:92.2114,knn_ttm_n=500:110.4303,knn_tta_r_n=500:85.0698,knn_ttm_r_n=500:86.0563,knn_tta_n=1000:88.4444,knn_ttm_n=1000:98.9949,knn_tta_r_n=1000:84.4493,knn_ttm_r_n=1000:84.6532'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:44.1723,knn_ttm_n=100:26.8206,knn_tta_r_n=100:54.8949,knn_ttm_r_n=100:37.9067,knn_tta_n=500:77.359,knn_ttm_n=500:62.9667,knn_tta_r_n=500:83.3246,knn_ttm_r_n=500:72.608,knn_tta_n=1000:84.3725,knn_ttm_n=1000:75.8472,knn_tta_r_n=1000:88.2348,knn_ttm_r_n=1000:81.6831'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:141.8002,knn_ttm_n=100:175.221,knn_tta_r_n=100:102.4087,knn_ttm_r_n=100:111.3244,knn_tta_n=500:103.1171,knn_ttm_n=500:121.349,knn_tta_r_n=500:93.2089,knn_ttm_r_n=500:94.3094,knn_tta_n=1000:98.1929,knn_ttm_n=1000:111.4027,knn_tta_r_n=1000:92.4324,knn_ttm_r_n=1000:92.6635'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:40.6713,knn_ttm_n=100:24.5021,knn_tta_r_n=100:50.0828,knn_ttm_r_n=100:35.7544,knn_tta_n=500:70.7226,knn_ttm_n=500:57.4115,knn_tta_r_n=500:75.7569,knn_ttm_r_n=500:65.927,knn_tta_n=1000:77.5566,knn_ttm_n=1000:69.4325,knn_tta_r_n=1000:80.0229,knn_ttm_r_n=1000:74.2164'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:157.4035,knn_ttm_n=100:195.7151,knn_tta_r_n=100:121.0246,knn_ttm_r_n=100:127.3057,knn_tta_n=500:117.7612,knn_ttm_n=500:131.2138,knn_tta_r_n=500:110.7182,knn_ttm_r_n=500:111.8449,knn_tta_n=1000:114.7596,knn_ttm_n=1000:123.1815,knn_tta_r_n=1000:109.5921,knn_ttm_r_n=1000:110.1651'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:41.2251,knn_ttm_n=100:25.7475,knn_tta_r_n=100:51.9768,knn_ttm_r_n=100:35.8796,knn_tta_n=500:72.9166,knn_ttm_n=500:59.7387,knn_tta_r_n=500:78.3235,knn_ttm_r_n=500:68.5401,knn_tta_n=1000:79.2929,knn_ttm_n=1000:71.526,knn_tta_r_n=1000:82.3825,knn_ttm_r_n=1000:76.8214'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:141.8302,knn_ttm_n=100:216.5345,knn_tta_r_n=100:101.1406,knn_ttm_r_n=100:107.729,knn_tta_n=500:94.3285,knn_ttm_n=500:112.7484,knn_tta_r_n=500:86.5487,knn_ttm_r_n=500:88.0957,knn_tta_n=1000:89.4203,knn_ttm_n=1000:100.276,knn_tta_r_n=1000:85.8554,knn_ttm_r_n=1000:86.1839'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:41.3573,knn_ttm_n=100:24.4906,knn_tta_r_n=100:50.9258,knn_ttm_r_n=100:33.9439,knn_tta_n=500:71.8637,knn_ttm_n=500:57.8384,knn_tta_r_n=500:76.9646,knn_ttm_r_n=500:66.903,knn_tta_n=1000:77.8001,knn_ttm_n=1000:69.3038,knn_tta_r_n=1000:80.9751,knn_ttm_r_n=1000:75.1256'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:170.0576,knn_ttm_n=100:200.1273,knn_tta_r_n=100:135.9456,knn_ttm_r_n=100:141.6677,knn_tta_n=500:135.9038,knn_ttm_n=500:142.1082,knn_tta_r_n=500:128.086,knn_ttm_r_n=500:128.2821,knn_tta_n=1000:133.7184,knn_ttm_n=1000:137.4016,knn_tta_r_n=1000:128.0712,knn_ttm_r_n=1000:127.7876'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_60'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:89.8349,knn_ttm_n=100:95.3021,knn_tta_r_n=100:91.3956,knn_ttm_r_n=100:92.1041,knn_tta_n=500:100.4641,knn_ttm_n=500:105.4696,knn_tta_r_n=500:100.6775,knn_ttm_r_n=500:100.8116,knn_tta_n=1000:102.017,knn_ttm_n=1000:106.38,knn_tta_r_n=1000:102.1035,knn_ttm_r_n=1000:102.2189'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:121.5049,knn_ttm_n=100:147.782,knn_tta_r_n=100:108.8611,knn_ttm_r_n=100:109.7172,knn_tta_n=500:108.155,knn_ttm_n=500:114.985,knn_tta_r_n=500:105.5409,knn_ttm_r_n=500:105.9437,knn_tta_n=1000:107.7588,knn_ttm_n=1000:113.7387,knn_tta_r_n=1000:105.4135,knn_ttm_r_n=1000:105.5327'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:89.5766,knn_ttm_n=100:95.3015,knn_tta_r_n=100:91.0417,knn_ttm_r_n=100:91.9796,knn_tta_n=500:100.6646,knn_ttm_n=500:105.9047,knn_tta_r_n=500:100.7725,knn_ttm_r_n=500:100.8712,knn_tta_n=1000:101.8906,knn_ttm_n=1000:107.1708,knn_tta_r_n=1000:102.0897,knn_ttm_r_n=1000:102.2189'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:3250.7078,knn_ttm_n=100:8161.5682,knn_tta_r_n=100:945.4937,knn_ttm_r_n=100:566.2612,knn_tta_n=500:96.9432,knn_ttm_n=500:109.9109,knn_tta_r_n=500:94.9905,knn_ttm_r_n=500:95.4458,knn_tta_n=1000:95.8415,knn_ttm_n=1000:104.9569,knn_tta_r_n=1000:94.4307,knn_ttm_r_n=1000:94.8703'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:89.1347,knn_ttm_n=100:93.7474,knn_tta_r_n=100:91.1097,knn_ttm_r_n=100:92.5792,knn_tta_n=500:101.1539,knn_ttm_n=500:105.2871,knn_tta_r_n=500:101.8727,knn_ttm_r_n=500:101.9286,knn_tta_n=1000:102.7489,knn_ttm_n=1000:107.3201,knn_tta_r_n=1000:103.4923,knn_ttm_r_n=1000:103.4443'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:140.4986,knn_ttm_n=100:176.5945,knn_tta_r_n=100:119.3924,knn_ttm_r_n=100:117.7805,knn_tta_n=500:111.4765,knn_ttm_n=500:127.8845,knn_tta_r_n=500:106.4252,knn_ttm_r_n=500:106.5451,knn_tta_n=1000:107.0634,knn_ttm_n=1000:116.7142,knn_tta_r_n=1000:105.5576,knn_ttm_r_n=1000:105.4731'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:84.5109,knn_ttm_n=100:86.8936,knn_tta_r_n=100:85.5888,knn_ttm_r_n=100:85.5059,knn_tta_n=500:93.4589,knn_ttm_n=500:96.4762,knn_tta_r_n=500:93.9872,knn_ttm_r_n=500:93.726,knn_tta_n=1000:94.7792,knn_ttm_n=1000:97.8929,knn_tta_r_n=1000:94.9268,knn_ttm_r_n=1000:94.8213'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:520.0129,knn_ttm_n=100:2427.446,knn_tta_r_n=100:179.6328,knn_ttm_r_n=100:125.3289,knn_tta_n=500:114.8128,knn_ttm_n=500:123.5342,knn_tta_r_n=500:112.4054,knn_ttm_r_n=500:112.475,knn_tta_n=1000:114.5274,knn_ttm_n=1000:122.0879,knn_tta_r_n=1000:112.9095,knn_ttm_r_n=1000:112.5096'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:85.7824,knn_ttm_n=100:89.004,knn_tta_r_n=100:87.3227,knn_ttm_r_n=100:87.5399,knn_tta_n=500:96.591,knn_ttm_n=500:100.4594,knn_tta_r_n=500:97.0699,knn_ttm_r_n=500:97.0357,knn_tta_n=1000:98.1487,knn_ttm_n=1000:101.4165,knn_tta_r_n=1000:98.4538,knn_ttm_r_n=1000:98.3219'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:114.8326,knn_ttm_n=100:149.1253,knn_tta_r_n=100:100.4032,knn_ttm_r_n=100:99.9208,knn_tta_n=500:97.7178,knn_ttm_n=500:107.1408,knn_tta_r_n=500:96.127,knn_ttm_r_n=500:96.1246,knn_tta_n=1000:96.9143,knn_ttm_n=1000:103.1371,knn_tta_r_n=1000:96.1269,knn_ttm_r_n=1000:96.1399'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:84.6793,knn_ttm_n=100:87.0329,knn_tta_r_n=100:86.532,knn_ttm_r_n=100:85.8239,knn_tta_n=500:94.9614,knn_ttm_n=500:97.9613,knn_tta_r_n=500:95.5104,knn_ttm_r_n=500:95.2525,knn_tta_n=1000:96.2475,knn_ttm_n=1000:99.6366,knn_tta_r_n=1000:96.5416,knn_ttm_r_n=1000:96.3677'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:137.7656,knn_ttm_n=100:161.4427,knn_tta_r_n=100:129.6929,knn_ttm_r_n=100:128.9356,knn_tta_n=500:126.7531,knn_ttm_n=500:134.1563,knn_tta_r_n=500:125.3244,knn_ttm_r_n=500:125.8812,knn_tta_n=1000:125.5099,knn_ttm_n=1000:130.4097,knn_tta_r_n=1000:124.7792,knn_ttm_r_n=1000:124.9279'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_61'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:82.3236,knn_ttm_n=100:75.3724,knn_tta_r_n=100:90.4462,knn_ttm_r_n=100:81.8794,knn_tta_n=500:107.7864,knn_ttm_n=500:109.9985,knn_tta_r_n=500:111.551,knn_ttm_r_n=500:107.4992,knn_tta_n=1000:112.4509,knn_ttm_n=1000:117.0939,knn_tta_r_n=1000:115.4619,knn_ttm_r_n=1000:112.7533'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:165.6381,knn_ttm_n=100:266.0053,knn_tta_r_n=100:149.3796,knn_ttm_r_n=100:164.078,knn_tta_n=500:129.9102,knn_ttm_n=500:151.5498,knn_tta_r_n=500:128.7837,knn_ttm_r_n=500:128.8806,knn_tta_n=1000:129.4471,knn_ttm_n=1000:142.6631,knn_tta_r_n=1000:130.7412,knn_ttm_r_n=1000:129.6152'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:84.511,knn_ttm_n=100:76.4513,knn_tta_r_n=100:91.2442,knn_ttm_r_n=100:81.5703,knn_tta_n=500:109.6048,knn_ttm_n=500:112.6155,knn_tta_r_n=500:113.3851,knn_ttm_r_n=500:109.3305,knn_tta_n=1000:114.5476,knn_ttm_n=1000:119.9134,knn_tta_r_n=1000:117.2529,knn_ttm_r_n=1000:114.9564'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:146.8148,knn_ttm_n=100:216.4563,knn_tta_r_n=100:122.4206,knn_ttm_r_n=100:126.9087,knn_tta_n=500:123.7423,knn_ttm_n=500:136.7502,knn_tta_r_n=500:116.5333,knn_ttm_r_n=500:117.2246,knn_tta_n=1000:124.8478,knn_ttm_n=1000:133.5263,knn_tta_r_n=1000:117.3348,knn_ttm_r_n=1000:116.5107'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:80.7719,knn_ttm_n=100:71.4754,knn_tta_r_n=100:87.5921,knn_ttm_r_n=100:77.5839,knn_tta_n=500:107.0683,knn_ttm_n=500:108.3281,knn_tta_r_n=500:111.6537,knn_ttm_r_n=500:106.768,knn_tta_n=1000:112.8325,knn_ttm_n=1000:116.1402,knn_tta_r_n=1000:116.8471,knn_ttm_r_n=1000:113.5233'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:161.2927,knn_ttm_n=100:198.2755,knn_tta_r_n=100:135.7248,knn_ttm_r_n=100:137.4878,knn_tta_n=500:130.6447,knn_ttm_n=500:149.1636,knn_tta_r_n=500:127.148,knn_ttm_r_n=500:127.8522,knn_tta_n=1000:129.0069,knn_ttm_n=1000:143.4691,knn_tta_r_n=1000:127.2538,knn_ttm_r_n=1000:127.4724'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:80.5684,knn_ttm_n=100:71.039,knn_tta_r_n=100:88.2856,knn_ttm_r_n=100:80.3888,knn_tta_n=500:105.2576,knn_ttm_n=500:105.6847,knn_tta_r_n=500:109.3914,knn_ttm_r_n=500:105.528,knn_tta_n=1000:110.7752,knn_ttm_n=1000:113.224,knn_tta_r_n=1000:114.4264,knn_ttm_r_n=1000:110.8911'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:138.868,knn_ttm_n=100:172.2425,knn_tta_r_n=100:122.4271,knn_ttm_r_n=100:124.0165,knn_tta_n=500:119.9566,knn_ttm_n=500:134.2687,knn_tta_r_n=500:119.6972,knn_ttm_r_n=500:121.2993,knn_tta_n=1000:118.6289,knn_ttm_n=1000:128.0966,knn_tta_r_n=1000:120.3628,knn_ttm_r_n=1000:120.6866'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:83.5829,knn_ttm_n=100:76.5831,knn_tta_r_n=100:91.9451,knn_ttm_r_n=100:83.3642,knn_tta_n=500:108.77,knn_ttm_n=500:109.8688,knn_tta_r_n=500:113.0392,knn_ttm_r_n=500:109.4186,knn_tta_n=1000:114.4288,knn_ttm_n=1000:117.6704,knn_tta_r_n=1000:117.9014,knn_ttm_r_n=1000:114.6893'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:155.717,knn_ttm_n=100:212.4591,knn_tta_r_n=100:134.3665,knn_ttm_r_n=100:134.4398,knn_tta_n=500:122.2154,knn_ttm_n=500:144.5696,knn_tta_r_n=500:115.755,knn_ttm_r_n=500:115.8626,knn_tta_n=1000:119.5744,knn_ttm_n=1000:135.2652,knn_tta_r_n=1000:116.1958,knn_ttm_r_n=1000:115.6894'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:84.103,knn_ttm_n=100:76.3833,knn_tta_r_n=100:90.9145,knn_ttm_r_n=100:82.059,knn_tta_n=500:108.1376,knn_ttm_n=500:110.2268,knn_tta_r_n=500:111.684,knn_ttm_r_n=500:107.793,knn_tta_n=1000:112.8333,knn_ttm_n=1000:117.0252,knn_tta_r_n=1000:115.4745,knn_ttm_r_n=1000:112.3251'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:161.2273,knn_ttm_n=100:201.8868,knn_tta_r_n=100:137.7389,knn_ttm_r_n=100:138.2102,knn_tta_n=500:134.8295,knn_ttm_n=500:154.1554,knn_tta_r_n=500:131.8778,knn_ttm_r_n=500:131.7017,knn_tta_n=1000:136.4541,knn_ttm_n=1000:146.5923,knn_tta_r_n=1000:134.8876,knn_ttm_r_n=1000:133.1216'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_63'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:75.9649,knn_ttm_n=100:76.1873,knn_tta_r_n=100:78.3905,knn_ttm_r_n=100:79.0853,knn_tta_n=500:91.7581,knn_ttm_n=500:93.8262,knn_tta_r_n=500:92.7593,knn_ttm_r_n=500:92.5593,knn_tta_n=1000:93.9438,knn_ttm_n=1000:96.3421,knn_tta_r_n=1000:94.8428,knn_ttm_r_n=1000:94.5728'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:150.3684,knn_ttm_n=100:196.6327,knn_tta_r_n=100:101.823,knn_ttm_r_n=100:104.1691,knn_tta_n=500:98.8998,knn_ttm_n=500:112.7632,knn_tta_r_n=500:92.8744,knn_ttm_r_n=500:92.858,knn_tta_n=1000:93.7863,knn_ttm_n=1000:102.928,knn_tta_r_n=1000:92.6164,knn_ttm_r_n=1000:92.6589'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:77.1673,knn_ttm_n=100:76.162,knn_tta_r_n=100:80.1411,knn_ttm_r_n=100:78.1693,knn_tta_n=500:93.1384,knn_ttm_n=500:96.1191,knn_tta_r_n=500:94.0631,knn_ttm_r_n=500:93.6927,knn_tta_n=1000:95.2585,knn_ttm_n=1000:98.5909,knn_tta_r_n=1000:95.9939,knn_ttm_r_n=1000:95.8549'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:936.6561,knn_ttm_n=100:535.3896,knn_tta_r_n=100:158.0475,knn_ttm_r_n=100:135.5298,knn_tta_n=500:92.4805,knn_ttm_n=500:102.6492,knn_tta_r_n=500:88.2621,knn_ttm_r_n=500:88.5129,knn_tta_n=1000:88.2824,knn_ttm_n=1000:96.661,knn_tta_r_n=1000:87.0046,knn_ttm_r_n=1000:87.7288'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:79.9271,knn_ttm_n=100:79.3578,knn_tta_r_n=100:82.3623,knn_ttm_r_n=100:82.2152,knn_tta_n=500:95.5737,knn_ttm_n=500:98.8088,knn_tta_r_n=500:96.7863,knn_ttm_r_n=500:96.4114,knn_tta_n=1000:97.8342,knn_ttm_n=1000:100.793,knn_tta_r_n=1000:98.8353,knn_ttm_r_n=1000:98.6171'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:121.6301,knn_ttm_n=100:155.38,knn_tta_r_n=100:99.5679,knn_ttm_r_n=100:98.9009,knn_tta_n=500:91.9486,knn_ttm_n=500:103.2251,knn_tta_r_n=500:90.495,knn_ttm_r_n=500:91.2179,knn_tta_n=1000:89.7363,knn_ttm_n=1000:95.5637,knn_tta_r_n=1000:90.1605,knn_ttm_r_n=1000:90.7422'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:70.6556,knn_ttm_n=100:70.7525,knn_tta_r_n=100:73.3055,knn_ttm_r_n=100:73.3248,knn_tta_n=500:85.7682,knn_ttm_n=500:89.1022,knn_tta_r_n=500:86.3067,knn_ttm_r_n=500:85.9461,knn_tta_n=1000:87.3562,knn_ttm_n=1000:90.3246,knn_tta_r_n=1000:87.8982,knn_ttm_r_n=1000:87.6519'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:132.4492,knn_ttm_n=100:157.4793,knn_tta_r_n=100:123.6178,knn_ttm_r_n=100:124.6393,knn_tta_n=500:122.7101,knn_ttm_n=500:131.1397,knn_tta_r_n=500:118.6518,knn_ttm_r_n=500:118.199,knn_tta_n=1000:121.6523,knn_ttm_n=1000:129.7362,knn_tta_r_n=1000:118.0653,knn_ttm_r_n=1000:117.5671'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:69.4237,knn_ttm_n=100:69.4466,knn_tta_r_n=100:71.9961,knn_ttm_r_n=100:71.3466,knn_tta_n=500:84.7647,knn_ttm_n=500:88.1558,knn_tta_r_n=500:85.6118,knn_ttm_r_n=500:85.5173,knn_tta_n=1000:86.4174,knn_ttm_n=1000:89.673,knn_tta_r_n=1000:87.4509,knn_ttm_r_n=1000:87.3901'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:111.5797,knn_ttm_n=100:141.4581,knn_tta_r_n=100:95.71,knn_ttm_r_n=100:96.0625,knn_tta_n=500:93.8128,knn_ttm_n=500:102.9428,knn_tta_r_n=500:91.9112,knn_ttm_r_n=500:92.1014,knn_tta_n=1000:92.5383,knn_ttm_n=1000:98.7324,knn_tta_r_n=1000:91.6472,knn_ttm_r_n=1000:91.5511'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:69.3199,knn_ttm_n=100:68.3279,knn_tta_r_n=100:71.8671,knn_ttm_r_n=100:70.5189,knn_tta_n=500:84.7766,knn_ttm_n=500:87.2573,knn_tta_r_n=500:85.48,knn_ttm_r_n=500:85.1244,knn_tta_n=1000:86.5416,knn_ttm_n=1000:89.4047,knn_tta_r_n=1000:87.0473,knn_ttm_r_n=1000:86.9895'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:166.8854,knn_ttm_n=100:188.1458,knn_tta_r_n=100:138.669,knn_ttm_r_n=100:143.1137,knn_tta_n=500:136.2677,knn_ttm_n=500:149.9096,knn_tta_r_n=500:133.488,knn_ttm_r_n=500:133.1659,knn_tta_n=1000:135.3985,knn_ttm_n=1000:140.9552,knn_tta_r_n=1000:133.965,knn_ttm_r_n=1000:133.8951'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_66'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:86.6481,knn_ttm_n=100:85.9808,knn_tta_r_n=100:91.2034,knn_ttm_r_n=100:87.3906,knn_tta_n=500:105.793,knn_ttm_n=500:111.6892,knn_tta_r_n=500:107.4209,knn_ttm_r_n=500:106.6237,knn_tta_n=1000:108.7311,knn_ttm_n=1000:115.06,knn_tta_r_n=1000:110.0185,knn_ttm_r_n=1000:109.9325'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1680.8586,knn_ttm_n=100:1736.3692,knn_tta_r_n=100:422.4062,knn_ttm_r_n=100:665.0146,knn_tta_n=500:123.532,knn_ttm_n=500:135.982,knn_tta_r_n=500:122.4345,knn_ttm_r_n=500:123.0419,knn_tta_n=1000:122.9989,knn_ttm_n=1000:131.172,knn_tta_r_n=1000:122.721,knn_ttm_r_n=1000:122.5052'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:87.6524,knn_ttm_n=100:89.3821,knn_tta_r_n=100:92.1025,knn_ttm_r_n=100:95.6087,knn_tta_n=500:107.3427,knn_ttm_n=500:113.9731,knn_tta_r_n=500:108.9415,knn_ttm_r_n=500:108.3931,knn_tta_n=1000:110.7382,knn_ttm_n=1000:118.1549,knn_tta_r_n=1000:112.0861,knn_ttm_r_n=1000:111.915'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:135.5523,knn_ttm_n=100:182.0027,knn_tta_r_n=100:117.7094,knn_ttm_r_n=100:120.7974,knn_tta_n=500:116.0815,knn_ttm_n=500:132.1844,knn_tta_r_n=500:112.4367,knn_ttm_r_n=500:112.442,knn_tta_n=1000:112.0508,knn_ttm_n=1000:123.9213,knn_tta_r_n=1000:111.0638,knn_ttm_r_n=1000:111.6694'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:87.4698,knn_ttm_n=100:89.9268,knn_tta_r_n=100:92.398,knn_ttm_r_n=100:92.0307,knn_tta_n=500:108.8626,knn_ttm_n=500:115.7014,knn_tta_r_n=500:110.8036,knn_ttm_r_n=500:110.5794,knn_tta_n=1000:113.4259,knn_ttm_n=1000:119.3153,knn_tta_r_n=1000:114.8602,knn_ttm_r_n=1000:114.8814'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:729.1131,knn_ttm_n=100:626.8494,knn_tta_r_n=100:153.5636,knn_ttm_r_n=100:162.3929,knn_tta_n=500:122.5682,knn_ttm_n=500:140.3843,knn_tta_r_n=500:118.2945,knn_ttm_r_n=500:118.6689,knn_tta_n=1000:120.6223,knn_ttm_n=1000:132.818,knn_tta_r_n=1000:119.0033,knn_ttm_r_n=1000:118.6864'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:88.0502,knn_ttm_n=100:87.1519,knn_tta_r_n=100:92.0246,knn_ttm_r_n=100:87.0258,knn_tta_n=500:106.7296,knn_ttm_n=500:110.5694,knn_tta_r_n=500:109.2436,knn_ttm_r_n=500:107.1685,knn_tta_n=1000:110.5594,knn_ttm_n=1000:115.2261,knn_tta_r_n=1000:112.2228,knn_ttm_r_n=1000:110.977'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:160.9401,knn_ttm_n=100:445.1197,knn_tta_r_n=100:125.4617,knn_ttm_r_n=100:417.5206,knn_tta_n=500:204.6757,knn_ttm_n=500:148.4351,knn_tta_r_n=500:185.0059,knn_ttm_r_n=500:149.816,knn_tta_n=1000:130.5185,knn_ttm_n=1000:161.6017,knn_tta_r_n=1000:120.9743,knn_ttm_r_n=1000:120.4229'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:90.4276,knn_ttm_n=100:91.8551,knn_tta_r_n=100:94.6738,knn_ttm_r_n=100:90.025,knn_tta_n=500:108.9132,knn_ttm_n=500:114.9092,knn_tta_r_n=500:110.7642,knn_ttm_r_n=500:109.1066,knn_tta_n=1000:111.5326,knn_ttm_n=1000:117.6631,knn_tta_r_n=1000:113.1419,knn_ttm_r_n=1000:112.2873'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:555.9807,knn_ttm_n=100:559.9365,knn_tta_r_n=100:224.2419,knn_ttm_r_n=100:143.4219,knn_tta_n=500:116.8119,knn_ttm_n=500:155.7569,knn_tta_r_n=500:110.484,knn_ttm_r_n=500:111.5244,knn_tta_n=1000:112.2692,knn_ttm_n=1000:127.3885,knn_tta_r_n=1000:109.6111,knn_ttm_r_n=1000:109.4007'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:88.5553,knn_ttm_n=100:88.8833,knn_tta_r_n=100:92.7986,knn_ttm_r_n=100:87.9361,knn_tta_n=500:106.9634,knn_ttm_n=500:113.8026,knn_tta_r_n=500:109.1313,knn_ttm_r_n=500:107.3519,knn_tta_n=1000:110.47,knn_ttm_n=1000:116.805,knn_tta_r_n=1000:111.856,knn_ttm_r_n=1000:110.8274'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:173.7356,knn_ttm_n=100:286.7245,knn_tta_r_n=100:146.0425,knn_ttm_r_n=100:161.7703,knn_tta_n=500:142.9363,knn_ttm_n=500:163.2859,knn_tta_r_n=500:135.6576,knn_ttm_r_n=500:136.6341,knn_tta_n=1000:135.3477,knn_ttm_n=1000:148.3512,knn_tta_r_n=1000:135.0821,knn_ttm_r_n=1000:135.679'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_69'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:97.0349,knn_ttm_n=100:86.0278,knn_tta_r_n=100:100.2788,knn_ttm_r_n=100:95.0677,knn_tta_n=500:109.7198,knn_ttm_n=500:110.5861,knn_tta_r_n=500:111.4047,knn_ttm_r_n=500:108.9714,knn_tta_n=1000:112.8894,knn_ttm_n=1000:115.8001,knn_tta_r_n=1000:113.536,knn_ttm_r_n=1000:111.8758'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:130.1614,knn_ttm_n=100:149.9807,knn_tta_r_n=100:120.72,knn_ttm_r_n=100:123.7433,knn_tta_n=500:126.238,knn_ttm_n=500:130.1433,knn_tta_r_n=500:120.9631,knn_ttm_r_n=500:125.3081,knn_tta_n=1000:121.2335,knn_ttm_n=1000:126.6228,knn_tta_r_n=1000:120.2873,knn_ttm_r_n=1000:119.735'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:96.9233,knn_ttm_n=100:87.5501,knn_tta_r_n=100:100.7032,knn_ttm_r_n=100:95.6392,knn_tta_n=500:109.7493,knn_ttm_n=500:111.1189,knn_tta_r_n=500:110.7173,knn_ttm_r_n=500:108.433,knn_tta_n=1000:112.3449,knn_ttm_n=1000:115.9495,knn_tta_r_n=1000:112.8697,knn_ttm_r_n=1000:111.3234'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:137.1141,knn_ttm_n=100:166.7914,knn_tta_r_n=100:118.1463,knn_ttm_r_n=100:242.8344,knn_tta_n=500:117.1941,knn_ttm_n=500:129.7936,knn_tta_r_n=500:115.999,knn_ttm_r_n=500:115.9925,knn_tta_n=1000:114.0938,knn_ttm_n=1000:120.7331,knn_tta_r_n=1000:114.4455,knn_ttm_r_n=1000:114.5487'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:97.6401,knn_ttm_n=100:86.7975,knn_tta_r_n=100:99.8968,knn_ttm_r_n=100:96.3969,knn_tta_n=500:108.3663,knn_ttm_n=500:109.5849,knn_tta_r_n=500:109.7682,knn_ttm_r_n=500:107.8266,knn_tta_n=1000:111.5108,knn_ttm_n=1000:115.7261,knn_tta_r_n=1000:112.2218,knn_ttm_r_n=1000:110.6596'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:139.8069,knn_ttm_n=100:164.2927,knn_tta_r_n=100:126.2908,knn_ttm_r_n=100:237.8203,knn_tta_n=500:120.2468,knn_ttm_n=500:133.1332,knn_tta_r_n=500:118.7959,knn_ttm_r_n=500:119.2141,knn_tta_n=1000:120.3817,knn_ttm_n=1000:129.0383,knn_tta_r_n=1000:119.4522,knn_ttm_r_n=1000:119.0365'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:94.0787,knn_ttm_n=100:86.7239,knn_tta_r_n=100:96.9424,knn_ttm_r_n=100:242.5381,knn_tta_n=500:105.2005,knn_ttm_n=500:108.3351,knn_tta_r_n=500:106.4087,knn_ttm_r_n=500:104.7646,knn_tta_n=1000:107.6902,knn_ttm_n=1000:113.4577,knn_tta_r_n=1000:108.2341,knn_ttm_r_n=1000:107.1619'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:130.3405,knn_ttm_n=100:150.065,knn_tta_r_n=100:120.0656,knn_ttm_r_n=100:121.5248,knn_tta_n=500:120.6786,knn_ttm_n=500:132.7789,knn_tta_r_n=500:116.9416,knn_ttm_r_n=500:117.2875,knn_tta_n=1000:120.0645,knn_ttm_n=1000:131.8139,knn_tta_r_n=1000:116.9412,knn_ttm_r_n=1000:116.9022'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:97.1114,knn_ttm_n=100:87.0541,knn_tta_r_n=100:100.6071,knn_ttm_r_n=100:94.6734,knn_tta_n=500:109.5766,knn_ttm_n=500:112.0005,knn_tta_r_n=500:111.0667,knn_ttm_r_n=500:109.1648,knn_tta_n=1000:112.7015,knn_ttm_n=1000:117.4182,knn_tta_r_n=1000:113.5892,knn_ttm_r_n=1000:112.0926'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:336.2509,knn_ttm_n=100:303.4346,knn_tta_r_n=100:178.3421,knn_ttm_r_n=100:156.7369,knn_tta_n=500:387.7116,knn_ttm_n=500:160.4931,knn_tta_r_n=500:140.544,knn_ttm_r_n=500:135.2473,knn_tta_n=1000:359.9399,knn_ttm_n=1000:346.7208,knn_tta_r_n=1000:154.8142,knn_ttm_r_n=1000:159.0012'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:96.7888,knn_ttm_n=100:86.749,knn_tta_r_n=100:99.3617,knn_ttm_r_n=100:93.5681,knn_tta_n=500:107.1482,knn_ttm_n=500:109.7889,knn_tta_r_n=500:108.4258,knn_ttm_r_n=500:106.8733,knn_tta_n=1000:109.8504,knn_ttm_n=1000:114.8576,knn_tta_r_n=1000:110.5521,knn_ttm_r_n=1000:109.3991'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:148.4534,knn_ttm_n=100:166.6481,knn_tta_r_n=100:140.4502,knn_ttm_r_n=100:142.779,knn_tta_n=500:139.1664,knn_ttm_n=500:147.9248,knn_tta_r_n=500:136.2295,knn_ttm_r_n=500:136.7267,knn_tta_n=1000:139.8803,knn_ttm_n=1000:147.3029,knn_tta_r_n=1000:137.1834,knn_ttm_r_n=1000:136.6527'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_74'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:23.6201,knn_ttm_n=100:15.3611,knn_tta_r_n=100:35.3051,knn_ttm_r_n=100:24.4648,knn_tta_n=500:66.6241,knn_ttm_n=500:55.4095,knn_tta_r_n=500:75.5313,knn_ttm_r_n=500:60.7219,knn_tta_n=1000:76.7301,knn_ttm_n=1000:71.856,knn_tta_r_n=1000:82.8979,knn_ttm_r_n=1000:73.332'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:194.4718,knn_ttm_n=100:262.1575,knn_tta_r_n=100:140.5536,knn_ttm_r_n=100:143.554,knn_tta_n=500:96.8714,knn_ttm_n=500:125.0706,knn_tta_r_n=500:87.992,knn_ttm_r_n=500:89.2701,knn_tta_n=1000:91.6043,knn_ttm_n=1000:107.3663,knn_tta_r_n=1000:88.1903,knn_ttm_r_n=1000:87.9016'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:25.0723,knn_ttm_n=100:16.3952,knn_tta_r_n=100:36.4559,knn_ttm_r_n=100:25.0311,knn_tta_n=500:67.9867,knn_ttm_n=500:57.3587,knn_tta_r_n=500:76.5958,knn_ttm_r_n=500:61.6336,knn_tta_n=1000:77.8605,knn_ttm_n=1000:73.9172,knn_tta_r_n=1000:84.1603,knn_ttm_r_n=1000:74.6189'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:179.5902,knn_ttm_n=100:233.1052,knn_tta_r_n=100:117.9985,knn_ttm_r_n=100:136.0591,knn_tta_n=500:91.9573,knn_ttm_n=500:113.1176,knn_tta_r_n=500:82.5727,knn_ttm_r_n=500:84.3215,knn_tta_n=1000:84.4796,knn_ttm_n=1000:102.6077,knn_tta_r_n=1000:80.9126,knn_ttm_r_n=1000:82.1707'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:23.6564,knn_ttm_n=100:16.5753,knn_tta_r_n=100:34.7337,knn_ttm_r_n=100:23.6997,knn_tta_n=500:65.6146,knn_ttm_n=500:53.5442,knn_tta_r_n=500:75.0996,knn_ttm_r_n=500:60.5911,knn_tta_n=1000:76.4832,knn_ttm_n=1000:69.7673,knn_tta_r_n=1000:83.1053,knn_ttm_r_n=1000:73.6851'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:211.0681,knn_ttm_n=100:279.8148,knn_tta_r_n=100:130.9118,knn_ttm_r_n=100:153.1055,knn_tta_n=500:105.2508,knn_ttm_n=500:134.7387,knn_tta_r_n=500:91.9063,knn_ttm_r_n=500:94.4365,knn_tta_n=1000:97.0076,knn_ttm_n=1000:118.9024,knn_tta_r_n=1000:90.5422,knn_ttm_r_n=1000:91.8962'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:22.546,knn_ttm_n=100:14.3826,knn_tta_r_n=100:32.317,knn_ttm_r_n=100:22.0952,knn_tta_n=500:60.6065,knn_ttm_n=500:47.5181,knn_tta_r_n=500:68.3185,knn_ttm_r_n=500:55.1437,knn_tta_n=1000:69.5353,knn_ttm_n=1000:62.158,knn_tta_r_n=1000:74.6214,knn_ttm_r_n=1000:66.4791'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:192.6312,knn_ttm_n=100:246.3514,knn_tta_r_n=100:142.507,knn_ttm_r_n=100:163.5086,knn_tta_n=500:119.7168,knn_ttm_n=500:137.4909,knn_tta_r_n=500:109.4554,knn_ttm_r_n=500:110.9531,knn_tta_n=1000:115.67,knn_ttm_n=1000:127.958,knn_tta_r_n=1000:109.4782,knn_ttm_r_n=1000:108.9588'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:22.2519,knn_ttm_n=100:13.7187,knn_tta_r_n=100:32.2133,knn_ttm_r_n=100:19.6485,knn_tta_n=500:61.6574,knn_ttm_n=500:48.9876,knn_tta_r_n=500:69.0926,knn_ttm_r_n=500:55.6171,knn_tta_n=1000:70.0436,knn_ttm_n=1000:63.0875,knn_tta_r_n=1000:75.6407,knn_ttm_r_n=1000:67.2332'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:195.1898,knn_ttm_n=100:240.9715,knn_tta_r_n=100:122.9882,knn_ttm_r_n=100:140.7212,knn_tta_n=500:102.6369,knn_ttm_n=500:123.9995,knn_tta_r_n=500:90.8702,knn_ttm_r_n=500:92.2735,knn_tta_n=1000:94.3005,knn_ttm_n=1000:110.6908,knn_tta_r_n=1000:88.4593,knn_ttm_r_n=1000:89.1192'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:22.5808,knn_ttm_n=100:14.2784,knn_tta_r_n=100:32.3,knn_ttm_r_n=100:20.4538,knn_tta_n=500:61.2895,knn_ttm_n=500:48.2002,knn_tta_r_n=500:69.0945,knn_ttm_r_n=500:54.9482,knn_tta_n=1000:70.0882,knn_ttm_n=1000:62.7825,knn_tta_r_n=1000:75.5171,knn_ttm_r_n=1000:66.8802'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1190.6945,knn_ttm_n=100:27722.3702,knn_tta_r_n=100:13668.4158,knn_ttm_r_n=100:1525.6135,knn_tta_n=500:145.4791,knn_ttm_n=500:164.4129,knn_tta_r_n=500:133.6233,knn_ttm_r_n=500:133.3423,knn_tta_n=1000:140.6516,knn_ttm_n=1000:156.0459,knn_tta_r_n=1000:133.4865,knn_ttm_r_n=1000:132.6992'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_75'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:42.9764,knn_ttm_n=100:36.9344,knn_tta_r_n=100:51.3917,knn_ttm_r_n=100:348.4152,knn_tta_n=500:83.0349,knn_ttm_n=500:82.1407,knn_tta_r_n=500:86.0978,knn_ttm_r_n=500:110.8749,knn_tta_n=1000:90.3201,knn_ttm_n=1000:92.0633,knn_tta_r_n=1000:91.8303,knn_ttm_r_n=1000:103.0534'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:60871.6832,knn_ttm_n=100:42226.4501,knn_tta_r_n=100:1964.3574,knn_ttm_r_n=100:3997.0565,knn_tta_n=500:11637.7345,knn_ttm_n=500:21097.8601,knn_tta_r_n=500:833.2598,knn_ttm_r_n=500:1469.2201,knn_tta_n=1000:160.1304,knn_ttm_n=1000:979.9175,knn_tta_r_n=1000:102.0423,knn_ttm_r_n=1000:106.7116'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:43.9441,knn_ttm_n=100:38.3585,knn_tta_r_n=100:52.0204,knn_ttm_r_n=100:374.2449,knn_tta_n=500:83.9873,knn_ttm_n=500:84.5251,knn_tta_r_n=500:87.429,knn_ttm_r_n=500:83.2582,knn_tta_n=1000:91.2136,knn_ttm_n=1000:93.3492,knn_tta_r_n=1000:92.9374,knn_ttm_r_n=1000:91.27'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:4889.9227,knn_ttm_n=100:7661.7342,knn_tta_r_n=100:1365.3356,knn_ttm_r_n=100:1731.8893,knn_tta_n=500:330.4472,knn_ttm_n=500:825.3907,knn_tta_r_n=500:122.1006,knn_ttm_r_n=500:148.4378,knn_tta_n=1000:253.4668,knn_ttm_n=1000:525.1655,knn_tta_r_n=1000:129.1883,knn_ttm_r_n=1000:126.8023'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:42.7436,knn_ttm_n=100:35.1672,knn_tta_r_n=100:50.8802,knn_ttm_r_n=100:277.4816,knn_tta_n=500:84.6764,knn_ttm_n=500:84.1466,knn_tta_r_n=500:88.2099,knn_ttm_r_n=500:84.2574,knn_tta_n=1000:92.2045,knn_ttm_n=1000:94.7165,knn_tta_r_n=1000:93.8338,knn_ttm_r_n=1000:92.2773'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1677.6161,knn_ttm_n=100:3497.0269,knn_tta_r_n=100:422.5572,knn_ttm_r_n=100:570.4853,knn_tta_n=500:108.9827,knn_ttm_n=500:127.5394,knn_tta_r_n=500:102.0712,knn_ttm_r_n=500:103.2412,knn_tta_n=1000:99.6122,knn_ttm_n=1000:111.8787,knn_tta_r_n=1000:97.3073,knn_ttm_r_n=1000:98.6071'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:41.2442,knn_ttm_n=100:35.3771,knn_tta_r_n=100:49.0815,knn_ttm_r_n=100:65.5807,knn_tta_n=500:78.7614,knn_ttm_n=500:77.5525,knn_tta_r_n=500:81.8463,knn_ttm_r_n=500:78.1612,knn_tta_n=1000:85.5792,knn_ttm_n=1000:87.4304,knn_tta_r_n=1000:87.2118,knn_ttm_r_n=1000:85.5989'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:2522.3061,knn_ttm_n=100:3059.8976,knn_tta_r_n=100:609.6079,knn_ttm_r_n=100:1626.081,knn_tta_n=500:154.2079,knn_ttm_n=500:151.9371,knn_tta_r_n=500:126.4012,knn_ttm_r_n=500:128.3398,knn_tta_n=1000:154.5573,knn_ttm_n=1000:235.0885,knn_tta_r_n=1000:128.4123,knn_ttm_r_n=1000:127.3059'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:41.029,knn_ttm_n=100:35.2462,knn_tta_r_n=100:49.2132,knn_ttm_r_n=100:40.0959,knn_tta_n=500:77.4918,knn_ttm_n=500:77.5726,knn_tta_r_n=500:81.0529,knn_ttm_r_n=500:77.4175,knn_tta_n=1000:84.9202,knn_ttm_n=1000:87.0485,knn_tta_r_n=1000:86.9008,knn_ttm_r_n=1000:85.127'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:2851.8763,knn_ttm_n=100:4003.0136,knn_tta_r_n=100:574.461,knn_ttm_r_n=100:904.0197,knn_tta_n=500:121.1218,knn_ttm_n=500:159.9069,knn_tta_r_n=500:100.2433,knn_ttm_r_n=500:99.2034,knn_tta_n=1000:102.0475,knn_ttm_n=1000:130.566,knn_tta_r_n=1000:94.5242,knn_ttm_r_n=1000:93.7464'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:40.693,knn_ttm_n=100:32.965,knn_tta_r_n=100:49.1331,knn_ttm_r_n=100:38.8948,knn_tta_n=500:78.3551,knn_ttm_n=500:77.1604,knn_tta_r_n=500:81.6328,knn_ttm_r_n=500:77.2162,knn_tta_n=1000:84.9151,knn_ttm_n=1000:86.2408,knn_tta_r_n=1000:86.8502,knn_ttm_r_n=1000:84.9182'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:621.7551,knn_ttm_n=100:3141.1477,knn_tta_r_n=100:289.4881,knn_ttm_r_n=100:516.9073,knn_tta_n=500:148.1702,knn_ttm_n=500:178.3175,knn_tta_r_n=500:131.0114,knn_ttm_r_n=500:131.5991,knn_tta_n=1000:131.9195,knn_ttm_n=1000:145.1699,knn_tta_r_n=1000:127.0224,knn_ttm_r_n=1000:126.3403'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_76'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:41.0022,knn_ttm_n=100:32.9633,knn_tta_r_n=100:48.7865,knn_ttm_r_n=100:37944448.3818,knn_tta_n=500:69.2004,knn_ttm_n=500:65.9809,knn_tta_r_n=500:73.1057,knn_ttm_r_n=500:66.8379,knn_tta_n=1000:76.2102,knn_ttm_n=1000:76.861,knn_tta_r_n=1000:78.2079,knn_ttm_r_n=1000:74.4199'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:172.4072,knn_ttm_n=100:295.7784,knn_tta_r_n=100:121.262,knn_ttm_r_n=100:199.1787,knn_tta_n=500:84.9076,knn_ttm_n=500:102.8917,knn_tta_r_n=500:73.6308,knn_ttm_r_n=500:73.6601,knn_tta_n=1000:78.3897,knn_ttm_n=1000:92.8325,knn_tta_r_n=1000:72.1234,knn_ttm_r_n=1000:71.7986'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:40.0045,knn_ttm_n=100:32.8628,knn_tta_r_n=100:48.2463,knn_ttm_r_n=100:5547.628,knn_tta_n=500:67.8481,knn_ttm_n=500:65.4987,knn_tta_r_n=500:72.215,knn_ttm_r_n=500:66.0273,knn_tta_n=1000:74.3295,knn_ttm_n=1000:75.9481,knn_tta_r_n=1000:77.0061,knn_ttm_r_n=1000:73.0978'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:331.6314,knn_ttm_n=100:281.6503,knn_tta_r_n=100:226.7428,knn_ttm_r_n=100:173.1897,knn_tta_n=500:81.0625,knn_ttm_n=500:105.9676,knn_tta_r_n=500:71.9862,knn_ttm_r_n=500:72.8158,knn_tta_n=1000:74.3766,knn_ttm_n=1000:92.0958,knn_tta_r_n=1000:70.4756,knn_ttm_r_n=1000:70.6048'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:41.8003,knn_ttm_n=100:34.736,knn_tta_r_n=100:49.9148,knn_ttm_r_n=100:41.1181,knn_tta_n=500:70.4021,knn_ttm_n=500:68.7872,knn_tta_r_n=500:74.7127,knn_ttm_r_n=500:67.8081,knn_tta_n=1000:77.4718,knn_ttm_n=1000:79.2688,knn_tta_r_n=1000:80.0383,knn_ttm_r_n=1000:75.6454'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:443.0548,knn_ttm_n=100:828.436,knn_tta_r_n=100:139.5928,knn_ttm_r_n=100:185.8626,knn_tta_n=500:79.5156,knn_ttm_n=500:113.5844,knn_tta_r_n=500:66.674,knn_ttm_r_n=500:69.3469,knn_tta_n=1000:295.9504,knn_ttm_n=1000:254.1477,knn_tta_r_n=1000:200.3596,knn_ttm_r_n=1000:191.0693'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:35.711,knn_ttm_n=100:28.5074,knn_tta_r_n=100:41.122,knn_ttm_r_n=100:33.2355,knn_tta_n=500:58.3937,knn_ttm_n=500:54.9906,knn_tta_r_n=500:60.9054,knn_ttm_r_n=500:55.3974,knn_tta_n=1000:63.2727,knn_ttm_n=1000:62.5108,knn_tta_r_n=1000:64.9857,knn_ttm_r_n=1000:61.8647'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:287.7726,knn_ttm_n=100:472.3817,knn_tta_r_n=100:298.432,knn_ttm_r_n=100:251.7414,knn_tta_n=500:128.0062,knn_ttm_n=500:144.4218,knn_tta_r_n=500:122.0955,knn_ttm_r_n=500:123.8518,knn_tta_n=1000:123.6771,knn_ttm_n=1000:132.9943,knn_tta_r_n=1000:120.7322,knn_ttm_r_n=1000:121.3535'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:35.1861,knn_ttm_n=100:27.063,knn_tta_r_n=100:40.792,knn_ttm_r_n=100:31.8917,knn_tta_n=500:57.0147,knn_ttm_n=500:54.1351,knn_tta_r_n=500:59.7369,knn_ttm_r_n=500:54.4204,knn_tta_n=1000:61.8917,knn_ttm_n=1000:62.1499,knn_tta_r_n=1000:63.3837,knn_ttm_r_n=1000:60.4192'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:353401.9367,knn_ttm_n=100:20843.6783,knn_tta_r_n=100:42399.4241,knn_ttm_r_n=100:192924.0466,knn_tta_n=500:79.8589,knn_ttm_n=500:93.5637,knn_tta_r_n=500:73.047,knn_ttm_r_n=500:73.6954,knn_tta_n=1000:75.6202,knn_ttm_n=1000:85.3085,knn_tta_r_n=1000:72.2801,knn_ttm_r_n=1000:72.6287'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:35.1431,knn_ttm_n=100:26.7978,knn_tta_r_n=100:40.8964,knn_ttm_r_n=100:32.9049,knn_tta_n=500:56.4612,knn_ttm_n=500:52.6397,knn_tta_r_n=500:59.093,knn_ttm_r_n=500:53.3476,knn_tta_n=1000:61.1254,knn_ttm_n=1000:60.2816,knn_tta_r_n=1000:62.5943,knn_ttm_r_n=1000:59.3832'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:333.4804,knn_ttm_n=100:821.5444,knn_tta_r_n=100:258.936,knn_ttm_r_n=100:253.6236,knn_tta_n=500:165.4555,knn_ttm_n=500:184.4337,knn_tta_r_n=500:147.7896,knn_ttm_r_n=500:148.8218,knn_tta_n=1000:145.4843,knn_ttm_n=1000:155.6133,knn_tta_r_n=1000:140.2845,knn_ttm_r_n=1000:140.0631'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_89'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:83.1675,knn_ttm_n=100:80.2557,knn_tta_r_n=100:84.971,knn_ttm_r_n=100:82.4558,knn_tta_n=500:91.0837,knn_ttm_n=500:94.6604,knn_tta_r_n=500:91.4274,knn_ttm_r_n=500:90.8931,knn_tta_n=1000:91.8421,knn_ttm_n=1000:95.5897,knn_tta_r_n=1000:92.3841,knn_ttm_r_n=1000:92.0475'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:97.702,knn_ttm_n=100:112.8929,knn_tta_r_n=100:91.3205,knn_ttm_r_n=100:92.6884,knn_tta_n=500:92.8264,knn_ttm_n=500:101.0849,knn_tta_r_n=500:90.4885,knn_ttm_r_n=500:90.7752,knn_tta_n=1000:91.2142,knn_ttm_n=1000:98.7029,knn_tta_r_n=1000:89.9088,knn_ttm_r_n=1000:90.1766'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:83.0443,knn_ttm_n=100:82.9475,knn_tta_r_n=100:85.1446,knn_ttm_r_n=100:82.4738,knn_tta_n=500:90.9915,knn_ttm_n=500:95.9163,knn_tta_r_n=500:91.7508,knn_ttm_r_n=500:91.1438,knn_tta_n=1000:92.2431,knn_ttm_n=1000:96.8448,knn_tta_r_n=1000:92.7281,knn_ttm_r_n=1000:92.3825'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:96.6138,knn_ttm_n=100:125.126,knn_tta_r_n=100:85.2693,knn_ttm_r_n=100:86.0972,knn_tta_n=500:85.6815,knn_ttm_n=500:99.1316,knn_tta_r_n=500:82.6714,knn_ttm_r_n=500:82.7648,knn_tta_n=1000:83.5169,knn_ttm_n=1000:92.7707,knn_tta_r_n=1000:81.981,knn_ttm_r_n=1000:82.2223'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:81.2279,knn_ttm_n=100:79.2821,knn_tta_r_n=100:83.8659,knn_ttm_r_n=100:80.8836,knn_tta_n=500:90.6694,knn_ttm_n=500:94.1915,knn_tta_r_n=500:91.3142,knn_ttm_r_n=500:90.6085,knn_tta_n=1000:92.0437,knn_ttm_n=1000:96.438,knn_tta_r_n=1000:92.3677,knn_ttm_r_n=1000:91.9837'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:106.0099,knn_ttm_n=100:133.2775,knn_tta_r_n=100:94.9568,knn_ttm_r_n=100:95.7748,knn_tta_n=500:94.1561,knn_ttm_n=500:105.8311,knn_tta_r_n=500:92.7677,knn_ttm_r_n=500:92.9145,knn_tta_n=1000:93.0381,knn_ttm_n=1000:100.8352,knn_tta_r_n=1000:92.4542,knn_ttm_r_n=1000:92.5526'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:71.7402,knn_ttm_n=100:67.29,knn_tta_r_n=100:74.5838,knn_ttm_r_n=100:72.0273,knn_tta_n=500:80.3369,knn_ttm_n=500:79.7801,knn_tta_r_n=500:80.957,knn_ttm_r_n=500:80.2844,knn_tta_n=1000:81.6076,knn_ttm_n=1000:81.8545,knn_tta_r_n=1000:81.8614,knn_ttm_r_n=1000:81.4842'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:121.0898,knn_ttm_n=100:139.5009,knn_tta_r_n=100:111.711,knn_ttm_r_n=100:111.5945,knn_tta_n=500:111.9251,knn_ttm_n=500:118.0477,knn_tta_r_n=500:109.9539,knn_ttm_r_n=500:109.7296,knn_tta_n=1000:110.8853,knn_ttm_n=1000:115.1495,knn_tta_r_n=1000:109.7909,knn_ttm_r_n=1000:109.5388'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:75.5405,knn_ttm_n=100:72.1777,knn_tta_r_n=100:78.2565,knn_ttm_r_n=100:76.0022,knn_tta_n=500:83.911,knn_ttm_n=500:85.0072,knn_tta_r_n=500:84.4992,knn_ttm_r_n=500:83.8842,knn_tta_n=1000:85.0283,knn_ttm_n=1000:86.6063,knn_tta_r_n=1000:85.3589,knn_ttm_r_n=1000:85.0323'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:92.2975,knn_ttm_n=100:113.0853,knn_tta_r_n=100:84.9785,knn_ttm_r_n=100:85.8027,knn_tta_n=500:84.7822,knn_ttm_n=500:93.6005,knn_tta_r_n=500:82.7301,knn_ttm_r_n=500:82.9505,knn_tta_n=1000:83.5101,knn_ttm_n=1000:89.5668,knn_tta_r_n=1000:82.1974,knn_ttm_r_n=1000:82.3774'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:73.4526,knn_ttm_n=100:68.95,knn_tta_r_n=100:76.0065,knn_ttm_r_n=100:73.3789,knn_tta_n=500:81.8149,knn_ttm_n=500:81.6988,knn_tta_r_n=500:82.4611,knn_ttm_r_n=500:81.8317,knn_tta_n=1000:83.0416,knn_ttm_n=1000:83.7203,knn_tta_r_n=1000:83.3585,knn_ttm_r_n=1000:82.9782'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:134.5837,knn_ttm_n=100:145.6314,knn_tta_r_n=100:128.6131,knn_ttm_r_n=100:128.7385,knn_tta_n=500:129.9221,knn_ttm_n=500:134.2499,knn_tta_r_n=500:127.9415,knn_ttm_r_n=500:127.8918,knn_tta_n=1000:128.3459,knn_ttm_n=1000:131.3107,knn_tta_r_n=1000:127.5185,knn_ttm_r_n=1000:127.5912'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_93'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:20.5172,knn_ttm_n=100:19.5918,knn_tta_r_n=100:28.6766,knn_ttm_r_n=100:62.75,knn_tta_n=500:78.6161,knn_ttm_n=500:74.4669,knn_tta_r_n=500:84.4201,knn_ttm_r_n=500:75.6386,knn_tta_n=1000:91.1646,knn_ttm_n=1000:91.2913,knn_tta_r_n=1000:94.8645,knn_ttm_r_n=1000:91.3078'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:53750.8135,knn_ttm_n=100:100622.2745,knn_tta_r_n=100:11726.2771,knn_ttm_r_n=100:11445.2774,knn_tta_n=500:575.093,knn_ttm_n=500:1268.753,knn_tta_r_n=500:148.719,knn_ttm_r_n=500:150.826,knn_tta_n=1000:116.6264,knn_ttm_n=1000:215.1249,knn_tta_r_n=1000:115.0586,knn_ttm_r_n=1000:124.6985'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:21.2534,knn_ttm_n=100:21.3049,knn_tta_r_n=100:29.5848,knn_ttm_r_n=100:93.4903,knn_tta_n=500:78.3185,knn_ttm_n=500:72.5403,knn_tta_r_n=500:84.8843,knn_ttm_r_n=500:76.894,knn_tta_n=1000:91.4715,knn_ttm_n=1000:91.2084,knn_tta_r_n=1000:95.4328,knn_ttm_r_n=1000:91.3447'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:9092.1708,knn_ttm_n=100:10789.4341,knn_tta_r_n=100:2738.7005,knn_ttm_r_n=100:1887.3814,knn_tta_n=500:143.0861,knn_ttm_n=500:205.092,knn_tta_r_n=500:132.6573,knn_ttm_r_n=500:161.88,knn_tta_n=1000:162.7488,knn_ttm_n=1000:242.6128,knn_tta_r_n=1000:121.3915,knn_ttm_r_n=1000:115.1595'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:21.0266,knn_ttm_n=100:22.3559,knn_tta_r_n=100:30.3363,knn_ttm_r_n=100:195357.2645,knn_tta_n=500:79.7645,knn_ttm_n=500:74.2037,knn_tta_r_n=500:86.2322,knn_ttm_r_n=500:76.5338,knn_tta_n=1000:93.1125,knn_ttm_n=1000:93.6446,knn_tta_r_n=1000:96.4256,knn_ttm_r_n=1000:92.3898'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:5881.9601,knn_ttm_n=100:29204.1958,knn_tta_r_n=100:1063.4328,knn_ttm_r_n=100:10343.2821,knn_tta_n=500:290.3462,knn_ttm_n=500:677.9976,knn_tta_r_n=500:133.2147,knn_ttm_r_n=500:140.0051,knn_tta_n=1000:117.1956,knn_ttm_n=1000:135.5326,knn_tta_r_n=1000:113.1523,knn_ttm_r_n=1000:112.6726'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:20.9806,knn_ttm_n=100:19.8518,knn_tta_r_n=100:29.1763,knn_ttm_r_n=100:62.2816,knn_tta_n=500:76.8384,knn_ttm_n=500:73.0218,knn_tta_r_n=500:83.1627,knn_ttm_r_n=500:72.7549,knn_tta_n=1000:89.9665,knn_ttm_n=1000:90.6451,knn_tta_r_n=1000:93.4498,knn_ttm_r_n=1000:88.5069'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:16306.8889,knn_ttm_n=100:5159.5314,knn_tta_r_n=100:11879.5565,knn_ttm_r_n=100:37707.4193,knn_tta_n=500:138.9252,knn_ttm_n=500:175.385,knn_tta_r_n=500:123.92,knn_ttm_r_n=500:127.266,knn_tta_n=1000:125.046,knn_ttm_n=1000:147.5694,knn_tta_r_n=1000:118.0388,knn_ttm_r_n=1000:119.1763'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:20.1968,knn_ttm_n=100:24.4406,knn_tta_r_n=100:28.9518,knn_ttm_r_n=100:29.2331,knn_tta_n=500:76.8888,knn_ttm_n=500:75.1522,knn_tta_r_n=500:83.0479,knn_ttm_r_n=500:73.8525,knn_tta_n=1000:89.7689,knn_ttm_n=1000:91.548,knn_tta_r_n=1000:93.7722,knn_ttm_r_n=1000:89.1368'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:43655.3395,knn_ttm_n=100:146288.1093,knn_tta_r_n=100:10913.9522,knn_ttm_r_n=100:35372.4923,knn_tta_n=500:313.8547,knn_ttm_n=500:2696.8268,knn_tta_r_n=500:187.0438,knn_ttm_r_n=500:543.1167,knn_tta_n=1000:114.0258,knn_ttm_n=1000:148.1878,knn_tta_r_n=1000:106.0838,knn_ttm_r_n=1000:108.7271'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:20.168,knn_ttm_n=100:19.5815,knn_tta_r_n=100:28.3673,knn_ttm_r_n=100:29.8315,knn_tta_n=500:76.0047,knn_ttm_n=500:71.7361,knn_tta_r_n=500:82.3614,knn_ttm_r_n=500:71.708,knn_tta_n=1000:89.0262,knn_ttm_n=1000:88.0113,knn_tta_r_n=1000:92.8921,knn_ttm_r_n=1000:87.4933'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:31545.5856,knn_ttm_n=100:31835.4086,knn_tta_r_n=100:3477.3636,knn_ttm_r_n=100:4801.1459,knn_tta_n=500:1911.4107,knn_ttm_n=500:2241.4255,knn_tta_r_n=500:538.5608,knn_ttm_r_n=500:759.0252,knn_tta_n=1000:137.4118,knn_ttm_n=1000:153.8758,knn_tta_r_n=1000:133.333,knn_ttm_r_n=1000:131.0629'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_99'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:24.0973,knn_ttm_n=100:18.6791,knn_tta_r_n=100:33.6269,knn_ttm_r_n=100:24.1146,knn_tta_n=500:74.591,knn_ttm_n=500:60.1455,knn_tta_r_n=500:83.3532,knn_ttm_r_n=500:67.762,knn_tta_n=1000:85.836,knn_ttm_n=1000:76.8515,knn_tta_r_n=1000:91.7596,knn_ttm_r_n=1000:81.8997'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1277.4683,knn_ttm_n=100:5482.7018,knn_tta_r_n=100:849.5069,knn_ttm_r_n=100:1515.501,knn_tta_n=500:124.2552,knn_ttm_n=500:206.3748,knn_tta_r_n=500:102.9291,knn_ttm_r_n=500:116.5705,knn_tta_n=1000:109.8167,knn_ttm_n=1000:132.967,knn_tta_r_n=1000:103.5063,knn_ttm_r_n=1000:102.413'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:24.0697,knn_ttm_n=100:18.134,knn_tta_r_n=100:33.7175,knn_ttm_r_n=100:36.4849,knn_tta_n=500:74.5773,knn_ttm_n=500:60.3147,knn_tta_r_n=500:82.5166,knn_ttm_r_n=500:67.8208,knn_tta_n=1000:85.3133,knn_ttm_n=1000:76.0336,knn_tta_r_n=1000:91.0292,knn_ttm_r_n=1000:82.0194'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:2885.7392,knn_ttm_n=100:8337.946,knn_tta_r_n=100:1725.769,knn_ttm_r_n=100:4467.6563,knn_tta_n=500:113.3637,knn_ttm_n=500:138.3775,knn_tta_r_n=500:99.6915,knn_ttm_r_n=500:100.9663,knn_tta_n=1000:101.3085,knn_ttm_n=1000:117.3835,knn_tta_r_n=1000:95.837,knn_ttm_r_n=1000:97.1771'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:24.305,knn_ttm_n=100:18.6294,knn_tta_r_n=100:33.8476,knn_ttm_r_n=100:33.8965,knn_tta_n=500:74.3136,knn_ttm_n=500:60.5509,knn_tta_r_n=500:82.8901,knn_ttm_r_n=500:68.3388,knn_tta_n=1000:85.7892,knn_ttm_n=1000:76.6962,knn_tta_r_n=1000:91.6583,knn_ttm_r_n=1000:82.8412'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=100:1941.2623,knn_ttm_n=100:2094.0681,knn_tta_r_n=100:800.2443,knn_ttm_r_n=100:2118.943,knn_tta_n=500:111.9037,knn_ttm_n=500:135.2325,knn_tta_r_n=500:101.4228,knn_ttm_r_n=500:102.5794,knn_tta_n=1000:104.8326,knn_ttm_n=1000:120.3326,knn_tta_r_n=1000:101.0534,knn_ttm_r_n=1000:101.1755'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:23.2836,knn_ttm_n=100:17.1749,knn_tta_r_n=100:32.8078,knn_ttm_r_n=100:679.8007,knn_tta_n=500:72.6194,knn_ttm_n=500:61.4991,knn_tta_r_n=500:80.1823,knn_ttm_r_n=500:65.2551,knn_tta_n=1000:82.5986,knn_ttm_n=1000:76.6588,knn_tta_r_n=1000:87.821,knn_ttm_r_n=1000:78.4201'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:12390.9531,knn_ttm_n=100:21619.3572,knn_tta_r_n=100:2791.9739,knn_ttm_r_n=100:3186.5607,knn_tta_n=500:123.1123,knn_ttm_n=500:144.9983,knn_tta_r_n=500:112.2077,knn_ttm_r_n=500:113.0529,knn_tta_n=1000:121.0102,knn_ttm_n=1000:136.8543,knn_tta_r_n=1000:111.7586,knn_ttm_r_n=1000:111.9541'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:23.8901,knn_ttm_n=100:18.1605,knn_tta_r_n=100:33.1812,knn_ttm_r_n=100:22.9533,knn_tta_n=500:73.2457,knn_ttm_n=500:61.0133,knn_tta_r_n=500:81.9387,knn_ttm_r_n=500:66.2514,knn_tta_n=1000:84.6963,knn_ttm_n=1000:77.5876,knn_tta_r_n=1000:90.5648,knn_ttm_r_n=1000:80.7522'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=100:30482.2317,knn_ttm_n=100:39106.9061,knn_tta_r_n=100:12672.628,knn_ttm_r_n=100:11762.4215,knn_tta_n=500:110.256,knn_ttm_n=500:137.5557,knn_tta_r_n=500:98.94,knn_ttm_r_n=500:102.2023,knn_tta_n=1000:100.7332,knn_ttm_n=1000:118.2735,knn_tta_r_n=1000:96.349,knn_ttm_r_n=1000:97.6443'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=100:23.4264,knn_ttm_n=100:17.7712,knn_tta_r_n=100:32.8302,knn_ttm_r_n=100:258.0248,knn_tta_n=500:71.7902,knn_ttm_n=500:59.4725,knn_tta_r_n=500:79.9562,knn_ttm_r_n=500:64.8951,knn_tta_n=1000:83.043,knn_ttm_n=1000:75.0373,knn_tta_r_n=1000:88.5228,knn_ttm_r_n=1000:78.8049'\n"
     ]
    }
   ],
   "source": [
    "def build_predictors(n,deep):\n",
    "    predictors = {}\n",
    "    for i in [100,500,1000]:\n",
    "        if i* 2 < n:\n",
    "            #predictors[f'knn_uu_n={i}'] = LWRBoost(deep,n_neighbors=i, weights='uniform',errors='uniform',convolution='additive',reverse=True)\n",
    "            #predictors[f'knn_ut_n={i}'] = LWRBoost(deep,n_neighbors=i, weights='uniform',errors='triangle',convolution='additive',reverse=True)\n",
    "            #predictors[f'knn_tu_n={i}'] = LWRBoost(deep,n_neighbors=i, weights='triangle',errors='uniform',convolution='additive',reverse=True)\n",
    "            predictors[f'knn_tta_n={i}'] = LWRBoost(deep,n_neighbors=i, weights='triangle',errors='triangle',convolution='additive',reverse=True)\n",
    "            predictors[f'knn_ttm_n={i}'] = LWRBoost(deep,n_neighbors=i, weights='triangle',errors='triangle',convolution='multiplicative',reverse=True)\n",
    "            predictors[f'knn_tta_r_n={i}'] = LWRBoost(deep,n_neighbors=i, weights='triangle',errors='triangle',convolution='additive',reverse=False)\n",
    "            predictors[f'knn_ttm_r_n={i}'] = LWRBoost(deep,n_neighbors=i, weights='triangle',errors='triangle',convolution='multiplicative',reverse=False)\n",
    "\n",
    "    return predictors\n",
    "\n",
    "models = {k:v for k,v in models.items() if k in best_n}\n",
    "for deep_name,deep_model in tqdm(models.items()):\n",
    "    if int(deep_name.replace(\"random_\",\"\")) >40 :\n",
    "        logging.getLogger().info(f\"Running model {deep_name}\")\n",
    "        temp_dict = {deep_name:deep_model}\n",
    "\n",
    "        lwr_scheme = BoostScheme(boost_models = build_predictors(nrow,deep_model),loss_fun_sk = mean_squared_error)\n",
    "        lwr_scores, lwr_preds, _ , _, _,_= eval_.evaluate(temp_dict,dataset,lwr_scheme,logger_name=\"log\")\n",
    "        lwr_scores_final, lwr_preds_final, _ , _, _,_= eval_.build(temp_dict,dataset,lwr_scheme,logger_name=\"test_log\")\n",
    "\n",
    "        #scores\n",
    "        for k,v in ut.flip_dicts(lwr_scores).items(): \n",
    "            dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "            all_scores.append({**dict1,**v})\n",
    "\n",
    "        for k,v in ut.flip_dicts(lwr_scores_final).items():\n",
    "            dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "            all_scores_final.append({**dict1,**v})\n",
    "\n",
    "        lwr_preds['deep'] = deep_preds[deep_name]\n",
    "        lwr_preds_final['deep'] = deep_preds_final[deep_name]\n",
    "\n",
    "        lwr_preds.to_csv(log_dir/deep_name/ f\"predictions.csv\",index=False)\n",
    "        lwr_preds_final.to_csv(log_dir/deep_name/ f\"predictions_test.csv\",index=False)\n",
    "\n",
    "        #preds\n",
    "        # todo save predictions - appending solns\n",
    "        plot_preds_and_res(lwr_preds,name_lambda=lambda x:f\"{deep_name} with {x} predictor\",save_lambda= lambda x:f\"deep_lwr{x}\",save_loc=log_dir/deep_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save scores\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(all_scores)\n",
    "scores_df.to_csv(log_dir/f\"scores.csv\",index=False)\n",
    "\n",
    "scores_df_sorted = pd.DataFrame(scores_df).sort_values(by='MSE')\n",
    "\n",
    "best_5 = []\n",
    "summary_logger.info(f\"Rank - \" +\" - \".join(list(scores_df_sorted.columns)))\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    if i < 5:\n",
    "        best_5.append((row[\"model_num\"],row[\"predictor\"],row[\"MSE\"],row[\"R2\"]))\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    summary_logger.info(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save scores\n"
    }
   },
   "outputs": [],
   "source": [
    "scores_df_final = pd.DataFrame(all_scores_final)\n",
    "scores_df_final.to_csv(log_dir/f\"test_scores.csv\",index=False)\n",
    "\n",
    "summary_logger.info(\"-----------------------\\n Best 5 on Test Sest \\n ---------------------\")\n",
    "summary_logger.info(f\"Rank -  Deep Model - Predictor - Val Set - Test Set\")\n",
    "for i, (j,k,v,x) in enumerate(best_5):\n",
    "    row = scores_df_final.loc[(scores_df_final['model_num']==j) & (scores_df_final['predictor'] == k)].iloc[0]\n",
    "    #print(row)\n",
    "    s = f\"{i} - {j} - {k} - {v} - {x} - {row['MSE']} - {row['R2']}\"\n",
    "    summary_logger.info(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#graph our deep models by rank - plot - then overlay our knn moels\n",
    "\n",
    "deep_set = scores_df[scores_df[\"predictor\"]==\"deep\"].sort_values(\"R2\")\n",
    "deep_set[\"order\"] = [i for i in range(0,100)]\n",
    "deep_ordering = {row[\"model_num\"]:row[\"order\"] for index, row in deep_set.iterrows()}\n",
    "\n",
    "def order_models(x):\n",
    "    x = [deep_ordering[i] for i in x]\n",
    "    return x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df[scores_df[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    if knn_model == \"deep\":\n",
    "        s=10\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph our deep models by rank on final set - plot - then overlay our knn moels\n",
    "\n",
    "deep_set = scores_df_final[scores_df_final[\"predictor\"]==\"deep\"].sort_values(\"R2\")\n",
    "deep_set[\"order\"] = [i for i in range(0,100)]\n",
    "deep_ordering = {row[\"model_num\"]:row[\"order\"] for index, row in deep_set.iterrows()}\n",
    "\n",
    "def order_models(x):\n",
    "    x = [deep_ordering[i] for i in x]\n",
    "    return x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df_final[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df_final[scores_df_final[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    if knn_model == \"deep\":\n",
    "        s=10\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot_final.png\", bbox_inches='tight')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df_final[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df_final[scores_df_final[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    if knn_model == \"deep\":\n",
    "        pass\n",
    "    else:\n",
    "        y1 = subset[\"R2\"].to_numpy() - scores_df_final[scores_df_final[\"predictor\"]=='deep'][\"R2\"].to_numpy()\n",
    "        ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=y1, s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"improvement_plot_final.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df_base = scores_df[scores_df[\"predictor\"]=='deep']\n",
    "scores_df_uu = scores_df[scores_df[\"predictor\"].str.contains('_uu')]   #val_eq_list(scores_df[\"predictor\"],'dist')] #np.logical_or(scores_df[\"predictor\"]==\"deep\",'dist' in scores_df[\"predictor\"])]\n",
    "scores_df_ut = scores_df[scores_df[\"predictor\"].str.contains('_ut')] \n",
    "scores_df_tu = scores_df[scores_df[\"predictor\"].str.contains('_tu')]   #val_eq_list(scores_df[\"predictor\"],'dist')] #np.logical_or(scores_df[\"predictor\"]==\"deep\",'dist' in scores_df[\"predictor\"])]\n",
    "scores_df_tta = scores_df[scores_df[\"predictor\"].str.contains('_tta')] \n",
    "scores_df_ttm = scores_df[scores_df[\"predictor\"].str.contains('_ttm')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "knn_models = scores_df_tta[\"predictor\"].unique()\n",
    "ax.scatter(x=order_models(scores_df_base[\"model_num\"].tolist()), y=scores_df_base[\"R2\"], s=10, label='deep')\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df_tta[scores_df_tta[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot_tta.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "knn_models = scores_df_ttm[\"predictor\"].unique()\n",
    "ax.scatter(x=order_models(scores_df_base[\"model_num\"].tolist()), y=scores_df_base[\"R2\"], s=10, label='deep')\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df_ttm[scores_df_ttm[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot_ttm.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (lazydeep)",
   "language": "python",
   "name": "pycharm-12fcba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
