{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% imports\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# set seed\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import utils as ut\n",
    "import experiment as exp\n",
    "import evaluation as ev\n",
    "from pathlib import *\n",
    "import torch\n",
    "import random\n",
    "import regex as re\n",
    "import plot\n",
    "import matplotlib.pyplot as plt\n",
    "from sk_models import LocalWeightedRegression, PCR,setup_pls_models_exh,LinearRidge,CustomWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% seed\n"
    }
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "\n",
    "random_state = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% set these parametesr\n"
    }
   },
   "outputs": [],
   "source": [
    "#we need to set parametesr\n",
    "file_name = \"mango_684_990.csv\" #\"mango_684_990.csv\" #\"mango_729_975.csv\" #fitlered=513-1050\n",
    "id_cols =['Set','Season','Region','Date','Type','Cultivar','Pop','Temp','FruitID']#\n",
    "output_cols = ['DM']\n",
    "\n",
    "data_path = Path('D:/workspace/lazydeep/data/soil_data/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/0.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup parametesr\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-114a65892fab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mncol\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mn_comps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m101\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTabularDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mid_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mid_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_cols\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "data_file = data_path / file_name\n",
    "log_dir = log_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "data = pd.read_csv(data_file)\n",
    "data = ut.sample_data(data,random_state)\n",
    "nrow, ncol = data.shape\n",
    "\n",
    "n_features = ncol - 1-len(id_cols)\n",
    "n_comps = [i*5 for i in range(1,21) if i *5 < n_features)]\n",
    "\n",
    "dataset = ut.TabularDataset(data,id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "\n",
    "# todo write a summary\n",
    "#ut.setup_logger(logger_name=\"\",file_name=log_dir/\"log.txt\")\n",
    "ut.setup_logger(logger_name=\"summary\",file_name=log_dir/\"summary.txt\")\n",
    "#tb = SummaryWriter(log_dir/\"tb\")\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Setup summary logging and results datastructures\n"
    }
   },
   "outputs": [],
   "source": [
    "#todo write a summary\n",
    "\n",
    "ut.setup_logger(logger_name=\"summary\",file_name=log_dir/\"summary.txt\")\n",
    "summary_logger = logging.getLogger(\"summary\")\n",
    "eval = ev.MangoesSplitter(preprocessing=None,tensorboard=None,time=True,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Define helper models\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_preds_and_res(preds,save_loc = \"\", name_lambda = lambda x:x,save_lambda = lambda x:x):\n",
    "    for col_name in preds.columns:\n",
    "        # plot predictions\n",
    "        fig, ax = plot.scatter_plot(preds,col_name,\"y\",color_col=\"set_id\",title= f\"Predictions for {name_lambda(col_name)}\")\n",
    "        plt.savefig(save_loc/f\"predictions_{save_lambda(col_name)}.png\",bbox_inches='tight')\n",
    "        plt.close()\n",
    "        # plt.show()\n",
    "\n",
    "        fig, ax = plot.residual_plot(preds, col_name, \"y\", color_col=\"set_id\",title = f\"Residuals for {name_lambda(col_name)}\")\n",
    "        plt.savefig(save_loc/f\"residuals_{save_lambda(col_name)}.png\", bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%% run PCR models\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#setup\n",
    "scores_df_pcr = None\n",
    "scores_df_pcr_final = None\n",
    "for n_component in n_comps:\n",
    "    save_loc = log_dir/f\"PCR_{n_component}\"\n",
    "    if not save_loc.exists():\n",
    "        save_loc.mkdir()\n",
    "\n",
    "    local_logger_name = f\"pcr_{n_component}\"\n",
    "    ut.setup_logger(logger_name=local_logger_name,file_name=save_loc/f\"{local_logger_name}_log.txt\")\n",
    "    local_logger = logging.getLogger(local_logger_name)\n",
    "\n",
    "    scheme = ev.PCAScheme(logger=local_logger_name,whiten=False,n_components=n_component)\n",
    "\n",
    "    local_logger.info(f\"Running PCR with {n_component} components\")\n",
    "    scores_sk, preds_sk, model_states_sk , train_time_sk, test_time_sk,_ = eval.evaluate(setup_pls_models_exh(nrow),dataset,scheme,logger_name=local_logger_name)\n",
    "    scores_sk_final, _, model_states_sk_final , _, _,_= eval.build(setup_pls_models_exh(nrow),dataset,scheme,logger_name=local_logger_name)\n",
    "    #for fold,nested in model_states_sk.items():\n",
    "    #    for name,model in nested.items():\n",
    "    #        model.save(save_loc/(f\"{name}_{fold}\"))\n",
    "    #for name,model in model_states_sk_final.items():\n",
    "    #    model.save(save_loc/(f\"{name}_final\"))\n",
    "\n",
    "    local_logger.info(f\"Train times: {train_time_sk}\")\n",
    "    local_logger.info(f\"Test times: {test_time_sk}\")\n",
    "    local_logger.info(f\"Scores: {scores_sk}\")\n",
    "    for key,value in ut.flip_dicts(scores_sk).items():\n",
    "        local_logger.info(f\"{key}: {value}\")\n",
    "\n",
    "    preds_sk.to_csv(save_loc/ (f\"predictions_pcr\" + \".csv\"), index=False)\n",
    "    plot_preds_and_res(preds_sk,name_lambda=lambda x:f\"PCR with {x} components\",save_lambda= lambda x:f\"pcr_{x}\",save_loc=save_loc)\n",
    "\n",
    "    flipped = ut.flip_dicts(scores_sk)\n",
    "    #add to scores\n",
    "    for name,record in flipped.items():\n",
    "        record1 = {'model':f\"pca_{name}\",'n_comp':n_component}\n",
    "        if scores_df_pcr is None:\n",
    "            scores_df_pcr =pd.DataFrame([{**record1,**record}])\n",
    "        else:\n",
    "           scores_df_pcr=scores_df_pcr.append([{**record1,**record}],ignore_index=True)\n",
    "        \n",
    "    flipped = ut.flip_dicts(scores_sk_final)\n",
    "    #add to scores\n",
    "    for name,record in flipped.items():\n",
    "        record1 = {'model':f\"pca_{name}\",'n_comp':n_component}\n",
    "        if scores_df_pcr_final is None:\n",
    "            scores_df_pcr_final =pd.DataFrame([{**record1,**record}])\n",
    "        else:\n",
    "           scores_df_pcr_final=scores_df_pcr_final.append([{**record1,**record}],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%% run PLS Models for each component\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_df_pls =None #datframe for scores\n",
    "scores_df_pls_final =None #datframe for scores\n",
    "\n",
    "for n_component in n_comps:\n",
    "    save_loc = log_dir/f\"PLS_{n_component}\"\n",
    "    if not save_loc.exists():\n",
    "        save_loc.mkdir()\n",
    "    local_log_name = f\"pls_{n_component}\"\n",
    "    ut.setup_logger(logger_name=local_log_name,file_name=save_loc/f\"{local_log_name}_log.txt\")\n",
    "    local_logger = logging.getLogger(local_log_name)\n",
    "    local_logger.info(f\"Running {n_component} components\")\n",
    "\n",
    "\n",
    "    #run pls\n",
    "    scheme = ev.PLSScheme(n_components=n_component,scale=True,logger=local_logger_name)\n",
    "    scores, preds, model_states ,train_time, test_time,_ = eval.evaluate(setup_pls_models_exh(nrow),dataset,scheme,logger_name=local_logger_name)\n",
    "    scores_pls_final, _, model_states_final , _, _,_= eval.build(setup_pls_models_exh(nrow),dataset,scheme,logger_name=local_logger_name)\n",
    "    #for fold,nested in model_states.items():\n",
    "    #    for name,model in nested.items():\n",
    "    #        model.save(save_loc/(f\"{name}_{fold}\"))\n",
    "    #for name,model in model_states_final.items():\n",
    "    #    model.save(save_loc/(f\"{name}_final\"))\n",
    "\n",
    "    #log results\n",
    "    local_logger.info(f\"Train times: {train_time}\")\n",
    "    local_logger.info(f\"Test times: {test_time}\")\n",
    "    local_logger.info(f\"Scores: {scores}\")\n",
    "    for key,value in ut.flip_dicts(scores).items():\n",
    "        local_logger.info(f\"{key}: {value}\")\n",
    "\n",
    "    #write preds\n",
    "    preds.to_csv(save_loc/ (f\"predictions_n_comp={n_component}\" + \".csv\"), index=False)\n",
    "    #plot our figures\n",
    "    plot_preds_and_res(preds,name_lambda=lambda x:f\"PLS with {x} components\",save_lambda= lambda x:f\"pls_{x}\",save_loc=save_loc)\n",
    "\n",
    "    flipped = ut.flip_dicts(scores)\n",
    "    for name,record in flipped.items():\n",
    "        record1 = {'model':f\"pls_{name}\",'n_comp':n_component}\n",
    "        if scores_df_pls is None:\n",
    "            scores_df_pls =pd.DataFrame([{**record1,**record}])\n",
    "        else:\n",
    "            scores_df_pls=scores_df_pls.append([{**record1,**record}],ignore_index=True)\n",
    "            \n",
    "    flipped = ut.flip_dicts(scores_pls_final)\n",
    "    for name,record in flipped.items():\n",
    "        record1 = {'model':f\"pls_{name}\",'n_comp':n_component}\n",
    "        if scores_df_pls_final is None:\n",
    "            scores_df_pls_final =pd.DataFrame([{**record1,**record}])\n",
    "        else:\n",
    "            scores_df_pls_final=scores_df_pls_final.append([{**record1,**record}],ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%% Concat scores and write summary\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_df = pd.concat((scores_df_pcr,scores_df_pls))#pd.concat((scores_df_lr,scores_df_pcr,scores_df_pls))\n",
    "scores_df.to_csv(log_dir / f\"scores.csv\", index=False)\n",
    "\n",
    "scores_df_final = pd.concat((scores_df_pcr_final,scores_df_pls_final))#pd.concat((scores_df_lr,scores_df_pcr,scores_df_pls))\n",
    "scores_df_final.to_csv(log_dir / f\"scores_final.csv\", index=False)\n",
    "\n",
    "summary_logger.info(\"-----------------------------\\n\"\n",
    "                    \"Rankings\\n\"\n",
    "                    \"-------------------------------\")\n",
    "scores_df_sorted= scores_df.sort_values(\"MSE\",ascending=True)\n",
    "summary_logger.info(f\"Rank - \" +\" - \".join(list(scores_df_sorted.columns)))\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    summary_logger.info(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%% setup for plottings\n"
    }
   },
   "outputs": [],
   "source": [
    "min_value = scores_df['MSE'].min()\n",
    "max_value = scores_df['MSE'].max()*1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%plot supervised\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Number of Components\")\n",
    "ax.set_ylabel(\"Loss (MSE)\")\n",
    "ax.set_title(\"Locally weighted PLS by number of components\")\n",
    "#ax.plot(x_ls,y_ls,label=\"lr\")\n",
    "\n",
    "series_labels = scores_df_pls['model'].unique()\n",
    "for name in series_labels:\n",
    "    subset = scores_df_pls[scores_df_pls[\"model\"]==name]\n",
    "    ax.plot(subset[\"n_comp\"],subset[\"MSE\"],label = f\"{name}\")\n",
    "ax.set_ylim(0,max_value)\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"mse_plot_pls.png\",bbox_inches='tight')\n",
    "\n",
    "ax.set_ylim(0,2)\n",
    "plt.savefig(log_dir / f\"mse_plot_pls_compressed.png\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%plot unsupervised\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Number of Components\")\n",
    "ax.set_ylabel(\"Loss (MSE)\")\n",
    "ax.set_title(\"Locally weighted PCR by number of components\")\n",
    "#ax.plot(x_ls,y_ls,label=\"lr\")\n",
    "\n",
    "series_labels = scores_df_pcr['model'].unique()\n",
    "for name in series_labels:\n",
    "    subset = scores_df_pcr[scores_df_pcr[\"model\"]==name]\n",
    "    ax.plot(subset[\"n_comp\"],subset[\"MSE\"],label = f\"{name}\")\n",
    "ax.set_ylim(0,max_value)\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"mse_plot_pca.png\",bbox_inches='tight')\n",
    "\n",
    "ax.set_ylim(0,2)\n",
    "plt.savefig(log_dir / f\"mse_plot_pca_compressed.png\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Number of Components\")\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_title(\"Locally weighted PLS by number of components\")\n",
    "\n",
    "series_labels = scores_df_pls['model'].unique()\n",
    "for name in series_labels:\n",
    "    subset = scores_df_pls[scores_df_pls[\"model\"]==name]\n",
    "    ax.plot(subset[\"n_comp\"],subset[\"R2\"],label = f\"{name}\")\n",
    "\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_pls.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_pls_v2.png\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Number of Components\")\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_title(\"Locally weighted PCR by number of components\")\n",
    "\n",
    "series_labels = scores_df_pcr['model'].unique()\n",
    "for name in series_labels:\n",
    "    subset = scores_df_pcr[scores_df_pcr[\"model\"]==name]\n",
    "    ax.plot(subset[\"n_comp\"],subset[\"R2\"],label = f\"{name}\")\n",
    "\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_pcr.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_pcr_v2.png\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/22521382/nonlinear-colormap-matplotlib\n",
    "\n",
    "class nlcmap(object):\n",
    "    def __init__(self, cmap, levels):\n",
    "        self.cmap = cmap\n",
    "        self.N = cmap.N\n",
    "        self.monochrome = self.cmap.monochrome\n",
    "        self.levels = np.asarray(levels, dtype='float64')\n",
    "        self._x = self.levels\n",
    "        self.levmax = self.levels.max()\n",
    "        self.levmin = self.levels.min()\n",
    "        self.transformed_levels = np.linspace(self.levmin, self.levmax, #uniform spacing along levels (colour segments)\n",
    "             len(self.levels))\n",
    "\n",
    "    def __call__(self, xi, alpha=1.0, **kw):\n",
    "        yi = np.interp(xi, self._x, self.transformed_levels)\n",
    "        return self.cmap((yi-self.levmin) / (self.levmax-self.levmin), alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = np.concatenate((\n",
    "    [0, 1],\n",
    "    [0.6,0.8,0.9,0.95,0.98]\n",
    "    ))\n",
    "\n",
    "levels = levels[levels <= 1]\n",
    "levels.sort()\n",
    "print(levels)\n",
    "cmap_nonlin = nlcmap(plt.cm.YlGnBu, levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = scores_df_pls[[\"model\",\"n_comp\",\"R2\"]]\n",
    "subset = subset[np.logical_not(subset[\"model\"]==\"pls_lr\")]\n",
    "trans = subset[\"model\"].transform(lambda x: int(x.replace(\"pls_lwr_k=\",\"\"))).tolist()\n",
    "\n",
    "subset.loc[:,\"model\"]=trans\n",
    "subset=subset.sort_values(\"model\",ascending=False)\n",
    "wide = subset.pivot(index = \"model\",columns= \"n_comp\",values=\"R2\")\n",
    "\n",
    "ax = sns.heatmap(wide, linewidth=0.0,vmin=0,center=0,cbar_kws={'label':\"R2 Score\"},cmap=cmap_nonlin)\n",
    "\n",
    "ax.set_title(\"Grid Search for number of neighbours and number of components \")\n",
    "ax.set_xlabel(\"Number of Components\")\n",
    "ax.set_ylabel(\"Number of Neighbours\")\n",
    "\n",
    "plt.savefig(log_dir/\"pls_heatmap.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = scores_df_pcr[[\"model\",\"n_comp\",\"R2\"]]\n",
    "subset = subset[np.logical_not(subset[\"model\"]==\"pca_lr\")]\n",
    "trans = subset[\"model\"].transform(lambda x: int(x.replace(\"pca_lwr_k=\",\"\"))).tolist()\n",
    "\n",
    "subset.loc[:,\"model\"]=trans\n",
    "subset=subset.sort_values(\"model\",ascending=False)\n",
    "wide = subset.pivot(index = \"model\",columns= \"n_comp\",values=\"R2\")\n",
    "\n",
    "ax = sns.heatmap(wide, linewidth=0.0,vmin=0,center=0,cbar_kws={'label':\"R2 Score\"},cmap=cmap_nonlin)\n",
    "\n",
    "ax.set_title(\"Grid Search for number of neighbours and number of components \")\n",
    "ax.set_xlabel(\"Number of Components\")\n",
    "ax.set_ylabel(\"Number of Neighbours\")\n",
    "\n",
    "plt.savefig(log_dir/\"pca_heatmap.png\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (lazydeep)",
   "language": "python",
   "name": "pycharm-12fcba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
