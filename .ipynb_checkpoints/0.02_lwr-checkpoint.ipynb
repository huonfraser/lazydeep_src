{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% imports\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# set seed\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import utils as ut\n",
    "import experiment as exp\n",
    "import evaluation as ev\n",
    "from pathlib import *\n",
    "import torch\n",
    "import random\n",
    "import regex as re\n",
    "import plot\n",
    "import matplotlib.pyplot as plt\n",
    "from sk_models import LocalWeightedRegression, PCR,setup_pls_models_exh,LinearRidge,StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% seed\n"
    }
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "\n",
    "random_state = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% set these parametesr\n"
    }
   },
   "outputs": [],
   "source": [
    "#we need to set parametesr\n",
    "file_name =\"A_C_OF_ALPHA.csv\"# \"A_AL_RT.csv\" #\"PLN7.csv\"\n",
    "id_cols =['sample_id'] ##[\"db_id\",\"sample_id\"]#[\"sample_id\"]\n",
    "\n",
    "data_path = Path('D:/workspace/lazydeep/data/soil_data/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/0.02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup parametesr\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\workspace\\lazydeep\\experiments\\0.02\\A_C_OF_ALPHA\n",
      "D:\\workspace\\lazydeep\\experiments\\0.02\\A_C_OF_ALPHA\n"
     ]
    }
   ],
   "source": [
    "data_file = data_path / file_name\n",
    "log_dir = log_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "print(log_dir)\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "data = ut.sample_data(data,random_state)\n",
    "nrow, ncol = data.shape\n",
    "\n",
    "n_features = ncol - 1-len(id_cols)\n",
    "dataset = ut.TabularDataset(data,id_cols = id_cols, cat_cols=None, output_cols=None, ignore_cols= None)\n",
    "\n",
    "# todo write a summary\n",
    "#ut.setup_logger(logger_name=\"\",file_name=log_dir/\"log.txt\")\n",
    "ut.setup_logger(logger_name=\"summary\",file_name=log_dir/\"summary.txt\")\n",
    "#tb = SummaryWriter(log_dir/\"tb\")\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Setup summary logging and results datastructures\n"
    }
   },
   "outputs": [],
   "source": [
    "ut.setup_logger(logger_name=\"summary\",file_name=log_dir/\"summary.txt\")\n",
    "summary_logger = logging.getLogger(\"summary\")\n",
    "eval = ev.CrossValEvaluation(preprocessing=StandardScaler(),tensorboard=None,time=True,random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Define helper models\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_preds_and_res(preds,save_loc = \"\", name_lambda = lambda x:x,save_lambda = lambda x:x):\n",
    "    for col_name in preds.columns:\n",
    "        # plot predictions\n",
    "        fig, ax = plot.scatter_plot(preds,col_name,\"y\",color_col=\"set_id\",title= f\"Predictions for {name_lambda(col_name)}\")\n",
    "        plt.savefig(save_loc/f\"predictions_{save_lambda(col_name)}.png\",bbox_inches='tight')\n",
    "        plt.close()\n",
    "        # plt.show()\n",
    "\n",
    "        fig, ax = plot.residual_plot(preds, col_name, \"y\", color_col=\"set_id\",title = f\"Residuals for {name_lambda(col_name)}\")\n",
    "        plt.savefig(save_loc/f\"residuals_{save_lambda(col_name)}.png\", bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% run PCR models\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LWR'\n",
      "Running Cross Evaluation with 5 folds'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LinearRegression' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_95900\\3174850488.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mlocal_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Running LWR\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mscores_sk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds_sk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_states_sk\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtrain_time_sk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_time_sk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msetup_pls_models_exh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscheme\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogger_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_logger_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mscores_sk_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_states_sk_final\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msetup_pls_models_exh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscheme\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogger_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_logger_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lazy_deep_v2\\lazydeep_src\\evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, original_models, data, eval_, pretrain, logger_name, load_fun, load_fun_pp)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m         \u001b[0mmodel_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'init_state'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moriginal_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[0mtrain_times\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lazy_deep_v2\\lazydeep_src\\evaluation.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m         \u001b[0mmodel_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'init_state'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moriginal_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[0mtrain_times\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lazy_deep_v2\\lazydeep_src\\sk_models.py\u001b[0m in \u001b[0;36mstate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         state_dict['lin_param'] = {\n\u001b[1;32m--> 271\u001b[1;33m                 \u001b[1;34m'coef_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m                 \u001b[1;34m'intercept_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m             }\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LinearRegression' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "scores_df_lwr = None\n",
    "scores_df_lwr_final = None\n",
    "\n",
    "save_loc = log_dir/f\"LWR\"\n",
    "if not save_loc.exists():\n",
    "    save_loc.mkdir()\n",
    "\n",
    "local_logger_name = f\"LWR\"\n",
    "ut.setup_logger(logger_name=local_logger_name,file_name=save_loc/f\"{local_logger_name}_log.txt\")\n",
    "local_logger = logging.getLogger(local_logger_name)\n",
    "\n",
    "scheme = ev.SKLearnScheme(logger=local_logger_name)\n",
    "\n",
    "local_logger.info(f\"Running LWR\")\n",
    "scores_sk, preds_sk, model_states_sk , train_time_sk, test_time_sk,_ = eval.evaluate(setup_pls_models_exh(nrow),dataset,scheme,logger_name=local_logger_name)\n",
    "scores_sk_final, _, model_states_sk_final , _, _,_= eval.build(setup_pls_models_exh(nrow),dataset,scheme,logger_name=local_logger_name)\n",
    "\n",
    "local_logger.info(f\"Train times: {train_time_sk}\")\n",
    "local_logger.info(f\"Test times: {test_time_sk}\")\n",
    "local_logger.info(f\"Scores: {scores_sk}\")\n",
    "for key,value in ut.flip_dicts(scores_sk).items():\n",
    "    local_logger.info(f\"{key}: {value}\")\n",
    "\n",
    "preds_sk.to_csv(save_loc/ (f\"predictions\" + \".csv\"), index=False)\n",
    "plot_preds_and_res(preds_sk,name_lambda=lambda x:f\"LWR\",save_lambda= lambda x:f\"lwr\",save_loc=save_loc)\n",
    "\n",
    "flipped = ut.flip_dicts(scores_sk)\n",
    "#add to scores\n",
    "for name,record in flipped.items():\n",
    "    record1 = {'model':f\"{name}\",'n_comp':n_features}\n",
    "    if scores_df_lwr is None:\n",
    "        scores_df_lwr =pd.DataFrame([{**record1,**record}])\n",
    "    else:\n",
    "        scores_df_lwr=scores_df_lwr.append([{**record1,**record}],ignore_index=True)\n",
    "\n",
    "flipped = ut.flip_dicts(scores_sk_final)\n",
    "#add to scores\n",
    "for name,record in flipped.items():\n",
    "    record1 = {'model':f\"{name}\",'n_comp':n_features}\n",
    "    if scores_df_lwr_final is None:\n",
    "        scores_df_lwr_final =pd.DataFrame([{**record1,**record}])\n",
    "    else:\n",
    "        scores_df_lwr_final=scores_df_lwr_final.append([{**record1,**record}],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% Concat scores and write summary\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_df = scores_df_lwr #pd.concat((scores_df_lr,scores_df_ pcr,scores_df_pls))\n",
    "scores_df.to_csv(log_dir / f\"scores.csv\", index=False)\n",
    "\n",
    "scores_df_final = scores_df_lwr_final#pd.concat((scores_df_lr,scores_df_pcr,scores_df_pls))\n",
    "scores_df_final.to_csv(log_dir / f\"scores_final.csv\", index=False)\n",
    "\n",
    "summary_logger.info(\"-----------------------------\\n\"\n",
    "                    \"Rankings\\n\"\n",
    "                    \"-------------------------------\")\n",
    "scores_df_sorted= scores_df.sort_values(\"MSE\",ascending=True)\n",
    "summary_logger.info(f\"Rank - \" +\" - \".join(list(scores_df_sorted.columns)))\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    summary_logger.info(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/22521382/nonlinear-colormap-matplotlib\n",
    "\n",
    "class nlcmap(object):\n",
    "    def __init__(self, cmap, levels):\n",
    "        self.cmap = cmap\n",
    "        self.N = cmap.N\n",
    "        self.monochrome = self.cmap.monochrome\n",
    "        self.levels = np.asarray(levels, dtype='float64')\n",
    "        self._x = self.levels\n",
    "        self.levmax = self.levels.max()\n",
    "        self.levmin = self.levels.min()\n",
    "        self.transformed_levels = np.linspace(self.levmin, self.levmax, #uniform spacing along levels (colour segments)\n",
    "             len(self.levels))\n",
    "\n",
    "    def __call__(self, xi, alpha=1.0, **kw):\n",
    "        yi = np.interp(xi, self._x, self.transformed_levels)\n",
    "        return self.cmap((yi-self.levmin) / (self.levmax-self.levmin), alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = np.concatenate((\n",
    "    [0, 1],\n",
    "    [0.6,0.8,0.9,0.95,0.98]\n",
    "    ))\n",
    "\n",
    "levels = levels[levels <= 1]\n",
    "levels.sort()\n",
    "print(levels)\n",
    "cmap_nonlin = nlcmap(plt.cm.YlGnBu, levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = scores_df[[\"model\",\"n_comp\",\"R2\"]]\n",
    "subset = subset[np.logical_not(subset[\"model\"]==\"lr\")]\n",
    "trans = subset[\"model\"].transform(lambda x: int(x.replace(\"lwr_k=\",\"\"))).tolist()\n",
    "\n",
    "subset.loc[:,\"model\"]=trans\n",
    "subset=subset.sort_values(\"model\",ascending=False)\n",
    "wide = subset.pivot(index = \"model\",columns= \"n_comp\",values=\"R2\")\n",
    "\n",
    "ax = sns.heatmap(wide, linewidth=0.0,vmin=0,center=0,cbar_kws={'label':\"R2 Score\"},cmap=cmap_nonlin)\n",
    "\n",
    "ax.set_title(\"Grid Search for number of neighbours\")\n",
    "ax.set_xlabel(\"Number of Components\")\n",
    "ax.set_ylabel(\"Number of Neighbours\")\n",
    "\n",
    "plt.savefig(log_dir/\"heatmap.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (lazydeep)",
   "language": "python",
   "name": "pycharm-12fcba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
