{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detected is GeForce GTX 970\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import logging\n",
    "import torch\n",
    "# set seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils as ut\n",
    "import experiment as ex\n",
    "from evaluation import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import random\n",
    "#define fixed_hyperparams and create a config gen\n",
    "from configurations import RandomConfigGen, Configuration\n",
    "from torch import nn\n",
    "from deep_net import RandomNet\n",
    "from experiment import run_experiment\n",
    "import regex as re\n",
    "from pathlib import *\n",
    "from sk_models import PLSRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sk_models import PLSRegression, StandardScaler,LocalWeightedRegression,PLSLWR,LinearRidge\n",
    "from river_models import *\n",
    "\n",
    "from river import stream,linear_model,preprocessing, ensemble, metrics, optim\n",
    "from river.neighbors import KNNRegressor \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from river.utils import dict2numpy, numpy2dict\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "random_state = np.random.RandomState(seed)\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"GPU detected is {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory is D:\\workspace\\lazydeep\\experiments\\12.0_v3\\PLN7\n"
     ]
    }
   ],
   "source": [
    "#setup input and output directories\n",
    "\n",
    "#setup input and outpu t formats, load data\n",
    "\n",
    "#we need to set parametesr\n",
    "file_name = \"PLN7.csv\" #\"mango_684_990.csv\" #\"mango_729_975.csv\" #fitlered=513-1050\n",
    "id_cols =[\"db_id\",\"sample_id\"] #\n",
    "output_cols = None\n",
    "data_path = Path('D:/workspace/lazydeep/data/soil_data/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/12.0_v3\") #1.01/\")\n",
    "if not log_path.exists():\n",
    "    log_path.mkdir()\n",
    "\n",
    "data_file = data_path / file_name\n",
    "log_dir = log_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "print(f\"Output directory is {log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data=data.sample(frac=1,random_state=random_state)\n",
    "\n",
    "pre_ind =[i for i in range(0,10000)]\n",
    "pretrain_ind,pretest_ind = train_test_split(pre_ind,train_size=5/6,random_state=random_state,shuffle=False)\n",
    "stream_ind = [i for i in range(110000,210000)]\n",
    "\n",
    "pretrain_data =  ut.TabularDataset(data.iloc[pretrain_ind,:],id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "pretest_data = ut.TabularDataset(data.iloc[pretest_ind,:],id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "stream_data = ut.TabularDataset(data.iloc[stream_ind,:],id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "\n",
    "nrow, ncol = data.shape\n",
    "nrow_train = len(pretrain_data)\n",
    "nrow_test = len(pretest_data)\n",
    "nrow_stream = len(stream_data)\n",
    "\n",
    "print(f\"train: {nrow_train}, test: {nrow_test}, stream: {nrow_stream}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep, deep_lwr, ensemble_deep, deep_ensemble_lwr, ensemble_deep\n",
    "\n",
    "def build_model(dir_,id_,scaler_):\n",
    "    deep_ = torch.load(dir_/\"models\"/id_/\"_model\")\n",
    "    deep_.load_state(dir_/\"models\"/id_/\"_final\")\n",
    "    \n",
    "    return (StreamWrapper(scaler_)|StreamDeep(deep_))\n",
    "\n",
    "def build_model_lwr(dir_,id_,scaler_,k_=1000,kernal_=False):\n",
    "    model = build_model(dir_,id_,scaler_)\n",
    "    \n",
    "    return (model|preprocessing.StandardScaler()|StreamLocalWeightedRegression(n_neighbors=k_,floor=False,kernal=kernal_))\n",
    "\n",
    "def build_model_knn(dir_,id_,scaler_,k_=5):\n",
    "    model = build_model(dir_,id_,scaler_)\n",
    "    \n",
    "    return (model|KNNRegressor(n_neighbors=k_))\n",
    "\n",
    "def build_model_lr(dir_,id_,scaler_,k_=5):\n",
    "    model = build_model(dir_,id_,scaler_)\n",
    "    \n",
    "    return (model|SlidingWindowLR())\n",
    "\n",
    "\n",
    "pls_model_dir = Path(\"D:/workspace/lazydeep/experiments/1.01/PLN7\")\n",
    "deep_model_dir = Path(\"D:/workspace/lazydeep/experiments/2.00/PLN7\")\n",
    "\n",
    "pls_scaler = PLSRegression(n_components=34).from_state(PLSRegression(n_components=34).load_state(pls_model_dir/'preprocessing'/f\"_final\"))      \n",
    "deep_scaler = StandardScaler().from_state(StandardScaler().load_state(deep_model_dir/'preprocessing'/f\"_final\"))      \n",
    "\n",
    "\n",
    "pls_nums = [\"random_82\",\"random_24\",\"random_10\",\"random_4\",\"random_73\"]\n",
    "deep_nums = [\"random_29\",\"random_60\",\"random_63\",\"random_41\",\"random_15\"]\n",
    "\n",
    "pls_num = 0\n",
    "pls_lwr_num = 0 \n",
    "pls_lwr_ens_num = 0\n",
    "\n",
    "deep_num = 1 \n",
    "deep_lwr_num = 1\n",
    "deep_lwr_ens_num = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "river_models = {}\n",
    "\n",
    "river_models['pls-deep']  = build_model(pls_model_dir,pls_nums[pls_num],pls_scaler)\n",
    "river_models['pls-deep-lr']  = build_model_lr(pls_model_dir,pls_nums[pls_num],pls_scaler)\n",
    "river_models['pls-deep-knn']  = build_model_knn(pls_model_dir,pls_nums[pls_num],pls_scaler)\n",
    "\n",
    "river_models['pls-deep-lwr']  = (build_model(pls_model_dir,pls_nums[pls_lwr_num],pls_scaler)|StreamLocalWeightedRegression(n_neighbors=1000,floor=False,kernal=True))\n",
    "river_models['pls-deep-E(lwr)'] = (build_model(pls_model_dir,pls_nums[pls_lwr_ens_num],pls_scaler)| BaggingRegressor2(n_models=3,seed=seed,model = StreamLocalWeightedRegression(n_neighbors=1000,floor=True),record_diversity=True))\n",
    "\n",
    "                                   \n",
    "river_models['std-deep']  = build_model(deep_model_dir,deep_nums[deep_num],deep_scaler)\n",
    "river_models['std-deep-lr']  = build_model_lr(deep_model_dir,deep_nums[deep_num],deep_scaler)\n",
    "river_models['std-deep-knn']  = build_model_knn(deep_model_dir,deep_nums[deep_num],deep_scaler)\n",
    "\n",
    "river_models['std-deep-lwr']  = (build_model(deep_model_dir,deep_nums[deep_lwr_num],deep_scaler)|StreamLocalWeightedRegression(n_neighbors=1000,floor=False,kernal=True))\n",
    "river_models['std-deep-E(lwr)'] = (build_model(deep_model_dir,deep_nums[deep_lwr_ens_num],deep_scaler)| BaggingRegressor2(n_models=3,seed=seed,model = StreamLocalWeightedRegression(n_neighbors=1000,floor=True),record_diversity=True))\n",
    "\n",
    "river_models['E(pls-deep)'] =  VotingRegressor([build_model(pls_model_dir,i,pls_scaler) for i in pls_nums])\n",
    "river_models['E(std-deep)'] = VotingRegressor([build_model(deep_model_dir,i,deep_scaler) for i in deep_nums])                                   \n",
    "                                   \n",
    "river_models['E(pls-deep-lwr)'] =  VotingRegressor([build_model_lwr(pls_model_dir,i,pls_scaler) for i in pls_nums])\n",
    "river_models['E(std-deep-lwr)'] =  VotingRegressor([build_model_lwr(deep_model_dir,i,deep_scaler) for i in deep_nums])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#setup our metrics and stores of results\n",
    "full_set = river_models.keys()\n",
    "metrics = {'R2':{name:metrics.R2() for name in full_set},\n",
    "           'R2_rolling':{name:RollingR2(window_size=1000) for name in full_set},\n",
    "           'MSE':{name:metrics.MSE() for name in river_models.keys()},\n",
    "           'MSE_rolling':{name:RollingMSE(window_size=1000) for name in full_set}\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set = river_models.keys()\n",
    "metrics = {'R2':{name:metrics.R2() for name in full_set},\n",
    "           'R2_rolling': {name:RollingR2(window_size=1000) for name in full_set},\n",
    "           'MSE':{name:metrics.MSE() for name in river_models.keys()},\n",
    "           'MSE_rolling':{name:RollingMSE(window_size=1000) for name in full_set}\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take our pretrained models, now evaluate them on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_,_,river_models,metrics = prequential_evaluate(pretrain_data,river_models,metrics,pretrain = len(pretrain_data),num_its=len(pretrain_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test,scores_test,metrics = score_evaluate(pretest_data,river_models,metrics,num_its=len(pretest_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_stream, scores_stream,river_models,metrics = prequential_evaluate(stream_data,river_models,metrics,pretrain=0,num_its=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_dict(dict1,dict2):\n",
    " \n",
    "    dict12 = {k:dict1[k]+dict2[k] for k in dict1.keys()}   \n",
    "    return dict12\n",
    "\n",
    "def zip_nested_dict(dict1,dict2):\n",
    "    dict12 = {}\n",
    "    \n",
    "    for k in dict1.keys():\n",
    "        dict12[k] = {name:dict1[k][name]+dict2[k][name] for name in dict1[k].keys()}\n",
    "    return dict12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = zip_dict(preds_test,preds_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = zip_nested_dict(scores_test,scores_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(preds)\n",
    "\n",
    "for (columnName, columnData) in preds_df.iteritems():\n",
    "    preds_df[f'diff_{columnName}'] = columnData-preds_df['y']\n",
    "\n",
    "preds_df.to_csv(log_dir/\"preds_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#findings\n",
    "#1) preprocessing works, random lr things for lr don't\n",
    "#) standardisation asks as regularisation\n",
    "\n",
    "scores_df_rolling = pd.DataFrame(scores['R2_rolling'])\n",
    "scores_df_total = pd.DataFrame(scores['R2'])\n",
    "\n",
    "scores_df_rolling.to_csv(log_dir/\"R2_rolling.csv\")\n",
    "scores_df_total.to_csv(log_dir/\"R2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_title(\"Streaming performance \")\n",
    "\n",
    "for (columnName, columnData) in scores_df_total.iteritems():\n",
    "    ax.plot(columnData.index,columnData,'-',label = f\"{columnName}\")\n",
    "ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_v2.png\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_title(\"Streaming performance (rolling average) \")\n",
    "    \n",
    "for (columnName, columnData) in scores_df_rolling.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label = f\"{columnName}\")\n",
    "ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling_v2.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.set_title(\"Streaming performance \")\n",
    "\n",
    "scores_df = pd.DataFrame(scores['MSE'])\n",
    "scores_df.to_csv(log_dir/\"MSE.csv\")\n",
    "for (columnName, columnData) in scores_df.iteritems():\n",
    "    ax.plot(columnData.index,columnData,'-',label = f\"{columnName}\")\n",
    "ax.plot([len(pretest_data),len(pretest_data)],[0,1000],c=\"black\",ls='--')\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"mse_plot.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1000)\n",
    "plt.savefig(log_dir / f\"mse_plot_v2.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.set_title(\"Streaming performance (rolling average) \")\n",
    "\n",
    "scores_df = pd.DataFrame(scores['MSE_rolling'])\n",
    "scores_df.to_csv(log_dir/\"MSE_rolling.csv\")\n",
    "for (columnName, columnData) in scores_df.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label = f\"{columnName}\")\n",
    "ax.plot([len(pretest_data),len(pretest_data)],[0,1000],c=\"black\",ls='--')\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"mse_plot_rolling.png\",bbox_inches='tight')\n",
    "ax.set_ylim(-1,200)\n",
    "plt.savefig(log_dir / f\"mse_plot_rolling_v2.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel('y_pred')\n",
    "ax.set_xlabel('y_true')\n",
    "\n",
    "for (columnName, columnData) in preds_df.iteritems():\n",
    "        if not columnName == 'y':\n",
    "            ax.scatter(preds_df['y'],columnData,label = f\"{columnName}\",s=1)\n",
    "            \n",
    "            corr_coef = scipy.stats.pearsonr(columnData, preds_df['y'])\n",
    "            r2 = r2_score(preds_df['y'],columnData)\n",
    "            #slope, intercept, r, p, stderr = scipy.stats.linregress(columnData, preds_df['y'])\n",
    "            loss = mean_squared_error(preds_df['y'], columnData)\n",
    "            mae = mean_absolute_error(preds_df['y'], columnData)    \n",
    "            print(f\"{columnName}, p = {corr_coef[0]}, MSE = {loss}, R2 = {r2}\")\n",
    "            \n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylim(0,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_subset_by_str(dataset,s,reverse=False):\n",
    "    col_names = dataset.columns.tolist()\n",
    "    if reverse:\n",
    "        encoding = [i for i in col_names if not (s in i)]\n",
    "    else:\n",
    "        encoding = [i for i in col_names if (s in i)]\n",
    "    return dataset[encoding]\n",
    "\n",
    "def take_subset_by_re(dataset,s,reverse=False):\n",
    "    col_names = dataset.columns.tolist()\n",
    "    if reverse:\n",
    "        encoding = [i for i in col_names if not s.match(i)]\n",
    "    else:\n",
    "        encoding = [i for i in col_names if s.match(i)]\n",
    "    return dataset[encoding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pls subset\n",
    "subset = take_subset_by_str(scores_df_total ,'pls',reverse=False)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R2\")\n",
    "ax.set_title(\"Streaming performance \")\n",
    "\n",
    "\n",
    "for (columnName, columnData) in subset.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label =  f\"{columnName}\")\n",
    "#ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_pls-deep.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_v2_pls-deep.png\",bbox_inches='tight')\n",
    "\n",
    "\n",
    "subset = take_subset_by_str(scores_df_rolling ,'pls',reverse=False)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R2\")\n",
    "ax.set_title(\"Streaming performance (rolling average) \")\n",
    "\n",
    "for (columnName, columnData) in subset.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label =  f\"{columnName}\")\n",
    "#ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling_pls-deep.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling_v2_pls-deep.png\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = take_subset_by_str(scores_df_total ,'std',reverse=False)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R2\")\n",
    "ax.set_title(\"Streaming performance \")\n",
    "\n",
    "for (columnName, columnData) in subset.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label =  f\"{columnName}\")\n",
    "#ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_std-deep.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_v2_std-deep.png\",bbox_inches='tight')\n",
    "\n",
    "\n",
    "subset = take_subset_by_str(scores_df_rolling ,'std',reverse=False)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R2\")\n",
    "ax.set_title(\"Streaming performance (rolling average) \")\n",
    "\n",
    "for (columnName, columnData) in subset.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label =  f\"{columnName}\")\n",
    "#ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling_std-deep.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling_v2_std-deep.png\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id1 = 87217-len(pretest_data)\n",
    "#x1,y1=stream_data[id1]\n",
    "#river_models[f'std-deep_0'].predict_one(numpy2dict(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in river_models.keys():\n",
    "    print(k)\n",
    "    if k in bags.keys():\n",
    "        print(bags[k].measure_diversity())\n",
    "    else:\n",
    "        print(river_models[k].measure_diversity())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
