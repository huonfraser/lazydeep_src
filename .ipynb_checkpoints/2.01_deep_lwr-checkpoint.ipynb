{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# set seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import utils as ut\n",
    "import experiment as exp\n",
    "from evaluation import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import random\n",
    "#define fixed_hyperparams and create a config gen\n",
    "from configurations import RandomConfigGen, Configuration\n",
    "from torch import nn\n",
    "from deep_net import RandomNet\n",
    "from experiment import run_experiment\n",
    "import regex as re\n",
    "from pathlib import *\n",
    "from plot import *\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sk_models import setup_pls_models_exh, StandardScaler, PLSRegression\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "random_state = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\workspace\\lazydeep\\experiments\\2.01\\A_C_OF_ALPHA\n"
     ]
    }
   ],
   "source": [
    "#setup input and output formats, load data\n",
    "\n",
    "file_name = \"A_C_OF_ALPHA.csv\"\n",
    "id_cols =[\"sample_id\"]#[\"db_id\", \"sample_id\"]#[\"sample_id\"]\n",
    "\n",
    "data_path = Path('D:/workspace/lazydeep/data/soil_data/')\n",
    "model_path = Path('D:/workspace/lazydeep/experiments/2.00/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/2.01\")\n",
    "\n",
    "data_file = data_path / file_name\n",
    "log_dir = log_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "model_dir = model_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "print(log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% load data\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7329, 1703)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data = data.sample(frac=1)\n",
    "nrow, ncol = data.shape\n",
    "data = ut.sample_data(data,random_state)\n",
    "n_features = ncol - 1-len(id_cols)\n",
    "\n",
    "dataset = TabularDataset(data,id_cols = id_cols, cat_cols=None, output_cols=None, ignore_cols= None)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% load models\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 models\n"
     ]
    }
   ],
   "source": [
    "n_models = 100\n",
    "model_names = [f\"random_{i}\" for i in range(0,n_models)]\n",
    "deep_models = {name:torch.load(model_dir/\"models\"/name/\"_model\") for name in model_names}\n",
    "configs =  None\n",
    "#for each model, load state\n",
    "print(f\"Loaded {len(deep_models)} models\")\n",
    "#print(deep_models)\n",
    "for name in model_names:\n",
    "    sub_path = log_dir / name\n",
    "    if not sub_path.exists():\n",
    "        sub_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup logging and tensorboard outputs\n"
    }
   },
   "outputs": [],
   "source": [
    "# set logging, in this case the root logger\n",
    "ut.setup_logger(logger_name=\"\",file_name=log_dir/\"log.txt\")\n",
    "ut.setup_logger(logger_name=\"summary\",file_name=log_dir/\"summary.txt\")\n",
    "summary_logger = logging.getLogger(\"summary\")\n",
    "tb = SummaryWriter(log_dir/\"tb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup experiment\n"
    }
   },
   "outputs": [],
   "source": [
    "fixed_hyperparams = {'bs': 32,'loss': nn.MSELoss(),'epochs': 100}\n",
    "preprocessing = StandardScaler()\n",
    "eval = CrossValEvaluation(preprocessing=preprocessing,tensorboard=None,time=True,random_state=random_state)\n",
    "scores={} #->model->knn:{fold_0:number,...,fold_n:number,mean:number,median:number\n",
    "preds={} #model-> foldsxknn_models\n",
    "deep_scores_dict={}\n",
    "deep_preds_dict={}\n",
    "actual_y = None\n",
    "\n",
    "device = \"cpu\" #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_fun_cv = lambda name,model, fold : model.load_state(model_dir/'models'/name/f\"_fold_{fold}\")\n",
    "load_fun_pp_cv = lambda fold : preprocessing.from_state(preprocessing.load_state(model_dir/'preprocessing'/f\"_fold_{fold}\"))\n",
    "load_fun_build = lambda name,model : model.load_state(model_dir/'models'/name/f\"_final\")\n",
    "load_fun_pp_build = lambda : preprocessing.from_state(preprocessing.load_state(model_dir/'preprocessing'/f\"_final\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% deep experiment\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Tested (test) on 1222 instances with mean losses of: random_0:12.3517,random_1:10.4208,random_2:603.8857,random_3:11.1601,random_4:12.3001,random_5:8.3633,random_6:607.3073,random_7:607.7903,random_8:604.4302,random_9:8.9701,random_10:10.3307,random_11:11.0018,random_12:11.4681,random_13:16.1366,random_14:108.9007,random_15:9.9472,random_16:15.5362,random_17:16.5022,random_18:14.4068,random_19:9.6157,random_20:15.0358,random_21:38.3918,random_22:94.0412,random_23:19.2689,random_24:13.7357,random_25:12.0343,random_26:11.434,random_27:11.8311,random_28:16.3709,random_29:9.5527,random_30:24.8279,random_31:11.6792,random_32:611.1023,random_33:599.2791,random_34:19.1817,random_35:12.6499,random_36:11.8897,random_37:9.9449,random_38:11.5293,random_39:604.3834,random_40:15.1597,random_41:8.9979,random_42:13.3156,random_43:606.8097,random_44:9.523,random_45:617.8652,random_46:10.208,random_47:8.9079,random_48:15.0799,random_49:10.3779,random_50:13.4244,random_51:10.5702,random_52:18.436,random_53:25.1514,random_54:23.6359,random_55:13.8,random_56:10.9313,random_57:11.418,random_58:616.0418,random_59:86.3769,random_60:9.7339,random_61:14.1301,random_62:611.8407,random_63:24.8045,random_64:15.7416,random_65:14.6494,random_66:14.1717,random_67:14.455,random_68:20.1299,random_69:11.6369,random_70:13.0141,random_71:605.2509,random_72:11.2496,random_73:11.7799,random_74:8.7745,random_75:9.8537,random_76:10.462,random_77:10.13,random_78:16.9064,random_79:10.9809,random_80:9.3567,random_81:15.7936,random_82:9.5457,random_83:609.4607,random_84:11.1921,random_85:608.5262,random_86:16.7189,random_87:9.8758,random_88:610.0345,random_89:12.5012,random_90:72.1204,random_91:32.9044,random_92:13.921,random_93:9.8578,random_94:15.3387,random_95:15.4931,random_96:16.9682,random_97:24.5389,random_98:10.6261,random_99:9.3494'\n",
      "Testing (test) took 0:00:10.076001'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Tested (test) on 1222 instances with mean losses of: random_0:21.0659,random_1:9.3206,random_2:509.3131,random_3:9.2362,random_4:14.3732,random_5:11.9329,random_6:512.558,random_7:513.0073,random_8:509.846,random_9:8.4368,random_10:11.3829,random_11:12.5301,random_12:15.3684,random_13:11.4454,random_14:520.6075,random_15:15.1142,random_16:9.5999,random_17:11.2001,random_18:11.5912,random_19:29.7032,random_20:15.9234,random_21:525.2234,random_22:8.1222,random_23:10.0348,random_24:24.5472,random_25:45.6595,random_26:9.7043,random_27:38.4541,random_28:22.897,random_29:8.9298,random_30:48.9319,random_31:10.7605,random_32:516.1393,random_33:509.8002,random_34:9.1635,random_35:15.2037,random_36:8.1478,random_37:12.5409,random_38:12.9326,random_39:509.8178,random_40:11.2929,random_41:40.2555,random_42:14.7706,random_43:512.1679,random_44:8.8982,random_45:516.3615,random_46:32.6123,random_47:13.1109,random_48:13.8939,random_49:14.778,random_50:13.7306,random_51:13.0584,random_52:15.0834,random_53:20.5979,random_54:13.1668,random_55:12.9027,random_56:12.7321,random_57:10.9375,random_58:520.7895,random_59:41.7875,random_60:13.4585,random_61:13.6447,random_62:516.8065,random_63:518.5152,random_64:11.6741,random_65:10.4999,random_66:13.7541,random_67:9.2444,random_68:12.2654,random_69:14.5613,random_70:38.1349,random_71:510.648,random_72:16.4375,random_73:15.1375,random_74:514.5138,random_75:11.4454,random_76:10.7881,random_77:10.9867,random_78:12.9331,random_79:8.9827,random_80:8.2858,random_81:45.3572,random_82:10.1446,random_83:514.5929,random_84:14.1979,random_85:513.7074,random_86:10.7155,random_87:9.7821,random_88:515.1848,random_89:14.5336,random_90:10.8987,random_91:12.6425,random_92:10.8329,random_93:20.9394,random_94:13.2106,random_95:509.0416,random_96:11.4657,random_97:10.5719,random_98:9.3322,random_99:12.6068'\n",
      "Testing (test) took 0:00:10.002001'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Tested (test) on 1221 instances with mean losses of: random_0:16.0508,random_1:39.8558,random_2:445.9146,random_3:8.1668,random_4:12.7511,random_5:6.4537,random_6:449.0653,random_7:449.5335,random_8:446.4224,random_9:6.6779,random_10:7.9544,random_11:7.1328,random_12:8.2522,random_13:7.4863,random_14:47.187,random_15:10.736,random_16:7.2277,random_17:7.5645,random_18:10.028,random_19:8.089,random_20:22.3351,random_21:35.4951,random_22:7.0507,random_23:8.4231,random_24:32.5394,random_25:42.9304,random_26:7.863,random_27:40.103,random_28:8.8968,random_29:8.3254,random_30:11.8153,random_31:7.318,random_32:452.5736,random_33:446.5214,random_34:7.9542,random_35:8.9894,random_36:8.2137,random_37:11.1442,random_38:10.3427,random_39:446.4063,random_40:7.2996,random_41:38.9261,random_42:8.3036,random_43:448.7172,random_44:7.3095,random_45:458.787,random_46:7.4382,random_47:9.5073,random_48:7.1138,random_49:13.0714,random_50:16.6307,random_51:14.6122,random_52:9.4075,random_53:9.0627,random_54:8.0276,random_55:7.9511,random_56:7.7649,random_57:7.8534,random_58:457.1386,random_59:33.256,random_60:16.4261,random_61:12.6357,random_62:453.2052,random_63:39.0081,random_64:10.1955,random_65:7.1525,random_66:8.1038,random_67:7.6916,random_68:8.6016,random_69:8.719,random_70:33.2713,random_71:447.2935,random_72:12.5494,random_73:8.2022,random_74:6.3785,random_75:8.8575,random_76:6.8401,random_77:6.5165,random_78:7.5824,random_79:7.7545,random_80:6.7168,random_81:12.7099,random_82:7.308,random_83:451.0706,random_84:7.4206,random_85:450.2103,random_86:7.7035,random_87:8.0835,random_88:41.0761,random_89:10.7128,random_90:8.8591,random_91:13.7554,random_92:8.4465,random_93:11.4699,random_94:6.8275,random_95:17.9772,random_96:7.5257,random_97:9.3649,random_98:22.0084,random_99:13.5555'\n",
      "Testing (test) took 0:00:10.075996'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Tested (test) on 1221 instances with mean losses of: random_0:28.7444,random_1:12.5004,random_2:556.2338,random_3:550.8917,random_4:35.0079,random_5:12.0813,random_6:559.5202,random_7:559.9679,random_8:556.8033,random_9:8.8892,random_10:9.8348,random_11:10.5858,random_12:14.2811,random_13:10.2951,random_14:17.3477,random_15:17.1782,random_16:9.9943,random_17:13.3424,random_18:13.8874,random_19:12.3874,random_20:20.2878,random_21:572.2249,random_22:13.0151,random_23:10.9444,random_24:24.794,random_25:565.3695,random_26:12.4882,random_27:47.3903,random_28:13.864,random_29:10.7054,random_30:15.1194,random_31:10.7188,random_32:563.1902,random_33:556.8462,random_34:14.6971,random_35:15.052,random_36:13.2959,random_37:15.994,random_38:11.6926,random_39:556.7505,random_40:12.8615,random_41:18.1813,random_42:15.7796,random_43:559.1137,random_44:10.9196,random_45:569.6291,random_46:11.6287,random_47:9.7948,random_48:13.1774,random_49:15.6292,random_50:14.3089,random_51:13.3869,random_52:12.2806,random_53:14.3363,random_54:14.5976,random_55:14.4229,random_56:13.2318,random_57:11.2911,random_58:567.8816,random_59:32.4687,random_60:15.1891,random_61:14.3519,random_62:563.7953,random_63:19.8602,random_64:13.0342,random_65:12.7536,random_66:14.6466,random_67:17.0075,random_68:11.7873,random_69:12.8758,random_70:13.3136,random_71:557.4834,random_72:16.1973,random_73:28.0107,random_74:8.6525,random_75:14.2313,random_76:21.9543,random_77:10.8331,random_78:13.6803,random_79:10.5972,random_80:8.608,random_81:15.4907,random_82:11.5718,random_83:561.5904,random_84:13.0796,random_85:560.6917,random_86:14.0712,random_87:12.9932,random_88:562.1514,random_89:21.5988,random_90:9.7963,random_91:29.611,random_92:11.0722,random_93:9.0952,random_94:12.448,random_95:18.9139,random_96:13.3982,random_97:13.7815,random_98:9.5958,random_99:18.8935'\n",
      "Testing (test) took 0:00:10.225998'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Tested (test) on 1221 instances with mean losses of: random_0:27.0847,random_1:24.1005,random_2:668.3282,random_3:27.1243,random_4:35.935,random_5:15.691,random_6:671.7107,random_7:672.1812,random_8:668.9159,random_9:669.9141,random_10:16.0334,random_11:27.3959,random_12:22.462,random_13:23.7874,random_14:45.541,random_15:32.9078,random_16:27.0674,random_17:33.4857,random_18:22.3382,random_19:22.0827,random_20:56.9269,random_21:684.6708,random_22:18.8626,random_23:39.6379,random_24:37.6067,random_25:20.5192,random_26:26.6134,random_27:19.3591,random_28:48.8473,random_29:27.8402,random_30:36.5822,random_31:31.7709,random_32:675.5403,random_33:668.6645,random_34:31.4237,random_35:24.5419,random_36:25.3631,random_37:33.0359,random_38:28.659,random_39:668.8236,random_40:32.2722,random_41:20.9325,random_42:38.318,random_43:671.2834,random_44:22.1972,random_45:682.2374,random_46:19.3294,random_47:20.1259,random_48:24.6905,random_49:28.2502,random_50:57.9322,random_51:30.2735,random_52:32.5728,random_53:24.6954,random_54:672.8607,random_55:26.3026,random_56:30.2381,random_57:21.273,random_58:680.3671,random_59:668.298,random_60:28.0302,random_61:27.8094,random_62:676.183,random_63:48.1153,random_64:27.403,random_65:26.7643,random_66:30.7113,random_67:18.714,random_68:34.4998,random_69:24.0634,random_70:25.1083,random_71:669.5646,random_72:30.6506,random_73:666.9692,random_74:15.1221,random_75:24.8435,random_76:23.7154,random_77:16.2861,random_78:31.8629,random_79:19.8661,random_80:15.8545,random_81:38.8735,random_82:17.8475,random_83:673.862,random_84:32.9104,random_85:672.9353,random_86:21.9162,random_87:25.8825,random_88:674.3817,random_89:247.5174,random_90:26.2309,random_91:32.993,random_92:30.8529,random_93:18.5399,random_94:30.205,random_95:667.5593,random_96:29.4602,random_97:32.2729,random_98:31.601,random_99:28.6695'\n",
      "Testing (test) took 0:00:10.031002'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Tested (test) on 1222 instances with mean losses of: random_0:18.2858,random_1:15.3046,random_2:564.2495,random_3:558.8751,random_4:16.0113,random_5:15.9893,random_6:567.5805,random_7:568.0457,random_8:564.7946,random_9:9.365,random_10:13.6578,random_11:11.4543,random_12:12.4308,random_13:14.752,random_14:44.8902,random_15:13.1488,random_16:15.0986,random_17:17.7622,random_18:13.614,random_19:13.2643,random_20:15.478,random_21:27.8257,random_22:11.4795,random_23:20.0402,random_24:25.2701,random_25:573.5144,random_26:15.2297,random_27:47.7062,random_28:13.3985,random_29:11.9748,random_30:16.9527,random_31:14.4388,random_32:571.2955,random_33:564.8735,random_34:10.6443,random_35:11.3812,random_36:15.1233,random_37:22.5311,random_38:12.6796,random_39:564.7417,random_40:13.3159,random_41:13.6647,random_42:16.828,random_43:567.1732,random_44:12.2218,random_45:577.8441,random_46:11.6994,random_47:8.9199,random_48:12.253,random_49:17.3233,random_50:15.5185,random_51:14.5308,random_52:15.9747,random_53:14.0455,random_54:10.5391,random_55:14.9586,random_56:12.7078,random_57:11.856,random_58:576.0702,random_59:564.4845,random_60:18.3817,random_61:14.574,random_62:571.942,random_63:81.698,random_64:14.2619,random_65:11.7227,random_66:14.6843,random_67:9.3723,random_68:12.8464,random_69:12.0322,random_70:11.9148,random_71:565.5699,random_72:16.3398,random_73:15.399,random_74:9.3301,random_75:13.2148,random_76:11.1923,random_77:10.4101,random_78:12.7599,random_79:13.619,random_80:10.6442,random_81:23.5142,random_82:14.8844,random_83:569.6737,random_84:17.1971,random_85:568.7631,random_86:12.8861,random_87:15.4594,random_88:41.6624,random_89:15.012,random_90:11.5569,random_91:15.3228,random_92:11.6987,random_93:11.2097,random_94:11.4755,random_95:24.066,random_96:14.3643,random_97:14.0343,random_98:12.8468,random_99:11.9809'\n",
      "Testing (test) took 0:00:10.016999'\n"
     ]
    }
   ],
   "source": [
    "deep_scheme = DeepScheme(configs, fixed_hyperparams=fixed_hyperparams,loss_eval=loss_target,device=device,tensorboard=tb,adaptive_lr=False,update=False)\n",
    "deep_scores, deep_preds, _ , _, _,_ = eval.evaluate(deep_models,dataset,deep_scheme,logger_name=\"log\",load_fun=load_fun_cv,load_fun_pp=load_fun_pp_cv)\n",
    "deep_scores_final, deep_preds_final, _ ,_, _,_ = eval.build(deep_models,dataset,deep_scheme,logger_name=\"test_log\",load_fun=load_fun_build,load_fun_pp=load_fun_pp_build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "for k,v in ut.flip_dicts(deep_scores).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores.append({**dict1,**v})\n",
    "\n",
    "all_scores_final = []\n",
    "for k,v in ut.flip_dicts(deep_scores_final).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores_final.append({**dict1,**v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - random_80 - deep - 9.35667500285197 - 8.285823323722752 - 6.716800460456142 - 8.608006351995819 - 15.8545239938272 - 9.764056871816873 - 0.9585970043533256\n",
      "1 - random_5 - deep - 8.363282239573676 - 11.932893898990462 - 6.45366010267553 - 12.08134427146771 - 15.690954698879732 - 10.904179259704094 - 0.9537624890609554\n",
      "2 - random_77 - deep - 10.129997791908377 - 10.986665495093638 - 6.516540925684374 - 10.833087069006067 - 16.286100628139735 - 10.95034995834599 - 0.9535667092473011\n",
      "3 - random_10 - deep - 10.33067052610182 - 11.382877679191127 - 7.954366040366483 - 9.834830644577863 - 16.03341594980351 - 11.107150273958244 - 0.9529018213969005\n",
      "4 - random_82 - deep - 9.545721391218969 - 10.144600848714576 - 7.3080058531327685 - 11.571789434168986 - 17.847468303521083 - 11.283046063033243 - 0.9521559621004065\n",
      "5 - random_79 - deep - 10.980880799738358 - 8.982656263485673 - 7.754505259008509 - 10.597175655942975 - 19.866092637364343 - 11.635720435904203 - 0.9506605001508949\n",
      "6 - random_44 - deep - 9.52298825384162 - 8.898159126993482 - 7.309500273283537 - 10.91958726848568 - 22.1971662101152 - 11.7686421942461 - 0.9500968656847886\n",
      "7 - random_47 - deep - 8.907901188745827 - 13.110862716325176 - 9.507269719504217 - 9.794840686151378 - 20.125946021099544 - 12.28894504136583 - 0.9478906007278085\n",
      "8 - random_57 - deep - 11.417966859820627 - 10.93752107799736 - 7.853435932662427 - 11.291140320845845 - 21.273006048678962 - 12.554163113164224 - 0.9467659838993482\n",
      "9 - random_29 - deep - 9.552723580998796 - 8.929788728392456 - 8.325419445490857 - 10.705373998551364 - 27.84022232511803 - 13.069451673932274 - 0.9445809812597342\n",
      "10 - random_87 - deep - 9.875811473827705 - 9.782050730553859 - 8.083531816312274 - 12.99321495090519 - 25.88254552586561 - 13.322286563830856 - 0.9435088734275878\n",
      "11 - random_36 - deep - 11.889654159545898 - 8.147820039778802 - 8.213650376166017 - 13.295923132275481 - 25.363136249326665 - 13.380935344917832 - 0.9432601822063152\n",
      "12 - random_67 - deep - 14.454988715301363 - 9.244372554379478 - 7.691564077241415 - 17.007515916660317 - 18.7140467438319 - 13.421982786027003 - 0.9430861267857189\n",
      "13 - random_26 - deep - 11.434023209367368 - 9.70428475693673 - 7.863040157071301 - 12.488153873556076 - 26.613444107268112 - 13.619589872117398 - 0.9422482040418677\n",
      "14 - random_11 - deep - 11.001792139780697 - 12.530085692429113 - 7.132792166663817 - 10.585779569853925 - 27.395862474683657 - 13.728619616867492 - 0.9417858800195368\n",
      "15 - random_13 - deep - 16.136629760167796 - 11.44541146478169 - 7.486267835756094 - 10.295060170663369 - 23.78743164115612 - 13.830147224221394 - 0.9413553676679113\n",
      "16 - random_75 - deep - 9.853691032397181 - 11.445362464105633 - 8.857515161687678 - 14.231261677082008 - 24.843453543973105 - 13.845209825905277 - 0.9412914970002029\n",
      "17 - random_16 - deep - 15.536192911151193 - 9.59987766691979 - 7.227671823181352 - 9.994330274970878 - 27.06740295916283 - 13.884663785670856 - 0.9411241984944831\n",
      "18 - random_93 - deep - 9.857819746051794 - 20.939418599180232 - 11.469891884793618 - 9.095197556157467 - 18.539932850049617 - 13.98091660610008 - 0.9407160530732173\n",
      "19 - random_86 - deep - 16.718913182884503 - 10.715471840529123 - 7.703454439411585 - 14.071203446212506 - 21.91623016891667 - 14.224888249551285 - 0.9396815284873478\n",
      "20 - random_65 - deep - 14.649402707376183 - 10.49988449341732 - 7.15253514173478 - 12.753595994399474 - 26.76430199597333 - 14.363358477775192 - 0.9390943665799959\n",
      "21 - random_12 - deep - 11.468095334579044 - 15.36842699487939 - 8.252218548730198 - 14.28105270657551 - 22.461967538557122 - 14.366041573888802 - 0.9390829893196859\n",
      "22 - random_69 - deep - 11.636907154526531 - 14.561334305621209 - 8.718981585865818 - 12.875821527645883 - 24.06340261954543 - 14.370872671754105 - 0.9390625037851882\n",
      "23 - random_31 - deep - 11.679184419628836 - 10.76052265003348 - 7.318017936162925 - 10.718760060834455 - 31.770921804785825 - 14.44842343065235 - 0.938733661606654\n",
      "24 - random_18 - deep - 14.40680645725731 - 11.591185887784693 - 10.027969419712125 - 13.88743562096948 - 22.338173798319747 - 14.449839021241074 - 0.9387276590104225\n",
      "25 - random_76 - deep - 10.462007857383565 - 10.78806992794605 - 6.840141374492723 - 21.95431542689443 - 23.71539915711249 - 14.75063508791374 - 0.937452179114875\n",
      "26 - random_48 - deep - 15.079861428655697 - 13.893923826186434 - 7.113819763174221 - 13.177420286933092 - 24.69054599124618 - 14.791014710955526 - 0.9372809554750539\n",
      "27 - random_56 - deep - 10.931306915470504 - 12.732127769879156 - 7.764929458218261 - 13.231821710803683 - 30.238090083210512 - 14.978624154431387 - 0.9364854262116052\n",
      "28 - random_92 - deep - 13.921040107302503 - 10.83285432556452 - 8.446470366844283 - 11.072180727092483 - 30.852914202515947 - 15.02422504349736 - 0.9362920625886493\n",
      "29 - random_38 - deep - 11.529250602285133 - 12.932572183749485 - 10.342650770457624 - 11.69257495268557 - 28.658987877117035 - 15.03029024646719 - 0.9362663440194672\n",
      "30 - random_55 - deep - 13.800012263065469 - 12.902726078969952 - 7.951137500547367 - 14.422855849933859 - 26.30258644300831 - 15.075298715301956 - 0.9360754924642485\n",
      "31 - random_35 - deep - 12.649850740760517 - 15.203695824805726 - 8.989437774983124 - 15.051950790958264 - 24.541922770397864 - 15.286926026637543 - 0.935178119091175\n",
      "32 - random_94 - deep - 15.338658040947298 - 13.21058543848328 - 6.827452146450483 - 12.447995132349437 - 30.204974585337094 - 15.605497025587841 - 0.9338272673032498\n",
      "33 - random_64 - deep - 15.741566656459177 - 11.674125251520286 - 10.195453817194158 - 13.034237646060728 - 27.40299413010881 - 15.609052508285721 - 0.9338121908205342\n",
      "34 - random_84 - deep - 11.192078306319866 - 14.197927281431207 - 7.420606145304212 - 13.079616214094544 - 32.91040286111792 - 15.759122479227138 - 0.933175841971367\n",
      "35 - random_96 - deep - 16.968235543433657 - 11.465680585945492 - 7.5256727001493235 - 13.398236512161493 - 29.46022990646175 - 15.763104175069634 - 0.9331589581967437\n",
      "36 - random_40 - deep - 15.159725609075418 - 11.292915824977543 - 7.299582702424271 - 12.861496915395488 - 32.27218217951269 - 15.77634520698399 - 0.9331028116181336\n",
      "37 - random_46 - deep - 10.208048437308953 - 32.61233824715872 - 7.438219751518931 - 11.628706392160113 - 19.329425896122064 - 16.245039982247764 - 0.931115382827558\n",
      "38 - random_66 - deep - 14.171684880108373 - 13.754087944467797 - 8.103796359069225 - 14.646562896333299 - 30.711338444677754 - 16.27673621484644 - 0.9309809797820282\n",
      "39 - random_19 - deep - 9.615690685528195 - 29.70321013455305 - 8.08904249642737 - 12.387385853287824 - 22.08273310352797 - 16.376687857173916 - 0.9305571500700047\n",
      "40 - random_51 - deep - 10.570224875123918 - 13.058366315064376 - 14.61215201837913 - 13.386902080414043 - 30.273465335417928 - 16.378726945899267 - 0.9305485036249126\n",
      "41 - random_17 - deep - 16.50222815936599 - 11.200119385352501 - 7.5645210951884 - 13.342448192771393 - 33.48573398980618 - 16.418169374779023 - 0.9303812540141574\n",
      "42 - random_49 - deep - 10.377915966530283 - 14.778031381959806 - 13.071431190434486 - 15.62921530452544 - 28.2502326262378 - 16.420106418826823 - 0.9303730402739743\n",
      "43 - random_34 - deep - 19.181682446194163 - 9.163497075316558 - 7.954170517605118 - 14.69710676812618 - 31.423702619585416 - 16.48327483449336 - 0.9301051842308169\n",
      "44 - random_61 - deep - 14.130083480560252 - 13.644701883562654 - 12.635681103136967 - 14.351879069494673 - 27.809366158244064 - 16.51348205886225 - 0.9299770950978404\n",
      "45 - random_37 - deep - 9.944884663127644 - 12.540853509731262 - 11.144245150829319 - 15.993997383273888 - 33.0358691422496 - 16.530238588463614 - 0.9299060415868617\n",
      "46 - random_60 - deep - 9.733871631653532 - 13.458541759297422 - 16.426127278345906 - 15.189095729887242 - 28.030186258701885 - 16.565936550907917 - 0.9297546698155703\n",
      "47 - random_78 - deep - 16.90639553132502 - 12.933087179196447 - 7.582394868599207 - 13.68034257056965 - 31.8628598774778 - 16.592468255971145 - 0.9296421661622577\n",
      "48 - random_99 - deep - 9.349355251231092 - 12.606784400690207 - 13.555476473746586 - 18.89352816699666 - 28.669504833455754 - 16.61308361834116 - 0.9295547498588026\n",
      "49 - random_98 - deep - 10.626133879741163 - 9.332177869231728 - 22.008431144858072 - 9.59582238837796 - 31.6009893425169 - 16.630531878324437 - 0.929480763170522\n",
      "50 - random_15 - deep - 9.947233520045803 - 15.114234921194722 - 10.735981396824293 - 17.178219596252003 - 32.90775129738448 - 17.17516220526167 - 0.9271713412415781\n",
      "51 - random_72 - deep - 11.249637002835687 - 16.437458047695127 - 12.549408613512695 - 16.197317018653408 - 30.65058709753038 - 17.415711110303977 - 0.9261513302564899\n",
      "52 - random_68 - deep - 20.12994358387399 - 12.265366342375986 - 8.601593823632093 - 11.787320688061788 - 34.49983888293367 - 17.456400223776413 - 0.9259787942696472\n",
      "53 - random_52 - deep - 18.436032955463116 - 15.08344180143016 - 9.407539641046798 - 12.280595329528358 - 32.57277027336327 - 17.55581580292709 - 0.9255572376518577\n",
      "54 - random_23 - deep - 19.26891012550766 - 10.034756993701142 - 8.42310145133641 - 10.944351558700925 - 39.637948869975446 - 17.660828044028896 - 0.9251119492416955\n",
      "55 - random_42 - deep - 13.315588565582924 - 14.770604459821886 - 8.303626344791697 - 15.779567514649187 - 38.31796463037689 - 18.096141933776416 - 0.9232660670106961\n",
      "56 - random_97 - deep - 24.538915904180897 - 10.571947153188203 - 9.364918678339928 - 13.781495291907508 - 32.27294563134121 - 18.10586462052603 - 0.9232248394387501\n",
      "57 - random_53 - deep - 25.151440440925562 - 20.597928710537925 - 9.062706146740112 - 14.336263321541452 - 24.695426687854514 - 18.770097822241674 - 0.9204082597403678\n",
      "58 - random_1 - deep - 10.42079413971222 - 9.320572140173905 - 39.85576488110591 - 12.500365526631267 - 24.100519917618534 - 19.236535228776788 - 0.9184304029779844\n",
      "59 - random_0 - deep - 12.351709666306766 - 21.065932760847375 - 16.050840541830226 - 28.744383124227312 - 27.084733941143014 - 21.05809527544463 - 0.9107063551080838\n",
      "60 - random_4 - deep - 12.300096499354087 - 14.373173228262294 - 12.751088063507956 - 35.00793709313645 - 35.93496138457877 - 22.07058987808808 - 0.9064130259954147\n",
      "61 - random_28 - deep - 16.370855161289146 - 22.897015462335315 - 8.896804178473795 - 13.86403295273277 - 48.84732393394427 - 22.174374068820768 - 0.9059729449457538\n",
      "62 - random_50 - deep - 13.424381921022107 - 13.730584115716713 - 16.630698773433302 - 14.308945983086913 - 57.93223357766891 - 23.202214949254945 - 0.9016145422800622\n",
      "63 - random_91 - deep - 32.90436477473832 - 12.642543864523331 - 13.755440533112347 - 29.610969808626916 - 32.99302929605645 - 24.38074310216457 - 0.896617173192092\n",
      "64 - random_70 - deep - 13.014082232785888 - 38.13488360746793 - 33.271337688799086 - 13.313619193046627 - 25.108273235917775 - 24.56876825570979 - 0.8958198811734263\n",
      "65 - random_41 - deep - 8.997948544310274 - 40.255459696493446 - 38.92610016931382 - 18.18127491901782 - 20.93248532035134 - 25.458381395447415 - 0.892047612183669\n",
      "66 - random_90 - deep - 72.12042071191067 - 10.898658430127583 - 8.859052091031462 - 9.79632442276757 - 26.230885725154142 - 25.586284466788534 - 0.8915052586952109\n",
      "67 - random_81 - deep - 15.7935793856357 - 45.35724001820466 - 12.70990668975555 - 15.490688867397136 - 38.87353833204015 - 25.64660506099066 - 0.8912494784051183\n",
      "68 - random_20 - deep - 15.035809351457512 - 15.923429989385527 - 22.335115399934736 - 20.28782128428554 - 56.926887680916 - 26.09833433864849 - 0.8893339892225094\n",
      "69 - random_24 - deep - 13.735732617042654 - 24.54719817072592 - 32.539442181099055 - 24.79397809671438 - 37.60670615687515 - 26.64215479493159 - 0.8870280014266936\n",
      "70 - random_30 - deep - 24.827889980934255 - 48.93192047768451 - 11.815314663911236 - 15.119366940272625 - 36.58216141209458 - 27.458416999856954 - 0.8835667659012617\n",
      "71 - random_22 - deep - 94.0411822011545 - 8.122244499318924 - 7.050653488884003 - 13.01507129520788 - 18.86260481685229 - 28.22583953881743 - 0.8803126275388099\n",
      "72 - random_27 - deep - 11.831145174959874 - 38.454081705471104 - 40.10302887462769 - 47.39033277809962 - 19.359050818684647 - 31.425469576897438 - 0.8667450838142366\n",
      "73 - random_89 - deep - 12.501188296147923 - 14.533573157658553 - 10.712831489381783 - 21.598839316184552 - 247.51741835135695 - 61.35709731769617 - 0.7398245763531232\n",
      "74 - random_74 - deep - 8.774464610360454 - 514.5137824575171 - 6.378507316551865 - 8.652528414269337 - 15.122101706427497 - 110.73771437453959 - 0.5304335926795358\n",
      "75 - random_3 - deep - 11.160089843987247 - 9.23615572222321 - 8.166752889447286 - 550.8917464147719 - 27.124250406519884 - 121.27940849209266 - 0.4857331447625003\n",
      "76 - random_63 - deep - 24.80448056359923 - 518.5152334160189 - 39.008080066177904 - 19.860228914984127 - 48.115320669638145 - 130.10704091698548 - 0.448300914322176\n",
      "77 - random_25 - deep - 12.034310921514484 - 45.659476448783316 - 42.93041640398055 - 565.3695050488722 - 20.51916150632791 - 137.26705495391565 - 0.41793996560046043\n",
      "78 - random_9 - deep - 8.970106681318018 - 8.43681700686191 - 6.677912561352579 - 8.889165362796268 - 669.9140729099682 - 140.53442711668472 - 0.40408517171640757\n",
      "79 - random_73 - deep - 11.779905051529505 - 15.137531865833239 - 8.202169985384554 - 28.01074727102931 - 666.9692107004577 - 145.97649932509938 - 0.381008893596373\n",
      "80 - random_54 - deep - 23.63588054363544 - 13.16677041841997 - 8.02760528639435 - 14.597599453070826 - 672.860661899526 - 146.4157667152887 - 0.37914624714905165\n",
      "81 - random_14 - deep - 108.90070903047602 - 520.6075016902043 - 47.18695702580133 - 17.34769628323267 - 45.540950147955265 - 147.9714012795998 - 0.3725498157743127\n",
      "82 - random_59 - deep - 86.37688812842735 - 41.78747891053045 - 33.256041636923904 - 32.46872290346488 - 668.2979835429023 - 172.40193733197336 - 0.26895584954681684\n",
      "83 - random_95 - deep - 15.493063097889802 - 509.0416056981063 - 17.9772229206357 - 18.91385168017763 - 667.5593415681307 - 245.80241153980515 - -0.042287679038367276\n",
      "84 - random_21 - deep - 38.39181450658071 - 525.223448308517 - 35.49507341064653 - 572.2249045532127 - 684.6707978119721 - 371.1719298180405 - -0.5738980217107754\n",
      "85 - random_88 - deep - 610.0345145817084 - 515.1847636071437 - 41.07610371657613 - 562.1513830086523 - 674.3816928972874 - 480.59256096991146 - -1.0378795382783133\n",
      "86 - random_33 - deep - 599.2790810542879 - 509.8001558144627 - 446.52143603675586 - 556.8461625382707 - 668.6645477944763 - 556.2217234299386 - -1.358573479864448\n",
      "87 - random_2 - deep - 603.885742936704 - 509.31309107204504 - 445.91457600011677 - 556.233758437448 - 668.328187997179 - 556.7350240618762 - -1.3607500529947099\n",
      "88 - random_39 - deep - 604.3833718557405 - 509.8178211468136 - 446.40633872842125 - 556.7504983538004 - 668.8236327175231 - 557.2362895805823 - -1.362875593060819\n",
      "89 - random_8 - deep - 604.4301979077428 - 509.8460132954749 - 446.4224228417649 - 556.8033151462564 - 668.915894679414 - 557.2835165602726 - -1.3630758518733388\n",
      "90 - random_71 - deep - 605.2509016920424 - 510.6479761900956 - 447.29350746898353 - 557.4834060231551 - 669.564556887265 - 558.0480402647704 - -1.3663176981698788\n",
      "91 - random_43 - deep - 606.8097021224651 - 512.16791380837 - 448.7172339437049 - 559.1137257044087 - 671.2834083750831 - 559.6183522771216 - -1.372976367026976\n",
      "92 - random_6 - deep - 607.3073171562532 - 512.5579690137198 - 449.0653329610239 - 559.5201507243438 - 671.7107109425988 - 560.0322601582429 - -1.374731480339523\n",
      "93 - random_7 - deep - 607.790277659015 - 513.0072701761649 - 449.5335260214716 - 559.9678828233973 - 672.1811779375256 - 560.4959919579811 - -1.3766978643884733\n",
      "94 - random_85 - deep - 608.5262012138304 - 513.7074003578598 - 450.2103412450092 - 560.6917255473469 - 672.935266768122 - 561.2141561590064 - -1.379743130273238\n",
      "95 - random_83 - deep - 609.4607305698426 - 514.5929121900892 - 451.0706498679521 - 561.5904272330969 - 673.8619531729884 - 562.115301770133 - -1.3835643009509906\n",
      "96 - random_32 - deep - 611.1023203448656 - 516.1392868216807 - 452.5736128223616 - 563.1901695757592 - 675.540324280635 - 563.7091190346403 - -1.3903226402489168\n",
      "97 - random_62 - deep - 611.8407029871464 - 516.8064551220783 - 453.2051820497255 - 563.7953229774519 - 676.1829888221184 - 564.3661128033094 - -1.393108522234367\n",
      "98 - random_58 - deep - 616.0417689746413 - 520.7895382945159 - 457.1386498803491 - 567.8816313247618 - 680.3670535200839 - 568.4437106396988 - -1.4103989546524955\n",
      "99 - random_45 - deep - 617.8651608531096 - 516.3615196215541 - 458.78701054903445 - 569.6291013275571 - 682.2373902666872 - 568.9754325448326 - -1.412653640385333\n"
     ]
    }
   ],
   "source": [
    "scores_df_sorted = pd.DataFrame(all_scores).sort_values(by='MSE')\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - random_47 - deep - 8.919891087940544 - 0.9624491752872761\n",
      "1 - random_74 - deep - 9.330148315122123 - 0.9607220805197345\n",
      "2 - random_9 - deep - 9.365010362338474 - 0.96057531879235\n",
      "3 - random_67 - deep - 9.372335621272377 - 0.9605444810263403\n",
      "4 - random_77 - deep - 10.410104090572132 - 0.9561756987734098\n",
      "5 - random_54 - deep - 10.539051099389242 - 0.9556328595753093\n",
      "6 - random_80 - deep - 10.644197250402254 - 0.9551902168740721\n",
      "7 - random_34 - deep - 10.644277164193543 - 0.9551898804541833\n",
      "8 - random_76 - deep - 11.192283060293786 - 0.9528828933908748\n",
      "9 - random_93 - deep - 11.209716252752152 - 0.9528095033967893\n",
      "10 - random_35 - deep - 11.381222868815062 - 0.952087497397685\n",
      "11 - random_11 - deep - 11.45432152691222 - 0.9517797677550379\n",
      "12 - random_94 - deep - 11.475549558651355 - 0.9516904023030416\n",
      "13 - random_22 - deep - 11.479450694018842 - 0.9516739793614473\n",
      "14 - random_90 - deep - 11.556877536235833 - 0.9513480289937257\n",
      "15 - random_92 - deep - 11.698672771713959 - 0.9507511015222976\n",
      "16 - random_46 - deep - 11.699411074214877 - 0.9507479934274202\n",
      "17 - random_65 - deep - 11.72270542205018 - 0.9506499292286832\n",
      "18 - random_57 - deep - 11.855992150852744 - 0.9500888207419929\n",
      "19 - random_70 - deep - 11.914767043629078 - 0.9498413910733574\n",
      "20 - random_29 - deep - 11.974758525688715 - 0.9495888398252683\n",
      "21 - random_99 - deep - 11.980928999704734 - 0.9495628634556148\n",
      "22 - random_69 - deep - 12.032244609668727 - 0.9493468357647173\n",
      "23 - random_44 - deep - 12.221778662509552 - 0.9485489381306375\n",
      "24 - random_48 - deep - 12.252952140302533 - 0.9484177044879002\n",
      "25 - random_12 - deep - 12.4307895743834 - 0.9476690471053498\n",
      "26 - random_38 - deep - 12.67964024039086 - 0.9466214392762\n",
      "27 - random_56 - deep - 12.707791979695429 - 0.946502926503167\n",
      "28 - random_78 - deep - 12.759905873240264 - 0.9462835382099348\n",
      "29 - random_68 - deep - 12.846443527830138 - 0.9459192332799176\n",
      "30 - random_98 - deep - 12.846837635551434 - 0.9459175741710995\n",
      "31 - random_86 - deep - 12.886116321455667 - 0.9457522193439166\n",
      "32 - random_15 - deep - 13.14880941295322 - 0.944646337878009\n",
      "33 - random_75 - deep - 13.214845911391734 - 0.9443683384099595\n",
      "34 - random_19 - deep - 13.26432621524267 - 0.9441600369634149\n",
      "35 - random_40 - deep - 13.31593925312266 - 0.9439427571649044\n",
      "36 - random_28 - deep - 13.398498398857365 - 0.943595200902238\n",
      "37 - random_18 - deep - 13.613996618646041 - 0.9426879997046663\n",
      "38 - random_79 - deep - 13.618987223178559 - 0.9426669903319999\n",
      "39 - random_10 - deep - 13.657757048032929 - 0.9425037777004893\n",
      "40 - random_41 - deep - 13.66473035464276 - 0.942474421578134\n",
      "41 - random_97 - deep - 14.034276809509624 - 0.9409187104138268\n",
      "42 - random_53 - deep - 14.045500791084745 - 0.9408714598632818\n",
      "43 - random_64 - deep - 14.261918079467403 - 0.9399603895844253\n",
      "44 - random_96 - deep - 14.364270466293332 - 0.9395295080300725\n",
      "45 - random_31 - deep - 14.438795708690698 - 0.9392157727740759\n",
      "46 - random_51 - deep - 14.530783810029632 - 0.9388285226344745\n",
      "47 - random_61 - deep - 14.573957845826941 - 0.9386467692213013\n",
      "48 - random_66 - deep - 14.684299720726186 - 0.938182253638996\n",
      "49 - random_13 - deep - 14.751956585088491 - 0.9378974327786027\n",
      "50 - random_82 - deep - 14.88444148715171 - 0.937339699810183\n",
      "51 - random_55 - deep - 14.958608742531089 - 0.9370274716026054\n",
      "52 - random_89 - deep - 15.012017687319478 - 0.9368026314219273\n",
      "53 - random_16 - deep - 15.098621903153362 - 0.9364380462833759\n",
      "54 - random_36 - deep - 15.12331817672224 - 0.9363340802785559\n",
      "55 - random_26 - deep - 15.229659065169454 - 0.9358864079894542\n",
      "56 - random_1 - deep - 15.304631965043257 - 0.9355707881916775\n",
      "57 - random_91 - deep - 15.322766305298963 - 0.9354944465160326\n",
      "58 - random_73 - deep - 15.399049761121377 - 0.9351733095593335\n",
      "59 - random_87 - deep - 15.459350831885951 - 0.9349194550093233\n",
      "60 - random_20 - deep - 15.478028052851986 - 0.9348408279225459\n",
      "61 - random_50 - deep - 15.518470578524354 - 0.9346705735800331\n",
      "62 - random_52 - deep - 15.974750024322141 - 0.9327497351616879\n",
      "63 - random_5 - deep - 15.98929776867421 - 0.932688492284085\n",
      "64 - random_4 - deep - 16.011334207479056 - 0.932595723612058\n",
      "65 - random_72 - deep - 16.339825005934628 - 0.9312128479389206\n",
      "66 - random_42 - deep - 16.828038221863622 - 0.929157575210471\n",
      "67 - random_30 - deep - 16.952672978725477 - 0.9286328896664557\n",
      "68 - random_84 - deep - 17.197131451434867 - 0.9276037720272661\n",
      "69 - random_49 - deep - 17.323268007429913 - 0.9270727642316171\n",
      "70 - random_17 - deep - 17.762154783799485 - 0.9252251452141083\n",
      "71 - random_0 - deep - 18.285768013415662 - 0.9230208460350339\n",
      "72 - random_60 - deep - 18.381726048242175 - 0.9226168833285363\n",
      "73 - random_23 - deep - 20.040208122053112 - 0.9156350301838195\n",
      "74 - random_37 - deep - 22.531130447401214 - 0.9051487824606141\n",
      "75 - random_81 - deep - 23.514165945669998 - 0.901010414254327\n",
      "76 - random_95 - deep - 24.065972608751725 - 0.8986874267787615\n",
      "77 - random_24 - deep - 25.270077596524683 - 0.8936184035265933\n",
      "78 - random_21 - deep - 27.825660718149788 - 0.8828599477458179\n",
      "79 - random_88 - deep - 41.66239446381989 - 0.8246102720089977\n",
      "80 - random_14 - deep - 44.890167361308094 - 0.811022041716598\n",
      "81 - random_27 - deep - 47.70616246092445 - 0.7991673074675952\n",
      "82 - random_63 - deep - 81.69801260478886 - 0.6560689227643204\n",
      "83 - random_3 - deep - 558.8751375632 - -1.3527442342102098\n",
      "84 - random_2 - deep - 564.2494830442619 - -1.3753690738091842\n",
      "85 - random_59 - deep - 564.4844619474037 - -1.3763582844975293\n",
      "86 - random_39 - deep - 564.7416758833091 - -1.3774410998957922\n",
      "87 - random_8 - deep - 564.7945931975814 - -1.377663870417643\n",
      "88 - random_33 - deep - 564.8735081467712 - -1.377996085395945\n",
      "89 - random_71 - deep - 565.5699345408448 - -1.3809278908621043\n",
      "90 - random_43 - deep - 567.1732089573608 - -1.3876773316330104\n",
      "91 - random_6 - deep - 567.5805415307693 - -1.3893921142366374\n",
      "92 - random_7 - deep - 568.0456626906858 - -1.3913501743714543\n",
      "93 - random_85 - deep - 568.7630478060235 - -1.3943702115503815\n",
      "94 - random_83 - deep - 569.673716456463 - -1.3982039308779926\n",
      "95 - random_32 - deep - 571.2955347342802 - -1.4050314373201442\n",
      "96 - random_62 - deep - 571.9420005199768 - -1.4077529193609157\n",
      "97 - random_25 - deep - 573.5143697291247 - -1.4143722558499254\n",
      "98 - random_58 - deep - 576.0701980803275 - -1.4251317439945264\n",
      "99 - random_45 - deep - 577.8440855923603 - -1.4325994292350432\n"
     ]
    }
   ],
   "source": [
    "scores_df_sorted_final = pd.DataFrame(all_scores_final).sort_values(by='MSE')\n",
    "\n",
    "for i,(index,row) in enumerate(scores_df_sorted_final.iterrows()):\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% lwr part\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2320eb619a1f4d17a0e7991116f3f83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_0'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.5466,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0045,lwr_k=40:0.0993,lwr_k=50:0.6652,lwr_k=100:3.4246,lwr_k=200:5.0124,lwr_k=300:5.5289,lwr_k=400:5.7965,lwr_k=500:6.0979,lwr_k=600:6.27,lwr_k=700:6.4826,lwr_k=800:6.64,lwr_k=900:6.7334,lwr_k=1000:6.8203'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:12.1349,lwr_k=10:28.6436,lwr_k=20:82.2975,lwr_k=30:821.9476,lwr_k=40:430.3186,lwr_k=50:214.9094,lwr_k=100:31.6357,lwr_k=200:11.0418,lwr_k=300:10.525,lwr_k=400:10.3349,lwr_k=500:10.1522,lwr_k=600:10.2411,lwr_k=700:10.017,lwr_k=800:10.0641,lwr_k=900:10.0018,lwr_k=1000:10.1132'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:26.8615,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0354,lwr_k=40:0.2322,lwr_k=50:1.0036,lwr_k=100:5.4825,lwr_k=200:9.4912,lwr_k=300:11.2929,lwr_k=400:12.3237,lwr_k=500:12.9424,lwr_k=600:13.5536,lwr_k=700:14.127,lwr_k=800:14.8097,lwr_k=900:15.2167,lwr_k=1000:15.9184'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:18.1802,lwr_k=10:29.617,lwr_k=20:132.6816,lwr_k=30:202.586,lwr_k=40:2275.3901,lwr_k=50:693.7789,lwr_k=100:44.6778,lwr_k=200:15.5787,lwr_k=300:10.5293,lwr_k=400:10.0342,lwr_k=500:9.6604,lwr_k=600:9.7451,lwr_k=700:9.7926,lwr_k=800:10.0157,lwr_k=900:10.0841,lwr_k=1000:10.2927'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:21.9808,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0431,lwr_k=40:0.1697,lwr_k=50:1.125,lwr_k=100:5.1692,lwr_k=200:8.6932,lwr_k=300:10.1943,lwr_k=400:11.1318,lwr_k=500:11.8696,lwr_k=600:12.5293,lwr_k=700:12.9979,lwr_k=800:13.5023,lwr_k=900:13.8243,lwr_k=1000:14.1053'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:14.8949,lwr_k=10:30.021,lwr_k=20:95.1993,lwr_k=30:160.4342,lwr_k=40:447.4709,lwr_k=50:215.6169,lwr_k=100:83.4038,lwr_k=200:33.065,lwr_k=300:10.2856,lwr_k=400:9.785,lwr_k=500:9.6446,lwr_k=600:9.4701,lwr_k=700:9.4007,lwr_k=800:9.3266,lwr_k=900:9.5442,lwr_k=1000:9.5547'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:27.7862,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0237,lwr_k=40:0.2396,lwr_k=50:1.2286,lwr_k=100:6.463,lwr_k=200:10.0542,lwr_k=300:11.5044,lwr_k=400:12.2523,lwr_k=500:12.9321,lwr_k=600:13.7781,lwr_k=700:14.2913,lwr_k=800:14.8207,lwr_k=900:15.3101,lwr_k=1000:15.6208'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:22.2022,lwr_k=10:43.4174,lwr_k=20:130.0661,lwr_k=30:214.0463,lwr_k=40:764.7403,lwr_k=50:253.7179,lwr_k=100:22.7992,lwr_k=200:12.1094,lwr_k=300:11.5586,lwr_k=400:11.5471,lwr_k=500:11.3917,lwr_k=600:11.5303,lwr_k=700:11.6772,lwr_k=800:11.991,lwr_k=900:12.2148,lwr_k=1000:12.2942'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.5874,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0083,lwr_k=40:0.1203,lwr_k=50:0.7213,lwr_k=100:2.9054,lwr_k=200:4.1782,lwr_k=300:4.7014,lwr_k=400:4.9188,lwr_k=500:5.0873,lwr_k=600:5.2205,lwr_k=700:5.3145,lwr_k=800:5.3907,lwr_k=900:5.4704,lwr_k=1000:5.5654'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:26.1711,lwr_k=10:29.8931,lwr_k=20:94.4627,lwr_k=30:294.8757,lwr_k=40:208.106,lwr_k=50:2209.9291,lwr_k=100:212.1618,lwr_k=200:33.3781,lwr_k=300:22.8861,lwr_k=400:22.232,lwr_k=500:28.2588,lwr_k=600:22.3727,lwr_k=700:22.5407,lwr_k=800:22.6195,lwr_k=900:22.8588,lwr_k=1000:23.231'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:17.0477,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0106,lwr_k=40:0.1834,lwr_k=50:0.9972,lwr_k=100:4.5373,lwr_k=200:7.1362,lwr_k=300:8.388,lwr_k=400:9.1285,lwr_k=500:9.5863,lwr_k=600:9.9733,lwr_k=700:10.3004,lwr_k=800:10.5841,lwr_k=900:10.9373,lwr_k=1000:11.1967'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:16.9309,lwr_k=10:33.3712,lwr_k=20:121.8174,lwr_k=30:248.3298,lwr_k=40:795.5212,lwr_k=50:499.6831,lwr_k=100:18.7997,lwr_k=200:13.8244,lwr_k=300:13.432,lwr_k=400:13.7189,lwr_k=500:13.8519,lwr_k=600:14.2703,lwr_k=700:13.8745,lwr_k=800:13.9632,lwr_k=900:14.3823,lwr_k=1000:14.4203'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_1'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.2834,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.5239,lwr_k=40:1.1526,lwr_k=50:1.5352,lwr_k=100:2.434,lwr_k=200:2.8117,lwr_k=300:3.0473,lwr_k=400:3.1741,lwr_k=500:3.2596,lwr_k=600:3.3196,lwr_k=700:3.3782,lwr_k=800:3.4372,lwr_k=900:3.4774,lwr_k=1000:3.5032'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.0898,lwr_k=10:49.3281,lwr_k=20:40.0128,lwr_k=30:121.4726,lwr_k=40:26.2092,lwr_k=50:14.2794,lwr_k=100:9.1943,lwr_k=200:8.3467,lwr_k=300:8.0147,lwr_k=400:7.944,lwr_k=500:8.042,lwr_k=600:8.0853,lwr_k=700:8.2009,lwr_k=800:8.1785,lwr_k=900:8.1806,lwr_k=1000:8.1802'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9705,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.4645,lwr_k=40:1.4695,lwr_k=50:2.1585,lwr_k=100:3.4061,lwr_k=200:4.2153,lwr_k=300:4.4146,lwr_k=400:4.6388,lwr_k=500:4.758,lwr_k=600:4.8542,lwr_k=700:4.923,lwr_k=800:5.0496,lwr_k=900:5.0979,lwr_k=1000:5.1226'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.6676,lwr_k=10:93.735,lwr_k=20:110.7102,lwr_k=30:1125.6642,lwr_k=40:89.7183,lwr_k=50:41.5904,lwr_k=100:8.7522,lwr_k=200:7.5882,lwr_k=300:7.0695,lwr_k=400:7.0603,lwr_k=500:6.9816,lwr_k=600:6.9218,lwr_k=700:6.9031,lwr_k=800:6.8695,lwr_k=900:6.9227,lwr_k=1000:6.929'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:45.0528,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:3.367,lwr_k=40:4.9755,lwr_k=50:6.9523,lwr_k=100:13.1743,lwr_k=200:17.5137,lwr_k=300:20.1976,lwr_k=400:21.5612,lwr_k=500:22.066,lwr_k=600:23.4499,lwr_k=700:24.1618,lwr_k=800:24.8153,lwr_k=900:26.0063,lwr_k=1000:26.748'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:32.5112,lwr_k=10:144.9847,lwr_k=20:119.4527,lwr_k=30:215.2455,lwr_k=40:53.2074,lwr_k=50:34.5612,lwr_k=100:22.9288,lwr_k=200:18.6042,lwr_k=300:17.7911,lwr_k=400:17.5148,lwr_k=500:17.279,lwr_k=600:17.5966,lwr_k=700:17.7425,lwr_k=800:17.7666,lwr_k=900:18.6652,lwr_k=1000:19.1044'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:14.1117,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.0772,lwr_k=40:2.6437,lwr_k=50:3.5382,lwr_k=100:6.617,lwr_k=200:9.2472,lwr_k=300:10.2579,lwr_k=400:10.6015,lwr_k=500:10.8615,lwr_k=600:11.1739,lwr_k=700:11.3846,lwr_k=800:11.5941,lwr_k=900:11.783,lwr_k=1000:11.8989'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:12.3176,lwr_k=10:267.4381,lwr_k=20:192.5119,lwr_k=30:440.091,lwr_k=40:42.9085,lwr_k=50:56.9096,lwr_k=100:12.7834,lwr_k=200:10.9839,lwr_k=300:11.9213,lwr_k=400:11.5132,lwr_k=500:11.054,lwr_k=600:12.1514,lwr_k=700:11.716,lwr_k=800:11.9187,lwr_k=900:10.6052,lwr_k=1000:10.7455'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.825,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.8464,lwr_k=40:1.6029,lwr_k=50:2.3154,lwr_k=100:3.6989,lwr_k=200:4.4716,lwr_k=300:4.809,lwr_k=400:5.0098,lwr_k=500:5.1074,lwr_k=600:5.1476,lwr_k=700:5.1967,lwr_k=800:5.2678,lwr_k=900:5.3096,lwr_k=1000:5.3291'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:24.9011,lwr_k=10:333.1684,lwr_k=20:70.6519,lwr_k=30:288.3707,lwr_k=40:37.7418,lwr_k=50:33.6719,lwr_k=100:27.3526,lwr_k=200:26.5405,lwr_k=300:26.0195,lwr_k=400:25.578,lwr_k=500:25.5268,lwr_k=600:25.515,lwr_k=700:25.3623,lwr_k=800:25.5886,lwr_k=900:25.2798,lwr_k=1000:25.2495'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:9.895,lwr_k=10:0.0,lwr_k=20:0.0003,lwr_k=30:0.8758,lwr_k=40:2.7171,lwr_k=50:3.1752,lwr_k=100:5.203,lwr_k=200:6.5958,lwr_k=300:7.1498,lwr_k=400:7.433,lwr_k=500:7.7463,lwr_k=600:7.927,lwr_k=700:8.0835,lwr_k=800:8.1784,lwr_k=900:8.2896,lwr_k=1000:8.3692'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:14.8192,lwr_k=10:35.0001,lwr_k=20:1013.5737,lwr_k=30:1000.5368,lwr_k=40:37.2551,lwr_k=50:22.9373,lwr_k=100:14.1976,lwr_k=200:12.2049,lwr_k=300:12.3667,lwr_k=400:12.5189,lwr_k=500:12.8156,lwr_k=600:12.7979,lwr_k=700:12.8294,lwr_k=800:13.1007,lwr_k=900:13.2061,lwr_k=1000:13.4372'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_2'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:77.4869,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:2.8646,lwr_k=40:5.5042,lwr_k=50:7.7433,lwr_k=100:13.1933,lwr_k=200:18.5769,lwr_k=300:22.3981,lwr_k=400:25.2391,lwr_k=500:28.0524,lwr_k=600:30.5104,lwr_k=700:32.6701,lwr_k=800:34.4941,lwr_k=900:36.2721,lwr_k=1000:37.8307'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:88.2221,lwr_k=10:57.865,lwr_k=20:165.2443,lwr_k=30:51.4878,lwr_k=40:32.4867,lwr_k=50:24.6083,lwr_k=100:23.6235,lwr_k=200:26.544,lwr_k=300:29.6663,lwr_k=400:32.0073,lwr_k=500:34.6492,lwr_k=600:36.9157,lwr_k=700:38.9506,lwr_k=800:40.448,lwr_k=900:41.956,lwr_k=1000:43.3745'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:99.0271,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:4.106,lwr_k=40:6.9401,lwr_k=50:8.4883,lwr_k=100:15.8597,lwr_k=200:23.5834,lwr_k=300:29.0239,lwr_k=400:32.9609,lwr_k=500:36.6272,lwr_k=600:40.5731,lwr_k=700:43.5594,lwr_k=800:46.1905,lwr_k=900:48.3967,lwr_k=1000:50.3'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:83.8969,lwr_k=10:47.9573,lwr_k=20:224.667,lwr_k=30:54.8676,lwr_k=40:36.2291,lwr_k=50:28.3394,lwr_k=100:22.2444,lwr_k=200:23.9067,lwr_k=300:26.0588,lwr_k=400:27.84,lwr_k=500:30.4691,lwr_k=600:32.2835,lwr_k=700:34.9668,lwr_k=800:37.3237,lwr_k=900:38.767,lwr_k=1000:41.3391'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:106.4007,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:4.2961,lwr_k=40:8.1656,lwr_k=50:9.6613,lwr_k=100:16.1183,lwr_k=200:23.9911,lwr_k=300:28.936,lwr_k=400:33.0597,lwr_k=500:36.5462,lwr_k=600:40.6973,lwr_k=700:44.1878,lwr_k=800:46.9898,lwr_k=900:49.4066,lwr_k=1000:51.4823'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:65.2332,lwr_k=10:53.0728,lwr_k=20:202.4447,lwr_k=30:50.5226,lwr_k=40:28.4655,lwr_k=50:22.8198,lwr_k=100:18.1208,lwr_k=200:19.6816,lwr_k=300:22.8026,lwr_k=400:24.3863,lwr_k=500:26.3854,lwr_k=600:28.4185,lwr_k=700:29.9413,lwr_k=800:31.1145,lwr_k=900:32.2548,lwr_k=1000:33.4445'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:104.6715,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:3.4484,lwr_k=40:7.1624,lwr_k=50:9.7163,lwr_k=100:17.457,lwr_k=200:25.2093,lwr_k=300:30.9302,lwr_k=400:35.0368,lwr_k=500:38.6597,lwr_k=600:42.5242,lwr_k=700:45.4246,lwr_k=800:47.6768,lwr_k=900:49.9275,lwr_k=1000:51.442'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:91.2813,lwr_k=10:57.9964,lwr_k=20:204.0256,lwr_k=30:58.3623,lwr_k=40:35.5811,lwr_k=50:28.5765,lwr_k=100:23.3628,lwr_k=200:24.4457,lwr_k=300:27.862,lwr_k=400:29.7672,lwr_k=500:31.7063,lwr_k=600:34.731,lwr_k=700:36.7986,lwr_k=800:39.2668,lwr_k=900:41.0025,lwr_k=1000:42.9265'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:76.5935,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:3.7762,lwr_k=40:6.3475,lwr_k=50:8.7681,lwr_k=100:13.5873,lwr_k=200:19.3616,lwr_k=300:23.0959,lwr_k=400:26.2927,lwr_k=500:28.8026,lwr_k=600:31.3253,lwr_k=700:33.1343,lwr_k=800:34.6952,lwr_k=900:36.1354,lwr_k=1000:37.5512'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:150.2473,lwr_k=10:82.596,lwr_k=20:206.0491,lwr_k=30:60.5377,lwr_k=40:51.4231,lwr_k=50:48.3863,lwr_k=100:48.3345,lwr_k=200:58.291,lwr_k=300:63.3475,lwr_k=400:67.2307,lwr_k=500:72.3535,lwr_k=600:77.29,lwr_k=700:80.3582,lwr_k=800:84.1338,lwr_k=900:86.4721,lwr_k=1000:88.4437'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:94.4186,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:3.3183,lwr_k=40:6.6844,lwr_k=50:8.6855,lwr_k=100:15.3262,lwr_k=200:21.3556,lwr_k=300:26.0035,lwr_k=400:29.5404,lwr_k=500:32.3202,lwr_k=600:34.963,lwr_k=700:37.6188,lwr_k=800:40.003,lwr_k=900:41.7852,lwr_k=1000:43.6725'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:86.239,lwr_k=10:59.3538,lwr_k=20:172.0966,lwr_k=30:60.4255,lwr_k=40:38.5834,lwr_k=50:36.2071,lwr_k=100:30.2495,lwr_k=200:31.1561,lwr_k=300:31.683,lwr_k=400:33.8886,lwr_k=500:34.3238,lwr_k=600:34.4744,lwr_k=700:36.3605,lwr_k=800:37.032,lwr_k=900:38.241,lwr_k=1000:37.8293'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_3'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.4291,lwr_k=10:0.3259,lwr_k=20:2.7476,lwr_k=30:3.6781,lwr_k=40:4.1788,lwr_k=50:4.602,lwr_k=100:5.2651,lwr_k=200:5.7431,lwr_k=300:5.9245,lwr_k=400:6.0182,lwr_k=500:6.0914,lwr_k=600:6.1162,lwr_k=700:6.1304,lwr_k=800:6.157,lwr_k=900:6.1884,lwr_k=1000:6.2034'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.1178,lwr_k=10:491.0014,lwr_k=20:12.8056,lwr_k=30:9.5123,lwr_k=40:9.4069,lwr_k=50:9.4391,lwr_k=100:8.9944,lwr_k=200:8.8107,lwr_k=300:8.7988,lwr_k=400:8.8294,lwr_k=500:8.8709,lwr_k=600:8.9198,lwr_k=700:8.9201,lwr_k=800:8.8997,lwr_k=900:8.9442,lwr_k=1000:8.9428'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.5876,lwr_k=10:0.5657,lwr_k=20:3.1146,lwr_k=30:4.2989,lwr_k=40:5.4591,lwr_k=50:5.9001,lwr_k=100:6.8891,lwr_k=200:7.594,lwr_k=300:7.8366,lwr_k=400:7.9219,lwr_k=500:8.0057,lwr_k=600:8.058,lwr_k=700:8.1144,lwr_k=800:8.1558,lwr_k=900:8.2269,lwr_k=1000:8.2375'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.4261,lwr_k=10:267.1727,lwr_k=20:39.0982,lwr_k=30:26.7674,lwr_k=40:15.0384,lwr_k=50:14.3038,lwr_k=100:6.4818,lwr_k=200:6.5864,lwr_k=300:6.6049,lwr_k=400:6.7525,lwr_k=500:6.8275,lwr_k=600:6.8616,lwr_k=700:6.8909,lwr_k=800:6.9612,lwr_k=900:6.9903,lwr_k=1000:7.103'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:12.3998,lwr_k=10:0.1797,lwr_k=20:3.6079,lwr_k=30:4.939,lwr_k=40:5.7617,lwr_k=50:6.4103,lwr_k=100:8.4847,lwr_k=200:10.1426,lwr_k=300:10.5591,lwr_k=400:10.8834,lwr_k=500:11.0045,lwr_k=600:11.1292,lwr_k=700:11.2468,lwr_k=800:11.3003,lwr_k=900:11.3385,lwr_k=1000:11.3872'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.1615,lwr_k=10:105389.732,lwr_k=20:15.3659,lwr_k=30:10.973,lwr_k=40:10.1374,lwr_k=50:9.358,lwr_k=100:7.7649,lwr_k=200:7.4428,lwr_k=300:7.5394,lwr_k=400:7.5284,lwr_k=500:7.4953,lwr_k=600:7.4615,lwr_k=700:7.4258,lwr_k=800:7.4046,lwr_k=900:7.381,lwr_k=1000:7.3946'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:132.9141,lwr_k=10:14.4277,lwr_k=20:31.4569,lwr_k=30:38.7508,lwr_k=40:44.0208,lwr_k=50:46.0211,lwr_k=100:53.7428,lwr_k=200:62.898,lwr_k=300:68.8425,lwr_k=400:73.0119,lwr_k=500:76.4781,lwr_k=600:79.2588,lwr_k=700:82.2973,lwr_k=800:85.3857,lwr_k=900:87.8016,lwr_k=1000:91.1497'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:140.339,lwr_k=10:446.5202,lwr_k=20:107.0984,lwr_k=30:119.6969,lwr_k=40:66.6335,lwr_k=50:67.3402,lwr_k=100:66.9572,lwr_k=200:83.7792,lwr_k=300:86.4999,lwr_k=400:88.6459,lwr_k=500:93.0717,lwr_k=600:96.4911,lwr_k=700:99.0722,lwr_k=800:101.2989,lwr_k=900:104.0606,lwr_k=1000:106.0113'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.7614,lwr_k=10:0.586,lwr_k=20:2.5919,lwr_k=30:3.098,lwr_k=40:3.3721,lwr_k=50:3.5533,lwr_k=100:3.8832,lwr_k=200:4.2103,lwr_k=300:4.365,lwr_k=400:4.4105,lwr_k=500:4.4672,lwr_k=600:4.4776,lwr_k=700:4.5065,lwr_k=800:4.5314,lwr_k=900:4.5468,lwr_k=1000:4.5608'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:18.2835,lwr_k=10:137.7403,lwr_k=20:25.0638,lwr_k=30:19.9087,lwr_k=40:19.4065,lwr_k=50:18.4247,lwr_k=100:17.8058,lwr_k=200:17.6279,lwr_k=300:17.6989,lwr_k=400:17.6704,lwr_k=500:17.7,lwr_k=600:17.6827,lwr_k=700:17.7531,lwr_k=800:17.8284,lwr_k=900:17.8746,lwr_k=1000:17.9083'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:121.39,lwr_k=10:14.4913,lwr_k=20:31.1795,lwr_k=30:37.585,lwr_k=40:41.2259,lwr_k=50:44.0358,lwr_k=100:50.4055,lwr_k=200:57.6053,lwr_k=300:61.9194,lwr_k=400:65.6034,lwr_k=500:68.3626,lwr_k=600:70.9107,lwr_k=700:73.3497,lwr_k=800:75.481,lwr_k=900:77.4,lwr_k=1000:79.2313'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:135.6246,lwr_k=10:490.0827,lwr_k=20:65.7541,lwr_k=30:60.4816,lwr_k=40:58.3072,lwr_k=50:55.8652,lwr_k=100:72.363,lwr_k=200:75.4318,lwr_k=300:77.6198,lwr_k=400:81.2115,lwr_k=500:81.5673,lwr_k=600:85.12,lwr_k=700:87.7333,lwr_k=800:90.182,lwr_k=900:92.3518,lwr_k=1000:95.2345'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_4'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.836,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.4501,lwr_k=40:1.6546,lwr_k=50:2.5021,lwr_k=100:4.4311,lwr_k=200:5.7494,lwr_k=300:6.2157,lwr_k=400:6.4147,lwr_k=500:6.6024,lwr_k=600:6.7334,lwr_k=700:6.853,lwr_k=800:6.95,lwr_k=900:7.0318,lwr_k=1000:7.0916'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:12.0988,lwr_k=10:37.3305,lwr_k=20:72.6575,lwr_k=30:180.0615,lwr_k=40:24.9449,lwr_k=50:15.8628,lwr_k=100:9.4488,lwr_k=200:9.4301,lwr_k=300:9.3113,lwr_k=400:9.2778,lwr_k=500:9.3111,lwr_k=600:9.45,lwr_k=700:9.6295,lwr_k=800:9.7318,lwr_k=900:9.8154,lwr_k=1000:9.8687'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:15.6553,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.4602,lwr_k=40:2.3334,lwr_k=50:3.6896,lwr_k=100:6.9061,lwr_k=200:9.2478,lwr_k=300:10.1029,lwr_k=400:10.6942,lwr_k=500:11.0722,lwr_k=600:11.331,lwr_k=700:11.5445,lwr_k=800:11.733,lwr_k=900:11.9732,lwr_k=1000:12.1403'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:14.6598,lwr_k=10:53.0209,lwr_k=20:105.3486,lwr_k=30:129.6308,lwr_k=40:27.2709,lwr_k=50:18.1907,lwr_k=100:11.0037,lwr_k=200:9.6706,lwr_k=300:9.763,lwr_k=400:10.0841,lwr_k=500:10.2477,lwr_k=600:10.4187,lwr_k=700:10.3627,lwr_k=800:10.6911,lwr_k=900:10.7977,lwr_k=1000:10.8581'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:17.5375,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.3943,lwr_k=40:2.3184,lwr_k=50:3.6957,lwr_k=100:6.8186,lwr_k=200:9.8323,lwr_k=300:10.7293,lwr_k=400:11.3936,lwr_k=500:11.9094,lwr_k=600:12.0956,lwr_k=700:12.3464,lwr_k=800:12.5223,lwr_k=900:12.7195,lwr_k=1000:12.8941'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:11.553,lwr_k=10:38.539,lwr_k=20:163.6043,lwr_k=30:277.1001,lwr_k=40:43.3878,lwr_k=50:18.0903,lwr_k=100:10.2629,lwr_k=200:8.3469,lwr_k=300:8.2156,lwr_k=400:8.0679,lwr_k=500:7.9489,lwr_k=600:7.8869,lwr_k=700:7.94,lwr_k=800:8.0698,lwr_k=900:8.0935,lwr_k=1000:8.0726'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:31.7382,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.6418,lwr_k=40:3.275,lwr_k=50:4.7571,lwr_k=100:8.8783,lwr_k=200:12.1445,lwr_k=300:13.7539,lwr_k=400:14.9413,lwr_k=500:16.5176,lwr_k=600:17.4667,lwr_k=700:18.4139,lwr_k=800:19.0531,lwr_k=900:19.6078,lwr_k=1000:20.3143'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:23.8527,lwr_k=10:78.8362,lwr_k=20:119.554,lwr_k=30:286.6255,lwr_k=40:47.1341,lwr_k=50:25.3579,lwr_k=100:13.599,lwr_k=200:14.4243,lwr_k=300:13.6074,lwr_k=400:13.9086,lwr_k=500:14.0262,lwr_k=600:14.5598,lwr_k=700:14.9477,lwr_k=800:15.2334,lwr_k=900:15.2862,lwr_k=1000:15.6953'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.2472,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.4923,lwr_k=40:1.9187,lwr_k=50:2.7407,lwr_k=100:4.5189,lwr_k=200:5.829,lwr_k=300:6.3228,lwr_k=400:6.7361,lwr_k=500:6.9788,lwr_k=600:7.2036,lwr_k=700:7.3576,lwr_k=800:7.5224,lwr_k=900:7.6566,lwr_k=1000:7.7777'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:33.7709,lwr_k=10:45.0761,lwr_k=20:178.5455,lwr_k=30:167.5747,lwr_k=40:31.28,lwr_k=50:24.6784,lwr_k=100:21.15,lwr_k=200:23.2684,lwr_k=300:23.4271,lwr_k=400:24.5265,lwr_k=500:25.1598,lwr_k=600:25.8072,lwr_k=700:26.3884,lwr_k=800:26.946,lwr_k=900:27.4844,lwr_k=1000:27.8981'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:14.3948,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.4162,lwr_k=40:1.9957,lwr_k=50:3.1111,lwr_k=100:5.6992,lwr_k=200:7.5936,lwr_k=300:8.4748,lwr_k=400:8.9869,lwr_k=500:9.392,lwr_k=600:9.6887,lwr_k=700:9.9628,lwr_k=800:10.2326,lwr_k=900:10.4383,lwr_k=1000:10.5963'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:16.1204,lwr_k=10:62.2447,lwr_k=20:139.5466,lwr_k=30:177.2238,lwr_k=40:27.377,lwr_k=50:29.0683,lwr_k=100:10.5786,lwr_k=200:10.8291,lwr_k=300:11.6204,lwr_k=400:11.7146,lwr_k=500:12.0839,lwr_k=600:12.257,lwr_k=700:12.5717,lwr_k=800:12.619,lwr_k=900:12.7313,lwr_k=1000:12.861'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_5'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.7172,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0418,lwr_k=40:0.7083,lwr_k=50:5.6498,lwr_k=100:4.0891,lwr_k=200:4.2232,lwr_k=300:4.5349,lwr_k=400:4.2584,lwr_k=500:4.7202,lwr_k=600:4.7057,lwr_k=700:4.7216,lwr_k=800:4.6224,lwr_k=900:4.6087,lwr_k=1000:4.6622'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.2198,lwr_k=10:34.0258,lwr_k=20:324.6431,lwr_k=30:735.085,lwr_k=40:117.7115,lwr_k=50:82.7734,lwr_k=100:12.9054,lwr_k=200:10.4873,lwr_k=300:7.9155,lwr_k=400:10.2121,lwr_k=500:8.4087,lwr_k=600:7.7266,lwr_k=700:8.649,lwr_k=800:8.5247,lwr_k=900:8.1896,lwr_k=1000:7.8975'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.4831,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.4769,lwr_k=40:1.2498,lwr_k=50:4.6245,lwr_k=100:5.1233,lwr_k=200:5.4713,lwr_k=300:5.5361,lwr_k=400:5.6952,lwr_k=500:5.6227,lwr_k=600:5.7489,lwr_k=700:5.7843,lwr_k=800:5.8351,lwr_k=900:5.9957,lwr_k=1000:5.9674'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.1635,lwr_k=10:48.9946,lwr_k=20:281.4452,lwr_k=30:928.9922,lwr_k=40:103.7036,lwr_k=50:124.682,lwr_k=100:12.9836,lwr_k=200:8.8005,lwr_k=300:7.1794,lwr_k=400:7.0535,lwr_k=500:7.2409,lwr_k=600:6.7214,lwr_k=700:6.6011,lwr_k=800:6.5387,lwr_k=900:6.6289,lwr_k=1000:6.6441'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:13.0277,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.5657,lwr_k=40:1.91,lwr_k=50:9.4534,lwr_k=100:8.3861,lwr_k=200:8.8427,lwr_k=300:7.4673,lwr_k=400:7.7065,lwr_k=500:7.4492,lwr_k=600:7.0747,lwr_k=700:7.4848,lwr_k=800:7.1462,lwr_k=900:7.4729,lwr_k=1000:7.9388'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:11.9719,lwr_k=10:52.4063,lwr_k=20:411.1325,lwr_k=30:1199.8261,lwr_k=40:64.8304,lwr_k=50:57.6511,lwr_k=100:14.6841,lwr_k=200:15.0842,lwr_k=300:12.1115,lwr_k=400:11.9021,lwr_k=500:8.4345,lwr_k=600:8.4914,lwr_k=700:7.3517,lwr_k=800:7.3657,lwr_k=900:6.8313,lwr_k=1000:6.6675'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.9044,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.4907,lwr_k=40:1.6977,lwr_k=50:37.3607,lwr_k=100:15.2575,lwr_k=200:10.5453,lwr_k=300:9.6197,lwr_k=400:7.4869,lwr_k=500:7.0702,lwr_k=600:6.9145,lwr_k=700:6.9781,lwr_k=800:6.5894,lwr_k=900:6.8045,lwr_k=1000:6.8636'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:11.2429,lwr_k=10:117.6427,lwr_k=20:429.2077,lwr_k=30:1823.1311,lwr_k=40:181.3396,lwr_k=50:534.4837,lwr_k=100:67.1019,lwr_k=200:14.9545,lwr_k=300:11.5967,lwr_k=400:9.9736,lwr_k=500:9.4377,lwr_k=600:9.2902,lwr_k=700:9.3817,lwr_k=800:9.7251,lwr_k=900:9.5558,lwr_k=1000:9.214'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.8171,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0345,lwr_k=40:0.4262,lwr_k=50:6.9349,lwr_k=100:3.7004,lwr_k=200:4.5021,lwr_k=300:4.7536,lwr_k=400:4.9167,lwr_k=500:5.0483,lwr_k=600:5.1177,lwr_k=700:5.1788,lwr_k=800:5.2477,lwr_k=900:5.2911,lwr_k=1000:5.3482'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:17.512,lwr_k=10:47.2934,lwr_k=20:95.9396,lwr_k=30:406.5062,lwr_k=40:4253.9189,lwr_k=50:693.9668,lwr_k=100:58.0019,lwr_k=200:19.5245,lwr_k=300:17.3148,lwr_k=400:17.1284,lwr_k=500:17.0786,lwr_k=600:17.071,lwr_k=700:17.3683,lwr_k=800:17.2711,lwr_k=900:17.348,lwr_k=1000:17.4979'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:7.755,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.1935,lwr_k=40:1.5107,lwr_k=50:8.7832,lwr_k=100:6.0551,lwr_k=200:6.2618,lwr_k=300:6.0966,lwr_k=400:6.5019,lwr_k=500:6.3857,lwr_k=600:6.4078,lwr_k=700:6.5735,lwr_k=800:6.2811,lwr_k=900:6.7266,lwr_k=1000:7.0593'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:15.1095,lwr_k=10:95.1573,lwr_k=20:253.7585,lwr_k=30:6528.6134,lwr_k=40:140.906,lwr_k=50:58.6519,lwr_k=100:19.4962,lwr_k=200:13.375,lwr_k=300:11.3962,lwr_k=400:10.297,lwr_k=500:10.8474,lwr_k=600:10.222,lwr_k=700:9.3123,lwr_k=800:8.8266,lwr_k=900:9.9707,lwr_k=1000:12.1718'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_6'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:62.596,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:2.8283,lwr_k=50:5.1308,lwr_k=100:12.7922,lwr_k=200:20.6818,lwr_k=300:24.7984,lwr_k=400:28.3294,lwr_k=500:31.663,lwr_k=600:34.028,lwr_k=700:35.9997,lwr_k=800:37.8965,lwr_k=900:39.4527,lwr_k=1000:40.8817'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:69.8484,lwr_k=10:95.769,lwr_k=20:299.8591,lwr_k=30:1150.2771,lwr_k=40:94.5569,lwr_k=50:47.0646,lwr_k=100:30.5255,lwr_k=200:32.2495,lwr_k=300:35.6577,lwr_k=400:38.9645,lwr_k=500:41.1686,lwr_k=600:42.7797,lwr_k=700:44.4666,lwr_k=800:45.8604,lwr_k=900:47.1098,lwr_k=1000:48.1282'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:78.0678,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0016,lwr_k=40:3.4803,lwr_k=50:6.3333,lwr_k=100:16.6558,lwr_k=200:27.2984,lwr_k=300:32.945,lwr_k=400:36.6968,lwr_k=500:40.3597,lwr_k=600:43.2084,lwr_k=700:45.558,lwr_k=800:48.0225,lwr_k=900:49.6638,lwr_k=1000:51.6047'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:70.2658,lwr_k=10:117.0519,lwr_k=20:425.9713,lwr_k=30:2907.6419,lwr_k=40:157.5636,lwr_k=50:131.2218,lwr_k=100:29.9375,lwr_k=200:30.1051,lwr_k=300:32.5729,lwr_k=400:34.8557,lwr_k=500:36.0848,lwr_k=600:38.2593,lwr_k=700:40.2489,lwr_k=800:42.8728,lwr_k=900:43.879,lwr_k=1000:44.7718'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:84.1892,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0211,lwr_k=40:3.7493,lwr_k=50:6.9686,lwr_k=100:17.9504,lwr_k=200:27.4059,lwr_k=300:34.4908,lwr_k=400:39.0001,lwr_k=500:42.4718,lwr_k=600:45.6033,lwr_k=700:48.2581,lwr_k=800:50.3997,lwr_k=900:52.5873,lwr_k=1000:54.6213'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:52.5839,lwr_k=10:60.3543,lwr_k=20:279.7102,lwr_k=30:6054.6197,lwr_k=40:297.7152,lwr_k=50:146.7919,lwr_k=100:167.6771,lwr_k=200:25.2027,lwr_k=300:26.6937,lwr_k=400:28.7064,lwr_k=500:30.5779,lwr_k=600:31.5481,lwr_k=700:32.2351,lwr_k=800:33.2482,lwr_k=900:34.5473,lwr_k=1000:35.0678'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:82.2777,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:3.3389,lwr_k=50:7.0192,lwr_k=100:17.5129,lwr_k=200:27.3734,lwr_k=300:34.6452,lwr_k=400:39.4805,lwr_k=500:42.3706,lwr_k=600:44.8781,lwr_k=700:47.6239,lwr_k=800:50.2392,lwr_k=900:52.077,lwr_k=1000:53.4506'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:77.3298,lwr_k=10:67.0109,lwr_k=20:332.0331,lwr_k=30:1898.0061,lwr_k=40:1092.3111,lwr_k=50:1329.7317,lwr_k=100:519.1434,lwr_k=200:274.389,lwr_k=300:261.3819,lwr_k=400:268.6421,lwr_k=500:257.852,lwr_k=600:256.9519,lwr_k=700:237.7993,lwr_k=800:169.7898,lwr_k=900:154.6371,lwr_k=1000:152.2953'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:61.1151,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0001,lwr_k=40:3.1103,lwr_k=50:5.3617,lwr_k=100:13.4307,lwr_k=200:21.0188,lwr_k=300:26.1199,lwr_k=400:29.5134,lwr_k=500:32.0188,lwr_k=600:34.1024,lwr_k=700:35.9427,lwr_k=800:37.4653,lwr_k=900:38.8135,lwr_k=1000:40.0667'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:193.4522,lwr_k=10:96.2132,lwr_k=20:410.6548,lwr_k=30:1897.0529,lwr_k=40:242.8757,lwr_k=50:235.211,lwr_k=100:75.1042,lwr_k=200:64.2291,lwr_k=300:69.3567,lwr_k=400:73.2027,lwr_k=500:73.7534,lwr_k=600:76.2628,lwr_k=700:80.0244,lwr_k=800:83.4511,lwr_k=900:83.6388,lwr_k=1000:85.5245'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:74.7135,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:2.9377,lwr_k=50:5.5051,lwr_k=100:15.0613,lwr_k=200:23.5767,lwr_k=300:29.3743,lwr_k=400:33.097,lwr_k=500:35.8808,lwr_k=600:38.1311,lwr_k=700:40.2883,lwr_k=800:41.9544,lwr_k=900:43.8161,lwr_k=1000:45.4771'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:77.0113,lwr_k=10:84.9962,lwr_k=20:401.8912,lwr_k=30:3101.9349,lwr_k=40:612.9256,lwr_k=50:583.0965,lwr_k=100:70.2843,lwr_k=200:73.7954,lwr_k=300:70.5309,lwr_k=400:67.7451,lwr_k=500:62.678,lwr_k=600:60.7515,lwr_k=700:64.3183,lwr_k=800:67.8118,lwr_k=900:69.5439,lwr_k=1000:73.4569'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_7'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:106.4276,lwr_k=10:0.0,lwr_k=20:12.1941,lwr_k=30:20.0017,lwr_k=40:23.5394,lwr_k=50:25.948,lwr_k=100:34.923,lwr_k=200:43.6174,lwr_k=300:49.5401,lwr_k=400:53.2114,lwr_k=500:56.2118,lwr_k=600:58.6176,lwr_k=700:60.7867,lwr_k=800:63.2942,lwr_k=900:65.5972,lwr_k=1000:67.296'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:141.629,lwr_k=10:939.6524,lwr_k=20:260.942,lwr_k=30:60.0871,lwr_k=40:55.8957,lwr_k=50:54.2057,lwr_k=100:54.4557,lwr_k=200:56.6268,lwr_k=300:60.6384,lwr_k=400:65.2746,lwr_k=500:68.8381,lwr_k=600:72.43,lwr_k=700:75.6502,lwr_k=800:78.9173,lwr_k=900:82.0521,lwr_k=1000:84.7015'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:131.447,lwr_k=10:0.0,lwr_k=20:12.2225,lwr_k=30:20.6327,lwr_k=40:24.9879,lwr_k=50:27.6626,lwr_k=100:38.0274,lwr_k=200:50.2475,lwr_k=300:57.7519,lwr_k=400:62.8054,lwr_k=500:66.5563,lwr_k=600:69.9887,lwr_k=700:72.8666,lwr_k=800:76.5442,lwr_k=900:79.9092,lwr_k=1000:82.3423'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:109.5394,lwr_k=10:1740.9675,lwr_k=20:95.6435,lwr_k=30:59.9512,lwr_k=40:51.7344,lwr_k=50:48.6243,lwr_k=100:46.1081,lwr_k=200:50.7018,lwr_k=300:53.4688,lwr_k=400:55.6707,lwr_k=500:58.0221,lwr_k=600:60.5069,lwr_k=700:62.9085,lwr_k=800:65.5879,lwr_k=900:67.9714,lwr_k=1000:69.5284'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:150.0622,lwr_k=10:0.0,lwr_k=20:13.5598,lwr_k=30:21.4884,lwr_k=40:25.8751,lwr_k=50:28.9354,lwr_k=100:40.1194,lwr_k=200:52.6558,lwr_k=300:60.1558,lwr_k=400:65.8989,lwr_k=500:70.5054,lwr_k=600:74.9642,lwr_k=700:79.0584,lwr_k=800:83.1267,lwr_k=900:86.8066,lwr_k=1000:89.2245'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:86.8008,lwr_k=10:833.8186,lwr_k=20:71.5086,lwr_k=30:54.3727,lwr_k=40:48.1879,lwr_k=50:43.2873,lwr_k=100:40.1942,lwr_k=200:43.3082,lwr_k=300:45.1269,lwr_k=400:46.9459,lwr_k=500:48.5348,lwr_k=600:49.7981,lwr_k=700:51.1202,lwr_k=800:52.3091,lwr_k=900:53.8585,lwr_k=1000:54.9648'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.3574,lwr_k=10:0.0,lwr_k=20:14.3724,lwr_k=30:21.8002,lwr_k=40:25.658,lwr_k=50:29.3304,lwr_k=100:39.5346,lwr_k=200:52.772,lwr_k=300:60.2448,lwr_k=400:65.2823,lwr_k=500:69.984,lwr_k=600:74.1061,lwr_k=700:77.9898,lwr_k=800:81.532,lwr_k=900:84.678,lwr_k=1000:87.3102'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:130.1834,lwr_k=10:2722.5654,lwr_k=20:124.3983,lwr_k=30:64.4437,lwr_k=40:48.7597,lwr_k=50:46.2991,lwr_k=100:48.9536,lwr_k=200:55.8608,lwr_k=300:60.0544,lwr_k=400:63.8401,lwr_k=500:66.5267,lwr_k=600:70.2495,lwr_k=700:73.4589,lwr_k=800:76.8639,lwr_k=900:78.9504,lwr_k=1000:81.587'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:110.1866,lwr_k=10:0.0,lwr_k=20:13.5865,lwr_k=30:21.136,lwr_k=40:24.5486,lwr_k=50:27.8017,lwr_k=100:35.5633,lwr_k=200:44.417,lwr_k=300:49.2573,lwr_k=400:53.0278,lwr_k=500:55.8091,lwr_k=600:58.8037,lwr_k=700:61.1949,lwr_k=800:63.7303,lwr_k=900:65.907,lwr_k=1000:67.9707'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:184.3549,lwr_k=10:1186.3781,lwr_k=20:87.416,lwr_k=30:86.6228,lwr_k=40:78.6979,lwr_k=50:75.7936,lwr_k=100:75.0864,lwr_k=200:83.1869,lwr_k=300:90.6279,lwr_k=400:97.1529,lwr_k=500:105.2592,lwr_k=600:109.2855,lwr_k=700:112.7908,lwr_k=800:116.0924,lwr_k=900:118.9565,lwr_k=1000:121.3836'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:128.5858,lwr_k=10:0.0,lwr_k=20:13.8449,lwr_k=30:21.1703,lwr_k=40:25.4375,lwr_k=50:28.2813,lwr_k=100:36.7127,lwr_k=200:45.5507,lwr_k=300:52.6709,lwr_k=400:57.2553,lwr_k=500:60.1123,lwr_k=600:63.3976,lwr_k=700:66.1264,lwr_k=800:68.6602,lwr_k=900:70.9698,lwr_k=1000:73.2356'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:128.1876,lwr_k=10:3189.1729,lwr_k=20:97.7425,lwr_k=30:51.6362,lwr_k=40:51.3418,lwr_k=50:51.784,lwr_k=100:55.5342,lwr_k=200:59.0858,lwr_k=300:63.2973,lwr_k=400:66.2235,lwr_k=500:68.4284,lwr_k=600:69.5133,lwr_k=700:71.0071,lwr_k=800:73.6228,lwr_k=900:75.6722,lwr_k=1000:77.3982'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_8'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:143.6131,lwr_k=10:0.0,lwr_k=20:5.5929,lwr_k=30:12.5155,lwr_k=40:16.6011,lwr_k=50:19.1934,lwr_k=100:28.6691,lwr_k=200:38.9415,lwr_k=300:47.0438,lwr_k=400:53.8711,lwr_k=500:58.7764,lwr_k=600:63.5634,lwr_k=700:67.8508,lwr_k=800:71.9521,lwr_k=900:75.7487,lwr_k=1000:78.7747'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:186.2555,lwr_k=10:645.7634,lwr_k=20:259.0923,lwr_k=30:123.8418,lwr_k=40:53.1282,lwr_k=50:51.2485,lwr_k=100:52.9944,lwr_k=200:60.9023,lwr_k=300:67.7045,lwr_k=400:74.8902,lwr_k=500:79.6666,lwr_k=600:85.2485,lwr_k=700:91.6351,lwr_k=800:96.9325,lwr_k=900:100.9114,lwr_k=1000:104.6841'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:168.5198,lwr_k=10:0.0,lwr_k=20:6.0227,lwr_k=30:12.655,lwr_k=40:17.9389,lwr_k=50:21.5152,lwr_k=100:33.122,lwr_k=200:45.9683,lwr_k=300:53.5879,lwr_k=400:61.9303,lwr_k=500:68.0433,lwr_k=600:73.3661,lwr_k=700:78.9587,lwr_k=800:83.5641,lwr_k=900:87.7028,lwr_k=1000:91.1004'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:148.6055,lwr_k=10:458.2702,lwr_k=20:85.1245,lwr_k=30:91.542,lwr_k=40:45.2778,lwr_k=50:42.9159,lwr_k=100:39.0032,lwr_k=200:44.7974,lwr_k=300:50.0795,lwr_k=400:55.7402,lwr_k=500:60.3966,lwr_k=600:64.8912,lwr_k=700:70.2727,lwr_k=800:74.5066,lwr_k=900:77.8258,lwr_k=1000:80.3528'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:187.3684,lwr_k=10:0.0,lwr_k=20:7.5035,lwr_k=30:14.8925,lwr_k=40:19.9478,lwr_k=50:23.6956,lwr_k=100:35.1161,lwr_k=200:49.1423,lwr_k=300:58.2979,lwr_k=400:66.8993,lwr_k=500:73.3525,lwr_k=600:79.2859,lwr_k=700:85.6086,lwr_k=800:90.0697,lwr_k=900:94.9042,lwr_k=1000:98.4139'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:127.4283,lwr_k=10:709.3045,lwr_k=20:185.5931,lwr_k=30:49.6213,lwr_k=40:38.509,lwr_k=50:34.6673,lwr_k=100:36.8738,lwr_k=200:42.0329,lwr_k=300:46.9663,lwr_k=400:52.6939,lwr_k=500:57.5413,lwr_k=600:62.0824,lwr_k=700:65.4882,lwr_k=800:69.1588,lwr_k=900:72.3898,lwr_k=1000:74.5481'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:180.6738,lwr_k=10:0.0,lwr_k=20:6.3521,lwr_k=30:14.7584,lwr_k=40:19.6587,lwr_k=50:22.5802,lwr_k=100:34.8793,lwr_k=200:48.8939,lwr_k=300:57.9784,lwr_k=400:66.149,lwr_k=500:72.5306,lwr_k=600:78.5869,lwr_k=700:84.1118,lwr_k=800:88.7472,lwr_k=900:93.2005,lwr_k=1000:97.2409'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:168.2766,lwr_k=10:507.8244,lwr_k=20:250.8989,lwr_k=30:56.2907,lwr_k=40:48.7521,lwr_k=50:47.1396,lwr_k=100:43.4938,lwr_k=200:49.6336,lwr_k=300:57.926,lwr_k=400:63.6896,lwr_k=500:69.3258,lwr_k=600:74.2871,lwr_k=700:79.3539,lwr_k=800:83.4471,lwr_k=900:87.1113,lwr_k=1000:89.9058'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:149.7283,lwr_k=10:0.0,lwr_k=20:5.2741,lwr_k=30:12.0315,lwr_k=40:16.3684,lwr_k=50:19.5248,lwr_k=100:29.3058,lwr_k=200:40.8192,lwr_k=300:49.5709,lwr_k=400:57.1801,lwr_k=500:62.7813,lwr_k=600:67.9278,lwr_k=700:72.9783,lwr_k=800:77.1176,lwr_k=900:80.8161,lwr_k=1000:83.5689'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:224.0067,lwr_k=10:738.7713,lwr_k=20:357.4684,lwr_k=30:134.8225,lwr_k=40:126.3317,lwr_k=50:134.664,lwr_k=100:67.4127,lwr_k=200:76.299,lwr_k=300:84.5285,lwr_k=400:94.2413,lwr_k=500:101.5777,lwr_k=600:109.6196,lwr_k=700:116.9835,lwr_k=800:123.3531,lwr_k=900:127.3644,lwr_k=1000:131.7364'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:167.1022,lwr_k=10:0.0,lwr_k=20:5.3416,lwr_k=30:12.2062,lwr_k=40:17.2334,lwr_k=50:19.9093,lwr_k=100:30.3407,lwr_k=200:40.9677,lwr_k=300:48.7029,lwr_k=400:55.1148,lwr_k=500:61.1542,lwr_k=600:65.8257,lwr_k=700:70.8162,lwr_k=800:74.6332,lwr_k=900:79.107,lwr_k=1000:82.7462'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:174.849,lwr_k=10:541.5008,lwr_k=20:121.5234,lwr_k=30:69.3198,lwr_k=40:61.5165,lwr_k=50:59.0376,lwr_k=100:57.5734,lwr_k=200:60.4461,lwr_k=300:65.4969,lwr_k=400:68.1246,lwr_k=500:72.1714,lwr_k=600:76.4922,lwr_k=700:80.3013,lwr_k=800:83.9407,lwr_k=900:87.2677,lwr_k=1000:89.6965'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_9'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.8959,lwr_k=10:0.0,lwr_k=20:0.0004,lwr_k=30:0.0026,lwr_k=40:0.0222,lwr_k=50:0.3445,lwr_k=100:1.9776,lwr_k=200:3.0238,lwr_k=300:3.4382,lwr_k=400:3.6894,lwr_k=500:3.8558,lwr_k=600:4.0059,lwr_k=700:4.1022,lwr_k=800:4.1674,lwr_k=900:4.2258,lwr_k=1000:4.2539'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.2549,lwr_k=10:17.3256,lwr_k=20:21.1719,lwr_k=30:603.6876,lwr_k=40:215.8897,lwr_k=50:101.5521,lwr_k=100:9.7458,lwr_k=200:7.9098,lwr_k=300:7.4002,lwr_k=400:7.2843,lwr_k=500:7.3839,lwr_k=600:7.3923,lwr_k=700:7.3564,lwr_k=800:7.4589,lwr_k=900:7.441,lwr_k=1000:7.4631'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.5491,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0012,lwr_k=40:0.0236,lwr_k=50:0.4176,lwr_k=100:2.2464,lwr_k=200:4.0534,lwr_k=300:4.9726,lwr_k=400:5.3429,lwr_k=500:5.6007,lwr_k=600:5.8477,lwr_k=700:5.9904,lwr_k=800:6.1362,lwr_k=900:6.2561,lwr_k=1000:6.3676'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.9434,lwr_k=10:20.3797,lwr_k=20:14.8701,lwr_k=30:27.2234,lwr_k=40:239821.8124,lwr_k=50:312.6308,lwr_k=100:7.7495,lwr_k=200:6.3421,lwr_k=300:6.1413,lwr_k=400:5.9568,lwr_k=500:5.95,lwr_k=600:6.052,lwr_k=700:6.2088,lwr_k=800:6.2995,lwr_k=900:6.4473,lwr_k=1000:6.5449'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.4141,lwr_k=10:0.0,lwr_k=20:0.0002,lwr_k=30:0.0008,lwr_k=40:0.0264,lwr_k=50:0.4032,lwr_k=100:2.6093,lwr_k=200:4.3319,lwr_k=300:4.9595,lwr_k=400:5.4297,lwr_k=500:5.683,lwr_k=600:5.8737,lwr_k=700:6.0425,lwr_k=800:6.1865,lwr_k=900:6.2759,lwr_k=1000:6.3571'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.1,lwr_k=10:14.2436,lwr_k=20:13.0656,lwr_k=30:25.3702,lwr_k=40:235.8563,lwr_k=50:179.2102,lwr_k=100:8.8085,lwr_k=200:5.6956,lwr_k=300:5.2991,lwr_k=400:5.1842,lwr_k=500:5.1757,lwr_k=600:5.1899,lwr_k=700:5.2363,lwr_k=800:5.3024,lwr_k=900:5.3167,lwr_k=1000:5.3312'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.393,lwr_k=10:0.0021,lwr_k=20:0.0377,lwr_k=30:0.1495,lwr_k=40:0.3286,lwr_k=50:0.6839,lwr_k=100:2.7084,lwr_k=200:4.0565,lwr_k=300:4.5812,lwr_k=400:4.8049,lwr_k=500:4.9944,lwr_k=600:5.0957,lwr_k=700:5.2218,lwr_k=800:5.3379,lwr_k=900:5.4299,lwr_k=1000:5.5051'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.3246,lwr_k=10:22.8199,lwr_k=20:60.6128,lwr_k=30:867.5647,lwr_k=40:10413432.8732,lwr_k=50:2023195.9892,lwr_k=100:12.593,lwr_k=200:7.5927,lwr_k=300:7.7108,lwr_k=400:7.7198,lwr_k=500:7.7269,lwr_k=600:7.8063,lwr_k=700:7.8667,lwr_k=800:7.8904,lwr_k=900:7.9076,lwr_k=1000:7.9663'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:52.2781,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0114,lwr_k=40:0.7267,lwr_k=50:1.9001,lwr_k=100:7.5254,lwr_k=200:13.5143,lwr_k=300:16.753,lwr_k=400:19.5896,lwr_k=500:21.9968,lwr_k=600:23.9154,lwr_k=700:25.6366,lwr_k=800:27.0215,lwr_k=900:28.1987,lwr_k=1000:29.4769'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:102.426,lwr_k=10:45.632,lwr_k=20:55.6292,lwr_k=30:147.6372,lwr_k=40:504.2211,lwr_k=50:470.2081,lwr_k=100:48.3176,lwr_k=200:46.3481,lwr_k=300:53.2924,lwr_k=400:57.9067,lwr_k=500:61.3349,lwr_k=600:64.547,lwr_k=700:66.7638,lwr_k=800:68.4128,lwr_k=900:70.4864,lwr_k=1000:72.4248'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:5.638,lwr_k=10:0.0002,lwr_k=20:0.0042,lwr_k=30:0.0125,lwr_k=40:0.1235,lwr_k=50:0.4847,lwr_k=100:2.2594,lwr_k=200:3.4269,lwr_k=300:3.8843,lwr_k=400:4.1374,lwr_k=500:4.3094,lwr_k=600:4.4662,lwr_k=700:4.551,lwr_k=800:4.5947,lwr_k=900:4.6683,lwr_k=1000:4.7307'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.0102,lwr_k=10:17.7942,lwr_k=20:48.7561,lwr_k=30:11227.2888,lwr_k=40:524250.4624,lwr_k=50:4794.6211,lwr_k=100:7.8568,lwr_k=200:6.7469,lwr_k=300:6.7634,lwr_k=400:7.1008,lwr_k=500:7.2815,lwr_k=600:7.4704,lwr_k=700:7.5377,lwr_k=800:7.6149,lwr_k=900:7.7192,lwr_k=1000:7.8163'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_10'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.0842,lwr_k=10:0.0,lwr_k=20:2.3212,lwr_k=30:2.8654,lwr_k=40:3.3291,lwr_k=50:3.5482,lwr_k=100:4.1269,lwr_k=200:4.3948,lwr_k=300:4.4998,lwr_k=400:4.5601,lwr_k=500:4.6228,lwr_k=600:4.6821,lwr_k=700:4.7173,lwr_k=800:4.7595,lwr_k=900:4.7961,lwr_k=1000:4.8164'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.277,lwr_k=10:721014.244,lwr_k=20:23.4179,lwr_k=30:16.8353,lwr_k=40:13.4661,lwr_k=50:9.8985,lwr_k=100:8.0711,lwr_k=200:8.2043,lwr_k=300:8.4671,lwr_k=400:8.5954,lwr_k=500:8.6662,lwr_k=600:8.7306,lwr_k=700:8.7566,lwr_k=800:8.7494,lwr_k=900:8.7769,lwr_k=1000:8.8057'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.4902,lwr_k=10:0.0,lwr_k=20:2.9787,lwr_k=30:4.0179,lwr_k=40:4.705,lwr_k=50:4.9728,lwr_k=100:5.7852,lwr_k=200:6.3575,lwr_k=300:6.6165,lwr_k=400:6.8095,lwr_k=500:6.9429,lwr_k=600:7.0504,lwr_k=700:7.1367,lwr_k=800:7.2305,lwr_k=900:7.3098,lwr_k=1000:7.3904'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.206,lwr_k=10:198164.8338,lwr_k=20:61.2508,lwr_k=30:13.321,lwr_k=40:13.3377,lwr_k=50:14.5755,lwr_k=100:23.501,lwr_k=200:8.5361,lwr_k=300:7.3201,lwr_k=400:7.5689,lwr_k=500:7.6507,lwr_k=600:7.6835,lwr_k=700:7.7744,lwr_k=800:7.8535,lwr_k=900:7.9358,lwr_k=1000:7.9769'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.0388,lwr_k=10:0.0,lwr_k=20:2.9711,lwr_k=30:3.9297,lwr_k=40:4.6827,lwr_k=50:5.4729,lwr_k=100:7.3039,lwr_k=200:8.2524,lwr_k=300:8.5703,lwr_k=400:8.7373,lwr_k=500:8.8221,lwr_k=600:8.8924,lwr_k=700:8.9392,lwr_k=800:9.0036,lwr_k=900:9.0679,lwr_k=1000:9.1209'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.3206,lwr_k=10:128215.5214,lwr_k=20:12.1206,lwr_k=30:7.8727,lwr_k=40:12.9074,lwr_k=50:6.5496,lwr_k=100:6.0599,lwr_k=200:5.9773,lwr_k=300:6.0106,lwr_k=400:6.0619,lwr_k=500:6.1667,lwr_k=600:6.2354,lwr_k=700:6.2528,lwr_k=800:6.2609,lwr_k=900:6.2594,lwr_k=1000:6.3216'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.2175,lwr_k=10:0.0001,lwr_k=20:2.9312,lwr_k=30:3.7304,lwr_k=40:4.1443,lwr_k=50:4.3492,lwr_k=100:5.3055,lwr_k=200:6.0609,lwr_k=300:6.284,lwr_k=400:6.4258,lwr_k=500:6.5308,lwr_k=600:6.5651,lwr_k=700:6.5948,lwr_k=800:6.6322,lwr_k=900:6.6791,lwr_k=1000:6.7242'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.9629,lwr_k=10:23040.104,lwr_k=20:98.072,lwr_k=30:24.9139,lwr_k=40:14.6291,lwr_k=50:10.1474,lwr_k=100:7.956,lwr_k=200:7.8532,lwr_k=300:8.0641,lwr_k=400:8.0899,lwr_k=500:8.217,lwr_k=600:8.3026,lwr_k=700:8.3707,lwr_k=800:8.4826,lwr_k=900:8.4367,lwr_k=1000:8.441'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.38,lwr_k=10:0.0,lwr_k=20:2.1949,lwr_k=30:2.9258,lwr_k=40:3.299,lwr_k=50:3.5347,lwr_k=100:3.9899,lwr_k=200:4.2708,lwr_k=300:4.3995,lwr_k=400:4.4889,lwr_k=500:4.5798,lwr_k=600:4.641,lwr_k=700:4.7044,lwr_k=800:4.7583,lwr_k=900:4.8132,lwr_k=1000:4.8495'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:15.7512,lwr_k=10:16319.9592,lwr_k=20:20.9963,lwr_k=30:16.1397,lwr_k=40:16.5291,lwr_k=50:16.347,lwr_k=100:17.0338,lwr_k=200:15.6289,lwr_k=300:15.5497,lwr_k=400:15.512,lwr_k=500:15.4752,lwr_k=600:15.426,lwr_k=700:15.3732,lwr_k=800:15.3534,lwr_k=900:15.3492,lwr_k=1000:15.3249'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:5.9898,lwr_k=10:0.0,lwr_k=20:2.2284,lwr_k=30:3.0122,lwr_k=40:3.3719,lwr_k=50:3.7348,lwr_k=100:4.4305,lwr_k=200:4.8122,lwr_k=300:5.0,lwr_k=400:5.1177,lwr_k=500:5.1944,lwr_k=600:5.2589,lwr_k=700:5.3161,lwr_k=800:5.3569,lwr_k=900:5.3898,lwr_k=1000:5.424'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.8586,lwr_k=10:2628.7302,lwr_k=20:30.6022,lwr_k=30:12.3414,lwr_k=40:10.3468,lwr_k=50:8.9849,lwr_k=100:7.8573,lwr_k=200:8.1731,lwr_k=300:8.1066,lwr_k=400:7.9693,lwr_k=500:8.2928,lwr_k=600:8.3922,lwr_k=700:8.5298,lwr_k=800:8.5771,lwr_k=900:8.6792,lwr_k=1000:8.8243'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_11'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.4991,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.0131,lwr_k=100:1.9434,lwr_k=200:2.9465,lwr_k=300:3.265,lwr_k=400:3.4473,lwr_k=500:3.5542,lwr_k=600:3.6321,lwr_k=700:3.6971,lwr_k=800:3.7315,lwr_k=900:3.7671,lwr_k=1000:3.8081'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.038,lwr_k=10:25.0228,lwr_k=20:32.1913,lwr_k=30:58.2323,lwr_k=40:73.0033,lwr_k=50:5049.7444,lwr_k=100:11.4689,lwr_k=200:7.477,lwr_k=300:7.3943,lwr_k=400:7.2916,lwr_k=500:7.3223,lwr_k=600:7.3545,lwr_k=700:7.3153,lwr_k=800:7.294,lwr_k=900:7.3108,lwr_k=1000:7.3356'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.3312,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0001,lwr_k=40:0.0134,lwr_k=50:1.0739,lwr_k=100:2.5522,lwr_k=200:4.7283,lwr_k=300:5.3626,lwr_k=400:6.1099,lwr_k=500:6.4164,lwr_k=600:6.676,lwr_k=700:6.9118,lwr_k=800:7.0974,lwr_k=900:7.1964,lwr_k=1000:7.3181'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.4281,lwr_k=10:36.0949,lwr_k=20:57.3386,lwr_k=30:107.2266,lwr_k=40:799.453,lwr_k=50:23164.2195,lwr_k=100:123.8884,lwr_k=200:21.1939,lwr_k=300:8.1669,lwr_k=400:7.0744,lwr_k=500:7.093,lwr_k=600:6.7631,lwr_k=700:6.9349,lwr_k=800:6.913,lwr_k=900:6.5941,lwr_k=1000:6.6936'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.7359,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0008,lwr_k=40:0.0319,lwr_k=50:2.3849,lwr_k=100:2.6229,lwr_k=200:3.9343,lwr_k=300:4.5705,lwr_k=400:4.8178,lwr_k=500:5.0342,lwr_k=600:5.1825,lwr_k=700:5.3087,lwr_k=800:5.434,lwr_k=900:5.5773,lwr_k=1000:5.6961'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.3842,lwr_k=10:33.5419,lwr_k=20:91.4276,lwr_k=30:182.0235,lwr_k=40:391.226,lwr_k=50:1231733.629,lwr_k=100:350.2276,lwr_k=200:6.8636,lwr_k=300:6.0827,lwr_k=400:5.9389,lwr_k=500:5.803,lwr_k=600:5.8142,lwr_k=700:5.8023,lwr_k=800:5.718,lwr_k=900:5.6565,lwr_k=1000:5.7352'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:11.6859,lwr_k=10:0.0011,lwr_k=20:0.0684,lwr_k=30:1.3495,lwr_k=40:1.4617,lwr_k=50:5.9813,lwr_k=100:4.6657,lwr_k=200:5.765,lwr_k=300:6.5507,lwr_k=400:6.7295,lwr_k=500:6.6645,lwr_k=600:7.0626,lwr_k=700:7.3445,lwr_k=800:8.0344,lwr_k=900:8.913,lwr_k=1000:9.2341'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:9.287,lwr_k=10:136.2208,lwr_k=20:221.9388,lwr_k=30:391.2681,lwr_k=40:975.0624,lwr_k=50:915.977,lwr_k=100:32.9911,lwr_k=200:9.6394,lwr_k=300:9.5112,lwr_k=400:9.7961,lwr_k=500:8.7844,lwr_k=600:8.9873,lwr_k=700:8.901,lwr_k=800:8.4225,lwr_k=900:8.1318,lwr_k=1000:8.2546'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.8954,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0001,lwr_k=50:0.0961,lwr_k=100:2.3633,lwr_k=200:3.4345,lwr_k=300:3.7357,lwr_k=400:3.9268,lwr_k=500:4.0389,lwr_k=600:4.1581,lwr_k=700:4.2199,lwr_k=800:4.2873,lwr_k=900:4.3302,lwr_k=1000:4.3794'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:19.6041,lwr_k=10:38.2874,lwr_k=20:141.0365,lwr_k=30:170.1247,lwr_k=40:237.6343,lwr_k=50:8734.4576,lwr_k=100:25.3087,lwr_k=200:18.0821,lwr_k=300:17.6566,lwr_k=400:17.5904,lwr_k=500:17.766,lwr_k=600:17.9242,lwr_k=700:18.3474,lwr_k=800:18.5488,lwr_k=900:18.6397,lwr_k=1000:18.6896'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:7.6942,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0532,lwr_k=40:0.208,lwr_k=50:4.5783,lwr_k=100:2.7195,lwr_k=200:4.3714,lwr_k=300:4.9311,lwr_k=400:5.3042,lwr_k=500:5.5992,lwr_k=600:5.7951,lwr_k=700:5.9205,lwr_k=800:6.1147,lwr_k=900:6.2331,lwr_k=1000:6.3397'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.9295,lwr_k=10:56.9009,lwr_k=20:120.2992,lwr_k=30:924.9973,lwr_k=40:2293.7739,lwr_k=50:6138.2983,lwr_k=100:32.3852,lwr_k=200:39.1973,lwr_k=300:14.7731,lwr_k=400:14.3312,lwr_k=500:8.7719,lwr_k=600:8.5503,lwr_k=700:10.7566,lwr_k=800:8.9461,lwr_k=900:8.9842,lwr_k=1000:8.9923'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_12'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.0571,lwr_k=10:6.4146,lwr_k=20:6.9303,lwr_k=30:7.0066,lwr_k=40:7.1264,lwr_k=50:7.203,lwr_k=100:7.5226,lwr_k=200:7.9784,lwr_k=300:8.1458,lwr_k=400:8.2173,lwr_k=500:8.2909,lwr_k=600:8.3366,lwr_k=700:8.3724,lwr_k=800:8.4341,lwr_k=900:8.504,lwr_k=1000:8.5702'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.3827,lwr_k=10:11.7954,lwr_k=20:10.1391,lwr_k=30:10.0613,lwr_k=40:9.598,lwr_k=50:9.735,lwr_k=100:9.8771,lwr_k=200:10.036,lwr_k=300:10.1972,lwr_k=400:10.2228,lwr_k=500:10.2924,lwr_k=600:10.3205,lwr_k=700:10.3812,lwr_k=800:10.4795,lwr_k=900:10.6028,lwr_k=1000:10.7417'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:13.0485,lwr_k=10:9.6597,lwr_k=20:10.3535,lwr_k=30:10.5432,lwr_k=40:10.8845,lwr_k=50:11.0438,lwr_k=100:11.4168,lwr_k=200:11.7472,lwr_k=300:11.8571,lwr_k=400:11.9157,lwr_k=500:11.96,lwr_k=600:11.9731,lwr_k=700:12.015,lwr_k=800:12.0372,lwr_k=900:12.06,lwr_k=1000:12.0714'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:12.5089,lwr_k=10:10.8735,lwr_k=20:10.3968,lwr_k=30:9.9146,lwr_k=40:9.6866,lwr_k=50:9.6598,lwr_k=100:9.6715,lwr_k=200:9.6999,lwr_k=300:9.6592,lwr_k=400:9.8306,lwr_k=500:9.9106,lwr_k=600:10.0312,lwr_k=700:10.4124,lwr_k=800:10.3886,lwr_k=900:10.4299,lwr_k=1000:10.4531'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.9282,lwr_k=10:6.8842,lwr_k=20:7.3879,lwr_k=30:7.7617,lwr_k=40:8.0246,lwr_k=50:8.1151,lwr_k=100:8.5911,lwr_k=200:8.9103,lwr_k=300:9.0551,lwr_k=400:9.2054,lwr_k=500:9.2846,lwr_k=600:9.3238,lwr_k=700:9.3575,lwr_k=800:9.4003,lwr_k=900:9.4567,lwr_k=1000:9.5297'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.1273,lwr_k=10:11.1631,lwr_k=20:46.5257,lwr_k=30:37.5501,lwr_k=40:31.516,lwr_k=50:8.9359,lwr_k=100:8.1837,lwr_k=200:7.7324,lwr_k=300:7.6491,lwr_k=400:7.6439,lwr_k=500:7.6496,lwr_k=600:7.6427,lwr_k=700:7.6643,lwr_k=800:7.684,lwr_k=900:7.7149,lwr_k=1000:7.7538'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:12.2768,lwr_k=10:7.5529,lwr_k=20:8.4459,lwr_k=30:8.9258,lwr_k=40:9.253,lwr_k=50:9.4213,lwr_k=100:10.5403,lwr_k=200:10.9352,lwr_k=300:11.0045,lwr_k=400:11.0487,lwr_k=500:11.1,lwr_k=600:11.092,lwr_k=700:11.1435,lwr_k=800:11.187,lwr_k=900:11.2683,lwr_k=1000:11.3405'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:12.9171,lwr_k=10:13.4724,lwr_k=20:11.9731,lwr_k=30:11.7797,lwr_k=40:12.0016,lwr_k=50:11.7613,lwr_k=100:11.8927,lwr_k=200:11.9798,lwr_k=300:11.9148,lwr_k=400:11.9217,lwr_k=500:11.9434,lwr_k=600:11.9992,lwr_k=700:12.0625,lwr_k=800:12.1904,lwr_k=900:12.261,lwr_k=1000:12.3051'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.8868,lwr_k=10:6.4827,lwr_k=20:7.1329,lwr_k=30:7.1955,lwr_k=40:7.3082,lwr_k=50:7.429,lwr_k=100:7.5278,lwr_k=200:7.7052,lwr_k=300:7.759,lwr_k=400:7.8177,lwr_k=500:7.8708,lwr_k=600:7.9268,lwr_k=700:7.9697,lwr_k=800:8.0127,lwr_k=900:8.0869,lwr_k=1000:8.1647'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:23.3269,lwr_k=10:20.9059,lwr_k=20:17.0315,lwr_k=30:18.4219,lwr_k=40:19.5656,lwr_k=50:20.5317,lwr_k=100:21.8311,lwr_k=200:22.4677,lwr_k=300:22.605,lwr_k=400:22.534,lwr_k=500:22.6251,lwr_k=600:22.6695,lwr_k=700:22.6735,lwr_k=800:22.5731,lwr_k=900:22.6332,lwr_k=1000:22.6632'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:9.6128,lwr_k=10:6.6619,lwr_k=20:7.2499,lwr_k=30:7.5077,lwr_k=40:7.7548,lwr_k=50:7.834,lwr_k=100:8.3428,lwr_k=200:8.5743,lwr_k=300:8.6665,lwr_k=400:8.7228,lwr_k=500:8.7874,lwr_k=600:8.8085,lwr_k=700:8.8978,lwr_k=800:8.9347,lwr_k=900:8.9999,lwr_k=1000:9.0425'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.4183,lwr_k=10:11.5417,lwr_k=20:11.2302,lwr_k=30:11.1932,lwr_k=40:10.9552,lwr_k=50:10.9382,lwr_k=100:11.1494,lwr_k=200:10.8358,lwr_k=300:10.8383,lwr_k=400:11.0075,lwr_k=500:11.0568,lwr_k=600:11.1541,lwr_k=700:11.2347,lwr_k=800:11.306,lwr_k=900:11.3306,lwr_k=1000:11.3616'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_13'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.3246,lwr_k=10:0.0008,lwr_k=20:2.8156,lwr_k=30:3.6952,lwr_k=40:4.3528,lwr_k=50:4.6594,lwr_k=100:5.2275,lwr_k=200:5.6011,lwr_k=300:5.691,lwr_k=400:5.7281,lwr_k=500:5.753,lwr_k=600:5.7921,lwr_k=700:5.8456,lwr_k=800:5.8786,lwr_k=900:5.914,lwr_k=1000:5.9564'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.0937,lwr_k=10:15537.5585,lwr_k=20:13.6064,lwr_k=30:9.9313,lwr_k=40:9.1072,lwr_k=50:8.3509,lwr_k=100:8.0887,lwr_k=200:8.1387,lwr_k=300:8.1763,lwr_k=400:8.2364,lwr_k=500:8.2684,lwr_k=600:8.3388,lwr_k=700:8.3897,lwr_k=800:8.4211,lwr_k=900:8.4444,lwr_k=1000:8.5089'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.4344,lwr_k=10:0.0001,lwr_k=20:2.711,lwr_k=30:3.7196,lwr_k=40:4.2429,lwr_k=50:4.5344,lwr_k=100:5.5694,lwr_k=200:6.1746,lwr_k=300:6.7287,lwr_k=400:6.9688,lwr_k=500:7.1317,lwr_k=600:7.2374,lwr_k=700:7.3779,lwr_k=800:7.4916,lwr_k=900:7.5784,lwr_k=1000:7.6355'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.4097,lwr_k=10:2189.3745,lwr_k=20:10.8848,lwr_k=30:6.7284,lwr_k=40:6.4294,lwr_k=50:6.2875,lwr_k=100:6.3002,lwr_k=200:6.2876,lwr_k=300:6.3343,lwr_k=400:6.3594,lwr_k=500:6.4081,lwr_k=600:6.4203,lwr_k=700:6.4746,lwr_k=800:6.4815,lwr_k=900:6.4964,lwr_k=1000:6.514'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.8277,lwr_k=10:0.0,lwr_k=20:2.6837,lwr_k=30:3.5948,lwr_k=40:4.2985,lwr_k=50:4.6234,lwr_k=100:5.8214,lwr_k=200:6.5644,lwr_k=300:6.9933,lwr_k=400:7.2983,lwr_k=500:7.5036,lwr_k=600:7.6461,lwr_k=700:7.8814,lwr_k=800:8.0681,lwr_k=900:8.1805,lwr_k=1000:8.3482'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.9666,lwr_k=10:56640.5745,lwr_k=20:8.1754,lwr_k=30:6.7382,lwr_k=40:6.1809,lwr_k=50:6.1268,lwr_k=100:5.4942,lwr_k=200:5.2648,lwr_k=300:5.2986,lwr_k=400:5.3067,lwr_k=500:5.2995,lwr_k=600:5.3068,lwr_k=700:5.292,lwr_k=800:5.3234,lwr_k=900:5.3607,lwr_k=1000:5.3685'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.1697,lwr_k=10:0.0,lwr_k=20:2.8009,lwr_k=30:3.8937,lwr_k=40:4.7233,lwr_k=50:5.188,lwr_k=100:6.2619,lwr_k=200:6.8241,lwr_k=300:7.1599,lwr_k=400:7.4303,lwr_k=500:7.5551,lwr_k=600:7.6628,lwr_k=700:7.7691,lwr_k=800:7.8506,lwr_k=900:7.9481,lwr_k=1000:8.0463'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.6989,lwr_k=10:2596.5578,lwr_k=20:10.2997,lwr_k=30:8.0677,lwr_k=40:7.7453,lwr_k=50:7.3035,lwr_k=100:6.8995,lwr_k=200:7.2892,lwr_k=300:7.2052,lwr_k=400:7.1338,lwr_k=500:7.1299,lwr_k=600:7.1614,lwr_k=700:7.1434,lwr_k=800:7.1719,lwr_k=900:7.1704,lwr_k=1000:7.1945'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.4135,lwr_k=10:0.0,lwr_k=20:2.8009,lwr_k=30:3.3842,lwr_k=40:3.8987,lwr_k=50:4.0636,lwr_k=100:4.4775,lwr_k=200:4.7182,lwr_k=300:4.8172,lwr_k=400:4.888,lwr_k=500:4.9176,lwr_k=600:4.9373,lwr_k=700:4.9615,lwr_k=800:4.9865,lwr_k=900:5.01,lwr_k=1000:5.0384'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:19.8932,lwr_k=10:126637.483,lwr_k=20:14.8468,lwr_k=30:17.7211,lwr_k=40:17.4927,lwr_k=50:17.4123,lwr_k=100:18.6565,lwr_k=200:19.2362,lwr_k=300:19.2289,lwr_k=400:19.1827,lwr_k=500:19.2351,lwr_k=600:19.2104,lwr_k=700:19.1172,lwr_k=800:19.1235,lwr_k=900:19.1414,lwr_k=1000:19.1865'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:9.0099,lwr_k=10:0.0,lwr_k=20:2.8719,lwr_k=30:3.8415,lwr_k=40:4.2388,lwr_k=50:4.5808,lwr_k=100:5.7612,lwr_k=200:6.5738,lwr_k=300:6.8552,lwr_k=400:6.9764,lwr_k=500:7.0377,lwr_k=600:7.1144,lwr_k=700:7.1833,lwr_k=800:7.2345,lwr_k=900:7.2994,lwr_k=1000:7.3625'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.863,lwr_k=10:13234.667,lwr_k=20:13.5746,lwr_k=30:9.3251,lwr_k=40:7.7655,lwr_k=50:7.3425,lwr_k=100:7.1137,lwr_k=200:7.6534,lwr_k=300:7.8614,lwr_k=400:7.8769,lwr_k=500:7.8751,lwr_k=600:7.849,lwr_k=700:7.8886,lwr_k=800:7.9613,lwr_k=900:7.9914,lwr_k=1000:8.037'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_14'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:54.084,lwr_k=10:45.4625,lwr_k=20:46.8018,lwr_k=30:46.0773,lwr_k=40:46.1291,lwr_k=50:46.4224,lwr_k=100:46.403,lwr_k=200:46.7002,lwr_k=300:47.2934,lwr_k=400:48.2813,lwr_k=500:48.7317,lwr_k=600:48.8826,lwr_k=700:48.9932,lwr_k=800:49.1404,lwr_k=900:49.3812,lwr_k=1000:49.5782'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:85.2198,lwr_k=10:71.5143,lwr_k=20:74.7992,lwr_k=30:71.1496,lwr_k=40:71.2966,lwr_k=50:69.2294,lwr_k=100:71.4913,lwr_k=200:72.2593,lwr_k=300:72.507,lwr_k=400:74.4666,lwr_k=500:75.4074,lwr_k=600:75.8896,lwr_k=700:76.2789,lwr_k=800:76.5783,lwr_k=900:76.9026,lwr_k=1000:77.2272'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:233.0272,lwr_k=10:215.7284,lwr_k=20:231.6988,lwr_k=30:226.182,lwr_k=40:228.1956,lwr_k=50:225.6936,lwr_k=100:229.8587,lwr_k=200:230.0001,lwr_k=300:229.38,lwr_k=400:229.7132,lwr_k=500:230.003,lwr_k=600:230.0787,lwr_k=700:230.3375,lwr_k=800:230.2145,lwr_k=900:230.0876,lwr_k=1000:230.1776'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:197.783,lwr_k=10:218.3368,lwr_k=20:207.3408,lwr_k=30:202.6823,lwr_k=40:202.6257,lwr_k=50:201.0194,lwr_k=100:198.5066,lwr_k=200:197.1093,lwr_k=300:197.1745,lwr_k=400:197.0049,lwr_k=500:196.724,lwr_k=600:197.0813,lwr_k=700:196.9087,lwr_k=800:197.0405,lwr_k=900:197.0524,lwr_k=1000:197.0073'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:53.7655,lwr_k=10:24.919,lwr_k=20:29.1845,lwr_k=30:29.7565,lwr_k=40:30.4758,lwr_k=50:31.0758,lwr_k=100:32.595,lwr_k=200:34.5725,lwr_k=300:35.9788,lwr_k=400:36.9359,lwr_k=500:37.6431,lwr_k=600:38.2362,lwr_k=700:38.8999,lwr_k=800:39.4703,lwr_k=900:40.0904,lwr_k=1000:40.6661'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:38.3867,lwr_k=10:34.1963,lwr_k=20:30.6156,lwr_k=30:29.9575,lwr_k=40:29.4745,lwr_k=50:29.1784,lwr_k=100:29.5653,lwr_k=200:29.4956,lwr_k=300:29.8051,lwr_k=400:29.9674,lwr_k=500:29.946,lwr_k=600:30.1594,lwr_k=700:30.2537,lwr_k=800:30.3593,lwr_k=900:30.4206,lwr_k=1000:30.4512'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:18.7512,lwr_k=10:9.2529,lwr_k=20:11.9577,lwr_k=30:13.0953,lwr_k=40:13.9008,lwr_k=50:14.3492,lwr_k=100:15.3698,lwr_k=200:15.7919,lwr_k=300:16.1662,lwr_k=400:16.4039,lwr_k=500:16.5597,lwr_k=600:16.6456,lwr_k=700:16.6833,lwr_k=800:16.735,lwr_k=900:16.8463,lwr_k=1000:16.9634'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:15.6472,lwr_k=10:19.4741,lwr_k=20:16.083,lwr_k=30:15.9339,lwr_k=40:15.2699,lwr_k=50:14.7946,lwr_k=100:13.9602,lwr_k=200:13.8254,lwr_k=300:13.9033,lwr_k=400:13.9218,lwr_k=500:13.9987,lwr_k=600:14.0721,lwr_k=700:14.1276,lwr_k=800:14.1075,lwr_k=900:14.127,lwr_k=1000:14.151'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:12.3863,lwr_k=10:7.0467,lwr_k=20:8.6694,lwr_k=30:8.9443,lwr_k=40:9.2093,lwr_k=50:9.3157,lwr_k=100:9.6661,lwr_k=200:9.951,lwr_k=300:10.1303,lwr_k=400:10.2842,lwr_k=500:10.4301,lwr_k=600:10.524,lwr_k=700:10.6378,lwr_k=800:10.7418,lwr_k=900:10.8379,lwr_k=1000:10.9086'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:37.7655,lwr_k=10:31.9226,lwr_k=20:22.8442,lwr_k=30:23.4153,lwr_k=40:25.6031,lwr_k=50:25.8131,lwr_k=100:27.2452,lwr_k=200:29.5302,lwr_k=300:30.6304,lwr_k=400:31.423,lwr_k=500:32.2315,lwr_k=600:32.7308,lwr_k=700:33.1871,lwr_k=800:33.5494,lwr_k=900:33.9038,lwr_k=1000:34.185'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:41.4221,lwr_k=10:19.1401,lwr_k=20:21.1699,lwr_k=30:22.1968,lwr_k=40:22.8991,lwr_k=50:23.341,lwr_k=100:24.5144,lwr_k=200:25.9554,lwr_k=300:26.8792,lwr_k=400:27.5642,lwr_k=500:28.2314,lwr_k=600:28.6735,lwr_k=700:29.1594,lwr_k=800:29.5578,lwr_k=900:29.9563,lwr_k=1000:30.3045'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:35.9271,lwr_k=10:32.4721,lwr_k=20:29.0663,lwr_k=30:28.1128,lwr_k=40:27.7535,lwr_k=50:26.893,lwr_k=100:24.5889,lwr_k=200:23.3893,lwr_k=300:23.0693,lwr_k=400:23.2342,lwr_k=500:23.4561,lwr_k=600:23.6889,lwr_k=700:23.8135,lwr_k=800:24.0771,lwr_k=900:24.3173,lwr_k=1000:24.6184'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_15'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.523,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0011,lwr_k=40:1.0147,lwr_k=50:1.7186,lwr_k=100:3.2101,lwr_k=200:4.2681,lwr_k=300:4.6876,lwr_k=400:4.9315,lwr_k=500:5.1398,lwr_k=600:5.2838,lwr_k=700:5.3994,lwr_k=800:5.4692,lwr_k=900:5.54,lwr_k=1000:5.6018'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.3374,lwr_k=10:30.7632,lwr_k=20:56.5211,lwr_k=30:7796.3019,lwr_k=40:17.5462,lwr_k=50:10.2543,lwr_k=100:7.8153,lwr_k=200:7.8164,lwr_k=300:8.1007,lwr_k=400:8.3174,lwr_k=500:8.4341,lwr_k=600:8.5031,lwr_k=700:8.5705,lwr_k=800:8.7338,lwr_k=900:8.8559,lwr_k=1000:8.9946'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:18.9347,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0029,lwr_k=40:1.5506,lwr_k=50:2.4451,lwr_k=100:5.3927,lwr_k=200:8.3154,lwr_k=300:9.4138,lwr_k=400:10.2096,lwr_k=500:10.676,lwr_k=600:11.219,lwr_k=700:11.6438,lwr_k=800:12.0629,lwr_k=900:12.3935,lwr_k=1000:12.7165'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:15.5411,lwr_k=10:40.8879,lwr_k=20:62.6975,lwr_k=30:16575.5716,lwr_k=40:28.6322,lwr_k=50:17.4316,lwr_k=100:8.7603,lwr_k=200:7.5024,lwr_k=300:7.7093,lwr_k=400:8.0114,lwr_k=500:8.2531,lwr_k=600:8.5023,lwr_k=700:8.9379,lwr_k=800:9.2075,lwr_k=900:9.3337,lwr_k=1000:9.4086'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:16.2533,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0009,lwr_k=40:1.2996,lwr_k=50:2.5101,lwr_k=100:5.5775,lwr_k=200:7.7758,lwr_k=300:8.8562,lwr_k=400:9.5928,lwr_k=500:10.0854,lwr_k=600:10.5034,lwr_k=700:10.9289,lwr_k=800:11.1427,lwr_k=900:11.4227,lwr_k=1000:11.6416'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:10.8806,lwr_k=10:37.3845,lwr_k=20:47.7171,lwr_k=30:14728.0715,lwr_k=40:29.2366,lwr_k=50:21.1541,lwr_k=100:8.7968,lwr_k=200:7.4391,lwr_k=300:6.9886,lwr_k=400:7.1151,lwr_k=500:7.0241,lwr_k=600:7.0693,lwr_k=700:7.2858,lwr_k=800:7.4135,lwr_k=900:7.4554,lwr_k=1000:7.5242'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:18.9198,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0009,lwr_k=40:1.5524,lwr_k=50:2.6459,lwr_k=100:5.7074,lwr_k=200:8.502,lwr_k=300:9.7126,lwr_k=400:10.4114,lwr_k=500:10.9303,lwr_k=600:11.4483,lwr_k=700:11.8716,lwr_k=800:12.2638,lwr_k=900:12.5619,lwr_k=1000:12.8486'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:15.5253,lwr_k=10:36.9837,lwr_k=20:79.9553,lwr_k=30:6081.126,lwr_k=40:29.8593,lwr_k=50:18.3234,lwr_k=100:10.6891,lwr_k=200:9.3944,lwr_k=300:9.634,lwr_k=400:9.6603,lwr_k=500:9.7788,lwr_k=600:10.0327,lwr_k=700:10.299,lwr_k=800:10.5129,lwr_k=900:10.5978,lwr_k=1000:10.7153'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.1518,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0098,lwr_k=40:1.3403,lwr_k=50:2.0161,lwr_k=100:4.0152,lwr_k=200:5.3359,lwr_k=300:5.808,lwr_k=400:6.0937,lwr_k=500:6.3406,lwr_k=600:6.5314,lwr_k=700:6.673,lwr_k=800:6.8135,lwr_k=900:6.893,lwr_k=1000:6.9937'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:30.5648,lwr_k=10:35.2817,lwr_k=20:62.2322,lwr_k=30:12512.7957,lwr_k=40:33.4442,lwr_k=50:24.1849,lwr_k=100:18.5528,lwr_k=200:20.1244,lwr_k=300:20.7679,lwr_k=400:21.9527,lwr_k=500:22.1503,lwr_k=600:22.4482,lwr_k=700:23.1409,lwr_k=800:23.6022,lwr_k=900:24.0418,lwr_k=1000:24.2104'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:10.004,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0003,lwr_k=40:1.1018,lwr_k=50:1.9848,lwr_k=100:3.7408,lwr_k=200:5.3936,lwr_k=300:6.0623,lwr_k=400:6.5228,lwr_k=500:6.807,lwr_k=600:7.0307,lwr_k=700:7.2083,lwr_k=800:7.3043,lwr_k=900:7.4501,lwr_k=1000:7.5723'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:13.39,lwr_k=10:33.2501,lwr_k=20:30.9123,lwr_k=30:11481.3665,lwr_k=40:21.0928,lwr_k=50:11.6506,lwr_k=100:9.3556,lwr_k=200:9.1507,lwr_k=300:9.609,lwr_k=400:10.0105,lwr_k=500:10.3224,lwr_k=600:10.7128,lwr_k=700:10.8506,lwr_k=800:11.0333,lwr_k=900:11.1743,lwr_k=1000:11.3574'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_16'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.152,lwr_k=10:6.1766,lwr_k=20:6.942,lwr_k=30:7.1088,lwr_k=40:7.2817,lwr_k=50:7.3896,lwr_k=100:7.484,lwr_k=200:7.5467,lwr_k=300:7.6066,lwr_k=400:7.679,lwr_k=500:7.7232,lwr_k=600:7.7363,lwr_k=700:7.7605,lwr_k=800:7.7693,lwr_k=900:7.7969,lwr_k=1000:7.8076'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.4163,lwr_k=10:11.6758,lwr_k=20:10.1285,lwr_k=30:10.2652,lwr_k=40:9.8567,lwr_k=50:9.3302,lwr_k=100:9.3902,lwr_k=200:9.5243,lwr_k=300:9.6007,lwr_k=400:9.6755,lwr_k=500:9.7445,lwr_k=600:9.7813,lwr_k=700:9.8367,lwr_k=800:9.8847,lwr_k=900:9.9193,lwr_k=1000:9.9421'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.3174,lwr_k=10:5.3106,lwr_k=20:6.4164,lwr_k=30:6.8901,lwr_k=40:7.2216,lwr_k=50:7.4394,lwr_k=100:8.118,lwr_k=200:8.5534,lwr_k=300:8.7909,lwr_k=400:8.9314,lwr_k=500:8.9312,lwr_k=600:8.9883,lwr_k=700:9.0235,lwr_k=800:9.028,lwr_k=900:9.0574,lwr_k=1000:9.0963'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.7346,lwr_k=10:9.6112,lwr_k=20:8.123,lwr_k=30:7.5254,lwr_k=40:7.0483,lwr_k=50:6.9379,lwr_k=100:7.0554,lwr_k=200:7.1561,lwr_k=300:7.2839,lwr_k=400:7.239,lwr_k=500:7.3122,lwr_k=600:7.3244,lwr_k=700:7.2991,lwr_k=800:7.3497,lwr_k=900:7.2739,lwr_k=1000:7.2928'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.4067,lwr_k=10:4.8455,lwr_k=20:5.6747,lwr_k=30:6.0247,lwr_k=40:6.5243,lwr_k=50:6.8505,lwr_k=100:7.7029,lwr_k=200:8.5693,lwr_k=300:8.6219,lwr_k=400:8.763,lwr_k=500:8.8828,lwr_k=600:8.9105,lwr_k=700:8.9286,lwr_k=800:8.9671,lwr_k=900:8.9624,lwr_k=1000:8.9851'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.8478,lwr_k=10:7.7656,lwr_k=20:7.5165,lwr_k=30:6.9901,lwr_k=40:6.6426,lwr_k=50:6.6297,lwr_k=100:6.1353,lwr_k=200:6.075,lwr_k=300:5.9358,lwr_k=400:5.9996,lwr_k=500:6.0075,lwr_k=600:6.0361,lwr_k=700:6.0691,lwr_k=800:6.8947,lwr_k=900:6.4844,lwr_k=1000:7.1926'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.4125,lwr_k=10:5.5783,lwr_k=20:6.4247,lwr_k=30:6.7745,lwr_k=40:6.9813,lwr_k=50:7.0973,lwr_k=100:7.3151,lwr_k=200:7.5969,lwr_k=300:7.6286,lwr_k=400:7.7083,lwr_k=500:7.7594,lwr_k=600:7.8115,lwr_k=700:7.8579,lwr_k=800:7.9041,lwr_k=900:7.946,lwr_k=1000:7.9761'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:10.1455,lwr_k=10:9.8595,lwr_k=20:9.5673,lwr_k=30:9.31,lwr_k=40:9.3685,lwr_k=50:9.2478,lwr_k=100:9.1063,lwr_k=200:9.6032,lwr_k=300:9.7108,lwr_k=400:9.7548,lwr_k=500:9.7496,lwr_k=600:9.8069,lwr_k=700:9.8373,lwr_k=800:9.8585,lwr_k=900:9.8645,lwr_k=1000:9.8894'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.5708,lwr_k=10:6.1253,lwr_k=20:6.9487,lwr_k=30:7.2372,lwr_k=40:7.4463,lwr_k=50:7.5214,lwr_k=100:7.7039,lwr_k=200:7.8964,lwr_k=300:7.9504,lwr_k=400:7.9643,lwr_k=500:8.0069,lwr_k=600:8.141,lwr_k=700:8.4846,lwr_k=800:8.8333,lwr_k=900:8.9965,lwr_k=1000:9.1337'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:18.2566,lwr_k=10:23.2577,lwr_k=20:21.5474,lwr_k=30:23.5678,lwr_k=40:18.8301,lwr_k=50:18.6523,lwr_k=100:17.8058,lwr_k=200:18.1135,lwr_k=300:18.1681,lwr_k=400:18.1308,lwr_k=500:18.06,lwr_k=600:17.795,lwr_k=700:17.5147,lwr_k=800:17.7599,lwr_k=900:17.7513,lwr_k=1000:17.8155'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:8.4667,lwr_k=10:6.1595,lwr_k=20:6.7954,lwr_k=30:6.9255,lwr_k=40:6.9594,lwr_k=50:7.0344,lwr_k=100:7.1972,lwr_k=200:7.4595,lwr_k=300:7.6798,lwr_k=400:7.7015,lwr_k=500:7.712,lwr_k=600:7.7504,lwr_k=700:7.7638,lwr_k=800:7.8029,lwr_k=900:7.8146,lwr_k=1000:7.8503'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:13.6631,lwr_k=10:12.5466,lwr_k=20:11.8523,lwr_k=30:11.6532,lwr_k=40:11.6797,lwr_k=50:11.7068,lwr_k=100:11.8133,lwr_k=200:12.0337,lwr_k=300:12.492,lwr_k=400:12.6613,lwr_k=500:12.751,lwr_k=600:12.7981,lwr_k=700:12.8537,lwr_k=800:12.8381,lwr_k=900:12.8656,lwr_k=1000:12.8505'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_17'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5933,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.006,lwr_k=40:0.6715,lwr_k=50:1.3877,lwr_k=100:2.8208,lwr_k=200:3.5761,lwr_k=300:3.7722,lwr_k=400:3.8902,lwr_k=500:3.9473,lwr_k=600:4.0261,lwr_k=700:4.0664,lwr_k=800:4.1023,lwr_k=900:4.1427,lwr_k=1000:4.1779'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:6.4908,lwr_k=10:51.8431,lwr_k=20:60.9652,lwr_k=30:192.1818,lwr_k=40:79.7361,lwr_k=50:22.3189,lwr_k=100:8.8236,lwr_k=200:7.002,lwr_k=300:6.4462,lwr_k=400:6.2757,lwr_k=500:6.1549,lwr_k=600:6.1231,lwr_k=700:6.1171,lwr_k=800:6.1005,lwr_k=900:6.1012,lwr_k=1000:6.0975'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.3187,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0001,lwr_k=40:0.8492,lwr_k=50:1.6803,lwr_k=100:4.0363,lwr_k=200:5.7999,lwr_k=300:6.6579,lwr_k=400:7.003,lwr_k=500:7.2157,lwr_k=600:7.4394,lwr_k=700:7.5564,lwr_k=800:7.6932,lwr_k=900:7.7875,lwr_k=1000:7.9011'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.8566,lwr_k=10:25.9887,lwr_k=20:53.1671,lwr_k=30:284.7901,lwr_k=40:60.7792,lwr_k=50:41.97,lwr_k=100:8.9062,lwr_k=200:6.8434,lwr_k=300:6.6877,lwr_k=400:6.6568,lwr_k=500:6.7282,lwr_k=600:6.7982,lwr_k=700:6.7618,lwr_k=800:6.8352,lwr_k=900:6.8893,lwr_k=1000:6.9404'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.7031,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0093,lwr_k=40:0.8792,lwr_k=50:1.869,lwr_k=100:4.0449,lwr_k=200:5.3748,lwr_k=300:5.7876,lwr_k=400:6.0817,lwr_k=500:6.3197,lwr_k=600:6.4794,lwr_k=700:6.6613,lwr_k=800:6.7838,lwr_k=900:6.8721,lwr_k=1000:6.9585'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.212,lwr_k=10:34.4778,lwr_k=20:67.1106,lwr_k=30:99.4604,lwr_k=40:47.7814,lwr_k=50:16.9146,lwr_k=100:6.9242,lwr_k=200:5.7839,lwr_k=300:5.7333,lwr_k=400:5.6412,lwr_k=500:5.6318,lwr_k=600:5.6116,lwr_k=700:5.6212,lwr_k=800:5.6437,lwr_k=900:5.6327,lwr_k=1000:5.6359'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.8487,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0031,lwr_k=40:0.6757,lwr_k=50:1.5386,lwr_k=100:3.5613,lwr_k=200:4.8824,lwr_k=300:5.432,lwr_k=400:5.7618,lwr_k=500:6.0087,lwr_k=600:6.3016,lwr_k=700:6.4106,lwr_k=800:6.4979,lwr_k=900:6.6326,lwr_k=1000:6.7846'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.9833,lwr_k=10:17.7381,lwr_k=20:72.0229,lwr_k=30:384.8797,lwr_k=40:94.813,lwr_k=50:17.7091,lwr_k=100:8.7688,lwr_k=200:7.7344,lwr_k=300:7.4239,lwr_k=400:7.438,lwr_k=500:7.2957,lwr_k=600:7.0777,lwr_k=700:7.068,lwr_k=800:7.0438,lwr_k=900:7.0336,lwr_k=1000:7.0537'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.6128,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0001,lwr_k=40:0.6894,lwr_k=50:1.4957,lwr_k=100:2.6299,lwr_k=200:3.2423,lwr_k=300:3.4897,lwr_k=400:3.664,lwr_k=500:3.7572,lwr_k=600:3.8487,lwr_k=700:3.926,lwr_k=800:3.9534,lwr_k=900:3.9922,lwr_k=1000:4.0275'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:18.6873,lwr_k=10:63.632,lwr_k=20:145.5108,lwr_k=30:317.495,lwr_k=40:66.6449,lwr_k=50:20.0456,lwr_k=100:16.1664,lwr_k=200:15.6338,lwr_k=300:15.9932,lwr_k=400:15.9421,lwr_k=500:15.9597,lwr_k=600:16.0006,lwr_k=700:15.9928,lwr_k=800:16.0356,lwr_k=900:16.0545,lwr_k=1000:16.0282'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:9.6678,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0185,lwr_k=40:0.9848,lwr_k=50:1.8389,lwr_k=100:4.7012,lwr_k=200:6.2458,lwr_k=300:6.7416,lwr_k=400:7.0353,lwr_k=500:7.2233,lwr_k=600:7.4114,lwr_k=700:7.5432,lwr_k=800:7.637,lwr_k=900:7.7399,lwr_k=1000:7.8226'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.9466,lwr_k=10:27.2727,lwr_k=20:95.715,lwr_k=30:278.2401,lwr_k=40:75.1592,lwr_k=50:26.8834,lwr_k=100:9.4179,lwr_k=200:8.4899,lwr_k=300:8.4037,lwr_k=400:8.4324,lwr_k=500:8.4602,lwr_k=600:8.621,lwr_k=700:8.7902,lwr_k=800:8.8686,lwr_k=900:8.9964,lwr_k=1000:9.1505'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_18'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.378,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0191,lwr_k=40:2.51,lwr_k=50:1.5167,lwr_k=100:3.7217,lwr_k=200:5.2976,lwr_k=300:5.8292,lwr_k=400:6.126,lwr_k=500:6.3669,lwr_k=600:6.5798,lwr_k=700:6.7722,lwr_k=800:6.9025,lwr_k=900:7.0271,lwr_k=1000:7.1292'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.9798,lwr_k=10:55.5387,lwr_k=20:55.3059,lwr_k=30:115.793,lwr_k=40:109.248,lwr_k=50:31.4735,lwr_k=100:10.4496,lwr_k=200:8.7481,lwr_k=300:9.2105,lwr_k=400:9.25,lwr_k=500:9.2982,lwr_k=600:9.4983,lwr_k=700:9.5935,lwr_k=800:9.7027,lwr_k=900:9.8169,lwr_k=1000:9.9528'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.8232,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0036,lwr_k=40:0.4647,lwr_k=50:1.2983,lwr_k=100:3.7587,lwr_k=200:5.4576,lwr_k=300:6.1641,lwr_k=400:6.5967,lwr_k=500:6.8494,lwr_k=600:7.0637,lwr_k=700:7.1457,lwr_k=800:7.2835,lwr_k=900:7.3839,lwr_k=1000:7.4477'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.5794,lwr_k=10:62.8192,lwr_k=20:45.9765,lwr_k=30:95.9622,lwr_k=40:87.6186,lwr_k=50:27.614,lwr_k=100:11.2823,lwr_k=200:8.2932,lwr_k=300:7.8419,lwr_k=400:7.6988,lwr_k=500:7.8604,lwr_k=600:7.83,lwr_k=700:7.9599,lwr_k=800:8.0489,lwr_k=900:8.1317,lwr_k=1000:8.157'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:11.5661,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.03,lwr_k=40:0.8391,lwr_k=50:1.8279,lwr_k=100:4.5887,lwr_k=200:6.6683,lwr_k=300:7.5778,lwr_k=400:8.1289,lwr_k=500:8.4783,lwr_k=600:8.7566,lwr_k=700:9.0492,lwr_k=800:9.3229,lwr_k=900:9.4543,lwr_k=1000:9.6017'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:9.5276,lwr_k=10:42.1676,lwr_k=20:41.8978,lwr_k=30:107.7627,lwr_k=40:155.9848,lwr_k=50:33.7622,lwr_k=100:10.5631,lwr_k=200:8.6037,lwr_k=300:8.2755,lwr_k=400:8.0848,lwr_k=500:7.966,lwr_k=600:8.1334,lwr_k=700:8.1188,lwr_k=800:8.1203,lwr_k=900:8.1761,lwr_k=1000:8.2944'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.1689,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0428,lwr_k=40:1.6764,lwr_k=50:1.7207,lwr_k=100:4.447,lwr_k=200:5.8184,lwr_k=300:6.5448,lwr_k=400:7.0043,lwr_k=500:7.3613,lwr_k=600:7.6268,lwr_k=700:7.7557,lwr_k=800:7.9562,lwr_k=900:8.0906,lwr_k=1000:8.2079'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:12.2558,lwr_k=10:39.8902,lwr_k=20:74.8975,lwr_k=30:132.5745,lwr_k=40:119.2613,lwr_k=50:28.0674,lwr_k=100:10.8184,lwr_k=200:9.5407,lwr_k=300:9.66,lwr_k=400:9.6601,lwr_k=500:9.7018,lwr_k=600:9.8653,lwr_k=700:9.8472,lwr_k=800:10.1036,lwr_k=900:10.2397,lwr_k=1000:10.402'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.9621,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0011,lwr_k=40:0.4897,lwr_k=50:1.4378,lwr_k=100:3.9023,lwr_k=200:5.289,lwr_k=300:5.9119,lwr_k=400:6.1913,lwr_k=500:6.4699,lwr_k=600:6.6927,lwr_k=700:6.8188,lwr_k=800:6.8898,lwr_k=900:6.9511,lwr_k=1000:7.0052'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:20.1725,lwr_k=10:37.747,lwr_k=20:195.0125,lwr_k=30:246.5511,lwr_k=40:241.5222,lwr_k=50:50.5832,lwr_k=100:20.0879,lwr_k=200:17.239,lwr_k=300:17.1004,lwr_k=400:17.7296,lwr_k=500:18.572,lwr_k=600:19.0673,lwr_k=700:19.1832,lwr_k=800:19.3417,lwr_k=900:19.3603,lwr_k=1000:19.3178'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:10.4365,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0095,lwr_k=40:0.4486,lwr_k=50:1.5027,lwr_k=100:3.7172,lwr_k=200:5.3079,lwr_k=300:6.273,lwr_k=400:6.7232,lwr_k=500:7.179,lwr_k=600:7.5335,lwr_k=700:7.809,lwr_k=800:7.963,lwr_k=900:8.1423,lwr_k=1000:8.3457'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.6026,lwr_k=10:41.0439,lwr_k=20:127.1657,lwr_k=30:231.4292,lwr_k=40:143.6337,lwr_k=50:40.9702,lwr_k=100:36.8171,lwr_k=200:12.3122,lwr_k=300:13.5247,lwr_k=400:20.2126,lwr_k=500:9.0905,lwr_k=600:8.941,lwr_k=700:8.7914,lwr_k=800:9.8544,lwr_k=900:10.4084,lwr_k=1000:10.6123'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_19'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.2575,lwr_k=10:6.797,lwr_k=20:7.2224,lwr_k=30:7.3963,lwr_k=40:7.5005,lwr_k=50:7.5733,lwr_k=100:7.7177,lwr_k=200:7.8765,lwr_k=300:7.8919,lwr_k=400:7.9323,lwr_k=500:7.9797,lwr_k=600:7.9806,lwr_k=700:7.9882,lwr_k=800:7.9942,lwr_k=900:8.0018,lwr_k=1000:8.007'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.7108,lwr_k=10:10.5764,lwr_k=20:10.0699,lwr_k=30:9.8918,lwr_k=40:9.8248,lwr_k=50:9.7249,lwr_k=100:9.5867,lwr_k=200:9.6454,lwr_k=300:9.6576,lwr_k=400:9.6229,lwr_k=500:9.629,lwr_k=600:9.5962,lwr_k=700:9.6009,lwr_k=800:9.588,lwr_k=900:9.5887,lwr_k=1000:9.6136'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:28.1426,lwr_k=10:21.0822,lwr_k=20:22.5524,lwr_k=30:23.5377,lwr_k=40:24.0061,lwr_k=50:24.249,lwr_k=100:25.2358,lwr_k=200:25.4308,lwr_k=300:25.5822,lwr_k=400:25.6447,lwr_k=500:25.7775,lwr_k=600:25.8127,lwr_k=700:25.8533,lwr_k=800:25.8601,lwr_k=900:25.8693,lwr_k=1000:25.8573'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:23.3885,lwr_k=10:23.6564,lwr_k=20:46.9561,lwr_k=30:43.6121,lwr_k=40:22.3981,lwr_k=50:22.2352,lwr_k=100:21.8275,lwr_k=200:21.6423,lwr_k=300:21.7092,lwr_k=400:21.713,lwr_k=500:21.6802,lwr_k=600:21.752,lwr_k=700:21.7284,lwr_k=800:21.7587,lwr_k=900:21.7511,lwr_k=1000:21.7563'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.2069,lwr_k=10:7.7761,lwr_k=20:8.0211,lwr_k=30:8.213,lwr_k=40:8.2365,lwr_k=50:8.3213,lwr_k=100:8.3746,lwr_k=200:8.4431,lwr_k=300:8.5859,lwr_k=400:8.6432,lwr_k=500:8.6405,lwr_k=600:8.6554,lwr_k=700:8.6609,lwr_k=800:8.671,lwr_k=900:8.6954,lwr_k=1000:8.7247'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.9194,lwr_k=10:9.4124,lwr_k=20:8.8097,lwr_k=30:8.4733,lwr_k=40:8.5872,lwr_k=50:8.7681,lwr_k=100:8.5362,lwr_k=200:8.7171,lwr_k=300:8.3321,lwr_k=400:8.4333,lwr_k=500:8.4374,lwr_k=600:8.481,lwr_k=700:8.5258,lwr_k=800:8.5196,lwr_k=900:8.5446,lwr_k=1000:8.5605'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:11.9637,lwr_k=10:7.9761,lwr_k=20:8.3747,lwr_k=30:8.7166,lwr_k=40:9.1149,lwr_k=50:9.5403,lwr_k=100:10.2885,lwr_k=200:10.8692,lwr_k=300:11.0672,lwr_k=400:11.1605,lwr_k=500:11.2486,lwr_k=600:11.2878,lwr_k=700:11.2965,lwr_k=800:11.3209,lwr_k=900:11.3281,lwr_k=1000:11.3509'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:10.2743,lwr_k=10:10.7459,lwr_k=20:10.4976,lwr_k=30:10.3125,lwr_k=40:10.1411,lwr_k=50:10.1287,lwr_k=100:10.0721,lwr_k=200:9.8524,lwr_k=300:9.79,lwr_k=400:9.9126,lwr_k=500:9.9519,lwr_k=600:9.996,lwr_k=700:10.0037,lwr_k=800:10.0096,lwr_k=900:10.0111,lwr_k=1000:10.0068'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:11.424,lwr_k=10:9.2034,lwr_k=20:9.6504,lwr_k=30:9.9087,lwr_k=40:9.9927,lwr_k=50:10.069,lwr_k=100:10.2308,lwr_k=200:10.421,lwr_k=300:10.5982,lwr_k=400:10.8192,lwr_k=500:10.879,lwr_k=600:10.9351,lwr_k=700:10.9631,lwr_k=800:10.9738,lwr_k=900:10.9902,lwr_k=1000:11.0034'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:19.866,lwr_k=10:32.1322,lwr_k=20:23.355,lwr_k=30:22.1723,lwr_k=40:22.4025,lwr_k=50:21.8683,lwr_k=100:20.8093,lwr_k=200:19.7139,lwr_k=300:19.2125,lwr_k=400:18.9637,lwr_k=500:18.9139,lwr_k=600:18.9407,lwr_k=700:18.97,lwr_k=800:19.0229,lwr_k=900:19.0291,lwr_k=1000:19.0667'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:8.2882,lwr_k=10:5.998,lwr_k=20:6.2509,lwr_k=30:6.474,lwr_k=40:6.6747,lwr_k=50:6.7471,lwr_k=100:6.9466,lwr_k=200:7.2772,lwr_k=300:7.4536,lwr_k=400:7.5902,lwr_k=500:7.6853,lwr_k=600:7.7358,lwr_k=700:7.7588,lwr_k=800:7.7764,lwr_k=900:7.796,lwr_k=1000:7.8068'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.0952,lwr_k=10:11.8001,lwr_k=20:10.9619,lwr_k=30:11.2018,lwr_k=40:11.1116,lwr_k=50:10.8556,lwr_k=100:10.622,lwr_k=200:10.331,lwr_k=300:10.383,lwr_k=400:10.5342,lwr_k=500:10.6464,lwr_k=600:10.6832,lwr_k=700:10.6912,lwr_k=800:10.703,lwr_k=900:10.7484,lwr_k=1000:10.5284'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_20'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:11.022,lwr_k=10:2.5776,lwr_k=20:5.5666,lwr_k=30:6.1897,lwr_k=40:6.6447,lwr_k=50:6.9047,lwr_k=100:7.5588,lwr_k=200:7.9709,lwr_k=300:8.2067,lwr_k=400:8.3621,lwr_k=500:8.4938,lwr_k=600:8.5955,lwr_k=700:8.7002,lwr_k=800:8.7677,lwr_k=900:8.8436,lwr_k=1000:8.9356'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:15.0183,lwr_k=10:32.3153,lwr_k=20:13.799,lwr_k=30:12.1282,lwr_k=40:10.9845,lwr_k=50:10.6583,lwr_k=100:9.9912,lwr_k=200:10.2594,lwr_k=300:10.64,lwr_k=400:10.9048,lwr_k=500:11.1466,lwr_k=600:11.3554,lwr_k=700:11.5632,lwr_k=800:11.6927,lwr_k=900:11.8321,lwr_k=1000:11.9998'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:22.0996,lwr_k=10:3.1538,lwr_k=20:6.8058,lwr_k=30:8.3229,lwr_k=40:9.5766,lwr_k=50:10.4009,lwr_k=100:12.4976,lwr_k=200:14.5397,lwr_k=300:15.2453,lwr_k=400:15.7836,lwr_k=500:16.1694,lwr_k=600:16.4952,lwr_k=700:16.8053,lwr_k=800:17.0764,lwr_k=900:17.3107,lwr_k=1000:17.4837'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:15.3228,lwr_k=10:34.065,lwr_k=20:13.9537,lwr_k=30:12.6777,lwr_k=40:12.7494,lwr_k=50:12.1772,lwr_k=100:11.866,lwr_k=200:11.6838,lwr_k=300:11.7633,lwr_k=400:11.829,lwr_k=500:11.9108,lwr_k=600:11.9743,lwr_k=700:12.1157,lwr_k=800:12.1858,lwr_k=900:12.2934,lwr_k=1000:12.3575'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:36.5163,lwr_k=10:4.0737,lwr_k=20:8.9635,lwr_k=30:10.7335,lwr_k=40:12.6497,lwr_k=50:13.9603,lwr_k=100:16.4847,lwr_k=200:18.2141,lwr_k=300:19.4184,lwr_k=400:20.3094,lwr_k=500:20.9367,lwr_k=600:21.5098,lwr_k=700:22.1107,lwr_k=800:22.647,lwr_k=900:23.2229,lwr_k=1000:23.6796'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:21.5659,lwr_k=10:49.6719,lwr_k=20:17.898,lwr_k=30:14.7607,lwr_k=40:13.8583,lwr_k=50:12.8743,lwr_k=100:12.2752,lwr_k=200:12.6021,lwr_k=300:13.0628,lwr_k=400:13.2589,lwr_k=500:13.6776,lwr_k=600:13.6716,lwr_k=700:13.8515,lwr_k=800:13.9877,lwr_k=900:14.1173,lwr_k=1000:14.3168'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:23.6691,lwr_k=10:3.5498,lwr_k=20:7.2431,lwr_k=30:8.815,lwr_k=40:9.8676,lwr_k=50:10.6066,lwr_k=100:12.8474,lwr_k=200:14.8416,lwr_k=300:15.7228,lwr_k=400:16.3398,lwr_k=500:16.7487,lwr_k=600:17.128,lwr_k=700:17.5015,lwr_k=800:17.7508,lwr_k=900:18.0097,lwr_k=1000:18.2305'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:19.5527,lwr_k=10:45.7762,lwr_k=20:16.7114,lwr_k=30:14.3394,lwr_k=40:13.4902,lwr_k=50:13.4298,lwr_k=100:13.2809,lwr_k=200:13.0059,lwr_k=300:13.4112,lwr_k=400:13.7086,lwr_k=500:13.996,lwr_k=600:14.198,lwr_k=700:14.3622,lwr_k=800:14.5323,lwr_k=900:14.6977,lwr_k=1000:14.7988'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:18.4894,lwr_k=10:3.566,lwr_k=20:7.1023,lwr_k=30:8.0591,lwr_k=40:8.5475,lwr_k=50:8.9865,lwr_k=100:9.7237,lwr_k=200:10.59,lwr_k=300:11.0243,lwr_k=400:11.357,lwr_k=500:11.6858,lwr_k=600:12.0016,lwr_k=700:12.3333,lwr_k=800:12.6756,lwr_k=900:12.8955,lwr_k=1000:13.1378'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:55.5578,lwr_k=10:54.2881,lwr_k=20:28.2641,lwr_k=30:25.8663,lwr_k=40:26.2107,lwr_k=50:27.1677,lwr_k=100:30.3457,lwr_k=200:33.8005,lwr_k=300:35.8171,lwr_k=400:37.254,lwr_k=500:38.462,lwr_k=600:39.8695,lwr_k=700:41.2202,lwr_k=800:42.384,lwr_k=900:43.155,lwr_k=1000:44.1271'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:14.8391,lwr_k=10:2.4105,lwr_k=20:5.2568,lwr_k=30:6.3681,lwr_k=40:7.1891,lwr_k=50:7.802,lwr_k=100:9.2742,lwr_k=200:10.2243,lwr_k=300:10.8482,lwr_k=400:11.1839,lwr_k=500:11.4734,lwr_k=600:11.7118,lwr_k=700:11.876,lwr_k=800:12.0053,lwr_k=900:12.1127,lwr_k=1000:12.2342'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:14.8074,lwr_k=10:24.9834,lwr_k=20:13.3643,lwr_k=30:11.0311,lwr_k=40:11.1854,lwr_k=50:10.96,lwr_k=100:11.408,lwr_k=200:11.969,lwr_k=300:12.4457,lwr_k=400:12.5348,lwr_k=500:12.6988,lwr_k=600:12.8294,lwr_k=700:12.9086,lwr_k=800:12.9645,lwr_k=900:13.0792,lwr_k=1000:13.2284'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_21'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:30.0231,lwr_k=10:17.7388,lwr_k=20:18.9812,lwr_k=30:19.4531,lwr_k=40:19.7086,lwr_k=50:19.9787,lwr_k=100:20.642,lwr_k=200:21.4215,lwr_k=300:21.8835,lwr_k=400:22.3568,lwr_k=500:22.6548,lwr_k=600:22.9646,lwr_k=700:23.2281,lwr_k=800:23.5047,lwr_k=900:23.7799,lwr_k=1000:24.1045'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:36.9521,lwr_k=10:307.9613,lwr_k=20:164.1765,lwr_k=30:39.5002,lwr_k=40:24.9612,lwr_k=50:24.9761,lwr_k=100:24.2557,lwr_k=200:24.4192,lwr_k=300:24.8763,lwr_k=400:25.5481,lwr_k=500:25.9684,lwr_k=600:26.4669,lwr_k=700:26.9035,lwr_k=800:27.3462,lwr_k=900:27.8149,lwr_k=1000:28.2806'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:225.3182,lwr_k=10:143.2157,lwr_k=20:170.048,lwr_k=30:176.6544,lwr_k=40:180.0868,lwr_k=50:181.7878,lwr_k=100:184.0285,lwr_k=200:189.0993,lwr_k=300:192.719,lwr_k=400:194.5424,lwr_k=500:195.9487,lwr_k=600:197.5298,lwr_k=700:198.5442,lwr_k=800:199.7749,lwr_k=900:200.7295,lwr_k=1000:201.7101'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:189.3441,lwr_k=10:192.5222,lwr_k=20:174.2545,lwr_k=30:168.0016,lwr_k=40:166.7107,lwr_k=50:162.4024,lwr_k=100:160.1366,lwr_k=200:160.4974,lwr_k=300:160.74,lwr_k=400:161.6915,lwr_k=500:162.9067,lwr_k=600:163.6031,lwr_k=700:164.6342,lwr_k=800:166.024,lwr_k=900:167.3313,lwr_k=1000:168.5112'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:43.7212,lwr_k=10:20.3053,lwr_k=20:23.2447,lwr_k=30:24.3229,lwr_k=40:25.1768,lwr_k=50:25.8673,lwr_k=100:27.6077,lwr_k=200:29.3715,lwr_k=300:30.5593,lwr_k=400:31.2344,lwr_k=500:31.8237,lwr_k=600:32.3036,lwr_k=700:32.78,lwr_k=800:33.2413,lwr_k=900:33.7601,lwr_k=1000:34.1734'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:30.067,lwr_k=10:26.3751,lwr_k=20:24.5784,lwr_k=30:24.0687,lwr_k=40:23.3784,lwr_k=50:23.0047,lwr_k=100:23.0667,lwr_k=200:23.9078,lwr_k=300:24.3475,lwr_k=400:24.5216,lwr_k=500:24.5918,lwr_k=600:24.7076,lwr_k=700:24.7285,lwr_k=800:24.8191,lwr_k=900:24.8119,lwr_k=1000:24.8715'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:242.344,lwr_k=10:144.3755,lwr_k=20:178.7446,lwr_k=30:188.1348,lwr_k=40:190.0582,lwr_k=50:192.4671,lwr_k=100:196.0227,lwr_k=200:201.6998,lwr_k=300:205.2933,lwr_k=400:207.7575,lwr_k=500:209.5033,lwr_k=600:211.4889,lwr_k=700:213.0628,lwr_k=800:214.7568,lwr_k=900:216.1937,lwr_k=1000:217.5854'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:227.3054,lwr_k=10:219.1733,lwr_k=20:196.3452,lwr_k=30:201.5208,lwr_k=40:195.5723,lwr_k=50:192.6532,lwr_k=100:191.5328,lwr_k=200:195.9726,lwr_k=300:197.575,lwr_k=400:198.2655,lwr_k=500:199.145,lwr_k=600:200.0919,lwr_k=700:200.9936,lwr_k=800:201.7259,lwr_k=900:202.5592,lwr_k=1000:203.5336'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:191.8404,lwr_k=10:113.7853,lwr_k=20:133.9047,lwr_k=30:140.689,lwr_k=40:142.6566,lwr_k=50:146.0266,lwr_k=100:150.3835,lwr_k=200:156.1481,lwr_k=300:158.9701,lwr_k=400:161.3475,lwr_k=500:162.9407,lwr_k=600:164.6973,lwr_k=700:166.3847,lwr_k=800:167.5072,lwr_k=900:168.9474,lwr_k=1000:170.0117'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:302.0189,lwr_k=10:299.0659,lwr_k=20:275.6975,lwr_k=30:274.1349,lwr_k=40:273.5668,lwr_k=50:270.8796,lwr_k=100:266.7262,lwr_k=200:266.0257,lwr_k=300:267.8814,lwr_k=400:269.0572,lwr_k=500:270.4318,lwr_k=600:271.2021,lwr_k=700:272.3848,lwr_k=800:272.7519,lwr_k=900:274.2668,lwr_k=1000:275.3588'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:26.6371,lwr_k=10:13.1188,lwr_k=20:15.0863,lwr_k=30:15.9259,lwr_k=40:16.5136,lwr_k=50:16.6779,lwr_k=100:17.8562,lwr_k=200:18.9092,lwr_k=300:19.4865,lwr_k=400:19.8636,lwr_k=500:20.1846,lwr_k=600:20.4241,lwr_k=700:20.6691,lwr_k=800:20.8496,lwr_k=900:21.0446,lwr_k=1000:21.1799'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:25.6877,lwr_k=10:30.4231,lwr_k=20:25.5454,lwr_k=30:23.7858,lwr_k=40:23.9778,lwr_k=50:22.8053,lwr_k=100:21.6038,lwr_k=200:20.9186,lwr_k=300:20.9162,lwr_k=400:21.0251,lwr_k=500:20.8806,lwr_k=600:20.9148,lwr_k=700:20.9186,lwr_k=800:20.8368,lwr_k=900:20.9846,lwr_k=1000:21.0934'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_22'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:51.3163,lwr_k=10:29.9664,lwr_k=20:28.8257,lwr_k=30:29.035,lwr_k=40:28.9109,lwr_k=50:29.3528,lwr_k=100:29.2661,lwr_k=200:33.777,lwr_k=300:36.5106,lwr_k=400:38.4808,lwr_k=500:39.9523,lwr_k=600:41.0772,lwr_k=700:42.0018,lwr_k=800:42.8224,lwr_k=900:43.5084,lwr_k=1000:44.0578'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:81.6508,lwr_k=10:49.0658,lwr_k=20:44.3169,lwr_k=30:41.4608,lwr_k=40:43.6548,lwr_k=50:45.7006,lwr_k=100:42.3739,lwr_k=200:47.6127,lwr_k=300:53.3746,lwr_k=400:57.4722,lwr_k=500:60.2726,lwr_k=600:62.6195,lwr_k=700:64.693,lwr_k=800:66.5569,lwr_k=900:67.9242,lwr_k=1000:69.0896'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.5832,lwr_k=10:2.6203,lwr_k=20:4.3103,lwr_k=30:4.9646,lwr_k=40:5.4446,lwr_k=50:5.6947,lwr_k=100:6.1572,lwr_k=200:6.8033,lwr_k=300:6.969,lwr_k=400:7.0519,lwr_k=500:7.113,lwr_k=600:7.1598,lwr_k=700:7.1865,lwr_k=800:7.2179,lwr_k=900:7.2338,lwr_k=1000:7.2604'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.1307,lwr_k=10:24.8454,lwr_k=20:8.3555,lwr_k=30:7.2929,lwr_k=40:6.9946,lwr_k=50:6.8495,lwr_k=100:6.545,lwr_k=200:6.5607,lwr_k=300:6.6329,lwr_k=400:6.6732,lwr_k=500:6.6984,lwr_k=600:6.7373,lwr_k=700:6.6963,lwr_k=800:6.7183,lwr_k=900:6.7373,lwr_k=1000:6.7497'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.721,lwr_k=10:2.9143,lwr_k=20:4.7222,lwr_k=30:5.39,lwr_k=40:5.9085,lwr_k=50:6.4826,lwr_k=100:7.2901,lwr_k=200:7.8008,lwr_k=300:7.9714,lwr_k=400:8.099,lwr_k=500:8.2251,lwr_k=600:8.2422,lwr_k=700:8.3148,lwr_k=800:8.3587,lwr_k=900:8.3926,lwr_k=1000:8.4144'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.3134,lwr_k=10:24.5801,lwr_k=20:13.0519,lwr_k=30:9.3746,lwr_k=40:8.6242,lwr_k=50:8.106,lwr_k=100:7.0736,lwr_k=200:6.934,lwr_k=300:6.8657,lwr_k=400:6.8823,lwr_k=500:6.9195,lwr_k=600:6.9212,lwr_k=700:6.9121,lwr_k=800:6.9089,lwr_k=900:6.8982,lwr_k=1000:6.9178'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.9176,lwr_k=10:3.0182,lwr_k=20:4.7113,lwr_k=30:5.2933,lwr_k=40:5.7354,lwr_k=50:6.0314,lwr_k=100:6.6095,lwr_k=200:7.0039,lwr_k=300:7.1195,lwr_k=400:7.2056,lwr_k=500:7.3347,lwr_k=600:7.3955,lwr_k=700:7.4531,lwr_k=800:7.4853,lwr_k=900:7.525,lwr_k=1000:7.5494'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:10.188,lwr_k=10:56.2667,lwr_k=20:10.1419,lwr_k=30:8.6868,lwr_k=40:8.5995,lwr_k=50:8.9668,lwr_k=100:12.2122,lwr_k=200:11.6706,lwr_k=300:11.637,lwr_k=400:11.4498,lwr_k=500:11.8769,lwr_k=600:9.4477,lwr_k=700:9.6739,lwr_k=800:9.74,lwr_k=900:9.7609,lwr_k=1000:9.7245'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.9061,lwr_k=10:2.1078,lwr_k=20:3.3976,lwr_k=30:3.6755,lwr_k=40:3.8754,lwr_k=50:3.9895,lwr_k=100:4.2967,lwr_k=200:4.4691,lwr_k=300:4.5529,lwr_k=400:4.5849,lwr_k=500:4.6151,lwr_k=600:4.6129,lwr_k=700:4.6231,lwr_k=800:4.6522,lwr_k=900:4.6574,lwr_k=1000:4.6686'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:18.3269,lwr_k=10:39.5538,lwr_k=20:16.4722,lwr_k=30:16.5095,lwr_k=40:18.7166,lwr_k=50:18.3746,lwr_k=100:18.816,lwr_k=200:18.8727,lwr_k=300:18.9332,lwr_k=400:18.9167,lwr_k=500:18.8267,lwr_k=600:18.7422,lwr_k=700:18.621,lwr_k=800:18.5597,lwr_k=900:18.5245,lwr_k=1000:18.51'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:8.0105,lwr_k=10:2.2926,lwr_k=20:4.2973,lwr_k=30:4.8434,lwr_k=40:5.1134,lwr_k=50:5.1918,lwr_k=100:5.9383,lwr_k=200:6.7014,lwr_k=300:6.888,lwr_k=400:6.9638,lwr_k=500:7.0112,lwr_k=600:7.0721,lwr_k=700:7.1319,lwr_k=800:7.1814,lwr_k=900:7.242,lwr_k=1000:7.2833'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.8793,lwr_k=10:197.7912,lwr_k=20:9.2736,lwr_k=30:8.5621,lwr_k=40:9.7283,lwr_k=50:10.2789,lwr_k=100:27.6905,lwr_k=200:35.7981,lwr_k=300:38.5485,lwr_k=400:35.3719,lwr_k=500:33.7877,lwr_k=600:33.8838,lwr_k=700:34.4147,lwr_k=800:34.2002,lwr_k=900:33.9199,lwr_k=1000:33.5614'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_23'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.9957,lwr_k=10:0.0,lwr_k=20:0.0005,lwr_k=30:2.0916,lwr_k=40:3.406,lwr_k=50:4.0804,lwr_k=100:5.2382,lwr_k=200:5.8056,lwr_k=300:6.0894,lwr_k=400:6.2577,lwr_k=500:6.348,lwr_k=600:6.4184,lwr_k=700:6.4947,lwr_k=800:6.5267,lwr_k=900:6.5846,lwr_k=1000:6.6124'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.1722,lwr_k=10:114.8674,lwr_k=20:29884.4774,lwr_k=30:155.4296,lwr_k=40:428.5176,lwr_k=50:467.0687,lwr_k=100:22.1631,lwr_k=200:9.7796,lwr_k=300:8.4468,lwr_k=400:8.4528,lwr_k=500:8.4337,lwr_k=600:8.425,lwr_k=700:8.4661,lwr_k=800:8.5359,lwr_k=900:8.5848,lwr_k=1000:8.6548'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.4825,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.368,lwr_k=40:1.9665,lwr_k=50:2.4985,lwr_k=100:3.9781,lwr_k=200:5.3206,lwr_k=300:5.8358,lwr_k=400:6.1774,lwr_k=500:6.3947,lwr_k=600:6.5629,lwr_k=700:6.7661,lwr_k=800:6.951,lwr_k=900:7.0901,lwr_k=1000:7.2021'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.3988,lwr_k=10:25.1671,lwr_k=20:151.9988,lwr_k=30:12.3613,lwr_k=40:8.223,lwr_k=50:7.3033,lwr_k=100:6.5522,lwr_k=200:6.2798,lwr_k=300:6.0144,lwr_k=400:5.9633,lwr_k=500:5.9661,lwr_k=600:5.9884,lwr_k=700:6.1539,lwr_k=800:6.2127,lwr_k=900:6.3359,lwr_k=1000:6.3671'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.0343,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.6178,lwr_k=40:2.3506,lwr_k=50:2.7909,lwr_k=100:3.9243,lwr_k=200:5.0709,lwr_k=300:5.7963,lwr_k=400:6.2589,lwr_k=500:6.6949,lwr_k=600:7.0199,lwr_k=700:7.4267,lwr_k=800:7.7073,lwr_k=900:7.9805,lwr_k=1000:8.246'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.9992,lwr_k=10:44.7403,lwr_k=20:488.5905,lwr_k=30:17.5704,lwr_k=40:11.2684,lwr_k=50:7.9253,lwr_k=100:6.305,lwr_k=200:5.674,lwr_k=300:5.7116,lwr_k=400:5.5959,lwr_k=500:5.6429,lwr_k=600:5.7105,lwr_k=700:5.9634,lwr_k=800:5.9687,lwr_k=900:6.0496,lwr_k=1000:6.0964'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.8402,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.3797,lwr_k=40:2.0025,lwr_k=50:2.5052,lwr_k=100:3.8793,lwr_k=200:4.7458,lwr_k=300:5.1748,lwr_k=400:5.4376,lwr_k=500:5.7632,lwr_k=600:5.9193,lwr_k=700:6.2246,lwr_k=800:6.4218,lwr_k=900:6.5176,lwr_k=1000:6.6155'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.8514,lwr_k=10:21.731,lwr_k=20:136.4866,lwr_k=30:13.5666,lwr_k=40:9.808,lwr_k=50:7.9626,lwr_k=100:7.036,lwr_k=200:7.0344,lwr_k=300:6.9933,lwr_k=400:6.9508,lwr_k=500:6.9501,lwr_k=600:6.99,lwr_k=700:6.9308,lwr_k=800:6.9664,lwr_k=900:7.0083,lwr_k=1000:7.0502'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.7438,lwr_k=10:0.0,lwr_k=20:0.0095,lwr_k=30:1.284,lwr_k=40:1.8582,lwr_k=50:2.1694,lwr_k=100:3.0839,lwr_k=200:3.6221,lwr_k=300:3.8423,lwr_k=400:3.9314,lwr_k=500:4.0287,lwr_k=600:4.0656,lwr_k=700:4.1224,lwr_k=800:4.1601,lwr_k=900:4.1884,lwr_k=1000:4.2254'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:17.3569,lwr_k=10:53.6997,lwr_k=20:358170.1346,lwr_k=30:25.0054,lwr_k=40:20.7086,lwr_k=50:17.9955,lwr_k=100:15.5973,lwr_k=200:16.6284,lwr_k=300:16.2681,lwr_k=400:15.9943,lwr_k=500:15.967,lwr_k=600:15.9525,lwr_k=700:16.0599,lwr_k=800:16.1293,lwr_k=900:16.1781,lwr_k=1000:16.2894'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:6.4412,lwr_k=10:0.0,lwr_k=20:0.003,lwr_k=30:1.1756,lwr_k=40:1.7627,lwr_k=50:2.2662,lwr_k=100:3.3275,lwr_k=200:3.9486,lwr_k=300:4.1745,lwr_k=400:4.3488,lwr_k=500:4.4583,lwr_k=600:4.5322,lwr_k=700:4.6185,lwr_k=800:4.6707,lwr_k=900:4.7267,lwr_k=1000:4.7672'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.1489,lwr_k=10:267.6191,lwr_k=20:229097.3372,lwr_k=30:4289.8219,lwr_k=40:50.4637,lwr_k=50:23.7523,lwr_k=100:11.7478,lwr_k=200:8.7526,lwr_k=300:7.4406,lwr_k=400:7.1394,lwr_k=500:7.0443,lwr_k=600:7.1818,lwr_k=700:7.3234,lwr_k=800:7.4273,lwr_k=900:7.471,lwr_k=1000:7.4032'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_24'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.2693,lwr_k=10:6.6601,lwr_k=20:7.2799,lwr_k=30:7.3683,lwr_k=40:7.6185,lwr_k=50:7.7156,lwr_k=100:7.9949,lwr_k=200:8.3574,lwr_k=300:8.4671,lwr_k=400:8.5798,lwr_k=500:8.6882,lwr_k=600:8.7555,lwr_k=700:8.8394,lwr_k=800:8.9433,lwr_k=900:9.0068,lwr_k=1000:9.0409'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:12.7049,lwr_k=10:14.5615,lwr_k=20:12.3163,lwr_k=30:11.8599,lwr_k=40:10.8733,lwr_k=50:10.9996,lwr_k=100:10.2057,lwr_k=200:10.5385,lwr_k=300:10.6763,lwr_k=400:10.8771,lwr_k=500:10.9444,lwr_k=600:11.0142,lwr_k=700:11.1113,lwr_k=800:11.2067,lwr_k=900:11.2715,lwr_k=1000:11.3381'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:25.0658,lwr_k=10:12.4344,lwr_k=20:15.0091,lwr_k=30:15.9889,lwr_k=40:16.5865,lwr_k=50:16.9081,lwr_k=100:17.8168,lwr_k=200:18.8388,lwr_k=300:19.39,lwr_k=400:19.7658,lwr_k=500:20.0949,lwr_k=600:20.3195,lwr_k=700:20.5873,lwr_k=800:20.8058,lwr_k=900:20.9999,lwr_k=1000:21.1211'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:19.3586,lwr_k=10:22.2889,lwr_k=20:16.9969,lwr_k=30:15.6858,lwr_k=40:15.1157,lwr_k=50:15.0093,lwr_k=100:14.4856,lwr_k=200:14.4129,lwr_k=300:14.3171,lwr_k=400:14.3972,lwr_k=500:14.5976,lwr_k=600:14.6366,lwr_k=700:14.6585,lwr_k=800:14.7326,lwr_k=900:14.776,lwr_k=1000:14.8476'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:48.0618,lwr_k=10:19.1016,lwr_k=20:21.618,lwr_k=30:23.0782,lwr_k=40:23.78,lwr_k=50:24.3387,lwr_k=100:25.5729,lwr_k=200:27.3988,lwr_k=300:29.0321,lwr_k=400:30.3406,lwr_k=500:31.176,lwr_k=600:32.0043,lwr_k=700:32.7278,lwr_k=800:33.4677,lwr_k=900:34.0613,lwr_k=1000:34.7082'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:31.1376,lwr_k=10:30.2699,lwr_k=20:23.3742,lwr_k=30:22.1488,lwr_k=40:21.5135,lwr_k=50:21.2322,lwr_k=100:20.2765,lwr_k=200:20.7673,lwr_k=300:21.1713,lwr_k=400:21.4225,lwr_k=500:21.6632,lwr_k=600:21.7554,lwr_k=700:21.8354,lwr_k=800:21.8935,lwr_k=900:22.042,lwr_k=1000:22.1041'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:22.3458,lwr_k=10:12.0144,lwr_k=20:13.8327,lwr_k=30:14.4702,lwr_k=40:15.2538,lwr_k=50:15.5446,lwr_k=100:16.3526,lwr_k=200:16.9076,lwr_k=300:17.1588,lwr_k=400:17.4309,lwr_k=500:17.684,lwr_k=600:17.9245,lwr_k=700:18.129,lwr_k=800:18.2983,lwr_k=900:18.4277,lwr_k=1000:18.5254'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:19.7112,lwr_k=10:32.1129,lwr_k=20:43.7795,lwr_k=30:52.3562,lwr_k=40:18.8386,lwr_k=50:17.337,lwr_k=100:15.5868,lwr_k=200:15.5269,lwr_k=300:15.5524,lwr_k=400:15.4849,lwr_k=500:15.5477,lwr_k=600:15.662,lwr_k=700:15.5934,lwr_k=800:15.6936,lwr_k=900:15.7872,lwr_k=1000:15.9255'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.0832,lwr_k=10:6.2593,lwr_k=20:7.2799,lwr_k=30:7.6787,lwr_k=40:7.8036,lwr_k=50:7.9502,lwr_k=100:8.1923,lwr_k=200:8.286,lwr_k=300:8.3639,lwr_k=400:8.4607,lwr_k=500:8.5179,lwr_k=600:8.5488,lwr_k=700:8.5417,lwr_k=800:8.5567,lwr_k=900:8.5968,lwr_k=1000:8.7263'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:29.1156,lwr_k=10:26.0122,lwr_k=20:21.7083,lwr_k=30:23.6321,lwr_k=40:25.0746,lwr_k=50:25.2892,lwr_k=100:24.9319,lwr_k=200:26.3562,lwr_k=300:26.7201,lwr_k=400:27.1658,lwr_k=500:27.3665,lwr_k=600:27.4569,lwr_k=700:27.4878,lwr_k=800:27.6148,lwr_k=900:27.7588,lwr_k=1000:28.074'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:20.6803,lwr_k=10:10.6342,lwr_k=20:12.5351,lwr_k=30:13.0059,lwr_k=40:13.3813,lwr_k=50:13.6576,lwr_k=100:14.6059,lwr_k=200:15.2757,lwr_k=300:15.6791,lwr_k=400:16.0789,lwr_k=500:16.3728,lwr_k=600:16.6021,lwr_k=700:16.879,lwr_k=800:17.0725,lwr_k=900:17.2532,lwr_k=1000:17.4329'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:20.683,lwr_k=10:19.3424,lwr_k=20:17.5993,lwr_k=30:18.4261,lwr_k=40:18.6883,lwr_k=50:17.3982,lwr_k=100:17.1121,lwr_k=200:17.304,lwr_k=300:17.3689,lwr_k=400:17.3236,lwr_k=500:17.2384,lwr_k=600:17.3617,lwr_k=700:17.4563,lwr_k=800:17.6259,lwr_k=900:17.6689,lwr_k=1000:17.8817'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_25'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.5217,lwr_k=10:4.5507,lwr_k=20:6.1783,lwr_k=30:6.5984,lwr_k=40:6.8259,lwr_k=50:7.0974,lwr_k=100:7.5641,lwr_k=200:7.747,lwr_k=300:7.8676,lwr_k=400:7.8743,lwr_k=500:7.9408,lwr_k=600:8.0238,lwr_k=700:7.9857,lwr_k=800:8.0022,lwr_k=900:8.0266,lwr_k=1000:8.06'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.6664,lwr_k=10:20.1283,lwr_k=20:13.2511,lwr_k=30:12.2949,lwr_k=40:11.8499,lwr_k=50:11.5314,lwr_k=100:11.1508,lwr_k=200:11.2655,lwr_k=300:11.3741,lwr_k=400:11.6271,lwr_k=500:11.6088,lwr_k=600:11.5323,lwr_k=700:11.5138,lwr_k=800:11.2993,lwr_k=900:11.5847,lwr_k=1000:11.5893'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:44.5089,lwr_k=10:0.0,lwr_k=20:1.4452,lwr_k=30:6.2971,lwr_k=40:9.2168,lwr_k=50:11.1898,lwr_k=100:17.4598,lwr_k=200:21.1803,lwr_k=300:23.0643,lwr_k=400:24.4165,lwr_k=500:25.5311,lwr_k=600:26.2448,lwr_k=700:27.1891,lwr_k=800:27.7611,lwr_k=900:28.4688,lwr_k=1000:29.2701'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:28.945,lwr_k=10:74.5745,lwr_k=20:433.4457,lwr_k=30:50.3662,lwr_k=40:41.9223,lwr_k=50:37.6345,lwr_k=100:23.5935,lwr_k=200:22.224,lwr_k=300:21.2489,lwr_k=400:20.6988,lwr_k=500:20.5656,lwr_k=600:20.3031,lwr_k=700:20.0414,lwr_k=800:19.8179,lwr_k=900:19.7439,lwr_k=1000:19.7621'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:45.497,lwr_k=10:0.0,lwr_k=20:1.2504,lwr_k=30:6.4724,lwr_k=40:9.5972,lwr_k=50:12.1334,lwr_k=100:17.6469,lwr_k=200:21.8414,lwr_k=300:24.2715,lwr_k=400:25.5153,lwr_k=500:26.3442,lwr_k=600:27.025,lwr_k=700:27.6404,lwr_k=800:28.2887,lwr_k=900:28.7988,lwr_k=1000:29.3009'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:34.6864,lwr_k=10:69.5168,lwr_k=20:649.9055,lwr_k=30:60.0004,lwr_k=40:38.4156,lwr_k=50:31.2976,lwr_k=100:24.2292,lwr_k=200:20.6072,lwr_k=300:20.8747,lwr_k=400:20.6075,lwr_k=500:20.6036,lwr_k=600:21.0124,lwr_k=700:21.381,lwr_k=800:21.7099,lwr_k=900:22.0541,lwr_k=1000:22.3022'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:94.8857,lwr_k=10:0.0,lwr_k=20:0.0164,lwr_k=30:2.9463,lwr_k=40:6.6213,lwr_k=50:9.8923,lwr_k=100:20.7189,lwr_k=200:28.9387,lwr_k=300:34.8721,lwr_k=400:38.4048,lwr_k=500:42.0687,lwr_k=600:44.5857,lwr_k=700:46.931,lwr_k=800:49.2669,lwr_k=900:51.4296,lwr_k=1000:53.3763'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:90.1944,lwr_k=10:54.2253,lwr_k=20:168.2751,lwr_k=30:6566.0489,lwr_k=40:3132.5743,lwr_k=50:43.6679,lwr_k=100:44.044,lwr_k=200:31.8805,lwr_k=300:35.5919,lwr_k=400:37.3736,lwr_k=500:40.4652,lwr_k=600:42.9352,lwr_k=700:45.2837,lwr_k=800:47.572,lwr_k=900:49.6587,lwr_k=1000:51.6002'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.1949,lwr_k=10:0.0,lwr_k=20:0.2197,lwr_k=30:1.6001,lwr_k=40:2.1877,lwr_k=50:2.5975,lwr_k=100:3.2132,lwr_k=200:3.6492,lwr_k=300:3.8259,lwr_k=400:3.9083,lwr_k=500:3.9529,lwr_k=600:3.9785,lwr_k=700:3.9951,lwr_k=800:4.0176,lwr_k=900:4.0272,lwr_k=1000:4.0508'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:20.5699,lwr_k=10:31.9854,lwr_k=20:188.3704,lwr_k=30:51.43,lwr_k=40:24.9982,lwr_k=50:24.1848,lwr_k=100:21.9562,lwr_k=200:21.0121,lwr_k=300:20.6566,lwr_k=400:20.4035,lwr_k=500:20.2039,lwr_k=600:20.2483,lwr_k=700:20.2894,lwr_k=800:20.2742,lwr_k=900:20.2779,lwr_k=1000:20.3217'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:87.593,lwr_k=10:0.0,lwr_k=20:0.0163,lwr_k=30:2.754,lwr_k=40:6.5442,lwr_k=50:10.1518,lwr_k=100:16.6178,lwr_k=200:25.4848,lwr_k=300:29.8737,lwr_k=400:33.5485,lwr_k=500:36.1575,lwr_k=600:38.3656,lwr_k=700:40.2655,lwr_k=800:41.7689,lwr_k=900:43.7342,lwr_k=1000:45.2544'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:90.3297,lwr_k=10:66.5709,lwr_k=20:317.7424,lwr_k=30:1617.7426,lwr_k=40:7443.8557,lwr_k=50:58.433,lwr_k=100:41.7429,lwr_k=200:42.6684,lwr_k=300:43.0832,lwr_k=400:45.3269,lwr_k=500:48.0905,lwr_k=600:49.598,lwr_k=700:51.1148,lwr_k=800:52.3847,lwr_k=900:54.9549,lwr_k=1000:55.9332'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_26'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.4469,lwr_k=10:2.0433,lwr_k=20:3.6056,lwr_k=30:4.3359,lwr_k=40:4.7451,lwr_k=50:4.9514,lwr_k=100:5.652,lwr_k=200:5.9108,lwr_k=300:6.0326,lwr_k=400:6.0909,lwr_k=500:6.1537,lwr_k=600:6.2071,lwr_k=700:6.2135,lwr_k=800:6.2146,lwr_k=900:6.2872,lwr_k=1000:6.2932'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.137,lwr_k=10:90.2233,lwr_k=20:19.5605,lwr_k=30:11.7577,lwr_k=40:734861.7564,lwr_k=50:224332.2277,lwr_k=100:47769.6556,lwr_k=200:14887.5991,lwr_k=300:2138.9249,lwr_k=400:8.1761,lwr_k=500:8.1807,lwr_k=600:8.1372,lwr_k=700:8.2318,lwr_k=800:8.228,lwr_k=900:8.188,lwr_k=1000:8.1428'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.8677,lwr_k=10:5.3126,lwr_k=20:6.3174,lwr_k=30:6.6786,lwr_k=40:6.7529,lwr_k=50:7.1353,lwr_k=100:6.9992,lwr_k=200:7.1252,lwr_k=300:7.2415,lwr_k=400:7.3242,lwr_k=500:6.9368,lwr_k=600:7.3706,lwr_k=700:7.3704,lwr_k=800:7.4464,lwr_k=900:7.4113,lwr_k=1000:7.6778'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.9607,lwr_k=10:9.8759,lwr_k=20:8.8294,lwr_k=30:8.6343,lwr_k=40:8.8029,lwr_k=50:8.4904,lwr_k=100:8.3662,lwr_k=200:8.1906,lwr_k=300:8.3445,lwr_k=400:8.8289,lwr_k=500:8.3789,lwr_k=600:8.4033,lwr_k=700:8.1917,lwr_k=800:8.9553,lwr_k=900:8.9459,lwr_k=1000:8.2984'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.2737,lwr_k=10:3.5025,lwr_k=20:4.827,lwr_k=30:5.331,lwr_k=40:5.6171,lwr_k=50:5.8021,lwr_k=100:6.3397,lwr_k=200:6.6657,lwr_k=300:6.7592,lwr_k=400:6.7982,lwr_k=500:6.8844,lwr_k=600:6.9081,lwr_k=700:6.9695,lwr_k=800:7.0216,lwr_k=900:7.0475,lwr_k=1000:7.0694'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.8716,lwr_k=10:15.4275,lwr_k=20:11.4508,lwr_k=30:10.2463,lwr_k=40:36945131949.5494,lwr_k=50:20398619.3304,lwr_k=100:1252618.4747,lwr_k=200:6.455,lwr_k=300:6.3835,lwr_k=400:6.5331,lwr_k=500:6.5707,lwr_k=600:6.6473,lwr_k=700:6.7196,lwr_k=800:6.7406,lwr_k=900:6.8099,lwr_k=1000:6.8304'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.3156,lwr_k=10:3.2796,lwr_k=20:5.4982,lwr_k=30:6.0695,lwr_k=40:6.5087,lwr_k=50:6.8458,lwr_k=100:7.3699,lwr_k=200:7.67,lwr_k=300:7.8106,lwr_k=400:7.8708,lwr_k=500:7.9722,lwr_k=600:8.0941,lwr_k=700:8.1298,lwr_k=800:8.143,lwr_k=900:8.1805,lwr_k=1000:8.1917'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:11.0088,lwr_k=10:83.9351,lwr_k=20:29.7426,lwr_k=30:12.2535,lwr_k=40:29718.0857,lwr_k=50:327487904.4013,lwr_k=100:10.3808,lwr_k=200:11.4638,lwr_k=300:11.4801,lwr_k=400:10.3733,lwr_k=500:10.5482,lwr_k=600:10.5274,lwr_k=700:10.5386,lwr_k=800:10.6104,lwr_k=900:10.7064,lwr_k=1000:10.7101'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.5358,lwr_k=10:3.8378,lwr_k=20:5.7297,lwr_k=30:6.0346,lwr_k=40:6.5134,lwr_k=50:6.5984,lwr_k=100:6.9331,lwr_k=200:7.0781,lwr_k=300:7.2114,lwr_k=400:7.3113,lwr_k=500:7.3332,lwr_k=600:7.3042,lwr_k=700:7.357,lwr_k=800:7.3645,lwr_k=900:7.4361,lwr_k=1000:7.4074'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:20.9249,lwr_k=10:19788.6282,lwr_k=20:301263.6769,lwr_k=30:19.0995,lwr_k=40:138157938.1342,lwr_k=50:3486997544.7141,lwr_k=100:127.297,lwr_k=200:17.3259,lwr_k=300:70.6351,lwr_k=400:31.2155,lwr_k=500:9.6065,lwr_k=600:71.7463,lwr_k=700:25.1452,lwr_k=800:49.7246,lwr_k=900:19.4225,lwr_k=1000:61.8471'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:12.1237,lwr_k=10:5.7652,lwr_k=20:6.9383,lwr_k=30:7.6931,lwr_k=40:8.6744,lwr_k=50:8.9863,lwr_k=100:9.8826,lwr_k=200:10.3469,lwr_k=300:10.4386,lwr_k=400:10.4168,lwr_k=500:10.4334,lwr_k=600:10.4771,lwr_k=700:10.5033,lwr_k=800:9.8957,lwr_k=900:10.4916,lwr_k=1000:10.6227'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:13.8317,lwr_k=10:152.4486,lwr_k=20:33.3469,lwr_k=30:24.2255,lwr_k=40:26.1227,lwr_k=50:21.6083,lwr_k=100:12.3703,lwr_k=200:12.3071,lwr_k=300:12.2592,lwr_k=400:12.1431,lwr_k=500:12.2524,lwr_k=600:12.2761,lwr_k=700:12.1945,lwr_k=800:12.2273,lwr_k=900:12.1252,lwr_k=1000:12.2295'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_27'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.2609,lwr_k=10:0.0,lwr_k=20:0.6225,lwr_k=30:1.6558,lwr_k=40:2.1055,lwr_k=50:2.3461,lwr_k=100:2.9231,lwr_k=200:3.2573,lwr_k=300:3.3834,lwr_k=400:3.4938,lwr_k=500:3.5666,lwr_k=600:3.6478,lwr_k=700:3.6978,lwr_k=800:3.7355,lwr_k=900:3.7701,lwr_k=1000:3.8431'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.2557,lwr_k=10:22.7516,lwr_k=20:95.5058,lwr_k=30:18.7185,lwr_k=40:12.7962,lwr_k=50:11.4435,lwr_k=100:9.7337,lwr_k=200:9.3699,lwr_k=300:9.2276,lwr_k=400:9.2368,lwr_k=500:9.1982,lwr_k=600:9.1765,lwr_k=700:9.1396,lwr_k=800:9.1325,lwr_k=900:9.1026,lwr_k=1000:9.1591'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:49.4172,lwr_k=10:0.0,lwr_k=20:2.1118,lwr_k=30:8.2116,lwr_k=40:10.5217,lwr_k=50:12.6876,lwr_k=100:19.7992,lwr_k=200:23.6977,lwr_k=300:26.1948,lwr_k=400:27.1146,lwr_k=500:27.8062,lwr_k=600:28.6443,lwr_k=700:29.4477,lwr_k=800:30.2149,lwr_k=900:30.9588,lwr_k=1000:31.6459'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:35.685,lwr_k=10:169.5573,lwr_k=20:3315.4243,lwr_k=30:61.1901,lwr_k=40:44.3438,lwr_k=50:37.8822,lwr_k=100:29.1263,lwr_k=200:25.1215,lwr_k=300:24.605,lwr_k=400:24.2288,lwr_k=500:23.762,lwr_k=600:24.3311,lwr_k=700:24.1304,lwr_k=800:23.9594,lwr_k=900:24.1772,lwr_k=1000:24.1912'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:50.1641,lwr_k=10:1.7292,lwr_k=20:42.1831,lwr_k=30:19.8568,lwr_k=40:18.1304,lwr_k=50:18.767,lwr_k=100:23.73,lwr_k=200:28.3295,lwr_k=300:30.4409,lwr_k=400:32.1126,lwr_k=500:32.9794,lwr_k=600:33.6375,lwr_k=700:34.538,lwr_k=800:36.1051,lwr_k=900:36.697,lwr_k=1000:37.3156'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:38.6579,lwr_k=10:1623137.3816,lwr_k=20:14360964.4361,lwr_k=30:1567729.2064,lwr_k=40:56334.9159,lwr_k=50:27632.9745,lwr_k=100:69163.7517,lwr_k=200:145.1288,lwr_k=300:29.9499,lwr_k=400:29.3506,lwr_k=500:28.9835,lwr_k=600:28.6312,lwr_k=700:28.6772,lwr_k=800:28.836,lwr_k=900:29.0465,lwr_k=1000:29.1919'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:39.7128,lwr_k=10:0.0,lwr_k=20:1.7439,lwr_k=30:7.3054,lwr_k=40:11.1221,lwr_k=50:13.2262,lwr_k=100:18.744,lwr_k=200:22.3242,lwr_k=300:23.9616,lwr_k=400:24.8147,lwr_k=500:25.5977,lwr_k=600:26.527,lwr_k=700:27.1164,lwr_k=800:27.7398,lwr_k=900:28.3268,lwr_k=1000:29.0027'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:31.2963,lwr_k=10:144.6837,lwr_k=20:401.9981,lwr_k=30:88.2722,lwr_k=40:44.0778,lwr_k=50:38.8131,lwr_k=100:24.5202,lwr_k=200:21.7957,lwr_k=300:22.0432,lwr_k=400:21.447,lwr_k=500:21.7098,lwr_k=600:21.8369,lwr_k=700:21.8868,lwr_k=800:22.1212,lwr_k=900:22.3287,lwr_k=1000:22.6145'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.7433,lwr_k=10:0.0,lwr_k=20:0.5452,lwr_k=30:2.1099,lwr_k=40:2.6978,lwr_k=50:3.0343,lwr_k=100:3.7028,lwr_k=200:4.1531,lwr_k=300:4.2822,lwr_k=400:4.3674,lwr_k=500:4.4322,lwr_k=600:4.4528,lwr_k=700:4.48,lwr_k=800:4.4994,lwr_k=900:4.5271,lwr_k=1000:4.5495'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:18.8009,lwr_k=10:67.238,lwr_k=20:417.2525,lwr_k=30:28.622,lwr_k=40:23.5497,lwr_k=50:21.3232,lwr_k=100:19.0132,lwr_k=200:18.8836,lwr_k=300:19.1532,lwr_k=400:19.3427,lwr_k=500:19.3968,lwr_k=600:19.5178,lwr_k=700:19.5226,lwr_k=800:19.5334,lwr_k=900:19.5467,lwr_k=1000:19.5242'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:36.3206,lwr_k=10:0.0,lwr_k=20:2.2913,lwr_k=30:6.579,lwr_k=40:9.0324,lwr_k=50:10.8059,lwr_k=100:15.9681,lwr_k=200:19.1712,lwr_k=300:20.4098,lwr_k=400:21.1933,lwr_k=500:21.971,lwr_k=600:22.5607,lwr_k=700:23.0416,lwr_k=800:23.7122,lwr_k=900:24.1625,lwr_k=1000:24.7422'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:32.3219,lwr_k=10:112.1174,lwr_k=20:117.6956,lwr_k=30:66.9269,lwr_k=40:60.1223,lwr_k=50:43.7509,lwr_k=100:21.3774,lwr_k=200:21.0731,lwr_k=300:21.6148,lwr_k=400:21.9479,lwr_k=500:21.9101,lwr_k=600:22.5301,lwr_k=700:22.9882,lwr_k=800:23.4054,lwr_k=900:23.5061,lwr_k=1000:23.7015'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_28'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:12.0226,lwr_k=10:7.4072,lwr_k=20:8.0528,lwr_k=30:8.2882,lwr_k=40:8.3948,lwr_k=50:8.4737,lwr_k=100:8.7758,lwr_k=200:9.0101,lwr_k=300:9.2164,lwr_k=400:9.3426,lwr_k=500:9.4416,lwr_k=600:9.5419,lwr_k=700:9.6292,lwr_k=800:9.7164,lwr_k=900:9.7794,lwr_k=1000:9.8548'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:16.0042,lwr_k=10:12.0822,lwr_k=20:11.6717,lwr_k=30:11.1186,lwr_k=40:10.9922,lwr_k=50:10.9466,lwr_k=100:10.8105,lwr_k=200:11.1274,lwr_k=300:11.3374,lwr_k=400:11.5956,lwr_k=500:11.798,lwr_k=600:12.0104,lwr_k=700:12.212,lwr_k=800:12.3414,lwr_k=900:12.4556,lwr_k=1000:12.5599'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:34.8275,lwr_k=10:13.9443,lwr_k=20:16.0612,lwr_k=30:17.3444,lwr_k=40:17.896,lwr_k=50:18.3581,lwr_k=100:19.708,lwr_k=200:20.915,lwr_k=300:21.7999,lwr_k=400:22.5283,lwr_k=500:23.0098,lwr_k=600:23.5113,lwr_k=700:23.9206,lwr_k=800:24.2694,lwr_k=900:24.6046,lwr_k=1000:24.9466'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:22.6957,lwr_k=10:19.2297,lwr_k=20:17.064,lwr_k=30:16.0984,lwr_k=40:15.585,lwr_k=50:15.2737,lwr_k=100:15.1888,lwr_k=200:15.4066,lwr_k=300:15.6202,lwr_k=400:15.7495,lwr_k=500:15.8605,lwr_k=600:15.9569,lwr_k=700:16.0887,lwr_k=800:16.272,lwr_k=900:16.4152,lwr_k=1000:16.5338'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:14.1259,lwr_k=10:7.8565,lwr_k=20:8.9354,lwr_k=30:9.2905,lwr_k=40:9.8657,lwr_k=50:10.2736,lwr_k=100:11.0832,lwr_k=200:11.7075,lwr_k=300:11.9749,lwr_k=400:12.1738,lwr_k=500:12.2707,lwr_k=600:12.3896,lwr_k=700:12.4691,lwr_k=800:12.515,lwr_k=900:12.5947,lwr_k=1000:12.6393'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:9.8025,lwr_k=10:11.1214,lwr_k=20:9.5839,lwr_k=30:9.2416,lwr_k=40:9.2014,lwr_k=50:9.018,lwr_k=100:8.6732,lwr_k=200:8.4757,lwr_k=300:8.4602,lwr_k=400:8.6322,lwr_k=500:8.6364,lwr_k=600:8.6516,lwr_k=700:8.6775,lwr_k=800:8.7891,lwr_k=900:8.7758,lwr_k=1000:8.8095'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:16.024,lwr_k=10:8.1705,lwr_k=20:9.3236,lwr_k=30:9.6107,lwr_k=40:10.0181,lwr_k=50:10.3426,lwr_k=100:11.1454,lwr_k=200:11.9923,lwr_k=300:12.4695,lwr_k=400:12.8371,lwr_k=500:12.9484,lwr_k=600:13.1631,lwr_k=700:13.3537,lwr_k=800:13.4299,lwr_k=900:13.528,lwr_k=1000:13.6795'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:14.0591,lwr_k=10:13.0725,lwr_k=20:11.4586,lwr_k=30:11.5589,lwr_k=40:11.5368,lwr_k=50:11.6192,lwr_k=100:11.8404,lwr_k=200:11.8711,lwr_k=300:11.7495,lwr_k=400:11.7233,lwr_k=500:11.7053,lwr_k=600:11.7002,lwr_k=700:11.7787,lwr_k=800:11.8248,lwr_k=900:11.8698,lwr_k=1000:11.8916'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:15.3476,lwr_k=10:9.094,lwr_k=20:9.9692,lwr_k=30:10.383,lwr_k=40:10.5443,lwr_k=50:10.7332,lwr_k=100:10.9319,lwr_k=200:11.2725,lwr_k=300:11.5057,lwr_k=400:11.7097,lwr_k=500:11.8678,lwr_k=600:12.0434,lwr_k=700:12.2023,lwr_k=800:12.3487,lwr_k=900:12.4735,lwr_k=1000:12.5654'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:48.1333,lwr_k=10:25.6878,lwr_k=20:25.2966,lwr_k=30:27.5258,lwr_k=40:28.3092,lwr_k=50:29.6378,lwr_k=100:31.126,lwr_k=200:34.1481,lwr_k=300:35.4928,lwr_k=400:36.7576,lwr_k=500:37.7711,lwr_k=600:38.6231,lwr_k=700:39.3693,lwr_k=800:40.0103,lwr_k=900:40.6142,lwr_k=1000:41.0769'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:12.3078,lwr_k=10:7.1114,lwr_k=20:8.0711,lwr_k=30:8.3132,lwr_k=40:8.4687,lwr_k=50:8.7083,lwr_k=100:9.2084,lwr_k=200:9.6261,lwr_k=300:9.9233,lwr_k=400:10.0834,lwr_k=500:10.2116,lwr_k=600:10.3091,lwr_k=700:10.3907,lwr_k=800:10.4525,lwr_k=900:10.5123,lwr_k=1000:10.5733'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:13.3531,lwr_k=10:16.0875,lwr_k=20:12.6031,lwr_k=30:12.3336,lwr_k=40:11.7974,lwr_k=50:11.795,lwr_k=100:11.913,lwr_k=200:11.9468,lwr_k=300:11.9139,lwr_k=400:12.003,lwr_k=500:12.2684,lwr_k=600:12.292,lwr_k=700:12.3985,lwr_k=800:12.4181,lwr_k=900:12.4361,lwr_k=1000:12.4568'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_29'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.8074,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.6905,lwr_k=40:0.9298,lwr_k=50:1.2128,lwr_k=100:3.2901,lwr_k=200:4.245,lwr_k=300:4.5939,lwr_k=400:4.8347,lwr_k=500:4.915,lwr_k=600:5.0032,lwr_k=700:5.0441,lwr_k=800:5.1081,lwr_k=900:5.1533,lwr_k=1000:5.198'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.6583,lwr_k=10:22.2356,lwr_k=20:366.452,lwr_k=30:185.5977,lwr_k=40:29.0399,lwr_k=50:51.5738,lwr_k=100:14.9515,lwr_k=200:12.7558,lwr_k=300:9.2657,lwr_k=400:9.2452,lwr_k=500:9.2476,lwr_k=600:8.3993,lwr_k=700:8.5787,lwr_k=800:8.6055,lwr_k=900:8.896,lwr_k=1000:8.6096'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.2375,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.8267,lwr_k=40:1.6722,lwr_k=50:2.0358,lwr_k=100:3.7779,lwr_k=200:5.417,lwr_k=300:6.1315,lwr_k=400:6.4636,lwr_k=500:6.6492,lwr_k=600:6.7789,lwr_k=700:6.8771,lwr_k=800:6.9835,lwr_k=900:7.05,lwr_k=1000:7.117'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.0984,lwr_k=10:19.5651,lwr_k=20:90.9489,lwr_k=30:152.5351,lwr_k=40:53.5051,lwr_k=50:32.4567,lwr_k=100:15.4821,lwr_k=200:8.9196,lwr_k=300:7.0913,lwr_k=400:7.2068,lwr_k=500:7.2786,lwr_k=600:7.2945,lwr_k=700:7.3018,lwr_k=800:7.3383,lwr_k=900:7.3939,lwr_k=1000:7.4245'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.8228,lwr_k=10:0.0,lwr_k=20:0.0033,lwr_k=30:1.3406,lwr_k=40:1.9607,lwr_k=50:2.747,lwr_k=100:4.9837,lwr_k=200:7.1986,lwr_k=300:7.9615,lwr_k=400:8.4954,lwr_k=500:8.7508,lwr_k=600:8.9968,lwr_k=700:9.0972,lwr_k=800:9.2516,lwr_k=900:9.338,lwr_k=1000:9.4139'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.2164,lwr_k=10:30.9168,lwr_k=20:1230.1723,lwr_k=30:385.1184,lwr_k=40:41.5858,lwr_k=50:356107.9705,lwr_k=100:22.9463,lwr_k=200:6108.9016,lwr_k=300:13.8143,lwr_k=400:7.0915,lwr_k=500:6.9192,lwr_k=600:6.8388,lwr_k=700:6.8288,lwr_k=800:6.8314,lwr_k=900:6.8247,lwr_k=1000:6.7988'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.3125,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.453,lwr_k=40:1.3149,lwr_k=50:1.8478,lwr_k=100:3.7521,lwr_k=200:5.449,lwr_k=300:6.03,lwr_k=400:6.3017,lwr_k=500:6.5703,lwr_k=600:6.7281,lwr_k=700:6.9133,lwr_k=800:6.9924,lwr_k=900:7.0888,lwr_k=1000:7.169'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:10.9084,lwr_k=10:35.9484,lwr_k=20:90.0781,lwr_k=30:1222394.6244,lwr_k=40:42.4205,lwr_k=50:31.8025,lwr_k=100:15.2293,lwr_k=200:11.658,lwr_k=300:9.6328,lwr_k=400:9.4873,lwr_k=500:9.5299,lwr_k=600:9.8096,lwr_k=700:9.8105,lwr_k=800:9.9342,lwr_k=900:10.0079,lwr_k=1000:10.0074'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.2824,lwr_k=10:0.0,lwr_k=20:0.0068,lwr_k=30:1.0469,lwr_k=40:0.7385,lwr_k=50:1.0594,lwr_k=100:3.1294,lwr_k=200:4.8184,lwr_k=300:5.46,lwr_k=400:5.8427,lwr_k=500:6.0283,lwr_k=600:6.1569,lwr_k=700:6.2725,lwr_k=800:6.3196,lwr_k=900:6.3779,lwr_k=1000:6.4144'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:26.7246,lwr_k=10:33.1916,lwr_k=20:934.1308,lwr_k=30:490.766,lwr_k=40:34495.9904,lwr_k=50:40.2628,lwr_k=100:36.6744,lwr_k=200:26.962,lwr_k=300:22.8009,lwr_k=400:23.3464,lwr_k=500:23.438,lwr_k=600:24.0576,lwr_k=700:24.222,lwr_k=800:24.3278,lwr_k=900:24.4805,lwr_k=1000:24.4994'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:6.8096,lwr_k=10:0.0,lwr_k=20:0.0003,lwr_k=30:0.7856,lwr_k=40:1.2966,lwr_k=50:1.6331,lwr_k=100:3.1844,lwr_k=200:4.6525,lwr_k=300:5.1072,lwr_k=400:5.3583,lwr_k=500:5.5045,lwr_k=600:5.6088,lwr_k=700:5.6878,lwr_k=800:5.756,lwr_k=900:5.7946,lwr_k=1000:5.8637'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:12.3824,lwr_k=10:36.9528,lwr_k=20:224.9221,lwr_k=30:653.7005,lwr_k=40:573939.9919,lwr_k=50:39.5591,lwr_k=100:18.6112,lwr_k=200:13.5733,lwr_k=300:9.9575,lwr_k=400:9.9924,lwr_k=500:10.4067,lwr_k=600:10.411,lwr_k=700:10.61,lwr_k=800:10.768,lwr_k=900:10.9516,lwr_k=1000:11.068'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_30'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:11.3403,lwr_k=10:8.4521,lwr_k=20:9.3255,lwr_k=30:9.3876,lwr_k=40:9.3264,lwr_k=50:9.4054,lwr_k=100:9.6695,lwr_k=200:10.0441,lwr_k=300:10.2161,lwr_k=400:10.3159,lwr_k=500:10.365,lwr_k=600:10.3742,lwr_k=700:10.394,lwr_k=800:10.4124,lwr_k=900:10.3915,lwr_k=1000:10.3828'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:14.4202,lwr_k=10:15.0921,lwr_k=20:14.4682,lwr_k=30:14.3447,lwr_k=40:13.8957,lwr_k=50:13.6812,lwr_k=100:13.509,lwr_k=200:13.6378,lwr_k=300:13.9271,lwr_k=400:14.0425,lwr_k=500:14.1325,lwr_k=600:14.1768,lwr_k=700:14.1988,lwr_k=800:14.2168,lwr_k=900:14.1982,lwr_k=1000:14.1683'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:45.8286,lwr_k=10:32.1924,lwr_k=20:35.6598,lwr_k=30:36.7591,lwr_k=40:37.9148,lwr_k=50:38.6783,lwr_k=100:40.7494,lwr_k=200:42.4577,lwr_k=300:43.0498,lwr_k=400:43.5008,lwr_k=500:43.8435,lwr_k=600:44.0969,lwr_k=700:44.3915,lwr_k=800:44.5417,lwr_k=900:44.6531,lwr_k=1000:44.7148'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:41.2297,lwr_k=10:51.14,lwr_k=20:47.2737,lwr_k=30:41.6096,lwr_k=40:40.3533,lwr_k=50:40.7855,lwr_k=100:39.4148,lwr_k=200:38.8312,lwr_k=300:38.6348,lwr_k=400:38.5377,lwr_k=500:38.6389,lwr_k=600:38.8247,lwr_k=700:39.1835,lwr_k=800:39.4199,lwr_k=900:39.7092,lwr_k=1000:39.9392'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:11.8035,lwr_k=10:10.2128,lwr_k=20:10.8741,lwr_k=30:11.1798,lwr_k=40:11.4921,lwr_k=50:11.4728,lwr_k=100:11.4223,lwr_k=200:11.5571,lwr_k=300:11.5479,lwr_k=400:11.544,lwr_k=500:11.5685,lwr_k=600:11.5769,lwr_k=700:11.5939,lwr_k=800:11.6117,lwr_k=900:11.6162,lwr_k=1000:11.619'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:12.1508,lwr_k=10:12.8138,lwr_k=20:11.8814,lwr_k=30:11.5251,lwr_k=40:11.931,lwr_k=50:12.0495,lwr_k=100:11.9138,lwr_k=200:12.0934,lwr_k=300:12.1267,lwr_k=400:12.0546,lwr_k=500:12.048,lwr_k=600:12.032,lwr_k=700:12.006,lwr_k=800:12.0267,lwr_k=900:12.0254,lwr_k=1000:12.026'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:13.1192,lwr_k=10:8.5494,lwr_k=20:9.0965,lwr_k=30:9.544,lwr_k=40:9.9308,lwr_k=50:10.3017,lwr_k=100:10.9663,lwr_k=200:12.3682,lwr_k=300:12.5646,lwr_k=400:12.6286,lwr_k=500:12.6998,lwr_k=600:12.7168,lwr_k=700:12.7443,lwr_k=800:12.7331,lwr_k=900:12.7751,lwr_k=1000:12.7727'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:12.295,lwr_k=10:12.5806,lwr_k=20:11.9386,lwr_k=30:11.4076,lwr_k=40:11.4423,lwr_k=50:11.1182,lwr_k=100:11.5309,lwr_k=200:12.1456,lwr_k=300:12.165,lwr_k=400:12.1457,lwr_k=500:12.1014,lwr_k=600:12.1278,lwr_k=700:12.1687,lwr_k=800:12.199,lwr_k=900:12.2633,lwr_k=1000:12.2885'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.5674,lwr_k=10:7.0168,lwr_k=20:7.57,lwr_k=30:7.6713,lwr_k=40:7.7677,lwr_k=50:7.8665,lwr_k=100:8.0286,lwr_k=200:8.2135,lwr_k=300:8.3011,lwr_k=400:8.3542,lwr_k=500:8.3717,lwr_k=600:8.4076,lwr_k=700:8.4257,lwr_k=800:8.4369,lwr_k=900:8.4632,lwr_k=1000:8.463'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:23.2038,lwr_k=10:24.9674,lwr_k=20:23.732,lwr_k=30:23.4593,lwr_k=40:23.5041,lwr_k=50:23.3457,lwr_k=100:23.0928,lwr_k=200:22.6815,lwr_k=300:22.7323,lwr_k=400:22.7612,lwr_k=500:22.8087,lwr_k=600:22.8083,lwr_k=700:22.8906,lwr_k=800:22.9051,lwr_k=900:22.96,lwr_k=1000:22.9882'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:14.2522,lwr_k=10:11.1723,lwr_k=20:12.0511,lwr_k=30:12.4795,lwr_k=40:12.7473,lwr_k=50:12.8254,lwr_k=100:13.0593,lwr_k=200:13.283,lwr_k=300:13.3542,lwr_k=400:13.3624,lwr_k=500:13.3745,lwr_k=600:13.3641,lwr_k=700:13.3755,lwr_k=800:13.3815,lwr_k=900:13.402,lwr_k=1000:13.408'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:15.5735,lwr_k=10:16.2548,lwr_k=20:15.2036,lwr_k=30:14.7703,lwr_k=40:14.8328,lwr_k=50:14.6956,lwr_k=100:14.8074,lwr_k=200:14.7917,lwr_k=300:14.8267,lwr_k=400:14.8653,lwr_k=500:14.8537,lwr_k=600:14.817,lwr_k=700:14.8482,lwr_k=800:14.8509,lwr_k=900:14.8674,lwr_k=1000:14.8772'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_31'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.1116,lwr_k=10:0.0001,lwr_k=20:0.0043,lwr_k=30:0.0192,lwr_k=40:0.0522,lwr_k=50:0.5722,lwr_k=100:2.4766,lwr_k=200:3.4399,lwr_k=300:3.8364,lwr_k=400:4.0404,lwr_k=500:4.1582,lwr_k=600:4.2047,lwr_k=700:4.2474,lwr_k=800:4.2882,lwr_k=900:4.3433,lwr_k=1000:4.3696'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.2705,lwr_k=10:17.5167,lwr_k=20:25.5776,lwr_k=30:49.0031,lwr_k=40:955.5511,lwr_k=50:29259.9058,lwr_k=100:9.7849,lwr_k=200:7.9769,lwr_k=300:7.8111,lwr_k=400:7.7854,lwr_k=500:7.894,lwr_k=600:7.9201,lwr_k=700:7.9974,lwr_k=800:8.05,lwr_k=900:8.1044,lwr_k=1000:8.0791'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.697,lwr_k=10:0.0058,lwr_k=20:0.0628,lwr_k=30:0.1278,lwr_k=40:0.3196,lwr_k=50:1.0744,lwr_k=100:3.2361,lwr_k=200:4.5288,lwr_k=300:5.1756,lwr_k=400:5.6432,lwr_k=500:5.9754,lwr_k=600:6.2391,lwr_k=700:6.456,lwr_k=800:6.5592,lwr_k=900:6.6585,lwr_k=1000:6.7895'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.4881,lwr_k=10:26.6828,lwr_k=20:50.0409,lwr_k=30:189.4772,lwr_k=40:104826.7739,lwr_k=50:133.3173,lwr_k=100:9.1559,lwr_k=200:6.962,lwr_k=300:6.4521,lwr_k=400:6.3507,lwr_k=500:6.2708,lwr_k=600:6.2877,lwr_k=700:6.2744,lwr_k=800:6.2898,lwr_k=900:6.3005,lwr_k=1000:6.3376'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.4872,lwr_k=10:0.0119,lwr_k=20:0.0794,lwr_k=30:0.1289,lwr_k=40:0.1914,lwr_k=50:1.1016,lwr_k=100:3.2965,lwr_k=200:4.3193,lwr_k=300:4.7671,lwr_k=400:5.1114,lwr_k=500:5.4267,lwr_k=600:5.5832,lwr_k=700:5.8465,lwr_k=800:6.0763,lwr_k=900:6.1938,lwr_k=1000:6.3871'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.7461,lwr_k=10:32.176,lwr_k=20:36.9184,lwr_k=30:286.9411,lwr_k=40:65554.6903,lwr_k=50:69119.4446,lwr_k=100:8.2266,lwr_k=200:6.7478,lwr_k=300:6.306,lwr_k=400:6.2404,lwr_k=500:6.2665,lwr_k=600:6.0937,lwr_k=700:6.0715,lwr_k=800:6.065,lwr_k=900:6.0297,lwr_k=1000:6.0668'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.7665,lwr_k=10:0.0,lwr_k=20:0.008,lwr_k=30:0.0259,lwr_k=40:0.0404,lwr_k=50:0.6243,lwr_k=100:2.8112,lwr_k=200:4.2751,lwr_k=300:4.8805,lwr_k=400:5.171,lwr_k=500:5.3624,lwr_k=600:5.5052,lwr_k=700:5.6263,lwr_k=800:5.751,lwr_k=900:5.8342,lwr_k=1000:5.8976'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.966,lwr_k=10:24.06,lwr_k=20:49.1318,lwr_k=30:58.8892,lwr_k=40:346.1059,lwr_k=50:96.2691,lwr_k=100:10.6106,lwr_k=200:9.6995,lwr_k=300:8.2471,lwr_k=400:8.2541,lwr_k=500:8.2667,lwr_k=600:8.2487,lwr_k=700:8.267,lwr_k=800:8.3004,lwr_k=900:8.3104,lwr_k=1000:8.3678'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.2151,lwr_k=10:0.0142,lwr_k=20:0.1153,lwr_k=30:0.212,lwr_k=40:0.4505,lwr_k=50:1.2311,lwr_k=100:3.171,lwr_k=200:4.042,lwr_k=300:4.2863,lwr_k=400:4.4417,lwr_k=500:4.5718,lwr_k=600:4.6533,lwr_k=700:4.6969,lwr_k=800:4.7485,lwr_k=900:4.7877,lwr_k=1000:4.8207'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:20.5052,lwr_k=10:59.7746,lwr_k=20:230.7856,lwr_k=30:197.9559,lwr_k=40:821.4578,lwr_k=50:4949.8254,lwr_k=100:20.5253,lwr_k=200:16.4753,lwr_k=300:15.6238,lwr_k=400:16.1545,lwr_k=500:16.7351,lwr_k=600:16.4441,lwr_k=700:16.5745,lwr_k=800:16.8152,lwr_k=900:17.3651,lwr_k=1000:17.3597'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:5.4689,lwr_k=10:0.0477,lwr_k=20:0.1578,lwr_k=30:0.3424,lwr_k=40:0.8961,lwr_k=50:1.0966,lwr_k=100:2.7947,lwr_k=200:3.7075,lwr_k=300:4.2439,lwr_k=400:4.606,lwr_k=500:4.8329,lwr_k=600:4.9707,lwr_k=700:5.0364,lwr_k=800:5.1095,lwr_k=900:5.157,lwr_k=1000:5.1828'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.7311,lwr_k=10:49.8857,lwr_k=20:72.5522,lwr_k=30:158.6142,lwr_k=40:838772.6114,lwr_k=50:119269.9335,lwr_k=100:10.6668,lwr_k=200:9.4797,lwr_k=300:8.7765,lwr_k=400:7.9049,lwr_k=500:7.7043,lwr_k=600:7.6583,lwr_k=700:7.5898,lwr_k=800:7.5993,lwr_k=900:7.5642,lwr_k=1000:7.5401'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_32'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:51.9503,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:1.7685,lwr_k=50:3.1675,lwr_k=100:7.7792,lwr_k=200:12.4101,lwr_k=300:15.9034,lwr_k=400:18.0115,lwr_k=500:20.1808,lwr_k=600:21.6639,lwr_k=700:23.0989,lwr_k=800:24.3629,lwr_k=900:25.7626,lwr_k=1000:27.1061'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:69.5441,lwr_k=10:37.4078,lwr_k=20:49.0049,lwr_k=30:1250.9767,lwr_k=40:46.0598,lwr_k=50:33.8371,lwr_k=100:22.8047,lwr_k=200:19.6124,lwr_k=300:22.0544,lwr_k=400:24.3841,lwr_k=500:26.1652,lwr_k=600:28.548,lwr_k=700:31.0702,lwr_k=800:33.1623,lwr_k=900:34.8113,lwr_k=1000:36.6512'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:65.7333,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:2.1615,lwr_k=50:4.2719,lwr_k=100:10.3143,lwr_k=200:16.076,lwr_k=300:19.3028,lwr_k=400:22.106,lwr_k=500:24.2134,lwr_k=600:26.3362,lwr_k=700:28.3451,lwr_k=800:30.1859,lwr_k=900:32.3691,lwr_k=1000:33.9205'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:56.5212,lwr_k=10:37.141,lwr_k=20:46.4767,lwr_k=30:534.3191,lwr_k=40:41.6068,lwr_k=50:28.3136,lwr_k=100:18.9672,lwr_k=200:20.1733,lwr_k=300:22.1988,lwr_k=400:23.6253,lwr_k=500:24.9024,lwr_k=600:26.3437,lwr_k=700:28.0282,lwr_k=800:29.1306,lwr_k=900:30.1304,lwr_k=1000:31.2513'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:73.0322,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:2.5354,lwr_k=50:4.5494,lwr_k=100:10.2782,lwr_k=200:17.0135,lwr_k=300:21.0058,lwr_k=400:23.9284,lwr_k=500:27.0231,lwr_k=600:29.0108,lwr_k=700:30.9811,lwr_k=800:32.9189,lwr_k=900:35.0847,lwr_k=1000:36.4926'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:47.11,lwr_k=10:32.2036,lwr_k=20:50.3378,lwr_k=30:576.0802,lwr_k=40:59.4587,lwr_k=50:27.8286,lwr_k=100:16.1505,lwr_k=200:16.2495,lwr_k=300:17.4904,lwr_k=400:18.0777,lwr_k=500:18.7842,lwr_k=600:20.1595,lwr_k=700:21.1666,lwr_k=800:21.6853,lwr_k=900:22.6375,lwr_k=1000:23.4256'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:70.8639,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:2.2,lwr_k=50:3.9119,lwr_k=100:8.9737,lwr_k=200:16.3773,lwr_k=300:21.1355,lwr_k=400:24.0228,lwr_k=500:26.9072,lwr_k=600:29.1451,lwr_k=700:31.116,lwr_k=800:33.1128,lwr_k=900:35.1166,lwr_k=1000:36.4048'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:63.4128,lwr_k=10:35.5768,lwr_k=20:58.5207,lwr_k=30:984.1997,lwr_k=40:44.1863,lwr_k=50:29.6869,lwr_k=100:20.4605,lwr_k=200:21.0387,lwr_k=300:22.7723,lwr_k=400:23.3458,lwr_k=500:24.4315,lwr_k=600:25.5737,lwr_k=700:26.9571,lwr_k=800:28.1382,lwr_k=900:29.1784,lwr_k=1000:30.3348'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:53.8343,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:2.0047,lwr_k=50:3.4052,lwr_k=100:7.5276,lwr_k=200:12.3804,lwr_k=300:15.8599,lwr_k=400:18.0427,lwr_k=500:19.8437,lwr_k=600:21.7642,lwr_k=700:23.2879,lwr_k=800:24.7029,lwr_k=900:26.1552,lwr_k=1000:27.5458'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:100.4585,lwr_k=10:54.57,lwr_k=20:54.3969,lwr_k=30:569.4849,lwr_k=40:56.1096,lwr_k=50:47.6463,lwr_k=100:34.4965,lwr_k=200:43.1275,lwr_k=300:47.0897,lwr_k=400:51.4487,lwr_k=500:55.3845,lwr_k=600:57.238,lwr_k=700:59.8317,lwr_k=800:61.5433,lwr_k=900:63.9341,lwr_k=1000:66.7696'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:64.5564,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:2.0311,lwr_k=50:3.8773,lwr_k=100:8.1401,lwr_k=200:13.1764,lwr_k=300:17.4447,lwr_k=400:20.0118,lwr_k=500:21.908,lwr_k=600:23.7582,lwr_k=700:25.4827,lwr_k=800:27.0101,lwr_k=900:28.3702,lwr_k=1000:29.651'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:63.5478,lwr_k=10:35.897,lwr_k=20:50.0315,lwr_k=30:1035.269,lwr_k=40:43.5054,lwr_k=50:25.31,lwr_k=100:21.2628,lwr_k=200:21.3112,lwr_k=300:21.8762,lwr_k=400:23.7786,lwr_k=500:25.0459,lwr_k=600:26.0092,lwr_k=700:27.0961,lwr_k=800:28.1513,lwr_k=900:28.6648,lwr_k=1000:29.6731'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_33'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:57.8736,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0036,lwr_k=50:1.0408,lwr_k=100:8.2455,lwr_k=200:14.7108,lwr_k=300:17.486,lwr_k=400:19.5484,lwr_k=500:21.3653,lwr_k=600:23.4371,lwr_k=700:25.4656,lwr_k=800:27.3012,lwr_k=900:28.7681,lwr_k=1000:30.6475'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:73.9139,lwr_k=10:95.885,lwr_k=20:115.2934,lwr_k=30:152.5029,lwr_k=40:263.1439,lwr_k=50:186.8843,lwr_k=100:33.7782,lwr_k=200:30.636,lwr_k=300:30.0498,lwr_k=400:31.1712,lwr_k=500:31.0309,lwr_k=600:32.063,lwr_k=700:33.9474,lwr_k=800:34.7345,lwr_k=900:35.6719,lwr_k=1000:37.3494'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:71.9798,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:1.0369,lwr_k=100:7.6869,lwr_k=200:14.7133,lwr_k=300:19.0583,lwr_k=400:22.3737,lwr_k=500:24.7611,lwr_k=600:27.3277,lwr_k=700:29.3088,lwr_k=800:31.0542,lwr_k=900:32.9302,lwr_k=1000:34.3874'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:56.7109,lwr_k=10:48.3705,lwr_k=20:58.3923,lwr_k=30:83.0099,lwr_k=40:176.477,lwr_k=50:125.8321,lwr_k=100:25.0372,lwr_k=200:19.3599,lwr_k=300:21.4515,lwr_k=400:22.5296,lwr_k=500:23.8792,lwr_k=600:24.8249,lwr_k=700:25.3145,lwr_k=800:26.8446,lwr_k=900:29.2205,lwr_k=1000:29.465'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:62.2801,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.9046,lwr_k=100:7.0162,lwr_k=200:12.7972,lwr_k=300:17.6864,lwr_k=400:19.7704,lwr_k=500:22.5602,lwr_k=600:25.2018,lwr_k=700:27.8746,lwr_k=800:29.6347,lwr_k=900:31.4831,lwr_k=1000:33.1643'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:41.0541,lwr_k=10:35.968,lwr_k=20:42.0006,lwr_k=30:67.0578,lwr_k=40:160.56,lwr_k=50:87.4153,lwr_k=100:19.4292,lwr_k=200:15.6852,lwr_k=300:15.853,lwr_k=400:16.9277,lwr_k=500:17.6915,lwr_k=600:17.848,lwr_k=700:19.0234,lwr_k=800:19.6723,lwr_k=900:20.3169,lwr_k=1000:20.3914'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:60.3111,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.819,lwr_k=100:7.2383,lwr_k=200:13.1012,lwr_k=300:16.6357,lwr_k=400:19.3189,lwr_k=500:22.0656,lwr_k=600:24.0983,lwr_k=700:26.4238,lwr_k=800:28.3628,lwr_k=900:30.2488,lwr_k=1000:31.8228'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:58.0351,lwr_k=10:32.3716,lwr_k=20:46.6222,lwr_k=30:70.9547,lwr_k=40:183.6983,lwr_k=50:78.8919,lwr_k=100:22.7608,lwr_k=200:20.0297,lwr_k=300:21.5881,lwr_k=400:22.5846,lwr_k=500:22.8695,lwr_k=600:25.1153,lwr_k=700:26.6276,lwr_k=800:28.0437,lwr_k=900:29.7458,lwr_k=1000:31.2555'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:43.9937,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.7072,lwr_k=100:5.6168,lwr_k=200:10.0519,lwr_k=300:12.6495,lwr_k=400:14.9593,lwr_k=500:16.8992,lwr_k=600:18.3187,lwr_k=700:19.9977,lwr_k=800:21.4969,lwr_k=900:22.7317,lwr_k=1000:23.8702'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:77.2767,lwr_k=10:47.5156,lwr_k=20:55.0466,lwr_k=30:81.446,lwr_k=40:181.8934,lwr_k=50:101.403,lwr_k=100:33.8958,lwr_k=200:36.5362,lwr_k=300:36.5744,lwr_k=400:40.1936,lwr_k=500:44.7552,lwr_k=600:45.7244,lwr_k=700:48.1486,lwr_k=800:50.3321,lwr_k=900:51.395,lwr_k=1000:52.5717'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:54.8934,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.8219,lwr_k=100:5.9029,lwr_k=200:10.8583,lwr_k=300:13.8206,lwr_k=400:16.1083,lwr_k=500:18.0167,lwr_k=600:19.7498,lwr_k=700:21.2914,lwr_k=800:22.7508,lwr_k=900:24.2124,lwr_k=1000:25.4809'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:59.8975,lwr_k=10:39.1041,lwr_k=20:57.8853,lwr_k=30:68.8808,lwr_k=40:169.6871,lwr_k=50:78.4138,lwr_k=100:17.9632,lwr_k=200:18.1464,lwr_k=300:21.7186,lwr_k=400:22.9415,lwr_k=500:25.1322,lwr_k=600:26.0717,lwr_k=700:27.4731,lwr_k=800:29.2067,lwr_k=900:30.358,lwr_k=1000:31.0043'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_34'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.0734,lwr_k=10:0.0,lwr_k=20:0.0001,lwr_k=30:0.2902,lwr_k=40:0.9074,lwr_k=50:8.5665,lwr_k=100:5.0941,lwr_k=200:6.8053,lwr_k=300:7.5401,lwr_k=400:8.0922,lwr_k=500:8.3329,lwr_k=600:8.4998,lwr_k=700:8.6482,lwr_k=800:8.7748,lwr_k=900:8.9045,lwr_k=1000:9.005'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:13.1533,lwr_k=10:76.3602,lwr_k=20:118.216,lwr_k=30:224.4542,lwr_k=40:500.4217,lwr_k=50:121.3862,lwr_k=100:19.0254,lwr_k=200:12.6032,lwr_k=300:12.3448,lwr_k=400:12.1286,lwr_k=500:11.9968,lwr_k=600:12.0696,lwr_k=700:12.1464,lwr_k=800:12.1821,lwr_k=900:12.2653,lwr_k=1000:12.3707'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.1473,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.5509,lwr_k=100:2.3474,lwr_k=200:4.0579,lwr_k=300:5.0451,lwr_k=400:5.4049,lwr_k=500:5.5788,lwr_k=600:5.7269,lwr_k=700:5.8034,lwr_k=800:5.9062,lwr_k=900:6.0131,lwr_k=1000:6.0913'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:6.8641,lwr_k=10:18.9542,lwr_k=20:28.7499,lwr_k=30:38.2296,lwr_k=40:268.0917,lwr_k=50:75.3611,lwr_k=100:8.6021,lwr_k=200:6.6858,lwr_k=300:6.2859,lwr_k=400:6.1486,lwr_k=500:6.1084,lwr_k=600:6.1181,lwr_k=700:6.1098,lwr_k=800:6.1396,lwr_k=900:6.1523,lwr_k=1000:6.1821'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.2133,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0097,lwr_k=40:0.1624,lwr_k=50:1.4576,lwr_k=100:3.0893,lwr_k=200:4.8985,lwr_k=300:5.316,lwr_k=400:5.5306,lwr_k=500:5.7261,lwr_k=600:5.8095,lwr_k=700:5.915,lwr_k=800:6.0355,lwr_k=900:6.1482,lwr_k=1000:6.2279'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.3502,lwr_k=10:81.4346,lwr_k=20:81.2322,lwr_k=30:164.8693,lwr_k=40:478.3864,lwr_k=50:240.6525,lwr_k=100:15.6069,lwr_k=200:6.803,lwr_k=300:6.1842,lwr_k=400:6.0776,lwr_k=500:6.0541,lwr_k=600:5.9807,lwr_k=700:5.8412,lwr_k=800:5.7618,lwr_k=900:5.7083,lwr_k=1000:5.72'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.836,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0247,lwr_k=40:0.4274,lwr_k=50:3.3636,lwr_k=100:3.6248,lwr_k=200:4.8187,lwr_k=300:5.1173,lwr_k=400:5.3492,lwr_k=500:5.4881,lwr_k=600:5.616,lwr_k=700:5.7147,lwr_k=800:5.7856,lwr_k=900:5.8334,lwr_k=1000:6.0044'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:9.021,lwr_k=10:52.8327,lwr_k=20:165.4866,lwr_k=30:312.3324,lwr_k=40:27722.3862,lwr_k=50:77264.2194,lwr_k=100:376.0008,lwr_k=200:9.2028,lwr_k=300:11.5344,lwr_k=400:7.9671,lwr_k=500:8.032,lwr_k=600:7.9352,lwr_k=700:7.8133,lwr_k=800:7.8971,lwr_k=900:7.9174,lwr_k=1000:12.2177'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.9451,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0004,lwr_k=40:0.0299,lwr_k=50:0.7347,lwr_k=100:2.5176,lwr_k=200:3.6104,lwr_k=300:3.9814,lwr_k=400:4.2106,lwr_k=500:4.3242,lwr_k=600:4.4401,lwr_k=700:4.5476,lwr_k=800:4.6101,lwr_k=900:4.6649,lwr_k=1000:4.6948'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:18.1838,lwr_k=10:61.5466,lwr_k=20:98.1624,lwr_k=30:135.0208,lwr_k=40:3211.5315,lwr_k=50:691.9473,lwr_k=100:51.453,lwr_k=200:16.2705,lwr_k=300:15.7925,lwr_k=400:15.6263,lwr_k=500:15.2642,lwr_k=600:15.5676,lwr_k=700:15.835,lwr_k=800:16.1683,lwr_k=900:16.3338,lwr_k=1000:16.8855'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:6.3272,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0008,lwr_k=50:0.5579,lwr_k=100:2.2732,lwr_k=200:3.2602,lwr_k=300:3.7039,lwr_k=400:3.9605,lwr_k=500:4.1061,lwr_k=600:4.2154,lwr_k=700:4.3558,lwr_k=800:4.4418,lwr_k=900:4.5288,lwr_k=1000:4.6087'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.9876,lwr_k=10:41.8848,lwr_k=20:55.4132,lwr_k=30:131.7361,lwr_k=40:1196.8644,lwr_k=50:187.5163,lwr_k=100:9.325,lwr_k=200:6.8208,lwr_k=300:6.6979,lwr_k=400:6.7735,lwr_k=500:6.758,lwr_k=600:6.7966,lwr_k=700:6.8581,lwr_k=800:6.9578,lwr_k=900:6.9871,lwr_k=1000:7.033'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_35'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.2739,lwr_k=10:3.4597,lwr_k=20:4.6863,lwr_k=30:4.9635,lwr_k=40:5.1424,lwr_k=50:5.2063,lwr_k=100:5.4729,lwr_k=200:5.658,lwr_k=300:5.7729,lwr_k=400:5.8388,lwr_k=500:5.8847,lwr_k=600:5.9236,lwr_k=700:5.9554,lwr_k=800:5.9718,lwr_k=900:5.9859,lwr_k=1000:6.0036'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.4118,lwr_k=10:13.314,lwr_k=20:9.9652,lwr_k=30:9.1347,lwr_k=40:8.8841,lwr_k=50:8.8289,lwr_k=100:8.7049,lwr_k=200:8.8073,lwr_k=300:8.9879,lwr_k=400:9.019,lwr_k=500:9.0244,lwr_k=600:9.0303,lwr_k=700:9.0611,lwr_k=800:9.1038,lwr_k=900:9.1502,lwr_k=1000:9.1817'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.4672,lwr_k=10:6.2304,lwr_k=20:7.8251,lwr_k=30:8.3434,lwr_k=40:8.5414,lwr_k=50:8.6151,lwr_k=100:8.8588,lwr_k=200:9.0615,lwr_k=300:9.1182,lwr_k=400:9.1748,lwr_k=500:9.1946,lwr_k=600:9.1966,lwr_k=700:9.222,lwr_k=800:9.2306,lwr_k=900:9.2389,lwr_k=1000:9.277'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.9506,lwr_k=10:14.8114,lwr_k=20:9.2622,lwr_k=30:8.9638,lwr_k=40:9.2971,lwr_k=50:9.3662,lwr_k=100:9.3041,lwr_k=200:9.3525,lwr_k=300:9.2814,lwr_k=400:9.3197,lwr_k=500:9.3309,lwr_k=600:9.3493,lwr_k=700:9.3852,lwr_k=800:9.3965,lwr_k=900:9.421,lwr_k=1000:9.5798'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.8783,lwr_k=10:3.9322,lwr_k=20:5.2316,lwr_k=30:5.8269,lwr_k=40:6.381,lwr_k=50:6.6045,lwr_k=100:7.62,lwr_k=200:9.0304,lwr_k=300:9.4896,lwr_k=400:9.6779,lwr_k=500:9.819,lwr_k=600:9.9141,lwr_k=700:10.0137,lwr_k=800:10.0823,lwr_k=900:10.1575,lwr_k=1000:10.2114'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.7408,lwr_k=10:13.1109,lwr_k=20:8.6498,lwr_k=30:8.0007,lwr_k=40:7.5345,lwr_k=50:7.2002,lwr_k=100:6.845,lwr_k=200:6.6765,lwr_k=300:6.6998,lwr_k=400:6.6971,lwr_k=500:6.757,lwr_k=600:6.9365,lwr_k=700:7.1099,lwr_k=800:7.1271,lwr_k=900:7.1304,lwr_k=1000:7.1407'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.3395,lwr_k=10:2.8994,lwr_k=20:4.6839,lwr_k=30:5.193,lwr_k=40:6.0976,lwr_k=50:6.5721,lwr_k=100:7.2177,lwr_k=200:7.8217,lwr_k=300:8.1684,lwr_k=400:8.3549,lwr_k=500:8.4329,lwr_k=600:8.4889,lwr_k=700:8.5473,lwr_k=800:8.5681,lwr_k=900:8.5912,lwr_k=1000:8.629'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:9.4553,lwr_k=10:14.0645,lwr_k=20:9.8814,lwr_k=30:9.1208,lwr_k=40:8.5823,lwr_k=50:8.5351,lwr_k=100:8.6281,lwr_k=200:9.0901,lwr_k=300:9.1064,lwr_k=400:9.3102,lwr_k=500:9.4123,lwr_k=600:9.4834,lwr_k=700:9.4907,lwr_k=800:9.4814,lwr_k=900:9.4714,lwr_k=1000:9.4453'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.7196,lwr_k=10:2.4601,lwr_k=20:4.1263,lwr_k=30:4.5944,lwr_k=40:4.7543,lwr_k=50:4.8429,lwr_k=100:5.1644,lwr_k=200:5.31,lwr_k=300:5.3522,lwr_k=400:5.4042,lwr_k=500:5.4378,lwr_k=600:5.4789,lwr_k=700:5.5105,lwr_k=800:5.5421,lwr_k=900:5.5593,lwr_k=1000:5.571'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:20.7434,lwr_k=10:36.0846,lwr_k=20:16.9677,lwr_k=30:16.3879,lwr_k=40:17.5525,lwr_k=50:18.4948,lwr_k=100:19.7223,lwr_k=200:20.3171,lwr_k=300:20.2148,lwr_k=400:20.3545,lwr_k=500:20.5453,lwr_k=600:20.6762,lwr_k=700:20.8333,lwr_k=800:20.8411,lwr_k=900:20.9065,lwr_k=1000:20.9133'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:7.7266,lwr_k=10:2.9824,lwr_k=20:4.3585,lwr_k=30:4.9911,lwr_k=40:5.1739,lwr_k=50:5.3249,lwr_k=100:5.9426,lwr_k=200:6.5083,lwr_k=300:6.6473,lwr_k=400:6.7737,lwr_k=500:6.8999,lwr_k=600:7.0185,lwr_k=700:7.0799,lwr_k=800:7.1319,lwr_k=900:7.2098,lwr_k=1000:7.2571'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.2424,lwr_k=10:51.1562,lwr_k=20:9.6126,lwr_k=30:9.6603,lwr_k=40:8.2943,lwr_k=50:8.4914,lwr_k=100:7.4545,lwr_k=200:7.8734,lwr_k=300:8.077,lwr_k=400:8.1567,lwr_k=500:8.2235,lwr_k=600:8.3256,lwr_k=700:8.398,lwr_k=800:8.4915,lwr_k=900:8.5627,lwr_k=1000:8.6245'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_36'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.633,lwr_k=10:5.9075,lwr_k=20:6.5512,lwr_k=30:6.7492,lwr_k=40:6.8262,lwr_k=50:6.9035,lwr_k=100:7.1236,lwr_k=200:6.9079,lwr_k=300:7.3283,lwr_k=400:7.3449,lwr_k=500:7.2965,lwr_k=600:7.3793,lwr_k=700:7.3849,lwr_k=800:7.4529,lwr_k=900:7.4485,lwr_k=1000:7.396'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.2941,lwr_k=10:10.3441,lwr_k=20:9.9097,lwr_k=30:10.3158,lwr_k=40:9.5133,lwr_k=50:9.6867,lwr_k=100:9.4672,lwr_k=200:9.7531,lwr_k=300:9.6285,lwr_k=400:9.8002,lwr_k=500:9.9184,lwr_k=600:10.1395,lwr_k=700:9.9781,lwr_k=800:10.2491,lwr_k=900:9.9222,lwr_k=1000:9.9347'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.8825,lwr_k=10:5.192,lwr_k=20:6.1556,lwr_k=30:6.7268,lwr_k=40:7.5849,lwr_k=50:7.3288,lwr_k=100:7.6942,lwr_k=200:8.3585,lwr_k=300:8.3664,lwr_k=400:8.4258,lwr_k=500:8.1725,lwr_k=600:8.4094,lwr_k=700:8.9507,lwr_k=800:8.499,lwr_k=900:8.6144,lwr_k=1000:8.3282'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.7256,lwr_k=10:14.1335,lwr_k=20:7.919,lwr_k=30:7.336,lwr_k=40:142.1868,lwr_k=50:1966247.1052,lwr_k=100:4899313.2895,lwr_k=200:6.8904,lwr_k=300:6.9042,lwr_k=400:6.832,lwr_k=500:7.0207,lwr_k=600:6.7608,lwr_k=700:6.9127,lwr_k=800:6.8219,lwr_k=900:6.7825,lwr_k=1000:6.9821'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.4529,lwr_k=10:5.8815,lwr_k=20:6.2589,lwr_k=30:6.4816,lwr_k=40:6.5717,lwr_k=50:6.7365,lwr_k=100:6.8236,lwr_k=200:7.0557,lwr_k=300:7.0554,lwr_k=400:7.1656,lwr_k=500:7.2107,lwr_k=600:7.2454,lwr_k=700:7.205,lwr_k=800:7.216,lwr_k=900:7.2063,lwr_k=1000:7.2764'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.7515,lwr_k=10:14.9825,lwr_k=20:7.7088,lwr_k=30:7.597,lwr_k=40:5025158998.7036,lwr_k=50:26.6629,lwr_k=100:7.3315,lwr_k=200:7.3666,lwr_k=300:7.4858,lwr_k=400:7.5919,lwr_k=500:7.3286,lwr_k=600:7.4772,lwr_k=700:7.5529,lwr_k=800:7.4819,lwr_k=900:7.6623,lwr_k=1000:7.4688'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.2796,lwr_k=10:6.3138,lwr_k=20:6.871,lwr_k=30:7.0058,lwr_k=40:7.2386,lwr_k=50:7.374,lwr_k=100:7.4154,lwr_k=200:7.7624,lwr_k=300:7.882,lwr_k=400:7.9385,lwr_k=500:7.9804,lwr_k=600:8.0132,lwr_k=700:8.018,lwr_k=800:8.0219,lwr_k=900:8.0277,lwr_k=1000:8.0092'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:11.7529,lwr_k=10:27.8076,lwr_k=20:10.6437,lwr_k=30:10.3916,lwr_k=40:11985168.394,lwr_k=50:10.9041,lwr_k=100:2635047.8772,lwr_k=200:22422.7309,lwr_k=300:11.3297,lwr_k=400:11.393,lwr_k=500:11.452,lwr_k=600:11.5076,lwr_k=700:11.5069,lwr_k=800:11.5424,lwr_k=900:11.5012,lwr_k=1000:11.5316'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.1068,lwr_k=10:5.3881,lwr_k=20:6.4989,lwr_k=30:6.7351,lwr_k=40:7.1113,lwr_k=50:7.2291,lwr_k=100:7.5038,lwr_k=200:7.7409,lwr_k=300:7.8291,lwr_k=400:7.7973,lwr_k=500:7.8307,lwr_k=600:7.9392,lwr_k=700:7.9853,lwr_k=800:7.9212,lwr_k=900:7.9606,lwr_k=1000:7.9646'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:21.4014,lwr_k=10:57.1406,lwr_k=20:20.2021,lwr_k=30:19.6097,lwr_k=40:21.34,lwr_k=50:380822314.5153,lwr_k=100:2183447.0069,lwr_k=200:2181774.2537,lwr_k=300:20.7578,lwr_k=400:21.0982,lwr_k=500:58.8605,lwr_k=600:21.8966,lwr_k=700:21.128,lwr_k=800:21.2279,lwr_k=900:21.1132,lwr_k=1000:21.1297'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:7.6596,lwr_k=10:5.7841,lwr_k=20:6.3509,lwr_k=30:6.4584,lwr_k=40:6.4702,lwr_k=50:6.6092,lwr_k=100:6.8648,lwr_k=200:7.2266,lwr_k=300:7.2411,lwr_k=400:7.2582,lwr_k=500:7.379,lwr_k=600:7.3544,lwr_k=700:7.5032,lwr_k=800:7.3444,lwr_k=900:7.4296,lwr_k=1000:7.4969'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.8939,lwr_k=10:11.7352,lwr_k=20:11.5583,lwr_k=30:10.356,lwr_k=40:2401835239.5528,lwr_k=50:10.1336,lwr_k=100:10.9111,lwr_k=200:10.8582,lwr_k=300:16.1561,lwr_k=400:10.1457,lwr_k=500:10.1165,lwr_k=600:10.0873,lwr_k=700:10.2087,lwr_k=800:10.1149,lwr_k=900:10.1441,lwr_k=1000:10.2151'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_37'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.8217,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.5549,lwr_k=50:1.2786,lwr_k=100:2.9429,lwr_k=200:4.0711,lwr_k=300:4.578,lwr_k=400:4.9099,lwr_k=500:5.1617,lwr_k=600:5.3612,lwr_k=700:5.5102,lwr_k=800:5.6382,lwr_k=900:5.7149,lwr_k=1000:5.788'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.8653,lwr_k=10:29.8799,lwr_k=20:55.5842,lwr_k=30:95.9799,lwr_k=40:37.9538,lwr_k=50:15.286,lwr_k=100:8.5316,lwr_k=200:7.5864,lwr_k=300:7.7113,lwr_k=400:7.8366,lwr_k=500:7.9177,lwr_k=600:8.1241,lwr_k=700:8.259,lwr_k=800:8.3755,lwr_k=900:8.4856,lwr_k=1000:8.5745'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:15.3824,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.5792,lwr_k=50:1.454,lwr_k=100:4.4088,lwr_k=200:6.7503,lwr_k=300:7.7722,lwr_k=400:8.6588,lwr_k=500:9.1413,lwr_k=600:9.4692,lwr_k=700:9.798,lwr_k=800:10.0743,lwr_k=900:10.3557,lwr_k=1000:10.6003'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:12.7835,lwr_k=10:28.986,lwr_k=20:39.5187,lwr_k=30:108.0241,lwr_k=40:64.0682,lwr_k=50:24.4665,lwr_k=100:9.6502,lwr_k=200:7.6429,lwr_k=300:7.5614,lwr_k=400:7.8092,lwr_k=500:7.7983,lwr_k=600:7.9847,lwr_k=700:8.0623,lwr_k=800:8.3948,lwr_k=900:8.5087,lwr_k=1000:8.6313'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:16.6621,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.725,lwr_k=50:1.6699,lwr_k=100:4.6985,lwr_k=200:7.3788,lwr_k=300:8.7035,lwr_k=400:9.3426,lwr_k=500:9.8942,lwr_k=600:10.2875,lwr_k=700:10.533,lwr_k=800:10.8407,lwr_k=900:11.0792,lwr_k=1000:11.267'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:10.964,lwr_k=10:27.6771,lwr_k=20:27.2328,lwr_k=30:73.8251,lwr_k=40:44.972,lwr_k=50:21.2082,lwr_k=100:8.1233,lwr_k=200:6.9343,lwr_k=300:6.7675,lwr_k=400:6.8592,lwr_k=500:7.0282,lwr_k=600:7.0214,lwr_k=700:7.054,lwr_k=800:7.0888,lwr_k=900:7.1635,lwr_k=1000:7.2455'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:17.37,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.6646,lwr_k=50:1.9806,lwr_k=100:4.8068,lwr_k=200:7.1822,lwr_k=300:8.6053,lwr_k=400:9.2664,lwr_k=500:9.8277,lwr_k=600:10.3555,lwr_k=700:10.8045,lwr_k=800:11.1855,lwr_k=900:11.4967,lwr_k=1000:11.776'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:14.2485,lwr_k=10:35.5147,lwr_k=20:45.0151,lwr_k=30:93.7685,lwr_k=40:73.7115,lwr_k=50:23.1234,lwr_k=100:10.9431,lwr_k=200:9.7061,lwr_k=300:9.333,lwr_k=400:9.2613,lwr_k=500:9.2988,lwr_k=600:9.4799,lwr_k=700:9.6101,lwr_k=800:9.7841,lwr_k=900:9.972,lwr_k=1000:10.0831'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.9535,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.693,lwr_k=50:1.4737,lwr_k=100:3.3167,lwr_k=200:4.5242,lwr_k=300:5.1731,lwr_k=400:5.5999,lwr_k=500:5.8726,lwr_k=600:6.0859,lwr_k=700:6.2647,lwr_k=800:6.4516,lwr_k=900:6.5936,lwr_k=1000:6.7112'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:30.4181,lwr_k=10:63.5831,lwr_k=20:106.1223,lwr_k=30:284.8212,lwr_k=40:120.683,lwr_k=50:42.8709,lwr_k=100:18.3774,lwr_k=200:20.5565,lwr_k=300:20.582,lwr_k=400:21.6067,lwr_k=500:22.51,lwr_k=600:22.8528,lwr_k=700:23.3624,lwr_k=800:23.9378,lwr_k=900:24.2875,lwr_k=1000:24.5188'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:22.4144,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.8771,lwr_k=50:2.2127,lwr_k=100:5.639,lwr_k=200:8.5144,lwr_k=300:10.0224,lwr_k=400:10.887,lwr_k=500:11.4851,lwr_k=600:12.0239,lwr_k=700:12.4304,lwr_k=800:12.7556,lwr_k=900:13.0814,lwr_k=1000:13.3632'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:19.6657,lwr_k=10:34.4891,lwr_k=20:66.9847,lwr_k=30:114.5259,lwr_k=40:63.0279,lwr_k=50:26.1941,lwr_k=100:12.5168,lwr_k=200:12.4076,lwr_k=300:12.4222,lwr_k=400:12.542,lwr_k=500:12.7801,lwr_k=600:12.9132,lwr_k=700:13.0748,lwr_k=800:13.3565,lwr_k=900:13.398,lwr_k=1000:13.5953'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_38'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.9839,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.1104,lwr_k=40:2.2798,lwr_k=50:2.9499,lwr_k=100:4.549,lwr_k=200:5.4737,lwr_k=300:5.9021,lwr_k=400:6.1151,lwr_k=500:6.2453,lwr_k=600:6.3657,lwr_k=700:6.4846,lwr_k=800:6.5691,lwr_k=900:6.643,lwr_k=1000:6.717'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.9654,lwr_k=10:33.0848,lwr_k=20:88.5076,lwr_k=30:43.2536,lwr_k=40:22.0364,lwr_k=50:16.4112,lwr_k=100:10.8072,lwr_k=200:9.1784,lwr_k=300:9.097,lwr_k=400:9.0442,lwr_k=500:9.1017,lwr_k=600:9.1675,lwr_k=700:9.1952,lwr_k=800:9.3002,lwr_k=900:9.3104,lwr_k=1000:9.3901'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:15.6044,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.4759,lwr_k=40:3.1407,lwr_k=50:4.5601,lwr_k=100:7.2147,lwr_k=200:9.3388,lwr_k=300:10.139,lwr_k=400:10.6181,lwr_k=500:10.8965,lwr_k=600:11.1136,lwr_k=700:11.272,lwr_k=800:11.4409,lwr_k=900:11.6255,lwr_k=1000:11.8116'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:12.9405,lwr_k=10:33.2268,lwr_k=20:136.2726,lwr_k=30:52.3712,lwr_k=40:21.2634,lwr_k=50:15.2471,lwr_k=100:9.8746,lwr_k=200:8.8137,lwr_k=300:8.6489,lwr_k=400:8.7882,lwr_k=500:8.8869,lwr_k=600:9.0145,lwr_k=700:9.3539,lwr_k=800:9.4195,lwr_k=900:9.4259,lwr_k=1000:9.4959'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:14.7121,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.5159,lwr_k=40:2.994,lwr_k=50:4.223,lwr_k=100:7.102,lwr_k=200:9.2539,lwr_k=300:10.0914,lwr_k=400:10.6146,lwr_k=500:10.9366,lwr_k=600:11.202,lwr_k=700:11.3791,lwr_k=800:11.5633,lwr_k=900:11.67,lwr_k=1000:11.8126'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:10.2105,lwr_k=10:35.67,lwr_k=20:85.2716,lwr_k=30:42.9167,lwr_k=40:16.7743,lwr_k=50:13.6748,lwr_k=100:9.5766,lwr_k=200:8.4586,lwr_k=300:8.2805,lwr_k=400:8.2857,lwr_k=500:8.1991,lwr_k=600:8.0679,lwr_k=700:8.0142,lwr_k=800:8.0107,lwr_k=900:8.029,lwr_k=1000:8.0127'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:11.705,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.2151,lwr_k=40:2.5363,lwr_k=50:3.7391,lwr_k=100:6.2494,lwr_k=200:7.6461,lwr_k=300:8.4348,lwr_k=400:8.7703,lwr_k=500:9.0201,lwr_k=600:9.2689,lwr_k=700:9.4772,lwr_k=800:9.5495,lwr_k=900:9.6535,lwr_k=1000:9.7284'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:11.5425,lwr_k=10:39.369,lwr_k=20:254.6712,lwr_k=30:41.0988,lwr_k=40:18.2679,lwr_k=50:14.1143,lwr_k=100:10.3506,lwr_k=200:10.4365,lwr_k=300:10.3525,lwr_k=400:10.3858,lwr_k=500:10.2787,lwr_k=600:10.2105,lwr_k=700:10.2389,lwr_k=800:10.333,lwr_k=900:10.3585,lwr_k=1000:10.3379'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.8757,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.131,lwr_k=40:2.4034,lwr_k=50:2.9407,lwr_k=100:4.4058,lwr_k=200:5.3743,lwr_k=300:5.7198,lwr_k=400:5.9426,lwr_k=500:6.0319,lwr_k=600:6.1605,lwr_k=700:6.2527,lwr_k=800:6.3662,lwr_k=900:6.4383,lwr_k=1000:6.5009'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:27.5792,lwr_k=10:39.5042,lwr_k=20:93.3746,lwr_k=30:48.1169,lwr_k=40:23.0696,lwr_k=50:22.3269,lwr_k=100:21.4651,lwr_k=200:21.7777,lwr_k=300:21.8136,lwr_k=400:22.1369,lwr_k=500:22.5366,lwr_k=600:22.9491,lwr_k=700:23.2051,lwr_k=800:23.4704,lwr_k=900:23.6988,lwr_k=1000:23.915'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:8.5706,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.9629,lwr_k=40:1.9751,lwr_k=50:2.7695,lwr_k=100:4.6263,lwr_k=200:5.8901,lwr_k=300:6.3771,lwr_k=400:6.6202,lwr_k=500:6.8321,lwr_k=600:6.9931,lwr_k=700:7.0961,lwr_k=800:7.1509,lwr_k=900:7.2159,lwr_k=1000:7.2976'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:12.9264,lwr_k=10:48.8857,lwr_k=20:103.766,lwr_k=30:55.3223,lwr_k=40:17.586,lwr_k=50:15.381,lwr_k=100:10.127,lwr_k=200:10.1201,lwr_k=300:10.4542,lwr_k=400:10.5945,lwr_k=500:10.9288,lwr_k=600:11.116,lwr_k=700:11.2579,lwr_k=800:11.3315,lwr_k=900:11.3847,lwr_k=1000:11.5609'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_39'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:46.1934,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:1.109,lwr_k=50:2.5743,lwr_k=100:6.9319,lwr_k=200:11.4355,lwr_k=300:14.6047,lwr_k=400:17.183,lwr_k=500:19.5549,lwr_k=600:21.4206,lwr_k=700:23.3843,lwr_k=800:25.0822,lwr_k=900:26.3965,lwr_k=1000:27.566'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:59.9724,lwr_k=10:30.5934,lwr_k=20:32.9785,lwr_k=30:107.496,lwr_k=40:64.2204,lwr_k=50:34.7035,lwr_k=100:17.9658,lwr_k=200:17.1132,lwr_k=300:18.7473,lwr_k=400:21.3942,lwr_k=500:24.212,lwr_k=600:26.5618,lwr_k=700:28.8446,lwr_k=800:30.8046,lwr_k=900:32.8062,lwr_k=1000:34.3921'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:59.7501,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:1.305,lwr_k=50:3.2449,lwr_k=100:8.9627,lwr_k=200:14.6932,lwr_k=300:18.1907,lwr_k=400:20.4747,lwr_k=500:24.1292,lwr_k=600:27.1726,lwr_k=700:29.8993,lwr_k=800:32.0928,lwr_k=900:33.8437,lwr_k=1000:35.427'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:47.3623,lwr_k=10:39.3598,lwr_k=20:45.2543,lwr_k=30:113.8005,lwr_k=40:64.9496,lwr_k=50:27.8437,lwr_k=100:16.0118,lwr_k=200:17.26,lwr_k=300:18.7557,lwr_k=400:20.2243,lwr_k=500:22.1826,lwr_k=600:23.3902,lwr_k=700:24.7035,lwr_k=800:25.4703,lwr_k=900:26.8771,lwr_k=1000:27.9157'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:64.8419,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:1.6493,lwr_k=50:3.7578,lwr_k=100:9.6984,lwr_k=200:15.4723,lwr_k=300:19.1974,lwr_k=400:21.6593,lwr_k=500:25.1711,lwr_k=600:28.3861,lwr_k=700:31.4335,lwr_k=800:33.5277,lwr_k=900:35.3082,lwr_k=1000:37.0084'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:44.7534,lwr_k=10:34.1664,lwr_k=20:39.2769,lwr_k=30:108.5771,lwr_k=40:65.3476,lwr_k=50:28.1875,lwr_k=100:15.5116,lwr_k=200:15.8372,lwr_k=300:16.9546,lwr_k=400:18.6979,lwr_k=500:21.1153,lwr_k=600:21.9129,lwr_k=700:23.5981,lwr_k=800:24.8132,lwr_k=900:25.7785,lwr_k=1000:26.3702'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:62.8026,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:1.3398,lwr_k=50:3.0793,lwr_k=100:9.0103,lwr_k=200:15.0318,lwr_k=300:19.4765,lwr_k=400:22.3442,lwr_k=500:25.7344,lwr_k=600:28.7117,lwr_k=700:31.5514,lwr_k=800:33.3294,lwr_k=900:35.1679,lwr_k=1000:36.8219'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:53.9788,lwr_k=10:29.9658,lwr_k=20:43.3684,lwr_k=30:143.4562,lwr_k=40:75.8331,lwr_k=50:37.1619,lwr_k=100:18.1802,lwr_k=200:18.6306,lwr_k=300:19.4233,lwr_k=400:20.8126,lwr_k=500:22.9862,lwr_k=600:25.1185,lwr_k=700:27.4781,lwr_k=800:28.7142,lwr_k=900:29.5675,lwr_k=1000:30.531'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:47.5898,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:1.1996,lwr_k=50:2.6952,lwr_k=100:7.1586,lwr_k=200:11.7745,lwr_k=300:14.6642,lwr_k=400:16.9804,lwr_k=500:19.3168,lwr_k=600:21.1748,lwr_k=700:23.0503,lwr_k=800:24.6356,lwr_k=900:26.1109,lwr_k=1000:27.5251'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:90.03,lwr_k=10:51.0736,lwr_k=20:57.7606,lwr_k=30:103.2,lwr_k=40:72.874,lwr_k=50:48.7918,lwr_k=100:29.8728,lwr_k=200:37.0408,lwr_k=300:43.8191,lwr_k=400:48.2922,lwr_k=500:52.7488,lwr_k=600:56.6965,lwr_k=700:60.0797,lwr_k=800:61.7127,lwr_k=900:63.6039,lwr_k=1000:65.3001'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:57.5192,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:1.1573,lwr_k=50:2.8025,lwr_k=100:7.6515,lwr_k=200:12.4762,lwr_k=300:15.773,lwr_k=400:18.6864,lwr_k=500:20.5894,lwr_k=600:22.8742,lwr_k=700:25.0759,lwr_k=800:27.1074,lwr_k=900:29.0577,lwr_k=1000:30.4591'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:59.4049,lwr_k=10:43.3313,lwr_k=20:57.5074,lwr_k=30:122.6373,lwr_k=40:57.2589,lwr_k=50:33.7478,lwr_k=100:20.9556,lwr_k=200:20.0273,lwr_k=300:20.9251,lwr_k=400:22.679,lwr_k=500:24.2573,lwr_k=600:26.3221,lwr_k=700:28.1219,lwr_k=800:29.8759,lwr_k=900:31.3898,lwr_k=1000:33.2061'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_40'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.4245,lwr_k=10:0.0002,lwr_k=20:0.7084,lwr_k=30:1.9071,lwr_k=40:14.4393,lwr_k=50:12.8434,lwr_k=100:7.0481,lwr_k=200:7.7221,lwr_k=300:7.5405,lwr_k=400:7.1627,lwr_k=500:7.4834,lwr_k=600:7.2175,lwr_k=700:7.0936,lwr_k=800:6.9042,lwr_k=900:7.5142,lwr_k=1000:7.5253'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.9061,lwr_k=10:839.2639,lwr_k=20:1335174.3793,lwr_k=30:120167.9956,lwr_k=40:5850.372,lwr_k=50:208910.1494,lwr_k=100:64306.3572,lwr_k=200:2751.3647,lwr_k=300:54857.735,lwr_k=400:50107.8724,lwr_k=500:43189.3583,lwr_k=600:25.5632,lwr_k=700:20161.8945,lwr_k=800:34796.935,lwr_k=900:2136.7619,lwr_k=1000:1315.5483'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.5367,lwr_k=10:0.0044,lwr_k=20:2.1727,lwr_k=30:3.3725,lwr_k=40:4.2399,lwr_k=50:4.6249,lwr_k=100:5.9927,lwr_k=200:6.7378,lwr_k=300:7.062,lwr_k=400:7.1333,lwr_k=500:7.198,lwr_k=600:7.2925,lwr_k=700:7.3093,lwr_k=800:7.3343,lwr_k=900:7.4193,lwr_k=1000:7.4555'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.1882,lwr_k=10:3791.7395,lwr_k=20:6377.8311,lwr_k=30:18.2481,lwr_k=40:41.0816,lwr_k=50:13.0796,lwr_k=100:8.3379,lwr_k=200:7.7347,lwr_k=300:7.7065,lwr_k=400:7.7624,lwr_k=500:7.7547,lwr_k=600:7.8418,lwr_k=700:7.9155,lwr_k=800:7.8242,lwr_k=900:7.9658,lwr_k=1000:7.8295'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.9795,lwr_k=10:0.061,lwr_k=20:3.0181,lwr_k=30:4.1433,lwr_k=40:4.8342,lwr_k=50:5.2347,lwr_k=100:6.0015,lwr_k=200:6.6589,lwr_k=300:6.8831,lwr_k=400:6.9894,lwr_k=500:7.1117,lwr_k=600:7.1064,lwr_k=700:7.1856,lwr_k=800:7.1944,lwr_k=900:7.2283,lwr_k=1000:7.325'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.3199,lwr_k=10:18806814.216,lwr_k=20:27.2702,lwr_k=30:12.468,lwr_k=40:8.1733,lwr_k=50:7.707,lwr_k=100:6.3771,lwr_k=200:6.0417,lwr_k=300:5.9854,lwr_k=400:5.9166,lwr_k=500:5.9358,lwr_k=600:5.9005,lwr_k=700:5.8749,lwr_k=800:5.9906,lwr_k=900:5.7513,lwr_k=1000:5.7083'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.8332,lwr_k=10:0.0021,lwr_k=20:1.3801,lwr_k=30:2.9659,lwr_k=40:10.3804,lwr_k=50:7.9987,lwr_k=100:8.0378,lwr_k=200:7.1512,lwr_k=300:6.668,lwr_k=400:6.7456,lwr_k=500:6.8935,lwr_k=600:6.8346,lwr_k=700:7.0902,lwr_k=800:7.2798,lwr_k=900:7.3196,lwr_k=1000:7.651'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:9.9412,lwr_k=10:14383.6593,lwr_k=20:7614839.3274,lwr_k=30:110659691.2656,lwr_k=40:47481491.7003,lwr_k=50:22655348.4058,lwr_k=100:2282890.7606,lwr_k=200:853864.421,lwr_k=300:295867.8615,lwr_k=400:189474.7457,lwr_k=500:33928.1604,lwr_k=600:2526.6731,lwr_k=700:279.2289,lwr_k=800:56.8784,lwr_k=900:863.1595,lwr_k=1000:156.0209'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.4268,lwr_k=10:0.0004,lwr_k=20:0.6963,lwr_k=30:2.0025,lwr_k=40:3.1404,lwr_k=50:4.4846,lwr_k=100:4.7943,lwr_k=200:8.3008,lwr_k=300:6.2052,lwr_k=400:6.9567,lwr_k=500:7.3873,lwr_k=600:6.9207,lwr_k=700:7.1991,lwr_k=800:6.6902,lwr_k=900:6.5493,lwr_k=1000:6.4991'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:41.1863,lwr_k=10:272.7113,lwr_k=20:6072117.2749,lwr_k=30:23907065.1758,lwr_k=40:303290.4642,lwr_k=50:989337.2845,lwr_k=100:167.6772,lwr_k=200:23973.2298,lwr_k=300:12653.729,lwr_k=400:6576.861,lwr_k=500:2521.6282,lwr_k=600:17283.8426,lwr_k=700:5199.9661,lwr_k=800:2613.856,lwr_k=900:1984.1895,lwr_k=1000:1111.965'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:6.2246,lwr_k=10:0.0124,lwr_k=20:1.5252,lwr_k=30:2.5969,lwr_k=40:3.3443,lwr_k=50:3.8249,lwr_k=100:4.6531,lwr_k=200:5.1119,lwr_k=300:5.2552,lwr_k=400:5.3689,lwr_k=500:5.4487,lwr_k=600:5.4809,lwr_k=700:5.518,lwr_k=800:5.5518,lwr_k=900:5.5891,lwr_k=1000:5.6124'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.857,lwr_k=10:34516.7813,lwr_k=20:14708145.0111,lwr_k=30:17823254.7777,lwr_k=40:14674830.2521,lwr_k=50:4466494.0133,lwr_k=100:243603.0967,lwr_k=200:18469.5757,lwr_k=300:46589.7344,lwr_k=400:14369.0389,lwr_k=500:31579.8967,lwr_k=600:10.6424,lwr_k=700:9.2062,lwr_k=800:67.9828,lwr_k=900:47.6338,lwr_k=1000:40.5706'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_41'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.1952,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.5813,lwr_k=40:1.5614,lwr_k=50:2.1603,lwr_k=100:3.2309,lwr_k=200:3.9292,lwr_k=300:4.2626,lwr_k=400:4.4012,lwr_k=500:4.516,lwr_k=600:4.5856,lwr_k=700:4.6469,lwr_k=800:4.7397,lwr_k=900:4.7583,lwr_k=1000:4.7843'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.1876,lwr_k=10:61.1333,lwr_k=20:66.9313,lwr_k=30:63.9497,lwr_k=40:22.0197,lwr_k=50:13.1291,lwr_k=100:9.9404,lwr_k=200:9.2351,lwr_k=300:8.8072,lwr_k=400:8.7478,lwr_k=500:8.7133,lwr_k=600:8.724,lwr_k=700:8.8214,lwr_k=800:8.8363,lwr_k=900:8.8623,lwr_k=1000:8.8336'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:41.3281,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.8476,lwr_k=40:5.1035,lwr_k=50:6.9723,lwr_k=100:13.8223,lwr_k=200:17.2938,lwr_k=300:19.5273,lwr_k=400:20.7493,lwr_k=500:21.7112,lwr_k=600:22.3444,lwr_k=700:23.1283,lwr_k=800:23.8571,lwr_k=900:24.3503,lwr_k=1000:25.1632'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:35.1116,lwr_k=10:239.0223,lwr_k=20:183.642,lwr_k=30:219.3783,lwr_k=40:66.2453,lwr_k=50:53.8006,lwr_k=100:28.3417,lwr_k=200:19.6463,lwr_k=300:19.7285,lwr_k=400:19.144,lwr_k=500:18.9809,lwr_k=600:18.6029,lwr_k=700:18.4893,lwr_k=800:18.5823,lwr_k=900:18.8123,lwr_k=1000:19.1045'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:41.5998,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.585,lwr_k=40:5.2384,lwr_k=50:7.8309,lwr_k=100:13.7688,lwr_k=200:18.5268,lwr_k=300:20.4901,lwr_k=400:21.4677,lwr_k=500:22.1796,lwr_k=600:23.1635,lwr_k=700:23.8363,lwr_k=800:24.4192,lwr_k=900:25.1575,lwr_k=1000:25.6595'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:31.2525,lwr_k=10:206.6032,lwr_k=20:145.0672,lwr_k=30:168.98,lwr_k=40:70.0849,lwr_k=50:45.8214,lwr_k=100:22.0062,lwr_k=200:18.9823,lwr_k=300:18.4488,lwr_k=400:18.6387,lwr_k=500:18.7313,lwr_k=600:18.4286,lwr_k=700:18.3684,lwr_k=800:18.4788,lwr_k=900:18.6703,lwr_k=1000:18.938'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:18.9856,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.4483,lwr_k=40:3.9418,lwr_k=50:5.3598,lwr_k=100:8.758,lwr_k=200:12.0069,lwr_k=300:12.9582,lwr_k=400:13.5576,lwr_k=500:13.9505,lwr_k=600:14.3154,lwr_k=700:14.4942,lwr_k=800:14.7376,lwr_k=900:15.0154,lwr_k=1000:15.2303'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:15.0235,lwr_k=10:530.3876,lwr_k=20:172.1573,lwr_k=30:124.5726,lwr_k=40:36.5046,lwr_k=50:23.6269,lwr_k=100:16.2622,lwr_k=200:13.6118,lwr_k=300:13.533,lwr_k=400:13.4036,lwr_k=500:13.4222,lwr_k=600:13.3839,lwr_k=700:13.3104,lwr_k=800:13.4375,lwr_k=900:13.3926,lwr_k=1000:13.5315'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.9435,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.7575,lwr_k=40:1.7928,lwr_k=50:2.3796,lwr_k=100:3.5491,lwr_k=200:4.1157,lwr_k=300:4.2805,lwr_k=400:4.3966,lwr_k=500:4.4742,lwr_k=600:4.5323,lwr_k=700:4.5699,lwr_k=800:4.625,lwr_k=900:4.6599,lwr_k=1000:4.6918'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:20.8689,lwr_k=10:45.5373,lwr_k=20:106.0314,lwr_k=30:115.1183,lwr_k=40:33.9354,lwr_k=50:29.6528,lwr_k=100:23.0979,lwr_k=200:20.622,lwr_k=300:20.1433,lwr_k=400:20.121,lwr_k=500:20.1225,lwr_k=600:20.0248,lwr_k=700:20.0023,lwr_k=800:20.0246,lwr_k=900:19.9969,lwr_k=1000:20.1085'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:10.0457,lwr_k=10:0.0,lwr_k=20:0.0018,lwr_k=30:0.8959,lwr_k=40:2.5502,lwr_k=50:3.669,lwr_k=100:5.7531,lwr_k=200:7.0651,lwr_k=300:7.5729,lwr_k=400:7.8504,lwr_k=500:8.0224,lwr_k=600:8.1361,lwr_k=700:8.2625,lwr_k=800:8.3645,lwr_k=900:8.4695,lwr_k=1000:8.5242'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:13.899,lwr_k=10:74.0742,lwr_k=20:315.4078,lwr_k=30:196.1873,lwr_k=40:113.0065,lwr_k=50:20.6941,lwr_k=100:13.1425,lwr_k=200:12.1974,lwr_k=300:12.2668,lwr_k=400:12.2218,lwr_k=500:12.4144,lwr_k=600:12.4254,lwr_k=700:12.4781,lwr_k=800:12.5572,lwr_k=900:12.7626,lwr_k=1000:12.8024'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_42'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.0786,lwr_k=10:5.2683,lwr_k=20:5.9742,lwr_k=30:5.9357,lwr_k=40:5.9675,lwr_k=50:6.0364,lwr_k=100:6.1395,lwr_k=200:6.4423,lwr_k=300:6.5126,lwr_k=400:6.5302,lwr_k=500:6.5499,lwr_k=600:6.5661,lwr_k=700:6.5815,lwr_k=800:6.577,lwr_k=900:6.5845,lwr_k=1000:6.5893'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.1696,lwr_k=10:10.4906,lwr_k=20:9.8494,lwr_k=30:9.8276,lwr_k=40:9.7744,lwr_k=50:9.6407,lwr_k=100:9.5617,lwr_k=200:10.98,lwr_k=300:10.9509,lwr_k=400:10.9026,lwr_k=500:10.8964,lwr_k=600:10.8972,lwr_k=700:10.9179,lwr_k=800:10.9222,lwr_k=900:10.972,lwr_k=1000:11.0068'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:14.6418,lwr_k=10:11.5734,lwr_k=20:11.8672,lwr_k=30:12.0086,lwr_k=40:12.1574,lwr_k=50:12.266,lwr_k=100:12.5273,lwr_k=200:12.7267,lwr_k=300:12.9371,lwr_k=400:13.0727,lwr_k=500:13.1553,lwr_k=600:13.1905,lwr_k=700:13.2316,lwr_k=800:13.25,lwr_k=900:13.2768,lwr_k=1000:13.3033'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:12.2734,lwr_k=10:12.18,lwr_k=20:11.6491,lwr_k=30:11.585,lwr_k=40:11.3766,lwr_k=50:11.3368,lwr_k=100:11.2408,lwr_k=200:11.2449,lwr_k=300:11.2393,lwr_k=400:11.2309,lwr_k=500:11.2617,lwr_k=600:11.2852,lwr_k=700:11.3321,lwr_k=800:11.3696,lwr_k=900:11.3782,lwr_k=1000:11.3914'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:12.5296,lwr_k=10:7.4434,lwr_k=20:8.4877,lwr_k=30:9.0694,lwr_k=40:9.7083,lwr_k=50:10.239,lwr_k=100:11.051,lwr_k=200:11.5754,lwr_k=300:11.6538,lwr_k=400:11.6692,lwr_k=500:11.7031,lwr_k=600:11.7558,lwr_k=700:11.7728,lwr_k=800:11.7839,lwr_k=900:11.8265,lwr_k=1000:11.8387'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.0591,lwr_k=10:7.797,lwr_k=20:7.8075,lwr_k=30:7.7969,lwr_k=40:7.6662,lwr_k=50:7.5177,lwr_k=100:7.3597,lwr_k=200:7.2877,lwr_k=300:7.2766,lwr_k=400:7.2417,lwr_k=500:7.2684,lwr_k=600:7.4185,lwr_k=700:7.416,lwr_k=800:7.4292,lwr_k=900:7.4524,lwr_k=1000:7.4829'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:16.1631,lwr_k=10:11.2969,lwr_k=20:11.7572,lwr_k=30:11.9506,lwr_k=40:12.2615,lwr_k=50:12.5088,lwr_k=100:13.1365,lwr_k=200:13.7333,lwr_k=300:14.0005,lwr_k=400:14.1034,lwr_k=500:14.1567,lwr_k=600:14.2318,lwr_k=700:14.2743,lwr_k=800:14.3014,lwr_k=900:14.3365,lwr_k=1000:14.3707'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:14.5955,lwr_k=10:14.9256,lwr_k=20:14.0086,lwr_k=30:13.88,lwr_k=40:14.0338,lwr_k=50:14.1657,lwr_k=100:13.7856,lwr_k=200:13.6266,lwr_k=300:13.6643,lwr_k=400:13.6258,lwr_k=500:13.497,lwr_k=600:13.5023,lwr_k=700:13.4896,lwr_k=800:13.4664,lwr_k=900:13.4646,lwr_k=1000:13.4762'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.0343,lwr_k=10:6.8407,lwr_k=20:7.2969,lwr_k=30:7.4073,lwr_k=40:7.5188,lwr_k=50:7.5787,lwr_k=100:7.7526,lwr_k=200:7.7998,lwr_k=300:7.8698,lwr_k=400:7.887,lwr_k=500:7.9352,lwr_k=600:7.9607,lwr_k=700:7.9797,lwr_k=800:8.0078,lwr_k=900:8.0542,lwr_k=1000:8.0977'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:31.0164,lwr_k=10:20.7747,lwr_k=20:18.3023,lwr_k=30:20.6206,lwr_k=40:22.2303,lwr_k=50:22.803,lwr_k=100:24.2683,lwr_k=200:25.1014,lwr_k=300:25.9097,lwr_k=400:26.2235,lwr_k=500:26.6483,lwr_k=600:26.8348,lwr_k=700:27.142,lwr_k=800:27.3854,lwr_k=900:27.4546,lwr_k=1000:27.6266'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:17.1952,lwr_k=10:14.5328,lwr_k=20:14.8499,lwr_k=30:14.883,lwr_k=40:15.2655,lwr_k=50:15.3662,lwr_k=100:15.9478,lwr_k=200:16.2872,lwr_k=300:16.4452,lwr_k=400:16.4659,lwr_k=500:16.4763,lwr_k=600:16.4912,lwr_k=700:16.507,lwr_k=800:16.5062,lwr_k=900:16.4919,lwr_k=1000:16.4917'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:15.5811,lwr_k=10:17.0499,lwr_k=20:16.0761,lwr_k=30:16.9516,lwr_k=40:16.0907,lwr_k=50:15.9099,lwr_k=100:15.6378,lwr_k=200:15.0747,lwr_k=300:14.8477,lwr_k=400:14.7503,lwr_k=500:14.7552,lwr_k=600:14.728,lwr_k=700:14.7228,lwr_k=800:14.7127,lwr_k=900:14.7358,lwr_k=1000:14.7421'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_43'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:46.4643,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.0028,lwr_k=100:4.6944,lwr_k=200:10.0981,lwr_k=300:13.5144,lwr_k=400:16.0553,lwr_k=500:18.1516,lwr_k=600:19.6866,lwr_k=700:20.8629,lwr_k=800:22.243,lwr_k=900:23.2476,lwr_k=1000:24.422'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:51.0447,lwr_k=10:55.4355,lwr_k=20:92.5061,lwr_k=30:268.1594,lwr_k=40:372.8149,lwr_k=50:2452.2987,lwr_k=100:30.5502,lwr_k=200:23.7407,lwr_k=300:22.5838,lwr_k=400:24.5699,lwr_k=500:24.9973,lwr_k=600:26.076,lwr_k=700:26.2327,lwr_k=800:26.9944,lwr_k=900:27.7516,lwr_k=1000:28.7293'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:43.9318,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.0047,lwr_k=100:5.5089,lwr_k=200:12.1743,lwr_k=300:16.371,lwr_k=400:19.1009,lwr_k=500:21.1167,lwr_k=600:22.8305,lwr_k=700:23.9285,lwr_k=800:25.2219,lwr_k=900:26.6264,lwr_k=1000:27.7406'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:54.9751,lwr_k=10:43.8624,lwr_k=20:81.2457,lwr_k=30:253.6828,lwr_k=40:130.1477,lwr_k=50:712.656,lwr_k=100:28.1142,lwr_k=200:24.1497,lwr_k=300:24.809,lwr_k=400:27.0452,lwr_k=500:28.4505,lwr_k=600:30.4656,lwr_k=700:32.6152,lwr_k=800:33.9229,lwr_k=900:35.045,lwr_k=1000:36.1541'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:44.9758,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.0036,lwr_k=100:6.3113,lwr_k=200:12.4612,lwr_k=300:16.2991,lwr_k=400:19.0424,lwr_k=500:21.5849,lwr_k=600:23.4066,lwr_k=700:24.6961,lwr_k=800:25.8718,lwr_k=900:27.0896,lwr_k=1000:28.1991'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:39.756,lwr_k=10:40.1364,lwr_k=20:91.4853,lwr_k=30:529.7495,lwr_k=40:93.3418,lwr_k=50:890.414,lwr_k=100:25.5622,lwr_k=200:22.9271,lwr_k=300:22.2285,lwr_k=400:23.5567,lwr_k=500:24.0679,lwr_k=600:24.7669,lwr_k=700:25.6575,lwr_k=800:26.0453,lwr_k=900:26.785,lwr_k=1000:27.3608'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:47.6297,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.0026,lwr_k=100:6.0541,lwr_k=200:12.5505,lwr_k=300:16.5858,lwr_k=400:19.8778,lwr_k=500:22.597,lwr_k=600:24.7796,lwr_k=700:26.1417,lwr_k=800:27.5464,lwr_k=900:29.1533,lwr_k=1000:30.361'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:44.5463,lwr_k=10:42.8538,lwr_k=20:89.7621,lwr_k=30:173.9997,lwr_k=40:98.0114,lwr_k=50:507.6333,lwr_k=100:29.2358,lwr_k=200:24.8835,lwr_k=300:25.2122,lwr_k=400:24.0668,lwr_k=500:24.1604,lwr_k=600:25.1598,lwr_k=700:25.2214,lwr_k=800:26.0271,lwr_k=900:27.274,lwr_k=1000:28.1014'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:40.4729,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.0052,lwr_k=100:5.0875,lwr_k=200:10.3198,lwr_k=300:13.6643,lwr_k=400:16.2742,lwr_k=500:18.526,lwr_k=600:20.0758,lwr_k=700:21.2315,lwr_k=800:22.3859,lwr_k=900:23.5962,lwr_k=1000:24.6547'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:184.2981,lwr_k=10:47.6048,lwr_k=20:127.5993,lwr_k=30:239.3061,lwr_k=40:122.1885,lwr_k=50:874.9133,lwr_k=100:241.7842,lwr_k=200:68.9451,lwr_k=300:48.089,lwr_k=400:49.9805,lwr_k=500:48.8548,lwr_k=600:47.5221,lwr_k=700:49.0706,lwr_k=800:49.082,lwr_k=900:50.3046,lwr_k=1000:49.5982'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:45.4249,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.0032,lwr_k=100:5.5233,lwr_k=200:10.9812,lwr_k=300:14.6421,lwr_k=400:17.3454,lwr_k=500:19.7992,lwr_k=600:21.6237,lwr_k=700:23.0268,lwr_k=800:24.3759,lwr_k=900:25.2984,lwr_k=1000:26.3323'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:57.2481,lwr_k=10:64.1716,lwr_k=20:106.8336,lwr_k=30:154.9805,lwr_k=40:320.594,lwr_k=50:1115.5334,lwr_k=100:38.8791,lwr_k=200:23.078,lwr_k=300:24.9518,lwr_k=400:27.2422,lwr_k=500:29.8265,lwr_k=600:31.1623,lwr_k=700:32.9684,lwr_k=800:34.0114,lwr_k=900:35.3496,lwr_k=1000:35.9479'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_44'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.7895,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.3862,lwr_k=100:2.1836,lwr_k=200:3.3534,lwr_k=300:3.8676,lwr_k=400:4.1347,lwr_k=500:4.2937,lwr_k=600:4.4254,lwr_k=700:4.5378,lwr_k=800:4.6275,lwr_k=900:4.7386,lwr_k=1000:4.8073'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.9522,lwr_k=10:21.3455,lwr_k=20:23.3727,lwr_k=30:51.9203,lwr_k=40:183.0562,lwr_k=50:48.419,lwr_k=100:13.1693,lwr_k=200:7.7092,lwr_k=300:7.6747,lwr_k=400:7.6118,lwr_k=500:7.7099,lwr_k=600:7.8279,lwr_k=700:7.9245,lwr_k=800:8.0066,lwr_k=900:8.0601,lwr_k=1000:8.1009'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.8933,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0018,lwr_k=50:0.3743,lwr_k=100:2.5123,lwr_k=200:4.3141,lwr_k=300:4.9691,lwr_k=400:5.3498,lwr_k=500:5.6628,lwr_k=600:5.8444,lwr_k=700:5.9715,lwr_k=800:6.1685,lwr_k=900:6.2551,lwr_k=1000:6.38'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.2098,lwr_k=10:17.2171,lwr_k=20:32.4324,lwr_k=30:270.7003,lwr_k=40:147.4796,lwr_k=50:94.8439,lwr_k=100:8.6262,lwr_k=200:6.654,lwr_k=300:6.4491,lwr_k=400:6.5275,lwr_k=500:6.7071,lwr_k=600:6.7259,lwr_k=700:6.7095,lwr_k=800:6.6693,lwr_k=900:6.6517,lwr_k=1000:6.7007'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.401,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0017,lwr_k=50:0.4964,lwr_k=100:2.9222,lwr_k=200:5.0558,lwr_k=300:5.6348,lwr_k=400:6.1407,lwr_k=500:6.3736,lwr_k=600:6.5948,lwr_k=700:6.7428,lwr_k=800:6.8792,lwr_k=900:6.963,lwr_k=1000:7.0586'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.953,lwr_k=10:30.0412,lwr_k=20:36.014,lwr_k=30:132.8687,lwr_k=40:2714.8617,lwr_k=50:2490.5747,lwr_k=100:14.9021,lwr_k=200:5.8042,lwr_k=300:5.7665,lwr_k=400:5.5265,lwr_k=500:5.5363,lwr_k=600:5.5867,lwr_k=700:5.7091,lwr_k=800:5.749,lwr_k=900:5.8073,lwr_k=1000:5.8262'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.3463,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0035,lwr_k=50:0.4868,lwr_k=100:3.1222,lwr_k=200:5.0515,lwr_k=300:5.7357,lwr_k=400:6.2278,lwr_k=500:6.6207,lwr_k=600:6.9575,lwr_k=700:7.1758,lwr_k=800:7.3202,lwr_k=900:7.5224,lwr_k=1000:7.6462'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:10.8801,lwr_k=10:24.4836,lwr_k=20:38.3662,lwr_k=30:107.8308,lwr_k=40:1292.4212,lwr_k=50:4796.5448,lwr_k=100:11.3126,lwr_k=200:8.3763,lwr_k=300:8.2608,lwr_k=400:8.2822,lwr_k=500:8.4497,lwr_k=600:8.5834,lwr_k=700:8.8051,lwr_k=800:8.9552,lwr_k=900:9.1361,lwr_k=1000:9.3207'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.8954,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0001,lwr_k=40:0.0073,lwr_k=50:0.3966,lwr_k=100:2.2144,lwr_k=200:3.2393,lwr_k=300:3.6135,lwr_k=400:3.8872,lwr_k=500:4.0682,lwr_k=600:4.1925,lwr_k=700:4.2815,lwr_k=800:4.348,lwr_k=900:4.4274,lwr_k=1000:4.492'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:21.8427,lwr_k=10:50.4339,lwr_k=20:637.3686,lwr_k=30:389.381,lwr_k=40:129.1217,lwr_k=50:229.2339,lwr_k=100:25.0677,lwr_k=200:21.6424,lwr_k=300:21.6814,lwr_k=400:21.736,lwr_k=500:21.7566,lwr_k=600:21.8093,lwr_k=700:21.8423,lwr_k=800:21.8763,lwr_k=900:21.9496,lwr_k=1000:21.8271'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:7.9484,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0009,lwr_k=50:0.4403,lwr_k=100:2.5146,lwr_k=200:4.1584,lwr_k=300:4.812,lwr_k=400:5.1623,lwr_k=500:5.413,lwr_k=600:5.6163,lwr_k=700:5.8287,lwr_k=800:5.9974,lwr_k=900:6.1321,lwr_k=1000:6.2476'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:12.3841,lwr_k=10:21.7995,lwr_k=20:41.8457,lwr_k=30:69.8906,lwr_k=40:560.3334,lwr_k=50:77.2455,lwr_k=100:10.7293,lwr_k=200:8.7153,lwr_k=300:8.7604,lwr_k=400:8.8986,lwr_k=500:9.143,lwr_k=600:9.4404,lwr_k=700:9.6042,lwr_k=800:9.7906,lwr_k=900:9.9049,lwr_k=1000:10.1202'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_45'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:118.6794,lwr_k=10:0.0,lwr_k=20:6.0986,lwr_k=30:13.64,lwr_k=40:18.0114,lwr_k=50:21.0731,lwr_k=100:30.151,lwr_k=200:40.8891,lwr_k=300:48.0097,lwr_k=400:53.1613,lwr_k=500:57.9819,lwr_k=600:62.1798,lwr_k=700:65.8866,lwr_k=800:69.2176,lwr_k=900:72.1904,lwr_k=1000:74.481'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:144.3661,lwr_k=10:789.9004,lwr_k=20:91.1895,lwr_k=30:65.1948,lwr_k=40:52.2065,lwr_k=50:48.4528,lwr_k=100:47.351,lwr_k=200:50.3732,lwr_k=300:55.674,lwr_k=400:61.2404,lwr_k=500:66.7294,lwr_k=600:71.0582,lwr_k=700:75.5959,lwr_k=800:79.9508,lwr_k=900:83.3806,lwr_k=1000:86.0067'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:160.0109,lwr_k=10:0.0,lwr_k=20:12.9862,lwr_k=30:29.1387,lwr_k=40:39.5523,lwr_k=50:47.1631,lwr_k=100:61.8288,lwr_k=200:71.5287,lwr_k=300:77.1743,lwr_k=400:81.3972,lwr_k=500:88.2988,lwr_k=600:101.0707,lwr_k=700:106.8372,lwr_k=800:110.3274,lwr_k=900:114.9169,lwr_k=1000:117.8427'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:138.6091,lwr_k=10:1108.9599,lwr_k=20:1399.5836,lwr_k=30:245.5333,lwr_k=40:151.6572,lwr_k=50:141.3373,lwr_k=100:79.4765,lwr_k=200:78.0875,lwr_k=300:79.2088,lwr_k=400:84.2205,lwr_k=500:89.436,lwr_k=600:99.0696,lwr_k=700:101.901,lwr_k=800:104.5672,lwr_k=900:107.7378,lwr_k=1000:110.3046'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:133.2877,lwr_k=10:0.0,lwr_k=20:6.5028,lwr_k=30:14.1785,lwr_k=40:20.2833,lwr_k=50:22.8943,lwr_k=100:32.647,lwr_k=200:43.3901,lwr_k=300:50.4417,lwr_k=400:57.1581,lwr_k=500:62.0026,lwr_k=600:65.753,lwr_k=700:69.712,lwr_k=800:73.0135,lwr_k=900:75.7925,lwr_k=1000:78.5249'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:105.4292,lwr_k=10:550.2085,lwr_k=20:105.0003,lwr_k=30:53.7241,lwr_k=40:46.1532,lwr_k=50:42.3545,lwr_k=100:38.2601,lwr_k=200:42.8141,lwr_k=300:46.7275,lwr_k=400:51.277,lwr_k=500:54.8632,lwr_k=600:57.2489,lwr_k=700:59.5959,lwr_k=800:62.3165,lwr_k=900:64.5578,lwr_k=1000:67.2005'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:139.1276,lwr_k=10:0.0,lwr_k=20:6.7348,lwr_k=30:16.2729,lwr_k=40:20.8658,lwr_k=50:25.3959,lwr_k=100:35.727,lwr_k=200:48.1636,lwr_k=300:56.8818,lwr_k=400:62.8663,lwr_k=500:68.2368,lwr_k=600:72.3456,lwr_k=700:76.2452,lwr_k=800:79.9304,lwr_k=900:82.6099,lwr_k=1000:85.4564'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:124.5098,lwr_k=10:1065.3717,lwr_k=20:1185.4373,lwr_k=30:436.9191,lwr_k=40:260.1785,lwr_k=50:130.6571,lwr_k=100:237.5262,lwr_k=200:153.6472,lwr_k=300:50.9816,lwr_k=400:57.4188,lwr_k=500:61.3178,lwr_k=600:64.3101,lwr_k=700:68.0545,lwr_k=800:70.5317,lwr_k=900:72.8336,lwr_k=1000:75.3602'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:124.5006,lwr_k=10:0.0,lwr_k=20:6.4943,lwr_k=30:14.5654,lwr_k=40:18.7667,lwr_k=50:22.8018,lwr_k=100:33.2588,lwr_k=200:43.0481,lwr_k=300:49.928,lwr_k=400:56.0759,lwr_k=500:60.8667,lwr_k=600:65.5903,lwr_k=700:69.5697,lwr_k=800:73.1287,lwr_k=900:76.3707,lwr_k=1000:78.9861'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:154.5129,lwr_k=10:760.9934,lwr_k=20:180.7814,lwr_k=30:74.5942,lwr_k=40:60.389,lwr_k=50:58.4541,lwr_k=100:58.5964,lwr_k=200:67.0077,lwr_k=300:75.0958,lwr_k=400:77.1557,lwr_k=500:82.9198,lwr_k=600:83.8513,lwr_k=700:86.5602,lwr_k=800:89.5634,lwr_k=900:92.1724,lwr_k=1000:94.4961'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:129.6025,lwr_k=10:0.0,lwr_k=20:6.8239,lwr_k=30:15.2251,lwr_k=40:20.1428,lwr_k=50:22.8469,lwr_k=100:31.9639,lwr_k=200:41.8166,lwr_k=300:48.0375,lwr_k=400:53.2694,lwr_k=500:57.8712,lwr_k=600:61.4541,lwr_k=700:65.1094,lwr_k=800:68.0665,lwr_k=900:71.0645,lwr_k=1000:73.6804'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:145.5744,lwr_k=10:692.4856,lwr_k=20:288.0842,lwr_k=30:115.2695,lwr_k=40:88.8574,lwr_k=50:69.4498,lwr_k=100:69.7759,lwr_k=200:74.5225,lwr_k=300:78.5054,lwr_k=400:84.407,lwr_k=500:87.8231,lwr_k=600:90.7452,lwr_k=700:92.5438,lwr_k=800:94.283,lwr_k=900:95.784,lwr_k=1000:97.3635'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_46'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.2008,lwr_k=10:0.0,lwr_k=20:0.0001,lwr_k=30:0.8716,lwr_k=40:1.5191,lwr_k=50:1.8307,lwr_k=100:2.7044,lwr_k=200:3.2429,lwr_k=300:3.352,lwr_k=400:3.4377,lwr_k=500:3.5043,lwr_k=600:3.5474,lwr_k=700:3.6036,lwr_k=800:3.6603,lwr_k=900:3.6951,lwr_k=1000:3.7229'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.3822,lwr_k=10:53.4949,lwr_k=20:223.6141,lwr_k=30:35.5101,lwr_k=40:18.171,lwr_k=50:14.7034,lwr_k=100:9.8549,lwr_k=200:9.0942,lwr_k=300:8.9327,lwr_k=400:8.9029,lwr_k=500:8.7946,lwr_k=600:8.8808,lwr_k=700:8.9163,lwr_k=800:8.8805,lwr_k=900:8.9175,lwr_k=1000:8.9613'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:39.363,lwr_k=10:0.0,lwr_k=20:0.0035,lwr_k=30:4.0876,lwr_k=40:7.3033,lwr_k=50:9.5374,lwr_k=100:15.7423,lwr_k=200:19.937,lwr_k=300:21.8809,lwr_k=400:23.139,lwr_k=500:23.8348,lwr_k=600:24.6921,lwr_k=700:25.2853,lwr_k=800:25.9508,lwr_k=900:26.5553,lwr_k=1000:27.173'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:30.2748,lwr_k=10:161.1647,lwr_k=20:365.0315,lwr_k=30:146.8969,lwr_k=40:66.5345,lwr_k=50:50.1875,lwr_k=100:39.6799,lwr_k=200:34.942,lwr_k=300:26.0332,lwr_k=400:22.4997,lwr_k=500:21.9359,lwr_k=600:18.5026,lwr_k=700:18.7207,lwr_k=800:19.1086,lwr_k=900:19.106,lwr_k=1000:19.3224'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.876,lwr_k=10:0.0,lwr_k=20:0.0007,lwr_k=30:1.4618,lwr_k=40:2.5814,lwr_k=50:3.2945,lwr_k=100:4.7752,lwr_k=200:5.812,lwr_k=300:6.164,lwr_k=400:6.4151,lwr_k=500:6.5739,lwr_k=600:6.6366,lwr_k=700:6.7296,lwr_k=800:6.831,lwr_k=900:6.9005,lwr_k=1000:6.9264'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.9102,lwr_k=10:79.1399,lwr_k=20:311.0449,lwr_k=30:36.0706,lwr_k=40:14.8044,lwr_k=50:11.416,lwr_k=100:7.6371,lwr_k=200:6.222,lwr_k=300:6.1614,lwr_k=400:6.1013,lwr_k=500:6.0485,lwr_k=600:6.079,lwr_k=700:6.0421,lwr_k=800:6.0771,lwr_k=900:6.155,lwr_k=1000:6.1667'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:11.9237,lwr_k=10:0.0,lwr_k=20:0.0003,lwr_k=30:1.5846,lwr_k=40:3.3143,lwr_k=50:4.2554,lwr_k=100:6.884,lwr_k=200:8.5386,lwr_k=300:9.1047,lwr_k=400:9.3741,lwr_k=500:9.5757,lwr_k=600:9.816,lwr_k=700:9.9679,lwr_k=800:10.1797,lwr_k=900:10.2951,lwr_k=1000:10.4317'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:11.4942,lwr_k=10:73.6328,lwr_k=20:735.4149,lwr_k=30:202.9186,lwr_k=40:63.5577,lwr_k=50:36.7981,lwr_k=100:20.0874,lwr_k=200:10.2221,lwr_k=300:10.6408,lwr_k=400:10.5666,lwr_k=500:10.5594,lwr_k=600:10.8289,lwr_k=700:10.6759,lwr_k=800:10.6648,lwr_k=900:10.5709,lwr_k=1000:10.5855'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.6016,lwr_k=10:0.0,lwr_k=20:0.0324,lwr_k=30:1.0421,lwr_k=40:1.9015,lwr_k=50:2.4511,lwr_k=100:3.3468,lwr_k=200:3.7712,lwr_k=300:3.9529,lwr_k=400:4.0689,lwr_k=500:4.1319,lwr_k=600:4.1607,lwr_k=700:4.1863,lwr_k=800:4.2206,lwr_k=900:4.2566,lwr_k=1000:4.3201'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:19.4379,lwr_k=10:912.5275,lwr_k=20:8393.4731,lwr_k=30:40169.226,lwr_k=40:37665.2236,lwr_k=50:4747.6013,lwr_k=100:194.6573,lwr_k=200:98.2757,lwr_k=300:21.5135,lwr_k=400:21.1249,lwr_k=500:20.6806,lwr_k=600:20.7473,lwr_k=700:20.7159,lwr_k=800:20.6254,lwr_k=900:20.6055,lwr_k=1000:20.2953'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:6.7405,lwr_k=10:0.0,lwr_k=20:0.0002,lwr_k=30:1.098,lwr_k=40:2.3674,lwr_k=50:3.0456,lwr_k=100:4.436,lwr_k=200:5.3068,lwr_k=300:5.6635,lwr_k=400:5.8899,lwr_k=500:5.9504,lwr_k=600:6.0275,lwr_k=700:6.0941,lwr_k=800:6.13,lwr_k=900:6.1704,lwr_k=1000:6.2122'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.6858,lwr_k=10:83.2834,lwr_k=20:140.8669,lwr_k=30:43.9859,lwr_k=40:17.2316,lwr_k=50:23.0777,lwr_k=100:11.0254,lwr_k=200:10.4997,lwr_k=300:10.7108,lwr_k=400:10.899,lwr_k=500:10.9762,lwr_k=600:11.1838,lwr_k=700:11.2142,lwr_k=800:11.3027,lwr_k=900:11.2443,lwr_k=1000:11.3011'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_47'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.4725,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.4342,lwr_k=40:1.6355,lwr_k=50:0.0666,lwr_k=100:0.3923,lwr_k=200:1.7789,lwr_k=300:2.8459,lwr_k=400:3.5652,lwr_k=500:3.8999,lwr_k=600:4.206,lwr_k=700:4.3814,lwr_k=800:4.6169,lwr_k=900:4.6458,lwr_k=1000:4.7546'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.9085,lwr_k=10:36.0206,lwr_k=20:48.1664,lwr_k=30:86.9463,lwr_k=40:21.8046,lwr_k=50:31.2438,lwr_k=100:23.8904,lwr_k=200:23.7873,lwr_k=300:14.5998,lwr_k=400:11.0981,lwr_k=500:9.6667,lwr_k=600:9.5594,lwr_k=700:9.8508,lwr_k=800:9.3534,lwr_k=900:9.641,lwr_k=1000:8.8577'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:14.3584,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.4149,lwr_k=40:2.3323,lwr_k=50:0.1186,lwr_k=100:0.3818,lwr_k=200:1.1007,lwr_k=300:2.1527,lwr_k=400:2.988,lwr_k=500:3.5571,lwr_k=600:4.638,lwr_k=700:4.8821,lwr_k=800:6.1088,lwr_k=900:6.1415,lwr_k=1000:6.4914'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:12.3369,lwr_k=10:45.7426,lwr_k=20:71.0975,lwr_k=30:229.7268,lwr_k=40:34.1331,lwr_k=50:38.3634,lwr_k=100:36.3866,lwr_k=200:20.1107,lwr_k=300:19.5668,lwr_k=400:17.2804,lwr_k=500:17.8241,lwr_k=600:17.4053,lwr_k=700:21.0856,lwr_k=800:26.6686,lwr_k=900:29.1689,lwr_k=1000:14.2444'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.7087,lwr_k=10:0.0,lwr_k=20:0.0001,lwr_k=30:1.9163,lwr_k=40:3.2945,lwr_k=50:4.1243,lwr_k=100:6.4691,lwr_k=200:7.9592,lwr_k=300:8.5645,lwr_k=400:8.9061,lwr_k=500:9.08,lwr_k=600:8.8507,lwr_k=700:9.2989,lwr_k=800:9.3292,lwr_k=900:9.3605,lwr_k=1000:9.4687'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:9.0838,lwr_k=10:39.84,lwr_k=20:138.9333,lwr_k=30:44.069,lwr_k=40:17.0775,lwr_k=50:13.0409,lwr_k=100:9.6291,lwr_k=200:8.9376,lwr_k=300:8.5858,lwr_k=400:8.6732,lwr_k=500:8.6494,lwr_k=600:8.5107,lwr_k=700:8.4443,lwr_k=800:8.4451,lwr_k=900:8.3755,lwr_k=1000:8.4048'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.5758,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.6186,lwr_k=40:1.8355,lwr_k=50:0.0652,lwr_k=100:0.3776,lwr_k=200:1.5162,lwr_k=300:2.4375,lwr_k=400:3.2954,lwr_k=500:3.9737,lwr_k=600:4.6994,lwr_k=700:4.9293,lwr_k=800:5.058,lwr_k=900:5.2553,lwr_k=1000:5.4356'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:10.4557,lwr_k=10:25.5762,lwr_k=20:52.599,lwr_k=30:117.9485,lwr_k=40:18.2973,lwr_k=50:28.5611,lwr_k=100:27.8648,lwr_k=200:18.2539,lwr_k=300:15.2463,lwr_k=400:13.2105,lwr_k=500:14.4431,lwr_k=600:11.3606,lwr_k=700:10.7672,lwr_k=800:9.6943,lwr_k=900:9.6416,lwr_k=1000:10.1902'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.1575,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.474,lwr_k=40:1.2068,lwr_k=50:0.0396,lwr_k=100:0.1912,lwr_k=200:0.9045,lwr_k=300:1.3269,lwr_k=400:1.6512,lwr_k=500:1.952,lwr_k=600:2.3753,lwr_k=700:2.4995,lwr_k=800:2.675,lwr_k=900:2.8152,lwr_k=1000:2.864'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:20.334,lwr_k=10:35.237,lwr_k=20:110.046,lwr_k=30:68.1828,lwr_k=40:23.3909,lwr_k=50:25.7735,lwr_k=100:27.806,lwr_k=200:28.3226,lwr_k=300:24.5468,lwr_k=400:22.4945,lwr_k=500:20.8573,lwr_k=600:21.1608,lwr_k=700:20.5953,lwr_k=800:19.6439,lwr_k=900:19.631,lwr_k=1000:19.6454'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:3.5761,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.171,lwr_k=40:1.119,lwr_k=50:0.0508,lwr_k=100:0.4857,lwr_k=200:1.6132,lwr_k=300:2.2684,lwr_k=400:2.6512,lwr_k=500:2.8839,lwr_k=600:2.9405,lwr_k=700:3.0064,lwr_k=800:3.1864,lwr_k=900:3.2615,lwr_k=1000:3.078'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.5662,lwr_k=10:19.006,lwr_k=20:66.7365,lwr_k=30:765.1777,lwr_k=40:43.5711,lwr_k=50:32.4271,lwr_k=100:19.9859,lwr_k=200:15.0813,lwr_k=300:11.1761,lwr_k=400:8.2965,lwr_k=500:8.1618,lwr_k=600:8.0822,lwr_k=700:7.9706,lwr_k=800:7.1741,lwr_k=900:7.32,lwr_k=1000:11.1747'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_48'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.1988,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0011,lwr_k=40:0.0294,lwr_k=50:0.5407,lwr_k=100:2.4919,lwr_k=200:3.3791,lwr_k=300:3.83,lwr_k=400:4.0897,lwr_k=500:4.2316,lwr_k=600:4.3401,lwr_k=700:4.3684,lwr_k=800:4.411,lwr_k=900:4.4323,lwr_k=1000:4.4799'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.594,lwr_k=10:36.7999,lwr_k=20:96.3896,lwr_k=30:89.9515,lwr_k=40:178.6419,lwr_k=50:170.49,lwr_k=100:10.0939,lwr_k=200:8.0815,lwr_k=300:7.7541,lwr_k=400:7.5952,lwr_k=500:7.6168,lwr_k=600:7.4588,lwr_k=700:7.2732,lwr_k=800:7.1681,lwr_k=900:7.0679,lwr_k=1000:6.9229'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.8118,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.003,lwr_k=40:0.0535,lwr_k=50:0.5991,lwr_k=100:2.4823,lwr_k=200:3.6664,lwr_k=300:4.0094,lwr_k=400:4.1835,lwr_k=500:4.2958,lwr_k=600:4.3475,lwr_k=700:4.3814,lwr_k=800:4.4184,lwr_k=900:4.4326,lwr_k=1000:4.4642'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.8775,lwr_k=10:43.2965,lwr_k=20:71.8131,lwr_k=30:76.2186,lwr_k=40:179.6694,lwr_k=50:77.2997,lwr_k=100:10.8814,lwr_k=200:7.586,lwr_k=300:7.1984,lwr_k=400:7.0898,lwr_k=500:6.9387,lwr_k=600:6.9153,lwr_k=700:6.9572,lwr_k=800:6.9175,lwr_k=900:6.9612,lwr_k=1000:6.912'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.9656,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0004,lwr_k=40:0.0139,lwr_k=50:0.6504,lwr_k=100:2.6706,lwr_k=200:3.8685,lwr_k=300:4.3261,lwr_k=400:4.5132,lwr_k=500:4.7362,lwr_k=600:4.9089,lwr_k=700:5.0545,lwr_k=800:5.1605,lwr_k=900:5.2587,lwr_k=1000:5.3165'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:5.4433,lwr_k=10:20.2176,lwr_k=20:33.3553,lwr_k=30:111.4029,lwr_k=40:2657.1688,lwr_k=50:90.812,lwr_k=100:9.9228,lwr_k=200:5.6772,lwr_k=300:5.124,lwr_k=400:5.0476,lwr_k=500:5.0274,lwr_k=600:5.0499,lwr_k=700:4.9994,lwr_k=800:5.0054,lwr_k=900:5.0447,lwr_k=1000:5.0426'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.737,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0016,lwr_k=40:0.0503,lwr_k=50:0.8548,lwr_k=100:2.8377,lwr_k=200:4.1994,lwr_k=300:4.6877,lwr_k=400:4.9467,lwr_k=500:5.1197,lwr_k=600:5.2454,lwr_k=700:5.3174,lwr_k=800:5.4221,lwr_k=900:5.5169,lwr_k=1000:5.561'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.2305,lwr_k=10:36.1261,lwr_k=20:75.2758,lwr_k=30:72.9345,lwr_k=40:212.7168,lwr_k=50:273.9176,lwr_k=100:10.0115,lwr_k=200:7.0657,lwr_k=300:6.8435,lwr_k=400:6.6932,lwr_k=500:6.7378,lwr_k=600:6.7432,lwr_k=700:6.7597,lwr_k=800:6.835,lwr_k=900:6.8715,lwr_k=1000:6.8512'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.9102,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.036,lwr_k=40:0.1595,lwr_k=50:0.635,lwr_k=100:2.1578,lwr_k=200:2.9784,lwr_k=300:3.1927,lwr_k=400:3.3557,lwr_k=500:3.4585,lwr_k=600:3.5156,lwr_k=700:3.5502,lwr_k=800:3.5998,lwr_k=900:3.6051,lwr_k=1000:3.6095'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:14.1927,lwr_k=10:130.3221,lwr_k=20:81.9028,lwr_k=30:159.812,lwr_k=40:390.1872,lwr_k=50:118.0305,lwr_k=100:18.1328,lwr_k=200:16.6306,lwr_k=300:15.3729,lwr_k=400:14.568,lwr_k=500:14.3649,lwr_k=600:14.1953,lwr_k=700:14.1067,lwr_k=800:14.0219,lwr_k=900:13.9315,lwr_k=1000:13.9384'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:5.1688,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0003,lwr_k=40:0.0415,lwr_k=50:0.4796,lwr_k=100:2.2729,lwr_k=200:3.1482,lwr_k=300:3.4898,lwr_k=400:3.6097,lwr_k=500:3.7171,lwr_k=600:3.7524,lwr_k=700:3.8011,lwr_k=800:3.8249,lwr_k=900:3.8398,lwr_k=1000:3.8701'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.6764,lwr_k=10:150.7762,lwr_k=20:71.872,lwr_k=30:266.5154,lwr_k=40:225.6569,lwr_k=50:103.9549,lwr_k=100:330.837,lwr_k=200:7.0813,lwr_k=300:7.3964,lwr_k=400:7.4453,lwr_k=500:7.0156,lwr_k=600:7.0331,lwr_k=700:7.093,lwr_k=800:7.0329,lwr_k=900:7.0459,lwr_k=1000:6.9941'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_49'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.2481,lwr_k=10:4.304,lwr_k=20:5.1622,lwr_k=30:5.5192,lwr_k=40:5.77,lwr_k=50:5.9214,lwr_k=100:6.1084,lwr_k=200:6.2231,lwr_k=300:6.2724,lwr_k=400:6.3121,lwr_k=500:6.3781,lwr_k=600:6.4075,lwr_k=700:6.4461,lwr_k=800:6.4845,lwr_k=900:6.51,lwr_k=1000:6.5459'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.5948,lwr_k=10:11.6403,lwr_k=20:9.8595,lwr_k=30:9.596,lwr_k=40:9.3222,lwr_k=50:9.0373,lwr_k=100:8.8181,lwr_k=200:8.865,lwr_k=300:9.0846,lwr_k=400:9.2094,lwr_k=500:9.3176,lwr_k=600:9.3465,lwr_k=700:9.3845,lwr_k=800:9.4544,lwr_k=900:9.4994,lwr_k=1000:9.5373'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:19.938,lwr_k=10:8.0316,lwr_k=20:9.8403,lwr_k=30:10.7147,lwr_k=40:11.323,lwr_k=50:11.6145,lwr_k=100:12.5159,lwr_k=200:13.4492,lwr_k=300:14.037,lwr_k=400:14.5697,lwr_k=500:14.932,lwr_k=600:15.2526,lwr_k=700:15.4933,lwr_k=800:15.7349,lwr_k=900:15.9826,lwr_k=1000:16.1788'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:14.9902,lwr_k=10:16.7413,lwr_k=20:13.1987,lwr_k=30:11.9718,lwr_k=40:11.7837,lwr_k=50:11.6022,lwr_k=100:11.386,lwr_k=200:11.3391,lwr_k=300:11.4927,lwr_k=400:11.5364,lwr_k=500:11.6631,lwr_k=600:11.857,lwr_k=700:11.9422,lwr_k=800:12.1654,lwr_k=900:12.2365,lwr_k=1000:12.2945'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:20.3169,lwr_k=10:8.2284,lwr_k=20:10.237,lwr_k=30:10.8786,lwr_k=40:11.5452,lwr_k=50:12.1134,lwr_k=100:13.4783,lwr_k=200:14.3752,lwr_k=300:14.8297,lwr_k=400:15.1792,lwr_k=500:15.3794,lwr_k=600:15.5817,lwr_k=700:15.7814,lwr_k=800:15.9499,lwr_k=900:16.093,lwr_k=1000:16.2596'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:13.2521,lwr_k=10:13.5525,lwr_k=20:11.7587,lwr_k=30:11.204,lwr_k=40:11.0891,lwr_k=50:10.5294,lwr_k=100:10.1915,lwr_k=200:10.1958,lwr_k=300:10.1469,lwr_k=400:10.2603,lwr_k=500:10.2634,lwr_k=600:10.3675,lwr_k=700:10.3882,lwr_k=800:10.4413,lwr_k=900:10.4455,lwr_k=1000:10.4751'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:18.1604,lwr_k=10:7.5862,lwr_k=20:9.2446,lwr_k=30:9.86,lwr_k=40:10.4661,lwr_k=50:11.0354,lwr_k=100:12.106,lwr_k=200:12.9807,lwr_k=300:13.4754,lwr_k=400:13.8867,lwr_k=500:14.1262,lwr_k=600:14.3555,lwr_k=700:14.5229,lwr_k=800:14.6815,lwr_k=900:14.8186,lwr_k=1000:14.968'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:15.7273,lwr_k=10:15.2061,lwr_k=20:12.5718,lwr_k=30:12.4746,lwr_k=40:12.0039,lwr_k=50:12.248,lwr_k=100:12.5342,lwr_k=200:12.5146,lwr_k=300:12.413,lwr_k=400:12.5218,lwr_k=500:12.568,lwr_k=600:12.6247,lwr_k=700:12.6917,lwr_k=800:12.7393,lwr_k=900:12.8265,lwr_k=1000:12.8883'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.7587,lwr_k=10:4.7166,lwr_k=20:5.6811,lwr_k=30:5.9505,lwr_k=40:6.2539,lwr_k=50:6.4264,lwr_k=100:6.6625,lwr_k=200:6.8087,lwr_k=300:6.9066,lwr_k=400:6.9662,lwr_k=500:7.0027,lwr_k=600:7.0436,lwr_k=700:7.0943,lwr_k=800:7.1187,lwr_k=900:7.1419,lwr_k=1000:7.1586'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:28.0524,lwr_k=10:18.7855,lwr_k=20:16.4116,lwr_k=30:18.1002,lwr_k=40:20.5075,lwr_k=50:21.0566,lwr_k=100:21.5464,lwr_k=200:22.9232,lwr_k=300:23.5882,lwr_k=400:24.0025,lwr_k=500:24.2536,lwr_k=600:24.6191,lwr_k=700:24.8166,lwr_k=800:25.0652,lwr_k=900:25.2008,lwr_k=1000:25.3284'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:18.3769,lwr_k=10:7.9724,lwr_k=20:9.621,lwr_k=30:10.0195,lwr_k=40:10.2926,lwr_k=50:10.6073,lwr_k=100:11.6628,lwr_k=200:12.3815,lwr_k=300:12.9635,lwr_k=400:13.3145,lwr_k=500:13.638,lwr_k=600:13.8644,lwr_k=700:14.0428,lwr_k=800:14.1673,lwr_k=900:14.3243,lwr_k=1000:14.4555'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:17.2962,lwr_k=10:16.6329,lwr_k=20:15.8724,lwr_k=30:14.6412,lwr_k=40:14.5399,lwr_k=50:14.1975,lwr_k=100:13.6291,lwr_k=200:13.9518,lwr_k=300:14.0563,lwr_k=400:14.0733,lwr_k=500:14.1492,lwr_k=600:14.1777,lwr_k=700:14.2505,lwr_k=800:14.2905,lwr_k=900:14.3278,lwr_k=1000:14.4176'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_50'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.7628,lwr_k=10:0.6229,lwr_k=20:4.6407,lwr_k=30:5.6828,lwr_k=40:6.2427,lwr_k=50:6.615,lwr_k=100:7.6008,lwr_k=200:8.1044,lwr_k=300:8.245,lwr_k=400:8.3743,lwr_k=500:8.5192,lwr_k=600:8.6209,lwr_k=700:8.6881,lwr_k=800:8.7598,lwr_k=900:8.8028,lwr_k=1000:8.8628'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:13.148,lwr_k=10:3536.6971,lwr_k=20:22.1476,lwr_k=30:15.1393,lwr_k=40:13.0668,lwr_k=50:12.341,lwr_k=100:11.3256,lwr_k=200:11.0774,lwr_k=300:11.1402,lwr_k=400:11.177,lwr_k=500:11.2657,lwr_k=600:11.4298,lwr_k=700:11.5574,lwr_k=800:11.6427,lwr_k=900:11.706,lwr_k=1000:11.7657'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:18.0532,lwr_k=10:0.6018,lwr_k=20:5.7683,lwr_k=30:7.7658,lwr_k=40:8.879,lwr_k=50:10.066,lwr_k=100:11.7669,lwr_k=200:13.0657,lwr_k=300:13.6082,lwr_k=400:13.9587,lwr_k=500:14.2334,lwr_k=600:14.417,lwr_k=700:14.5666,lwr_k=800:14.7926,lwr_k=900:15.0113,lwr_k=1000:15.1767'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:14.0664,lwr_k=10:5485779855.0758,lwr_k=20:1491.6575,lwr_k=30:20.1716,lwr_k=40:14.8224,lwr_k=50:13.7821,lwr_k=100:11.8411,lwr_k=200:11.2619,lwr_k=300:11.0979,lwr_k=400:11.171,lwr_k=500:11.335,lwr_k=600:11.3908,lwr_k=700:11.3749,lwr_k=800:11.5134,lwr_k=900:11.5997,lwr_k=1000:11.634'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:29.3615,lwr_k=10:0.7087,lwr_k=20:7.2907,lwr_k=30:9.6796,lwr_k=40:11.2917,lwr_k=50:12.548,lwr_k=100:15.1988,lwr_k=200:16.9491,lwr_k=300:17.8344,lwr_k=400:18.2409,lwr_k=500:18.9116,lwr_k=600:19.298,lwr_k=700:19.8781,lwr_k=800:20.1304,lwr_k=900:20.5675,lwr_k=1000:20.9649'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:17.7002,lwr_k=10:29030181.2076,lwr_k=20:4158351.2142,lwr_k=30:1957230.794,lwr_k=40:229890.7478,lwr_k=50:1568691.4416,lwr_k=100:7528.2841,lwr_k=200:12.1226,lwr_k=300:11.9553,lwr_k=400:12.0055,lwr_k=500:12.0573,lwr_k=600:12.0445,lwr_k=700:12.0126,lwr_k=800:12.153,lwr_k=900:12.0483,lwr_k=1000:12.175'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:14.4748,lwr_k=10:0.7777,lwr_k=20:5.3,lwr_k=30:6.8861,lwr_k=40:8.0853,lwr_k=50:8.848,lwr_k=100:10.1501,lwr_k=200:11.2991,lwr_k=300:11.8111,lwr_k=400:12.3059,lwr_k=500:12.4693,lwr_k=600:12.5976,lwr_k=700:12.7039,lwr_k=800:12.736,lwr_k=900:12.8223,lwr_k=1000:12.8854'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:14.5415,lwr_k=10:193763461.7358,lwr_k=20:28.9972,lwr_k=30:45.421,lwr_k=40:16.7287,lwr_k=50:21.4205,lwr_k=100:13.0368,lwr_k=200:12.5716,lwr_k=300:12.5022,lwr_k=400:12.474,lwr_k=500:12.61,lwr_k=600:12.6951,lwr_k=700:12.7353,lwr_k=800:12.7585,lwr_k=900:12.7488,lwr_k=1000:12.7583'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:18.7018,lwr_k=10:0.7149,lwr_k=20:6.5055,lwr_k=30:8.3508,lwr_k=40:9.3919,lwr_k=50:9.9115,lwr_k=100:11.1587,lwr_k=200:12.0101,lwr_k=300:12.4344,lwr_k=400:12.7603,lwr_k=500:13.1328,lwr_k=600:13.4261,lwr_k=700:13.825,lwr_k=800:14.083,lwr_k=900:14.3082,lwr_k=1000:14.5628'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:54.5677,lwr_k=10:226112.9059,lwr_k=20:41304.9651,lwr_k=30:43.852,lwr_k=40:51.009,lwr_k=50:48.5346,lwr_k=100:153.6166,lwr_k=200:35.5443,lwr_k=300:37.6283,lwr_k=400:39.0751,lwr_k=500:41.0672,lwr_k=600:42.4211,lwr_k=700:43.8244,lwr_k=800:44.7617,lwr_k=900:45.5026,lwr_k=1000:46.4162'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:11.0567,lwr_k=10:0.7963,lwr_k=20:4.7765,lwr_k=30:5.9914,lwr_k=40:6.6526,lwr_k=50:7.4542,lwr_k=100:8.4296,lwr_k=200:9.1835,lwr_k=300:9.539,lwr_k=400:9.6715,lwr_k=500:9.7665,lwr_k=600:9.8083,lwr_k=700:9.8599,lwr_k=800:9.9155,lwr_k=900:9.9667,lwr_k=1000:10.0158'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:15.5213,lwr_k=10:95309.6581,lwr_k=20:291426.455,lwr_k=30:49.1197,lwr_k=40:38.4384,lwr_k=50:17.2027,lwr_k=100:13.8846,lwr_k=200:14.1803,lwr_k=300:14.5737,lwr_k=400:14.5493,lwr_k=500:14.7571,lwr_k=600:14.979,lwr_k=700:15.076,lwr_k=800:14.9864,lwr_k=900:14.9503,lwr_k=1000:15.0677'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_51'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.9224,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0002,lwr_k=40:0.002,lwr_k=50:0.6238,lwr_k=100:2.7044,lwr_k=200:3.9476,lwr_k=300:4.4051,lwr_k=400:4.638,lwr_k=500:4.8349,lwr_k=600:4.9782,lwr_k=700:5.1037,lwr_k=800:5.2306,lwr_k=900:5.321,lwr_k=1000:5.4001'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.3893,lwr_k=10:30.9761,lwr_k=20:36.0171,lwr_k=30:55.6791,lwr_k=40:182.4126,lwr_k=50:48.3372,lwr_k=100:11.439,lwr_k=200:8.7044,lwr_k=300:8.3626,lwr_k=400:8.3275,lwr_k=500:8.2763,lwr_k=600:8.3645,lwr_k=700:8.4681,lwr_k=800:8.6189,lwr_k=900:8.6405,lwr_k=1000:8.6513'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:13.5962,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0098,lwr_k=50:0.8513,lwr_k=100:4.1839,lwr_k=200:6.8655,lwr_k=300:7.9916,lwr_k=400:8.602,lwr_k=500:9.1041,lwr_k=600:9.4158,lwr_k=700:9.6942,lwr_k=800:9.8947,lwr_k=900:10.087,lwr_k=1000:10.2706'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:13.6148,lwr_k=10:38.5296,lwr_k=20:57.2196,lwr_k=30:66.9285,lwr_k=40:185.1435,lwr_k=50:70.6432,lwr_k=100:14.7351,lwr_k=200:9.9376,lwr_k=300:9.3475,lwr_k=400:9.406,lwr_k=500:9.6627,lwr_k=600:9.6496,lwr_k=700:9.7958,lwr_k=800:9.7656,lwr_k=900:9.9121,lwr_k=1000:10.0338'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:21.0614,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0001,lwr_k=40:0.011,lwr_k=50:0.8956,lwr_k=100:5.1208,lwr_k=200:8.0911,lwr_k=300:9.8634,lwr_k=400:10.874,lwr_k=500:11.4327,lwr_k=600:11.9602,lwr_k=700:12.4284,lwr_k=800:12.7984,lwr_k=900:13.0739,lwr_k=1000:13.2219'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:13.2112,lwr_k=10:29.2666,lwr_k=20:60.3862,lwr_k=30:76.9885,lwr_k=40:242.0832,lwr_k=50:56.0852,lwr_k=100:14.3077,lwr_k=200:10.1814,lwr_k=300:8.9679,lwr_k=400:8.7867,lwr_k=500:8.6654,lwr_k=600:8.6896,lwr_k=700:8.7411,lwr_k=800:8.7047,lwr_k=900:8.626,lwr_k=1000:8.6656'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:14.1225,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0003,lwr_k=40:0.0244,lwr_k=50:1.0219,lwr_k=100:4.6152,lwr_k=200:6.8885,lwr_k=300:7.948,lwr_k=400:8.4035,lwr_k=500:8.7596,lwr_k=600:9.0974,lwr_k=700:9.4467,lwr_k=800:9.647,lwr_k=900:9.8107,lwr_k=1000:9.9923'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:13.3609,lwr_k=10:45.8588,lwr_k=20:58.9156,lwr_k=30:73.2367,lwr_k=40:214.8785,lwr_k=50:60.8579,lwr_k=100:15.3885,lwr_k=200:10.4833,lwr_k=300:9.9543,lwr_k=400:9.9629,lwr_k=500:9.8837,lwr_k=600:9.9469,lwr_k=700:9.9338,lwr_k=800:10.0513,lwr_k=900:10.2036,lwr_k=1000:10.0542'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.6656,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0001,lwr_k=40:0.0167,lwr_k=50:0.6382,lwr_k=100:2.8738,lwr_k=200:4.2656,lwr_k=300:4.8092,lwr_k=400:5.0358,lwr_k=500:5.2529,lwr_k=600:5.4643,lwr_k=700:5.6192,lwr_k=800:5.7194,lwr_k=900:5.7857,lwr_k=1000:5.8815'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:27.7232,lwr_k=10:43.4291,lwr_k=20:66.7301,lwr_k=30:70.337,lwr_k=40:348.3595,lwr_k=50:153.2137,lwr_k=100:24.9019,lwr_k=200:23.212,lwr_k=300:23.5295,lwr_k=400:23.454,lwr_k=500:23.6809,lwr_k=600:23.4614,lwr_k=700:23.7713,lwr_k=800:23.6692,lwr_k=900:23.7866,lwr_k=1000:24.104'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:12.1997,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0002,lwr_k=40:0.0124,lwr_k=50:0.7515,lwr_k=100:3.6397,lwr_k=200:5.6129,lwr_k=300:6.6135,lwr_k=400:7.2776,lwr_k=500:7.6419,lwr_k=600:7.9536,lwr_k=700:8.1953,lwr_k=800:8.3597,lwr_k=900:8.5093,lwr_k=1000:8.6651'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:14.3791,lwr_k=10:159.4246,lwr_k=20:58.5212,lwr_k=30:65.0014,lwr_k=40:226.2903,lwr_k=50:130.1829,lwr_k=100:12.4299,lwr_k=200:10.6532,lwr_k=300:10.8039,lwr_k=400:11.1554,lwr_k=500:11.6365,lwr_k=600:11.7912,lwr_k=700:11.9646,lwr_k=800:12.0499,lwr_k=900:12.3258,lwr_k=1000:12.3765'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_52'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.3761,lwr_k=10:0.0,lwr_k=20:0.0076,lwr_k=30:1.4662,lwr_k=40:4.8303,lwr_k=50:4.7402,lwr_k=100:6.1807,lwr_k=200:6.7047,lwr_k=300:7.1179,lwr_k=400:7.0325,lwr_k=500:7.1751,lwr_k=600:7.2492,lwr_k=700:7.2977,lwr_k=800:7.3922,lwr_k=900:7.4607,lwr_k=1000:7.5358'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.8636,lwr_k=10:92.0067,lwr_k=20:248.0041,lwr_k=30:3695.7937,lwr_k=40:194.0028,lwr_k=50:750469.7431,lwr_k=100:15.4227,lwr_k=200:11.3874,lwr_k=300:10.7773,lwr_k=400:10.149,lwr_k=500:9.9438,lwr_k=600:9.9352,lwr_k=700:9.9307,lwr_k=800:10.0275,lwr_k=900:10.068,lwr_k=1000:10.179'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.9092,lwr_k=10:0.0,lwr_k=20:0.0017,lwr_k=30:0.54,lwr_k=40:2.0012,lwr_k=50:2.5885,lwr_k=100:4.1657,lwr_k=200:6.0881,lwr_k=300:7.0891,lwr_k=400:7.5084,lwr_k=500:7.7027,lwr_k=600:7.8048,lwr_k=700:7.869,lwr_k=800:7.9293,lwr_k=900:7.976,lwr_k=1000:8.0254'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.1615,lwr_k=10:49.8252,lwr_k=20:1862.2915,lwr_k=30:64055.2553,lwr_k=40:81681.7523,lwr_k=50:14146.1334,lwr_k=100:611.395,lwr_k=200:9.0994,lwr_k=300:7.0215,lwr_k=400:7.0412,lwr_k=500:7.0615,lwr_k=600:7.0511,lwr_k=700:7.0657,lwr_k=800:7.066,lwr_k=900:7.0316,lwr_k=1000:7.0141'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:11.3095,lwr_k=10:0.0024,lwr_k=20:0.385,lwr_k=30:2.4998,lwr_k=40:17.6672,lwr_k=50:15.5737,lwr_k=100:13.1655,lwr_k=200:8.5316,lwr_k=300:8.1974,lwr_k=400:8.9116,lwr_k=500:9.4041,lwr_k=600:9.5556,lwr_k=700:10.2288,lwr_k=800:10.3376,lwr_k=900:10.4183,lwr_k=1000:10.5008'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.5428,lwr_k=10:2339.1286,lwr_k=20:70287262.1853,lwr_k=30:19102487.5394,lwr_k=40:569.8357,lwr_k=50:347.8866,lwr_k=100:121.6957,lwr_k=200:11.2584,lwr_k=300:9.6776,lwr_k=400:8.1046,lwr_k=500:7.9005,lwr_k=600:7.3855,lwr_k=700:7.4339,lwr_k=800:7.4088,lwr_k=900:7.459,lwr_k=1000:7.4782'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.1363,lwr_k=10:0.0,lwr_k=20:0.0135,lwr_k=30:0.5307,lwr_k=40:1.5343,lwr_k=50:2.619,lwr_k=100:4.3401,lwr_k=200:5.1879,lwr_k=300:5.5761,lwr_k=400:6.0173,lwr_k=500:6.6711,lwr_k=600:6.961,lwr_k=700:7.1958,lwr_k=800:7.3702,lwr_k=900:7.5443,lwr_k=1000:7.6853'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:9.0641,lwr_k=10:38.5981,lwr_k=20:143.5924,lwr_k=30:39807256.8606,lwr_k=40:40245.8815,lwr_k=50:213.7494,lwr_k=100:10.5163,lwr_k=200:8.4299,lwr_k=300:8.4483,lwr_k=400:8.4642,lwr_k=500:8.5156,lwr_k=600:8.5889,lwr_k=700:8.672,lwr_k=800:8.6064,lwr_k=900:8.6259,lwr_k=1000:8.6271'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.5621,lwr_k=10:0.0,lwr_k=20:0.0013,lwr_k=30:0.6082,lwr_k=40:1.406,lwr_k=50:2.0611,lwr_k=100:3.5923,lwr_k=200:4.2708,lwr_k=300:4.613,lwr_k=400:4.7747,lwr_k=500:4.8818,lwr_k=600:4.9544,lwr_k=700:5.0027,lwr_k=800:5.074,lwr_k=900:5.1172,lwr_k=1000:5.1534'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:21.3252,lwr_k=10:200.3603,lwr_k=20:557.6237,lwr_k=30:2263117.0454,lwr_k=40:180124.3295,lwr_k=50:61343.3665,lwr_k=100:1948.4713,lwr_k=200:15.1209,lwr_k=300:15.0226,lwr_k=400:15.6632,lwr_k=500:16.4893,lwr_k=600:17.1125,lwr_k=700:17.5144,lwr_k=800:17.9312,lwr_k=900:18.3264,lwr_k=1000:18.5944'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:10.8948,lwr_k=10:0.0004,lwr_k=20:0.3581,lwr_k=30:3.2077,lwr_k=40:18.3575,lwr_k=50:16.7778,lwr_k=100:13.2494,lwr_k=200:10.4692,lwr_k=300:10.9884,lwr_k=400:10.014,lwr_k=500:10.2761,lwr_k=600:10.3323,lwr_k=700:11.4073,lwr_k=800:10.8873,lwr_k=900:12.0005,lwr_k=1000:10.7547'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.5658,lwr_k=10:8886.1485,lwr_k=20:6782574.0258,lwr_k=30:795666.2119,lwr_k=40:64642.9528,lwr_k=50:406940.8949,lwr_k=100:587190.1655,lwr_k=200:4589078.7992,lwr_k=300:4874181.6875,lwr_k=400:68562554.1529,lwr_k=500:96034910.8464,lwr_k=600:4694923.8461,lwr_k=700:1275546.2255,lwr_k=800:6138395.2345,lwr_k=900:11.886,lwr_k=1000:38116.5253'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_53'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.8677,lwr_k=10:0.0,lwr_k=20:0.301,lwr_k=30:2.3812,lwr_k=40:3.5822,lwr_k=50:4.3417,lwr_k=100:6.1953,lwr_k=200:7.0626,lwr_k=300:7.6055,lwr_k=400:7.8631,lwr_k=500:7.9747,lwr_k=600:8.1137,lwr_k=700:8.2269,lwr_k=800:8.3426,lwr_k=900:8.4563,lwr_k=1000:8.5323'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:14.2178,lwr_k=10:153.4389,lwr_k=20:281.2355,lwr_k=30:29.3389,lwr_k=40:15.7581,lwr_k=50:12.4194,lwr_k=100:10.6822,lwr_k=200:10.0899,lwr_k=300:10.3705,lwr_k=400:10.6447,lwr_k=500:10.8494,lwr_k=600:10.8902,lwr_k=700:11.0547,lwr_k=800:11.23,lwr_k=900:11.4009,lwr_k=1000:11.4833'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:17.5846,lwr_k=10:0.0,lwr_k=20:0.4142,lwr_k=30:3.0868,lwr_k=40:5.005,lwr_k=50:6.1499,lwr_k=100:9.6507,lwr_k=200:11.4825,lwr_k=300:12.2954,lwr_k=400:12.7936,lwr_k=500:13.2339,lwr_k=600:13.4704,lwr_k=700:13.7587,lwr_k=800:13.9827,lwr_k=900:14.1827,lwr_k=1000:14.3748'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:14.0526,lwr_k=10:198.5239,lwr_k=20:914.3324,lwr_k=30:42.8145,lwr_k=40:24.022,lwr_k=50:17.2721,lwr_k=100:12.144,lwr_k=200:10.259,lwr_k=300:10.2923,lwr_k=400:10.4718,lwr_k=500:10.5783,lwr_k=600:10.8793,lwr_k=700:10.9721,lwr_k=800:11.0713,lwr_k=900:11.2216,lwr_k=1000:11.3165'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:12.937,lwr_k=10:0.0,lwr_k=20:0.3854,lwr_k=30:2.8506,lwr_k=40:4.0471,lwr_k=50:5.1801,lwr_k=100:7.5366,lwr_k=200:8.5529,lwr_k=300:9.4057,lwr_k=400:9.8678,lwr_k=500:10.2847,lwr_k=600:10.5001,lwr_k=700:10.673,lwr_k=800:10.8399,lwr_k=900:10.971,lwr_k=1000:11.1499'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.1067,lwr_k=10:85.9343,lwr_k=20:671.6986,lwr_k=30:38.7161,lwr_k=40:18.488,lwr_k=50:17.3828,lwr_k=100:8.7505,lwr_k=200:7.8619,lwr_k=300:7.3602,lwr_k=400:7.3023,lwr_k=500:7.1304,lwr_k=600:7.1559,lwr_k=700:7.1316,lwr_k=800:7.1056,lwr_k=900:7.1271,lwr_k=1000:7.1186'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:13.9912,lwr_k=10:0.0,lwr_k=20:0.4147,lwr_k=30:2.8645,lwr_k=40:4.1301,lwr_k=50:5.1157,lwr_k=100:7.8519,lwr_k=200:9.3972,lwr_k=300:10.3334,lwr_k=400:10.8952,lwr_k=500:11.2059,lwr_k=600:11.4034,lwr_k=700:11.6296,lwr_k=800:11.8292,lwr_k=900:12.0382,lwr_k=1000:12.2421'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:12.1654,lwr_k=10:135.2374,lwr_k=20:5034.9963,lwr_k=30:7438.7827,lwr_k=40:9194.1943,lwr_k=50:2335.3125,lwr_k=100:13.0246,lwr_k=200:11.1182,lwr_k=300:11.0217,lwr_k=400:11.0131,lwr_k=500:11.1728,lwr_k=600:11.2931,lwr_k=700:11.2807,lwr_k=800:11.2978,lwr_k=900:11.436,lwr_k=1000:11.4067'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.6062,lwr_k=10:0.0,lwr_k=20:0.3757,lwr_k=30:2.508,lwr_k=40:3.5989,lwr_k=50:4.3023,lwr_k=100:5.7114,lwr_k=200:6.6301,lwr_k=300:7.0589,lwr_k=400:7.319,lwr_k=500:7.4301,lwr_k=600:7.5328,lwr_k=700:7.6392,lwr_k=800:7.7569,lwr_k=900:7.8464,lwr_k=1000:7.9169'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:22.2894,lwr_k=10:110.2252,lwr_k=20:723.1521,lwr_k=30:41.826,lwr_k=40:25.2147,lwr_k=50:22.6845,lwr_k=100:21.9336,lwr_k=200:21.8381,lwr_k=300:21.3521,lwr_k=400:21.07,lwr_k=500:20.9234,lwr_k=600:20.8882,lwr_k=700:20.933,lwr_k=800:21.0714,lwr_k=900:21.0958,lwr_k=1000:21.1916'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:10.7525,lwr_k=10:0.0,lwr_k=20:0.3486,lwr_k=30:2.8697,lwr_k=40:4.4174,lwr_k=50:5.3287,lwr_k=100:7.4393,lwr_k=200:8.4147,lwr_k=300:8.9228,lwr_k=400:9.2334,lwr_k=500:9.4624,lwr_k=600:9.675,lwr_k=700:9.7856,lwr_k=800:9.8685,lwr_k=900:9.9465,lwr_k=1000:10.0134'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:16.4801,lwr_k=10:79.302,lwr_k=20:342.7836,lwr_k=30:33.989,lwr_k=40:22.8274,lwr_k=50:18.3419,lwr_k=100:16.5712,lwr_k=200:16.2991,lwr_k=300:15.4612,lwr_k=400:15.8378,lwr_k=500:16.0932,lwr_k=600:16.1869,lwr_k=700:16.3543,lwr_k=800:16.3871,lwr_k=900:16.3711,lwr_k=1000:16.346'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_54'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.7261,lwr_k=10:0.005,lwr_k=20:0.6943,lwr_k=30:2.0902,lwr_k=40:2.8118,lwr_k=50:3.3378,lwr_k=100:4.4608,lwr_k=200:5.2755,lwr_k=300:5.594,lwr_k=400:5.823,lwr_k=500:6.021,lwr_k=600:6.1435,lwr_k=700:6.3368,lwr_k=800:6.5034,lwr_k=900:6.6414,lwr_k=1000:6.763'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:15.6178,lwr_k=10:54.0421,lwr_k=20:205.2303,lwr_k=30:189.3241,lwr_k=40:14.321,lwr_k=50:11.0478,lwr_k=100:9.4198,lwr_k=200:9.5053,lwr_k=300:9.7188,lwr_k=400:10.0655,lwr_k=500:10.1949,lwr_k=600:10.451,lwr_k=700:10.8243,lwr_k=800:11.1039,lwr_k=900:11.4069,lwr_k=1000:11.7255'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.1982,lwr_k=10:0.0203,lwr_k=20:0.5527,lwr_k=30:2.2204,lwr_k=40:3.15,lwr_k=50:3.7314,lwr_k=100:5.8326,lwr_k=200:7.2654,lwr_k=300:7.7175,lwr_k=400:7.9625,lwr_k=500:8.1583,lwr_k=600:8.2755,lwr_k=700:8.3794,lwr_k=800:8.4909,lwr_k=900:8.5748,lwr_k=1000:8.6636'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.4112,lwr_k=10:637.8074,lwr_k=20:48342.0835,lwr_k=30:20.5074,lwr_k=40:15.1799,lwr_k=50:11.2849,lwr_k=100:7.1091,lwr_k=200:7.1881,lwr_k=300:7.2329,lwr_k=400:7.3929,lwr_k=500:7.5381,lwr_k=600:7.641,lwr_k=700:7.7212,lwr_k=800:7.7983,lwr_k=900:7.8564,lwr_k=1000:7.912'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.3079,lwr_k=10:1.2172,lwr_k=20:2.3139,lwr_k=30:3.4522,lwr_k=40:4.1007,lwr_k=50:4.5678,lwr_k=100:5.192,lwr_k=200:6.1232,lwr_k=300:6.3763,lwr_k=400:6.4914,lwr_k=500:6.5741,lwr_k=600:6.648,lwr_k=700:6.7038,lwr_k=800:6.7582,lwr_k=900:6.7873,lwr_k=1000:6.8611'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.211,lwr_k=10:91.6454,lwr_k=20:471.5331,lwr_k=30:8.072,lwr_k=40:8.0333,lwr_k=50:7.7774,lwr_k=100:7.3176,lwr_k=200:6.6917,lwr_k=300:6.485,lwr_k=400:6.5309,lwr_k=500:6.5519,lwr_k=600:6.5958,lwr_k=700:6.6072,lwr_k=800:6.6142,lwr_k=900:6.6022,lwr_k=1000:6.633'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.4487,lwr_k=10:0.0686,lwr_k=20:0.7709,lwr_k=30:2.127,lwr_k=40:2.7337,lwr_k=50:3.2548,lwr_k=100:4.1621,lwr_k=200:5.2831,lwr_k=300:6.1142,lwr_k=400:6.6648,lwr_k=500:7.0285,lwr_k=600:7.3052,lwr_k=700:7.4966,lwr_k=800:7.6998,lwr_k=900:7.8299,lwr_k=1000:7.9158'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:9.4151,lwr_k=10:70.5322,lwr_k=20:1116967.8958,lwr_k=30:18.2321,lwr_k=40:17.0259,lwr_k=50:9.8803,lwr_k=100:8.3909,lwr_k=200:8.2327,lwr_k=300:8.1432,lwr_k=400:8.1906,lwr_k=500:8.237,lwr_k=600:8.1883,lwr_k=700:8.2143,lwr_k=800:8.2672,lwr_k=900:8.2841,lwr_k=1000:8.3119'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:142.8502,lwr_k=10:0.0,lwr_k=20:9.4238,lwr_k=30:19.3074,lwr_k=40:25.71,lwr_k=50:29.5517,lwr_k=100:44.2715,lwr_k=200:59.375,lwr_k=300:68.2898,lwr_k=400:73.551,lwr_k=500:76.7343,lwr_k=600:79.9847,lwr_k=700:83.5476,lwr_k=800:86.6674,lwr_k=900:89.2282,lwr_k=1000:91.1841'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:213.6159,lwr_k=10:1369.8821,lwr_k=20:175.8751,lwr_k=30:253.7761,lwr_k=40:196.7065,lwr_k=50:179.8755,lwr_k=100:87.6694,lwr_k=200:88.4892,lwr_k=300:114.0087,lwr_k=400:121.0962,lwr_k=500:125.1168,lwr_k=600:128.4458,lwr_k=700:135.9871,lwr_k=800:141.5617,lwr_k=900:145.2671,lwr_k=1000:148.6155'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:6.929,lwr_k=10:0.0835,lwr_k=20:0.5786,lwr_k=30:1.7625,lwr_k=40:2.2715,lwr_k=50:2.6719,lwr_k=100:3.7932,lwr_k=200:4.6228,lwr_k=300:4.975,lwr_k=400:5.1234,lwr_k=500:5.2952,lwr_k=600:5.4364,lwr_k=700:5.4988,lwr_k=800:5.5601,lwr_k=900:5.6298,lwr_k=1000:5.7211'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.9233,lwr_k=10:85.3953,lwr_k=20:1021.8973,lwr_k=30:15.6135,lwr_k=40:12.1933,lwr_k=50:10.9001,lwr_k=100:6.8556,lwr_k=200:6.8668,lwr_k=300:6.8076,lwr_k=400:7.0178,lwr_k=500:7.0848,lwr_k=600:7.082,lwr_k=700:7.1339,lwr_k=800:7.1053,lwr_k=900:7.0332,lwr_k=1000:7.048'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_55'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.7252,lwr_k=10:0.0016,lwr_k=20:1.6425,lwr_k=30:3.3275,lwr_k=40:3.8515,lwr_k=50:4.4214,lwr_k=100:5.3011,lwr_k=200:5.7159,lwr_k=300:5.8405,lwr_k=400:5.9193,lwr_k=500:5.9943,lwr_k=600:6.061,lwr_k=700:6.0922,lwr_k=800:6.1234,lwr_k=900:6.169,lwr_k=1000:6.1905'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.4852,lwr_k=10:5571.5067,lwr_k=20:446.2276,lwr_k=30:9668.0807,lwr_k=40:5921.8514,lwr_k=50:1200.2311,lwr_k=100:8.9343,lwr_k=200:8.2991,lwr_k=300:8.2348,lwr_k=400:8.321,lwr_k=500:8.2662,lwr_k=600:8.2884,lwr_k=700:8.3516,lwr_k=800:8.3104,lwr_k=900:8.3236,lwr_k=1000:8.3364'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.4661,lwr_k=10:0.0003,lwr_k=20:0.9589,lwr_k=30:2.6067,lwr_k=40:3.731,lwr_k=50:4.2729,lwr_k=100:5.5011,lwr_k=200:6.3267,lwr_k=300:6.819,lwr_k=400:7.0239,lwr_k=500:7.2296,lwr_k=600:7.3743,lwr_k=700:7.502,lwr_k=800:7.5922,lwr_k=900:7.6985,lwr_k=1000:7.7995'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.4974,lwr_k=10:15769.5421,lwr_k=20:9444.4937,lwr_k=30:13841.2103,lwr_k=40:88665.8661,lwr_k=50:9031.4241,lwr_k=100:9583.5579,lwr_k=200:12.2546,lwr_k=300:8.2094,lwr_k=400:8.2334,lwr_k=500:8.3303,lwr_k=600:8.3738,lwr_k=700:8.5864,lwr_k=800:8.694,lwr_k=900:8.7071,lwr_k=1000:8.818'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.5261,lwr_k=10:0.0007,lwr_k=20:2.362,lwr_k=30:3.6183,lwr_k=40:4.3899,lwr_k=50:4.9126,lwr_k=100:5.7872,lwr_k=200:6.3512,lwr_k=300:6.8834,lwr_k=400:6.9769,lwr_k=500:7.0354,lwr_k=600:7.1036,lwr_k=700:7.1152,lwr_k=800:7.1496,lwr_k=900:7.1563,lwr_k=1000:7.1976'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.9871,lwr_k=10:1367009.7355,lwr_k=20:1955.5599,lwr_k=30:151.8712,lwr_k=40:12.5616,lwr_k=50:8.668,lwr_k=100:8.0133,lwr_k=200:7.4494,lwr_k=300:7.0073,lwr_k=400:6.3807,lwr_k=500:6.3299,lwr_k=600:6.4274,lwr_k=700:6.4567,lwr_k=800:6.4826,lwr_k=900:6.4682,lwr_k=1000:6.3826'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.255,lwr_k=10:0.0002,lwr_k=20:0.5889,lwr_k=30:2.244,lwr_k=40:3.3994,lwr_k=50:4.0297,lwr_k=100:5.6884,lwr_k=200:6.4837,lwr_k=300:6.7922,lwr_k=400:6.8937,lwr_k=500:6.9903,lwr_k=600:7.0755,lwr_k=700:7.1375,lwr_k=800:7.1785,lwr_k=900:7.2008,lwr_k=1000:7.2481'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:9.7292,lwr_k=10:361.8202,lwr_k=20:437.1993,lwr_k=30:81.3187,lwr_k=40:34.0152,lwr_k=50:17.1633,lwr_k=100:11.252,lwr_k=200:11.0633,lwr_k=300:10.3259,lwr_k=400:9.461,lwr_k=500:9.6599,lwr_k=600:9.6554,lwr_k=700:9.6185,lwr_k=800:9.6236,lwr_k=900:9.7073,lwr_k=1000:9.7719'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.5209,lwr_k=10:0.0024,lwr_k=20:1.9229,lwr_k=30:2.8753,lwr_k=40:3.8822,lwr_k=50:4.4268,lwr_k=100:5.4795,lwr_k=200:6.0682,lwr_k=300:6.3156,lwr_k=400:6.3838,lwr_k=500:6.5089,lwr_k=600:6.5826,lwr_k=700:6.6387,lwr_k=800:6.6997,lwr_k=900:6.7237,lwr_k=1000:6.7696'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:18.8592,lwr_k=10:7573.5953,lwr_k=20:133.0994,lwr_k=30:44034.2752,lwr_k=40:37.6706,lwr_k=50:17117.1058,lwr_k=100:21.3491,lwr_k=200:20.1584,lwr_k=300:18.978,lwr_k=400:18.3939,lwr_k=500:18.3697,lwr_k=600:18.3833,lwr_k=700:18.3924,lwr_k=800:18.6158,lwr_k=900:18.6498,lwr_k=1000:18.6463'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:7.4995,lwr_k=10:0.0005,lwr_k=20:1.4024,lwr_k=30:2.6238,lwr_k=40:3.3459,lwr_k=50:3.8096,lwr_k=100:4.8117,lwr_k=200:5.4027,lwr_k=300:5.6227,lwr_k=400:5.7429,lwr_k=500:5.8913,lwr_k=600:5.9473,lwr_k=700:6.0334,lwr_k=800:6.0821,lwr_k=900:6.1262,lwr_k=1000:6.1946'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.2536,lwr_k=10:1355.0013,lwr_k=20:118.3368,lwr_k=30:51602.2468,lwr_k=40:5631.398,lwr_k=50:60.6382,lwr_k=100:27.4827,lwr_k=200:9.3793,lwr_k=300:8.6337,lwr_k=400:8.4849,lwr_k=500:8.4001,lwr_k=600:8.4744,lwr_k=700:8.4836,lwr_k=800:8.5279,lwr_k=900:8.593,lwr_k=1000:8.5766'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_56'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.0234,lwr_k=10:0.0,lwr_k=20:2.6357,lwr_k=30:3.9316,lwr_k=40:4.8516,lwr_k=50:5.1249,lwr_k=100:5.7369,lwr_k=200:6.1505,lwr_k=300:6.3182,lwr_k=400:6.3685,lwr_k=500:6.4046,lwr_k=600:6.4194,lwr_k=700:6.4466,lwr_k=800:6.4848,lwr_k=900:6.5012,lwr_k=1000:6.5302'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.9398,lwr_k=10:164.5606,lwr_k=20:17.7296,lwr_k=30:11.1413,lwr_k=40:9.8696,lwr_k=50:8.7434,lwr_k=100:8.2548,lwr_k=200:8.3124,lwr_k=300:8.2669,lwr_k=400:8.2383,lwr_k=500:8.2995,lwr_k=600:8.386,lwr_k=700:8.4478,lwr_k=800:8.5448,lwr_k=900:8.554,lwr_k=1000:8.574'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:11.5135,lwr_k=10:0.0128,lwr_k=20:3.2325,lwr_k=30:5.0184,lwr_k=40:6.1307,lwr_k=50:6.7377,lwr_k=100:8.0011,lwr_k=200:9.0776,lwr_k=300:9.4691,lwr_k=400:9.696,lwr_k=500:9.802,lwr_k=600:9.9155,lwr_k=700:10.0216,lwr_k=800:10.1129,lwr_k=900:10.169,lwr_k=1000:10.2174'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.9997,lwr_k=10:2931.8809,lwr_k=20:23.9413,lwr_k=30:11.4723,lwr_k=40:9.7956,lwr_k=50:9.3305,lwr_k=100:7.9229,lwr_k=200:7.4952,lwr_k=300:7.6089,lwr_k=400:7.6715,lwr_k=500:7.7689,lwr_k=600:8.0895,lwr_k=700:8.1441,lwr_k=800:8.2141,lwr_k=900:8.198,lwr_k=1000:8.2336'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.4895,lwr_k=10:0.0003,lwr_k=20:3.177,lwr_k=30:4.6041,lwr_k=40:5.3014,lwr_k=50:5.9031,lwr_k=100:7.0953,lwr_k=200:8.6657,lwr_k=300:9.0645,lwr_k=400:9.2041,lwr_k=500:9.3439,lwr_k=600:9.3753,lwr_k=700:9.4908,lwr_k=800:9.5582,lwr_k=900:9.656,lwr_k=1000:9.8129'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.5296,lwr_k=10:994.9143,lwr_k=20:40.3078,lwr_k=30:11.2015,lwr_k=40:9.8417,lwr_k=50:8.2039,lwr_k=100:7.7442,lwr_k=200:7.5323,lwr_k=300:7.4086,lwr_k=400:7.3929,lwr_k=500:7.3488,lwr_k=600:7.3754,lwr_k=700:7.3452,lwr_k=800:7.3262,lwr_k=900:7.2972,lwr_k=1000:7.2644'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.6534,lwr_k=10:0.0055,lwr_k=20:3.339,lwr_k=30:4.8214,lwr_k=40:5.7282,lwr_k=50:6.066,lwr_k=100:7.1403,lwr_k=200:7.78,lwr_k=300:8.0573,lwr_k=400:8.2743,lwr_k=500:8.5034,lwr_k=600:8.5749,lwr_k=700:8.6026,lwr_k=800:8.653,lwr_k=900:8.7343,lwr_k=1000:8.817'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:10.4249,lwr_k=10:1939.9322,lwr_k=20:38.023,lwr_k=30:28.3928,lwr_k=40:12.1207,lwr_k=50:11.2316,lwr_k=100:10.2674,lwr_k=200:9.777,lwr_k=300:9.5859,lwr_k=400:9.6569,lwr_k=500:9.9872,lwr_k=600:9.9683,lwr_k=700:9.9858,lwr_k=800:10.0424,lwr_k=900:10.0435,lwr_k=1000:10.0743'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.5093,lwr_k=10:0.0066,lwr_k=20:2.7465,lwr_k=30:4.0717,lwr_k=40:4.6841,lwr_k=50:5.1022,lwr_k=100:5.937,lwr_k=200:6.5641,lwr_k=300:6.7832,lwr_k=400:6.8736,lwr_k=500:6.9289,lwr_k=600:7.0118,lwr_k=700:7.0549,lwr_k=800:7.0799,lwr_k=900:7.1088,lwr_k=1000:7.1322'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:24.9764,lwr_k=10:753.7602,lwr_k=20:27.354,lwr_k=30:19.3671,lwr_k=40:17.0568,lwr_k=50:17.6755,lwr_k=100:19.3103,lwr_k=200:21.6232,lwr_k=300:22.9032,lwr_k=400:22.6669,lwr_k=500:22.7657,lwr_k=600:22.7484,lwr_k=700:22.8354,lwr_k=800:22.88,lwr_k=900:23.0746,lwr_k=1000:23.1268'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:8.4132,lwr_k=10:0.0006,lwr_k=20:2.4597,lwr_k=30:3.8126,lwr_k=40:4.5607,lwr_k=50:4.9321,lwr_k=100:6.0856,lwr_k=200:6.8688,lwr_k=300:7.3232,lwr_k=400:7.5083,lwr_k=500:7.5638,lwr_k=600:7.5905,lwr_k=700:7.6491,lwr_k=800:7.7001,lwr_k=900:7.7751,lwr_k=1000:7.8007'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.4006,lwr_k=10:3769.9668,lwr_k=20:14777.3134,lwr_k=30:136.5736,lwr_k=40:163.491,lwr_k=50:5437.5923,lwr_k=100:729.2946,lwr_k=200:10.4982,lwr_k=300:10.3715,lwr_k=400:10.5236,lwr_k=500:10.3675,lwr_k=600:10.2969,lwr_k=700:10.2766,lwr_k=800:10.1823,lwr_k=900:10.1259,lwr_k=1000:10.0855'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_57'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.911,lwr_k=10:0.0718,lwr_k=20:3.5808,lwr_k=30:4.4461,lwr_k=40:4.8612,lwr_k=50:5.1809,lwr_k=100:5.7675,lwr_k=200:6.1864,lwr_k=300:6.2866,lwr_k=400:6.3559,lwr_k=500:6.4093,lwr_k=600:6.4497,lwr_k=700:6.4697,lwr_k=800:6.5013,lwr_k=900:6.5248,lwr_k=1000:6.5629'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.1513,lwr_k=10:1314.3135,lwr_k=20:15.6291,lwr_k=30:11.5895,lwr_k=40:9.9782,lwr_k=50:9.3874,lwr_k=100:8.544,lwr_k=200:8.4797,lwr_k=300:8.4961,lwr_k=400:8.5733,lwr_k=500:8.6231,lwr_k=600:8.6419,lwr_k=700:8.7289,lwr_k=800:8.7341,lwr_k=900:8.8024,lwr_k=1000:8.8491'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.9809,lwr_k=10:0.8808,lwr_k=20:4.1755,lwr_k=30:5.2017,lwr_k=40:5.9362,lwr_k=50:6.4389,lwr_k=100:7.5796,lwr_k=200:8.6559,lwr_k=300:8.956,lwr_k=400:9.1296,lwr_k=500:9.205,lwr_k=600:9.275,lwr_k=700:9.3495,lwr_k=800:9.4106,lwr_k=900:9.4452,lwr_k=1000:9.4933'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.9818,lwr_k=10:224.3328,lwr_k=20:11.6151,lwr_k=30:11.3613,lwr_k=40:10.5002,lwr_k=50:8.3776,lwr_k=100:6.8853,lwr_k=200:6.9615,lwr_k=300:7.0249,lwr_k=400:7.0637,lwr_k=500:7.1077,lwr_k=600:7.1674,lwr_k=700:7.2309,lwr_k=800:7.2648,lwr_k=900:7.3013,lwr_k=1000:7.3554'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.6615,lwr_k=10:0.0,lwr_k=20:3.9734,lwr_k=30:4.9898,lwr_k=40:5.5233,lwr_k=50:6.0444,lwr_k=100:7.4609,lwr_k=200:8.1726,lwr_k=300:8.5746,lwr_k=400:8.7201,lwr_k=500:8.8802,lwr_k=600:8.951,lwr_k=700:9.008,lwr_k=800:9.0618,lwr_k=900:9.1065,lwr_k=1000:9.157'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.9899,lwr_k=10:13633.8135,lwr_k=20:14.2761,lwr_k=30:9.8403,lwr_k=40:8.9082,lwr_k=50:8.3189,lwr_k=100:7.392,lwr_k=200:6.8869,lwr_k=300:6.7422,lwr_k=400:6.7016,lwr_k=500:6.6701,lwr_k=600:6.6791,lwr_k=700:6.6988,lwr_k=800:6.6998,lwr_k=900:6.7083,lwr_k=1000:6.7061'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.4197,lwr_k=10:0.5029,lwr_k=20:4.4936,lwr_k=30:5.8636,lwr_k=40:6.3899,lwr_k=50:6.8394,lwr_k=100:8.0287,lwr_k=200:8.7714,lwr_k=300:9.1385,lwr_k=400:9.3126,lwr_k=500:9.366,lwr_k=600:9.4356,lwr_k=700:9.5175,lwr_k=800:9.5491,lwr_k=900:9.6354,lwr_k=1000:9.6859'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:10.5487,lwr_k=10:261.9964,lwr_k=20:17.851,lwr_k=30:11.6407,lwr_k=40:11.7218,lwr_k=50:10.9965,lwr_k=100:9.7594,lwr_k=200:9.6426,lwr_k=300:9.6221,lwr_k=400:9.7098,lwr_k=500:9.7067,lwr_k=600:9.7036,lwr_k=700:9.7895,lwr_k=800:9.8591,lwr_k=900:9.9466,lwr_k=1000:9.9676'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.536,lwr_k=10:0.0284,lwr_k=20:3.1285,lwr_k=30:4.2662,lwr_k=40:4.9076,lwr_k=50:5.1791,lwr_k=100:5.9346,lwr_k=200:6.3981,lwr_k=300:6.5936,lwr_k=400:6.6619,lwr_k=500:6.7548,lwr_k=600:6.8115,lwr_k=700:6.8764,lwr_k=800:6.9154,lwr_k=900:6.9301,lwr_k=1000:6.9653'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:21.0067,lwr_k=10:62864.2988,lwr_k=20:22.6906,lwr_k=30:14.5255,lwr_k=40:19.0014,lwr_k=50:22.4387,lwr_k=100:20.7699,lwr_k=200:19.7117,lwr_k=300:20.3356,lwr_k=400:20.3621,lwr_k=500:20.4703,lwr_k=600:20.5827,lwr_k=700:20.6784,lwr_k=800:20.669,lwr_k=900:20.669,lwr_k=1000:20.695'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:7.9667,lwr_k=10:0.0,lwr_k=20:3.0449,lwr_k=30:4.3115,lwr_k=40:4.8725,lwr_k=50:5.2554,lwr_k=100:6.0369,lwr_k=200:6.6426,lwr_k=300:6.8659,lwr_k=400:6.9845,lwr_k=500:7.078,lwr_k=600:7.1646,lwr_k=700:7.2165,lwr_k=800:7.2582,lwr_k=900:7.298,lwr_k=1000:7.3235'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.4376,lwr_k=10:27218.6034,lwr_k=20:15.6007,lwr_k=30:12.1594,lwr_k=40:9.7818,lwr_k=50:9.3453,lwr_k=100:8.8921,lwr_k=200:9.4939,lwr_k=300:9.4342,lwr_k=400:9.5044,lwr_k=500:9.5905,lwr_k=600:9.5977,lwr_k=700:9.5498,lwr_k=800:9.5215,lwr_k=900:9.497,lwr_k=1000:9.4897'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_58'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:97.9205,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:4.2542,lwr_k=40:8.7688,lwr_k=50:12.4759,lwr_k=100:21.7321,lwr_k=200:31.8156,lwr_k=300:38.2639,lwr_k=400:42.5416,lwr_k=500:46.1742,lwr_k=600:48.6354,lwr_k=700:51.2909,lwr_k=800:53.3532,lwr_k=900:55.122,lwr_k=1000:57.4158'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:126.748,lwr_k=10:115.6601,lwr_k=20:410.0897,lwr_k=30:338.4247,lwr_k=40:45.5553,lwr_k=50:35.6898,lwr_k=100:35.006,lwr_k=200:39.954,lwr_k=300:45.4203,lwr_k=400:51.6365,lwr_k=500:55.274,lwr_k=600:59.4652,lwr_k=700:62.8656,lwr_k=800:66.3116,lwr_k=900:69.47,lwr_k=1000:72.1433'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:122.308,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:4.6538,lwr_k=40:9.7361,lwr_k=50:12.3168,lwr_k=100:23.4747,lwr_k=200:34.3452,lwr_k=300:40.5473,lwr_k=400:46.3096,lwr_k=500:50.8664,lwr_k=600:55.1201,lwr_k=700:58.249,lwr_k=800:61.7554,lwr_k=900:65.1621,lwr_k=1000:68.3928'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:99.3874,lwr_k=10:128.6094,lwr_k=20:422.5841,lwr_k=30:91.0478,lwr_k=40:97.2738,lwr_k=50:103.6178,lwr_k=100:39.5028,lwr_k=200:42.7711,lwr_k=300:47.7346,lwr_k=400:51.091,lwr_k=500:52.5221,lwr_k=600:55.4413,lwr_k=700:56.0915,lwr_k=800:57.4654,lwr_k=900:58.8521,lwr_k=1000:60.5256'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:132.7482,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:4.7246,lwr_k=40:9.2147,lwr_k=50:12.4863,lwr_k=100:24.0673,lwr_k=200:34.4988,lwr_k=300:42.2341,lwr_k=400:48.3181,lwr_k=500:53.452,lwr_k=600:57.9537,lwr_k=700:61.5361,lwr_k=800:65.2804,lwr_k=900:69.0217,lwr_k=1000:72.5462'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:97.7648,lwr_k=10:134.5129,lwr_k=20:593.9476,lwr_k=30:442.5228,lwr_k=40:168.8339,lwr_k=50:70.086,lwr_k=100:34.5375,lwr_k=200:36.4551,lwr_k=300:38.1824,lwr_k=400:40.9954,lwr_k=500:42.1526,lwr_k=600:44.9569,lwr_k=700:47.7319,lwr_k=800:48.145,lwr_k=900:48.495,lwr_k=1000:49.3576'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:128.1002,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:4.0244,lwr_k=40:8.3028,lwr_k=50:11.4415,lwr_k=100:23.7847,lwr_k=200:34.6242,lwr_k=300:42.0261,lwr_k=400:49.7328,lwr_k=500:54.3837,lwr_k=600:57.9121,lwr_k=700:61.2673,lwr_k=800:64.3387,lwr_k=900:67.5152,lwr_k=1000:71.2598'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:118.4971,lwr_k=10:197.6923,lwr_k=20:243.6298,lwr_k=30:321.5307,lwr_k=40:86.8988,lwr_k=50:73.32,lwr_k=100:49.6571,lwr_k=200:45.3528,lwr_k=300:50.0324,lwr_k=400:54.0245,lwr_k=500:57.1728,lwr_k=600:59.6118,lwr_k=700:62.2302,lwr_k=800:64.638,lwr_k=900:66.4487,lwr_k=1000:68.9687'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:101.1872,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:3.6335,lwr_k=40:7.3987,lwr_k=50:10.6326,lwr_k=100:20.8684,lwr_k=200:30.5222,lwr_k=300:37.3371,lwr_k=400:42.2263,lwr_k=500:45.7727,lwr_k=600:48.1511,lwr_k=700:50.2393,lwr_k=800:52.3957,lwr_k=900:54.3878,lwr_k=1000:56.1721'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:177.404,lwr_k=10:223.7852,lwr_k=20:289.9081,lwr_k=30:122.3164,lwr_k=40:81.3011,lwr_k=50:64.1326,lwr_k=100:53.4517,lwr_k=200:60.8225,lwr_k=300:73.6228,lwr_k=400:78.7898,lwr_k=500:83.3412,lwr_k=600:88.3026,lwr_k=700:92.6559,lwr_k=800:96.2422,lwr_k=900:99.1914,lwr_k=1000:104.2818'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:118.0652,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:3.5138,lwr_k=40:7.6352,lwr_k=50:10.6716,lwr_k=100:19.9268,lwr_k=200:29.3398,lwr_k=300:35.4978,lwr_k=400:40.8216,lwr_k=500:45.79,lwr_k=600:49.4575,lwr_k=700:52.3711,lwr_k=800:55.0102,lwr_k=900:57.2104,lwr_k=1000:59.2478'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:111.3464,lwr_k=10:138.1267,lwr_k=20:426.3189,lwr_k=30:169.3094,lwr_k=40:133.021,lwr_k=50:125.9709,lwr_k=100:45.523,lwr_k=200:53.1274,lwr_k=300:54.1584,lwr_k=400:56.2242,lwr_k=500:58.43,lwr_k=600:61.3196,lwr_k=700:62.9603,lwr_k=800:63.5577,lwr_k=900:64.7735,lwr_k=1000:66.3307'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_59'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:37.4305,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:3.4513,lwr_k=40:5.7848,lwr_k=50:7.6772,lwr_k=100:11.5935,lwr_k=200:14.8027,lwr_k=300:16.6868,lwr_k=400:17.7392,lwr_k=500:18.7017,lwr_k=600:19.4993,lwr_k=700:20.1867,lwr_k=800:20.8768,lwr_k=900:21.5269,lwr_k=1000:22.3858'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:46.9907,lwr_k=10:79.4239,lwr_k=20:490.3966,lwr_k=30:45.9056,lwr_k=40:27.6373,lwr_k=50:22.6493,lwr_k=100:18.5651,lwr_k=200:19.8561,lwr_k=300:20.898,lwr_k=400:22.0488,lwr_k=500:23.2894,lwr_k=600:24.3722,lwr_k=700:25.4527,lwr_k=800:26.3368,lwr_k=900:27.2568,lwr_k=1000:28.388'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:39.9444,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:3.2258,lwr_k=40:5.5958,lwr_k=50:6.7119,lwr_k=100:11.416,lwr_k=200:15.9077,lwr_k=300:18.3544,lwr_k=400:20.2752,lwr_k=500:21.737,lwr_k=600:22.7246,lwr_k=700:23.6765,lwr_k=800:24.4119,lwr_k=900:25.1991,lwr_k=1000:25.9425'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:25.9598,lwr_k=10:71.3729,lwr_k=20:758.8276,lwr_k=30:47.4749,lwr_k=40:26.1809,lwr_k=50:22.1715,lwr_k=100:17.9805,lwr_k=200:14.1771,lwr_k=300:14.5145,lwr_k=400:14.8704,lwr_k=500:15.1257,lwr_k=600:15.5021,lwr_k=700:15.7716,lwr_k=800:16.2088,lwr_k=900:16.398,lwr_k=1000:16.7053'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:39.7232,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:2.7938,lwr_k=40:4.9129,lwr_k=50:7.1501,lwr_k=100:11.7513,lwr_k=200:15.6276,lwr_k=300:18.5211,lwr_k=400:19.7887,lwr_k=500:20.8581,lwr_k=600:21.8514,lwr_k=700:22.6919,lwr_k=800:23.2506,lwr_k=900:23.8147,lwr_k=1000:24.3837'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:23.689,lwr_k=10:52.5281,lwr_k=20:380.4219,lwr_k=30:27.5614,lwr_k=40:18.5987,lwr_k=50:12.6754,lwr_k=100:12.1051,lwr_k=200:11.8645,lwr_k=300:12.4214,lwr_k=400:12.5243,lwr_k=500:12.8626,lwr_k=600:13.1563,lwr_k=700:13.6606,lwr_k=800:13.887,lwr_k=900:14.0856,lwr_k=1000:14.2453'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:33.491,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:2.727,lwr_k=40:4.5281,lwr_k=50:5.5925,lwr_k=100:9.3377,lwr_k=200:13.3089,lwr_k=300:15.56,lwr_k=400:16.8273,lwr_k=500:17.6951,lwr_k=600:18.5169,lwr_k=700:19.0465,lwr_k=800:19.5601,lwr_k=900:20.0603,lwr_k=1000:20.412'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:26.6292,lwr_k=10:60.9599,lwr_k=20:704.4629,lwr_k=30:48.5101,lwr_k=40:25.615,lwr_k=50:17.6677,lwr_k=100:13.7255,lwr_k=200:12.7757,lwr_k=300:13.2858,lwr_k=400:13.7252,lwr_k=500:14.1033,lwr_k=600:14.4793,lwr_k=700:14.6856,lwr_k=800:14.9673,lwr_k=900:15.3719,lwr_k=1000:15.5802'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:45.95,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:3.0109,lwr_k=40:5.1026,lwr_k=50:6.4797,lwr_k=100:10.6445,lwr_k=200:15.6949,lwr_k=300:19.3613,lwr_k=400:22.0337,lwr_k=500:24.4063,lwr_k=600:26.2994,lwr_k=700:27.9752,lwr_k=800:29.2803,lwr_k=900:30.434,lwr_k=1000:31.4035'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:95.864,lwr_k=10:79.7557,lwr_k=20:497.6746,lwr_k=30:56.279,lwr_k=40:53.5028,lwr_k=50:49.1943,lwr_k=100:50.2614,lwr_k=200:56.4072,lwr_k=300:60.901,lwr_k=400:66.1198,lwr_k=500:68.9111,lwr_k=600:71.7193,lwr_k=700:74.2519,lwr_k=800:76.185,lwr_k=900:78.2666,lwr_k=1000:80.0651'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:57.8765,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:3.2312,lwr_k=40:5.4596,lwr_k=50:8.061,lwr_k=100:14.0551,lwr_k=200:20.4642,lwr_k=300:24.3083,lwr_k=400:27.4381,lwr_k=500:30.1921,lwr_k=600:32.4593,lwr_k=700:34.0393,lwr_k=800:35.5192,lwr_k=900:37.0694,lwr_k=1000:38.4626'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:58.5919,lwr_k=10:66.42,lwr_k=20:578.7314,lwr_k=30:56.0918,lwr_k=40:40.827,lwr_k=50:30.1111,lwr_k=100:27.1772,lwr_k=200:26.0785,lwr_k=300:28.7377,lwr_k=400:30.0049,lwr_k=500:32.1489,lwr_k=600:33.6262,lwr_k=700:35.096,lwr_k=800:36.1516,lwr_k=900:37.4245,lwr_k=1000:38.8923'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_60'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.5902,lwr_k=10:2.1244,lwr_k=20:4.2177,lwr_k=30:4.7295,lwr_k=40:5.1561,lwr_k=50:5.3612,lwr_k=100:5.7165,lwr_k=200:5.9667,lwr_k=300:6.0913,lwr_k=400:6.1518,lwr_k=500:6.209,lwr_k=600:6.2301,lwr_k=700:6.2526,lwr_k=800:6.2705,lwr_k=900:6.3036,lwr_k=1000:6.3122'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.9385,lwr_k=10:37.6037,lwr_k=20:13.5595,lwr_k=30:10.9532,lwr_k=40:10.4,lwr_k=50:10.1055,lwr_k=100:9.2587,lwr_k=200:9.3136,lwr_k=300:9.3274,lwr_k=400:9.3754,lwr_k=500:9.4433,lwr_k=600:9.4544,lwr_k=700:9.5054,lwr_k=800:9.4802,lwr_k=900:9.5082,lwr_k=1000:9.539'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:18.2269,lwr_k=10:3.2466,lwr_k=20:6.9978,lwr_k=30:8.46,lwr_k=40:9.7282,lwr_k=50:10.4656,lwr_k=100:12.0523,lwr_k=200:13.2819,lwr_k=300:13.7473,lwr_k=400:14.1079,lwr_k=500:14.3827,lwr_k=600:14.599,lwr_k=700:14.7653,lwr_k=800:14.9278,lwr_k=900:15.151,lwr_k=1000:15.3155'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:13.92,lwr_k=10:49.4426,lwr_k=20:19.9101,lwr_k=30:14.0592,lwr_k=40:12.8795,lwr_k=50:12.7095,lwr_k=100:11.057,lwr_k=200:10.5049,lwr_k=300:10.6852,lwr_k=400:10.9202,lwr_k=500:11.0385,lwr_k=600:11.1754,lwr_k=700:11.2965,lwr_k=800:11.4045,lwr_k=900:11.5227,lwr_k=1000:11.5654'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:27.1373,lwr_k=10:3.9601,lwr_k=20:8.9393,lwr_k=30:10.9512,lwr_k=40:12.521,lwr_k=50:13.1967,lwr_k=100:15.5569,lwr_k=200:16.7945,lwr_k=300:17.478,lwr_k=400:17.9289,lwr_k=500:18.3619,lwr_k=600:18.7809,lwr_k=700:19.0731,lwr_k=800:19.3517,lwr_k=900:19.5862,lwr_k=1000:19.878'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:16.7326,lwr_k=10:56.9538,lwr_k=20:19.8846,lwr_k=30:16.2844,lwr_k=40:14.5572,lwr_k=50:13.8132,lwr_k=100:12.8428,lwr_k=200:12.5577,lwr_k=300:12.4703,lwr_k=400:12.5098,lwr_k=500:12.3076,lwr_k=600:12.2728,lwr_k=700:12.3059,lwr_k=800:12.2598,lwr_k=900:12.3199,lwr_k=1000:12.3443'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:17.9495,lwr_k=10:3.7135,lwr_k=20:8.1268,lwr_k=30:9.1802,lwr_k=40:10.2665,lwr_k=50:11.308,lwr_k=100:13.0351,lwr_k=200:13.8854,lwr_k=300:14.3391,lwr_k=400:14.5839,lwr_k=500:14.7013,lwr_k=600:14.9043,lwr_k=700:15.0592,lwr_k=800:15.2183,lwr_k=900:15.2957,lwr_k=1000:15.4291'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:15.1169,lwr_k=10:44.7215,lwr_k=20:16.569,lwr_k=30:14.69,lwr_k=40:14.4889,lwr_k=50:13.9575,lwr_k=100:13.0709,lwr_k=200:12.964,lwr_k=300:12.957,lwr_k=400:13.0199,lwr_k=500:13.1312,lwr_k=600:13.1742,lwr_k=700:13.2231,lwr_k=800:13.2141,lwr_k=900:13.2194,lwr_k=1000:13.2103'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.5109,lwr_k=10:2.2656,lwr_k=20:4.7194,lwr_k=30:5.3794,lwr_k=40:5.6851,lwr_k=50:5.9025,lwr_k=100:6.4164,lwr_k=200:6.5996,lwr_k=300:6.6512,lwr_k=400:6.6842,lwr_k=500:6.7323,lwr_k=600:6.7662,lwr_k=700:6.8271,lwr_k=800:6.8801,lwr_k=900:6.9113,lwr_k=1000:6.9465'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:27.1786,lwr_k=10:29.0832,lwr_k=20:17.3202,lwr_k=30:18.6464,lwr_k=40:22.1126,lwr_k=50:21.5545,lwr_k=100:21.9831,lwr_k=200:23.1612,lwr_k=300:23.4328,lwr_k=400:23.7153,lwr_k=500:23.915,lwr_k=600:24.1171,lwr_k=700:24.3775,lwr_k=800:24.6682,lwr_k=900:24.8934,lwr_k=1000:25.1345'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:19.0279,lwr_k=10:3.5292,lwr_k=20:7.55,lwr_k=30:8.7188,lwr_k=40:9.4703,lwr_k=50:10.1907,lwr_k=100:12.068,lwr_k=200:12.95,lwr_k=300:13.6082,lwr_k=400:14.0122,lwr_k=500:14.204,lwr_k=600:14.3776,lwr_k=700:14.528,lwr_k=800:14.7107,lwr_k=900:14.837,lwr_k=1000:14.9652'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:17.8449,lwr_k=10:50.0462,lwr_k=20:21.9465,lwr_k=30:17.2294,lwr_k=40:17.1536,lwr_k=50:16.1592,lwr_k=100:15.7584,lwr_k=200:15.6068,lwr_k=300:15.6566,lwr_k=400:15.6389,lwr_k=500:15.6226,lwr_k=600:15.5753,lwr_k=700:15.6255,lwr_k=800:15.5489,lwr_k=900:15.5614,lwr_k=1000:15.5159'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_61'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.3447,lwr_k=10:0.0,lwr_k=20:2.4033,lwr_k=30:3.7557,lwr_k=40:4.4172,lwr_k=50:4.8818,lwr_k=100:6.032,lwr_k=200:6.6566,lwr_k=300:7.0062,lwr_k=400:7.2125,lwr_k=500:7.4202,lwr_k=600:7.5332,lwr_k=700:7.6709,lwr_k=800:7.7848,lwr_k=900:7.8947,lwr_k=1000:7.9924'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:12.6648,lwr_k=10:304.7824,lwr_k=20:2736.3602,lwr_k=30:13.5682,lwr_k=40:30.7895,lwr_k=50:52.9183,lwr_k=100:9.2033,lwr_k=200:9.2607,lwr_k=300:9.6087,lwr_k=400:9.9422,lwr_k=500:10.1129,lwr_k=600:10.3346,lwr_k=700:10.5336,lwr_k=800:10.7483,lwr_k=900:10.8732,lwr_k=1000:11.045'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:15.6128,lwr_k=10:0.0319,lwr_k=20:2.7533,lwr_k=30:4.0653,lwr_k=40:5.3557,lwr_k=50:6.928,lwr_k=100:8.5443,lwr_k=200:9.8093,lwr_k=300:10.5736,lwr_k=400:10.865,lwr_k=500:11.2436,lwr_k=600:11.5275,lwr_k=700:11.6819,lwr_k=800:11.9094,lwr_k=900:12.1327,lwr_k=1000:12.3272'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:13.2888,lwr_k=10:722.7484,lwr_k=20:186.5875,lwr_k=30:82.3068,lwr_k=40:30.5366,lwr_k=50:30.048,lwr_k=100:9.4857,lwr_k=200:9.2886,lwr_k=300:9.1962,lwr_k=400:9.3121,lwr_k=500:9.3514,lwr_k=600:9.2887,lwr_k=700:9.4072,lwr_k=800:9.5345,lwr_k=900:9.5446,lwr_k=1000:9.5927'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:17.1914,lwr_k=10:0.0037,lwr_k=20:3.2988,lwr_k=30:5.5628,lwr_k=40:6.9523,lwr_k=50:7.9655,lwr_k=100:10.5401,lwr_k=200:11.6683,lwr_k=300:12.3792,lwr_k=400:12.7983,lwr_k=500:13.0304,lwr_k=600:13.2789,lwr_k=700:13.4126,lwr_k=800:13.6373,lwr_k=900:13.7883,lwr_k=1000:13.8845'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:11.2752,lwr_k=10:7788.9548,lwr_k=20:16.5561,lwr_k=30:11.5709,lwr_k=40:9.3204,lwr_k=50:8.9725,lwr_k=100:8.2621,lwr_k=200:8.0975,lwr_k=300:8.0843,lwr_k=400:8.3512,lwr_k=500:8.4621,lwr_k=600:8.5265,lwr_k=700:8.6535,lwr_k=800:8.7468,lwr_k=900:8.7687,lwr_k=1000:8.8555'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:14.4298,lwr_k=10:0.0271,lwr_k=20:3.343,lwr_k=30:5.2192,lwr_k=40:6.5565,lwr_k=50:6.9598,lwr_k=100:9.2581,lwr_k=200:10.8309,lwr_k=300:11.3866,lwr_k=400:11.7451,lwr_k=500:11.8978,lwr_k=600:12.0058,lwr_k=700:12.1914,lwr_k=800:12.3111,lwr_k=900:12.4414,lwr_k=1000:12.5663'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:11.4238,lwr_k=10:139097.2045,lwr_k=20:664.4668,lwr_k=30:917.3401,lwr_k=40:326.3804,lwr_k=50:357.1472,lwr_k=100:10.5961,lwr_k=200:10.0928,lwr_k=300:10.0782,lwr_k=400:10.0794,lwr_k=500:10.0113,lwr_k=600:10.0494,lwr_k=700:10.0287,lwr_k=800:10.1032,lwr_k=900:10.2124,lwr_k=1000:10.2564'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.3305,lwr_k=10:0.1134,lwr_k=20:3.0916,lwr_k=30:4.215,lwr_k=40:4.8473,lwr_k=50:5.3811,lwr_k=100:6.4717,lwr_k=200:7.2242,lwr_k=300:7.5434,lwr_k=400:7.6555,lwr_k=500:7.7917,lwr_k=600:7.8757,lwr_k=700:7.9251,lwr_k=800:8.0227,lwr_k=900:8.0657,lwr_k=1000:8.1143'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:26.236,lwr_k=10:21509.7849,lwr_k=20:621.9593,lwr_k=30:23.4479,lwr_k=40:20.8696,lwr_k=50:19.7347,lwr_k=100:21.6426,lwr_k=200:22.2418,lwr_k=300:23.0725,lwr_k=400:22.9636,lwr_k=500:23.07,lwr_k=600:23.7553,lwr_k=700:23.8768,lwr_k=800:23.9369,lwr_k=900:24.1541,lwr_k=1000:24.2681'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:13.3629,lwr_k=10:0.0658,lwr_k=20:2.9897,lwr_k=30:4.3331,lwr_k=40:5.0075,lwr_k=50:5.8931,lwr_k=100:8.4381,lwr_k=200:9.6139,lwr_k=300:9.9796,lwr_k=400:10.2041,lwr_k=500:10.2967,lwr_k=600:10.4252,lwr_k=700:10.4914,lwr_k=800:10.5927,lwr_k=900:10.7036,lwr_k=1000:10.7974'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:13.6912,lwr_k=10:20814.7623,lwr_k=20:16245.7088,lwr_k=30:813.7364,lwr_k=40:321.476,lwr_k=50:388.8076,lwr_k=100:48.8434,lwr_k=200:35.1386,lwr_k=300:21.5354,lwr_k=400:22.0974,lwr_k=500:15.7827,lwr_k=600:15.0612,lwr_k=700:14.6222,lwr_k=800:14.5852,lwr_k=900:14.8337,lwr_k=1000:14.6446'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_62'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:55.8132,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.475,lwr_k=40:4.2328,lwr_k=50:6.157,lwr_k=100:12.029,lwr_k=200:17.242,lwr_k=300:20.7447,lwr_k=400:23.6278,lwr_k=500:26.039,lwr_k=600:28.4459,lwr_k=700:30.0262,lwr_k=800:31.4211,lwr_k=900:32.5089,lwr_k=1000:33.5922'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:68.5185,lwr_k=10:64.2566,lwr_k=20:357.3893,lwr_k=30:155.1152,lwr_k=40:234.7606,lwr_k=50:225.7665,lwr_k=100:129.2766,lwr_k=200:47.5649,lwr_k=300:24.8004,lwr_k=400:27.1803,lwr_k=500:30.0556,lwr_k=600:33.0545,lwr_k=700:35.2767,lwr_k=800:36.5998,lwr_k=900:38.6499,lwr_k=1000:40.0063'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:67.7317,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.5871,lwr_k=40:4.7004,lwr_k=50:6.9542,lwr_k=100:12.6941,lwr_k=200:19.4802,lwr_k=300:24.4531,lwr_k=400:27.8736,lwr_k=500:31.1425,lwr_k=600:33.3299,lwr_k=700:35.611,lwr_k=800:37.3201,lwr_k=900:38.7259,lwr_k=1000:39.8161'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:56.9722,lwr_k=10:47.7936,lwr_k=20:383.6493,lwr_k=30:466.9932,lwr_k=40:229.3221,lwr_k=50:44.6086,lwr_k=100:26.4737,lwr_k=200:25.3667,lwr_k=300:27.4225,lwr_k=400:29.1767,lwr_k=500:32.1377,lwr_k=600:32.2799,lwr_k=700:33.3802,lwr_k=800:34.589,lwr_k=900:34.9713,lwr_k=1000:35.6744'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:71.5348,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.9361,lwr_k=40:5.3684,lwr_k=50:7.8385,lwr_k=100:13.2231,lwr_k=200:19.6474,lwr_k=300:23.88,lwr_k=400:26.706,lwr_k=500:29.4879,lwr_k=600:33.2182,lwr_k=700:35.6101,lwr_k=800:37.646,lwr_k=900:39.2181,lwr_k=1000:40.125'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:56.8513,lwr_k=10:55.3625,lwr_k=20:254.7833,lwr_k=30:842.2116,lwr_k=40:100.6742,lwr_k=50:34.7409,lwr_k=100:20.5619,lwr_k=200:22.513,lwr_k=300:26.2144,lwr_k=400:27.5713,lwr_k=500:28.033,lwr_k=600:29.3813,lwr_k=700:30.9256,lwr_k=800:32.0535,lwr_k=900:32.4421,lwr_k=1000:33.2871'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:70.4939,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.5948,lwr_k=40:5.0731,lwr_k=50:7.5127,lwr_k=100:13.8363,lwr_k=200:20.4255,lwr_k=300:24.7215,lwr_k=400:27.8885,lwr_k=500:31.4584,lwr_k=600:34.3298,lwr_k=700:36.1119,lwr_k=800:37.758,lwr_k=900:38.7723,lwr_k=1000:39.7956'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:62.6533,lwr_k=10:66.9438,lwr_k=20:184.4995,lwr_k=30:124.3411,lwr_k=40:39.3627,lwr_k=50:30.7446,lwr_k=100:23.2499,lwr_k=200:24.2174,lwr_k=300:24.7851,lwr_k=400:26.6722,lwr_k=500:28.4331,lwr_k=600:30.9831,lwr_k=700:32.6403,lwr_k=800:33.9741,lwr_k=900:35.3809,lwr_k=1000:36.2043'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:58.2975,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.533,lwr_k=40:4.6815,lwr_k=50:6.7335,lwr_k=100:12.094,lwr_k=200:17.4815,lwr_k=300:21.1856,lwr_k=400:23.6361,lwr_k=500:26.1248,lwr_k=600:28.3773,lwr_k=700:30.4031,lwr_k=800:31.6914,lwr_k=900:32.7811,lwr_k=1000:34.0482'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:94.4487,lwr_k=10:78.1198,lwr_k=20:321.3675,lwr_k=30:252.712,lwr_k=40:106.7395,lwr_k=50:70.053,lwr_k=100:43.6564,lwr_k=200:43.4659,lwr_k=300:46.3676,lwr_k=400:49.4111,lwr_k=500:51.1702,lwr_k=600:55.9601,lwr_k=700:58.6471,lwr_k=800:60.2675,lwr_k=900:61.4542,lwr_k=1000:62.3779'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:66.6308,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.5321,lwr_k=40:4.1477,lwr_k=50:6.4232,lwr_k=100:12.0507,lwr_k=200:18.1115,lwr_k=300:21.8196,lwr_k=400:24.9052,lwr_k=500:27.2167,lwr_k=600:28.9896,lwr_k=700:31.2174,lwr_k=800:33.4198,lwr_k=900:34.9526,lwr_k=1000:36.0719'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:68.4656,lwr_k=10:87.0291,lwr_k=20:204.5523,lwr_k=30:248.5149,lwr_k=40:104.4954,lwr_k=50:53.2295,lwr_k=100:38.3971,lwr_k=200:28.1101,lwr_k=300:28.9733,lwr_k=400:30.9321,lwr_k=500:31.6314,lwr_k=600:32.3843,lwr_k=700:33.3414,lwr_k=800:34.8592,lwr_k=900:35.8919,lwr_k=1000:36.9617'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_63'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:17.462,lwr_k=10:10.5626,lwr_k=20:10.7388,lwr_k=30:11.54,lwr_k=40:12.3762,lwr_k=50:12.7328,lwr_k=100:13.6449,lwr_k=200:14.1704,lwr_k=300:14.4204,lwr_k=400:14.677,lwr_k=500:14.8879,lwr_k=600:15.0837,lwr_k=700:15.3865,lwr_k=800:15.6385,lwr_k=900:15.8732,lwr_k=1000:16.0244'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:24.872,lwr_k=10:451018305.8361,lwr_k=20:1395.8831,lwr_k=30:1622.6055,lwr_k=40:38.4289,lwr_k=50:23.8822,lwr_k=100:5184698.8386,lwr_k=200:21.027,lwr_k=300:21.7937,lwr_k=400:22.2821,lwr_k=500:22.9097,lwr_k=600:23.5247,lwr_k=700:23.976,lwr_k=800:24.275,lwr_k=900:24.5646,lwr_k=1000:25.0822'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:181.7912,lwr_k=10:71.4055,lwr_k=20:72.4942,lwr_k=30:78.1636,lwr_k=40:83.2094,lwr_k=50:87.0215,lwr_k=100:96.9596,lwr_k=200:110.5066,lwr_k=300:115.1598,lwr_k=400:119.9525,lwr_k=500:122.7861,lwr_k=600:125.7385,lwr_k=700:127.7511,lwr_k=800:129.8844,lwr_k=900:131.6645,lwr_k=1000:133.2037'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:156.3493,lwr_k=10:6427473.0236,lwr_k=20:443914.0117,lwr_k=30:100.7625,lwr_k=40:101.1295,lwr_k=50:95.7453,lwr_k=100:100.0582,lwr_k=200:102.1727,lwr_k=300:105.36,lwr_k=400:108.1623,lwr_k=500:110.9294,lwr_k=600:112.3618,lwr_k=700:113.9293,lwr_k=800:116.2009,lwr_k=900:117.6252,lwr_k=1000:118.5452'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:42.6332,lwr_k=10:36.6863,lwr_k=20:25.8578,lwr_k=30:27.4278,lwr_k=40:26.3769,lwr_k=50:26.495,lwr_k=100:28.2406,lwr_k=200:29.6399,lwr_k=300:30.6136,lwr_k=400:31.369,lwr_k=500:31.8971,lwr_k=600:32.2359,lwr_k=700:33.4426,lwr_k=800:33.9113,lwr_k=900:34.4449,lwr_k=1000:35.2267'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:34.671,lwr_k=10:83840776.972,lwr_k=20:4849643.4962,lwr_k=30:3531041.5124,lwr_k=40:27.8788,lwr_k=50:26.1914,lwr_k=100:26.2066,lwr_k=200:25.439,lwr_k=300:25.5596,lwr_k=400:25.846,lwr_k=500:26.2162,lwr_k=600:27.567,lwr_k=700:28.272,lwr_k=800:26.6911,lwr_k=900:26.8957,lwr_k=1000:26.9715'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:21.7268,lwr_k=10:10.8258,lwr_k=20:12.2773,lwr_k=30:12.484,lwr_k=40:13.1867,lwr_k=50:13.6855,lwr_k=100:14.8091,lwr_k=200:15.9705,lwr_k=300:16.5756,lwr_k=400:17.56,lwr_k=500:17.3567,lwr_k=600:18.4757,lwr_k=700:18.0252,lwr_k=800:18.0235,lwr_k=900:18.3291,lwr_k=1000:22.8577'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:17.0163,lwr_k=10:224095048.3279,lwr_k=20:701959.8985,lwr_k=30:209760.4469,lwr_k=40:14980.1435,lwr_k=50:360.4339,lwr_k=100:14.4234,lwr_k=200:13.5477,lwr_k=300:13.6185,lwr_k=400:13.727,lwr_k=500:13.9231,lwr_k=600:13.9978,lwr_k=700:13.9099,lwr_k=800:14.0594,lwr_k=900:14.066,lwr_k=1000:14.117'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:13.1154,lwr_k=10:5.8813,lwr_k=20:8.0155,lwr_k=30:8.9489,lwr_k=40:9.3435,lwr_k=50:9.7191,lwr_k=100:10.5154,lwr_k=200:11.0037,lwr_k=300:11.2092,lwr_k=400:11.332,lwr_k=500:11.4515,lwr_k=600:11.5682,lwr_k=700:11.6279,lwr_k=800:11.7085,lwr_k=900:11.7805,lwr_k=1000:11.8525'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:38.5897,lwr_k=10:5467240.0563,lwr_k=20:88.9174,lwr_k=30:26.4044,lwr_k=40:26.805,lwr_k=50:27.4417,lwr_k=100:28.7765,lwr_k=200:31.1601,lwr_k=300:32.9595,lwr_k=400:33.9459,lwr_k=500:34.8913,lwr_k=600:35.572,lwr_k=700:35.9402,lwr_k=800:36.2307,lwr_k=900:36.3799,lwr_k=1000:36.5494'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:61.2246,lwr_k=10:55.1272,lwr_k=20:184384604677132.47,lwr_k=30:60.0843,lwr_k=40:59.222,lwr_k=50:57.8615,lwr_k=100:55.339,lwr_k=200:57.3826,lwr_k=300:57.8034,lwr_k=400:58.0655,lwr_k=500:58.157,lwr_k=600:58.3071,lwr_k=700:58.4456,lwr_k=800:58.5828,lwr_k=900:58.6792,lwr_k=1000:58.7655'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:55.5407,lwr_k=10:14244042.1959,lwr_k=20:250609199785530.88,lwr_k=30:59.0406,lwr_k=40:58.04,lwr_k=50:56.3487,lwr_k=100:51.4033,lwr_k=200:52.2113,lwr_k=300:52.5137,lwr_k=400:52.7579,lwr_k=500:52.7146,lwr_k=600:52.9222,lwr_k=700:53.1332,lwr_k=800:53.3145,lwr_k=900:53.4285,lwr_k=1000:53.5556'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_64'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.4428,lwr_k=10:5.6052,lwr_k=20:6.1049,lwr_k=30:6.3465,lwr_k=40:6.4292,lwr_k=50:6.5027,lwr_k=100:6.6777,lwr_k=200:6.9139,lwr_k=300:6.9518,lwr_k=400:6.9728,lwr_k=500:7.004,lwr_k=600:7.027,lwr_k=700:7.0287,lwr_k=800:7.0421,lwr_k=900:7.0539,lwr_k=1000:7.0722'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.8128,lwr_k=10:13.5337,lwr_k=20:11.2243,lwr_k=30:11.9445,lwr_k=40:11.4988,lwr_k=50:11.6578,lwr_k=100:11.739,lwr_k=200:11.6256,lwr_k=300:11.4504,lwr_k=400:11.4009,lwr_k=500:11.4844,lwr_k=600:11.4424,lwr_k=700:11.4729,lwr_k=800:11.4926,lwr_k=900:11.4759,lwr_k=1000:11.4907'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.6933,lwr_k=10:6.4865,lwr_k=20:6.9688,lwr_k=30:7.1847,lwr_k=40:7.3869,lwr_k=50:7.5299,lwr_k=100:7.6189,lwr_k=200:7.7382,lwr_k=300:7.7627,lwr_k=400:7.8676,lwr_k=500:7.9027,lwr_k=600:7.9643,lwr_k=700:8.0117,lwr_k=800:8.0352,lwr_k=900:8.052,lwr_k=1000:8.0922'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.9848,lwr_k=10:9.9143,lwr_k=20:8.5785,lwr_k=30:8.3341,lwr_k=40:8.3875,lwr_k=50:8.3104,lwr_k=100:8.1907,lwr_k=200:8.231,lwr_k=300:8.2281,lwr_k=400:8.3727,lwr_k=500:8.3799,lwr_k=600:8.3989,lwr_k=700:8.4632,lwr_k=800:8.4894,lwr_k=900:8.4915,lwr_k=1000:8.5207'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:13.4443,lwr_k=10:7.7759,lwr_k=20:8.7182,lwr_k=30:9.2534,lwr_k=40:9.844,lwr_k=50:10.4919,lwr_k=100:11.7656,lwr_k=200:12.1884,lwr_k=300:12.3515,lwr_k=400:12.5935,lwr_k=500:12.6868,lwr_k=600:12.7242,lwr_k=700:12.7603,lwr_k=800:12.8188,lwr_k=900:12.8757,lwr_k=1000:12.9132'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:9.7222,lwr_k=10:12.8491,lwr_k=20:10.6474,lwr_k=30:9.9098,lwr_k=40:9.5017,lwr_k=50:9.021,lwr_k=100:8.681,lwr_k=200:9.1411,lwr_k=300:8.6982,lwr_k=400:8.7343,lwr_k=500:8.7916,lwr_k=600:8.8973,lwr_k=700:9.0834,lwr_k=800:9.189,lwr_k=900:9.2513,lwr_k=1000:9.285'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.9598,lwr_k=10:6.2841,lwr_k=20:7.2312,lwr_k=30:7.6042,lwr_k=40:7.8722,lwr_k=50:8.0906,lwr_k=100:8.7261,lwr_k=200:9.0704,lwr_k=300:9.3218,lwr_k=400:9.4311,lwr_k=500:9.4898,lwr_k=600:9.4878,lwr_k=700:9.5148,lwr_k=800:9.5394,lwr_k=900:9.5643,lwr_k=1000:9.5694'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:9.5061,lwr_k=10:12.8663,lwr_k=20:11.7442,lwr_k=30:11.8775,lwr_k=40:10.5613,lwr_k=50:9.9163,lwr_k=100:9.9183,lwr_k=200:9.8715,lwr_k=300:9.7758,lwr_k=400:9.678,lwr_k=500:9.6306,lwr_k=600:9.6162,lwr_k=700:9.6195,lwr_k=800:9.6214,lwr_k=900:9.6272,lwr_k=1000:9.6344'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.0827,lwr_k=10:4.5838,lwr_k=20:5.7118,lwr_k=30:6.0678,lwr_k=40:6.2963,lwr_k=50:6.4001,lwr_k=100:6.6482,lwr_k=200:6.7824,lwr_k=300:6.7931,lwr_k=400:6.8146,lwr_k=500:6.833,lwr_k=600:6.854,lwr_k=700:6.8747,lwr_k=800:6.8886,lwr_k=900:6.9038,lwr_k=1000:6.9138'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:21.5869,lwr_k=10:26.0171,lwr_k=20:19.2507,lwr_k=30:18.0676,lwr_k=40:19.6671,lwr_k=50:19.3085,lwr_k=100:20.7605,lwr_k=200:23.3124,lwr_k=300:21.1572,lwr_k=400:21.2487,lwr_k=500:21.2607,lwr_k=600:21.2748,lwr_k=700:21.2077,lwr_k=800:21.1918,lwr_k=900:21.1713,lwr_k=1000:21.1904'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:12.9561,lwr_k=10:8.6001,lwr_k=20:9.687,lwr_k=30:9.9278,lwr_k=40:10.1361,lwr_k=50:10.4492,lwr_k=100:11.3211,lwr_k=200:11.8732,lwr_k=300:12.0343,lwr_k=400:12.0379,lwr_k=500:12.1038,lwr_k=600:12.133,lwr_k=700:12.1608,lwr_k=800:12.2165,lwr_k=900:12.2315,lwr_k=1000:12.2479'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:12.6479,lwr_k=10:13.7017,lwr_k=20:12.7065,lwr_k=30:12.4771,lwr_k=40:12.5143,lwr_k=50:12.3808,lwr_k=100:12.275,lwr_k=200:12.2638,lwr_k=300:12.4844,lwr_k=400:12.4956,lwr_k=500:12.5031,lwr_k=600:12.4916,lwr_k=700:12.4665,lwr_k=800:12.4665,lwr_k=900:12.4623,lwr_k=1000:12.4407'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_65'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.5663,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0228,lwr_k=40:0.163,lwr_k=50:1.4112,lwr_k=100:3.6301,lwr_k=200:4.8796,lwr_k=300:5.3191,lwr_k=400:5.5049,lwr_k=500:5.6733,lwr_k=600:5.7342,lwr_k=700:5.8179,lwr_k=800:5.8668,lwr_k=900:5.91,lwr_k=1000:5.9679'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.7116,lwr_k=10:51.1806,lwr_k=20:85.7227,lwr_k=30:588.7117,lwr_k=40:38798.798,lwr_k=50:165.2959,lwr_k=100:10.9427,lwr_k=200:8.6713,lwr_k=300:8.3107,lwr_k=400:8.2186,lwr_k=500:8.0988,lwr_k=600:8.1129,lwr_k=700:8.0979,lwr_k=800:8.0629,lwr_k=900:8.0343,lwr_k=1000:7.9721'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.1917,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0081,lwr_k=40:0.2485,lwr_k=50:1.2518,lwr_k=100:3.1691,lwr_k=200:4.6152,lwr_k=300:5.0001,lwr_k=400:5.26,lwr_k=500:5.3469,lwr_k=600:5.4332,lwr_k=700:5.4713,lwr_k=800:5.5456,lwr_k=900:5.6007,lwr_k=1000:5.6512'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.7892,lwr_k=10:46.2546,lwr_k=20:118.9638,lwr_k=30:593.7541,lwr_k=40:4044.3835,lwr_k=50:4608.6563,lwr_k=100:12.6758,lwr_k=200:9.1517,lwr_k=300:8.3398,lwr_k=400:8.3323,lwr_k=500:8.0384,lwr_k=600:7.7895,lwr_k=700:7.5236,lwr_k=800:7.488,lwr_k=900:7.211,lwr_k=1000:7.1859'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.0709,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.027,lwr_k=40:0.1462,lwr_k=50:1.4462,lwr_k=100:3.6654,lwr_k=200:5.0774,lwr_k=300:5.454,lwr_k=400:5.8152,lwr_k=500:6.0094,lwr_k=600:6.1617,lwr_k=700:6.2921,lwr_k=800:6.4095,lwr_k=900:6.4873,lwr_k=1000:6.5844'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.439,lwr_k=10:24.2491,lwr_k=20:42.2355,lwr_k=30:148.9525,lwr_k=40:417.6092,lwr_k=50:193.3237,lwr_k=100:9.2699,lwr_k=200:6.319,lwr_k=300:5.9589,lwr_k=400:5.8912,lwr_k=500:5.8926,lwr_k=600:5.8119,lwr_k=700:5.7598,lwr_k=800:5.7795,lwr_k=900:5.7882,lwr_k=1000:5.7761'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.7936,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0041,lwr_k=40:0.0495,lwr_k=50:0.9899,lwr_k=100:3.4117,lwr_k=200:4.8788,lwr_k=300:5.4151,lwr_k=400:5.8691,lwr_k=500:6.0961,lwr_k=600:6.2795,lwr_k=700:6.4231,lwr_k=800:6.5151,lwr_k=900:6.5814,lwr_k=1000:6.734'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.7406,lwr_k=10:30.5611,lwr_k=20:58.1283,lwr_k=30:110.6636,lwr_k=40:2309.8985,lwr_k=50:428.4432,lwr_k=100:11.9361,lwr_k=200:10.2423,lwr_k=300:8.2972,lwr_k=400:8.3779,lwr_k=500:8.2822,lwr_k=600:8.2359,lwr_k=700:8.1791,lwr_k=800:8.2245,lwr_k=900:8.2345,lwr_k=1000:8.2333'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.8462,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.026,lwr_k=50:0.6701,lwr_k=100:2.9746,lwr_k=200:4.1394,lwr_k=300:4.4982,lwr_k=400:4.6783,lwr_k=500:4.8224,lwr_k=600:4.9347,lwr_k=700:4.9894,lwr_k=800:5.0498,lwr_k=900:5.1007,lwr_k=1000:5.1544'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:21.4542,lwr_k=10:44.9788,lwr_k=20:47.4956,lwr_k=30:97.6213,lwr_k=40:254.3656,lwr_k=50:80.1703,lwr_k=100:15.9714,lwr_k=200:18.2129,lwr_k=300:17.7982,lwr_k=400:17.775,lwr_k=500:17.8148,lwr_k=600:18.1032,lwr_k=700:18.3079,lwr_k=800:18.4022,lwr_k=900:18.4161,lwr_k=1000:18.5668'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:7.7488,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0017,lwr_k=40:0.1148,lwr_k=50:0.7502,lwr_k=100:3.1122,lwr_k=200:4.4684,lwr_k=300:5.0649,lwr_k=400:5.3851,lwr_k=500:5.5186,lwr_k=600:5.69,lwr_k=700:5.7873,lwr_k=800:5.8597,lwr_k=900:5.9466,lwr_k=1000:5.9808'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.8912,lwr_k=10:29.3439,lwr_k=20:146.7336,lwr_k=30:4798.3833,lwr_k=40:13168.7095,lwr_k=50:533.2358,lwr_k=100:9.5801,lwr_k=200:7.2858,lwr_k=300:7.3427,lwr_k=400:7.2183,lwr_k=500:7.3245,lwr_k=600:7.3921,lwr_k=700:7.3695,lwr_k=800:7.4052,lwr_k=900:7.4528,lwr_k=1000:7.5062'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_66'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.8334,lwr_k=10:0.0,lwr_k=20:2.2671,lwr_k=30:3.1082,lwr_k=40:3.5493,lwr_k=50:3.8417,lwr_k=100:4.5388,lwr_k=200:4.83,lwr_k=300:5.0834,lwr_k=400:5.2623,lwr_k=500:5.4445,lwr_k=600:5.5586,lwr_k=700:5.6689,lwr_k=800:5.7473,lwr_k=900:5.8144,lwr_k=1000:5.8604'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.0505,lwr_k=10:1895.6677,lwr_k=20:12.4838,lwr_k=30:9.935,lwr_k=40:9.3536,lwr_k=50:8.6424,lwr_k=100:8.5034,lwr_k=200:8.7443,lwr_k=300:9.0457,lwr_k=400:9.2124,lwr_k=500:9.3725,lwr_k=600:9.505,lwr_k=700:9.6197,lwr_k=800:9.6855,lwr_k=900:9.7535,lwr_k=1000:9.8352'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.7748,lwr_k=10:0.0006,lwr_k=20:2.5361,lwr_k=30:3.2178,lwr_k=40:3.5667,lwr_k=50:3.8287,lwr_k=100:4.6676,lwr_k=200:5.6954,lwr_k=300:6.1445,lwr_k=400:6.5559,lwr_k=500:6.6982,lwr_k=600:6.7533,lwr_k=700:6.8859,lwr_k=800:6.9875,lwr_k=900:7.0634,lwr_k=1000:7.1347'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.0077,lwr_k=10:8565.0731,lwr_k=20:10.6004,lwr_k=30:7.1622,lwr_k=40:6.1894,lwr_k=50:5.8554,lwr_k=100:5.6299,lwr_k=200:5.6916,lwr_k=300:5.7227,lwr_k=400:5.7441,lwr_k=500:5.8223,lwr_k=600:5.8751,lwr_k=700:5.9038,lwr_k=800:5.9366,lwr_k=900:5.9688,lwr_k=1000:6.0267'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.6335,lwr_k=10:0.0,lwr_k=20:2.7571,lwr_k=30:3.6897,lwr_k=40:4.1483,lwr_k=50:4.4243,lwr_k=100:5.0319,lwr_k=200:5.5678,lwr_k=300:5.8762,lwr_k=400:6.0968,lwr_k=500:6.2943,lwr_k=600:6.5417,lwr_k=700:6.7866,lwr_k=800:7.155,lwr_k=900:7.3867,lwr_k=1000:7.6294'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.9337,lwr_k=10:6447.0394,lwr_k=20:7.8719,lwr_k=30:6.8118,lwr_k=40:6.1759,lwr_k=50:5.7642,lwr_k=100:5.4751,lwr_k=200:5.5759,lwr_k=300:5.6437,lwr_k=400:5.629,lwr_k=500:5.645,lwr_k=600:5.6532,lwr_k=700:5.6688,lwr_k=800:5.6749,lwr_k=900:5.6825,lwr_k=1000:5.6935'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:11.4451,lwr_k=10:0.0001,lwr_k=20:2.648,lwr_k=30:3.6652,lwr_k=40:4.2105,lwr_k=50:4.8936,lwr_k=100:6.4236,lwr_k=200:7.4605,lwr_k=300:7.6622,lwr_k=400:7.9186,lwr_k=500:8.0484,lwr_k=600:8.168,lwr_k=700:8.3148,lwr_k=800:8.4685,lwr_k=900:8.5749,lwr_k=1000:8.6734'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.6962,lwr_k=10:12470.9711,lwr_k=20:9.7236,lwr_k=30:7.5243,lwr_k=40:6.8129,lwr_k=50:6.6848,lwr_k=100:6.8574,lwr_k=200:7.0199,lwr_k=300:6.9569,lwr_k=400:7.0248,lwr_k=500:7.1107,lwr_k=600:7.2016,lwr_k=700:7.1983,lwr_k=800:7.1709,lwr_k=900:7.2383,lwr_k=1000:7.285'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.2659,lwr_k=10:0.0,lwr_k=20:2.1049,lwr_k=30:2.6498,lwr_k=40:3.0548,lwr_k=50:3.2354,lwr_k=100:3.6069,lwr_k=200:3.8307,lwr_k=300:3.9268,lwr_k=400:3.9846,lwr_k=500:4.0119,lwr_k=600:4.0514,lwr_k=700:4.0679,lwr_k=800:4.0976,lwr_k=900:4.1101,lwr_k=1000:4.1196'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:16.627,lwr_k=10:4254.9818,lwr_k=20:15.237,lwr_k=30:14.7887,lwr_k=40:14.1556,lwr_k=50:11.4519,lwr_k=100:13.0527,lwr_k=200:14.9299,lwr_k=300:15.1929,lwr_k=400:15.5285,lwr_k=500:15.7847,lwr_k=600:15.8505,lwr_k=700:16.0114,lwr_k=800:16.1925,lwr_k=900:16.2927,lwr_k=1000:16.378'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:6.2916,lwr_k=10:0.0001,lwr_k=20:2.2258,lwr_k=30:2.9128,lwr_k=40:3.2405,lwr_k=50:3.4793,lwr_k=100:4.0501,lwr_k=200:4.8312,lwr_k=300:4.9624,lwr_k=400:5.0544,lwr_k=500:5.1167,lwr_k=600:5.1545,lwr_k=700:5.1821,lwr_k=800:5.2187,lwr_k=900:5.2553,lwr_k=1000:5.2958'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.7148,lwr_k=10:1062.3211,lwr_k=20:12.3896,lwr_k=30:7.492,lwr_k=40:6.4222,lwr_k=50:6.2162,lwr_k=100:6.0152,lwr_k=200:6.1913,lwr_k=300:6.3131,lwr_k=400:6.3889,lwr_k=500:6.4118,lwr_k=600:6.4481,lwr_k=700:6.4789,lwr_k=800:6.5278,lwr_k=900:6.5494,lwr_k=1000:6.5764'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_67'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.6795,lwr_k=10:0.0,lwr_k=20:2.9475,lwr_k=30:4.8876,lwr_k=40:5.7308,lwr_k=50:6.3524,lwr_k=100:7.5594,lwr_k=200:8.4998,lwr_k=300:8.8315,lwr_k=400:9.0326,lwr_k=500:9.1787,lwr_k=600:9.2655,lwr_k=700:9.3343,lwr_k=800:9.3981,lwr_k=900:9.4669,lwr_k=1000:9.5252'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:13.9081,lwr_k=10:145.9789,lwr_k=20:31.0456,lwr_k=30:18.0338,lwr_k=40:15.4724,lwr_k=50:14.1081,lwr_k=100:11.9769,lwr_k=200:11.6566,lwr_k=300:11.799,lwr_k=400:11.8223,lwr_k=500:11.917,lwr_k=600:12.0468,lwr_k=700:12.1338,lwr_k=800:12.2427,lwr_k=900:12.3196,lwr_k=1000:12.3655'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.3953,lwr_k=10:0.0,lwr_k=20:2.2394,lwr_k=30:4.2471,lwr_k=40:5.4969,lwr_k=50:6.176,lwr_k=100:8.0039,lwr_k=200:8.8106,lwr_k=300:9.203,lwr_k=400:9.3462,lwr_k=500:9.4658,lwr_k=600:9.5526,lwr_k=700:9.6104,lwr_k=800:9.7145,lwr_k=900:9.7594,lwr_k=1000:9.8098'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.5298,lwr_k=10:72.2448,lwr_k=20:29.0293,lwr_k=30:15.7317,lwr_k=40:11.6122,lwr_k=50:10.6784,lwr_k=100:8.8349,lwr_k=200:8.3344,lwr_k=300:8.2809,lwr_k=400:8.3634,lwr_k=500:8.2937,lwr_k=600:8.4,lwr_k=700:8.4698,lwr_k=800:8.4868,lwr_k=900:8.4589,lwr_k=1000:8.4717'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.0874,lwr_k=10:0.0,lwr_k=20:2.3503,lwr_k=30:3.8887,lwr_k=40:4.8567,lwr_k=50:5.4859,lwr_k=100:7.1921,lwr_k=200:8.3627,lwr_k=300:8.7838,lwr_k=400:9.0549,lwr_k=500:9.2297,lwr_k=600:9.377,lwr_k=700:9.4182,lwr_k=800:9.4445,lwr_k=900:9.496,lwr_k=1000:9.5206'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.5493,lwr_k=10:57.2569,lwr_k=20:19.394,lwr_k=30:10.7692,lwr_k=40:9.5826,lwr_k=50:8.3884,lwr_k=100:7.7613,lwr_k=200:7.4989,lwr_k=300:7.3856,lwr_k=400:7.3182,lwr_k=500:7.2761,lwr_k=600:7.2094,lwr_k=700:7.1711,lwr_k=800:7.1503,lwr_k=900:7.1368,lwr_k=1000:7.1333'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:19.1941,lwr_k=10:0.0,lwr_k=20:2.0906,lwr_k=30:5.1544,lwr_k=40:6.53,lwr_k=50:7.3119,lwr_k=100:10.7802,lwr_k=200:12.7481,lwr_k=300:13.818,lwr_k=400:14.4769,lwr_k=500:14.763,lwr_k=600:15.1344,lwr_k=700:15.4321,lwr_k=800:15.7726,lwr_k=900:15.9608,lwr_k=1000:16.0536'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:14.4476,lwr_k=10:73.1607,lwr_k=20:75.7187,lwr_k=30:25.9736,lwr_k=40:19.898,lwr_k=50:16.7707,lwr_k=100:14.0854,lwr_k=200:12.708,lwr_k=300:12.4075,lwr_k=400:12.468,lwr_k=500:12.3988,lwr_k=600:12.5839,lwr_k=700:12.5203,lwr_k=800:12.5945,lwr_k=900:12.7203,lwr_k=1000:12.6771'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.0148,lwr_k=10:0.0,lwr_k=20:1.0847,lwr_k=30:1.7955,lwr_k=40:2.0745,lwr_k=50:2.2513,lwr_k=100:2.5687,lwr_k=200:2.7269,lwr_k=300:2.7994,lwr_k=400:2.841,lwr_k=500:2.8501,lwr_k=600:2.8705,lwr_k=700:2.8717,lwr_k=800:2.8814,lwr_k=900:2.8935,lwr_k=1000:2.9039'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:16.6084,lwr_k=10:46.5964,lwr_k=20:33.5319,lwr_k=30:18.6113,lwr_k=40:17.7816,lwr_k=50:16.9616,lwr_k=100:16.314,lwr_k=200:16.1044,lwr_k=300:15.963,lwr_k=400:16.0022,lwr_k=500:15.9696,lwr_k=600:16.085,lwr_k=700:16.0736,lwr_k=800:16.0789,lwr_k=900:16.0829,lwr_k=1000:16.0707'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:3.3547,lwr_k=10:0.0,lwr_k=20:1.2094,lwr_k=30:2.0262,lwr_k=40:2.3437,lwr_k=50:2.5469,lwr_k=100:2.9178,lwr_k=200:3.0948,lwr_k=300:3.1691,lwr_k=400:3.206,lwr_k=500:3.2197,lwr_k=600:3.2396,lwr_k=700:3.2576,lwr_k=800:3.2662,lwr_k=900:3.2817,lwr_k=1000:3.2884'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.8801,lwr_k=10:35.9774,lwr_k=20:17.7232,lwr_k=30:9.5829,lwr_k=40:9.0053,lwr_k=50:9.1899,lwr_k=100:8.8614,lwr_k=200:8.6399,lwr_k=300:8.6563,lwr_k=400:8.62,lwr_k=500:8.6593,lwr_k=600:8.6909,lwr_k=700:8.6785,lwr_k=800:8.6834,lwr_k=900:8.6851,lwr_k=1000:8.6915'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_68'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.1205,lwr_k=10:0.0004,lwr_k=20:0.4055,lwr_k=30:1.9729,lwr_k=40:3.3533,lwr_k=50:13.48,lwr_k=100:9.7981,lwr_k=200:11.5591,lwr_k=300:13.8817,lwr_k=400:13.2085,lwr_k=500:12.009,lwr_k=600:12.0521,lwr_k=700:12.2541,lwr_k=800:11.2629,lwr_k=900:10.7669,lwr_k=1000:11.6135'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:14.575,lwr_k=10:188.3788,lwr_k=20:9721.2115,lwr_k=30:4378.7218,lwr_k=40:756.4001,lwr_k=50:2886.5624,lwr_k=100:98.6395,lwr_k=200:19.9099,lwr_k=300:19.2996,lwr_k=400:20.3243,lwr_k=500:19.7529,lwr_k=600:17.9438,lwr_k=700:18.5202,lwr_k=800:17.2991,lwr_k=900:14.6768,lwr_k=1000:14.7094'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.9316,lwr_k=10:0.2319,lwr_k=20:21.4372,lwr_k=30:17.2247,lwr_k=40:11.7485,lwr_k=50:11.2623,lwr_k=100:8.2814,lwr_k=200:7.6043,lwr_k=300:7.6648,lwr_k=400:7.7733,lwr_k=500:7.9448,lwr_k=600:8.0391,lwr_k=700:8.2577,lwr_k=800:8.1791,lwr_k=900:8.1004,lwr_k=1000:8.2702'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.3351,lwr_k=10:641.4994,lwr_k=20:5927.8433,lwr_k=30:76.4697,lwr_k=40:66.1721,lwr_k=50:23.8416,lwr_k=100:11.7293,lwr_k=200:8.6544,lwr_k=300:7.9676,lwr_k=400:7.7234,lwr_k=500:7.7313,lwr_k=600:7.6337,lwr_k=700:7.7632,lwr_k=800:7.9603,lwr_k=900:7.8764,lwr_k=1000:8.0149'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.2038,lwr_k=10:0.0006,lwr_k=20:0.83,lwr_k=30:2.4366,lwr_k=40:3.2805,lwr_k=50:4.183,lwr_k=100:5.3117,lwr_k=200:6.0288,lwr_k=300:6.2544,lwr_k=400:6.4996,lwr_k=500:6.64,lwr_k=600:6.6929,lwr_k=700:6.7168,lwr_k=800:6.8244,lwr_k=900:6.9216,lwr_k=1000:6.9477'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.5816,lwr_k=10:619.6767,lwr_k=20:2868371.3801,lwr_k=30:34645960.9929,lwr_k=40:26304724.1276,lwr_k=50:3221679.1715,lwr_k=100:149432.2864,lwr_k=200:50705.9913,lwr_k=300:2812.1157,lwr_k=400:7.5886,lwr_k=500:7.2474,lwr_k=600:1026.9848,lwr_k=700:6.8918,lwr_k=800:6.9753,lwr_k=900:6.5755,lwr_k=1000:621.2964'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.0656,lwr_k=10:0.0004,lwr_k=20:0.9046,lwr_k=30:2.4106,lwr_k=40:3.4824,lwr_k=50:5.9469,lwr_k=100:7.3045,lwr_k=200:7.5378,lwr_k=300:8.2744,lwr_k=400:9.3545,lwr_k=500:8.1546,lwr_k=600:7.5968,lwr_k=700:7.6099,lwr_k=800:8.0523,lwr_k=900:8.1785,lwr_k=1000:8.5154'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:11.4676,lwr_k=10:637.4259,lwr_k=20:507.4852,lwr_k=30:2033.26,lwr_k=40:443.4281,lwr_k=50:204.6699,lwr_k=100:16.8847,lwr_k=200:13.3669,lwr_k=300:11.8953,lwr_k=400:13.21,lwr_k=500:12.8845,lwr_k=600:13.8976,lwr_k=700:13.9579,lwr_k=800:13.672,lwr_k=900:13.8972,lwr_k=1000:13.5326'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.701,lwr_k=10:0.0021,lwr_k=20:6.9034,lwr_k=30:11.8601,lwr_k=40:9.6299,lwr_k=50:11.562,lwr_k=100:8.7835,lwr_k=200:8.4789,lwr_k=300:7.6922,lwr_k=400:7.4218,lwr_k=500:7.8246,lwr_k=600:7.983,lwr_k=700:7.8791,lwr_k=800:7.6443,lwr_k=900:7.7836,lwr_k=1000:8.24'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:82.6346,lwr_k=10:398.3176,lwr_k=20:1501.5461,lwr_k=30:127139669.5673,lwr_k=40:7454334.326,lwr_k=50:17382667.0737,lwr_k=100:561263.0951,lwr_k=200:111.8012,lwr_k=300:611942.2692,lwr_k=400:96.2005,lwr_k=500:92.5825,lwr_k=600:67.058,lwr_k=700:76.1559,lwr_k=800:77.1025,lwr_k=900:89.8286,lwr_k=1000:91.2648'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:8.4078,lwr_k=10:0.1376,lwr_k=20:7.4671,lwr_k=30:6.8902,lwr_k=40:6.4647,lwr_k=50:8.0529,lwr_k=100:6.8061,lwr_k=200:7.7408,lwr_k=300:8.9938,lwr_k=400:9.1668,lwr_k=500:9.9883,lwr_k=600:9.6736,lwr_k=700:9.1008,lwr_k=800:9.0454,lwr_k=900:10.4085,lwr_k=1000:9.4865'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.3206,lwr_k=10:57935734.5636,lwr_k=20:90916.5323,lwr_k=30:366230.0566,lwr_k=40:476378.8997,lwr_k=50:3161.3867,lwr_k=100:12.901,lwr_k=200:11.3299,lwr_k=300:3674.9272,lwr_k=400:266.9183,lwr_k=500:12.0837,lwr_k=600:1286.5169,lwr_k=700:13.1476,lwr_k=800:11.9335,lwr_k=900:16.0738,lwr_k=1000:14.4542'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_69'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.7786,lwr_k=10:4.7449,lwr_k=20:5.6115,lwr_k=30:6.0672,lwr_k=40:6.2708,lwr_k=50:6.3991,lwr_k=100:6.6901,lwr_k=200:6.9652,lwr_k=300:7.0887,lwr_k=400:7.1133,lwr_k=500:7.1562,lwr_k=600:7.1637,lwr_k=700:7.1689,lwr_k=800:7.184,lwr_k=900:7.199,lwr_k=1000:7.2159'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.3719,lwr_k=10:13.5281,lwr_k=20:10.0726,lwr_k=30:9.4487,lwr_k=40:9.1788,lwr_k=50:9.1122,lwr_k=100:8.8844,lwr_k=200:9.1396,lwr_k=300:16.9164,lwr_k=400:9.4647,lwr_k=500:9.5219,lwr_k=600:9.4882,lwr_k=700:9.5217,lwr_k=800:9.5005,lwr_k=900:9.5346,lwr_k=1000:9.56'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:12.4753,lwr_k=10:7.487,lwr_k=20:8.6211,lwr_k=30:8.8853,lwr_k=40:9.2179,lwr_k=50:9.3466,lwr_k=100:9.9376,lwr_k=200:10.2523,lwr_k=300:10.7093,lwr_k=400:10.8222,lwr_k=500:10.9584,lwr_k=600:11.0593,lwr_k=700:11.1971,lwr_k=800:11.3571,lwr_k=900:11.4845,lwr_k=1000:11.5661'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.8511,lwr_k=10:18.6083,lwr_k=20:9.4803,lwr_k=30:8.6265,lwr_k=40:8.5357,lwr_k=50:8.1246,lwr_k=100:8.6381,lwr_k=200:8.3774,lwr_k=300:8.4068,lwr_k=400:8.5008,lwr_k=500:8.7126,lwr_k=600:8.8595,lwr_k=700:8.9866,lwr_k=800:9.2111,lwr_k=900:9.3664,lwr_k=1000:9.4763'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:9.8081,lwr_k=10:5.9818,lwr_k=20:6.6923,lwr_k=30:7.1406,lwr_k=40:7.5133,lwr_k=50:7.822,lwr_k=100:8.5571,lwr_k=200:9.0266,lwr_k=300:9.1674,lwr_k=400:9.2102,lwr_k=500:9.2729,lwr_k=600:9.2844,lwr_k=700:9.327,lwr_k=800:9.3819,lwr_k=900:9.3984,lwr_k=1000:9.4047'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.9264,lwr_k=10:10.0458,lwr_k=20:8.8029,lwr_k=30:7.9967,lwr_k=40:7.8778,lwr_k=50:7.8117,lwr_k=100:8.2433,lwr_k=200:8.0843,lwr_k=300:8.08,lwr_k=400:8.107,lwr_k=500:8.123,lwr_k=600:8.1249,lwr_k=700:8.1112,lwr_k=800:8.1328,lwr_k=900:8.1381,lwr_k=1000:8.1716'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.9617,lwr_k=10:6.939,lwr_k=20:7.6639,lwr_k=30:7.9128,lwr_k=40:8.3755,lwr_k=50:8.8518,lwr_k=100:9.5691,lwr_k=200:9.981,lwr_k=300:10.142,lwr_k=400:10.188,lwr_k=500:10.3052,lwr_k=600:10.3006,lwr_k=700:10.3785,lwr_k=800:10.4171,lwr_k=900:10.4499,lwr_k=1000:10.4818'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:11.0149,lwr_k=10:14.3845,lwr_k=20:11.5211,lwr_k=30:10.4941,lwr_k=40:10.3251,lwr_k=50:10.3367,lwr_k=100:10.8434,lwr_k=200:10.624,lwr_k=300:10.6024,lwr_k=400:10.7796,lwr_k=500:10.6673,lwr_k=600:10.7297,lwr_k=700:10.7986,lwr_k=800:10.8729,lwr_k=900:10.9638,lwr_k=1000:11.0328'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.1253,lwr_k=10:5.6803,lwr_k=20:6.5445,lwr_k=30:6.7539,lwr_k=40:6.8904,lwr_k=50:6.9583,lwr_k=100:7.0329,lwr_k=200:7.1912,lwr_k=300:7.2606,lwr_k=400:7.2707,lwr_k=500:7.293,lwr_k=600:7.3153,lwr_k=700:7.3387,lwr_k=800:7.3645,lwr_k=900:7.4298,lwr_k=1000:7.4912'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:23.5601,lwr_k=10:20.7513,lwr_k=20:32.5297,lwr_k=30:23.6913,lwr_k=40:23.5121,lwr_k=50:23.1843,lwr_k=100:23.4237,lwr_k=200:23.6835,lwr_k=300:23.1207,lwr_k=400:23.2012,lwr_k=500:23.1269,lwr_k=600:23.0092,lwr_k=700:22.9482,lwr_k=800:22.9623,lwr_k=900:23.0243,lwr_k=1000:23.1055'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:8.8285,lwr_k=10:5.958,lwr_k=20:6.5822,lwr_k=30:6.9129,lwr_k=40:7.105,lwr_k=50:7.2225,lwr_k=100:7.7137,lwr_k=200:7.9862,lwr_k=300:8.0494,lwr_k=400:8.0876,lwr_k=500:8.1453,lwr_k=600:8.1905,lwr_k=700:8.2432,lwr_k=800:8.2685,lwr_k=900:8.3206,lwr_k=1000:8.3595'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.6307,lwr_k=10:12.0266,lwr_k=20:11.2561,lwr_k=30:12.7347,lwr_k=40:12.5486,lwr_k=50:12.3226,lwr_k=100:10.724,lwr_k=200:10.799,lwr_k=300:11.0268,lwr_k=400:11.0243,lwr_k=500:11.146,lwr_k=600:11.2068,lwr_k=700:11.3144,lwr_k=800:11.3604,lwr_k=900:11.4896,lwr_k=1000:11.5132'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_70'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9867,lwr_k=10:4.769,lwr_k=20:5.277,lwr_k=30:5.4807,lwr_k=40:5.537,lwr_k=50:5.5426,lwr_k=100:5.5617,lwr_k=200:5.6168,lwr_k=300:5.6219,lwr_k=400:5.6401,lwr_k=500:5.6669,lwr_k=600:5.6677,lwr_k=700:5.644,lwr_k=800:5.6453,lwr_k=900:5.6478,lwr_k=1000:5.637'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.042,lwr_k=10:9.9965,lwr_k=20:9.8132,lwr_k=30:9.7108,lwr_k=40:9.5224,lwr_k=50:9.5061,lwr_k=100:9.4828,lwr_k=200:9.345,lwr_k=300:9.322,lwr_k=400:9.3851,lwr_k=500:9.3819,lwr_k=600:9.3866,lwr_k=700:9.3964,lwr_k=800:9.3757,lwr_k=900:9.3741,lwr_k=1000:9.3909'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:53.2901,lwr_k=10:9.275,lwr_k=20:9.8931,lwr_k=30:10.3874,lwr_k=40:10.6043,lwr_k=50:10.7809,lwr_k=100:35.6773,lwr_k=200:45.8017,lwr_k=300:46.4706,lwr_k=400:46.8295,lwr_k=500:47.1694,lwr_k=600:47.4899,lwr_k=700:47.7562,lwr_k=800:48.0006,lwr_k=900:48.1497,lwr_k=1000:48.2821'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:32.3185,lwr_k=10:11.7102,lwr_k=20:11.3429,lwr_k=30:10.883,lwr_k=40:10.7781,lwr_k=50:10.9514,lwr_k=100:24.8034,lwr_k=200:30.1083,lwr_k=300:30.382,lwr_k=400:30.4011,lwr_k=500:30.3744,lwr_k=600:30.3922,lwr_k=700:30.351,lwr_k=800:30.2317,lwr_k=900:30.1543,lwr_k=1000:30.0953'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:34.4008,lwr_k=10:18.3172,lwr_k=20:19.9346,lwr_k=30:20.3103,lwr_k=40:21.0421,lwr_k=50:21.4504,lwr_k=100:22.6702,lwr_k=200:23.0498,lwr_k=300:23.1145,lwr_k=400:23.1828,lwr_k=500:23.25,lwr_k=600:23.2967,lwr_k=700:23.348,lwr_k=800:23.4166,lwr_k=900:23.4647,lwr_k=1000:23.5238'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:28.0329,lwr_k=10:19.0308,lwr_k=20:18.8152,lwr_k=30:18.2269,lwr_k=40:17.8771,lwr_k=50:17.424,lwr_k=100:17.0502,lwr_k=200:16.8863,lwr_k=300:16.8696,lwr_k=400:16.919,lwr_k=500:16.9412,lwr_k=600:16.9863,lwr_k=700:17.0359,lwr_k=800:17.0517,lwr_k=900:17.0422,lwr_k=1000:17.0779'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.3006,lwr_k=10:5.6435,lwr_k=20:6.269,lwr_k=30:6.6384,lwr_k=40:6.9766,lwr_k=50:7.3944,lwr_k=100:8.1328,lwr_k=200:8.8149,lwr_k=300:9.2013,lwr_k=400:9.3747,lwr_k=500:9.475,lwr_k=600:9.5231,lwr_k=700:9.5934,lwr_k=800:9.6128,lwr_k=900:9.6577,lwr_k=1000:9.6782'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.9845,lwr_k=10:9.0799,lwr_k=20:8.6522,lwr_k=30:8.5555,lwr_k=40:8.7993,lwr_k=50:8.7941,lwr_k=100:8.6544,lwr_k=200:8.5622,lwr_k=300:8.5372,lwr_k=400:8.5426,lwr_k=500:8.554,lwr_k=600:8.5409,lwr_k=700:8.5374,lwr_k=800:8.5393,lwr_k=900:8.5498,lwr_k=1000:8.5723'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.0411,lwr_k=10:5.3449,lwr_k=20:5.7045,lwr_k=30:5.7703,lwr_k=40:5.8513,lwr_k=50:5.8742,lwr_k=100:5.9436,lwr_k=200:5.9735,lwr_k=300:5.9812,lwr_k=400:6.0113,lwr_k=500:6.0167,lwr_k=600:6.0295,lwr_k=700:6.028,lwr_k=800:6.0354,lwr_k=900:6.0412,lwr_k=1000:6.0451'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:23.9257,lwr_k=10:20.5292,lwr_k=20:20.0159,lwr_k=30:20.0912,lwr_k=40:21.1615,lwr_k=50:21.2311,lwr_k=100:22.3239,lwr_k=200:22.747,lwr_k=300:22.9152,lwr_k=400:22.9109,lwr_k=500:22.8649,lwr_k=600:22.8639,lwr_k=700:22.8244,lwr_k=800:22.7563,lwr_k=900:22.7383,lwr_k=1000:22.685'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:9.8892,lwr_k=10:6.6358,lwr_k=20:7.1138,lwr_k=30:7.2425,lwr_k=40:7.539,lwr_k=50:7.751,lwr_k=100:8.3495,lwr_k=200:8.6417,lwr_k=300:8.7728,lwr_k=400:8.9315,lwr_k=500:9.0356,lwr_k=600:9.0766,lwr_k=700:9.1075,lwr_k=800:9.1359,lwr_k=900:9.188,lwr_k=1000:9.2361'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.689,lwr_k=10:12.2433,lwr_k=20:11.815,lwr_k=30:11.6766,lwr_k=40:11.4547,lwr_k=50:11.8875,lwr_k=100:11.2438,lwr_k=200:11.4141,lwr_k=300:11.3856,lwr_k=400:11.4343,lwr_k=500:11.4446,lwr_k=600:11.4384,lwr_k=700:11.4313,lwr_k=800:11.4391,lwr_k=900:11.4492,lwr_k=1000:11.4416'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_71'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:43.6243,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.8032,lwr_k=100:5.2344,lwr_k=200:9.7458,lwr_k=300:12.2104,lwr_k=400:14.4533,lwr_k=500:16.3888,lwr_k=600:18.0447,lwr_k=700:19.5866,lwr_k=800:20.9003,lwr_k=900:22.1116,lwr_k=1000:23.2324'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:51.1579,lwr_k=10:30.9534,lwr_k=20:39.3896,lwr_k=30:45.876,lwr_k=40:96.8915,lwr_k=50:68.8478,lwr_k=100:21.925,lwr_k=200:17.9285,lwr_k=300:18.9903,lwr_k=400:21.5948,lwr_k=500:22.9126,lwr_k=600:24.7163,lwr_k=700:26.2591,lwr_k=800:27.6652,lwr_k=900:28.9481,lwr_k=1000:29.76'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:55.9441,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:1.0744,lwr_k=100:6.4246,lwr_k=200:11.251,lwr_k=300:14.7428,lwr_k=400:17.9247,lwr_k=500:20.5805,lwr_k=600:22.9471,lwr_k=700:24.8377,lwr_k=800:26.4105,lwr_k=900:27.9919,lwr_k=1000:29.1134'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:48.7986,lwr_k=10:29.744,lwr_k=20:36.2284,lwr_k=30:43.4886,lwr_k=40:132.8132,lwr_k=50:72.0056,lwr_k=100:19.4536,lwr_k=200:18.252,lwr_k=300:18.3682,lwr_k=400:18.5343,lwr_k=500:19.7058,lwr_k=600:21.3109,lwr_k=700:22.6224,lwr_k=800:23.9452,lwr_k=900:25.1571,lwr_k=1000:26.2004'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:59.3617,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:1.274,lwr_k=100:6.6904,lwr_k=200:11.8954,lwr_k=300:16.0711,lwr_k=400:18.7887,lwr_k=500:21.5372,lwr_k=600:24.056,lwr_k=700:26.2393,lwr_k=800:28.0741,lwr_k=900:29.8211,lwr_k=1000:31.2889'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:41.4482,lwr_k=10:27.4284,lwr_k=20:33.2713,lwr_k=30:49.2847,lwr_k=40:142.7135,lwr_k=50:79.6728,lwr_k=100:19.9131,lwr_k=200:15.3732,lwr_k=300:14.9202,lwr_k=400:16.186,lwr_k=500:17.1687,lwr_k=600:18.3898,lwr_k=700:18.9848,lwr_k=800:19.8395,lwr_k=900:20.4858,lwr_k=1000:21.0272'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:59.5846,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.9764,lwr_k=100:6.7383,lwr_k=200:11.886,lwr_k=300:15.1596,lwr_k=400:18.2821,lwr_k=500:21.0263,lwr_k=600:23.45,lwr_k=700:25.6398,lwr_k=800:27.7295,lwr_k=900:29.5886,lwr_k=1000:31.0211'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:49.8419,lwr_k=10:33.3401,lwr_k=20:37.039,lwr_k=30:71.8397,lwr_k=40:149.9437,lwr_k=50:74.4762,lwr_k=100:23.2517,lwr_k=200:17.5287,lwr_k=300:17.8746,lwr_k=400:19.4228,lwr_k=500:21.1603,lwr_k=600:22.4891,lwr_k=700:23.906,lwr_k=800:25.3397,lwr_k=900:26.7042,lwr_k=1000:27.7817'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:44.3642,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.9624,lwr_k=100:5.5544,lwr_k=200:9.891,lwr_k=300:12.0916,lwr_k=400:14.4629,lwr_k=500:16.4844,lwr_k=600:18.1118,lwr_k=700:19.5722,lwr_k=800:21.0955,lwr_k=900:22.3998,lwr_k=1000:23.434'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:88.4981,lwr_k=10:38.7022,lwr_k=20:45.3526,lwr_k=30:79.7967,lwr_k=40:149.3188,lwr_k=50:92.9251,lwr_k=100:34.5648,lwr_k=200:36.157,lwr_k=300:39.1557,lwr_k=400:44.0148,lwr_k=500:45.5537,lwr_k=600:48.788,lwr_k=700:51.1377,lwr_k=800:53.7802,lwr_k=900:55.5153,lwr_k=1000:57.1218'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:54.5937,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.9801,lwr_k=100:5.7035,lwr_k=200:10.2685,lwr_k=300:13.0036,lwr_k=400:15.1067,lwr_k=500:17.3455,lwr_k=600:19.4129,lwr_k=700:21.1755,lwr_k=800:22.6931,lwr_k=900:23.9635,lwr_k=1000:25.2895'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:51.8622,lwr_k=10:33.6453,lwr_k=20:37.6196,lwr_k=30:55.0974,lwr_k=40:110.93,lwr_k=50:81.4221,lwr_k=100:21.8828,lwr_k=200:19.3767,lwr_k=300:20.3306,lwr_k=400:21.9092,lwr_k=500:22.5378,lwr_k=600:24.4495,lwr_k=700:26.1259,lwr_k=800:26.5297,lwr_k=900:27.9152,lwr_k=1000:29.1087'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_72'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.126,lwr_k=10:5.757,lwr_k=20:6.1255,lwr_k=30:6.3556,lwr_k=40:6.4408,lwr_k=50:6.499,lwr_k=100:6.7972,lwr_k=200:7.1227,lwr_k=300:7.2544,lwr_k=400:7.3509,lwr_k=500:7.4442,lwr_k=600:7.5012,lwr_k=700:7.5686,lwr_k=800:7.6404,lwr_k=900:7.7078,lwr_k=1000:7.7633'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.4189,lwr_k=10:10.9838,lwr_k=20:9.6579,lwr_k=30:9.5451,lwr_k=40:10.134,lwr_k=50:10.0104,lwr_k=100:10.2059,lwr_k=200:10.4392,lwr_k=300:10.5446,lwr_k=400:10.5894,lwr_k=500:10.6949,lwr_k=600:10.7248,lwr_k=700:10.811,lwr_k=800:10.8664,lwr_k=900:10.9336,lwr_k=1000:10.9922'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:11.3076,lwr_k=10:9.6168,lwr_k=20:9.7067,lwr_k=30:9.5913,lwr_k=40:9.4312,lwr_k=50:9.4259,lwr_k=100:9.463,lwr_k=200:9.7197,lwr_k=300:9.8607,lwr_k=400:9.8877,lwr_k=500:9.9109,lwr_k=600:9.9639,lwr_k=700:10.032,lwr_k=800:10.0988,lwr_k=900:10.1503,lwr_k=1000:10.2176'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:13.1119,lwr_k=10:11.934,lwr_k=20:11.3264,lwr_k=30:11.0682,lwr_k=40:11.0105,lwr_k=50:10.901,lwr_k=100:10.8826,lwr_k=200:11.2848,lwr_k=300:11.4886,lwr_k=400:11.5455,lwr_k=500:11.4671,lwr_k=600:11.5674,lwr_k=700:11.6042,lwr_k=800:11.6679,lwr_k=900:11.7402,lwr_k=1000:11.831'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:17.6388,lwr_k=10:9.59,lwr_k=20:10.4628,lwr_k=30:10.5045,lwr_k=40:11.0023,lwr_k=50:11.366,lwr_k=100:12.3607,lwr_k=200:13.3049,lwr_k=300:14.242,lwr_k=400:14.8351,lwr_k=500:15.1269,lwr_k=600:15.249,lwr_k=700:15.348,lwr_k=800:15.4518,lwr_k=900:15.5342,lwr_k=1000:15.6166'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:11.9788,lwr_k=10:11.8748,lwr_k=20:11.1901,lwr_k=30:10.998,lwr_k=40:10.4615,lwr_k=50:10.085,lwr_k=100:9.6972,lwr_k=200:9.231,lwr_k=300:9.1583,lwr_k=400:9.191,lwr_k=500:9.2331,lwr_k=600:9.3044,lwr_k=700:9.319,lwr_k=800:9.4063,lwr_k=900:9.4592,lwr_k=1000:9.5404'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:12.6006,lwr_k=10:8.9944,lwr_k=20:9.0154,lwr_k=30:9.161,lwr_k=40:11.6943,lwr_k=50:9.7513,lwr_k=100:10.1696,lwr_k=200:10.7597,lwr_k=300:11.3038,lwr_k=400:11.5391,lwr_k=500:11.6128,lwr_k=600:11.6764,lwr_k=700:11.7041,lwr_k=800:11.7346,lwr_k=900:11.7635,lwr_k=1000:11.7887'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:12.0691,lwr_k=10:12.9446,lwr_k=20:11.8321,lwr_k=30:11.3575,lwr_k=40:11.2702,lwr_k=50:11.1131,lwr_k=100:11.0843,lwr_k=200:11.1574,lwr_k=300:11.1802,lwr_k=400:11.2206,lwr_k=500:11.2275,lwr_k=600:11.2363,lwr_k=700:11.2436,lwr_k=800:11.2126,lwr_k=900:11.1898,lwr_k=1000:11.2208'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.3447,lwr_k=10:6.5778,lwr_k=20:6.9483,lwr_k=30:7.1165,lwr_k=40:7.1985,lwr_k=50:7.2428,lwr_k=100:7.2985,lwr_k=200:7.3516,lwr_k=300:7.3782,lwr_k=400:7.3976,lwr_k=500:7.5524,lwr_k=600:7.6326,lwr_k=700:7.7,lwr_k=800:7.7346,lwr_k=900:7.7669,lwr_k=1000:7.8043'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:20.5945,lwr_k=10:16.6442,lwr_k=20:21.3101,lwr_k=30:17.8388,lwr_k=40:16.4494,lwr_k=50:16.6277,lwr_k=100:16.9673,lwr_k=200:17.7691,lwr_k=300:18.1737,lwr_k=400:18.448,lwr_k=500:18.9196,lwr_k=600:19.3512,lwr_k=700:19.7507,lwr_k=800:19.831,lwr_k=900:19.9426,lwr_k=1000:20.0667'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:12.216,lwr_k=10:7.932,lwr_k=20:8.2831,lwr_k=30:8.586,lwr_k=40:8.6922,lwr_k=50:8.693,lwr_k=100:9.0792,lwr_k=200:9.3994,lwr_k=300:9.7021,lwr_k=400:9.9126,lwr_k=500:10.132,lwr_k=600:10.3238,lwr_k=700:10.538,lwr_k=800:10.677,lwr_k=900:10.7486,lwr_k=1000:10.8209'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:14.3141,lwr_k=10:12.3086,lwr_k=20:12.2861,lwr_k=30:12.0496,lwr_k=40:11.5158,lwr_k=50:11.2992,lwr_k=100:11.4658,lwr_k=200:11.6856,lwr_k=300:11.9627,lwr_k=400:12.085,lwr_k=500:12.1152,lwr_k=600:12.207,lwr_k=700:12.3269,lwr_k=800:12.4484,lwr_k=900:12.5201,lwr_k=1000:12.5932'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_73'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.2878,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.2104,lwr_k=40:1.3138,lwr_k=50:2.075,lwr_k=100:4.0294,lwr_k=200:5.1298,lwr_k=300:5.5572,lwr_k=400:5.8251,lwr_k=500:6.0531,lwr_k=600:6.1852,lwr_k=700:6.3478,lwr_k=800:6.4722,lwr_k=900:6.5635,lwr_k=1000:6.6716'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.1618,lwr_k=10:28.4847,lwr_k=20:37.0691,lwr_k=30:1051.5475,lwr_k=40:71.7634,lwr_k=50:19.9055,lwr_k=100:15.5669,lwr_k=200:8.1196,lwr_k=300:8.3953,lwr_k=400:8.2893,lwr_k=500:8.4787,lwr_k=600:8.6356,lwr_k=700:8.8093,lwr_k=800:8.8846,lwr_k=900:9.0322,lwr_k=1000:9.1941'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:17.0455,lwr_k=10:0.0,lwr_k=20:0.082,lwr_k=30:1.0604,lwr_k=40:2.5064,lwr_k=50:3.7078,lwr_k=100:7.1208,lwr_k=200:9.4115,lwr_k=300:10.3767,lwr_k=400:10.9131,lwr_k=500:11.4147,lwr_k=600:11.7993,lwr_k=700:12.0695,lwr_k=800:12.2277,lwr_k=900:12.5078,lwr_k=1000:12.6944'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:14.4905,lwr_k=10:36.2107,lwr_k=20:143.3474,lwr_k=30:17248.3056,lwr_k=40:776.6888,lwr_k=50:529.6638,lwr_k=100:10.327,lwr_k=200:8.5943,lwr_k=300:8.9678,lwr_k=400:9.0487,lwr_k=500:9.2424,lwr_k=600:9.4883,lwr_k=700:9.7587,lwr_k=800:9.9011,lwr_k=900:10.1242,lwr_k=1000:10.2869'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.7343,lwr_k=10:0.0,lwr_k=20:0.0113,lwr_k=30:0.4491,lwr_k=40:1.3335,lwr_k=50:2.088,lwr_k=100:4.4821,lwr_k=200:6.7521,lwr_k=300:7.4474,lwr_k=400:7.8127,lwr_k=500:8.1303,lwr_k=600:8.3307,lwr_k=700:8.4387,lwr_k=800:8.5625,lwr_k=900:8.627,lwr_k=1000:8.7175'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.108,lwr_k=10:23.3846,lwr_k=20:234.9861,lwr_k=30:236.5376,lwr_k=40:36.279,lwr_k=50:64.0054,lwr_k=100:8.6488,lwr_k=200:6.259,lwr_k=300:5.9862,lwr_k=400:5.9723,lwr_k=500:6.0695,lwr_k=600:6.152,lwr_k=700:6.2911,lwr_k=800:6.2695,lwr_k=900:6.2872,lwr_k=1000:6.3924'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:28.7312,lwr_k=10:0.0023,lwr_k=20:0.1436,lwr_k=30:1.3919,lwr_k=40:2.382,lwr_k=50:3.9084,lwr_k=100:8.0977,lwr_k=200:11.654,lwr_k=300:13.2181,lwr_k=400:14.0996,lwr_k=500:15.1219,lwr_k=600:15.8234,lwr_k=700:16.4912,lwr_k=800:17.1781,lwr_k=900:17.6379,lwr_k=1000:18.119'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:22.5717,lwr_k=10:42.4531,lwr_k=20:156.8401,lwr_k=30:1077.1594,lwr_k=40:128547.828,lwr_k=50:3614477.8576,lwr_k=100:15.0575,lwr_k=200:13.3496,lwr_k=300:13.2663,lwr_k=400:13.106,lwr_k=500:13.2986,lwr_k=600:13.5844,lwr_k=700:13.9371,lwr_k=800:14.2991,lwr_k=900:14.498,lwr_k=1000:14.739'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:63.2255,lwr_k=10:0.0,lwr_k=20:0.0519,lwr_k=30:2.3281,lwr_k=40:2.5941,lwr_k=50:3.5769,lwr_k=100:9.0278,lwr_k=200:17.8737,lwr_k=300:21.7278,lwr_k=400:25.0968,lwr_k=500:27.3369,lwr_k=600:29.4925,lwr_k=700:31.4102,lwr_k=800:33.2931,lwr_k=900:35.0152,lwr_k=1000:36.3539'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:129.0229,lwr_k=10:71.4504,lwr_k=20:512.3208,lwr_k=30:447.4747,lwr_k=40:127.6613,lwr_k=50:23095369.9273,lwr_k=100:73.3004,lwr_k=200:70.5127,lwr_k=300:67.2538,lwr_k=400:73.447,lwr_k=500:74.5708,lwr_k=600:77.9536,lwr_k=700:81.265,lwr_k=800:84.6019,lwr_k=900:87.3684,lwr_k=1000:90.2031'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:12.7799,lwr_k=10:3.5859,lwr_k=20:5.9255,lwr_k=30:6.9706,lwr_k=40:7.7993,lwr_k=50:8.2908,lwr_k=100:8.883,lwr_k=200:10.0379,lwr_k=300:10.4663,lwr_k=400:11.0126,lwr_k=500:10.6911,lwr_k=600:10.8191,lwr_k=700:10.7905,lwr_k=800:10.868,lwr_k=900:10.8962,lwr_k=1000:10.9526'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:14.4883,lwr_k=10:216.7596,lwr_k=20:2484.8186,lwr_k=30:6966.4312,lwr_k=40:13246061.229,lwr_k=50:8537240.4198,lwr_k=100:14.236,lwr_k=200:13.164,lwr_k=300:13.0179,lwr_k=400:13.1037,lwr_k=500:13.3571,lwr_k=600:13.3242,lwr_k=700:13.3807,lwr_k=800:13.4768,lwr_k=900:13.4598,lwr_k=1000:13.5674'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_74'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.5272,lwr_k=10:0.0001,lwr_k=20:0.0122,lwr_k=30:0.2618,lwr_k=40:0.8862,lwr_k=50:1.3947,lwr_k=100:2.6218,lwr_k=200:3.3253,lwr_k=300:3.5963,lwr_k=400:3.7233,lwr_k=500:3.8062,lwr_k=600:3.9004,lwr_k=700:3.9448,lwr_k=800:3.9994,lwr_k=900:4.0442,lwr_k=1000:4.1007'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.9931,lwr_k=10:24.1717,lwr_k=20:3591.4,lwr_k=30:1043.0663,lwr_k=40:883.9464,lwr_k=50:37274.5219,lwr_k=100:8.7897,lwr_k=200:7.3315,lwr_k=300:6.9188,lwr_k=400:7.0241,lwr_k=500:7.0862,lwr_k=600:7.1495,lwr_k=700:7.1955,lwr_k=800:7.2634,lwr_k=900:7.3396,lwr_k=1000:7.3752'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:64.0668,lwr_k=10:0.0,lwr_k=20:0.0031,lwr_k=30:1.115,lwr_k=40:4.0257,lwr_k=50:7.0477,lwr_k=100:14.7088,lwr_k=200:20.6152,lwr_k=300:23.9742,lwr_k=400:26.9707,lwr_k=500:28.7348,lwr_k=600:30.6027,lwr_k=700:32.5202,lwr_k=800:33.4841,lwr_k=900:34.8166,lwr_k=1000:35.9254'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:51.4615,lwr_k=10:55.4126,lwr_k=20:174.1111,lwr_k=30:612.1585,lwr_k=40:4901.0715,lwr_k=50:146.8141,lwr_k=100:26.0101,lwr_k=200:24.5957,lwr_k=300:26.2579,lwr_k=400:27.0663,lwr_k=500:27.8271,lwr_k=600:27.8297,lwr_k=700:28.5652,lwr_k=800:29.487,lwr_k=900:30.2131,lwr_k=1000:30.5454'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.0999,lwr_k=10:0.0049,lwr_k=20:0.0339,lwr_k=30:0.2126,lwr_k=40:0.7066,lwr_k=50:1.2952,lwr_k=100:2.8914,lwr_k=200:4.085,lwr_k=300:4.5165,lwr_k=400:4.7817,lwr_k=500:4.9514,lwr_k=600:5.0265,lwr_k=700:5.1039,lwr_k=800:5.1994,lwr_k=900:5.2687,lwr_k=1000:5.3548'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.2246,lwr_k=10:16.092,lwr_k=20:142.8928,lwr_k=30:9602.0361,lwr_k=40:588524.0053,lwr_k=50:96755.9216,lwr_k=100:6.1543,lwr_k=200:5.2608,lwr_k=300:5.1238,lwr_k=400:5.304,lwr_k=500:5.3779,lwr_k=600:5.4611,lwr_k=700:5.4992,lwr_k=800:5.4796,lwr_k=900:5.5236,lwr_k=1000:5.5425'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.7976,lwr_k=10:0.0029,lwr_k=20:0.0071,lwr_k=30:0.0772,lwr_k=40:0.6374,lwr_k=50:1.2892,lwr_k=100:3.2446,lwr_k=200:4.5127,lwr_k=300:4.9308,lwr_k=400:5.2867,lwr_k=500:5.4192,lwr_k=600:5.5607,lwr_k=700:5.6922,lwr_k=800:5.7877,lwr_k=900:5.8694,lwr_k=1000:5.9283'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.407,lwr_k=10:20.9387,lwr_k=20:91.53,lwr_k=30:533.545,lwr_k=40:61451859.3729,lwr_k=50:15587207.707,lwr_k=100:8.5593,lwr_k=200:6.651,lwr_k=300:6.8858,lwr_k=400:7.4221,lwr_k=500:7.4932,lwr_k=600:7.5733,lwr_k=700:7.6348,lwr_k=800:7.7495,lwr_k=900:7.821,lwr_k=1000:7.8791'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.3872,lwr_k=10:0.0135,lwr_k=20:0.1055,lwr_k=30:0.4981,lwr_k=40:0.9237,lwr_k=50:1.2918,lwr_k=100:1.8755,lwr_k=200:2.9372,lwr_k=300:3.3434,lwr_k=400:3.5569,lwr_k=500:3.6954,lwr_k=600:3.804,lwr_k=700:3.8956,lwr_k=800:3.9545,lwr_k=900:4.0209,lwr_k=1000:4.0644'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:16.0309,lwr_k=10:33.8558,lwr_k=20:131.9237,lwr_k=30:1566.0514,lwr_k=40:123699408.5229,lwr_k=50:20051977.1829,lwr_k=100:42798823.4036,lwr_k=200:44.9318,lwr_k=300:15.0744,lwr_k=400:14.0506,lwr_k=500:14.4514,lwr_k=600:15.6191,lwr_k=700:15.7099,lwr_k=800:16.1609,lwr_k=900:16.0788,lwr_k=1000:16.3815'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:4.9511,lwr_k=10:0.0626,lwr_k=20:0.4217,lwr_k=30:0.9505,lwr_k=40:1.5628,lwr_k=50:2.0289,lwr_k=100:2.995,lwr_k=200:3.6723,lwr_k=300:3.9243,lwr_k=400:4.0361,lwr_k=500:4.1294,lwr_k=600:4.2242,lwr_k=700:4.2952,lwr_k=800:4.3655,lwr_k=900:4.4097,lwr_k=1000:4.4401'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.145,lwr_k=10:18562.7478,lwr_k=20:4724.4363,lwr_k=30:103.8584,lwr_k=40:145362760.3046,lwr_k=50:57129301.5748,lwr_k=100:1303862.4889,lwr_k=200:271565.8789,lwr_k=300:2051.7177,lwr_k=400:10.8685,lwr_k=500:8.105,lwr_k=600:8.0037,lwr_k=700:7.355,lwr_k=800:7.6535,lwr_k=900:8.6314,lwr_k=1000:8.8588'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_75'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:3.931,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.5408,lwr_k=40:1.2749,lwr_k=50:1.6932,lwr_k=100:2.5231,lwr_k=200:3.0314,lwr_k=300:3.2261,lwr_k=400:3.3471,lwr_k=500:3.4355,lwr_k=600:3.4699,lwr_k=700:3.5306,lwr_k=800:3.5591,lwr_k=900:3.5866,lwr_k=1000:3.6096'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.8685,lwr_k=10:21.1034,lwr_k=20:192.3509,lwr_k=30:127.4567,lwr_k=40:19.1883,lwr_k=50:13.4832,lwr_k=100:9.6648,lwr_k=200:8.0416,lwr_k=300:8.2594,lwr_k=400:8.309,lwr_k=500:8.4477,lwr_k=600:8.4485,lwr_k=700:8.5378,lwr_k=800:8.5807,lwr_k=900:8.5829,lwr_k=1000:8.6053'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:13.4967,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.9515,lwr_k=40:2.5162,lwr_k=50:3.8157,lwr_k=100:6.5229,lwr_k=200:8.4839,lwr_k=300:9.4901,lwr_k=400:9.9773,lwr_k=500:10.3433,lwr_k=600:10.5889,lwr_k=700:10.7496,lwr_k=800:10.9769,lwr_k=900:11.1695,lwr_k=1000:11.3191'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.8255,lwr_k=10:30.4584,lwr_k=20:536.1761,lwr_k=30:361.7727,lwr_k=40:24.3663,lwr_k=50:16.4409,lwr_k=100:10.6897,lwr_k=200:8.9423,lwr_k=300:8.8301,lwr_k=400:8.9057,lwr_k=500:9.0815,lwr_k=600:9.1891,lwr_k=700:9.3133,lwr_k=800:9.3308,lwr_k=900:9.3991,lwr_k=1000:9.6255'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:12.0378,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.1141,lwr_k=40:2.7745,lwr_k=50:3.9727,lwr_k=100:6.5472,lwr_k=200:8.1601,lwr_k=300:8.9138,lwr_k=400:9.3456,lwr_k=500:9.6136,lwr_k=600:9.9036,lwr_k=700:10.0892,lwr_k=800:10.2196,lwr_k=900:10.3055,lwr_k=1000:10.3876'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.7283,lwr_k=10:40.6535,lwr_k=20:467.0411,lwr_k=30:2763.3577,lwr_k=40:30.1375,lwr_k=50:14.953,lwr_k=100:10.4122,lwr_k=200:10.4332,lwr_k=300:9.6364,lwr_k=400:7.6769,lwr_k=500:7.6762,lwr_k=600:7.5915,lwr_k=700:7.5323,lwr_k=800:7.4757,lwr_k=900:7.4673,lwr_k=1000:7.4705'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:14.3779,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.0457,lwr_k=40:2.8548,lwr_k=50:4.0679,lwr_k=100:7.0618,lwr_k=200:8.7139,lwr_k=300:9.5342,lwr_k=400:9.9961,lwr_k=500:10.8965,lwr_k=600:11.1707,lwr_k=700:11.2759,lwr_k=800:11.4427,lwr_k=900:11.6021,lwr_k=1000:11.7136'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:14.0762,lwr_k=10:53.2976,lwr_k=20:278.317,lwr_k=30:171.1959,lwr_k=40:51.3755,lwr_k=50:27.5242,lwr_k=100:43.7729,lwr_k=200:13.7969,lwr_k=300:13.3069,lwr_k=400:11.8218,lwr_k=500:11.7138,lwr_k=600:11.4492,lwr_k=700:11.5297,lwr_k=800:11.5345,lwr_k=900:11.4847,lwr_k=1000:11.5708'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.7944,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.646,lwr_k=40:1.8022,lwr_k=50:2.4447,lwr_k=100:3.8286,lwr_k=200:4.489,lwr_k=300:4.7351,lwr_k=400:4.8577,lwr_k=500:4.9356,lwr_k=600:5.0055,lwr_k=700:5.0812,lwr_k=800:5.1243,lwr_k=900:5.1731,lwr_k=1000:5.2058'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:23.1408,lwr_k=10:48.9219,lwr_k=20:310.9607,lwr_k=30:64.7841,lwr_k=40:26.6053,lwr_k=50:18.2296,lwr_k=100:19.6103,lwr_k=200:20.6313,lwr_k=300:20.8328,lwr_k=400:20.6938,lwr_k=500:20.7451,lwr_k=600:21.0585,lwr_k=700:21.0764,lwr_k=800:21.1477,lwr_k=900:21.2175,lwr_k=1000:21.306'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:10.017,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.8595,lwr_k=40:2.3358,lwr_k=50:3.307,lwr_k=100:5.3316,lwr_k=200:6.9399,lwr_k=300:7.394,lwr_k=400:7.8041,lwr_k=500:8.0203,lwr_k=600:8.1748,lwr_k=700:8.3187,lwr_k=800:8.4304,lwr_k=900:8.5234,lwr_k=1000:8.6068'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:13.3543,lwr_k=10:84.192,lwr_k=20:193.9536,lwr_k=30:251.25,lwr_k=40:59.6602,lwr_k=50:46.7998,lwr_k=100:11.1965,lwr_k=200:10.6785,lwr_k=300:10.7037,lwr_k=400:11.0428,lwr_k=500:11.0379,lwr_k=600:11.1714,lwr_k=700:11.3568,lwr_k=800:11.5578,lwr_k=900:11.6579,lwr_k=1000:11.7964'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_76'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.8638,lwr_k=10:0.0,lwr_k=20:1.5402,lwr_k=30:2.906,lwr_k=40:3.6767,lwr_k=50:4.1264,lwr_k=100:4.9203,lwr_k=200:5.5278,lwr_k=300:5.7555,lwr_k=400:5.8557,lwr_k=500:5.969,lwr_k=600:6.0659,lwr_k=700:6.1332,lwr_k=800:6.1725,lwr_k=900:6.1998,lwr_k=1000:6.2334'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.515,lwr_k=10:97.2792,lwr_k=20:87.16,lwr_k=30:20.6092,lwr_k=40:15.3723,lwr_k=50:12.1125,lwr_k=100:10.4304,lwr_k=200:9.6166,lwr_k=300:9.6443,lwr_k=400:8.9107,lwr_k=500:9.0215,lwr_k=600:9.07,lwr_k=700:9.2123,lwr_k=800:9.3083,lwr_k=900:9.3395,lwr_k=1000:9.4008'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:11.6141,lwr_k=10:0.0,lwr_k=20:2.2386,lwr_k=30:4.0198,lwr_k=40:5.5398,lwr_k=50:6.1166,lwr_k=100:7.7299,lwr_k=200:8.8497,lwr_k=300:9.3959,lwr_k=400:9.6239,lwr_k=500:9.792,lwr_k=600:9.929,lwr_k=700:9.9998,lwr_k=800:10.0605,lwr_k=900:10.1181,lwr_k=1000:10.1938'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.6169,lwr_k=10:169.1508,lwr_k=20:149.9551,lwr_k=30:17.2004,lwr_k=40:12.9294,lwr_k=50:11.5312,lwr_k=100:8.6514,lwr_k=200:8.3276,lwr_k=300:19.3395,lwr_k=400:19.1176,lwr_k=500:26.021,lwr_k=600:22.4969,lwr_k=700:8.5431,lwr_k=800:8.6145,lwr_k=900:8.613,lwr_k=1000:8.6402'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.619,lwr_k=10:0.0,lwr_k=20:2.0328,lwr_k=30:3.6238,lwr_k=40:4.2105,lwr_k=50:4.7356,lwr_k=100:5.7919,lwr_k=200:6.4987,lwr_k=300:6.7149,lwr_k=400:6.877,lwr_k=500:6.9193,lwr_k=600:6.9503,lwr_k=700:7.0275,lwr_k=800:7.0493,lwr_k=900:7.094,lwr_k=1000:7.1045'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.8408,lwr_k=10:135.3307,lwr_k=20:219317.0982,lwr_k=30:5306.8569,lwr_k=40:13.8789,lwr_k=50:18.4602,lwr_k=100:8.0057,lwr_k=200:6.9969,lwr_k=300:6.9092,lwr_k=400:6.973,lwr_k=500:6.8607,lwr_k=600:6.6946,lwr_k=700:6.6613,lwr_k=800:6.6361,lwr_k=900:6.6563,lwr_k=1000:6.6457'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:26.4296,lwr_k=10:13.653,lwr_k=20:16.1118,lwr_k=30:17.015,lwr_k=40:18.0907,lwr_k=50:18.4258,lwr_k=100:19.7651,lwr_k=200:20.7241,lwr_k=300:21.4443,lwr_k=400:21.8285,lwr_k=500:22.1585,lwr_k=600:22.4162,lwr_k=700:22.6542,lwr_k=800:22.8319,lwr_k=900:22.9829,lwr_k=1000:23.2102'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:21.0667,lwr_k=10:315176.5328,lwr_k=20:387.9029,lwr_k=30:232870.5689,lwr_k=40:28.9578,lwr_k=50:32.062,lwr_k=100:23.7464,lwr_k=200:18.5142,lwr_k=300:17.618,lwr_k=400:17.8897,lwr_k=500:18.1949,lwr_k=600:18.1524,lwr_k=700:18.2583,lwr_k=800:18.4127,lwr_k=900:18.4144,lwr_k=1000:18.5155'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.5901,lwr_k=10:0.0,lwr_k=20:1.1709,lwr_k=30:2.4758,lwr_k=40:3.1779,lwr_k=50:3.4853,lwr_k=100:4.2499,lwr_k=200:4.6667,lwr_k=300:4.8091,lwr_k=400:4.9066,lwr_k=500:4.967,lwr_k=600:5.0238,lwr_k=700:5.0695,lwr_k=800:5.094,lwr_k=900:5.1215,lwr_k=1000:5.1647'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:23.2036,lwr_k=10:157.075,lwr_k=20:59.2609,lwr_k=30:24.5294,lwr_k=40:25.5687,lwr_k=50:23.5259,lwr_k=100:21.1836,lwr_k=200:21.3072,lwr_k=300:22.6826,lwr_k=400:21.4427,lwr_k=500:21.6019,lwr_k=600:21.8237,lwr_k=700:21.862,lwr_k=800:21.8683,lwr_k=900:21.9496,lwr_k=1000:21.9605'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:6.3741,lwr_k=10:0.0,lwr_k=20:1.4093,lwr_k=30:2.5001,lwr_k=40:2.9802,lwr_k=50:3.358,lwr_k=100:4.5103,lwr_k=200:5.0877,lwr_k=300:5.3416,lwr_k=400:5.4943,lwr_k=500:5.5708,lwr_k=600:5.6391,lwr_k=700:5.7221,lwr_k=800:5.7814,lwr_k=900:5.82,lwr_k=1000:5.8474'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.2903,lwr_k=10:113.7846,lwr_k=20:2668.6776,lwr_k=30:17.5675,lwr_k=40:534.8708,lwr_k=50:570.5221,lwr_k=100:10.0593,lwr_k=200:9.3548,lwr_k=300:9.4015,lwr_k=400:9.4801,lwr_k=500:9.6026,lwr_k=600:9.7302,lwr_k=700:9.894,lwr_k=800:10.0219,lwr_k=900:10.0704,lwr_k=1000:10.1124'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_77'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.6036,lwr_k=10:0.0,lwr_k=20:0.4548,lwr_k=30:1.7776,lwr_k=40:2.5494,lwr_k=50:2.9718,lwr_k=100:3.9386,lwr_k=200:4.52,lwr_k=300:4.6373,lwr_k=400:4.741,lwr_k=500:4.7986,lwr_k=600:4.859,lwr_k=700:4.9152,lwr_k=800:4.9578,lwr_k=900:4.9895,lwr_k=1000:5.0373'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.5109,lwr_k=10:768.1111,lwr_k=20:103.8653,lwr_k=30:22.7404,lwr_k=40:12.1846,lwr_k=50:9.6831,lwr_k=100:7.5072,lwr_k=200:7.1788,lwr_k=300:7.2303,lwr_k=400:7.3242,lwr_k=500:7.3276,lwr_k=600:7.3811,lwr_k=700:7.3727,lwr_k=800:7.4579,lwr_k=900:7.4993,lwr_k=1000:7.5772'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.285,lwr_k=10:0.0,lwr_k=20:0.2542,lwr_k=30:1.7224,lwr_k=40:2.6717,lwr_k=50:3.3377,lwr_k=100:4.4627,lwr_k=200:5.1823,lwr_k=300:5.3989,lwr_k=400:5.6048,lwr_k=500:5.6943,lwr_k=600:5.8088,lwr_k=700:5.9459,lwr_k=800:6.0018,lwr_k=900:6.0483,lwr_k=1000:6.161'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.7206,lwr_k=10:215.8651,lwr_k=20:4152.9891,lwr_k=30:55.8427,lwr_k=40:36.0531,lwr_k=50:24.7133,lwr_k=100:10.8969,lwr_k=200:7.6895,lwr_k=300:7.5025,lwr_k=400:7.496,lwr_k=500:7.3835,lwr_k=600:7.2989,lwr_k=700:7.3147,lwr_k=800:7.2196,lwr_k=900:7.0941,lwr_k=1000:7.0865'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.1445,lwr_k=10:0.0,lwr_k=20:0.7168,lwr_k=30:2.0875,lwr_k=40:2.8686,lwr_k=50:3.3596,lwr_k=100:4.6427,lwr_k=200:5.4331,lwr_k=300:5.7077,lwr_k=400:5.8519,lwr_k=500:6.0005,lwr_k=600:6.0574,lwr_k=700:6.0938,lwr_k=800:6.1633,lwr_k=900:6.2654,lwr_k=1000:6.3127'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.2607,lwr_k=10:226.7339,lwr_k=20:935.8034,lwr_k=30:31.3536,lwr_k=40:20.9948,lwr_k=50:13.5624,lwr_k=100:8.9235,lwr_k=200:7.0125,lwr_k=300:6.5163,lwr_k=400:5.8522,lwr_k=500:5.7902,lwr_k=600:5.8632,lwr_k=700:5.91,lwr_k=800:5.9749,lwr_k=900:5.9785,lwr_k=1000:6.0251'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.443,lwr_k=10:0.0,lwr_k=20:0.1621,lwr_k=30:1.8615,lwr_k=40:2.9926,lwr_k=50:3.6029,lwr_k=100:5.0855,lwr_k=200:5.9129,lwr_k=300:6.2099,lwr_k=400:6.3574,lwr_k=500:6.5264,lwr_k=600:6.624,lwr_k=700:6.688,lwr_k=800:6.7173,lwr_k=900:6.7558,lwr_k=1000:6.7928'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.9433,lwr_k=10:432.7714,lwr_k=20:679.8977,lwr_k=30:97.8714,lwr_k=40:26.377,lwr_k=50:31.1153,lwr_k=100:10.9058,lwr_k=200:9.0633,lwr_k=300:8.5378,lwr_k=400:8.4588,lwr_k=500:8.5493,lwr_k=600:8.5665,lwr_k=700:8.574,lwr_k=800:8.4803,lwr_k=900:8.5139,lwr_k=1000:8.484'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.8426,lwr_k=10:0.0,lwr_k=20:0.0377,lwr_k=30:1.6301,lwr_k=40:2.5775,lwr_k=50:3.1265,lwr_k=100:4.225,lwr_k=200:4.8001,lwr_k=300:4.987,lwr_k=400:5.1074,lwr_k=500:5.227,lwr_k=600:5.2953,lwr_k=700:5.343,lwr_k=800:5.3726,lwr_k=900:5.4225,lwr_k=1000:5.4262'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:15.7624,lwr_k=10:147.9695,lwr_k=20:644.4468,lwr_k=30:51.1888,lwr_k=40:25.1086,lwr_k=50:19.4718,lwr_k=100:14.8785,lwr_k=200:14.1862,lwr_k=300:14.0045,lwr_k=400:14.0796,lwr_k=500:14.0437,lwr_k=600:14.2149,lwr_k=700:14.3349,lwr_k=800:14.2963,lwr_k=900:14.4662,lwr_k=1000:14.4568'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:5.7294,lwr_k=10:0.0,lwr_k=20:0.4312,lwr_k=30:1.864,lwr_k=40:2.6015,lwr_k=50:3.0769,lwr_k=100:3.8634,lwr_k=200:4.4057,lwr_k=300:4.6306,lwr_k=400:4.7962,lwr_k=500:4.8502,lwr_k=600:4.8923,lwr_k=700:4.9674,lwr_k=800:4.9874,lwr_k=900:5.0223,lwr_k=1000:5.0434'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.6053,lwr_k=10:180.8268,lwr_k=20:320.0909,lwr_k=30:27.4799,lwr_k=40:12.6781,lwr_k=50:10.1728,lwr_k=100:7.317,lwr_k=200:6.9383,lwr_k=300:6.9738,lwr_k=400:7.0286,lwr_k=500:7.0535,lwr_k=600:7.0643,lwr_k=700:7.1575,lwr_k=800:7.3466,lwr_k=900:7.4173,lwr_k=1000:7.5008'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_78'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.0622,lwr_k=10:0.0,lwr_k=20:0.6982,lwr_k=30:1.7069,lwr_k=40:2.186,lwr_k=50:2.4606,lwr_k=100:3.0747,lwr_k=200:3.4452,lwr_k=300:3.6017,lwr_k=400:3.6709,lwr_k=500:3.738,lwr_k=600:3.7762,lwr_k=700:3.8308,lwr_k=800:3.8833,lwr_k=900:3.9357,lwr_k=1000:3.9738'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.5046,lwr_k=10:28.3909,lwr_k=20:33.1089,lwr_k=30:10.67,lwr_k=40:8.2728,lwr_k=50:7.4332,lwr_k=100:6.1611,lwr_k=200:6.4632,lwr_k=300:6.5795,lwr_k=400:6.6842,lwr_k=500:6.6851,lwr_k=600:6.7739,lwr_k=700:6.8579,lwr_k=800:6.9162,lwr_k=900:7.0096,lwr_k=1000:7.0899'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.7614,lwr_k=10:0.0,lwr_k=20:0.8759,lwr_k=30:2.3217,lwr_k=40:3.0374,lwr_k=50:3.5572,lwr_k=100:4.6651,lwr_k=200:5.5286,lwr_k=300:5.8921,lwr_k=400:6.1155,lwr_k=500:6.3455,lwr_k=600:6.5417,lwr_k=700:6.6946,lwr_k=800:6.8535,lwr_k=900:6.982,lwr_k=1000:7.1475'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.6778,lwr_k=10:47.7096,lwr_k=20:29.7949,lwr_k=30:9.5226,lwr_k=40:7.5511,lwr_k=50:7.1826,lwr_k=100:6.1873,lwr_k=200:6.2986,lwr_k=300:6.4499,lwr_k=400:6.4407,lwr_k=500:6.5133,lwr_k=600:6.5231,lwr_k=700:6.5383,lwr_k=800:6.6592,lwr_k=900:6.7,lwr_k=1000:6.7429'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:8.0835,lwr_k=10:0.0,lwr_k=20:1.0337,lwr_k=30:2.3491,lwr_k=40:3.1156,lwr_k=50:3.415,lwr_k=100:4.3783,lwr_k=200:5.5789,lwr_k=300:6.2246,lwr_k=400:6.3891,lwr_k=500:6.4621,lwr_k=600:6.5575,lwr_k=700:6.6148,lwr_k=800:6.6602,lwr_k=900:6.6987,lwr_k=1000:6.7515'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.2582,lwr_k=10:67.88,lwr_k=20:68.3279,lwr_k=30:9.6024,lwr_k=40:7.0414,lwr_k=50:6.1254,lwr_k=100:5.1763,lwr_k=200:5.0437,lwr_k=300:5.0249,lwr_k=400:5.0199,lwr_k=500:5.04,lwr_k=600:5.0115,lwr_k=700:5.0386,lwr_k=800:5.0822,lwr_k=900:5.0608,lwr_k=1000:5.0675'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.6875,lwr_k=10:0.0,lwr_k=20:0.9535,lwr_k=30:2.061,lwr_k=40:2.8816,lwr_k=50:3.2928,lwr_k=100:4.3169,lwr_k=200:5.0146,lwr_k=300:5.231,lwr_k=400:5.3503,lwr_k=500:5.4323,lwr_k=600:5.5014,lwr_k=700:5.571,lwr_k=800:5.6351,lwr_k=900:5.6621,lwr_k=1000:5.6867'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.1373,lwr_k=10:74.3212,lwr_k=20:46.6278,lwr_k=30:13.9266,lwr_k=40:8.2823,lwr_k=50:7.4675,lwr_k=100:6.2866,lwr_k=200:6.6082,lwr_k=300:6.6587,lwr_k=400:6.7012,lwr_k=500:6.6815,lwr_k=600:6.6626,lwr_k=700:6.6641,lwr_k=800:6.6672,lwr_k=900:6.6647,lwr_k=1000:6.6809'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.9643,lwr_k=10:0.0,lwr_k=20:1.1471,lwr_k=30:2.3688,lwr_k=40:2.9088,lwr_k=50:3.2386,lwr_k=100:3.997,lwr_k=200:4.4401,lwr_k=300:4.5624,lwr_k=400:4.6596,lwr_k=500:4.6761,lwr_k=600:4.7151,lwr_k=700:4.7505,lwr_k=800:4.7655,lwr_k=900:4.7822,lwr_k=1000:4.7948'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:17.4445,lwr_k=10:107.3375,lwr_k=20:120.4182,lwr_k=30:18.4092,lwr_k=40:14.8644,lwr_k=50:14.2534,lwr_k=100:15.626,lwr_k=200:17.2534,lwr_k=300:16.7658,lwr_k=400:16.7474,lwr_k=500:16.6537,lwr_k=600:16.7001,lwr_k=700:16.7775,lwr_k=800:16.9025,lwr_k=900:16.9418,lwr_k=1000:16.9929'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:6.7765,lwr_k=10:0.0,lwr_k=20:0.7414,lwr_k=30:1.8028,lwr_k=40:2.2793,lwr_k=50:2.5563,lwr_k=100:3.6908,lwr_k=200:4.3046,lwr_k=300:4.538,lwr_k=400:4.6495,lwr_k=500:4.7515,lwr_k=600:4.805,lwr_k=700:4.8477,lwr_k=800:4.897,lwr_k=900:4.9314,lwr_k=1000:4.9723'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:9.2039,lwr_k=10:22.6719,lwr_k=20:34.181,lwr_k=30:9.6104,lwr_k=40:9.6617,lwr_k=50:7.2831,lwr_k=100:6.6376,lwr_k=200:6.6867,lwr_k=300:7.1205,lwr_k=400:7.2691,lwr_k=500:7.4413,lwr_k=600:7.6171,lwr_k=700:7.7383,lwr_k=800:7.883,lwr_k=900:7.9561,lwr_k=1000:8.0286'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_79'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.9881,lwr_k=10:0.237,lwr_k=20:1.2128,lwr_k=30:2.2851,lwr_k=40:3.1214,lwr_k=50:3.7151,lwr_k=100:4.7382,lwr_k=200:5.2968,lwr_k=300:5.5035,lwr_k=400:5.6232,lwr_k=500:5.678,lwr_k=600:5.7242,lwr_k=700:5.7256,lwr_k=800:5.7591,lwr_k=900:5.778,lwr_k=1000:5.805'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.7189,lwr_k=10:2345.3802,lwr_k=20:1745.6262,lwr_k=30:31.0917,lwr_k=40:24.654,lwr_k=50:13.6726,lwr_k=100:19.9441,lwr_k=200:8.6277,lwr_k=300:9.1638,lwr_k=400:8.0743,lwr_k=500:8.1644,lwr_k=600:8.1675,lwr_k=700:7.9524,lwr_k=800:7.6379,lwr_k=900:7.7287,lwr_k=1000:7.7666'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.9716,lwr_k=10:0.0023,lwr_k=20:0.1008,lwr_k=30:1.1345,lwr_k=40:2.023,lwr_k=50:2.6405,lwr_k=100:4.6315,lwr_k=200:5.9866,lwr_k=300:6.3866,lwr_k=400:6.5597,lwr_k=500:6.7228,lwr_k=600:6.8586,lwr_k=700:6.9578,lwr_k=800:7.0283,lwr_k=900:7.0819,lwr_k=1000:7.1306'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.283,lwr_k=10:44.0516,lwr_k=20:179.0107,lwr_k=30:33.5097,lwr_k=40:15.7928,lwr_k=50:9.5897,lwr_k=100:6.8229,lwr_k=200:6.3799,lwr_k=300:6.3641,lwr_k=400:6.341,lwr_k=500:6.3811,lwr_k=600:6.4428,lwr_k=700:6.4672,lwr_k=800:6.5248,lwr_k=900:6.5778,lwr_k=1000:6.5874'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.1983,lwr_k=10:0.3442,lwr_k=20:1.2995,lwr_k=30:2.7052,lwr_k=40:3.5143,lwr_k=50:3.8891,lwr_k=100:5.0078,lwr_k=200:5.5923,lwr_k=300:5.6945,lwr_k=400:5.7722,lwr_k=500:5.8323,lwr_k=600:5.862,lwr_k=700:5.9196,lwr_k=800:5.9252,lwr_k=900:5.9539,lwr_k=1000:5.9552'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:5.9037,lwr_k=10:595883.6411,lwr_k=20:47.4581,lwr_k=30:164.0701,lwr_k=40:88.3649,lwr_k=50:12.0591,lwr_k=100:6.6801,lwr_k=200:5.8654,lwr_k=300:5.7348,lwr_k=400:5.7865,lwr_k=500:5.8391,lwr_k=600:6.1512,lwr_k=700:7.0197,lwr_k=800:5.8359,lwr_k=900:5.8758,lwr_k=1000:5.8728'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.3274,lwr_k=10:0.0142,lwr_k=20:0.1631,lwr_k=30:1.491,lwr_k=40:2.5597,lwr_k=50:3.266,lwr_k=100:4.387,lwr_k=200:5.1279,lwr_k=300:5.4757,lwr_k=400:5.7019,lwr_k=500:5.9183,lwr_k=600:6.0774,lwr_k=700:6.1757,lwr_k=800:6.2347,lwr_k=900:6.2667,lwr_k=1000:6.2895'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:8.3213,lwr_k=10:33.4146,lwr_k=20:6203.0582,lwr_k=30:75.9461,lwr_k=40:19.7376,lwr_k=50:12.7249,lwr_k=100:8.3911,lwr_k=200:8.0613,lwr_k=300:8.0901,lwr_k=400:8.0825,lwr_k=500:8.2106,lwr_k=600:8.1655,lwr_k=700:8.1996,lwr_k=800:8.1915,lwr_k=900:8.2267,lwr_k=1000:8.241'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.0472,lwr_k=10:0.0018,lwr_k=20:0.0573,lwr_k=30:1.1683,lwr_k=40:2.0904,lwr_k=50:2.4178,lwr_k=100:3.6492,lwr_k=200:4.1616,lwr_k=300:4.4188,lwr_k=400:4.5552,lwr_k=500:4.6267,lwr_k=600:4.69,lwr_k=700:4.73,lwr_k=800:4.7504,lwr_k=900:4.7843,lwr_k=1000:4.8074'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:19.9289,lwr_k=10:47.1802,lwr_k=20:1316.029,lwr_k=30:33.4637,lwr_k=40:22.7047,lwr_k=50:17.6139,lwr_k=100:18.3879,lwr_k=200:18.3509,lwr_k=300:18.6112,lwr_k=400:18.7105,lwr_k=500:18.8571,lwr_k=600:19.0388,lwr_k=700:19.1641,lwr_k=800:19.2352,lwr_k=900:19.3053,lwr_k=1000:19.3842'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:11.2021,lwr_k=10:0.0748,lwr_k=20:0.5232,lwr_k=30:2.3508,lwr_k=40:3.6228,lwr_k=50:4.5095,lwr_k=100:6.9002,lwr_k=200:8.2341,lwr_k=300:8.8476,lwr_k=400:9.1431,lwr_k=500:9.3194,lwr_k=600:9.4801,lwr_k=700:9.562,lwr_k=800:9.6952,lwr_k=900:9.7664,lwr_k=1000:9.8731'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:11.2454,lwr_k=10:89.3801,lwr_k=20:969.005,lwr_k=30:53.5519,lwr_k=40:23.6585,lwr_k=50:26.3305,lwr_k=100:11.9385,lwr_k=200:10.4695,lwr_k=300:10.5705,lwr_k=400:10.6956,lwr_k=500:10.4245,lwr_k=600:10.4325,lwr_k=700:10.4296,lwr_k=800:10.5452,lwr_k=900:10.619,lwr_k=1000:10.6715'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_80'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.4522,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.0227,lwr_k=100:1.5853,lwr_k=200:2.7643,lwr_k=300:3.2835,lwr_k=400:3.4776,lwr_k=500:3.6244,lwr_k=600:3.7729,lwr_k=700:3.8349,lwr_k=800:3.9024,lwr_k=900:3.9818,lwr_k=1000:4.0218'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.139,lwr_k=10:29.5769,lwr_k=20:72.1615,lwr_k=30:139.7145,lwr_k=40:6986.3375,lwr_k=50:47979.4366,lwr_k=100:119.9876,lwr_k=200:12.1909,lwr_k=300:11.6255,lwr_k=400:13.5893,lwr_k=500:7.5482,lwr_k=600:7.1673,lwr_k=700:7.2048,lwr_k=800:6.9861,lwr_k=900:6.7814,lwr_k=1000:6.8062'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.3607,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.0359,lwr_k=100:2.0397,lwr_k=200:3.6287,lwr_k=300:4.2145,lwr_k=400:4.5871,lwr_k=500:4.8047,lwr_k=600:5.0157,lwr_k=700:5.1709,lwr_k=800:5.2802,lwr_k=900:5.3831,lwr_k=1000:5.4734'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.3121,lwr_k=10:14.4766,lwr_k=20:25.407,lwr_k=30:32.1212,lwr_k=40:67.7198,lwr_k=50:1484.0297,lwr_k=100:9.5569,lwr_k=200:6.5042,lwr_k=300:6.3309,lwr_k=400:6.4455,lwr_k=500:6.3679,lwr_k=600:6.3456,lwr_k=700:6.328,lwr_k=800:6.3707,lwr_k=900:6.3496,lwr_k=1000:6.3509'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.1123,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0002,lwr_k=50:0.059,lwr_k=100:1.9957,lwr_k=200:3.1995,lwr_k=300:3.6884,lwr_k=400:3.9926,lwr_k=500:4.1692,lwr_k=600:4.3427,lwr_k=700:4.4475,lwr_k=800:4.6135,lwr_k=900:4.7453,lwr_k=1000:4.7932'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.3419,lwr_k=10:17.5124,lwr_k=20:58.8075,lwr_k=30:251.1558,lwr_k=40:791.2959,lwr_k=50:18925.0635,lwr_k=100:77.5068,lwr_k=200:10.8595,lwr_k=300:7.5787,lwr_k=400:7.5546,lwr_k=500:7.2945,lwr_k=600:7.2919,lwr_k=700:7.1338,lwr_k=800:7.0149,lwr_k=900:6.7223,lwr_k=1000:6.6558'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.7703,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.0123,lwr_k=100:2.2004,lwr_k=200:3.4375,lwr_k=300:3.9213,lwr_k=400:4.212,lwr_k=500:4.3942,lwr_k=600:4.5475,lwr_k=700:4.6522,lwr_k=800:4.7167,lwr_k=900:4.803,lwr_k=1000:4.8779'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:7.9878,lwr_k=10:16.6447,lwr_k=20:32.6984,lwr_k=30:68.4918,lwr_k=40:513.886,lwr_k=50:16679.3179,lwr_k=100:213.5631,lwr_k=200:12.0149,lwr_k=300:7.3959,lwr_k=400:7.1598,lwr_k=500:7.2192,lwr_k=600:7.0556,lwr_k=700:7.078,lwr_k=800:7.0979,lwr_k=900:7.0715,lwr_k=1000:7.1153'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.2169,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0001,lwr_k=50:0.0303,lwr_k=100:1.9605,lwr_k=200:2.8522,lwr_k=300:3.1674,lwr_k=400:3.3615,lwr_k=500:3.5187,lwr_k=600:3.621,lwr_k=700:3.7282,lwr_k=800:3.7782,lwr_k=900:3.8338,lwr_k=1000:3.8789'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:16.708,lwr_k=10:21.9232,lwr_k=20:36.7504,lwr_k=30:92.9396,lwr_k=40:77.8712,lwr_k=50:497.2479,lwr_k=100:17.3803,lwr_k=200:15.491,lwr_k=300:15.7611,lwr_k=400:16.0062,lwr_k=500:16.1115,lwr_k=600:16.1679,lwr_k=700:16.2222,lwr_k=800:16.369,lwr_k=900:16.4488,lwr_k=1000:16.5484'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:4.9236,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.0197,lwr_k=100:1.9684,lwr_k=200:3.0428,lwr_k=300:3.4303,lwr_k=400:3.6277,lwr_k=500:3.7221,lwr_k=600:3.8049,lwr_k=700:3.901,lwr_k=800:3.9569,lwr_k=900:3.9799,lwr_k=1000:4.018'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.9064,lwr_k=10:41.0835,lwr_k=20:49.8959,lwr_k=30:70.9982,lwr_k=40:1022.1007,lwr_k=50:49999.4893,lwr_k=100:322.2781,lwr_k=200:12.4844,lwr_k=300:7.1304,lwr_k=400:6.7704,lwr_k=500:6.4653,lwr_k=600:6.5547,lwr_k=700:7.3916,lwr_k=800:6.8539,lwr_k=900:7.154,lwr_k=1000:7.3296'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_81'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:11.7588,lwr_k=10:7.8068,lwr_k=20:8.5502,lwr_k=30:8.8583,lwr_k=40:8.8942,lwr_k=50:9.1134,lwr_k=100:9.3239,lwr_k=200:9.8781,lwr_k=300:10.1262,lwr_k=400:10.3731,lwr_k=500:10.3836,lwr_k=600:10.5514,lwr_k=700:10.8672,lwr_k=800:10.8357,lwr_k=900:11.1057,lwr_k=1000:10.9605'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:15.5728,lwr_k=10:15.4444,lwr_k=20:14.2486,lwr_k=30:14.1047,lwr_k=40:801049119.3053,lwr_k=50:235388.5849,lwr_k=100:14.1932,lwr_k=200:13.1557,lwr_k=300:13.9101,lwr_k=400:14.4222,lwr_k=500:14.0209,lwr_k=600:14.747,lwr_k=700:14.5555,lwr_k=800:14.639,lwr_k=900:14.7482,lwr_k=1000:14.9009'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:33.5813,lwr_k=10:23.4145,lwr_k=20:27.073,lwr_k=30:28.0481,lwr_k=40:28.9254,lwr_k=50:28.8919,lwr_k=100:29.5384,lwr_k=200:29.8811,lwr_k=300:30.2168,lwr_k=400:30.5959,lwr_k=500:30.7247,lwr_k=600:31.1235,lwr_k=700:31.2842,lwr_k=800:31.5794,lwr_k=900:31.6481,lwr_k=1000:31.7893'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:35.6229,lwr_k=10:37.4026,lwr_k=20:6658.1774,lwr_k=30:30.362,lwr_k=40:30.1689,lwr_k=50:29.2619,lwr_k=100:30.1979,lwr_k=200:30.4301,lwr_k=300:30.5901,lwr_k=400:30.4262,lwr_k=500:30.3953,lwr_k=600:30.4225,lwr_k=700:30.7264,lwr_k=800:31.0554,lwr_k=900:30.9746,lwr_k=1000:31.0548'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:18.3279,lwr_k=10:11.2496,lwr_k=20:12.5138,lwr_k=30:12.7685,lwr_k=40:13.3216,lwr_k=50:13.4166,lwr_k=100:14.259,lwr_k=200:15.2811,lwr_k=300:16.0138,lwr_k=400:15.8894,lwr_k=500:15.7617,lwr_k=600:15.7962,lwr_k=700:15.7905,lwr_k=800:16.0927,lwr_k=900:16.4196,lwr_k=1000:16.6691'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:12.6746,lwr_k=10:15.5805,lwr_k=20:13.5509,lwr_k=30:12.6379,lwr_k=40:11.8172,lwr_k=50:10.9475,lwr_k=100:10.6335,lwr_k=200:10.4427,lwr_k=300:10.4714,lwr_k=400:10.5247,lwr_k=500:10.5225,lwr_k=600:10.4947,lwr_k=700:10.5367,lwr_k=800:10.6118,lwr_k=900:10.6295,lwr_k=1000:10.7089'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:17.8228,lwr_k=10:10.0998,lwr_k=20:10.7032,lwr_k=30:11.1227,lwr_k=40:11.7723,lwr_k=50:12.0757,lwr_k=100:13.1387,lwr_k=200:14.4765,lwr_k=300:15.2934,lwr_k=400:15.6661,lwr_k=500:15.7416,lwr_k=600:16.3395,lwr_k=700:16.1246,lwr_k=800:17.3134,lwr_k=900:16.645,lwr_k=1000:16.4151'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:13.9851,lwr_k=10:12.6029,lwr_k=20:12.4184,lwr_k=30:12.6324,lwr_k=40:12.6413,lwr_k=50:12.5745,lwr_k=100:12.5629,lwr_k=200:12.3908,lwr_k=300:12.5024,lwr_k=400:12.5448,lwr_k=500:12.5864,lwr_k=600:12.6177,lwr_k=700:12.2533,lwr_k=800:12.7662,lwr_k=900:12.813,lwr_k=1000:13.1338'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:12.8541,lwr_k=10:8.4468,lwr_k=20:8.8868,lwr_k=30:8.9561,lwr_k=40:9.0717,lwr_k=50:9.1049,lwr_k=100:9.3012,lwr_k=200:9.5472,lwr_k=300:9.7988,lwr_k=400:9.9832,lwr_k=500:10.5,lwr_k=600:10.8703,lwr_k=700:10.9011,lwr_k=800:11.1326,lwr_k=900:11.1043,lwr_k=1000:11.2192'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:39.1286,lwr_k=10:69.4596,lwr_k=20:23.4073,lwr_k=30:21.7278,lwr_k=40:23.0773,lwr_k=50:22.8244,lwr_k=100:25.6442,lwr_k=200:28.1547,lwr_k=300:29.7506,lwr_k=400:29.1863,lwr_k=500:33.445,lwr_k=600:43.9174,lwr_k=700:35.4777,lwr_k=800:34.0922,lwr_k=900:36.5587,lwr_k=1000:33.6269'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:17.3385,lwr_k=10:12.9873,lwr_k=20:13.6187,lwr_k=30:13.691,lwr_k=40:13.8433,lwr_k=50:13.993,lwr_k=100:14.3177,lwr_k=200:14.5096,lwr_k=300:14.7913,lwr_k=400:15.0192,lwr_k=500:15.3322,lwr_k=600:15.4158,lwr_k=700:15.3848,lwr_k=800:15.3838,lwr_k=900:15.8882,lwr_k=1000:15.742'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:31.5523,lwr_k=10:30.6998,lwr_k=20:30.3466,lwr_k=30:30.0126,lwr_k=40:29.7174,lwr_k=50:28.917,lwr_k=100:32.0596,lwr_k=200:27.0486,lwr_k=300:26.8748,lwr_k=400:29.0254,lwr_k=500:31.1335,lwr_k=600:29.0819,lwr_k=700:33.3031,lwr_k=800:29.226,lwr_k=900:29.2264,lwr_k=1000:29.2841'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_82'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.0886,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.2924,lwr_k=40:1.0396,lwr_k=50:6.1218,lwr_k=100:4.9432,lwr_k=200:6.1098,lwr_k=300:5.3112,lwr_k=400:5.0126,lwr_k=500:4.9127,lwr_k=600:4.8443,lwr_k=700:5.0748,lwr_k=800:4.8656,lwr_k=900:4.7223,lwr_k=1000:4.7421'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.2926,lwr_k=10:82.2212,lwr_k=20:227.4327,lwr_k=30:2434.438,lwr_k=40:583.3172,lwr_k=50:72.0812,lwr_k=100:17.9103,lwr_k=200:14.8733,lwr_k=300:9.7752,lwr_k=400:10.0727,lwr_k=500:9.3799,lwr_k=600:9.2142,lwr_k=700:8.6787,lwr_k=800:8.8468,lwr_k=900:8.3322,lwr_k=1000:8.4497'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.9049,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:1.0122,lwr_k=40:2.0715,lwr_k=50:6.6198,lwr_k=100:5.6349,lwr_k=200:5.6867,lwr_k=300:6.0801,lwr_k=400:6.056,lwr_k=500:6.2813,lwr_k=600:6.2615,lwr_k=700:6.3316,lwr_k=800:6.3467,lwr_k=900:6.5385,lwr_k=1000:6.4993'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:6.9321,lwr_k=10:594.774,lwr_k=20:1346.0659,lwr_k=30:438.5445,lwr_k=40:147.3724,lwr_k=50:57.8409,lwr_k=100:24.3706,lwr_k=200:13.4152,lwr_k=300:18.4628,lwr_k=400:8.2623,lwr_k=500:8.5513,lwr_k=600:8.0217,lwr_k=700:7.9816,lwr_k=800:7.6971,lwr_k=900:7.2222,lwr_k=1000:6.8953'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.5924,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.1276,lwr_k=40:0.8946,lwr_k=50:6.3198,lwr_k=100:4.7688,lwr_k=200:4.5689,lwr_k=300:4.8685,lwr_k=400:5.0737,lwr_k=500:5.1837,lwr_k=600:5.276,lwr_k=700:5.3987,lwr_k=800:5.4809,lwr_k=900:5.5415,lwr_k=1000:5.5996'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.1826,lwr_k=10:44.8891,lwr_k=20:391.0891,lwr_k=30:2482.046,lwr_k=40:489.324,lwr_k=50:73.553,lwr_k=100:12.7388,lwr_k=200:8.2409,lwr_k=300:7.853,lwr_k=400:8.0865,lwr_k=500:6.6758,lwr_k=600:6.4264,lwr_k=700:6.4145,lwr_k=800:6.3184,lwr_k=900:6.1633,lwr_k=1000:5.9468'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:10.1504,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.2895,lwr_k=40:1.5701,lwr_k=50:26.3305,lwr_k=100:14.0586,lwr_k=200:7.7871,lwr_k=300:7.1681,lwr_k=400:9.6504,lwr_k=500:8.8644,lwr_k=600:8.8805,lwr_k=700:9.0862,lwr_k=800:8.2813,lwr_k=900:8.6936,lwr_k=1000:9.5722'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:12.3129,lwr_k=10:61.253,lwr_k=20:356.3827,lwr_k=30:2329.4822,lwr_k=40:1103.379,lwr_k=50:474.1874,lwr_k=100:29.367,lwr_k=200:22.0111,lwr_k=300:13.1058,lwr_k=400:14.9957,lwr_k=500:13.2055,lwr_k=600:14.096,lwr_k=700:12.4081,lwr_k=800:10.3436,lwr_k=900:10.9523,lwr_k=1000:14.8317'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.1304,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.1838,lwr_k=40:1.1946,lwr_k=50:4.1203,lwr_k=100:3.7115,lwr_k=200:4.1688,lwr_k=300:4.4261,lwr_k=400:4.5713,lwr_k=500:4.5894,lwr_k=600:4.6829,lwr_k=700:4.7584,lwr_k=800:4.7731,lwr_k=900:4.793,lwr_k=1000:4.8397'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:14.3792,lwr_k=10:59.8756,lwr_k=20:333.7585,lwr_k=30:1047.734,lwr_k=40:1132.6263,lwr_k=50:898.1035,lwr_k=100:20.2692,lwr_k=200:13.8679,lwr_k=300:13.0784,lwr_k=400:13.5027,lwr_k=500:13.4787,lwr_k=600:13.6636,lwr_k=700:13.4022,lwr_k=800:13.4285,lwr_k=900:13.5512,lwr_k=1000:13.7276'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:7.761,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.4973,lwr_k=40:1.5123,lwr_k=50:11.2438,lwr_k=100:7.7512,lwr_k=200:7.7622,lwr_k=300:10.2904,lwr_k=400:9.4776,lwr_k=500:11.0695,lwr_k=600:10.4747,lwr_k=700:11.9531,lwr_k=800:9.334,lwr_k=900:10.6962,lwr_k=1000:11.0412'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.7322,lwr_k=10:182.0244,lwr_k=20:663.6861,lwr_k=30:1690.8987,lwr_k=40:541.8667,lwr_k=50:696.5141,lwr_k=100:136.2785,lwr_k=200:51.5925,lwr_k=300:19.6451,lwr_k=400:14.646,lwr_k=500:14.2815,lwr_k=600:21.0895,lwr_k=700:14.7168,lwr_k=800:21.0974,lwr_k=900:15.3386,lwr_k=1000:17.4834'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_83'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:42.285,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.7399,lwr_k=100:5.2102,lwr_k=200:9.274,lwr_k=300:11.6953,lwr_k=400:13.5291,lwr_k=500:15.089,lwr_k=600:16.493,lwr_k=700:17.8171,lwr_k=800:18.8795,lwr_k=900:19.9606,lwr_k=1000:20.5967'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:55.8134,lwr_k=10:39.0301,lwr_k=20:45.7011,lwr_k=30:57.6858,lwr_k=40:145.5735,lwr_k=50:69.99,lwr_k=100:21.191,lwr_k=200:19.7461,lwr_k=300:21.2908,lwr_k=400:21.8832,lwr_k=500:22.9214,lwr_k=600:23.9345,lwr_k=700:25.5921,lwr_k=800:26.9639,lwr_k=900:27.8189,lwr_k=1000:29.2066'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:53.8876,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.833,lwr_k=100:5.7938,lwr_k=200:11.0584,lwr_k=300:15.1863,lwr_k=400:17.5935,lwr_k=500:20.3311,lwr_k=600:22.6991,lwr_k=700:24.3913,lwr_k=800:25.8568,lwr_k=900:27.3443,lwr_k=1000:28.6299'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:41.4162,lwr_k=10:30.8268,lwr_k=20:51.1727,lwr_k=30:81.2231,lwr_k=40:201.3918,lwr_k=50:96.6498,lwr_k=100:20.1592,lwr_k=200:15.1558,lwr_k=300:14.7816,lwr_k=400:15.8906,lwr_k=500:16.21,lwr_k=600:17.8617,lwr_k=700:19.466,lwr_k=800:20.5094,lwr_k=900:21.1627,lwr_k=1000:21.7877'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:58.9426,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.8912,lwr_k=100:6.0523,lwr_k=200:12.0259,lwr_k=300:16.0257,lwr_k=400:19.1655,lwr_k=500:22.2804,lwr_k=600:24.7719,lwr_k=700:26.6348,lwr_k=800:28.0474,lwr_k=900:29.4989,lwr_k=1000:30.8285'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:41.5059,lwr_k=10:40.6435,lwr_k=20:54.7856,lwr_k=30:83.7136,lwr_k=40:159.2583,lwr_k=50:78.4233,lwr_k=100:19.4745,lwr_k=200:15.4225,lwr_k=300:15.7421,lwr_k=400:17.0456,lwr_k=500:17.9838,lwr_k=600:19.6662,lwr_k=700:20.6199,lwr_k=800:21.5837,lwr_k=900:22.1082,lwr_k=1000:22.4182'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:54.4991,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.942,lwr_k=100:6.2972,lwr_k=200:11.6785,lwr_k=300:15.5709,lwr_k=400:18.7866,lwr_k=500:21.8187,lwr_k=600:23.9877,lwr_k=700:25.4572,lwr_k=800:27.39,lwr_k=900:28.5688,lwr_k=1000:29.8681'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:57.8256,lwr_k=10:36.1602,lwr_k=20:50.6748,lwr_k=30:73.6572,lwr_k=40:171.2483,lwr_k=50:72.1275,lwr_k=100:18.4717,lwr_k=200:18.8811,lwr_k=300:21.5993,lwr_k=400:22.9807,lwr_k=500:24.0809,lwr_k=600:25.5287,lwr_k=700:26.3994,lwr_k=800:27.216,lwr_k=900:28.0702,lwr_k=1000:29.1344'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:42.9996,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.8548,lwr_k=100:5.5794,lwr_k=200:10.0797,lwr_k=300:12.4826,lwr_k=400:14.3828,lwr_k=500:15.8308,lwr_k=600:17.2242,lwr_k=700:18.3219,lwr_k=800:19.5658,lwr_k=900:20.5982,lwr_k=1000:21.5499'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:78.3128,lwr_k=10:42.0927,lwr_k=20:82.3037,lwr_k=30:112.3047,lwr_k=40:267.4462,lwr_k=50:133.3164,lwr_k=100:39.3229,lwr_k=200:44.5026,lwr_k=300:52.5526,lwr_k=400:54.3316,lwr_k=500:54.1026,lwr_k=600:55.4001,lwr_k=700:56.1315,lwr_k=800:56.8012,lwr_k=900:57.1809,lwr_k=1000:58.0886'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:50.7877,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.8522,lwr_k=100:5.1918,lwr_k=200:9.8807,lwr_k=300:13.1928,lwr_k=400:15.7395,lwr_k=500:17.7676,lwr_k=600:19.7013,lwr_k=700:21.1973,lwr_k=800:22.6662,lwr_k=900:23.8752,lwr_k=1000:24.89'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:53.7221,lwr_k=10:40.5614,lwr_k=20:57.656,lwr_k=30:68.8548,lwr_k=40:243.8326,lwr_k=50:109.106,lwr_k=100:25.118,lwr_k=200:22.105,lwr_k=300:23.2359,lwr_k=400:22.628,lwr_k=500:22.4843,lwr_k=600:23.1388,lwr_k=700:23.5835,lwr_k=800:25.3768,lwr_k=900:25.7583,lwr_k=1000:26.5403'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_84'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.8382,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.01,lwr_k=40:0.1866,lwr_k=50:1.9912,lwr_k=100:2.4251,lwr_k=200:3.2799,lwr_k=300:3.4878,lwr_k=400:3.717,lwr_k=500:3.8661,lwr_k=600:4.0314,lwr_k=700:4.1213,lwr_k=800:4.1646,lwr_k=900:4.2104,lwr_k=1000:4.2735'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.5994,lwr_k=10:108.3513,lwr_k=20:95.4212,lwr_k=30:260.2159,lwr_k=40:167.5806,lwr_k=50:426.0672,lwr_k=100:11.849,lwr_k=200:7.9732,lwr_k=300:7.5468,lwr_k=400:7.7726,lwr_k=500:7.521,lwr_k=600:8.4107,lwr_k=700:8.4377,lwr_k=800:8.3794,lwr_k=900:8.3192,lwr_k=1000:8.1365'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.7105,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.1552,lwr_k=100:2.27,lwr_k=200:3.5764,lwr_k=300:4.3761,lwr_k=400:4.8932,lwr_k=500:5.2106,lwr_k=600:5.4331,lwr_k=700:5.5909,lwr_k=800:5.7057,lwr_k=900:5.7709,lwr_k=1000:5.8283'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:7.7389,lwr_k=10:18.0805,lwr_k=20:28.2989,lwr_k=30:51.9304,lwr_k=40:199.4799,lwr_k=50:7517.0828,lwr_k=100:10.0554,lwr_k=200:6.9693,lwr_k=300:6.9031,lwr_k=400:6.9949,lwr_k=500:6.9246,lwr_k=600:6.9957,lwr_k=700:6.9658,lwr_k=800:7.0177,lwr_k=900:7.0393,lwr_k=1000:6.9394'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:7.4919,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0029,lwr_k=50:0.3214,lwr_k=100:2.9186,lwr_k=200:4.1523,lwr_k=300:4.7479,lwr_k=400:5.1251,lwr_k=500:5.47,lwr_k=600:5.7232,lwr_k=700:5.9332,lwr_k=800:6.1187,lwr_k=900:6.2476,lwr_k=1000:6.3755'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.8801,lwr_k=10:40.715,lwr_k=20:66.1719,lwr_k=30:169.6757,lwr_k=40:952.1241,lwr_k=50:406.4306,lwr_k=100:10.854,lwr_k=200:7.6919,lwr_k=300:6.7763,lwr_k=400:6.6368,lwr_k=500:6.5236,lwr_k=600:6.4905,lwr_k=700:6.4379,lwr_k=800:6.4248,lwr_k=900:6.4061,lwr_k=1000:6.3898'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.8369,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.1468,lwr_k=100:2.208,lwr_k=200:3.3282,lwr_k=300:3.7301,lwr_k=400:3.9488,lwr_k=500:4.1357,lwr_k=600:4.2266,lwr_k=700:4.3655,lwr_k=800:4.4301,lwr_k=900:4.5212,lwr_k=1000:4.605'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:9.2477,lwr_k=10:26.2095,lwr_k=20:28.6534,lwr_k=30:66.3293,lwr_k=40:110.6706,lwr_k=50:1090.5403,lwr_k=100:9.2603,lwr_k=200:8.3315,lwr_k=300:8.0363,lwr_k=400:8.0043,lwr_k=500:8.0255,lwr_k=600:8.1976,lwr_k=700:8.23,lwr_k=800:8.293,lwr_k=900:8.3735,lwr_k=1000:8.315'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:4.4468,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0,lwr_k=50:0.1832,lwr_k=100:1.9761,lwr_k=200:2.7765,lwr_k=300:3.1842,lwr_k=400:3.3897,lwr_k=500:3.5225,lwr_k=600:3.6261,lwr_k=700:3.6866,lwr_k=800:3.7246,lwr_k=900:3.7759,lwr_k=1000:3.844'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:20.858,lwr_k=10:37.6556,lwr_k=20:67.9609,lwr_k=30:194.4,lwr_k=40:377.8149,lwr_k=50:803.3507,lwr_k=100:16.7259,lwr_k=200:15.716,lwr_k=300:16.9017,lwr_k=400:17.8685,lwr_k=500:18.3563,lwr_k=600:18.409,lwr_k=700:18.4987,lwr_k=800:18.6278,lwr_k=900:18.812,lwr_k=1000:18.9073'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:5.2154,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.0,lwr_k=40:0.0006,lwr_k=50:0.2241,lwr_k=100:2.1852,lwr_k=200:3.1291,lwr_k=300:3.4151,lwr_k=400:3.5782,lwr_k=500:3.7506,lwr_k=600:3.8627,lwr_k=700:4.0003,lwr_k=800:4.1246,lwr_k=900:4.2316,lwr_k=1000:4.3183'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:8.949,lwr_k=10:151.4717,lwr_k=20:75.9854,lwr_k=30:126.3175,lwr_k=40:375.9338,lwr_k=50:414.6464,lwr_k=100:10.8179,lwr_k=200:7.8667,lwr_k=300:7.6042,lwr_k=400:7.8206,lwr_k=500:7.2504,lwr_k=600:7.5463,lwr_k=700:7.648,lwr_k=800:7.5634,lwr_k=900:7.5328,lwr_k=1000:7.6095'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_85'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:55.2101,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:2.0536,lwr_k=40:4.5475,lwr_k=50:6.1161,lwr_k=100:10.7732,lwr_k=200:14.2261,lwr_k=300:16.4454,lwr_k=400:18.2837,lwr_k=500:19.8485,lwr_k=600:21.2229,lwr_k=700:22.5064,lwr_k=800:23.8824,lwr_k=900:25.143,lwr_k=1000:26.3154'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:67.9609,lwr_k=10:76.1821,lwr_k=20:137.7844,lwr_k=30:59.9741,lwr_k=40:32.1707,lwr_k=50:28.8983,lwr_k=100:22.6347,lwr_k=200:23.2803,lwr_k=300:26.1046,lwr_k=400:28.6607,lwr_k=500:30.3377,lwr_k=600:31.988,lwr_k=700:33.1984,lwr_k=800:34.5659,lwr_k=900:35.9027,lwr_k=1000:37.0256'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:69.4892,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:2.3464,lwr_k=40:5.0268,lwr_k=50:7.2941,lwr_k=100:13.5391,lwr_k=200:19.3478,lwr_k=300:22.3193,lwr_k=400:24.7641,lwr_k=500:26.3162,lwr_k=600:28.3845,lwr_k=700:30.0506,lwr_k=800:31.9455,lwr_k=900:33.6179,lwr_k=1000:34.8731'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:53.6902,lwr_k=10:61.6878,lwr_k=20:137.8677,lwr_k=30:59.886,lwr_k=40:31.1114,lwr_k=50:23.0993,lwr_k=100:17.3616,lwr_k=200:17.6322,lwr_k=300:18.588,lwr_k=400:19.6023,lwr_k=500:20.6247,lwr_k=600:21.1455,lwr_k=700:21.8222,lwr_k=800:22.7325,lwr_k=900:23.8216,lwr_k=1000:24.699'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:75.4766,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:2.5034,lwr_k=40:5.3069,lwr_k=50:7.5734,lwr_k=100:13.8604,lwr_k=200:20.3246,lwr_k=300:24.0337,lwr_k=400:26.9771,lwr_k=500:29.0068,lwr_k=600:30.9059,lwr_k=700:32.8615,lwr_k=800:34.6342,lwr_k=900:36.2768,lwr_k=1000:37.8139'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:53.3951,lwr_k=10:68.4164,lwr_k=20:199.9304,lwr_k=30:70.3803,lwr_k=40:35.8477,lwr_k=50:27.4297,lwr_k=100:22.5469,lwr_k=200:20.0628,lwr_k=300:20.3894,lwr_k=400:21.6687,lwr_k=500:22.2788,lwr_k=600:22.6627,lwr_k=700:23.9559,lwr_k=800:25.361,lwr_k=900:25.6943,lwr_k=1000:26.3659'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:72.3269,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:2.3344,lwr_k=40:5.3481,lwr_k=50:7.3303,lwr_k=100:13.1756,lwr_k=200:19.9166,lwr_k=300:23.2687,lwr_k=400:26.3469,lwr_k=500:28.4047,lwr_k=600:30.1566,lwr_k=700:31.9673,lwr_k=800:33.5856,lwr_k=900:35.3182,lwr_k=1000:36.8955'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:67.5258,lwr_k=10:73.7119,lwr_k=20:150.3278,lwr_k=30:56.4936,lwr_k=40:28.3902,lwr_k=50:26.0634,lwr_k=100:19.3755,lwr_k=200:20.1925,lwr_k=300:21.7113,lwr_k=400:22.9988,lwr_k=500:24.9538,lwr_k=600:25.9343,lwr_k=700:27.6266,lwr_k=800:29.1913,lwr_k=900:30.2251,lwr_k=1000:31.5445'\n",
      "-----------------------------------Fold 4 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:56.6596,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:2.1905,lwr_k=40:4.6401,lwr_k=50:6.4543,lwr_k=100:10.8933,lwr_k=200:15.0471,lwr_k=300:17.6531,lwr_k=400:19.7312,lwr_k=500:21.5527,lwr_k=600:23.0102,lwr_k=700:24.4531,lwr_k=800:25.8473,lwr_k=900:27.264,lwr_k=1000:28.496'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:99.2036,lwr_k=10:90.2366,lwr_k=20:199.4569,lwr_k=30:77.247,lwr_k=40:42.8997,lwr_k=50:37.2871,lwr_k=100:38.7406,lwr_k=200:41.8741,lwr_k=300:44.3597,lwr_k=400:45.7902,lwr_k=500:46.9083,lwr_k=600:49.4044,lwr_k=700:50.9518,lwr_k=800:53.1752,lwr_k=900:55.3769,lwr_k=1000:56.8948'\n",
      "Building final model - Train 4885 - Test 1222'\n",
      "Finished training DeepLWR with a train loss of lr:66.7904,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:2.2581,lwr_k=40:4.6728,lwr_k=50:6.5548,lwr_k=100:11.9156,lwr_k=200:16.885,lwr_k=300:20.0589,lwr_k=400:21.9876,lwr_k=500:23.9457,lwr_k=600:25.4344,lwr_k=700:26.7819,lwr_k=800:28.0213,lwr_k=900:29.2398,lwr_k=1000:30.4758'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:62.9883,lwr_k=10:100.4005,lwr_k=20:194.1281,lwr_k=30:72.2946,lwr_k=40:50.8894,lwr_k=50:34.5431,lwr_k=100:22.7162,lwr_k=200:23.7332,lwr_k=300:25.3977,lwr_k=400:25.3686,lwr_k=500:26.4606,lwr_k=600:26.9894,lwr_k=700:27.3105,lwr_k=800:27.9015,lwr_k=900:28.7679,lwr_k=1000:29.2558'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_86'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:12.6538,lwr_k=10:0.0,lwr_k=20:0.8739,lwr_k=30:3.4557,lwr_k=40:5.0148,lwr_k=50:6.036,lwr_k=100:7.9525,lwr_k=200:9.4211,lwr_k=300:9.9728,lwr_k=400:10.2119,lwr_k=500:10.2566,lwr_k=600:10.56,lwr_k=700:10.6533,lwr_k=800:10.9147,lwr_k=900:10.9231,lwr_k=1000:11.0602'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:15.304,lwr_k=10:72.3171,lwr_k=20:233.0563,lwr_k=30:30.4706,lwr_k=40:20.7032,lwr_k=50:17.4583,lwr_k=100:14.2935,lwr_k=200:13.8743,lwr_k=300:13.9621,lwr_k=400:13.8393,lwr_k=500:13.8991,lwr_k=600:13.9392,lwr_k=700:13.9211,lwr_k=800:13.8438,lwr_k=900:13.9492,lwr_k=1000:13.9913'\n",
      "-----------------------------------Fold 1 - Train 3663 - Val 1222 - Test 1222-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:6.5548,lwr_k=10:0.0013,lwr_k=20:2.5958,lwr_k=30:3.8477,lwr_k=40:4.4823,lwr_k=50:4.8708,lwr_k=100:5.719,lwr_k=200:6.1726,lwr_k=300:6.2027,lwr_k=400:6.3863,lwr_k=500:6.3392,lwr_k=600:6.372,lwr_k=700:6.4029,lwr_k=800:6.4149,lwr_k=900:6.4384,lwr_k=1000:6.4394'\n",
      "Tested (test) on 1222 instances with mean losses of: lr:10.458,lwr_k=10:446.1525,lwr_k=20:498606.8382,lwr_k=30:505.2859,lwr_k=40:22246676.4198,lwr_k=50:14645165.7988,lwr_k=100:11.3975,lwr_k=200:10.9086,lwr_k=300:10.7103,lwr_k=400:10.5997,lwr_k=500:10.6456,lwr_k=600:10.5684,lwr_k=700:10.6305,lwr_k=800:10.5947,lwr_k=900:10.512,lwr_k=1000:10.4534'\n",
      "-----------------------------------Fold 2 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:5.5216,lwr_k=10:0.0,lwr_k=20:0.0,lwr_k=30:0.7419,lwr_k=40:1.7114,lwr_k=50:0.0702,lwr_k=100:0.5454,lwr_k=200:1.6904,lwr_k=300:2.7849,lwr_k=400:3.3489,lwr_k=500:3.8759,lwr_k=600:4.2052,lwr_k=700:4.3661,lwr_k=800:4.4262,lwr_k=900:4.7049,lwr_k=1000:4.7697'\n",
      "Tested (test) on 1221 instances with mean losses of: lr:6.8835,lwr_k=10:26.0185,lwr_k=20:80.7176,lwr_k=30:55.9218,lwr_k=40:19.1102,lwr_k=50:24.6298,lwr_k=100:19.2027,lwr_k=200:15.3986,lwr_k=300:12.9537,lwr_k=400:9.5052,lwr_k=500:8.8528,lwr_k=600:8.739,lwr_k=700:7.4978,lwr_k=800:7.3033,lwr_k=900:6.8981,lwr_k=1000:6.9376'\n",
      "-----------------------------------Fold 3 - Train 3665 - Val 1221 - Test 1221-----------------------------------'\n",
      "Finished training DeepLWR with a train loss of lr:16.8721,lwr_k=10:0.0,lwr_k=20:0.0119,lwr_k=30:2.9547,lwr_k=40:4.8194,lwr_k=50:5.9136,lwr_k=100:9.4124,lwr_k=200:10.5726,lwr_k=300:11.9751,lwr_k=400:12.4907,lwr_k=500:12.7044,lwr_k=600:12.9484,lwr_k=700:13.1032,lwr_k=800:13.4648,lwr_k=900:13.5529,lwr_k=1000:13.6489'\n"
     ]
    }
   ],
   "source": [
    "for deep_name,deep_model in tqdm(deep_models.items()):\n",
    "    logging.getLogger().info(f\"Running model {deep_name}\")\n",
    "    temp_dict = {deep_name:deep_model}\n",
    "\n",
    "    lwr_scheme = DeepLWRScheme_1_to_n(lwr_models = setup_pls_models_exh(nrow),n_neighbours=500,loss_fun_sk = mean_squared_error)\n",
    "    lwr_scores, lwr_preds, _ , _, _,_= eval.evaluate(temp_dict,dataset,lwr_scheme,logger_name=\"log\",load_fun=load_fun_cv,load_fun_pp = load_fun_pp_cv)\n",
    "    lwr_scores_final, lwr_preds_final, _ , _, _,_= eval.build(temp_dict,dataset,lwr_scheme,logger_name=\"test_log\",load_fun=load_fun_build,load_fun_pp = load_fun_pp_build)\n",
    "\n",
    "    #scores\n",
    "    for k,v in ut.flip_dicts(lwr_scores).items():\n",
    "        dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "        all_scores.append({**dict1,**v})\n",
    "\n",
    "    for k,v in ut.flip_dicts(lwr_scores_final).items():\n",
    "        dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "        all_scores_final.append({**dict1,**v})\n",
    "\n",
    "    lwr_preds['deep'] = deep_preds[deep_name]\n",
    "    lwr_preds_final['deep'] = deep_preds_final[deep_name]\n",
    "\n",
    "    lwr_preds.to_csv(log_dir/deep_name/ f\"predictions.csv\",index=False)\n",
    "    lwr_preds_final.to_csv(log_dir/deep_name/ f\"predictions_test.csv\",index=False)\n",
    "\n",
    "    #preds\n",
    "    # todo save predictions - appending solns\n",
    "    plot_preds_and_res(lwr_preds,name_lambda=lambda x:f\"{deep_name} with {x} predictor\",save_lambda= lambda x:f\"deep_lwr{x}\",save_loc=log_dir/deep_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save scores\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(all_scores)\n",
    "scores_df.to_csv(log_dir/f\"scores.csv\",index=False)\n",
    "scores_df_final = pd.DataFrame(all_scores_final)\n",
    "scores_df_final.to_csv(log_dir/f\"test_scores.csv\",index=False)\n",
    "\n",
    "scores_df_sorted = pd.DataFrame(scores_df).sort_values(by='MSE')\n",
    "\n",
    "best_5 = []\n",
    "summary_logger.info(f\"Rank - \" +\" - \".join(list(scores_df_sorted.columns)))\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    if i < 5:\n",
    "        best_5.append((row[\"model_num\"],row[\"predictor\"],row[\"MSE\"]))\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    summary_logger.info(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save scores\n"
    }
   },
   "outputs": [],
   "source": [
    "summary_logger.info(\"-----------------------\\n Best 5 on Test Sest \\n ---------------------\")\n",
    "summary_logger.info(f\"Rank -  Deep Model - Predictor - Val Set - Test Set\")\n",
    "for i, (j,k,v) in enumerate(best_5):\n",
    "\n",
    "    row = scores_df_final.loc[(scores_df_final['model_num']==j) & (scores_df_final['predictor'] == k)].iloc[0]\n",
    "    #print(row)\n",
    "    s = f\"{i} - {j} - {k} - {v} - {row['MSE']} - {row['R2']}\"\n",
    "    summary_logger.info(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#take 1 is a scatter plot - lets, for each dataset\n",
    "#graph our deep models by rank - plot - then overlay our knn moels\n",
    "#plot points\n",
    "\n",
    "deep_set = scores_df[scores_df[\"predictor\"]==\"deep\"].sort_values(\"R2\")\n",
    "deep_set[\"order\"] = [i for i in range(0,100)]\n",
    "deep_ordering = {row[\"model_num\"]:row[\"order\"] for index, row in deep_set.iterrows()}\n",
    "\n",
    "def order_models(x):\n",
    "    x = [deep_ordering[i] for i in x]\n",
    "    return x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df[scores_df[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    if knn_model == \"deep\":\n",
    "        s=10\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot.png\", bbox_inches='tight')\n",
    "logging.getLogger().info(\"Wrote Summary Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df[\"n_features\"] = [deep_models[i].n_features for i in scores_df[\"model_num\"]] \n",
    "from matplotlib.colors import Colormap\n",
    "import seaborn as sns #heatmap of features - pls model - score\n",
    "class nlcmap(Colormap):\n",
    "    def __init__(self, cmap, levels):\n",
    "        self.cmap = cmap\n",
    "        self.N = cmap.N\n",
    "        self.monochrome = self.cmap.monochrome\n",
    "        self.levels = np.asarray(levels, dtype='float64')\n",
    "        self._x = self.levels\n",
    "        self.levmax = self.levels.max()\n",
    "        self.levmin = self.levels.min()\n",
    "        self.transformed_levels = np.linspace(self.levmin, self.levmax, #uniform spacing along levels (colour segments)\n",
    "             len(self.levels))\n",
    "\n",
    "    def __call__(self, xi, alpha=1.0, **kw):\n",
    "        yi = np.interp(xi, self._x, self.transformed_levels)\n",
    "        return self.cmap((yi-self.levmin) / (self.levmax-self.levmin), alpha)\n",
    "    \n",
    "levels = np.concatenate((\n",
    "    [0, 1],\n",
    "    [0.6,0.8,0.9,0.95,0.98]\n",
    "    ))\n",
    "\n",
    "levels = levels[levels <= 1]\n",
    "levels.sort()\n",
    "cmap_nonlin = nlcmap(plt.cm.YlGnBu, levels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = scores_df[[\"predictor\",\"n_features\",\"R2\"]]\n",
    "subset = subset[np.logical_not(subset[\"predictor\"]==\"deep\")]\n",
    "subset = subset[np.logical_not(subset[\"predictor\"]==\"lr\")]\n",
    "trans = subset[\"predictor\"].transform(lambda x: int(x.replace(\"lwr_k=\",\"\"))).tolist()\n",
    "subset.loc[:,\"predictor\"]=trans\n",
    "subset=subset.sort_values(\"predictor\",ascending=False)\n",
    "\n",
    "def rand_jitter(arr):\n",
    "    stdev = .01 * (max(arr) - min(arr))\n",
    "    return arr + np.random.randn(len(arr)) * stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sc = ax.scatter(x=rand_jitter(subset[\"n_features\"]), y=rand_jitter(subset[\"predictor\"]), s=20,c=subset[\"R2\"],cmap=cmap_nonlin,vmin=0)\n",
    "ax.set_xlabel(\"Number of Features\")\n",
    "ax.set_ylabel(\"Number of Neighbours\")\n",
    "\n",
    "cbar = fig.colorbar(sc,label=\"R2 Score\")\n",
    "\n",
    "ax.set_title(\"LWR performance as a function of the number of components\")\n",
    "plt.savefig(log_dir/f\"heat_scatter.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (lazydeep)",
   "language": "python",
   "name": "pycharm-12fcba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
