{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# set seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import utils as ut\n",
    "import experiment as exp\n",
    "from evaluation import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import random\n",
    "#define fixed_hyperparams and create a config gen\n",
    "from configurations import RandomConfigGen, Configuration\n",
    "from torch import nn\n",
    "from deep_net import RandomNet\n",
    "from experiment import run_experiment\n",
    "import regex as re\n",
    "from pathlib import *\n",
    "from plot import *\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sk_models import setup_pls_models_exh, StandardScaler, PLSRegression, CustomWrapper, KNNBoost\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "random_state = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up some stuff to manage metadata for each dataset\n",
    "id_col_db = {'A_C_OF_ALPHA':[\"sample_id\"],\n",
    "             'A_C_OF_SIWARE':[],\n",
    "             'A_AL_RT':[],\n",
    "             'PLN7':[\"db_id\", \"sample_id\"],\n",
    "             'mango_684_990': ['Set','Season','Region','Date','Type','Cultivar','Pop','Temp',\"FruitID\"]\n",
    "            }\n",
    "\n",
    "output_col_db= {'A_C_OF_ALPHA':None,\n",
    "             'A_C_OF_SIWARE':None,\n",
    "             'A_AL_RT':None,\n",
    "             'PLN7':None,\n",
    "             'mango_684_990': ['DM']\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\workspace\\lazydeep\\experiments\\1.06_reverse\\PLN7\n"
     ]
    }
   ],
   "source": [
    "#setup input and output formats, load data\n",
    "\n",
    "file_name = \"PLN7.csv\"\n",
    "dataset_name = re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "\n",
    "\n",
    "\n",
    "data_path = Path('D:/workspace/lazydeep/data/soil_data/')\n",
    "model_path = Path('D:/workspace/lazydeep/experiments/1.01/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/1.06_reverse\")\n",
    "n_components =  34\n",
    "\n",
    "data_file = data_path / file_name\n",
    "log_dir = log_path / dataset_name\n",
    "model_dir = model_path / dataset_name\n",
    "\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "print(log_dir)\n",
    "\n",
    "id_cols =id_col_db[dataset_name]\n",
    "output_cols = output_col_db[dataset_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% load data\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data = data.sample(frac=1)\n",
    "nrow, ncol = data.shape\n",
    "data = ut.sample_data(data,random_state)\n",
    "n_features = ncol - 1-len(id_cols)\n",
    "dataset = TabularDataset(data,id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "#dataset = TabularDataset(data,id_cols = id_cols, cat_cols=None, output_cols=None, ignore_cols= None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% load models\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 models\n"
     ]
    }
   ],
   "source": [
    "n_models = 100\n",
    "model_names = [f\"random_{i}\" for i in range(0,n_models)]\n",
    "deep_models = {name:torch.load(model_dir/\"models\"/name/\"_model\") for name in model_names}\n",
    "#for each model, load state\n",
    "print(f\"Loaded {len(deep_models)} models\")\n",
    "\n",
    "#print(deep_models)\n",
    "for name in model_names:\n",
    "    sub_path = log_dir / name\n",
    "    if not sub_path.exists():\n",
    "        sub_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup logging and tensorboard outputs\n"
    }
   },
   "outputs": [],
   "source": [
    "# set logging, in this case the root logger\n",
    "ut.setup_logger(logger_name=\"\",file_name=log_dir/\"log.txt\")\n",
    "ut.setup_logger(logger_name=\"summary\",file_name=log_dir/\"summary.txt\")\n",
    "summary_logger = logging.getLogger(\"summary\")\n",
    "tb = SummaryWriter(log_dir/\"tb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% setup experiment\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is (10000, 129)\n"
     ]
    }
   ],
   "source": [
    "fixed_hyperparams = {'bs': 32,'loss': nn.MSELoss(),'epochs': 100}\n",
    "preprocessing = PLSRegression(n_components=n_components)\n",
    "\n",
    "if dataset_name == 'mango_684_990':\n",
    "    eval_ = MangoesSplitter(preprocessing=preprocessing,tensorboard=None,time=True,random_state=random_state)\n",
    "else:\n",
    "    eval_ = CrossValEvaluation(preprocessing=preprocessing,tensorboard=None,time=True,random_state=random_state)\n",
    "    \n",
    "print(f\"Dataset shape is {data.shape}\")\n",
    "scores={} #->model->knn:{fold_0:number,...,fold_n:number,mean:number,median:number\n",
    "preds={} #model-> foldsxknn_models\n",
    "deep_scores_dict={}\n",
    "deep_preds_dict={}\n",
    "actual_y = None\n",
    "\n",
    "device = \"cpu\" #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_fun_cv = lambda name,model, fold : model.load_state(model_dir/'models'/name/f\"_fold_{fold}\")\n",
    "load_fun_pp_cv = None # lambda fold : preprocessing.from_state(preprocessing.load_state(model_dir/'preprocessing'/f\"_fold_{fold}\"))\n",
    "load_fun_build = lambda name,model : model.load_state(model_dir/'models'/name/f\"_final\")\n",
    "load_fun_pp_build = None # lambda : preprocessing.from_state(preprocessing.load_state(model_dir/'preprocessing'/f\"_final\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% deep experiment\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Tested (test) on 1667 instances with mean losses of: random_0:147.1446,random_1:161.1235,random_2:148.0153,random_3:2762.2158,random_4:149.5205,random_5:134.669,random_6:466.0829,random_7:151.6422,random_8:151.2387,random_9:310.3846,random_10:146.2283,random_11:152.8767,random_12:166.4905,random_13:684.0451,random_14:137.7049,random_15:156.9714,random_16:169.3578,random_17:144.9467,random_18:159.2038,random_19:166.2787,random_20:152.0457,random_21:182.3562,random_22:175.5737,random_23:181.1456,random_24:144.4135,random_25:155.3511,random_26:466.1744,random_27:224.4122,random_28:142.8462,random_29:154.4464,random_30:173.3534,random_31:1270.8496,random_32:152.9794,random_33:160.7083,random_34:154.5682,random_35:465.9934,random_36:142.6404,random_37:166.6472,random_38:162.0285,random_39:164.3657,random_40:153.9292,random_41:155.9942,random_42:251.2476,random_43:339.4361,random_44:148.3971,random_45:161.8606,random_46:152.1294,random_47:154.4685,random_48:1020.6516,random_49:395.3792,random_50:160.3652,random_51:325.7392,random_52:1543.3301,random_53:152.0561,random_54:143.337,random_55:146.6807,random_56:145.7448,random_57:149.1403,random_58:152.5084,random_59:160.1906,random_60:162.2731,random_61:143.138,random_62:163.0945,random_63:191.5376,random_64:162.2601,random_65:148.3225,random_66:156.1508,random_67:205.2405,random_68:466.593,random_69:184.2796,random_70:187.4995,random_71:147.4211,random_72:205.1887,random_73:143.3698,random_74:153.4553,random_75:152.5712,random_76:152.16,random_77:148.7748,random_78:158.8913,random_79:145.9491,random_80:159.3029,random_81:176.8159,random_82:137.5075,random_83:145.0249,random_84:160.862,random_85:189.6642,random_86:157.523,random_87:152.8857,random_88:162.0142,random_89:466.1002,random_90:139.4601,random_91:153.6203,random_92:2781.881,random_93:155.2179,random_94:147.7485,random_95:466.0357,random_96:156.7473,random_97:665.7362,random_98:186.2882,random_99:158.5273'\n",
      "Testing (test) took 0:00:02.153001'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Tested (test) on 1667 instances with mean losses of: random_0:148.0008,random_1:144.2612,random_2:145.0499,random_3:152.0345,random_4:139.5041,random_5:142.3263,random_6:141.6708,random_7:155.104,random_8:152.0488,random_9:143.1419,random_10:131.2531,random_11:498.9816,random_12:149.8912,random_13:513.7776,random_14:143.5664,random_15:148.1501,random_16:185.4176,random_17:183.6008,random_18:150.7018,random_19:156.4546,random_20:155.5693,random_21:153.0119,random_22:154.8608,random_23:514.9816,random_24:132.8159,random_25:148.612,random_26:514.5891,random_27:271.9099,random_28:513.7774,random_29:146.686,random_30:185.5018,random_31:159.0032,random_32:139.3803,random_33:158.3283,random_34:154.392,random_35:142.5927,random_36:465.0108,random_37:139.1235,random_38:177.5098,random_39:142.6209,random_40:145.4948,random_41:192.3752,random_42:153.0581,random_43:2904.6899,random_44:163.6855,random_45:164.5139,random_46:159.3647,random_47:150.39,random_48:1222.5734,random_49:602.405,random_50:157.4969,random_51:385.0494,random_52:164.7968,random_53:326.8645,random_54:153.0258,random_55:152.2478,random_56:149.7551,random_57:156.1512,random_58:146.709,random_59:188.0667,random_60:149.2189,random_61:231.3234,random_62:156.1511,random_63:200.617,random_64:158.2461,random_65:137.4342,random_66:149.8862,random_67:213.7093,random_68:516.1761,random_69:137.7548,random_70:160.1036,random_71:145.4025,random_72:243.9084,random_73:138.5785,random_74:145.833,random_75:149.313,random_76:144.8256,random_77:136.9131,random_78:146.8002,random_79:143.5927,random_80:146.6703,random_81:140.4785,random_82:130.4421,random_83:147.3903,random_84:145.3098,random_85:2002.3053,random_86:157.0982,random_87:163.5835,random_88:155.0942,random_89:513.9314,random_90:514.673,random_91:150.3186,random_92:160.8836,random_93:299.1196,random_94:133.9411,random_95:127.0093,random_96:152.7334,random_97:2592.0743,random_98:159.6562,random_99:145.0231'\n",
      "Testing (test) took 0:00:02.088343'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Tested (test) on 1667 instances with mean losses of: random_0:159.2522,random_1:165.968,random_2:1801.2777,random_3:477.6612,random_4:143.9305,random_5:147.2763,random_6:387.9102,random_7:165.9713,random_8:153.7772,random_9:154.4154,random_10:142.5462,random_11:156.2559,random_12:158.2287,random_13:663.1099,random_14:148.2283,random_15:172.834,random_16:166.8948,random_17:151.1486,random_18:154.3236,random_19:188.3211,random_20:162.4378,random_21:164.307,random_22:167.8061,random_23:170.0383,random_24:145.4006,random_25:160.5468,random_26:477.6822,random_27:276.7694,random_28:150.7173,random_29:152.7773,random_30:186.086,random_31:162.183,random_32:163.8631,random_33:161.4014,random_34:156.477,random_35:176.4314,random_36:149.5971,random_37:159.6392,random_38:2554.7328,random_39:152.7702,random_40:154.5902,random_41:477.6775,random_42:152.6498,random_43:2874.17,random_44:172.8528,random_45:174.2463,random_46:162.3512,random_47:161.257,random_48:183.7435,random_49:2530.0331,random_50:2884.4274,random_51:170.6085,random_52:3121.022,random_53:421.224,random_54:146.232,random_55:157.9174,random_56:151.7304,random_57:154.7122,random_58:2853.6657,random_59:147.9642,random_60:156.3865,random_61:146.7111,random_62:162.8552,random_63:153.1518,random_64:164.6062,random_65:164.6585,random_66:169.2091,random_67:161.0262,random_68:477.6964,random_69:157.2185,random_70:152.4009,random_71:150.0015,random_72:635.4183,random_73:150.1126,random_74:151.3223,random_75:156.1372,random_76:174.7629,random_77:150.0817,random_78:152.97,random_79:157.209,random_80:161.2426,random_81:148.8484,random_82:144.0645,random_83:156.1235,random_84:160.1145,random_85:172.6342,random_86:157.4279,random_87:170.4553,random_88:169.8041,random_89:477.6978,random_90:169.365,random_91:162.8963,random_92:161.8216,random_93:160.0911,random_94:150.2785,random_95:145.07,random_96:161.6327,random_97:2368.4496,random_98:157.957,random_99:154.3858'\n",
      "Testing (test) took 0:00:02.108165'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Tested (test) on 1666 instances with mean losses of: random_0:133.357,random_1:192.2467,random_2:1415.5633,random_3:134.9737,random_4:124.7036,random_5:123.8185,random_6:157.0571,random_7:176.8107,random_8:135.3755,random_9:245.6379,random_10:119.5908,random_11:472.5846,random_12:134.675,random_13:713.0095,random_14:157.7538,random_15:136.3398,random_16:145.303,random_17:133.2364,random_18:133.1141,random_19:161.8239,random_20:133.3432,random_21:138.4661,random_22:169.4892,random_23:472.5129,random_24:121.6522,random_25:131.5783,random_26:1624.6619,random_27:216.848,random_28:136.6674,random_29:133.7198,random_30:164.806,random_31:1935.45,random_32:136.4928,random_33:135.5115,random_34:133.8875,random_35:146.5755,random_36:144.2897,random_37:131.683,random_38:2431.4706,random_39:132.3304,random_40:136.8123,random_41:181.3128,random_42:174.2485,random_43:2686.9451,random_44:138.8564,random_45:142.5028,random_46:144.239,random_47:138.7671,random_48:1977.4979,random_49:495.7517,random_50:152.9357,random_51:145.659,random_52:2846.5281,random_53:200.3157,random_54:126.7564,random_55:259.1991,random_56:132.3274,random_57:128.3768,random_58:471.6211,random_59:125.6756,random_60:137.3581,random_61:119.7391,random_62:127.3378,random_63:210.6187,random_64:132.9177,random_65:176.9314,random_66:141.4423,random_67:134.8516,random_68:472.3926,random_69:136.2145,random_70:472.4526,random_71:132.4932,random_72:232.6625,random_73:130.9746,random_74:135.8892,random_75:139.1481,random_76:407.2409,random_77:139.1033,random_78:132.9269,random_79:260.4291,random_80:137.2758,random_81:127.8606,random_82:127.6599,random_83:130.1486,random_84:145.5172,random_85:142.5383,random_86:138.7751,random_87:139.3711,random_88:142.9177,random_89:472.3927,random_90:125.1426,random_91:127.1109,random_92:474.5244,random_93:132.6615,random_94:128.0873,random_95:143.1267,random_96:140.311,random_97:471.79,random_98:164.9911,random_99:135.9104'\n",
      "Testing (test) took 0:00:02.115933'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Tested (test) on 1666 instances with mean losses of: random_0:148.6053,random_1:168.7185,random_2:208.2626,random_3:163.9045,random_4:135.6274,random_5:212.8488,random_6:215.8807,random_7:153.8888,random_8:151.5435,random_9:147.4957,random_10:137.4024,random_11:150.7574,random_12:157.272,random_13:490.8967,random_14:142.8191,random_15:157.8033,random_16:160.2569,random_17:188.5516,random_18:149.9715,random_19:162.3633,random_20:159.013,random_21:215.3753,random_22:162.1375,random_23:173.2692,random_24:130.3835,random_25:151.0191,random_26:468.0707,random_27:348.3353,random_28:133.5176,random_29:142.78,random_30:170.1586,random_31:1409.3124,random_32:148.1136,random_33:154.7793,random_34:155.3584,random_35:158.8298,random_36:151.4864,random_37:157.3666,random_38:2674.5696,random_39:147.9702,random_40:157.8587,random_41:2854.7169,random_42:214.2356,random_43:2789.4853,random_44:170.6055,random_45:166.7587,random_46:157.81,random_47:154.4264,random_48:2254.8898,random_49:1791.4051,random_50:159.3631,random_51:157.0975,random_52:2159.3965,random_53:2693.7183,random_54:144.3304,random_55:194.3157,random_56:218.6769,random_57:162.0064,random_58:152.6066,random_59:240.8172,random_60:155.0633,random_61:141.8397,random_62:265.379,random_63:143.0361,random_64:161.859,random_65:165.5859,random_66:151.4811,random_67:151.5285,random_68:467.8714,random_69:160.299,random_70:467.8797,random_71:149.4263,random_72:149.3267,random_73:134.5115,random_74:151.2776,random_75:145.9744,random_76:154.5654,random_77:157.0348,random_78:145.2294,random_79:138.5148,random_80:155.5301,random_81:146.1472,random_82:131.8439,random_83:147.7245,random_84:155.1951,random_85:162.4605,random_86:157.9949,random_87:148.0234,random_88:157.7004,random_89:467.8628,random_90:135.3262,random_91:156.4463,random_92:153.8961,random_93:140.3847,random_94:142.8339,random_95:182.9616,random_96:153.3846,random_97:1080.9239,random_98:163.7234,random_99:144.5762'\n",
      "Testing (test) took 0:00:02.107316'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Tested (test) on 1667 instances with mean losses of: random_0:148.8265,random_1:149.872,random_2:376.3356,random_3:146.5714,random_4:146.598,random_5:133.5081,random_6:698.0153,random_7:168.8136,random_8:159.7339,random_9:144.5003,random_10:142.4375,random_11:156.7136,random_12:150.6126,random_13:485.2733,random_14:138.6782,random_15:160.192,random_16:153.3117,random_17:135.5052,random_18:143.0904,random_19:143.4403,random_20:158.8435,random_21:155.4229,random_22:170.3754,random_23:152.8703,random_24:130.7422,random_25:155.2039,random_26:481.204,random_27:192.29,random_28:142.5244,random_29:144.5691,random_30:189.5855,random_31:160.682,random_32:142.8227,random_33:151.4686,random_34:158.0551,random_35:173.876,random_36:137.4498,random_37:154.1287,random_38:2078.1625,random_39:139.0234,random_40:158.3656,random_41:2901.9386,random_42:145.6764,random_43:2885.6209,random_44:177.5122,random_45:161.4243,random_46:150.4457,random_47:153.572,random_48:407989.7919,random_49:2612.8249,random_50:154.9875,random_51:228.4547,random_52:2798.9508,random_53:2715.1806,random_54:158.0454,random_55:156.7729,random_56:225.8742,random_57:157.9843,random_58:153.4846,random_59:172.9738,random_60:166.1266,random_61:136.6601,random_62:187.1484,random_63:203.4299,random_64:160.6635,random_65:139.607,random_66:157.085,random_67:137.5318,random_68:481.2553,random_69:146.0202,random_70:481.2521,random_71:146.3163,random_72:375.6847,random_73:138.23,random_74:151.9656,random_75:147.5415,random_76:144.0803,random_77:142.0133,random_78:138.2711,random_79:147.4801,random_80:151.5035,random_81:143.7027,random_82:133.6739,random_83:147.4844,random_84:154.461,random_85:155.8948,random_86:150.1848,random_87:138.2064,random_88:166.3994,random_89:481.2561,random_90:138.8256,random_91:154.4019,random_92:156.2352,random_93:158.8351,random_94:144.6764,random_95:147.8741,random_96:166.669,random_97:138.3341,random_98:178.8772,random_99:153.2657'\n",
      "Testing (test) took 0:00:02.056164'\n"
     ]
    }
   ],
   "source": [
    "deep_scheme = DeepScheme(None, fixed_hyperparams=fixed_hyperparams,loss_eval=loss_target,device=device,tensorboard=tb,adaptive_lr=False,update=False)\n",
    "deep_scores, deep_preds, _ , _, _,_ = eval_.evaluate(deep_models,dataset,deep_scheme,logger_name=\"log\",load_fun=load_fun_cv,load_fun_pp = load_fun_pp_cv)\n",
    "deep_scores_final, deep_preds_final, _ ,_, _,_ = eval_.build(deep_models,dataset,deep_scheme,logger_name=\"test_log\",load_fun=load_fun_build,load_fun_pp = load_fun_pp_build)\n",
    "\n",
    "all_scores = []\n",
    "for k,v in ut.flip_dicts(deep_scores).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores.append({**dict1,**v})\n",
    "    \n",
    "all_scores_final = []\n",
    "for k,v in ut.flip_dicts(deep_scores_final).items():\n",
    "    dict1 = {'model_num':k,\"predictor\":\"deep\"}\n",
    "    all_scores_final.append({**dict1,**v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - random_82 - deep - 137.5075182648712 - 130.4421176006498 - 144.06449480977827 - 127.65992345271849 - 131.84387805109836 - 134.30467871071176 - 0.7199893993454223\n",
      "1 - random_24 - deep - 144.41353603516356 - 132.81591498472767 - 145.4006378800839 - 121.6521948073663 - 130.38346345313028 - 134.9352893915091 - 0.7186746448841157\n",
      "2 - random_10 - deep - 146.22829733827405 - 131.2531475577443 - 142.54620770487017 - 119.59081962557973 - 137.4023663176208 - 135.40582546692042 - 0.7176936285087342\n",
      "3 - random_4 - deep - 149.52052070283574 - 139.50407097535572 - 143.93053564656333 - 124.70355024944548 - 135.62736985663406 - 138.6592477281742 - 0.7109105980863994\n",
      "4 - random_73 - deep - 143.369752692833 - 138.57852169190184 - 150.11264153991405 - 130.9745516782763 - 134.5115186226468 - 139.51102111677213 - 0.7091347435111719\n",
      "5 - random_94 - deep - 147.74845175007968 - 133.9410871426789 - 150.27850711595963 - 128.0872647581982 - 142.83391092032517 - 140.57907244776365 - 0.7069079730249028\n",
      "6 - random_54 - deep - 143.3369931162083 - 153.02575410821157 - 146.23201375502487 - 126.75642759545224 - 144.33043288726623 - 142.73805122060224 - 0.7024067378573241\n",
      "7 - random_71 - deep - 147.42106379444326 - 145.40249613651488 - 150.00145401522724 - 132.49321839331435 - 149.42633086865118 - 144.94986936347323 - 0.6977953383687179\n",
      "8 - random_83 - deep - 145.02487304357976 - 147.3902957506643 - 156.12350985041334 - 130.14863648706552 - 147.72448534467497 - 145.28388368452516 - 0.6970989549548054\n",
      "9 - random_14 - deep - 137.70490223702086 - 143.56642867593473 - 148.22834771195787 - 157.75380246092578 - 142.81907055730008 - 146.01348448413944 - 0.6955778168969267\n",
      "10 - random_29 - deep - 154.446354651494 - 146.6859692697691 - 152.77725805089227 - 133.71976552461805 - 142.77998224741557 - 146.08374610812191 - 0.6954313290774168\n",
      "11 - random_77 - deep - 148.77480655754835 - 136.91305230775134 - 150.08172788660042 - 139.1033063982429 - 157.03478088928443 - 146.38112929019692 - 0.6948113175913184\n",
      "12 - random_0 - deep - 147.1445725308826 - 148.0008328900626 - 159.25217494953156 - 133.35702390544841 - 148.6052618496129 - 147.27348410121905 - 0.6929508551783186\n",
      "13 - random_78 - deep - 158.89134197086364 - 146.8002499292622 - 152.97004405652683 - 132.92693485475246 - 145.22940014018303 - 147.3655830805905 - 0.6927588388555735\n",
      "14 - random_74 - deep - 153.45526117669226 - 145.8329661643355 - 151.3222925590053 - 135.88923227372004 - 151.27763947375826 - 147.55643185984212 - 0.6923609399750175\n",
      "15 - random_99 - deep - 158.52725067779411 - 145.02305100503338 - 154.38577592136906 - 135.91042533956943 - 144.576222038498 - 147.68633145297855 - 0.6920901134971309\n",
      "16 - random_39 - deep - 164.36570207473397 - 142.62089369235528 - 152.7702025360309 - 132.3304426506931 - 147.9701933385659 - 148.01337385772723 - 0.6914082657679803\n",
      "17 - random_81 - deep - 176.8159001927642 - 140.4785398633164 - 148.84839134010357 - 127.860574765795 - 146.1472452262155 - 148.03277671218763 - 0.6913678129335442\n",
      "18 - random_32 - deep - 152.97942731705123 - 139.38026185656423 - 163.863112735119 - 136.49283807761387 - 148.11364142061853 - 148.16726493576093 - 0.6910874196618784\n",
      "19 - random_75 - deep - 152.5712334255866 - 149.3129566561053 - 156.1371806041166 - 139.14811772487315 - 145.9744149170288 - 148.63023752479896 - 0.6901221723303064\n",
      "20 - random_8 - deep - 151.23871260141283 - 152.04883586881257 - 153.77720893809519 - 135.3754873653563 - 151.5434860559214 - 148.7980271650407 - 0.6897723492385219\n",
      "21 - random_25 - deep - 155.35112474689817 - 148.6119859463166 - 160.54683642167134 - 131.57825921506299 - 151.01910835440134 - 149.4234122263752 - 0.6884684896236095\n",
      "22 - random_18 - deep - 159.2038448130076 - 150.7018404241515 - 154.32362722706924 - 133.1140560411176 - 149.97153083645568 - 149.46488185862907 - 0.6883820299652581\n",
      "23 - random_40 - deep - 153.92921740664073 - 145.49475220312382 - 154.59019869304947 - 136.81229081903757 - 157.85874189763797 - 149.73761682867652 - 0.6878134073117839\n",
      "24 - random_57 - deep - 149.14027304097286 - 156.1511642007536 - 154.7122040538639 - 128.37676139181258 - 162.0063626585888 - 150.07852621532834 - 0.6871026484384406\n",
      "25 - random_91 - deep - 153.620345600222 - 150.31857823381614 - 162.8963279952957 - 127.11086940879868 - 156.4462514879609 - 150.08046612553136 - 0.6870986039373377\n",
      "26 - random_37 - deep - 166.647212444413 - 139.12350676227058 - 159.6392497581569 - 131.68301010589784 - 157.36661104566338 - 150.8934462727633 - 0.6854036290374907\n",
      "27 - random_34 - deep - 154.56817166077283 - 154.3920279847839 - 156.47700864566465 - 133.88745565975412 - 155.35841047234322 - 150.93813077537928 - 0.6853104667252201\n",
      "28 - random_47 - deep - 154.46845284721132 - 150.39001206716665 - 161.25703940937888 - 138.767085484096 - 154.42642385933866 - 151.86306536051902 - 0.6833820790380791\n",
      "29 - random_80 - deep - 159.3029143866051 - 146.6703013218157 - 161.24257640918717 - 137.27580574466114 - 155.53014179609832 - 152.0056930065216 - 0.6830847159587694\n",
      "30 - random_60 - deep - 162.27312153917484 - 149.2188880888373 - 156.38646359091828 - 137.35813310309476 - 155.0632761466403 - 152.06138062313747 - 0.6829686133543975\n",
      "31 - random_5 - deep - 134.66904243510427 - 142.32630676013235 - 147.27630952081068 - 123.81846252294864 - 212.8487847226293 - 152.18390586583163 - 0.6827131615925416\n",
      "32 - random_20 - deep - 152.0456795123214 - 155.5693030491802 - 162.43784279643094 - 133.34324928091354 - 159.01298762913368 - 152.4833254194813 - 0.6820889044939058\n",
      "33 - random_96 - deep - 156.74727865172204 - 152.73341804417436 - 161.63271283502698 - 140.3110226085063 - 153.38456757214604 - 152.9632668004845 - 0.6810882790826112\n",
      "34 - random_12 - deep - 166.49045075780987 - 149.89121054573266 - 158.2286906720066 - 134.67502651695443 - 157.2720019282127 - 153.31323775183708 - 0.6803586278356061\n",
      "35 - random_84 - deep - 160.86198042907898 - 145.30979812338313 - 160.11448720120782 - 145.51721045779152 - 155.1951267384395 - 153.40045155720236 - 0.6801767965676254\n",
      "36 - random_66 - deep - 156.15075935313425 - 149.8862396771134 - 169.2090683418187 - 141.4422553200968 - 151.481117706482 - 153.63560923805974 - 0.6796865184619219\n",
      "37 - random_86 - deep - 157.52297369505592 - 157.09822286641304 - 157.42790203288993 - 138.77506606890802 - 157.9949466389339 - 153.76511409923057 - 0.679416514957113\n",
      "38 - random_33 - deep - 160.70834340974824 - 158.32827788080078 - 161.40144821148687 - 135.51153196263857 - 154.7793091754524 - 154.14794262294382 - 0.6786183592569415\n",
      "39 - random_15 - deep - 156.9714350754727 - 148.15011470362177 - 172.83399741636757 - 136.3397816157713 - 157.8032911879962 - 154.42148773746416 - 0.678048047540639\n",
      "40 - random_87 - deep - 152.88574119892817 - 163.5835175677267 - 170.45526103767438 - 139.37112779376886 - 148.0233774173732 - 154.8664841480599 - 0.6771202785796749\n",
      "41 - random_69 - deep - 184.2796111630335 - 137.754818061046 - 157.21845980726036 - 136.21446411206085 - 160.2989878568615 - 155.1549236684153 - 0.6765189136523875\n",
      "42 - random_46 - deep - 152.12944892100683 - 159.36474299988635 - 162.35117764292752 - 144.2390072606191 - 157.81001028035726 - 155.1798754199314 - 0.6764668919730501\n",
      "43 - random_64 - deep - 162.2600555236853 - 158.24614114652655 - 164.60620457352317 - 132.91768263396668 - 161.85900162677376 - 155.97987831429353 - 0.6747989732294428\n",
      "44 - random_61 - deep - 143.13800560963247 - 231.3233687979201 - 146.7110830511815 - 119.73905226763557 - 141.83969843888482 - 156.55642390768728 - 0.6735969385761402\n",
      "45 - random_88 - deep - 162.0142171089708 - 155.0941768250354 - 169.8041499514886 - 142.91770699673913 - 157.7003786286243 - 157.50785300003724 - 0.6716133127323751\n",
      "46 - random_65 - deep - 148.32248614058926 - 137.43423286167962 - 164.65849010373705 - 176.9313974735402 - 165.58588623742955 - 158.5834580233449 - 0.6693707936218369\n",
      "47 - random_44 - deep - 148.39711365359375 - 163.68551773043828 - 172.85278245711942 - 138.85642161832996 - 170.60551890433908 - 158.8804664285704 - 0.6687515635045765\n",
      "48 - random_56 - deep - 145.7448183184408 - 149.75511053184871 - 151.73036057003688 - 132.3274281880721 - 218.6768508856179 - 159.64310852601199 - 0.6671615379459803\n",
      "49 - random_17 - deep - 144.94666282045105 - 183.60079701588978 - 151.14859541977103 - 133.23641724145713 - 188.5515621501286 - 160.29666370621445 - 0.6657989467069694\n",
      "50 - random_7 - deep - 151.64223659632088 - 155.10397609809093 - 165.97125007066458 - 176.81070711976196 - 153.88882547953264 - 160.6822792508325 - 0.664994980372313\n",
      "51 - random_45 - deep - 161.86059964139375 - 164.5138501291441 - 174.24633187338057 - 142.50278724771158 - 166.75869967127477 - 161.97821719709586 - 0.6622930911587146\n",
      "52 - random_16 - deep - 169.35776610852145 - 185.41757143566403 - 166.89483514429926 - 145.3030489203738 - 160.2569451257676 - 165.44907279212296 - 0.6550567359603807\n",
      "53 - random_22 - deep - 175.57371266072713 - 154.86078630526336 - 167.8061403939305 - 169.48919913119056 - 162.1374607246463 - 165.97349783560256 - 0.6539633669665921\n",
      "54 - random_1 - deep - 161.12350827258865 - 144.26118596471136 - 165.96799771973096 - 192.24671431377726 - 168.71851978095927 - 166.4602206410644 - 0.6529486030252463\n",
      "55 - random_98 - deep - 186.28815338921962 - 159.65621146400602 - 157.9569506539366 - 164.99110850394845 - 163.72338969309646 - 166.52368093492535 - 0.6528162952369228\n",
      "56 - random_19 - deep - 166.27871105924078 - 156.45464102980185 - 188.3210877165082 - 161.82390342611654 - 162.3632909035196 - 167.04951569928306 - 0.651719987128923\n",
      "57 - random_79 - deep - 145.949127256763 - 143.59269041577426 - 157.20897991269666 - 260.42908010677417 - 138.51477217473902 - 169.13165067791914 - 0.6473789628875591\n",
      "58 - random_21 - deep - 182.35615583029633 - 153.01192431801726 - 164.3069572242778 - 138.46614069211668 - 215.37528136254502 - 170.70180058761753 - 0.6441053716504334\n",
      "59 - random_59 - deep - 160.19059733738067 - 188.06666404756157 - 147.96422720155675 - 125.67558226293447 - 240.817212831788 - 172.5402877785584 - 0.6402723264611443\n",
      "60 - random_67 - deep - 205.24045169603775 - 213.70926477241173 - 161.0261890615041 - 134.85159571030562 - 151.52847057402062 - 173.27841316296212 - 0.638733415574127\n",
      "61 - random_62 - deep - 163.09446299826948 - 156.1511381866693 - 162.85520207588732 - 127.33779319222806 - 265.3790267083396 - 174.95838932791807 - 0.6352308485783194\n",
      "62 - random_30 - deep - 173.3533757192043 - 185.50183336135507 - 186.08602185812836 - 164.8059586871858 - 170.15860179521027 - 175.98319842292648 - 0.6330942334357622\n",
      "63 - random_93 - deep - 155.2179052699592 - 299.11956988485116 - 160.09105209368892 - 132.66151291754494 - 140.3846710223396 - 177.50477686591913 - 0.6299219084069139\n",
      "64 - random_63 - deep - 191.53762106617984 - 200.61696854964944 - 153.1517904083673 - 210.61870356052577 - 143.03606591562405 - 179.79294112922187 - 0.6251513355876019\n",
      "65 - random_55 - deep - 146.68073118240733 - 152.2477806562711 - 157.91743109279145 - 259.19905293660435 - 194.31572880922388 - 182.0614203569256 - 0.6204218039196103\n",
      "66 - random_42 - deep - 251.2475656430451 - 153.05805732164114 - 152.6498317661297 - 174.24853471662104 - 214.23556274011068 - 189.08667258193154 - 0.6057749195805249\n",
      "67 - random_9 - deep - 310.38463308314897 - 143.14187168059553 - 154.41544005880831 - 245.6378944644264 - 147.49568408906532 - 200.21598038757668 - 0.5825715271637883\n",
      "68 - random_76 - deep - 152.16003187301993 - 144.8255891851415 - 174.76287267418343 - 407.24086128592063 - 154.56537553070544 - 206.69313749800142 - 0.5690673613340134\n",
      "69 - random_36 - deep - 142.64040199925103 - 465.0107623983016 - 149.59706328082527 - 144.28972853789952 - 151.4863744921186 - 210.61991914337602 - 0.5608804500684044\n",
      "70 - random_95 - deep - 466.0357204590576 - 127.00927894560247 - 145.0699664243482 - 143.12668319280837 - 182.96160533305118 - 212.85260281028292 - 0.5562255482388943\n",
      "71 - random_28 - deep - 142.84624130166642 - 513.7774482640093 - 150.717256714215 - 136.66736076144326 - 133.51756206480394 - 215.52447263281496 - 0.5506549911960563\n",
      "72 - random_90 - deep - 139.46011549566919 - 514.6729708501659 - 169.36498542195247 - 125.14263848239491 - 135.32623114019168 - 216.81416396538575 - 0.5479661254904169\n",
      "73 - random_35 - deep - 465.99340326941933 - 142.59268921667328 - 176.4314055828971 - 146.57553641879116 - 158.82982911182052 - 218.10026291658392 - 0.545284749507962\n",
      "74 - random_51 - deep - 325.73920026938214 - 385.0494466963541 - 170.60847450947432 - 145.6590373209831 - 157.09753128546342 - 236.85125326279024 - 0.5061909806228231\n",
      "75 - random_27 - deep - 224.41219365074738 - 271.90993467261137 - 276.769445029146 - 216.84801762501877 - 348.33531820931495 - 267.6513971490468 - 0.4419760413323257\n",
      "76 - random_6 - deep - 466.0828696321283 - 141.67080462386528 - 387.9102466539773 - 157.05710355431236 - 215.88066088251708 - 273.7412787156305 - 0.4292793027544586\n",
      "77 - random_11 - deep - 152.87669865929158 - 498.9816036487527 - 156.25594332808853 - 472.58464118069105 - 150.75741988842657 - 286.285171241492 - 0.4031266555463996\n",
      "78 - random_70 - deep - 187.49950451499055 - 160.10357839931038 - 152.40089890881077 - 472.4525561201043 - 467.87971077102713 - 288.0235480358472 - 0.3995023296105932\n",
      "79 - random_72 - deep - 205.18874024114854 - 243.90843077112117 - 635.4182856421879 - 232.66252412830366 - 149.32667355577485 - 293.3254871819242 - 0.3884483650043056\n",
      "80 - random_23 - deep - 181.14561097866488 - 514.9816022025087 - 170.038321487619 - 472.512864423113 - 173.26917229294062 - 302.384593748075 - 0.3695611162849547\n",
      "81 - random_89 - deep - 466.10016369833943 - 513.9313962097717 - 477.69780327076677 - 472.3927264265081 - 467.86279575306685 - 479.5992494363184 - 8.789569117728657e-05\n",
      "82 - random_68 - deep - 466.5929696415453 - 516.1761393326803 - 477.69639091285745 - 472.39263967305675 - 467.87135232510974 - 480.14830461973656 - -0.0010568244569015839\n",
      "83 - random_85 - deep - 189.664187206504 - 2002.3053440581416 - 172.63422487621617 - 142.53825361931882 - 162.46052386408664 - 534.0120498519592 - -0.11335685600283818\n",
      "84 - random_13 - deep - 684.0451448894792 - 513.7775837898827 - 663.1098745216777 - 713.0094548073135 - 490.8966737818174 - 612.9703903896211 - -0.2779763806008002\n",
      "85 - random_50 - deep - 160.36521464017744 - 157.49689449317168 - 2884.4273858851275 - 152.93569041386087 - 159.3630966424656 - 703.0488874300769 - -0.46578021814758475\n",
      "86 - random_26 - deep - 466.1744460647665 - 514.5890979640986 - 477.68216640790496 - 1624.6619264893457 - 468.0707411382522 - 710.1549983181146 - -0.48059568397631747\n",
      "87 - random_3 - deep - 2762.2157660508915 - 152.03450223651558 - 477.6611929963861 - 134.97366123268154 - 163.90448042925667 - 738.2992173620416 - -0.5392733097678863\n",
      "88 - random_2 - deep - 148.015276594797 - 145.04986391027458 - 1801.2777444511098 - 1415.5632643682472 - 208.26263287602637 - 743.6173708804092 - -0.5503610795711924\n",
      "89 - random_92 - deep - 2781.880973683193 - 160.88361652010417 - 161.82161745942133 - 474.5243501697554 - 153.89610513089514 - 746.7051138217261 - -0.5567986866893138\n",
      "90 - random_58 - deep - 152.50841684804823 - 146.70903570750693 - 2853.6657045544016 - 471.6211347820378 - 152.60657100059262 - 755.5285603548361 - -0.5751946099534722\n",
      "91 - random_53 - deep - 152.05613927949884 - 326.86451718445375 - 421.2239868402052 - 200.31568483716728 - 2693.718315793114 - 758.6705613181265 - -0.5817453391271239\n",
      "92 - random_41 - deep - 155.9941819882636 - 192.3752413579784 - 477.6774804310378 - 181.3127581721165 - 2854.716855418925 - 772.2363557107115 - -0.6100285402239836\n",
      "93 - random_31 - deep - 1270.8496071781738 - 159.0032286206333 - 162.1829776523638 - 1935.4499854629353 - 1409.312398518978 - 987.1952277860047 - -1.0581943335801665\n",
      "94 - random_49 - deep - 395.3791950651465 - 602.4050220473483 - 2530.0331304832785 - 495.751736607729 - 1791.4050561142426 - 1162.9994843727166 - -1.424727025940872\n",
      "95 - random_48 - deep - 1020.651579016472 - 1222.5734120753975 - 183.74350586349405 - 1977.4979138139631 - 2254.889812785466 - 1331.6829908161287 - -1.7764137312229638\n",
      "96 - random_97 - deep - 665.7361578801183 - 2592.074283776057 - 2368.449622599894 - 471.79004052792993 - 1080.923870585832 - 1435.9530618911933 - -1.993805452139204\n",
      "97 - random_38 - deep - 162.02848151835698 - 177.5097919869151 - 2554.732763701166 - 2431.4705829597465 - 2674.5695529676714 - 1599.8335232421664 - -2.3354783324807538\n",
      "98 - random_52 - deep - 1543.3301443593118 - 164.7967505131786 - 3121.0219840797467 - 2846.5280823266808 - 2159.3965115587253 - 1966.8860678431233 - -3.1007428375758224\n",
      "99 - random_43 - deep - 339.4360802735693 - 2904.689921634814 - 2874.169992539578 - 2686.9450581013657 - 2789.4853359556714 - 2318.8446419293336 - -3.8345380611040127\n"
     ]
    }
   ],
   "source": [
    "scores_df_sorted = pd.DataFrame(all_scores).sort_values(by='MSE')\n",
    "n = 30\n",
    "best_n = []\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    print(s)\n",
    "    if i < n:\n",
    "        best_n.append(row['model_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% lwr part\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34af49806164ba5bc0989250b279c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_0'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:148.0664,knn_ttm_n=5:105.5902,knn_tta_r_n=5:144.1748,knn_ttm_r_n=5:197.1219,knn_tta_n=10:196.3511,knn_ttm_n=10:162.6592,knn_tta_r_n=10:199.7318,knn_ttm_r_n=10:205.5867,knn_tta_n=20:227.2585,knn_ttm_n=20:208.4482,knn_tta_r_n=20:229.7561,knn_ttm_r_n=20:225.5881,knn_tta_n=50:249.3085,knn_ttm_n=50:249.495,knn_tta_r_n=50:249.2732,knn_ttm_r_n=50:245.3054,knn_tta_n=100:257.6136,knn_ttm_n=100:266.7268,knn_tta_r_n=100:256.3324,knn_ttm_r_n=100:254.3579'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:385.8147,knn_ttm_n=5:439.3799,knn_tta_r_n=5:311.0836,knn_ttm_r_n=5:335.7976,knn_tta_n=10:335.8011,knn_ttm_n=10:395.2473,knn_tta_r_n=10:294.1917,knn_ttm_r_n=10:305.7211,knn_tta_n=20:309.7378,knn_ttm_n=20:358.1524,knn_tta_r_n=20:287.0192,knn_ttm_r_n=20:294.1251,knn_tta_n=50:292.3337,knn_ttm_n=50:326.6447,knn_tta_r_n=50:281.8397,knn_ttm_r_n=50:285.8126,knn_tta_n=100:284.4203,knn_ttm_n=100:312.0187,knn_tta_r_n=100:279.9122,knn_ttm_r_n=100:282.5414'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:184.0364,knn_ttm_n=5:152.389,knn_tta_r_n=5:187.4107,knn_ttm_r_n=5:260.7906,knn_tta_n=10:247.2254,knn_ttm_n=10:236.8034,knn_tta_r_n=10:261.4185,knn_ttm_r_n=10:276.9123,knn_tta_n=20:290.4164,knn_ttm_n=20:300.4678,knn_tta_r_n=20:304.2484,knn_ttm_r_n=20:303.2927,knn_tta_n=50:322.4155,knn_ttm_n=50:353.9353,knn_tta_r_n=50:335.7236,knn_ttm_r_n=50:331.615,knn_tta_n=100:336.9748,knn_ttm_n=100:374.5385,knn_tta_r_n=100:350.9881,knn_ttm_r_n=100:346.8648'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:453.8609,knn_ttm_n=5:531.8507,knn_tta_r_n=5:388.1308,knn_ttm_r_n=5:421.6707,knn_tta_n=10:403.9496,knn_ttm_n=10:490.2036,knn_tta_r_n=10:371.6515,knn_ttm_r_n=10:391.8831,knn_tta_n=20:384.6328,knn_ttm_n=20:465.6882,knn_tta_r_n=20:367.9273,knn_ttm_r_n=20:380.8156,knn_tta_n=50:373.7773,knn_ttm_n=50:441.4145,knn_tta_r_n=50:374.4726,knn_ttm_r_n=50:378.3096,knn_tta_n=100:371.0088,knn_ttm_n=100:430.2383,knn_tta_r_n=100:381.4617,knn_ttm_r_n=100:382.2532'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:186.0637,knn_ttm_n=5:143.668,knn_tta_r_n=5:181.4296,knn_ttm_r_n=5:254.8756,knn_tta_n=10:253.2412,knn_ttm_n=10:226.4688,knn_tta_r_n=10:255.0729,knn_ttm_r_n=10:272.2949,knn_tta_n=20:290.8863,knn_ttm_n=20:288.7671,knn_tta_r_n=20:299.9616,knn_ttm_r_n=20:300.5322,knn_tta_n=50:321.8701,knn_ttm_n=50:339.8609,knn_tta_r_n=50:332.8984,knn_ttm_r_n=50:329.9149,knn_tta_n=100:336.6751,knn_ttm_n=100:365.544,knn_tta_r_n=100:351.2312,knn_ttm_r_n=100:347.3002'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:451.0803,knn_ttm_n=5:503.4451,knn_tta_r_n=5:391.0339,knn_ttm_r_n=5:438.5042,knn_tta_n=10:403.7782,knn_ttm_n=10:474.8147,knn_tta_r_n=10:373.7855,knn_ttm_r_n=10:395.8301,knn_tta_n=20:372.3546,knn_ttm_n=20:438.9104,knn_tta_r_n=20:361.7736,knn_ttm_r_n=20:379.5789,knn_tta_n=50:362.4363,knn_ttm_n=50:410.3817,knn_tta_r_n=50:364.9301,knn_ttm_r_n=50:372.6086,knn_tta_n=100:362.9511,knn_ttm_n=100:406.5268,knn_tta_r_n=100:371.7351,knn_ttm_r_n=100:375.0147'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:114.8674,knn_ttm_n=5:83.3517,knn_tta_r_n=5:112.6464,knn_ttm_r_n=5:152.9246,knn_tta_n=10:148.7461,knn_ttm_n=10:119.2615,knn_tta_r_n=10:151.8994,knn_ttm_r_n=10:155.6391,knn_tta_n=20:169.7638,knn_ttm_n=20:145.4148,knn_tta_r_n=20:175.5968,knn_ttm_r_n=20:169.5502,knn_tta_n=50:184.6547,knn_ttm_n=50:170.4263,knn_tta_r_n=50:190.2424,knn_ttm_r_n=50:185.2483,knn_tta_n=100:191.4635,knn_ttm_n=100:182.7183,knn_tta_r_n=100:196.0324,knn_ttm_r_n=100:192.2213'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:290.8134,knn_ttm_n=5:368.165,knn_tta_r_n=5:212.4956,knn_ttm_r_n=5:225.8719,knn_tta_n=10:236.7976,knn_ttm_n=10:300.6906,knn_tta_r_n=10:203.6024,knn_ttm_r_n=10:209.0572,knn_tta_n=20:209.8122,knn_ttm_n=20:247.531,knn_tta_r_n=20:197.9237,knn_ttm_r_n=20:201.5026,knn_tta_n=50:197.2511,knn_ttm_n=50:213.7967,knn_tta_r_n=50:194.4696,knn_ttm_r_n=50:196.8943,knn_tta_n=100:191.8427,knn_ttm_n=100:200.0215,knn_tta_r_n=100:192.9303,knn_ttm_r_n=100:194.1534'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:112.8333,knn_ttm_n=5:80.4734,knn_tta_r_n=5:113.3436,knn_ttm_r_n=5:156.0473,knn_tta_n=10:154.5459,knn_ttm_n=10:120.7275,knn_tta_r_n=10:160.3928,knn_ttm_r_n=10:162.0454,knn_tta_n=20:179.2859,knn_ttm_n=20:155.6756,knn_tta_r_n=20:185.6586,knn_ttm_r_n=20:179.2615,knn_tta_n=50:196.9519,knn_ttm_n=50:185.4964,knn_tta_r_n=50:203.6943,knn_ttm_r_n=50:197.3432,knn_tta_n=100:206.4145,knn_ttm_n=100:200.1678,knn_tta_r_n=100:211.1122,knn_ttm_r_n=100:206.3974'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:303.3211,knn_ttm_n=5:361.5284,knn_tta_r_n=5:226.1941,knn_ttm_r_n=5:239.8779,knn_tta_n=10:257.4736,knn_ttm_n=10:315.9973,knn_tta_r_n=10:217.2938,knn_ttm_r_n=10:221.0444,knn_tta_n=20:238.5357,knn_ttm_n=20:279.706,knn_tta_r_n=20:213.3466,knn_ttm_r_n=20:215.7483,knn_tta_n=50:224.87,knn_ttm_n=50:251.1737,knn_tta_r_n=50:211.9165,knn_ttm_r_n=50:212.0231,knn_tta_n=100:219.7247,knn_ttm_n=100:237.9327,knn_tta_r_n=100:212.1451,knn_ttm_r_n=100:211.3835'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:70.6537,knn_ttm_n=5:46.1758,knn_tta_r_n=5:70.8211,knn_ttm_r_n=5:95.4145,knn_tta_n=10:94.3881,knn_ttm_n=10:71.1719,knn_tta_r_n=10:98.0656,knn_ttm_r_n=10:99.0883,knn_tta_n=20:108.9236,knn_ttm_n=20:90.2995,knn_tta_r_n=20:112.7019,knn_ttm_r_n=20:108.9008,knn_tta_n=50:119.3058,knn_ttm_n=50:110.1007,knn_tta_r_n=50:122.9512,knn_ttm_r_n=50:119.3243,knn_tta_n=100:123.5333,knn_ttm_n=100:119.1978,knn_tta_r_n=100:127.3116,knn_ttm_r_n=100:124.4061'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:191.9866,knn_ttm_n=5:233.1535,knn_tta_r_n=5:154.5079,knn_ttm_r_n=5:164.196,knn_tta_n=10:166.1675,knn_ttm_n=10:198.0738,knn_tta_r_n=10:146.695,knn_ttm_r_n=10:151.4469,knn_tta_n=20:149.0707,knn_ttm_n=20:169.5229,knn_tta_r_n=20:144.012,knn_ttm_r_n=20:146.768,knn_tta_n=50:144.3308,knn_ttm_n=50:152.3441,knn_tta_r_n=50:143.214,knn_ttm_r_n=50:143.98,knn_tta_n=100:142.0994,knn_ttm_n=100:147.1748,knn_tta_r_n=100:144.2588,knn_ttm_r_n=100:143.8921'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_4'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:113.0832,knn_ttm_n=5:62.5068,knn_tta_r_n=5:121.3245,knn_ttm_r_n=5:170.1177,knn_tta_n=10:156.0348,knn_ttm_n=10:101.2297,knn_tta_r_n=10:175.7723,knn_ttm_r_n=10:174.5502,knn_tta_n=20:189.7063,knn_ttm_n=20:139.3066,knn_tta_r_n=20:211.2593,knn_ttm_r_n=20:196.8092,knn_tta_n=50:218.1311,knn_ttm_n=50:185.4821,knn_tta_r_n=50:237.7789,knn_ttm_r_n=50:226.1497,knn_tta_n=100:236.4837,knn_ttm_n=100:215.4173,knn_tta_r_n=100:251.8312,knn_ttm_r_n=100:242.7588'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:334.6771,knn_ttm_n=5:383.7,knn_tta_r_n=5:280.0124,knn_ttm_r_n=5:292.2835,knn_tta_n=10:299.3343,knn_ttm_n=10:341.3357,knn_tta_r_n=10:273.8963,knn_ttm_r_n=10:278.1972,knn_tta_n=20:272.3212,knn_ttm_n=20:301.5187,knn_tta_r_n=20:272.5612,knn_ttm_r_n=20:275.7459,knn_tta_n=50:267.1824,knn_ttm_n=50:274.4431,knn_tta_r_n=50:277.996,knn_ttm_r_n=50:276.3685,knn_tta_n=100:268.6666,knn_ttm_n=100:269.2247,knn_tta_r_n=100:282.8253,knn_ttm_r_n=100:281.1043'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:125.5779,knn_ttm_n=5:75.1161,knn_tta_r_n=5:142.7243,knn_ttm_r_n=5:198.7345,knn_tta_n=10:178.869,knn_ttm_n=10:134.9263,knn_tta_r_n=10:212.3161,knn_ttm_r_n=10:215.3173,knn_tta_n=20:221.6591,knn_ttm_n=20:190.1862,knn_tta_r_n=20:263.8387,knn_ttm_r_n=20:247.7768,knn_tta_n=50:262.1756,knn_ttm_n=50:253.9738,knn_tta_r_n=50:313.4574,knn_ttm_r_n=50:294.6076,knn_tta_n=100:293.461,knn_ttm_n=100:296.8856,knn_tta_r_n=100:346.2265,knn_ttm_r_n=100:329.1117'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:339.1802,knn_ttm_n=5:378.25,knn_tta_r_n=5:339.9292,knn_ttm_r_n=5:367.6192,knn_tta_n=10:302.4431,knn_ttm_n=10:345.4217,knn_tta_r_n=10:332.6154,knn_ttm_r_n=10:346.5893,knn_tta_n=20:292.0526,knn_ttm_n=20:322.2221,knn_tta_r_n=20:335.8396,knn_ttm_r_n=20:341.9066,knn_tta_n=50:302.3638,knn_ttm_n=50:325.3734,knn_tta_r_n=50:355.953,knn_ttm_r_n=50:351.6958,knn_tta_n=100:325.4136,knn_ttm_n=100:343.2434,knn_tta_r_n=100:379.8454,knn_ttm_r_n=100:370.0068'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:133.4311,knn_ttm_n=5:78.8226,knn_tta_r_n=5:138.1387,knn_ttm_r_n=5:195.5413,knn_tta_n=10:187.3595,knn_ttm_n=10:140.3655,knn_tta_r_n=10:209.1494,knn_ttm_r_n=10:216.4911,knn_tta_n=20:227.6546,knn_ttm_n=20:195.2291,knn_tta_r_n=20:259.445,knn_ttm_r_n=20:249.2358,knn_tta_n=50:269.9671,knn_ttm_n=50:259.3187,knn_tta_r_n=50:309.928,knn_ttm_r_n=50:295.3226,knn_tta_n=100:303.1523,knn_ttm_n=100:304.158,knn_tta_r_n=100:345.865,knn_ttm_r_n=100:330.6028'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:340.4279,knn_ttm_n=5:394.7169,knn_tta_r_n=5:330.6342,knn_ttm_r_n=5:366.3981,knn_tta_n=10:323.8282,knn_ttm_n=10:362.3951,knn_tta_r_n=10:320.8121,knn_ttm_r_n=10:340.4311,knn_tta_n=20:310.7385,knn_ttm_n=20:347.3895,knn_tta_r_n=20:323.4777,knn_ttm_r_n=20:332.6183,knn_tta_n=50:314.7042,knn_ttm_n=50:342.2329,knn_tta_r_n=50:346.6955,knn_ttm_r_n=50:343.4511,knn_tta_n=100:332.4149,knn_ttm_n=100:355.157,knn_tta_r_n=100:371.7643,knn_ttm_r_n=100:363.0614'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:101.9979,knn_ttm_n=5:53.1445,knn_tta_r_n=5:108.1598,knn_ttm_r_n=5:147.9283,knn_tta_n=10:146.8218,knn_ttm_n=10:92.82,knn_tta_r_n=10:154.2246,knn_ttm_r_n=10:150.8819,knn_tta_n=20:175.6008,knn_ttm_n=20:129.7829,knn_tta_r_n=20:182.7602,knn_ttm_r_n=20:167.9301,knn_tta_n=50:196.9156,knn_ttm_n=50:170.4111,knn_tta_r_n=50:201.758,knn_ttm_r_n=50:191.1734,knn_tta_n=100:206.8789,knn_ttm_n=100:193.1255,knn_tta_r_n=100:209.2991,knn_ttm_r_n=100:202.8903'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:291.4631,knn_ttm_n=5:339.6751,knn_tta_r_n=5:220.2366,knn_ttm_r_n=5:232.6414,knn_tta_n=10:248.8414,knn_ttm_n=10:295.0593,knn_tta_r_n=10:207.3787,knn_ttm_r_n=10:216.3501,knn_tta_n=20:223.5789,knn_ttm_n=20:258.9154,knn_tta_r_n=20:204.9287,knn_ttm_r_n=20:206.7949,knn_tta_n=50:211.9279,knn_ttm_n=50:229.709,knn_tta_r_n=50:204.8094,knn_ttm_r_n=50:205.0989,knn_tta_n=100:209.7295,knn_ttm_n=100:219.5597,knn_tta_r_n=100:206.8508,knn_ttm_r_n=100:205.8927'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:110.8151,knn_ttm_n=5:64.0331,knn_tta_r_n=5:116.771,knn_ttm_r_n=5:161.1264,knn_tta_n=10:149.5859,knn_ttm_n=10:100.3382,knn_tta_r_n=10:165.2293,knn_ttm_r_n=10:165.5222,knn_tta_n=20:181.5018,knn_ttm_n=20:135.5353,knn_tta_r_n=20:198.5552,knn_ttm_r_n=20:184.4069,knn_tta_n=50:210.825,knn_ttm_n=50:181.9266,knn_tta_r_n=50:221.4798,knn_ttm_r_n=50:209.9083,knn_tta_n=100:225.1636,knn_ttm_n=100:210.8878,knn_tta_r_n=100:231.6124,knn_ttm_r_n=100:223.4215'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:295.2623,knn_ttm_n=5:351.1865,knn_tta_r_n=5:226.2434,knn_ttm_r_n=5:242.3131,knn_tta_n=10:259.8514,knn_ttm_n=10:301.3967,knn_tta_r_n=10:221.7387,knn_ttm_r_n=10:225.4003,knn_tta_n=20:238.6747,knn_ttm_n=20:265.6256,knn_tta_r_n=20:223.9203,knn_ttm_r_n=20:223.1005,knn_tta_n=50:225.4774,knn_ttm_n=50:243.7705,knn_tta_r_n=50:222.3642,knn_ttm_r_n=50:222.7664,knn_tta_n=100:224.1629,knn_ttm_n=100:235.5133,knn_tta_r_n=100:223.8874,knn_ttm_r_n=100:222.9908'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:71.2745,knn_ttm_n=5:38.295,knn_tta_r_n=5:71.1601,knn_ttm_r_n=5:98.1688,knn_tta_n=10:98.0395,knn_ttm_n=10:60.4345,knn_tta_r_n=10:101.9237,knn_ttm_r_n=10:97.9283,knn_tta_n=20:114.8487,knn_ttm_n=20:83.0273,knn_tta_r_n=20:119.7152,knn_ttm_r_n=20:109.9653,knn_tta_n=50:128.6912,knn_ttm_n=50:113.6752,knn_tta_r_n=50:130.8776,knn_ttm_r_n=50:124.7244,knn_tta_n=100:134.1617,knn_ttm_n=100:127.8986,knn_tta_r_n=100:135.5984,knn_ttm_r_n=100:131.8152'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:220.6651,knn_ttm_n=5:255.0944,knn_tta_r_n=5:155.2891,knn_ttm_r_n=5:162.7157,knn_tta_n=10:185.5359,knn_ttm_n=10:223.2702,knn_tta_r_n=10:150.9889,knn_ttm_r_n=10:154.4262,knn_tta_n=20:167.0879,knn_ttm_n=20:194.0456,knn_tta_r_n=20:148.439,knn_ttm_r_n=20:149.1756,knn_tta_n=50:156.294,knn_ttm_n=50:170.0979,knn_tta_r_n=50:148.2005,knn_ttm_r_n=50:147.5168,knn_tta_n=100:150.8497,knn_ttm_n=100:160.4262,knn_tta_r_n=100:148.0265,knn_ttm_r_n=100:147.7006'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_8'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:168.1953,knn_ttm_n=5:148.6121,knn_tta_r_n=5:161.7934,knn_ttm_r_n=5:218.4921,knn_tta_n=10:212.5715,knn_ttm_n=10:203.6083,knn_tta_r_n=10:213.8971,knn_ttm_r_n=10:228.4823,knn_tta_n=20:237.7617,knn_ttm_n=20:237.6897,knn_tta_r_n=20:240.0783,knn_ttm_r_n=20:243.9162,knn_tta_n=50:252.8958,knn_ttm_n=50:260.7586,knn_tta_r_n=50:254.9357,knn_ttm_r_n=50:256.1785,knn_tta_n=100:260.5903,knn_ttm_n=100:271.0434,knn_tta_r_n=100:262.0319,knn_ttm_r_n=100:261.8017'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:378.4288,knn_ttm_n=5:454.7002,knn_tta_r_n=5:313.3429,knn_ttm_r_n=5:343.4109,knn_tta_n=10:330.6929,knn_ttm_n=10:402.4219,knn_tta_r_n=10:297.6092,knn_ttm_r_n=10:310.6115,knn_tta_n=20:308.4203,knn_ttm_n=20:357.444,knn_tta_r_n=20:290.037,knn_ttm_r_n=20:297.6282,knn_tta_n=50:296.6934,knn_ttm_n=50:325.9457,knn_tta_r_n=50:286.8269,knn_ttm_r_n=50:291.3203,knn_tta_n=100:292.5841,knn_ttm_n=100:317.0403,knn_tta_r_n=100:286.9087,knn_ttm_r_n=100:289.1979'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:250.4224,knn_ttm_n=5:240.3996,knn_tta_r_n=5:242.8849,knn_ttm_r_n=5:331.3991,knn_tta_n=10:323.5138,knn_ttm_n=10:347.5698,knn_tta_r_n=10:323.8419,knn_ttm_r_n=10:348.8282,knn_tta_n=20:365.6066,knn_ttm_n=20:410.8417,knn_tta_r_n=20:364.917,knn_ttm_r_n=20:373.3403,knn_tta_n=50:389.4822,knn_ttm_n=50:456.3529,knn_tta_r_n=50:388.3795,knn_ttm_r_n=50:392.8297,knn_tta_n=100:396.8717,knn_ttm_n=100:467.7429,knn_tta_r_n=100:397.6729,knn_ttm_r_n=100:401.3968'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:610.3175,knn_ttm_n=5:742.2112,knn_tta_r_n=5:489.0751,knn_ttm_r_n=5:528.433,knn_tta_n=10:531.6523,knn_ttm_n=10:672.2796,knn_tta_r_n=10:456.7759,knn_ttm_r_n=10:482.8884,knn_tta_n=20:482.9144,knn_ttm_n=20:606.5312,knn_tta_r_n=20:441.7262,knn_ttm_r_n=20:456.8096,knn_tta_n=50:454.6332,knn_ttm_n=50:558.9989,knn_tta_r_n=50:432.9287,knn_ttm_r_n=50:442.7424,knn_tta_n=100:439.3107,knn_ttm_n=100:531.5632,knn_tta_r_n=100:431.1168,knn_ttm_r_n=100:438.1423'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:243.1016,knn_ttm_n=5:243.874,knn_tta_r_n=5:243.731,knn_ttm_r_n=5:336.7915,knn_tta_n=10:323.5171,knn_ttm_n=10:361.5928,knn_tta_r_n=10:325.6253,knn_ttm_r_n=10:361.0524,knn_tta_n=20:368.1412,knn_ttm_n=20:427.0064,knn_tta_r_n=20:368.3139,knn_ttm_r_n=20:383.0523,knn_tta_n=50:400.225,knn_ttm_n=50:481.6786,knn_tta_r_n=50:394.3539,knn_ttm_r_n=50:401.8571,knn_tta_n=100:407.5609,knn_ttm_n=100:500.9719,knn_tta_r_n=100:404.3294,knn_ttm_r_n=100:409.9997'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:617.0249,knn_ttm_n=5:752.7437,knn_tta_r_n=5:496.3388,knn_ttm_r_n=5:541.9448,knn_tta_n=10:531.5567,knn_ttm_n=10:677.0028,knn_tta_r_n=10:461.8619,knn_ttm_r_n=10:493.4087,knn_tta_n=20:485.0355,knn_ttm_n=20:621.8038,knn_tta_r_n=20:443.0166,knn_ttm_r_n=20:465.3926,knn_tta_n=50:461.7906,knn_ttm_n=50:583.0857,knn_tta_r_n=50:436.4814,knn_ttm_r_n=50:449.4958,knn_tta_n=100:448.4403,knn_ttm_n=100:567.9863,knn_tta_r_n=100:435.9021,knn_ttm_r_n=100:444.4027'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:124.1982,knn_ttm_n=5:100.6334,knn_tta_r_n=5:121.5272,knn_ttm_r_n=5:163.6002,knn_tta_n=10:164.576,knn_ttm_n=10:147.8792,knn_tta_r_n=10:166.3754,knn_ttm_r_n=10:173.7055,knn_tta_n=20:187.5529,knn_ttm_n=20:179.8047,knn_tta_r_n=20:189.4431,knn_ttm_r_n=20:188.7635,knn_tta_n=50:202.2621,knn_ttm_n=50:200.3815,knn_tta_r_n=50:202.9076,knn_ttm_r_n=50:201.0565,knn_tta_n=100:206.3419,knn_ttm_n=100:208.0242,knn_tta_r_n=100:207.6424,knn_ttm_r_n=100:205.9053'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:302.2273,knn_ttm_n=5:382.8377,knn_tta_r_n=5:227.9347,knn_ttm_r_n=5:234.7518,knn_tta_n=10:252.3023,knn_ttm_n=10:317.6323,knn_tta_r_n=10:213.4333,knn_ttm_r_n=10:218.5925,knn_tta_n=20:225.2657,knn_ttm_n=20:271.7866,knn_tta_r_n=20:209.1444,knn_ttm_r_n=20:211.573,knn_tta_n=50:211.9741,knn_ttm_n=50:233.5667,knn_tta_r_n=50:207.33,knn_ttm_r_n=50:208.1963,knn_tta_n=100:210.1802,knn_ttm_n=100:221.7641,knn_tta_r_n=100:208.1905,knn_ttm_r_n=100:208.2326'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:138.654,knn_ttm_n=5:124.0148,knn_tta_r_n=5:133.5302,knn_ttm_r_n=5:179.4515,knn_tta_n=10:177.593,knn_ttm_n=10:176.8961,knn_tta_r_n=10:176.6097,knn_ttm_r_n=10:188.744,knn_tta_n=20:198.1048,knn_ttm_n=20:205.216,knn_tta_r_n=20:199.9437,knn_ttm_r_n=20:201.0787,knn_tta_n=50:212.3214,knn_ttm_n=50:223.1562,knn_tta_r_n=50:213.5234,knn_ttm_r_n=50:212.5531,knn_tta_n=100:217.6118,knn_ttm_n=100:229.2821,knn_tta_r_n=100:218.6281,knn_ttm_r_n=100:217.9437'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:321.4424,knn_ttm_n=5:408.1597,knn_tta_r_n=5:239.8928,knn_ttm_r_n=5:247.551,knn_tta_n=10:272.6167,knn_ttm_n=10:346.5901,knn_tta_r_n=10:229.4161,knn_ttm_r_n=10:232.7357,knn_tta_n=20:248.6869,knn_ttm_n=20:302.1794,knn_tta_r_n=20:222.8408,knn_ttm_r_n=20:224.9674,knn_tta_n=50:234.8416,knn_ttm_n=50:276.3367,knn_tta_r_n=50:220.9821,knn_ttm_r_n=50:221.2687,knn_tta_n=100:228.9173,knn_ttm_n=100:257.85,knn_tta_r_n=100:221.1409,knn_ttm_r_n=100:220.787'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:76.5432,knn_ttm_n=5:65.4868,knn_tta_r_n=5:75.759,knn_ttm_r_n=5:101.054,knn_tta_n=10:100.4041,knn_ttm_n=10:91.0784,knn_tta_r_n=10:102.4247,knn_ttm_r_n=10:107.5947,knn_tta_n=20:113.6212,knn_ttm_n=20:109.9502,knn_tta_r_n=20:116.3019,knn_ttm_r_n=20:116.7449,knn_tta_n=50:122.586,knn_ttm_n=50:123.9997,knn_tta_r_n=50:124.8405,knn_ttm_r_n=50:123.9676,knn_tta_n=100:125.7611,knn_ttm_n=100:127.9542,knn_tta_r_n=100:128.6559,knn_ttm_r_n=100:127.5127'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:210.58,knn_ttm_n=5:258.6589,knn_tta_r_n=5:169.3705,knn_ttm_r_n=5:178.5574,knn_tta_n=10:183.1441,knn_ttm_n=10:220.5088,knn_tta_r_n=10:162.1853,knn_ttm_r_n=10:165.993,knn_tta_n=20:166.637,knn_ttm_n=20:192.8484,knn_tta_r_n=20:157.6299,knn_ttm_r_n=20:160.034,knn_tta_n=50:157.6604,knn_ttm_n=50:170.8912,knn_tta_r_n=50:156.3159,knn_ttm_r_n=50:156.7858,knn_tta_n=100:154.7119,knn_ttm_n=100:161.4996,knn_tta_r_n=100:156.492,knn_ttm_r_n=100:156.3127'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_10'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:135.6963,knn_ttm_n=5:83.2149,knn_tta_r_n=5:143.076,knn_ttm_r_n=5:193.7304,knn_tta_n=10:186.8162,knn_ttm_n=10:132.5864,knn_tta_r_n=10:204.653,knn_ttm_r_n=10:204.1054,knn_tta_n=20:224.1468,knn_ttm_n=20:181.3696,knn_tta_r_n=20:242.1425,knn_ttm_r_n=20:229.9771,knn_tta_n=50:258.4404,knn_ttm_n=50:238.9465,knn_tta_r_n=50:271.7467,knn_ttm_r_n=50:262.0437,knn_tta_n=100:276.1563,knn_ttm_n=100:272.7635,knn_tta_r_n=100:283.8122,knn_ttm_r_n=100:277.7593'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:396.2926,knn_ttm_n=5:448.883,knn_tta_r_n=5:322.427,knn_ttm_r_n=5:345.8814,knn_tta_n=10:354.0493,knn_ttm_n=10:404.2036,knn_tta_r_n=10:319.3701,knn_ttm_r_n=10:329.7066,knn_tta_n=20:327.9816,knn_ttm_n=20:364.0212,knn_tta_r_n=20:313.4745,knn_ttm_r_n=20:321.3863,knn_tta_n=50:316.2589,knn_ttm_n=50:341.8258,knn_tta_r_n=50:312.5775,knn_ttm_r_n=50:315.5116,knn_tta_n=100:315.4482,knn_ttm_n=100:336.9333,knn_tta_r_n=100:314.2943,knn_ttm_r_n=100:315.2068'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:184.3774,knn_ttm_n=5:132.5307,knn_tta_r_n=5:187.1541,knn_ttm_r_n=5:253.1708,knn_tta_n=10:256.9532,knn_ttm_n=10:227.5255,knn_tta_r_n=10:268.7448,knn_ttm_r_n=10:269.412,knn_tta_n=20:309.0387,knn_ttm_n=20:306.626,knn_tta_r_n=20:318.928,knn_ttm_r_n=20:302.9726,knn_tta_n=50:349.5501,knn_ttm_n=50:385.4509,knn_tta_r_n=50:355.7309,knn_ttm_r_n=50:342.8902,knn_tta_n=100:372.6555,knn_ttm_n=100:430.6506,knn_tta_r_n=100:376.925,knn_ttm_r_n=100:367.1616'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:510.8279,knn_ttm_n=5:586.0956,knn_tta_r_n=5:420.7403,knn_ttm_r_n=5:455.443,knn_tta_n=10:462.0718,knn_ttm_n=10:549.86,knn_tta_r_n=10:400.7219,knn_ttm_r_n=10:418.6881,knn_tta_n=20:425.3628,knn_ttm_n=20:519.3611,knn_tta_r_n=20:393.7028,knn_ttm_r_n=20:402.8705,knn_tta_n=50:413.3788,knn_ttm_n=50:498.3708,knn_tta_r_n=50:397.8821,knn_ttm_r_n=50:398.5431,knn_tta_n=100:422.3799,knn_ttm_n=100:512.3933,knn_tta_r_n=100:410.7002,knn_ttm_r_n=100:407.6387'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:179.8945,knn_ttm_n=5:131.6662,knn_tta_r_n=5:190.073,knn_ttm_r_n=5:260.7018,knn_tta_n=10:255.7402,knn_ttm_n=10:222.0293,knn_tta_r_n=10:272.9661,knn_ttm_r_n=10:282.0788,knn_tta_n=20:310.802,knn_ttm_n=20:304.844,knn_tta_r_n=20:322.6052,knn_ttm_r_n=20:313.1376,knn_tta_n=50:352.6815,knn_ttm_n=50:381.8064,knn_tta_r_n=50:362.0211,knn_ttm_r_n=50:354.3962,knn_tta_n=100:381.3021,knn_ttm_n=100:427.2484,knn_tta_r_n=100:384.8685,knn_ttm_r_n=100:377.9657'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:458.9273,knn_ttm_n=5:524.3307,knn_tta_r_n=5:429.6878,knn_ttm_r_n=5:471.8973,knn_tta_n=10:418.8861,knn_ttm_n=10:480.0436,knn_tta_r_n=10:402.853,knn_ttm_r_n=10:434.2407,knn_tta_n=20:397.8402,knn_ttm_n=20:462.1875,knn_tta_r_n=20:393.5545,knn_ttm_r_n=20:409.6989,knn_tta_n=50:388.9876,knn_ttm_n=50:452.7194,knn_tta_r_n=50:395.2285,knn_ttm_r_n=50:401.7984,knn_tta_n=100:397.5724,knn_ttm_n=100:460.5186,knn_tta_r_n=100:405.5048,knn_ttm_r_n=100:407.182'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:101.8582,knn_ttm_n=5:63.2511,knn_tta_r_n=5:103.6751,knn_ttm_r_n=5:141.9082,knn_tta_n=10:137.593,knn_ttm_n=10:98.223,knn_tta_r_n=10:146.6548,knn_ttm_r_n=10:146.0149,knn_tta_n=20:162.162,knn_ttm_n=20:126.6815,knn_tta_r_n=20:173.2901,knn_ttm_r_n=20:163.288,knn_tta_n=50:185.5078,knn_ttm_n=50:163.4342,knn_tta_r_n=50:191.3476,knn_ttm_r_n=50:184.243,knn_tta_n=100:195.5205,knn_ttm_n=100:186.8576,knn_tta_r_n=100:198.239,knn_ttm_r_n=100:194.2144'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:300.3112,knn_ttm_n=5:359.4054,knn_tta_r_n=5:216.9908,knn_ttm_r_n=5:227.6841,knn_tta_n=10:255.363,knn_ttm_n=10:309.7815,knn_tta_r_n=10:209.9892,knn_ttm_r_n=10:214.2049,knn_tta_n=20:226.1162,knn_ttm_n=20:266.1197,knn_tta_r_n=20:206.0077,knn_ttm_r_n=20:209.2034,knn_tta_n=50:207.5588,knn_ttm_n=50:226.7795,knn_tta_r_n=50:203.1624,knn_ttm_r_n=50:204.2566,knn_tta_n=100:204.6961,knn_ttm_n=100:213.5164,knn_tta_r_n=100:202.9365,knn_ttm_r_n=100:203.2218'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:102.4853,knn_ttm_n=5:62.7685,knn_tta_r_n=5:112.6527,knn_ttm_r_n=5:157.2035,knn_tta_n=10:144.5401,knn_ttm_n=10:102.1014,knn_tta_r_n=10:160.1658,knn_ttm_r_n=10:161.9631,knn_tta_n=20:176.0248,knn_ttm_n=20:139.1688,knn_tta_r_n=20:190.441,knn_ttm_r_n=20:180.6397,knn_tta_n=50:202.332,knn_ttm_n=50:185.4844,knn_tta_r_n=50:210.0932,knn_ttm_r_n=50:203.1741,knn_tta_n=100:215.4929,knn_ttm_n=100:213.6881,knn_tta_r_n=100:219.1437,knn_ttm_r_n=100:214.5785'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:306.5825,knn_ttm_n=5:362.0592,knn_tta_r_n=5:226.8609,knn_ttm_r_n=5:240.5624,knn_tta_n=10:258.6859,knn_ttm_n=10:314.7798,knn_tta_r_n=10:222.9732,knn_ttm_r_n=10:226.7271,knn_tta_n=20:229.7138,knn_ttm_n=20:269.9056,knn_tta_r_n=20:218.6816,knn_ttm_r_n=20:222.0599,knn_tta_n=50:221.6077,knn_ttm_n=50:243.1037,knn_tta_r_n=50:217.5627,knn_ttm_r_n=50:219.2134,knn_tta_n=100:220.6008,knn_ttm_n=100:239.1022,knn_tta_r_n=100:218.6426,knn_ttm_r_n=100:218.9582'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:59.6613,knn_ttm_n=5:33.9951,knn_tta_r_n=5:57.2032,knn_ttm_r_n=5:76.4065,knn_tta_n=10:80.1642,knn_ttm_n=10:53.8341,knn_tta_r_n=10:81.51,knn_ttm_r_n=10:79.4268,knn_tta_n=20:91.3219,knn_ttm_n=20:70.8774,knn_tta_r_n=20:94.4097,knn_ttm_r_n=20:88.2448,knn_tta_n=50:100.6076,knn_ttm_n=50:90.0165,knn_tta_r_n=50:103.0474,knn_ttm_r_n=50:98.9714,knn_tta_n=100:105.2131,knn_ttm_n=100:99.6645,knn_tta_r_n=100:106.773,knn_ttm_r_n=100:104.1927'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:180.4706,knn_ttm_n=5:205.9188,knn_tta_r_n=5:146.1248,knn_ttm_r_n=5:152.3707,knn_tta_n=10:160.7249,knn_ttm_n=10:184.258,knn_tta_r_n=10:141.4265,knn_ttm_r_n=10:143.6532,knn_tta_n=20:151.2559,knn_ttm_n=20:166.6478,knn_tta_r_n=20:140.321,knn_ttm_r_n=20:141.206,knn_tta_n=50:145.5171,knn_ttm_n=50:152.5948,knn_tta_r_n=50:140.6356,knn_ttm_r_n=50:140.1047,knn_tta_n=100:143.5656,knn_ttm_n=100:147.9056,knn_tta_r_n=100:141.5384,knn_ttm_r_n=100:140.791'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_14'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:115.0727,knn_ttm_n=5:60.051,knn_tta_r_n=5:114.9632,knn_ttm_r_n=5:157.1017,knn_tta_n=10:157.5339,knn_ttm_n=10:98.8353,knn_tta_r_n=10:166.3927,knn_ttm_r_n=10:158.7674,knn_tta_n=20:188.1303,knn_ttm_n=20:137.0628,knn_tta_r_n=20:197.1213,knn_ttm_r_n=20:177.2532,knn_tta_n=50:218.0466,knn_ttm_n=50:186.7294,knn_tta_r_n=50:221.2472,knn_ttm_r_n=50:205.2002,knn_tta_n=100:231.5169,knn_ttm_n=100:215.727,knn_tta_r_n=100:232.425,knn_ttm_r_n=100:221.1172'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:314.7074,knn_ttm_n=5:349.6226,knn_tta_r_n=5:263.2763,knn_ttm_r_n=5:286.8627,knn_tta_n=10:289.698,knn_ttm_n=10:315.9705,knn_tta_r_n=10:259.6487,knn_ttm_r_n=10:265.5599,knn_tta_n=20:274.8724,knn_ttm_n=20:298.5381,knn_tta_r_n=20:255.0669,knn_ttm_r_n=20:258.5073,knn_tta_n=50:264.9104,knn_ttm_n=50:283.1399,knn_tta_r_n=50:256.5694,knn_ttm_r_n=50:255.7764,knn_tta_n=100:267.015,knn_ttm_n=100:278.1786,knn_tta_r_n=100:259.4153,knn_ttm_r_n=100:257.9291'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:142.8053,knn_ttm_n=5:78.0252,knn_tta_r_n=5:156.2983,knn_ttm_r_n=5:211.8085,knn_tta_n=10:201.4939,knn_ttm_n=10:142.2825,knn_tta_r_n=10:228.8043,knn_ttm_r_n=10:223.468,knn_tta_n=20:250.8701,knn_ttm_n=20:204.6728,knn_tta_r_n=20:277.109,knn_ttm_r_n=20:250.9694,knn_tta_n=50:296.0858,knn_ttm_n=50:281.3981,knn_tta_r_n=50:315.9971,knn_ttm_r_n=50:290.7321,knn_tta_n=100:318.2524,knn_ttm_n=100:327.1417,knn_tta_r_n=100:337.4303,knn_ttm_r_n=100:317.4866'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:376.5076,knn_ttm_n=5:421.9973,knn_tta_r_n=5:357.8436,knn_ttm_r_n=5:397.9396,knn_tta_n=10:348.0787,knn_ttm_n=10:382.0505,knn_tta_r_n=10:343.9805,knn_ttm_r_n=10:362.1983,knn_tta_n=20:339.249,knn_ttm_n=20:372.1097,knn_tta_r_n=20:347.9163,knn_ttm_r_n=20:354.7393,knn_tta_n=50:342.5547,knn_ttm_n=50:374.2521,knn_tta_r_n=50:358.5537,knn_ttm_r_n=50:355.3697,knn_tta_n=100:352.2501,knn_ttm_n=100:385.2996,knn_tta_r_n=100:368.5846,knn_ttm_r_n=100:362.1298'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:146.1973,knn_ttm_n=5:78.0651,knn_tta_r_n=5:153.2289,knn_ttm_r_n=5:217.9253,knn_tta_n=10:209.6562,knn_ttm_n=10:141.0162,knn_tta_r_n=10:228.4286,knn_ttm_r_n=10:221.8627,knn_tta_n=20:255.8536,knn_ttm_n=20:204.9343,knn_tta_r_n=20:277.4555,knn_ttm_r_n=20:251.7027,knn_tta_n=50:303.0834,knn_ttm_n=50:281.8142,knn_tta_r_n=50:321.1955,knn_ttm_r_n=50:295.94,knn_tta_n=100:331.8854,knn_ttm_n=100:329.4959,knn_tta_r_n=100:345.0959,knn_ttm_r_n=100:325.1005'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:383.0082,knn_ttm_n=5:419.393,knn_tta_r_n=5:383.8235,knn_ttm_r_n=5:417.8397,knn_tta_n=10:356.3071,knn_ttm_n=10:389.7601,knn_tta_r_n=10:364.0943,knn_ttm_r_n=10:387.1101,knn_tta_n=20:341.7863,knn_ttm_n=20:372.3541,knn_tta_r_n=20:357.7663,knn_ttm_r_n=20:370.0988,knn_tta_n=50:344.9787,knn_ttm_n=50:370.1492,knn_tta_r_n=50:357.2598,knn_ttm_r_n=50:357.6574,knn_tta_n=100:357.2949,knn_ttm_n=100:381.1747,knn_tta_r_n=100:368.73,knn_ttm_r_n=100:362.7582'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:96.159,knn_ttm_n=5:45.9153,knn_tta_r_n=5:96.4398,knn_ttm_r_n=5:131.5616,knn_tta_n=10:132.8539,knn_ttm_n=10:76.8822,knn_tta_r_n=10:138.0546,knn_ttm_r_n=10:129.8327,knn_tta_n=20:156.4672,knn_ttm_n=20:109.3217,knn_tta_r_n=20:163.6831,knn_ttm_r_n=20:144.895,knn_tta_n=50:177.8445,knn_ttm_n=50:148.4186,knn_tta_r_n=50:183.3544,knn_ttm_r_n=50:167.9577,knn_tta_n=100:188.9227,knn_ttm_n=100:171.8394,knn_tta_r_n=100:192.2835,knn_ttm_r_n=100:181.0423'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:250.8012,knn_ttm_n=5:288.7446,knn_tta_r_n=5:196.3819,knn_ttm_r_n=5:213.3585,knn_tta_n=10:223.8028,knn_ttm_n=10:254.0751,knn_tta_r_n=10:190.6428,knn_ttm_r_n=10:195.8977,knn_tta_n=20:202.8907,knn_ttm_n=20:227.1557,knn_tta_r_n=20:186.4577,knn_ttm_r_n=20:188.9838,knn_tta_n=50:190.5542,knn_ttm_n=50:205.3326,knn_tta_r_n=50:186.942,knn_ttm_r_n=50:186.0686,knn_tta_n=100:188.2029,knn_ttm_n=100:196.5036,knn_tta_r_n=100:189.2063,knn_ttm_r_n=100:186.3897'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:89.3328,knn_ttm_n=5:49.4451,knn_tta_r_n=5:93.3605,knn_ttm_r_n=5:125.6021,knn_tta_n=10:125.3189,knn_ttm_n=10:83.2899,knn_tta_r_n=10:135.0823,knn_ttm_r_n=10:127.7029,knn_tta_n=20:151.2991,knn_ttm_n=20:113.6395,knn_tta_r_n=20:161.6578,knn_ttm_r_n=20:145.5838,knn_tta_n=50:174.2618,knn_ttm_n=50:151.3805,knn_tta_r_n=50:180.7923,knn_ttm_r_n=50:167.1392,knn_tta_n=100:184.694,knn_ttm_n=100:172.8645,knn_tta_r_n=100:189.8405,knn_ttm_r_n=100:179.8059'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:259.3333,knn_ttm_n=5:292.0636,knn_tta_r_n=5:200.9046,knn_ttm_r_n=5:222.5217,knn_tta_n=10:231.8397,knn_ttm_n=10:262.2838,knn_tta_r_n=10:191.5388,knn_ttm_r_n=10:196.7749,knn_tta_n=20:210.2863,knn_ttm_n=20:238.1754,knn_tta_r_n=20:186.6541,knn_ttm_r_n=20:189.7798,knn_tta_n=50:200.6936,knn_ttm_n=50:219.5149,knn_tta_r_n=50:186.4716,knn_ttm_r_n=50:186.1542,knn_tta_n=100:197.3629,knn_ttm_n=100:214.548,knn_tta_r_n=100:188.4824,knn_ttm_r_n=100:186.2439'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:64.0866,knn_ttm_n=5:30.1041,knn_tta_r_n=5:63.1886,knn_ttm_r_n=5:85.2799,knn_tta_n=10:85.1833,knn_ttm_n=10:47.8242,knn_tta_r_n=10:89.4054,knn_ttm_r_n=10:84.5474,knn_tta_n=20:101.2557,knn_ttm_n=20:65.369,knn_tta_r_n=20:107.2198,knn_ttm_r_n=20:94.2637,knn_tta_n=50:115.4808,knn_ttm_n=50:90.3349,knn_tta_r_n=50:120.3908,knn_ttm_r_n=50:109.6226,knn_tta_n=100:123.4144,knn_ttm_n=100:106.6848,knn_tta_r_n=100:127.6244,knn_ttm_r_n=100:118.9074'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:206.9509,knn_ttm_n=5:236.7835,knn_tta_r_n=5:152.2944,knn_ttm_r_n=5:161.104,knn_tta_n=10:174.6133,knn_ttm_n=10:206.9038,knn_tta_r_n=10:146.9744,knn_ttm_r_n=10:149.8128,knn_tta_n=20:157.3945,knn_ttm_n=20:178.7375,knn_tta_r_n=20:144.5675,knn_ttm_r_n=20:146.3903,knn_tta_n=50:151.2436,knn_ttm_n=50:160.0072,knn_tta_r_n=50:146.0248,knn_ttm_r_n=50:144.5657,knn_tta_n=100:150.2658,knn_ttm_n=100:154.095,knn_tta_r_n=100:148.6909,knn_ttm_r_n=100:145.5765'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_18'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:105.6656,knn_ttm_n=5:54.775,knn_tta_r_n=5:108.9014,knn_ttm_r_n=5:147.8437,knn_tta_n=10:142.9229,knn_ttm_n=10:89.2068,knn_tta_r_n=10:156.5243,knn_ttm_r_n=10:151.5052,knn_tta_n=20:172.4257,knn_ttm_n=20:123.7737,knn_tta_r_n=20:186.5846,knn_ttm_r_n=20:171.0438,knn_tta_n=50:196.5356,knn_ttm_n=50:166.7766,knn_tta_r_n=50:207.8921,knn_ttm_r_n=50:196.2593,knn_tta_n=100:208.4592,knn_ttm_n=100:191.483,knn_tta_r_n=100:218.6938,knn_ttm_r_n=100:210.3301'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:306.6123,knn_ttm_n=5:356.3374,knn_tta_r_n=5:253.2689,knn_ttm_r_n=5:275.8524,knn_tta_n=10:263.5234,knn_ttm_n=10:307.999,knn_tta_r_n=10:244.692,knn_ttm_r_n=10:254.077,knn_tta_n=20:242.165,knn_ttm_n=20:270.9007,knn_tta_r_n=20:242.2192,knn_ttm_r_n=20:247.9973,knn_tta_n=50:236.2551,knn_ttm_n=50:245.0776,knn_tta_r_n=50:241.6365,knn_ttm_r_n=50:244.498,knn_tta_n=100:237.7187,knn_ttm_n=100:239.7521,knn_tta_r_n=100:244.9564,knn_ttm_r_n=100:244.8028'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:143.8571,knn_ttm_n=5:93.9728,knn_tta_r_n=5:156.6084,knn_ttm_r_n=5:213.6738,knn_tta_n=10:195.095,knn_ttm_n=10:155.4277,knn_tta_r_n=10:222.3498,knn_ttm_r_n=10:220.9516,knn_tta_n=20:233.8977,knn_ttm_n=20:207.0238,knn_tta_r_n=20:266.7325,knn_ttm_r_n=20:246.3357,knn_tta_n=50:272.7998,knn_ttm_n=50:271.2416,knn_tta_r_n=50:305.2684,knn_ttm_r_n=50:287.5381,knn_tta_n=100:295.864,knn_ttm_n=100:311.7982,knn_tta_r_n=100:326.8795,knn_ttm_r_n=100:311.6987'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:364.341,knn_ttm_n=5:405.9313,knn_tta_r_n=5:354.7969,knn_ttm_r_n=5:376.4088,knn_tta_n=10:329.4164,knn_ttm_n=10:378.2221,knn_tta_r_n=10:340.1537,knn_ttm_r_n=10:356.7362,knn_tta_n=20:318.4254,knn_ttm_n=20:355.9416,knn_tta_r_n=20:336.3964,knn_ttm_r_n=20:345.2935,knn_tta_n=50:310.7711,knn_ttm_n=50:351.4943,knn_tta_r_n=50:343.0485,knn_ttm_r_n=50:342.8813,knn_tta_n=100:321.637,knn_ttm_n=100:358.3458,knn_tta_r_n=100:356.7738,knn_ttm_r_n=100:352.0422'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:146.4309,knn_ttm_n=5:88.2035,knn_tta_r_n=5:156.5809,knn_ttm_r_n=5:212.8684,knn_tta_n=10:202.1071,knn_ttm_n=10:156.8355,knn_tta_r_n=10:224.7834,knn_ttm_r_n=10:225.4703,knn_tta_n=20:247.5184,knn_ttm_n=20:219.6337,knn_tta_r_n=20:269.1501,knn_ttm_r_n=20:252.6515,knn_tta_n=50:288.3655,knn_ttm_n=50:291.6383,knn_tta_r_n=50:308.9849,knn_ttm_r_n=50:292.0238,knn_tta_n=100:309.666,knn_ttm_n=100:335.8865,knn_tta_r_n=100:328.6396,knn_ttm_r_n=100:315.0693'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:376.3371,knn_ttm_n=5:429.9998,knn_tta_r_n=5:348.793,knn_ttm_r_n=5:371.8165,knn_tta_n=10:351.7201,knn_ttm_n=10:400.0955,knn_tta_r_n=10:331.9195,knn_ttm_r_n=10:344.5151,knn_tta_n=20:332.2397,knn_ttm_n=20:384.4875,knn_tta_r_n=20:329.9465,knn_ttm_r_n=20:336.1404,knn_tta_n=50:332.0569,knn_ttm_n=50:377.8895,knn_tta_r_n=50:337.5009,knn_ttm_r_n=50:337.357,knn_tta_n=100:334.4102,knn_ttm_n=100:385.2408,knn_tta_r_n=100:347.9911,knn_ttm_r_n=100:344.6044'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:97.0239,knn_ttm_n=5:52.3543,knn_tta_r_n=5:96.9232,knn_ttm_r_n=5:132.9039,knn_tta_n=10:128.7263,knn_ttm_n=10:82.1975,knn_tta_r_n=10:137.0017,knn_ttm_r_n=10:133.6864,knn_tta_n=20:149.9716,knn_ttm_n=20:108.354,knn_tta_r_n=20:160.3609,knn_ttm_r_n=20:147.7447,knn_tta_n=50:169.2085,knn_ttm_n=50:140.9472,knn_tta_r_n=50:176.3833,knn_ttm_r_n=50:166.0567,knn_tta_n=100:177.9679,knn_ttm_n=100:161.1663,knn_tta_r_n=100:184.2823,knn_ttm_r_n=100:176.4242'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:262.4126,knn_ttm_n=5:322.529,knn_tta_r_n=5:185.1562,knn_ttm_r_n=5:199.609,knn_tta_n=10:211.3087,knn_ttm_n=10:265.7965,knn_tta_r_n=10:178.5765,knn_ttm_r_n=10:183.5032,knn_tta_n=20:192.1817,knn_ttm_n=20:221.5435,knn_tta_r_n=20:176.6237,knn_ttm_r_n=20:177.9807,knn_tta_n=50:180.6575,knn_ttm_n=50:194.5168,knn_tta_r_n=50:177.1522,knn_ttm_r_n=50:176.7437,knn_tta_n=100:176.976,knn_ttm_n=100:183.7879,knn_tta_r_n=100:179.7155,knn_ttm_r_n=100:177.9663'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:95.6084,knn_ttm_n=5:50.9604,knn_tta_r_n=5:98.8722,knn_ttm_r_n=5:134.5705,knn_tta_n=10:130.9474,knn_ttm_n=10:84.2293,knn_tta_r_n=10:143.6757,knn_ttm_r_n=10:139.742,knn_tta_n=20:155.8364,knn_ttm_n=20:114.9877,knn_tta_r_n=20:170.127,knn_ttm_r_n=20:157.4763,knn_tta_n=50:178.3766,knn_ttm_n=50:151.7517,knn_tta_r_n=50:188.5213,knn_ttm_r_n=50:178.3231,knn_tta_n=100:188.6721,knn_ttm_n=100:173.9016,knn_tta_r_n=100:196.3973,knn_ttm_r_n=100:189.8657'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:268.958,knn_ttm_n=5:319.8815,knn_tta_r_n=5:201.9293,knn_ttm_r_n=5:217.0396,knn_tta_n=10:239.8356,knn_ttm_n=10:281.8297,knn_tta_r_n=10:196.4525,knn_ttm_r_n=10:198.9538,knn_tta_n=20:217.1815,knn_ttm_n=20:249.8211,knn_tta_r_n=20:194.5076,knn_ttm_r_n=20:195.5651,knn_tta_n=50:203.0178,knn_ttm_n=50:225.505,knn_tta_r_n=50:194.4221,knn_ttm_r_n=50:193.6678,knn_tta_n=100:196.1042,knn_ttm_n=100:212.4869,knn_tta_r_n=100:194.4819,knn_ttm_r_n=100:193.8138'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:67.5522,knn_ttm_n=5:34.7247,knn_tta_r_n=5:67.4717,knn_ttm_r_n=5:90.8986,knn_tta_n=10:91.2075,knn_ttm_n=10:54.8856,knn_tta_r_n=10:96.7724,knn_ttm_r_n=10:92.7708,knn_tta_n=20:107.7419,knn_ttm_n=20:75.3507,knn_tta_r_n=20:114.0104,knn_ttm_r_n=20:103.9605,knn_tta_n=50:120.7213,knn_ttm_n=50:100.3592,knn_tta_r_n=50:126.7666,knn_ttm_r_n=50:118.9241,knn_tta_n=100:127.2844,knn_ttm_n=100:114.1576,knn_tta_r_n=100:132.3204,knn_ttm_r_n=100:126.8271'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:202.2372,knn_ttm_n=5:235.1725,knn_tta_r_n=5:149.1808,knn_ttm_r_n=5:160.2746,knn_tta_n=10:173.9808,knn_ttm_n=10:204.5596,knn_tta_r_n=10:144.5336,knn_ttm_r_n=10:147.4551,knn_tta_n=20:156.1138,knn_ttm_n=20:177.4636,knn_tta_r_n=20:142.8607,knn_ttm_r_n=20:143.817,knn_tta_n=50:148.1064,knn_ttm_n=50:158.4229,knn_tta_r_n=50:143.7908,knn_ttm_r_n=50:142.9159,knn_tta_n=100:147.9845,knn_ttm_n=100:152.015,knn_tta_r_n=100:146.5138,knn_ttm_r_n=100:144.5388'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_24'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:134.8688,knn_ttm_n=5:73.9391,knn_tta_r_n=5:144.7547,knn_ttm_r_n=5:199.0699,knn_tta_n=10:190.3426,knn_ttm_n=10:127.217,knn_tta_r_n=10:209.1456,knn_ttm_r_n=10:210.282,knn_tta_n=20:230.6981,knn_ttm_n=20:182.798,knn_tta_r_n=20:247.7759,knn_ttm_r_n=20:236.1237,knn_tta_n=50:264.4709,knn_ttm_n=50:243.6843,knn_tta_r_n=50:274.8913,knn_ttm_r_n=50:267.2463,knn_tta_n=100:282.3954,knn_ttm_n=100:283.0057,knn_tta_r_n=100:285.8187,knn_ttm_r_n=100:282.812'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:417.4311,knn_ttm_n=5:482.9253,knn_tta_r_n=5:321.3447,knn_ttm_r_n=5:341.6288,knn_tta_n=10:367.938,knn_ttm_n=10:424.8239,knn_tta_r_n=10:318.7756,knn_ttm_r_n=10:324.7491,knn_tta_n=20:334.517,knn_ttm_n=20:379.6276,knn_tta_r_n=20:315.6411,knn_ttm_r_n=20:320.1892,knn_tta_n=50:322.3905,knn_ttm_n=50:349.652,knn_tta_r_n=50:315.4233,knn_ttm_r_n=50:317.2148,knn_tta_n=100:320.6762,knn_ttm_n=100:342.3486,knn_tta_r_n=100:316.2619,knn_ttm_r_n=100:317.2608'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:178.5786,knn_ttm_n=5:127.8067,knn_tta_r_n=5:194.44,knn_ttm_r_n=5:261.026,knn_tta_n=10:254.356,knn_ttm_n=10:214.1365,knn_tta_r_n=10:279.151,knn_ttm_r_n=10:276.3527,knn_tta_n=20:306.1022,knn_ttm_n=20:295.0758,knn_tta_r_n=20:336.1056,knn_ttm_r_n=20:318.5181,knn_tta_n=50:357.5054,knn_ttm_n=50:390.1124,knn_tta_r_n=50:382.2701,knn_ttm_r_n=50:368.7347,knn_tta_n=100:393.3453,knn_ttm_n=100:451.6146,knn_tta_r_n=100:408.6355,knn_ttm_r_n=100:401.0393'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:485.6163,knn_ttm_n=5:537.578,knn_tta_r_n=5:416.8145,knn_ttm_r_n=5:457.5497,knn_tta_n=10:446.4454,knn_ttm_n=10:519.0589,knn_tta_r_n=10:406.2864,knn_ttm_r_n=10:429.181,knn_tta_n=20:429.1968,knn_ttm_n=20:505.2671,knn_tta_r_n=20:407.0729,knn_ttm_r_n=20:417.6771,knn_tta_n=50:425.6856,knn_ttm_n=50:503.4144,knn_tta_r_n=50:422.9168,knn_ttm_r_n=50:423.002,knn_tta_n=100:440.056,knn_ttm_n=100:520.5619,knn_tta_r_n=100:438.9131,knn_ttm_r_n=100:436.5545'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:192.3105,knn_ttm_n=5:136.929,knn_tta_r_n=5:197.2818,knn_ttm_r_n=5:263.9717,knn_tta_n=10:277.2059,knn_ttm_n=10:237.4884,knn_tta_r_n=10:290.0167,knn_ttm_r_n=10:290.2303,knn_tta_n=20:335.0228,knn_ttm_n=20:326.2972,knn_tta_r_n=20:353.2055,knn_ttm_r_n=20:336.3565,knn_tta_n=50:394.0198,knn_ttm_n=50:427.5465,knn_tta_r_n=50:405.4915,knn_ttm_r_n=50:395.2402,knn_tta_n=100:428.1212,knn_ttm_n=100:499.0331,knn_tta_r_n=100:429.2301,knn_ttm_r_n=100:426.1823'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:519.6825,knn_ttm_n=5:604.3664,knn_tta_r_n=5:438.7411,knn_ttm_r_n=5:491.2401,knn_tta_n=10:462.1726,knn_ttm_n=10:551.9608,knn_tta_r_n=10:419.318,knn_ttm_r_n=10:446.6387,knn_tta_n=20:427.6101,knn_ttm_n=20:509.1042,knn_tta_r_n=20:417.904,knn_ttm_r_n=20:432.519,knn_tta_n=50:432.5747,knn_ttm_n=50:504.3041,knn_tta_r_n=50:431.3338,knn_ttm_r_n=50:438.2643,knn_tta_n=100:444.562,knn_ttm_n=100:531.9626,knn_tta_r_n=100:443.0426,knn_ttm_r_n=100:448.0782'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:109.7677,knn_ttm_n=5:61.4333,knn_tta_r_n=5:111.303,knn_ttm_r_n=5:155.7194,knn_tta_n=10:147.1433,knn_ttm_n=10:97.9889,knn_tta_r_n=10:157.0658,knn_ttm_r_n=10:157.0599,knn_tta_n=20:174.0796,knn_ttm_n=20:135.0817,knn_tta_r_n=20:183.1311,knn_ttm_r_n=20:174.66,knn_tta_n=50:194.5051,knn_ttm_n=50:176.365,knn_tta_r_n=50:200.2635,knn_ttm_r_n=50:194.4276,knn_tta_n=100:204.2517,knn_ttm_n=100:197.884,knn_tta_r_n=100:206.4133,knn_ttm_r_n=100:203.4823'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:293.8997,knn_ttm_n=5:349.2266,knn_tta_r_n=5:226.4647,knn_ttm_r_n=5:240.6688,knn_tta_n=10:252.9759,knn_ttm_n=10:298.3039,knn_tta_r_n=10:219.4835,knn_ttm_r_n=10:225.6246,knn_tta_n=20:232.8239,knn_ttm_n=20:262.4893,knn_tta_r_n=20:215.1557,knn_ttm_r_n=20:217.5965,knn_tta_n=50:221.1543,knn_ttm_n=50:235.628,knn_tta_r_n=50:214.186,knn_ttm_r_n=50:214.3574,knn_tta_n=100:215.4409,knn_ttm_n=100:224.4146,knn_tta_r_n=100:213.2763,knn_ttm_r_n=100:213.9676'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:107.9408,knn_ttm_n=5:64.1225,knn_tta_r_n=5:114.8554,knn_ttm_r_n=5:157.2956,knn_tta_n=10:146.1726,knn_ttm_n=10:102.5572,knn_tta_r_n=10:164.9902,knn_ttm_r_n=10:166.2033,knn_tta_n=20:176.348,knn_ttm_n=20:139.5416,knn_tta_r_n=20:195.3407,knn_ttm_r_n=20:186.5238,knn_tta_n=50:203.2054,knn_ttm_n=50:183.8905,knn_tta_r_n=50:216.8749,knn_ttm_r_n=50:210.3757,knn_tta_n=100:218.5307,knn_ttm_n=100:211.5667,knn_tta_r_n=100:226.5607,knn_ttm_r_n=100:222.8553'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:305.7302,knn_ttm_n=5:372.2324,knn_tta_r_n=5:227.4405,knn_ttm_r_n=5:244.5045,knn_tta_n=10:258.533,knn_ttm_n=10:322.8139,knn_tta_r_n=10:216.5013,knn_ttm_r_n=10:223.3977,knn_tta_n=20:232.2088,knn_ttm_n=20:278.7557,knn_tta_r_n=20:213.615,knn_ttm_r_n=20:215.8639,knn_tta_n=50:216.3913,knn_ttm_n=50:241.286,knn_tta_r_n=50:216.3032,knn_ttm_r_n=50:216.1198,knn_tta_n=100:218.1889,knn_ttm_n=100:233.7731,knn_tta_r_n=100:220.2004,knn_ttm_r_n=100:219.1357'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:60.9935,knn_ttm_n=5:34.0709,knn_tta_r_n=5:59.0142,knn_ttm_r_n=5:79.1245,knn_tta_n=10:80.3077,knn_ttm_n=10:53.7727,knn_tta_r_n=10:82.7468,knn_ttm_r_n=10:81.0207,knn_tta_n=20:94.1076,knn_ttm_n=20:72.6738,knn_tta_r_n=20:96.6883,knn_ttm_r_n=20:90.4852,knn_tta_n=50:103.5442,knn_ttm_n=50:94.5664,knn_tta_r_n=50:105.2313,knn_ttm_r_n=50:101.4576,knn_tta_n=100:107.4918,knn_ttm_n=100:103.6528,knn_tta_r_n=100:109.0247,knn_ttm_r_n=100:106.7726'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:191.5696,knn_ttm_n=5:222.2095,knn_tta_r_n=5:138.5102,knn_ttm_r_n=5:148.0086,knn_tta_n=10:163.2815,knn_ttm_n=10:193.9646,knn_tta_r_n=10:134.1579,knn_ttm_r_n=10:136.9475,knn_tta_n=20:146.3026,knn_ttm_n=20:172.0549,knn_tta_r_n=20:133.0188,knn_ttm_r_n=20:133.0771,knn_tta_n=50:136.5343,knn_ttm_n=50:149.2737,knn_tta_r_n=50:132.3292,knn_ttm_r_n=50:131.8378,knn_tta_n=100:133.9151,knn_ttm_n=100:139.2421,knn_tta_r_n=100:132.7227,knn_ttm_r_n=100:132.097'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_25'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:165.0487,knn_ttm_n=5:125.4745,knn_tta_r_n=5:163.6239,knn_ttm_r_n=5:224.8987,knn_tta_n=10:218.464,knn_ttm_n=10:190.6762,knn_tta_r_n=10:225.7732,knn_ttm_r_n=10:237.772,knn_tta_n=20:249.5848,knn_ttm_n=20:236.8177,knn_tta_r_n=20:257.0751,knn_ttm_r_n=20:258.9023,knn_tta_n=50:273.9242,knn_ttm_n=50:281.0722,knn_tta_r_n=50:276.9886,knn_ttm_r_n=50:277.5748,knn_tta_n=100:282.775,knn_ttm_n=100:297.5037,knn_tta_r_n=100:283.5078,knn_ttm_r_n=100:284.6543'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:394.8964,knn_ttm_n=5:470.1336,knn_tta_r_n=5:324.0543,knn_ttm_r_n=5:343.0058,knn_tta_n=10:351.9247,knn_ttm_n=10:414.75,knn_tta_r_n=10:312.6569,knn_ttm_r_n=10:320.8039,knn_tta_n=20:325.931,knn_ttm_n=20:374.0412,knn_tta_r_n=20:306.9875,knn_ttm_r_n=20:312.1462,knn_tta_n=50:312.5879,knn_ttm_n=50:346.5862,knn_tta_r_n=50:305.8274,knn_ttm_r_n=50:308.4296,knn_tta_n=100:308.1392,knn_ttm_n=100:334.921,knn_tta_r_n=100:304.1033,knn_ttm_r_n=100:306.597'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:239.455,knn_ttm_n=5:203.7138,knn_tta_r_n=5:246.0868,knn_ttm_r_n=5:337.8733,knn_tta_n=10:321.7029,knn_ttm_n=10:320.8736,knn_tta_r_n=10:335.9939,knn_ttm_r_n=10:359.5201,knn_tta_n=20:375.5421,knn_ttm_n=20:400.985,knn_tta_r_n=20:385.3153,knn_ttm_r_n=20:391.8883,knn_tta_n=50:411.171,knn_ttm_n=50:467.5435,knn_tta_r_n=50:414.7111,knn_ttm_r_n=50:418.1706,knn_tta_n=100:425.2629,knn_ttm_n=100:498.0811,knn_tta_r_n=100:424.3846,knn_ttm_r_n=100:428.8568'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:611.0141,knn_ttm_n=5:762.7968,knn_tta_r_n=5:488.4156,knn_ttm_r_n=5:525.2004,knn_tta_n=10:540.9997,knn_ttm_n=10:692.2907,knn_tta_r_n=10:461.8648,knn_ttm_r_n=10:482.5409,knn_tta_n=20:498.4169,knn_ttm_n=20:627.5652,knn_tta_r_n=20:456.609,knn_ttm_r_n=20:469.7666,knn_tta_n=50:479.5489,knn_ttm_n=50:581.0764,knn_tta_r_n=50:457.7761,knn_ttm_r_n=50:462.8798,knn_tta_n=100:477.254,knn_ttm_n=100:578.0327,knn_tta_r_n=100:460.71,knn_ttm_r_n=100:463.7756'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:260.0793,knn_ttm_n=5:244.1423,knn_tta_r_n=5:258.3829,knn_ttm_r_n=5:356.6064,knn_tta_n=10:346.1424,knn_ttm_n=10:364.0787,knn_tta_r_n=10:356.1699,knn_ttm_r_n=10:386.979,knn_tta_n=20:401.5926,knn_ttm_n=20:447.3052,knn_tta_r_n=20:409.2089,knn_ttm_r_n=20:423.1302,knn_tta_n=50:438.4226,knn_ttm_n=50:520.0776,knn_tta_r_n=50:440.547,knn_ttm_r_n=50:451.0842,knn_tta_n=100:452.4562,knn_ttm_n=100:547.9627,knn_tta_r_n=100:449.9352,knn_ttm_r_n=100:459.2801'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:612.7879,knn_ttm_n=5:779.5999,knn_tta_r_n=5:521.242,knn_ttm_r_n=5:574.9331,knn_tta_n=10:532.0404,knn_ttm_n=10:667.3045,knn_tta_r_n=10:487.6254,knn_ttm_r_n=10:524.4867,knn_tta_n=20:496.3348,knn_ttm_n=20:608.5598,knn_tta_r_n=20:473.9756,knn_ttm_r_n=20:496.563,knn_tta_n=50:477.2826,knn_ttm_n=50:579.9686,knn_tta_r_n=50:469.0808,knn_ttm_r_n=50:485.1009,knn_tta_n=100:469.2571,knn_ttm_n=100:576.2293,knn_tta_r_n=100:465.0195,knn_ttm_r_n=100:478.6509'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:122.5618,knn_ttm_n=5:90.2266,knn_tta_r_n=5:122.7672,knn_ttm_r_n=5:165.5109,knn_tta_n=10:164.5131,knn_ttm_n=10:139.4258,knn_tta_r_n=10:169.4916,knn_ttm_r_n=10:175.5359,knn_tta_n=20:188.7455,knn_ttm_n=20:173.7079,knn_tta_r_n=20:194.771,knn_ttm_r_n=20:193.4071,knn_tta_n=50:207.1622,knn_ttm_n=50:201.9688,knn_tta_r_n=50:209.7472,knn_ttm_r_n=50:208.3097,knn_tta_n=100:213.5403,knn_ttm_n=100:213.5569,knn_tta_r_n=100:214.7853,knn_ttm_r_n=100:213.8943'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:299.1551,knn_ttm_n=5:363.2442,knn_tta_r_n=5:227.6855,knn_ttm_r_n=5:246.028,knn_tta_n=10:256.4215,knn_ttm_n=10:313.6791,knn_tta_r_n=10:217.4546,knn_ttm_r_n=10:225.6429,knn_tta_n=20:231.4664,knn_ttm_n=20:268.4535,knn_tta_r_n=20:212.4274,knn_ttm_r_n=20:215.9939,knn_tta_n=50:215.0706,knn_ttm_n=50:233.0177,knn_tta_r_n=50:209.8736,knn_ttm_r_n=50:210.9286,knn_tta_n=100:210.524,knn_ttm_n=100:220.0618,knn_tta_r_n=100:208.4354,knn_ttm_r_n=100:209.1227'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:126.3799,knn_ttm_n=5:96.5874,knn_tta_r_n=5:128.0056,knn_ttm_r_n=5:172.6293,knn_tta_n=10:167.5112,knn_ttm_n=10:146.344,knn_tta_r_n=10:175.8379,knn_ttm_r_n=10:183.959,knn_tta_n=20:197.3095,knn_ttm_n=20:183.1236,knn_tta_r_n=20:201.9302,knn_ttm_r_n=20:200.6217,knn_tta_n=50:215.5955,knn_ttm_n=50:215.6562,knn_tta_r_n=50:217.0124,knn_ttm_r_n=50:215.659,knn_tta_n=100:221.1353,knn_ttm_n=100:226.1515,knn_tta_r_n=100:222.0452,knn_ttm_r_n=100:221.1079'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:328.9029,knn_ttm_n=5:414.0844,knn_tta_r_n=5:240.2318,knn_ttm_r_n=5:250.0103,knn_tta_n=10:267.3096,knn_ttm_n=10:345.7345,knn_tta_r_n=10:228.2772,knn_ttm_r_n=10:231.5672,knn_tta_n=20:234.6268,knn_ttm_n=20:282.511,knn_tta_r_n=20:223.1013,knn_ttm_r_n=20:225.8149,knn_tta_n=50:223.7963,knn_ttm_n=50:243.762,knn_tta_r_n=50:220.5951,knn_ttm_r_n=50:221.157,knn_tta_n=100:222.5212,knn_ttm_n=100:234.32,knn_tta_r_n=100:221.2148,knn_ttm_r_n=100:221.2937'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:70.9781,knn_ttm_n=5:53.1801,knn_tta_r_n=5:70.294,knn_ttm_r_n=5:95.4912,knn_tta_n=10:94.6513,knn_ttm_n=10:81.2851,knn_tta_r_n=10:96.3301,knn_ttm_r_n=10:101.3201,knn_tta_n=20:108.341,knn_ttm_n=20:102.3454,knn_tta_r_n=20:110.287,knn_ttm_r_n=20:109.9609,knn_tta_n=50:117.6133,knn_ttm_n=50:119.835,knn_tta_r_n=50:118.5042,knn_ttm_r_n=50:117.5835,knn_tta_n=100:120.3249,knn_ttm_n=100:125.6502,knn_tta_r_n=100:121.3935,knn_ttm_r_n=100:120.7904'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:195.8159,knn_ttm_n=5:231.1147,knn_tta_r_n=5:156.5793,knn_ttm_r_n=5:169.2089,knn_tta_n=10:170.4017,knn_ttm_n=10:203.0734,knn_tta_r_n=10:150.2363,knn_ttm_r_n=10:154.6653,knn_tta_n=20:156.6983,knn_ttm_n=20:181.1921,knn_tta_r_n=20:148.6795,knn_ttm_r_n=20:150.5451,knn_tta_n=50:147.9627,knn_ttm_n=50:160.7181,knn_tta_r_n=50:146.9974,knn_ttm_r_n=50:148.1037,knn_tta_n=100:145.5022,knn_ttm_n=100:152.9896,knn_tta_r_n=100:146.4997,knn_ttm_r_n=100:147.083'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_29'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:108.2814,knn_ttm_n=5:60.2675,knn_tta_r_n=5:113.9648,knn_ttm_r_n=5:159.8399,knn_tta_n=10:148.1098,knn_ttm_n=10:94.9454,knn_tta_r_n=10:163.7553,knn_ttm_r_n=10:159.9424,knn_tta_n=20:177.8971,knn_ttm_n=20:129.2092,knn_tta_r_n=20:194.7484,knn_ttm_r_n=20:178.646,knn_tta_n=50:202.2746,knn_ttm_n=50:170.2206,knn_tta_r_n=50:219.3297,knn_ttm_r_n=50:204.6442,knn_tta_n=100:216.125,knn_ttm_n=100:195.6527,knn_tta_r_n=100:231.6371,knn_ttm_r_n=100:220.2501'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:326.8505,knn_ttm_n=5:367.9835,knn_tta_r_n=5:270.4822,knn_ttm_r_n=5:291.0382,knn_tta_n=10:287.7451,knn_ttm_n=10:330.3923,knn_tta_r_n=10:258.7725,knn_ttm_r_n=10:269.3576,knn_tta_n=20:266.8507,knn_ttm_n=20:298.6385,knn_tta_r_n=20:253.5277,knn_ttm_r_n=20:259.2801,knn_tta_n=50:254.6688,knn_ttm_n=50:272.4438,knn_tta_r_n=50:253.7784,knn_ttm_r_n=50:255.1787,knn_tta_n=100:253.5954,knn_ttm_n=100:263.3086,knn_tta_r_n=100:257.4585,knn_ttm_r_n=100:256.1253'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:129.4353,knn_ttm_n=5:77.7864,knn_tta_r_n=5:144.675,knn_ttm_r_n=5:198.0299,knn_tta_n=10:174.186,knn_ttm_n=10:127.8285,knn_tta_r_n=10:209.6029,knn_ttm_r_n=10:204.6815,knn_tta_n=20:209.7367,knn_ttm_n=20:169.5805,knn_tta_r_n=20:252.0627,knn_ttm_r_n=20:232.5389,knn_tta_n=50:245.0271,knn_ttm_n=50:221.7585,knn_tta_r_n=50:290.4832,knn_ttm_r_n=50:270.8848,knn_tta_n=100:266.2501,knn_ttm_n=100:255.7868,knn_tta_r_n=100:313.0173,knn_ttm_r_n=100:296.0063'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:359.5297,knn_ttm_n=5:423.0457,knn_tta_r_n=5:328.3311,knn_ttm_r_n=5:356.8475,knn_tta_n=10:311.5025,knn_ttm_n=10:370.8991,knn_tta_r_n=10:311.7052,knn_ttm_r_n=10:327.5523,knn_tta_n=20:286.2479,knn_ttm_n=20:326.4935,knn_tta_r_n=20:312.372,knn_ttm_r_n=20:318.7873,knn_tta_n=50:282.0848,knn_ttm_n=50:303.4422,knn_tta_r_n=50:320.7261,knn_ttm_r_n=50:319.8755,knn_tta_n=100:288.6042,knn_ttm_n=100:302.8496,knn_tta_r_n=100:333.8328,knn_ttm_r_n=100:326.7857'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:129.9602,knn_ttm_n=5:72.7491,knn_tta_r_n=5:138.8206,knn_ttm_r_n=5:194.9208,knn_tta_n=10:182.3921,knn_ttm_n=10:127.2084,knn_tta_r_n=10:206.537,knn_ttm_r_n=10:201.6552,knn_tta_n=20:215.5009,knn_ttm_n=20:178.4905,knn_tta_r_n=20:246.1636,knn_ttm_r_n=20:227.8494,knn_tta_n=50:249.005,knn_ttm_n=50:231.9992,knn_tta_r_n=50:281.9019,knn_ttm_r_n=50:264.2508,knn_tta_n=100:268.5538,knn_ttm_n=100:264.0361,knn_tta_r_n=100:302.9876,knn_ttm_r_n=100:288.1225'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:343.5291,knn_ttm_n=5:381.4456,knn_tta_r_n=5:338.0896,knn_ttm_r_n=5:369.195,knn_tta_n=10:294.8148,knn_ttm_n=10:342.5235,knn_tta_r_n=10:313.3721,knn_ttm_r_n=10:337.1208,knn_tta_n=20:274.5808,knn_ttm_n=20:309.2884,knn_tta_r_n=20:303.2729,knn_ttm_r_n=20:318.6221,knn_tta_n=50:270.9473,knn_ttm_n=50:292.6902,knn_tta_r_n=50:306.9485,knn_ttm_r_n=50:310.85,knn_tta_n=100:277.9006,knn_ttm_n=100:293.5083,knn_tta_r_n=100:318.8157,knn_ttm_r_n=100:315.0373'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:92.6862,knn_ttm_n=5:52.0149,knn_tta_r_n=5:94.7707,knn_ttm_r_n=5:128.5032,knn_tta_n=10:122.8135,knn_ttm_n=10:80.4602,knn_tta_r_n=10:134.218,knn_ttm_r_n=10:129.8186,knn_tta_n=20:146.4073,knn_ttm_n=20:107.0558,knn_tta_r_n=20:158.5024,knn_ttm_r_n=20:144.0838,knn_tta_n=50:167.8418,knn_ttm_n=50:142.5561,knn_tta_r_n=50:175.9826,knn_ttm_r_n=50:164.1027,knn_tta_n=100:177.1329,knn_ttm_n=100:163.3991,knn_tta_r_n=100:183.7155,knn_ttm_r_n=100:175.4937'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:260.4856,knn_ttm_n=5:308.9329,knn_tta_r_n=5:192.9432,knn_ttm_r_n=5:210.7251,knn_tta_n=10:220.4189,knn_ttm_n=10:268.7283,knn_tta_r_n=10:185.899,knn_ttm_r_n=10:192.2546,knn_tta_n=20:199.9339,knn_ttm_n=20:233.2278,knn_tta_r_n=20:184.1622,knn_ttm_r_n=20:186.4878,knn_tta_n=50:188.7844,knn_ttm_n=50:206.7991,knn_tta_r_n=50:183.6984,knn_ttm_r_n=50:183.7833,knn_tta_n=100:183.8262,knn_ttm_n=100:197.301,knn_tta_r_n=100:184.2474,knn_ttm_r_n=100:183.7499'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:92.4236,knn_ttm_n=5:50.2258,knn_tta_r_n=5:97.6233,knn_ttm_r_n=5:128.8453,knn_tta_n=10:124.5685,knn_ttm_n=10:83.7817,knn_tta_r_n=10:139.8274,knn_ttm_r_n=10:135.6863,knn_tta_n=20:150.895,knn_ttm_n=20:113.529,knn_tta_r_n=20:165.7817,knn_ttm_r_n=20:152.9368,knn_tta_n=50:172.1175,knn_ttm_n=50:149.7009,knn_tta_r_n=50:186.0933,knn_ttm_r_n=50:174.3935,knn_tta_n=100:183.4346,knn_ttm_n=100:169.5813,knn_tta_r_n=100:195.4699,knn_ttm_r_n=100:186.7101'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:268.4402,knn_ttm_n=5:309.5716,knn_tta_r_n=5:203.3218,knn_ttm_r_n=5:220.5843,knn_tta_n=10:225.2321,knn_ttm_n=10:274.261,knn_tta_r_n=10:195.8689,knn_ttm_r_n=10:203.0138,knn_tta_n=20:204.2538,knn_ttm_n=20:238.687,knn_tta_r_n=20:191.8953,knn_ttm_r_n=20:195.6163,knn_tta_n=50:192.582,knn_ttm_n=50:212.417,knn_tta_r_n=50:191.5411,knn_ttm_r_n=50:192.6574,knn_tta_n=100:190.7203,knn_ttm_n=100:203.1812,knn_tta_r_n=100:194.1178,knn_ttm_r_n=100:193.149'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:62.2068,knn_ttm_n=5:31.2849,knn_tta_r_n=5:63.4117,knn_ttm_r_n=5:85.9457,knn_tta_n=10:84.0515,knn_ttm_n=10:52.0918,knn_tta_r_n=10:90.0968,knn_ttm_r_n=10:85.3992,knn_tta_n=20:99.4355,knn_ttm_n=20:71.9691,knn_tta_r_n=20:106.3465,knn_ttm_r_n=20:96.2735,knn_tta_n=50:112.0604,knn_ttm_n=50:94.6365,knn_tta_r_n=50:118.4661,knn_ttm_r_n=50:110.7379,knn_tta_n=100:118.2649,knn_ttm_n=100:108.0464,knn_tta_r_n=100:123.6632,knn_ttm_r_n=100:118.1539'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:192.9979,knn_ttm_n=5:222.7947,knn_tta_r_n=5:146.5852,knn_ttm_r_n=5:153.7776,knn_tta_n=10:164.1182,knn_ttm_n=10:191.7993,knn_tta_r_n=10:140.1599,knn_ttm_r_n=10:143.856,knn_tta_n=20:147.0653,knn_ttm_n=20:167.7643,knn_tta_r_n=20:138.1525,knn_ttm_r_n=20:139.3934,knn_tta_n=50:140.4476,knn_ttm_n=50:150.152,knn_tta_r_n=50:139.8041,knn_ttm_r_n=50:138.6646,knn_tta_n=100:140.1238,knn_ttm_n=100:144.9514,knn_tta_r_n=100:141.6424,knn_ttm_r_n=100:140.0341'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_32'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:199.6303,knn_ttm_n=5:212.7686,knn_tta_r_n=5:261.376,knn_ttm_r_n=5:255.5625,knn_tta_n=10:240.9771,knn_ttm_n=10:268.7891,knn_tta_r_n=10:270.3362,knn_ttm_r_n=10:271.5089,knn_tta_n=20:260.6455,knn_ttm_n=20:283.8125,knn_tta_r_n=20:277.0447,knn_ttm_r_n=20:272.7577,knn_tta_n=50:287.1666,knn_ttm_n=50:286.3286,knn_tta_r_n=50:279.0197,knn_ttm_r_n=50:275.2598,knn_tta_n=100:294.5273,knn_ttm_n=100:290.2392,knn_tta_r_n=100:280.2247,knn_ttm_r_n=100:278.7667'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:420.892,knn_ttm_n=5:517.88,knn_tta_r_n=5:400.0581,knn_ttm_r_n=5:367.2686,knn_tta_n=10:375.9934,knn_ttm_n=10:464.1744,knn_tta_r_n=10:358.0352,knn_ttm_r_n=10:348.7325,knn_tta_n=20:345.9232,knn_ttm_n=20:408.5589,knn_tta_r_n=20:338.0915,knn_ttm_r_n=20:331.7191,knn_tta_n=50:340.9769,knn_ttm_n=50:354.31,knn_tta_r_n=50:325.4493,knn_ttm_r_n=50:324.7067,knn_tta_n=100:337.6383,knn_ttm_n=100:339.4778,knn_tta_r_n=100:319.1675,knn_ttm_r_n=100:321.7652'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:338.0333,knn_ttm_n=5:360.782,knn_tta_r_n=5:347.8161,knn_ttm_r_n=5:399.8116,knn_tta_n=10:416.3574,knn_ttm_n=10:453.0171,knn_tta_r_n=10:405.3132,knn_ttm_r_n=10:412.191,knn_tta_n=20:516.9461,knn_ttm_n=20:495.8386,knn_tta_r_n=20:416.9686,knn_ttm_r_n=20:425.2196,knn_tta_n=50:462.8789,knn_ttm_n=50:514.8857,knn_tta_r_n=50:432.4151,knn_ttm_r_n=50:434.7236,knn_tta_n=100:461.1661,knn_ttm_n=100:516.6638,knn_tta_r_n=100:439.1785,knn_ttm_r_n=100:438.6914'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:645.5369,knn_ttm_n=5:811.3774,knn_tta_r_n=5:548.934,knn_ttm_r_n=5:538.8588,knn_tta_n=10:584.6152,knn_ttm_n=10:725.0342,knn_tta_r_n=10:517.432,knn_ttm_r_n=10:504.4241,knn_tta_n=20:627.761,knn_ttm_n=20:670.1338,knn_tta_r_n=20:487.8212,knn_ttm_r_n=20:489.8254,knn_tta_n=50:527.0167,knn_ttm_n=50:612.7037,knn_tta_r_n=50:480.9189,knn_ttm_r_n=50:482.0525,knn_tta_n=100:510.9987,knn_ttm_n=100:584.463,knn_tta_r_n=100:479.2458,knn_ttm_r_n=100:478.4136'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:351.3798,knn_ttm_n=5:364.2663,knn_tta_r_n=5:388.7764,knn_ttm_r_n=5:416.8584,knn_tta_n=10:635.3545,knn_ttm_n=10:436.4184,knn_tta_r_n=10:410.594,knn_ttm_r_n=10:430.7189,knn_tta_n=20:543.7617,knn_ttm_n=20:473.9852,knn_tta_r_n=20:438.5549,knn_ttm_r_n=20:440.7949,knn_tta_n=50:488.5525,knn_ttm_n=50:502.3117,knn_tta_r_n=50:457.3078,knn_ttm_r_n=50:453.765,knn_tta_n=100:532.4762,knn_ttm_n=100:509.9467,knn_tta_r_n=100:460.8523,knn_ttm_r_n=100:456.5697'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:631.5989,knn_ttm_n=5:781.5398,knn_tta_r_n=5:579.9388,knn_ttm_r_n=5:551.9801,knn_tta_n=10:784.4269,knn_ttm_n=10:694.6769,knn_tta_r_n=10:515.1725,knn_ttm_r_n=10:508.9506,knn_tta_n=20:622.955,knn_ttm_n=20:619.7123,knn_tta_r_n=20:499.3903,knn_ttm_r_n=20:491.5614,knn_tta_n=50:519.9116,knn_ttm_n=50:568.8298,knn_tta_r_n=50:489.0237,knn_ttm_r_n=50:483.9204,knn_tta_n=100:544.2521,knn_ttm_n=100:541.6027,knn_tta_r_n=100:480.1559,knn_ttm_r_n=100:475.1265'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:156.0457,knn_ttm_n=5:159.0823,knn_tta_r_n=5:154.1643,knn_ttm_r_n=5:192.5956,knn_tta_n=10:190.8424,knn_ttm_n=10:197.9421,knn_tta_r_n=10:191.5608,knn_ttm_r_n=10:201.7839,knn_tta_n=20:207.0687,knn_ttm_n=20:214.7365,knn_tta_r_n=20:207.9574,knn_ttm_r_n=20:211.0861,knn_tta_n=50:229.745,knn_ttm_n=50:221.4051,knn_tta_r_n=50:217.8824,knn_ttm_r_n=50:217.5769,knn_tta_n=100:227.6294,knn_ttm_n=100:225.9021,knn_tta_r_n=100:222.6522,knn_ttm_r_n=100:221.5431'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:318.8713,knn_ttm_n=5:407.0911,knn_tta_r_n=5:256.9403,knn_ttm_r_n=5:258.0798,knn_tta_n=10:277.9483,knn_ttm_n=10:344.5431,knn_tta_r_n=10:245.1979,knn_ttm_r_n=10:243.1352,knn_tta_n=20:261.147,knn_ttm_n=20:305.8528,knn_tta_r_n=20:238.1477,knn_ttm_r_n=20:236.79,knn_tta_n=50:251.4202,knn_ttm_n=50:271.6929,knn_tta_r_n=50:232.9295,knn_ttm_r_n=50:231.3609,knn_tta_n=100:237.568,knn_ttm_n=100:253.2225,knn_tta_r_n=100:229.3162,knn_ttm_r_n=100:228.4962'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:177.7543,knn_ttm_n=5:179.2858,knn_tta_r_n=5:168.5042,knn_ttm_r_n=5:212.0748,knn_tta_n=10:208.5041,knn_ttm_n=10:226.3883,knn_tta_r_n=10:207.9128,knn_ttm_r_n=10:219.8225,knn_tta_n=20:229.7184,knn_ttm_n=20:244.1983,knn_tta_r_n=20:226.3003,knn_ttm_r_n=20:229.3509,knn_tta_n=50:238.5898,knn_ttm_n=50:251.5486,knn_tta_r_n=50:235.9851,knn_ttm_r_n=50:236.1703,knn_tta_n=100:243.1238,knn_ttm_n=100:250.3493,knn_tta_r_n=100:239.432,knn_ttm_r_n=100:238.6661'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:325.8195,knn_ttm_n=5:421.8801,knn_tta_r_n=5:260.7135,knn_ttm_r_n=5:262.8213,knn_tta_n=10:277.1681,knn_ttm_n=10:347.3766,knn_tta_r_n=10:248.1415,knn_ttm_r_n=10:249.4015,knn_tta_n=20:260.6224,knn_ttm_n=20:305.8836,knn_tta_r_n=20:242.8691,knn_ttm_r_n=20:244.1556,knn_tta_n=50:247.0271,knn_ttm_n=50:276.1884,knn_tta_r_n=50:239.1066,knn_ttm_r_n=50:239.9026,knn_tta_n=100:242.4016,knn_ttm_n=100:260.0215,knn_tta_r_n=100:236.9853,knn_ttm_r_n=100:237.5843'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:79.4898,knn_ttm_n=5:82.1911,knn_tta_r_n=5:78.7336,knn_ttm_r_n=5:99.2351,knn_tta_n=10:97.8653,knn_ttm_n=10:102.0174,knn_tta_r_n=10:98.2932,knn_ttm_r_n=10:104.9263,knn_tta_n=20:106.8747,knn_ttm_n=20:110.3226,knn_tta_r_n=20:107.9213,knn_ttm_r_n=20:109.6529,knn_tta_n=50:113.3706,knn_ttm_n=50:115.4448,knn_tta_r_n=50:114.0784,knn_ttm_r_n=50:113.9977,knn_tta_n=100:116.1912,knn_ttm_n=100:116.7918,knn_tta_r_n=100:116.814,knn_ttm_r_n=100:116.1342'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:175.7593,knn_ttm_n=5:217.8529,knn_tta_r_n=5:149.9469,knn_ttm_r_n=5:153.5362,knn_tta_n=10:159.9631,knn_ttm_n=10:189.7613,knn_tta_r_n=10:144.2737,knn_ttm_r_n=10:144.8362,knn_tta_n=20:151.5159,knn_ttm_n=20:172.2806,knn_tta_r_n=20:144.4518,knn_ttm_r_n=20:143.9536,knn_tta_n=50:144.5685,knn_ttm_n=50:154.0557,knn_tta_r_n=50:143.0071,knn_ttm_r_n=50:143.2583,knn_tta_n=100:143.9895,knn_ttm_n=100:147.5826,knn_tta_r_n=100:143.9489,knn_ttm_r_n=100:143.4109'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_34'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:119.6192,knn_ttm_n=5:68.0109,knn_tta_r_n=5:115.6148,knn_ttm_r_n=5:157.3994,knn_tta_n=10:161.744,knn_ttm_n=10:110.3543,knn_tta_r_n=10:165.9701,knn_ttm_r_n=10:161.5025,knn_tta_n=20:191.4928,knn_ttm_n=20:150.8791,knn_tta_r_n=20:196.4242,knn_ttm_r_n=20:181.6756,knn_tta_n=50:213.0081,knn_ttm_n=50:193.8837,knn_tta_r_n=50:217.7664,knn_ttm_r_n=50:206.1463,knn_tta_n=100:227.4776,knn_ttm_n=100:217.9156,knn_tta_r_n=100:229.9267,knn_ttm_r_n=100:220.563'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:313.9171,knn_ttm_n=5:366.2415,knn_tta_r_n=5:254.6425,knn_ttm_r_n=5:269.2498,knn_tta_n=10:274.7421,knn_ttm_n=10:322.7752,knn_tta_r_n=10:248.136,knn_ttm_r_n=10:254.552,knn_tta_n=20:254.8378,knn_ttm_n=20:289.9893,knn_tta_r_n=20:242.4928,knn_ttm_r_n=20:246.8696,knn_tta_n=50:248.3246,knn_ttm_n=50:267.799,knn_tta_r_n=50:241.6529,knn_ttm_r_n=50:244.5985,knn_tta_n=100:246.1731,knn_ttm_n=100:261.5496,knn_tta_r_n=100:243.2261,knn_ttm_r_n=100:243.2467'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:132.1971,knn_ttm_n=5:88.4089,knn_tta_r_n=5:141.5833,knn_ttm_r_n=5:193.9996,knn_tta_n=10:175.9646,knn_ttm_n=10:145.0086,knn_tta_r_n=10:198.8042,knn_ttm_r_n=10:199.0271,knn_tta_n=20:207.4688,knn_ttm_n=20:189.5248,knn_tta_r_n=20:235.777,knn_ttm_r_n=20:220.3399,knn_tta_n=50:237.0777,knn_ttm_n=50:235.4422,knn_tta_r_n=50:266.5556,knn_ttm_r_n=50:252.9447,knn_tta_n=100:251.7313,knn_ttm_n=100:263.3731,knn_tta_r_n=100:282.6781,knn_ttm_r_n=100:271.7381'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:326.7223,knn_ttm_n=5:366.4488,knn_tta_r_n=5:321.1907,knn_ttm_r_n=5:349.5257,knn_tta_n=10:297.113,knn_ttm_n=10:343.8655,knn_tta_r_n=10:298.1594,knn_ttm_r_n=10:318.1925,knn_tta_n=20:281.404,knn_ttm_n=20:324.1927,knn_tta_r_n=20:291.9686,knn_ttm_r_n=20:302.5705,knn_tta_n=50:275.8212,knn_ttm_n=50:314.2876,knn_tta_r_n=50:296.03,knn_ttm_r_n=50:298.7127,knn_tta_n=100:278.6578,knn_ttm_n=100:314.2568,knn_tta_r_n=100:307.1926,knn_ttm_r_n=100:303.8152'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:139.8334,knn_ttm_n=5:96.5941,knn_tta_r_n=5:146.8445,knn_ttm_r_n=5:205.3981,knn_tta_n=10:190.8856,knn_ttm_n=10:158.805,knn_tta_r_n=10:209.9582,knn_ttm_r_n=10:213.4754,knn_tta_n=20:228.3949,knn_ttm_n=20:209.7344,knn_tta_r_n=20:247.6237,knn_ttm_r_n=20:236.5161,knn_tta_n=50:260.9583,knn_ttm_n=50:266.3683,knn_tta_r_n=50:275.0706,knn_ttm_r_n=50:263.2779,knn_tta_n=100:278.3766,knn_ttm_n=100:300.7979,knn_tta_r_n=100:290.6547,knn_ttm_r_n=100:280.7605'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:349.0879,knn_ttm_n=5:395.8478,knn_tta_r_n=5:336.0498,knn_ttm_r_n=5:374.0591,knn_tta_n=10:318.7754,knn_ttm_n=10:363.7864,knn_tta_r_n=10:315.228,knn_ttm_r_n=10:338.8507,knn_tta_n=20:300.6681,knn_ttm_n=20:344.7136,knn_tta_r_n=20:309.1861,knn_ttm_r_n=20:322.9544,knn_tta_n=50:295.6255,knn_ttm_n=50:334.4852,knn_tta_r_n=50:307.6669,knn_ttm_r_n=50:315.0318,knn_tta_n=100:297.5066,knn_ttm_n=100:339.1119,knn_tta_r_n=100:312.2501,knn_ttm_r_n=100:314.8189'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:102.8728,knn_ttm_n=5:57.5005,knn_tta_r_n=5:104.1206,knn_ttm_r_n=5:142.9348,knn_tta_n=10:140.6147,knn_ttm_n=10:91.7964,knn_tta_r_n=10:145.6819,knn_ttm_r_n=10:143.5296,knn_tta_n=20:163.2584,knn_ttm_n=20:122.2171,knn_tta_r_n=20:170.2401,knn_ttm_r_n=20:156.7649,knn_tta_n=50:181.6704,knn_ttm_n=50:158.33,knn_tta_r_n=50:187.4548,knn_ttm_r_n=50:176.3807,knn_tta_n=100:191.3524,knn_ttm_n=100:177.8833,knn_tta_r_n=100:195.4838,knn_ttm_r_n=100:187.1212'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:271.379,knn_ttm_n=5:326.6172,knn_tta_r_n=5:205.1079,knn_ttm_r_n=5:224.3733,knn_tta_n=10:238.0077,knn_ttm_n=10:280.9679,knn_tta_r_n=10:197.1861,knn_ttm_r_n=10:204.0077,knn_tta_n=20:210.5049,knn_ttm_n=20:248.1811,knn_tta_r_n=20:192.033,knn_ttm_r_n=20:196.8753,knn_tta_n=50:196.0683,knn_ttm_n=50:215.6408,knn_tta_r_n=50:189.8024,knn_ttm_r_n=50:191.4036,knn_tta_n=100:194.1285,knn_ttm_n=100:203.7089,knn_tta_r_n=100:191.4909,knn_ttm_r_n=100:190.1647'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:104.1054,knn_ttm_n=5:54.658,knn_tta_r_n=5:106.5503,knn_ttm_r_n=5:145.7997,knn_tta_n=10:141.8137,knn_ttm_n=10:92.3169,knn_tta_r_n=10:150.8679,knn_ttm_r_n=10:148.6469,knn_tta_n=20:169.1319,knn_ttm_n=20:129.0065,knn_tta_r_n=20:177.4538,knn_ttm_r_n=20:164.0508,knn_tta_n=50:188.6636,knn_ttm_n=50:167.3599,knn_tta_r_n=50:196.2512,knn_ttm_r_n=50:185.4767,knn_tta_n=100:198.5373,knn_ttm_n=100:186.5077,knn_tta_r_n=100:204.2629,knn_ttm_r_n=100:196.39'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:278.9415,knn_ttm_n=5:324.3626,knn_tta_r_n=5:218.8962,knn_ttm_r_n=5:236.8339,knn_tta_n=10:234.2572,knn_ttm_n=10:284.6751,knn_tta_r_n=10:207.1116,knn_ttm_r_n=10:217.216,knn_tta_n=20:217.4821,knn_ttm_n=20:246.2462,knn_tta_r_n=20:200.9379,knn_ttm_r_n=20:206.8698,knn_tta_n=50:205.7777,knn_ttm_n=50:224.1006,knn_tta_r_n=50:199.514,knn_ttm_r_n=50:201.2453,knn_tta_n=100:204.0141,knn_ttm_n=100:215.6162,knn_tta_r_n=100:202.0268,knn_ttm_r_n=100:200.8342'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:64.4309,knn_ttm_n=5:34.4636,knn_tta_r_n=5:63.2974,knn_ttm_r_n=5:85.5967,knn_tta_n=10:85.8091,knn_ttm_n=10:55.5662,knn_tta_r_n=10:90.2007,knn_ttm_r_n=10:86.4097,knn_tta_n=20:101.3763,knn_ttm_n=20:74.3186,knn_tta_r_n=20:107.3708,knn_ttm_r_n=20:97.289,knn_tta_n=50:113.3587,knn_ttm_n=50:97.9119,knn_tta_r_n=50:119.3551,knn_ttm_r_n=50:111.4565,knn_tta_n=100:120.493,knn_ttm_n=100:111.191,knn_tta_r_n=100:126.1456,knn_ttm_r_n=100:119.3631'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:186.5503,knn_ttm_n=5:216.5213,knn_tta_r_n=5:154.5961,knn_ttm_r_n=5:169.6069,knn_tta_n=10:170.1052,knn_ttm_n=10:190.7528,knn_tta_r_n=10:149.3359,knn_ttm_r_n=10:155.5285,knn_tta_n=20:154.2615,knn_ttm_n=20:172.8671,knn_tta_r_n=20:146.51,knn_ttm_r_n=20:149.937,knn_tta_n=50:145.4832,knn_ttm_n=50:153.8673,knn_tta_r_n=50:148.3133,knn_ttm_r_n=50:147.7618,knn_tta_n=100:145.5133,knn_ttm_n=100:147.9338,knn_tta_r_n=100:150.5524,knn_ttm_r_n=100:148.832'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_37'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:181.822,knn_ttm_n=5:191.0439,knn_tta_r_n=5:178.5998,knn_ttm_r_n=5:232.0372,knn_tta_n=10:228.4856,knn_ttm_n=10:249.6069,knn_tta_r_n=10:227.5966,knn_ttm_r_n=10:247.7094,knn_tta_n=20:251.4422,knn_ttm_n=20:271.852,knn_tta_r_n=20:251.3316,knn_ttm_r_n=20:258.9976,knn_tta_n=50:266.6028,knn_ttm_n=50:285.3355,knn_tta_r_n=50:265.997,knn_ttm_r_n=50:269.1233,knn_tta_n=100:272.2012,knn_ttm_n=100:289.9414,knn_tta_r_n=100:271.4177,knn_ttm_r_n=100:273.0234'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:393.5504,knn_ttm_n=5:500.6881,knn_tta_r_n=5:318.755,knn_ttm_r_n=5:327.7182,knn_tta_n=10:350.549,knn_ttm_n=10:436.892,knn_tta_r_n=10:308.3254,knn_ttm_r_n=10:313.0536,knn_tta_n=20:331.3182,knn_ttm_n=20:392.4724,knn_tta_r_n=20:305.9582,knn_ttm_r_n=20:307.8517,knn_tta_n=50:313.0877,knn_ttm_n=50:352.9924,knn_tta_r_n=50:302.2432,knn_ttm_r_n=50:304.1481,knn_tta_n=100:307.4846,knn_ttm_n=100:334.129,knn_tta_r_n=100:300.748,knn_ttm_r_n=100:301.7759'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:284.9363,knn_ttm_n=5:324.6498,knn_tta_r_n=5:284.8972,knn_ttm_r_n=5:378.5118,knn_tta_n=10:363.3466,knn_ttm_n=10:441.5978,knn_tta_r_n=10:364.709,knn_ttm_r_n=10:403.7648,knn_tta_n=20:400.1325,knn_ttm_n=20:487.7175,knn_tta_r_n=20:399.1276,knn_ttm_r_n=20:418.8285,knn_tta_n=50:424.6724,knn_ttm_n=50:518.9095,knn_tta_r_n=50:421.9983,knn_ttm_r_n=50:430.6524,knn_tta_n=100:433.9615,knn_ttm_n=100:530.4266,knn_tta_r_n=100:430.3888,knn_ttm_r_n=100:435.9054'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:659.2703,knn_ttm_n=5:845.1829,knn_tta_r_n=5:527.3927,knn_ttm_r_n=5:555.2073,knn_tta_n=10:579.9564,knn_ttm_n=10:773.7881,knn_tta_r_n=10:495.941,knn_ttm_r_n=10:515.335,knn_tta_n=20:527.8949,knn_ttm_n=20:705.0805,knn_tta_r_n=20:482.5507,knn_ttm_r_n=20:495.8823,knn_tta_n=50:498.8064,knn_ttm_n=50:638.1374,knn_tta_r_n=50:475.4463,knn_ttm_r_n=50:481.8077,knn_tta_n=100:487.4728,knn_ttm_n=100:612.4514,knn_tta_r_n=100:470.4456,knn_ttm_r_n=100:476.0359'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:306.9626,knn_ttm_n=5:350.586,knn_tta_r_n=5:301.1178,knn_ttm_r_n=5:402.7411,knn_tta_n=10:392.0724,knn_ttm_n=10:479.924,knn_tta_r_n=10:387.5885,knn_ttm_r_n=10:436.2839,knn_tta_n=20:429.5431,knn_ttm_n=20:544.8648,knn_tta_r_n=20:424.4598,knn_ttm_r_n=20:452.8857,knn_tta_n=50:451.9556,knn_ttm_n=50:577.5988,knn_tta_r_n=50:444.855,knn_ttm_r_n=50:460.2068,knn_tta_n=100:458.6086,knn_ttm_n=100:586.4352,knn_tta_r_n=100:451.6001,knn_ttm_r_n=100:462.496'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:658.0878,knn_ttm_n=5:869.6091,knn_tta_r_n=5:544.101,knn_ttm_r_n=5:593.4873,knn_tta_n=10:574.0153,knn_ttm_n=10:768.1478,knn_tta_r_n=10:512.4803,knn_ttm_r_n=10:548.2595,knn_tta_n=20:526.1613,knn_ttm_n=20:704.4298,knn_tta_r_n=20:495.435,knn_ttm_r_n=20:521.0317,knn_tta_n=50:494.6501,knn_ttm_n=50:642.1339,knn_tta_r_n=50:481.7586,knn_ttm_r_n=50:498.4477,knn_tta_n=100:484.0196,knn_ttm_n=100:618.7429,knn_tta_r_n=100:476.4456,knn_ttm_r_n=100:489.7029'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:130.3474,knn_ttm_n=5:133.0549,knn_tta_r_n=5:129.0223,knn_ttm_r_n=5:167.1896,knn_tta_n=10:162.2617,knn_ttm_n=10:170.3435,knn_tta_r_n=10:164.7463,knn_ttm_r_n=10:176.5126,knn_tta_n=20:181.579,knn_ttm_n=20:190.6559,knn_tta_r_n=20:182.7712,knn_ttm_r_n=20:186.0565,knn_tta_n=50:191.764,knn_ttm_n=50:202.2207,knn_tta_r_n=50:192.4949,knn_ttm_r_n=50:193.158,knn_tta_n=100:195.4504,knn_ttm_n=100:202.4343,knn_tta_r_n=100:196.5806,knn_ttm_r_n=100:196.427'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:297.5987,knn_ttm_n=5:385.4207,knn_tta_r_n=5:219.3751,knn_ttm_r_n=5:220.397,knn_tta_n=10:246.7305,knn_ttm_n=10:332.1149,knn_tta_r_n=10:207.2145,knn_ttm_r_n=10:206.5092,knn_tta_n=20:215.4451,knn_ttm_n=20:266.547,knn_tta_r_n=20:199.5509,knn_ttm_r_n=20:199.8896,knn_tta_n=50:202.1558,knn_ttm_n=50:229.4392,knn_tta_r_n=50:195.2025,knn_ttm_r_n=50:195.6236,knn_tta_n=100:195.3806,knn_ttm_n=100:212.0869,knn_tta_r_n=100:193.5755,knn_ttm_r_n=100:194.1504'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:155.7135,knn_ttm_n=5:162.8817,knn_tta_r_n=5:150.9387,knn_ttm_r_n=5:193.7751,knn_tta_n=10:192.5271,knn_ttm_n=10:208.5207,knn_tta_r_n=10:192.6255,knn_ttm_r_n=10:207.4338,knn_tta_n=20:212.1111,knn_ttm_n=20:230.9958,knn_tta_r_n=20:212.2006,knn_ttm_r_n=20:216.9299,knn_tta_n=50:222.27,knn_ttm_n=50:237.6659,knn_tta_r_n=50:223.3748,knn_ttm_r_n=50:224.3633,knn_tta_n=100:227.7316,knn_ttm_n=100:238.4693,knn_tta_r_n=100:228.0528,knn_ttm_r_n=100:227.8152'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:312.0421,knn_ttm_n=5:410.3893,knn_tta_r_n=5:243.8783,knn_ttm_r_n=5:245.2782,knn_tta_n=10:267.8787,knn_ttm_n=10:350.5808,knn_tta_r_n=10:230.3265,knn_ttm_r_n=10:231.6834,knn_tta_n=20:244.2488,knn_ttm_n=20:300.1566,knn_tta_r_n=20:225.4106,knn_ttm_r_n=20:226.333,knn_tta_n=50:230.1864,knn_ttm_n=50:264.2135,knn_tta_r_n=50:222.9821,knn_ttm_r_n=50:223.406,knn_tta_n=100:226.4996,knn_ttm_n=100:247.602,knn_tta_r_n=100:223.2615,knn_ttm_r_n=100:223.0376'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:95.6413,knn_ttm_n=5:96.1495,knn_tta_r_n=5:93.2131,knn_ttm_r_n=5:120.543,knn_tta_n=10:118.989,knn_ttm_n=10:126.2334,knn_tta_r_n=10:119.2216,knn_ttm_r_n=10:127.2376,knn_tta_n=20:130.9827,knn_ttm_n=20:138.9663,knn_tta_r_n=20:131.6477,knn_ttm_r_n=20:134.5787,knn_tta_n=50:137.7671,knn_ttm_n=50:146.4765,knn_tta_r_n=50:138.2933,knn_ttm_r_n=50:139.076,knn_tta_n=100:140.1079,knn_ttm_n=100:148.0546,knn_tta_r_n=100:140.8459,knn_ttm_r_n=100:140.9694'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:216.6252,knn_ttm_n=5:275.4618,knn_tta_r_n=5:172.3875,knn_ttm_r_n=5:174.1305,knn_tta_n=10:182.488,knn_ttm_n=10:235.2197,knn_tta_r_n=10:161.4698,knn_ttm_r_n=10:162.9646,knn_tta_n=20:162.9231,knn_ttm_n=20:197.3258,knn_tta_r_n=20:155.6743,knn_ttm_r_n=20:157.6529,knn_tta_n=50:152.6506,knn_ttm_n=50:168.6121,knn_tta_r_n=50:151.7571,knn_ttm_r_n=50:153.469,knn_tta_n=100:149.4351,knn_ttm_n=100:159.0819,knn_tta_r_n=100:151.321,knn_ttm_r_n=100:152.286'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_39'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:131.0609,knn_ttm_n=5:76.1764,knn_tta_r_n=5:129.606,knn_ttm_r_n=5:175.3792,knn_tta_n=10:176.8908,knn_ttm_n=10:126.5507,knn_tta_r_n=10:184.0671,knn_ttm_r_n=10:182.2654,knn_tta_n=20:211.4995,knn_ttm_n=20:170.156,knn_tta_r_n=20:217.3602,knn_ttm_r_n=20:204.1088,knn_tta_n=50:241.3804,knn_ttm_n=50:221.4552,knn_tta_r_n=50:244.9092,knn_ttm_r_n=50:231.8454,knn_tta_n=100:256.7177,knn_ttm_n=100:248.3532,knn_tta_r_n=100:259.2421,knn_ttm_r_n=100:248.2993'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:368.4165,knn_ttm_n=5:443.5312,knn_tta_r_n=5:296.4939,knn_ttm_r_n=5:308.3634,knn_tta_n=10:324.8445,knn_ttm_n=10:381.617,knn_tta_r_n=10:285.0676,knn_ttm_r_n=10:289.9461,knn_tta_n=20:303.54,knn_ttm_n=20:342.2287,knn_tta_r_n=20:283.101,knn_ttm_r_n=20:284.6063,knn_tta_n=50:293.8509,knn_ttm_n=50:316.9772,knn_tta_r_n=50:282.9963,knn_ttm_r_n=50:282.3868,knn_tta_n=100:291.0575,knn_ttm_n=100:310.4775,knn_tta_r_n=100:285.6381,knn_ttm_r_n=100:284.5102'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:187.0167,knn_ttm_n=5:114.6745,knn_tta_r_n=5:196.6448,knn_ttm_r_n=5:272.7589,knn_tta_n=10:264.7992,knn_ttm_n=10:192.0875,knn_tta_r_n=10:282.4221,knn_ttm_r_n=10:280.5114,knn_tta_n=20:312.2542,knn_ttm_n=20:266.4462,knn_tta_r_n=20:335.9931,knn_ttm_r_n=20:315.4841,knn_tta_n=50:355.0201,knn_ttm_n=50:343.2803,knn_tta_r_n=50:374.8313,knn_ttm_r_n=50:358.6756,knn_tta_n=100:379.3067,knn_ttm_n=100:389.8272,knn_tta_r_n=100:392.6611,knn_ttm_r_n=100:383.0354'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:535.0494,knn_ttm_n=5:599.3025,knn_tta_r_n=5:442.7344,knn_ttm_r_n=5:469.6789,knn_tta_n=10:471.9222,knn_ttm_n=10:544.2136,knn_tta_r_n=10:430.2406,knn_ttm_r_n=10:446.4919,knn_tta_n=20:448.9967,knn_ttm_n=20:506.0276,knn_tta_r_n=20:425.4571,knn_ttm_r_n=20:435.2091,knn_tta_n=50:431.8123,knn_ttm_n=50:483.1736,knn_tta_r_n=50:430.5493,knn_ttm_r_n=50:434.8127,knn_tta_n=100:431.8477,knn_ttm_n=100:475.7191,knn_tta_r_n=100:436.1633,knn_ttm_r_n=100:436.6311'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:189.2936,knn_ttm_n=5:110.0809,knn_tta_r_n=5:198.0011,knn_ttm_r_n=5:280.1302,knn_tta_n=10:264.3553,knn_ttm_n=10:189.4903,knn_tta_r_n=10:282.1849,knn_ttm_r_n=10:287.6123,knn_tta_n=20:314.5063,knn_ttm_n=20:266.1821,knn_tta_r_n=20:334.675,knn_ttm_r_n=20:319.9124,knn_tta_n=50:360.0312,knn_ttm_n=50:342.5212,knn_tta_r_n=50:374.2419,knn_ttm_r_n=50:358.6815,knn_tta_n=100:383.0357,knn_ttm_n=100:386.6334,knn_tta_r_n=100:392.8058,knn_ttm_r_n=100:380.5614'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:499.3911,knn_ttm_n=5:563.4126,knn_tta_r_n=5:445.1905,knn_ttm_r_n=5:481.5784,knn_tta_n=10:460.2851,knn_ttm_n=10:517.6554,knn_tta_r_n=10:422.1124,knn_ttm_r_n=10:441.725,knn_tta_n=20:425.0973,knn_ttm_n=20:481.2533,knn_tta_r_n=20:412.1617,knn_ttm_r_n=20:424.7281,knn_tta_n=50:411.3175,knn_ttm_n=50:451.2377,knn_tta_r_n=50:410.8147,knn_ttm_r_n=50:414.8052,knn_tta_n=100:411.3331,knn_ttm_n=100:447.3661,knn_tta_r_n=100:414.2084,knn_ttm_r_n=100:415.9026'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:115.5386,knn_ttm_n=5:66.2984,knn_tta_r_n=5:108.7467,knn_ttm_r_n=5:142.7514,knn_tta_n=10:151.0135,knn_ttm_n=10:107.1815,knn_tta_r_n=10:154.8368,knn_ttm_r_n=10:149.4254,knn_tta_n=20:176.4809,knn_ttm_n=20:140.075,knn_tta_r_n=20:183.5351,knn_ttm_r_n=20:168.0738,knn_tta_n=50:197.3545,knn_ttm_n=50:174.61,knn_tta_r_n=50:203.1592,knn_ttm_r_n=50:191.0254,knn_tta_n=100:209.2085,knn_ttm_n=100:195.2719,knn_tta_r_n=100:213.5866,knn_ttm_r_n=100:203.5064'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:295.519,knn_ttm_n=5:357.5225,knn_tta_r_n=5:228.6609,knn_ttm_r_n=5:249.8479,knn_tta_n=10:250.3214,knn_ttm_n=10:301.8269,knn_tta_r_n=10:217.971,knn_ttm_r_n=10:226.4281,knn_tta_n=20:230.1456,knn_ttm_n=20:263.2469,knn_tta_r_n=20:217.2119,knn_ttm_r_n=20:218.312,knn_tta_n=50:220.5073,knn_ttm_n=50:235.6326,knn_tta_r_n=50:219.47,knn_ttm_r_n=50:218.2946,knn_tta_n=100:221.5837,knn_ttm_n=100:228.0947,knn_tta_r_n=100:222.554,knn_ttm_r_n=100:220.1846'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:122.1917,knn_ttm_n=5:71.4718,knn_tta_r_n=5:119.7782,knn_ttm_r_n=5:160.9194,knn_tta_n=10:165.7731,knn_ttm_n=10:118.6727,knn_tta_r_n=10:171.1547,knn_ttm_r_n=10:166.8758,knn_tta_n=20:194.7538,knn_ttm_n=20:160.0282,knn_tta_r_n=20:201.9084,knn_ttm_r_n=20:188.1868,knn_tta_n=50:216.197,knn_ttm_n=50:199.6269,knn_tta_r_n=50:223.8493,knn_ttm_r_n=50:212.984,knn_tta_n=100:228.2136,knn_ttm_n=100:219.9139,knn_tta_r_n=100:234.0918,knn_ttm_r_n=100:225.4202'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:302.3161,knn_ttm_n=5:347.8877,knn_tta_r_n=5:230.8161,knn_ttm_r_n=5:250.2052,knn_tta_n=10:262.8757,knn_ttm_n=10:308.4863,knn_tta_r_n=10:221.8728,knn_ttm_r_n=10:229.0999,knn_tta_n=20:245.0931,knn_ttm_n=20:280.6633,knn_tta_r_n=20:221.0741,knn_ttm_r_n=20:222.6803,knn_tta_n=50:230.931,knn_ttm_n=50:258.1509,knn_tta_r_n=50:222.3177,knn_ttm_r_n=50:222.392,knn_tta_n=100:230.0017,knn_ttm_n=100:248.731,knn_tta_r_n=100:226.9717,knn_ttm_r_n=100:223.6583'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:59.0678,knn_ttm_n=5:34.5388,knn_tta_r_n=5:56.7621,knn_ttm_r_n=5:76.3049,knn_tta_n=10:77.8859,knn_ttm_n=10:53.1129,knn_tta_r_n=10:80.4988,knn_ttm_r_n=10:78.4459,knn_tta_n=20:90.8165,knn_ttm_n=20:69.9596,knn_tta_r_n=20:93.853,knn_ttm_r_n=20:86.648,knn_tta_n=50:101.2275,knn_ttm_n=50:89.7079,knn_tta_r_n=50:104.602,knn_ttm_r_n=50:97.9657,knn_tta_n=100:106.3342,knn_ttm_n=100:99.1173,knn_tta_r_n=100:110.6452,knn_ttm_r_n=100:104.7875'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:192.323,knn_ttm_n=5:228.1873,knn_tta_r_n=5:147.872,knn_ttm_r_n=5:153.6056,knn_tta_n=10:170.8982,knn_ttm_n=10:198.4429,knn_tta_r_n=10:144.9928,knn_ttm_r_n=10:146.7547,knn_tta_n=20:161.54,knn_ttm_n=20:178.7274,knn_tta_r_n=20:144.7951,knn_ttm_r_n=20:145.1257,knn_tta_n=50:153.6825,knn_ttm_n=50:163.9971,knn_tta_r_n=50:147.3482,knn_ttm_r_n=50:145.5829,knn_tta_n=100:151.9059,knn_ttm_n=100:158.9532,knn_tta_r_n=100:149.9516,knn_ttm_r_n=100:147.4721'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_40'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:131.2421,knn_ttm_n=5:90.8596,knn_tta_r_n=5:131.5224,knn_ttm_r_n=5:177.3771,knn_tta_n=10:177.0118,knn_ttm_n=10:141.3127,knn_tta_r_n=10:186.2676,knn_ttm_r_n=10:189.7155,knn_tta_n=20:207.1652,knn_ttm_n=20:181.0456,knn_tta_r_n=20:216.3165,knn_ttm_r_n=20:210.1499,knn_tta_n=50:230.976,knn_ttm_n=50:221.44,knn_tta_r_n=50:236.151,knn_ttm_r_n=50:230.8186,knn_tta_n=100:240.035,knn_ttm_n=100:240.9146,knn_tta_r_n=100:244.1024,knn_ttm_r_n=100:240.581'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:333.4607,knn_ttm_n=5:394.2285,knn_tta_r_n=5:274.2061,knn_ttm_r_n=5:291.8543,knn_tta_n=10:298.6579,knn_ttm_n=10:350.7436,knn_tta_r_n=10:268.7584,knn_ttm_r_n=10:273.9628,knn_tta_n=20:280.6223,knn_ttm_n=20:320.4742,knn_tta_r_n=20:267.7279,knn_ttm_r_n=20:270.7227,knn_tta_n=50:268.848,knn_ttm_n=50:295.013,knn_tta_r_n=50:266.3103,knn_ttm_r_n=50:268.1573,knn_tta_n=100:267.8221,knn_ttm_n=100:284.8434,knn_tta_r_n=100:267.5071,knn_ttm_r_n=100:267.792'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:186.7321,knn_ttm_n=5:141.1036,knn_tta_r_n=5:198.7117,knn_ttm_r_n=5:278.5661,knn_tta_n=10:256.4897,knn_ttm_n=10:217.1626,knn_tta_r_n=10:278.8956,knn_ttm_r_n=10:292.5626,knn_tta_n=20:304.1259,knn_ttm_n=20:279.7255,knn_tta_r_n=20:325.2489,knn_ttm_r_n=20:320.8685,knn_tta_n=50:337.9679,knn_ttm_n=50:342.3484,knn_tta_r_n=50:356.532,knn_ttm_r_n=50:351.9595,knn_tta_n=100:353.3348,knn_ttm_n=100:371.1605,knn_tta_r_n=100:370.8349,knn_ttm_r_n=100:368.0802'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:489.8988,knn_ttm_n=5:583.3689,knn_tta_r_n=5:407.1174,knn_ttm_r_n=5:438.3817,knn_tta_n=10:437.623,knn_ttm_n=10:511.5718,knn_tta_r_n=10:385.1295,knn_ttm_r_n=10:404.6902,knn_tta_n=20:404.6885,knn_ttm_n=20:470.9147,knn_tta_r_n=20:388.9128,knn_ttm_r_n=20:395.6903,knn_tta_n=50:394.301,knn_ttm_n=50:442.4226,knn_tta_r_n=50:395.5727,knn_ttm_r_n=50:398.0581,knn_tta_n=100:397.8779,knn_ttm_n=100:438.1937,knn_tta_r_n=100:403.0449,knn_ttm_r_n=100:403.9687'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:175.3997,knn_ttm_n=5:134.1541,knn_tta_r_n=5:181.079,knn_ttm_r_n=5:257.5026,knn_tta_n=10:231.2627,knn_ttm_n=10:203.128,knn_tta_r_n=10:249.4448,knn_ttm_r_n=10:267.7249,knn_tta_n=20:271.7694,knn_ttm_n=20:256.4042,knn_tta_r_n=20:294.6805,knn_ttm_r_n=20:293.9107,knn_tta_n=50:310.8576,knn_ttm_n=50:313.6793,knn_tta_r_n=50:331.1849,knn_ttm_r_n=50:326.263,knn_tta_n=100:332.4023,knn_ttm_n=100:346.9184,knn_tta_r_n=100:351.29,knn_ttm_r_n=100:346.9564'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:408.1788,knn_ttm_n=5:476.4389,knn_tta_r_n=5:383.3365,knn_ttm_r_n=5:428.8724,knn_tta_n=10:374.4329,knn_ttm_n=10:429.7409,knn_tta_r_n=10:360.8243,knn_ttm_r_n=10:387.7295,knn_tta_n=20:354.2992,knn_ttm_n=20:398.4811,knn_tta_r_n=20:359.0306,knn_ttm_r_n=20:374.5108,knn_tta_n=50:349.5496,knn_ttm_n=50:386.9341,knn_tta_r_n=50:365.3523,knn_ttm_r_n=50:371.7238,knn_tta_n=100:351.5157,knn_ttm_n=100:385.5554,knn_tta_r_n=100:374.1671,knn_ttm_r_n=100:376.7792'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:114.5683,knn_ttm_n=5:78.4268,knn_tta_r_n=5:112.3978,knn_ttm_r_n=5:151.3103,knn_tta_n=10:149.779,knn_ttm_n=10:116.2263,knn_tta_r_n=10:155.3033,knn_ttm_r_n=10:156.4862,knn_tta_n=20:174.5558,knn_ttm_n=20:147.5866,knn_tta_r_n=20:180.0842,knn_ttm_r_n=20:173.9092,knn_tta_n=50:191.7992,knn_ttm_n=50:178.9739,knn_tta_r_n=50:195.8784,knn_ttm_r_n=50:191.0989,knn_tta_n=100:198.7281,knn_ttm_n=100:192.7275,knn_tta_r_n=100:201.2078,knn_ttm_r_n=100:198.3602'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:269.6682,knn_ttm_n=5:315.4944,knn_tta_r_n=5:208.0003,knn_ttm_r_n=5:227.7708,knn_tta_n=10:235.809,knn_ttm_n=10:272.563,knn_tta_r_n=10:204.4436,knn_ttm_r_n=10:210.8718,knn_tta_n=20:215.6491,knn_ttm_n=20:241.9488,knn_tta_r_n=20:201.6499,knn_ttm_r_n=20:204.4488,knn_tta_n=50:204.2403,knn_ttm_n=50:218.7225,knn_tta_r_n=50:200.971,knn_ttm_r_n=50:202.0989,knn_tta_n=100:201.7601,knn_ttm_n=100:209.5659,knn_tta_r_n=100:201.0912,knn_ttm_r_n=100:201.4889'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:118.05,knn_ttm_n=5:85.6367,knn_tta_r_n=5:118.2488,knn_ttm_r_n=5:159.9056,knn_tta_n=10:157.9457,knn_ttm_n=10:126.5844,knn_tta_r_n=10:165.8979,knn_ttm_r_n=10:170.2562,knn_tta_n=20:185.3082,knn_ttm_n=20:158.9315,knn_tta_r_n=20:193.2704,knn_ttm_r_n=20:187.6109,knn_tta_n=50:204.1381,knn_ttm_n=50:189.8978,knn_tta_r_n=50:210.1381,knn_ttm_r_n=50:204.7958,knn_tta_n=100:213.7558,knn_ttm_n=100:207.4176,knn_tta_r_n=100:216.7457,knn_ttm_r_n=100:212.8575'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:288.6759,knn_ttm_n=5:347.624,knn_tta_r_n=5:215.2505,knn_ttm_r_n=5:232.9565,knn_tta_n=10:243.0246,knn_ttm_n=10:297.4939,knn_tta_r_n=10:207.4261,knn_ttm_r_n=10:213.0893,knn_tta_n=20:222.5944,knn_ttm_n=20:259.5443,knn_tta_r_n=20:206.8639,knn_ttm_r_n=20:208.4058,knn_tta_n=50:214.5829,knn_ttm_n=50:232.7752,knn_tta_r_n=50:208.1237,knn_ttm_r_n=50:207.5563,knn_tta_n=100:211.4349,knn_ttm_n=100:222.4748,knn_tta_r_n=100:209.0212,knn_ttm_r_n=100:208.3561'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:69.7413,knn_ttm_n=5:47.2679,knn_tta_r_n=5:68.4475,knn_ttm_r_n=5:94.3052,knn_tta_n=10:91.463,knn_ttm_n=10:72.2427,knn_tta_r_n=10:95.0396,knn_ttm_r_n=10:96.7519,knn_tta_n=20:105.2467,knn_ttm_n=20:90.4687,knn_tta_r_n=20:110.4565,knn_ttm_r_n=20:106.6765,knn_tta_n=50:117.2462,knn_ttm_n=50:109.6003,knn_tta_r_n=50:121.6653,knn_ttm_r_n=50:118.0632,knn_tta_n=100:122.2255,knn_ttm_n=100:118.8244,knn_tta_r_n=100:126.3327,knn_ttm_r_n=100:123.6951'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:202.4337,knn_ttm_n=5:236.1304,knn_tta_r_n=5:162.6735,knn_ttm_r_n=5:172.0119,knn_tta_n=10:183.487,knn_ttm_n=10:207.2236,knn_tta_r_n=10:155.3811,knn_ttm_r_n=10:160.0225,knn_tta_n=20:164.1058,knn_ttm_n=20:188.5685,knn_tta_r_n=20:152.372,knn_ttm_r_n=20:154.3726,knn_tta_n=50:152.0851,knn_ttm_n=50:167.0155,knn_tta_r_n=50:150.6583,knn_ttm_r_n=50:151.307,knn_tta_n=100:149.1108,knn_ttm_n=100:157.754,knn_tta_r_n=100:150.8069,knn_ttm_r_n=100:150.925'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_47'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:205.5975,knn_ttm_n=5:216.0394,knn_tta_r_n=5:204.5821,knn_ttm_r_n=5:255.8102,knn_tta_n=10:267.4231,knn_ttm_n=10:263.7416,knn_tta_r_n=10:251.5178,knn_ttm_r_n=10:269.4894,knn_tta_n=20:297.5109,knn_ttm_n=20:289.1514,knn_tta_r_n=20:273.7231,knn_ttm_r_n=20:283.5491,knn_tta_n=50:302.0689,knn_ttm_n=50:304.2588,knn_tta_r_n=50:287.3456,knn_ttm_r_n=50:289.293,knn_tta_n=100:299.6807,knn_ttm_n=100:307.7558,knn_tta_r_n=100:291.3081,knn_ttm_r_n=100:291.1687'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:439.7858,knn_ttm_n=5:541.1363,knn_tta_r_n=5:361.8996,knn_ttm_r_n=5:376.46,knn_tta_n=10:390.3203,knn_ttm_n=10:455.0639,knn_tta_r_n=10:336.873,knn_ttm_r_n=10:346.799,knn_tta_n=20:365.6044,knn_ttm_n=20:394.3842,knn_tta_r_n=20:324.5434,knn_ttm_r_n=20:335.4217,knn_tta_n=50:339.4832,knn_ttm_n=50:353.4984,knn_tta_r_n=50:319.3669,knn_ttm_r_n=50:324.3521,knn_tta_n=100:329.4396,knn_ttm_n=100:341.029,knn_tta_r_n=100:317.7064,knn_ttm_r_n=100:320.6026'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:318.6037,knn_ttm_n=5:332.7552,knn_tta_r_n=5:302.8795,knn_ttm_r_n=5:386.9892,knn_tta_n=10:379.7308,knn_ttm_n=10:420.9535,knn_tta_r_n=10:375.2752,knn_ttm_r_n=10:404.1729,knn_tta_n=20:418.6591,knn_ttm_n=20:464.7303,knn_tta_r_n=20:412.1112,knn_ttm_r_n=20:420.3236,knn_tta_n=50:444.3212,knn_ttm_n=50:492.8302,knn_tta_r_n=50:427.9126,knn_ttm_r_n=50:432.1355,knn_tta_n=100:456.5784,knn_ttm_n=100:496.4192,knn_tta_r_n=100:434.8929,knn_ttm_r_n=100:436.6929'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:673.9405,knn_ttm_n=5:835.7316,knn_tta_r_n=5:524.8367,knn_ttm_r_n=5:547.172,knn_tta_n=10:588.2487,knn_ttm_n=10:758.1821,knn_tta_r_n=10:497.9645,knn_ttm_r_n=10:507.0213,knn_tta_n=20:548.3632,knn_ttm_n=20:691.7043,knn_tta_r_n=20:492.4089,knn_ttm_r_n=20:492.542,knn_tta_n=50:519.9221,knn_ttm_n=50:619.2709,knn_tta_r_n=50:481.6285,knn_ttm_r_n=50:483.9177,knn_tta_n=100:516.0882,knn_ttm_n=100:584.9654,knn_tta_r_n=100:477.663,knn_ttm_r_n=100:479.2157'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:422.0409,knn_ttm_n=5:364.6691,knn_tta_r_n=5:367.8719,knn_ttm_r_n=5:421.3947,knn_tta_n=10:463.5347,knn_ttm_n=10:444.9258,knn_tta_r_n=10:437.464,knn_ttm_r_n=10:438.8165,knn_tta_n=20:468.0811,knn_ttm_n=20:484.921,knn_tta_r_n=20:457.2813,knn_ttm_r_n=20:454.3596,knn_tta_n=50:527.6876,knn_ttm_n=50:505.931,knn_tta_r_n=50:457.2398,knn_ttm_r_n=50:462.2145,knn_tta_n=100:524.8272,knn_ttm_n=100:514.3109,knn_tta_r_n=100:468.539,knn_ttm_r_n=100:464.8813'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:700.0144,knn_ttm_n=5:786.7648,knn_tta_r_n=5:572.3741,knn_ttm_r_n=5:564.9097,knn_tta_n=10:602.0295,knn_ttm_n=10:677.1472,knn_tta_r_n=10:543.4436,knn_ttm_r_n=10:519.2132,knn_tta_n=20:543.5201,knn_ttm_n=20:621.0007,knn_tta_r_n=20:517.4451,knn_ttm_r_n=20:504.7149,knn_tta_n=50:565.6343,knn_ttm_n=50:578.894,knn_tta_r_n=50:489.3561,knn_ttm_r_n=50:492.918,knn_tta_n=100:547.4897,knn_ttm_n=100:563.3051,knn_tta_r_n=100:491.2597,knn_ttm_r_n=100:487.0413'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:151.1915,knn_ttm_n=5:147.4584,knn_tta_r_n=5:143.4386,knn_ttm_r_n=5:182.0688,knn_tta_n=10:189.9533,knn_ttm_n=10:188.2972,knn_tta_r_n=10:181.267,knn_ttm_r_n=10:194.2009,knn_tta_n=20:204.4604,knn_ttm_n=20:202.2561,knn_tta_r_n=20:199.409,knn_ttm_r_n=20:203.9398,knn_tta_n=50:210.8219,knn_ttm_n=50:212.146,knn_tta_r_n=50:209.4491,knn_ttm_r_n=50:210.3817,knn_tta_n=100:213.1432,knn_ttm_n=100:215.1614,knn_tta_r_n=100:212.5339,knn_ttm_r_n=100:212.7203'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:294.3032,knn_ttm_n=5:365.898,knn_tta_r_n=5:230.9514,knn_ttm_r_n=5:243.5114,knn_tta_n=10:257.0997,knn_ttm_n=10:312.6091,knn_tta_r_n=10:219.2125,knn_ttm_r_n=10:222.5469,knn_tta_n=20:235.4006,knn_ttm_n=20:265.2539,knn_tta_r_n=20:216.3165,knn_ttm_r_n=20:217.3235,knn_tta_n=50:221.2284,knn_ttm_n=50:236.1139,knn_tta_r_n=50:214.9731,knn_ttm_r_n=50:215.1541,knn_tta_n=100:217.6858,knn_ttm_n=100:226.0344,knn_tta_r_n=100:214.6215,knn_ttm_r_n=100:214.729'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:165.7735,knn_ttm_n=5:170.206,knn_tta_r_n=5:161.3201,knn_ttm_r_n=5:204.4681,knn_tta_n=10:203.091,knn_ttm_n=10:217.6218,knn_tta_r_n=10:202.19,knn_ttm_r_n=10:216.4419,knn_tta_n=20:221.2429,knn_ttm_n=20:235.4565,knn_tta_r_n=20:221.8784,knn_ttm_r_n=20:226.8077,knn_tta_n=50:233.0016,knn_ttm_n=50:243.151,knn_tta_r_n=50:233.7158,knn_ttm_r_n=50:234.6037,knn_tta_n=100:236.9101,knn_ttm_n=100:244.8561,knn_tta_r_n=100:237.7174,knn_ttm_r_n=100:237.5205'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:318.7532,knn_ttm_n=5:428.6695,knn_tta_r_n=5:247.3907,knn_ttm_r_n=5:252.9885,knn_tta_n=10:273.7597,knn_ttm_n=10:353.3241,knn_tta_r_n=10:234.4791,knn_ttm_r_n=10:235.9322,knn_tta_n=20:247.8926,knn_ttm_n=20:302.9962,knn_tta_r_n=20:228.8944,knn_ttm_r_n=20:229.7612,knn_tta_n=50:236.4193,knn_ttm_n=50:267.0359,knn_tta_r_n=50:225.5933,knn_ttm_r_n=50:225.5577,knn_tta_n=100:230.5989,knn_ttm_n=100:252.3987,knn_tta_r_n=100:225.4138,knn_ttm_r_n=100:224.9737'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:85.8537,knn_ttm_n=5:88.1317,knn_tta_r_n=5:83.2784,knn_ttm_r_n=5:104.9836,knn_tta_n=10:103.5895,knn_ttm_n=10:109.9393,knn_tta_r_n=10:103.2386,knn_ttm_r_n=10:110.3187,knn_tta_n=20:112.4031,knn_ttm_n=20:119.9774,knn_tta_r_n=20:112.9653,knn_ttm_r_n=20:115.1153,knn_tta_n=50:118.5034,knn_ttm_n=50:124.1941,knn_tta_r_n=50:119.0759,knn_ttm_r_n=50:119.2964,knn_tta_n=100:120.7451,knn_ttm_n=100:125.2421,knn_tta_r_n=100:122.1507,knn_ttm_r_n=100:121.641'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:191.1846,knn_ttm_n=5:235.7889,knn_tta_r_n=5:158.0836,knn_ttm_r_n=5:163.4559,knn_tta_n=10:167.6967,knn_ttm_n=10:204.7046,knn_tta_r_n=10:150.4428,knn_ttm_r_n=10:153.1353,knn_tta_n=20:155.8828,knn_ttm_n=20:181.4159,knn_tta_r_n=20:146.579,knn_ttm_r_n=20:146.8678,knn_tta_n=50:147.2737,knn_ttm_n=50:162.309,knn_tta_r_n=50:143.9705,knn_ttm_r_n=50:145.0136,knn_tta_n=100:142.4781,knn_ttm_n=100:150.3178,knn_tta_r_n=100:143.0558,knn_ttm_r_n=100:143.6007'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_54'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:159.9143,knn_ttm_n=5:136.5886,knn_tta_r_n=5:162.0084,knn_ttm_r_n=5:206.9516,knn_tta_n=10:208.8086,knn_ttm_n=10:186.8327,knn_tta_r_n=10:211.3611,knn_ttm_r_n=10:223.888,knn_tta_n=20:238.4734,knn_ttm_n=20:221.6172,knn_tta_r_n=20:242.755,knn_ttm_r_n=20:242.8209,knn_tta_n=50:260.1356,knn_ttm_n=50:260.2179,knn_tta_r_n=50:264.2803,knn_ttm_r_n=50:262.3396,knn_tta_n=100:270.4836,knn_ttm_n=100:279.2882,knn_tta_r_n=100:272.0832,knn_ttm_r_n=100:271.4207'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:403.4047,knn_ttm_n=5:495.2399,knn_tta_r_n=5:321.5832,knn_ttm_r_n=5:325.0164,knn_tta_n=10:351.1089,knn_ttm_n=10:423.7318,knn_tta_r_n=10:307.5407,knn_ttm_r_n=10:305.3527,knn_tta_n=20:322.7225,knn_ttm_n=20:379.6555,knn_tta_r_n=20:306.9814,knn_ttm_r_n=20:303.6536,knn_tta_n=50:310.7353,knn_ttm_n=50:347.2304,knn_tta_r_n=50:309.2568,knn_ttm_r_n=50:307.8215,knn_tta_n=100:308.5588,knn_ttm_n=100:331.8262,knn_tta_r_n=100:308.2293,knn_ttm_r_n=100:310.8561'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:241.7201,knn_ttm_n=5:236.6612,knn_tta_r_n=5:250.0897,knn_ttm_r_n=5:327.552,knn_tta_n=10:308.6188,knn_ttm_n=10:333.1963,knn_tta_r_n=10:328.0397,knn_ttm_r_n=10:350.3155,knn_tta_n=20:352.0765,knn_ttm_n=20:390.2203,knn_tta_r_n=20:370.0227,knn_ttm_r_n=20:374.5654,knn_tta_n=50:387.1661,knn_ttm_n=50:446.5509,knn_tta_r_n=50:396.76,knn_ttm_r_n=50:395.8051,knn_tta_n=100:405.2693,knn_ttm_n=100:487.7,knn_tta_r_n=100:406.2612,knn_ttm_r_n=100:408.276'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:563.5846,knn_ttm_n=5:685.7265,knn_tta_r_n=5:464.8586,knn_ttm_r_n=5:487.7809,knn_tta_n=10:490.7625,knn_ttm_n=10:626.4932,knn_tta_r_n=10:452.2,knn_ttm_r_n=10:462.0051,knn_tta_n=20:474.9697,knn_ttm_n=20:585.5151,knn_tta_r_n=20:451.7495,knn_ttm_r_n=20:456.2123,knn_tta_n=50:458.625,knn_ttm_n=50:560.3147,knn_tta_r_n=50:453.3826,knn_ttm_r_n=50:457.2917,knn_tta_n=100:457.7233,knn_ttm_n=100:565.2889,knn_tta_r_n=100:452.2905,knn_ttm_r_n=100:456.9322'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:229.4421,knn_ttm_n=5:224.8892,knn_tta_r_n=5:233.0316,knn_ttm_r_n=5:309.0815,knn_tta_n=10:300.6932,knn_ttm_n=10:314.3656,knn_tta_r_n=10:311.6251,knn_ttm_r_n=10:335.9368,knn_tta_n=20:344.3335,knn_ttm_n=20:374.3751,knn_tta_r_n=20:358.1556,knn_ttm_r_n=20:364.1249,knn_tta_n=50:383.0851,knn_ttm_n=50:436.8138,knn_tta_r_n=50:396.5823,knn_ttm_r_n=50:393.0346,knn_tta_n=100:408.7919,knn_ttm_n=100:487.6189,knn_tta_r_n=100:413.1405,knn_ttm_r_n=100:411.5738'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:514.9329,knn_ttm_n=5:645.57,knn_tta_r_n=5:456.8811,knn_ttm_r_n=5:490.4783,knn_tta_n=10:458.1536,knn_ttm_n=10:565.7817,knn_tta_r_n=10:435.0111,knn_ttm_r_n=10:457.4026,knn_tta_n=20:424.1388,knn_ttm_n=20:512.639,knn_tta_r_n=20:426.607,knn_ttm_r_n=20:440.0457,knn_tta_n=50:419.4161,knn_ttm_n=50:491.1817,knn_tta_r_n=50:432.9233,knn_ttm_r_n=50:438.6036,knn_tta_n=100:427.2262,knn_ttm_n=100:506.4926,knn_tta_r_n=100:438.1461,knn_ttm_r_n=100:442.7115'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:147.3927,knn_ttm_n=5:119.138,knn_tta_r_n=5:128.6128,knn_ttm_r_n=5:170.7747,knn_tta_n=10:175.7991,knn_ttm_n=10:153.4677,knn_tta_r_n=10:166.1115,knn_ttm_r_n=10:177.0026,knn_tta_n=20:191.9967,knn_ttm_n=20:176.2721,knn_tta_r_n=20:184.1114,knn_ttm_r_n=20:186.396,knn_tta_n=50:193.4909,knn_ttm_n=50:192.6194,knn_tta_r_n=50:194.3197,knn_ttm_r_n=50:192.0855,knn_tta_n=100:197.5838,knn_ttm_n=100:200.4867,knn_tta_r_n=100:197.8391,knn_ttm_r_n=100:196.1143'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:316.6686,knn_ttm_n=5:381.4599,knn_tta_r_n=5:221.2319,knn_ttm_r_n=5:233.9027,knn_tta_n=10:265.2298,knn_ttm_n=10:323.9626,knn_tta_r_n=10:211.0774,knn_ttm_r_n=10:216.1846,knn_tta_n=20:232.8486,knn_ttm_n=20:272.5353,knn_tta_r_n=20:205.6854,knn_ttm_r_n=20:210.1646,knn_tta_n=50:203.7839,knn_ttm_n=50:225.9276,knn_tta_r_n=50:199.2036,knn_ttm_r_n=50:200.1469,knn_tta_n=100:200.0898,knn_ttm_n=100:215.803,knn_tta_r_n=100:198.2798,knn_ttm_r_n=100:198.9747'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:137.4036,knn_ttm_n=5:123.9531,knn_tta_r_n=5:136.2253,knn_ttm_r_n=5:176.7077,knn_tta_n=10:170.7231,knn_ttm_n=10:161.1052,knn_tta_r_n=10:175.5091,knn_ttm_r_n=10:183.2968,knn_tta_n=20:192.7587,knn_ttm_n=20:187.8246,knn_tta_r_n=20:196.8428,knn_ttm_r_n=20:197.5099,knn_tta_n=50:207.7326,knn_ttm_n=50:209.9693,knn_tta_r_n=50:209.0047,knn_ttm_r_n=50:208.4692,knn_tta_n=100:213.2834,knn_ttm_n=100:219.4026,knn_tta_r_n=100:213.8481,knn_ttm_r_n=100:213.8746'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:309.5012,knn_ttm_n=5:381.0157,knn_tta_r_n=5:231.4434,knn_ttm_r_n=5:241.1639,knn_tta_n=10:260.2478,knn_ttm_n=10:334.0829,knn_tta_r_n=10:222.5727,knn_ttm_r_n=10:225.8401,knn_tta_n=20:232.618,knn_ttm_n=20:289.2341,knn_tta_r_n=20:214.9192,knn_ttm_r_n=20:219.3476,knn_tta_n=50:218.3012,knn_ttm_n=50:254.9583,knn_tta_r_n=50:211.0457,knn_ttm_r_n=50:213.6789,knn_tta_n=100:212.9226,knn_ttm_n=100:242.546,knn_tta_r_n=100:210.5282,knn_ttm_r_n=100:212.262'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:100.3462,knn_ttm_n=5:85.495,knn_tta_r_n=5:94.0205,knn_ttm_r_n=5:116.642,knn_tta_n=10:120.5616,knn_ttm_n=10:109.0157,knn_tta_r_n=10:117.1416,knn_ttm_r_n=10:121.6415,knn_tta_n=20:146.4088,knn_ttm_n=20:129.1414,knn_tta_r_n=20:129.3941,knn_ttm_r_n=20:133.5245,knn_tta_n=50:138.0177,knn_ttm_n=50:136.4139,knn_tta_r_n=50:136.8649,knn_ttm_r_n=50:135.091,knn_tta_n=100:141.3514,knn_ttm_n=100:142.4469,knn_tta_r_n=100:139.6754,knn_ttm_r_n=100:138.7815'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:211.4948,knn_ttm_n=5:253.8866,knn_tta_r_n=5:171.1089,knn_ttm_r_n=5:177.0613,knn_tta_n=10:177.3668,knn_ttm_n=10:212.5015,knn_tta_r_n=10:159.4391,knn_ttm_r_n=10:161.0508,knn_tta_n=20:173.3328,knn_ttm_n=20:186.8286,knn_tta_r_n=20:154.3132,knn_ttm_r_n=20:158.4,knn_tta_n=50:156.981,knn_ttm_n=50:167.7024,knn_tta_r_n=50:155.5248,knn_ttm_r_n=50:154.1794,knn_tta_n=100:155.3594,knn_ttm_n=100:160.4483,knn_tta_r_n=100:154.8485,knn_ttm_r_n=100:154.3554'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_57'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:139.5428,knn_ttm_n=5:112.3401,knn_tta_r_n=5:140.9049,knn_ttm_r_n=5:188.175,knn_tta_n=10:186.5431,knn_ttm_n=10:157.2256,knn_tta_r_n=10:195.0771,knn_ttm_r_n=10:202.8412,knn_tta_n=20:218.7618,knn_ttm_n=20:195.8667,knn_tta_r_n=20:225.7946,knn_ttm_r_n=20:223.4413,knn_tta_n=50:242.7302,knn_ttm_n=50:234.0726,knn_tta_r_n=50:246.569,knn_ttm_r_n=50:242.7567,knn_tta_n=100:253.2341,knn_ttm_n=100:252.2899,knn_tta_r_n=100:255.4586,knn_ttm_r_n=100:252.3428'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:352.8689,knn_ttm_n=5:423.8556,knn_tta_r_n=5:287.4915,knn_ttm_r_n=5:307.8247,knn_tta_n=10:312.6936,knn_ttm_n=10:365.6034,knn_tta_r_n=10:275.0956,knn_ttm_r_n=10:285.2155,knn_tta_n=20:291.8096,knn_ttm_n=20:329.9673,knn_tta_r_n=20:272.661,knn_ttm_r_n=20:275.549,knn_tta_n=50:281.3383,knn_ttm_n=50:301.8329,knn_tta_r_n=50:274.2736,knn_ttm_r_n=50:273.9207,knn_tta_n=100:278.208,knn_ttm_n=100:294.275,knn_tta_r_n=100:276.092,knn_ttm_r_n=100:276.3976'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:211.342,knn_ttm_n=5:182.0771,knn_tta_r_n=5:214.8268,knn_ttm_r_n=5:294.2239,knn_tta_n=10:290.4392,knn_ttm_n=10:277.8102,knn_tta_r_n=10:299.2401,knn_ttm_r_n=10:316.1989,knn_tta_n=20:337.6116,knn_ttm_n=20:343.9768,knn_tta_r_n=20:345.0929,knn_ttm_r_n=20:347.2513,knn_tta_n=50:365.2779,knn_ttm_n=50:398.6704,knn_tta_r_n=50:374.1165,knn_ttm_r_n=50:374.8564,knn_tta_n=100:383.7042,knn_ttm_n=100:428.5925,knn_tta_r_n=100:387.848,knn_ttm_r_n=100:387.524'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:549.6947,knn_ttm_n=5:648.2281,knn_tta_r_n=5:446.0084,knn_ttm_r_n=5:480.2254,knn_tta_n=10:479.5746,knn_ttm_n=10:578.4669,knn_tta_r_n=10:423.6186,knn_ttm_r_n=10:447.0385,knn_tta_n=20:443.9503,knn_ttm_n=20:530.9176,knn_tta_r_n=20:418.6597,knn_ttm_r_n=20:430.2349,knn_tta_n=50:425.4128,knn_ttm_n=50:491.2337,knn_tta_r_n=50:416.4043,knn_ttm_r_n=50:423.3822,knn_tta_n=100:419.7919,knn_ttm_n=100:481.12,knn_tta_r_n=100:418.4047,knn_ttm_r_n=100:422.9139'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:197.4889,knn_ttm_n=5:160.8417,knn_tta_r_n=5:197.779,knn_ttm_r_n=5:275.2391,knn_tta_n=10:265.6322,knn_ttm_n=10:255.6958,knn_tta_r_n=10:271.8046,knn_ttm_r_n=10:295.2105,knn_tta_n=20:309.0861,knn_ttm_n=20:322.2419,knn_tta_r_n=20:314.1646,knn_ttm_r_n=20:320.3698,knn_tta_n=50:346.7776,knn_ttm_n=50:383.4369,knn_tta_r_n=50:347.6801,knn_ttm_r_n=50:349.3117,knn_tta_n=100:364.9132,knn_ttm_n=100:419.113,knn_tta_r_n=100:363.146,knn_ttm_r_n=100:364.4137'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:493.234,knn_ttm_n=5:572.5573,knn_tta_r_n=5:435.2809,knn_ttm_r_n=5:466.5927,knn_tta_n=10:438.7004,knn_ttm_n=10:525.7285,knn_tta_r_n=10:408.3179,knn_ttm_r_n=10:432.5091,knn_tta_n=20:405.6925,knn_ttm_n=20:484.9055,knn_tta_r_n=20:396.447,knn_ttm_r_n=20:415.8777,knn_tta_n=50:386.853,knn_ttm_n=50:454.0713,knn_tta_r_n=50:386.2484,knn_ttm_r_n=50:400.5673,knn_tta_n=100:391.0596,knn_ttm_n=100:455.6479,knn_tta_r_n=100:388.3234,knn_ttm_r_n=100:396.6224'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:111.9733,knn_ttm_n=5:87.0519,knn_tta_r_n=5:111.528,knn_ttm_r_n=5:148.7453,knn_tta_n=10:148.8002,knn_ttm_n=10:125.7904,knn_tta_r_n=10:153.5149,knn_ttm_r_n=10:158.5273,knn_tta_n=20:170.5851,knn_ttm_n=20:154.1476,knn_tta_r_n=20:176.1193,knn_ttm_r_n=20:172.8439,knn_tta_n=50:187.8311,knn_ttm_n=50:181.2513,knn_tta_r_n=50:191.6459,knn_ttm_r_n=50:187.9426,knn_tta_n=100:194.0668,knn_ttm_n=100:189.059,knn_tta_r_n=100:197.5683,knn_ttm_r_n=100:194.7115'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:291.7871,knn_ttm_n=5:355.8494,knn_tta_r_n=5:211.1486,knn_ttm_r_n=5:225.5357,knn_tta_n=10:243.5751,knn_ttm_n=10:304.158,knn_tta_r_n=10:200.8718,knn_ttm_r_n=10:205.9871,knn_tta_n=20:215.2414,knn_ttm_n=20:260.4807,knn_tta_r_n=20:197.3773,knn_ttm_r_n=20:199.3255,knn_tta_n=50:198.2103,knn_ttm_n=50:219.0441,knn_tta_r_n=50:194.0725,knn_ttm_r_n=50:194.8801,knn_tta_n=100:192.3755,knn_ttm_n=100:200.9381,knn_tta_r_n=100:193.3829,knn_ttm_r_n=100:193.5947'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:120.6835,knn_ttm_n=5:94.5814,knn_tta_r_n=5:118.6758,knn_ttm_r_n=5:158.0301,knn_tta_n=10:161.7293,knn_ttm_n=10:136.5539,knn_tta_r_n=10:164.3647,knn_ttm_r_n=10:170.1143,knn_tta_n=20:187.4432,knn_ttm_n=20:173.7173,knn_tta_r_n=20:190.4008,knn_ttm_r_n=20:187.5351,knn_tta_n=50:203.4174,knn_ttm_n=50:201.1401,knn_tta_r_n=50:206.6816,knn_ttm_r_n=50:202.7988,knn_tta_n=100:210.3963,knn_ttm_n=100:211.9752,knn_tta_r_n=100:213.1711,knn_ttm_r_n=100:210.191'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:310.9486,knn_ttm_n=5:371.3459,knn_tta_r_n=5:231.7698,knn_ttm_r_n=5:247.0656,knn_tta_n=10:260.4993,knn_ttm_n=10:319.3608,knn_tta_r_n=10:219.1304,knn_ttm_r_n=10:223.9488,knn_tta_n=20:236.7347,knn_ttm_n=20:279.7466,knn_tta_r_n=20:216.824,knn_ttm_r_n=20:217.329,knn_tta_n=50:221.0801,knn_ttm_n=50:248.2411,knn_tta_r_n=50:213.9247,knn_ttm_r_n=50:214.4315,knn_tta_n=100:215.1074,knn_ttm_n=100:233.9685,knn_tta_r_n=100:213.2716,knn_ttm_r_n=100:213.6043'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:84.6981,knn_ttm_n=5:62.3453,knn_tta_r_n=5:82.8571,knn_ttm_r_n=5:111.0297,knn_tta_n=10:109.6287,knn_ttm_n=10:92.3998,knn_tta_r_n=10:113.0869,knn_ttm_r_n=10:117.4743,knn_tta_n=20:125.2062,knn_ttm_n=20:113.7908,knn_tta_r_n=20:129.3621,knn_ttm_r_n=20:127.6144,knn_tta_n=50:138.1072,knn_ttm_n=50:135.0531,knn_tta_r_n=50:140.0373,knn_ttm_r_n=50:137.5811,knn_tta_n=100:141.8233,knn_ttm_n=100:143.8527,knn_tta_r_n=100:144.0021,knn_ttm_r_n=100:142.1722'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:206.5554,knn_ttm_n=5:252.8518,knn_tta_r_n=5:163.4246,knn_ttm_r_n=5:172.1349,knn_tta_n=10:184.5582,knn_ttm_n=10:218.1843,knn_tta_r_n=10:159.354,knn_ttm_r_n=10:162.8658,knn_tta_n=20:164.3096,knn_ttm_n=20:192.1654,knn_tta_r_n=20:154.8802,knn_ttm_r_n=20:158.0897,knn_tta_n=50:158.2412,knn_ttm_n=50:170.9114,knn_tta_r_n=50:155.7457,knn_ttm_r_n=50:155.8433,knn_tta_n=100:156.1696,knn_ttm_n=100:163.6031,knn_tta_r_n=100:156.9958,knn_ttm_r_n=100:156.4647'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_71'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:142.1977,knn_ttm_n=5:88.2241,knn_tta_r_n=5:146.7435,knn_ttm_r_n=5:185.0092,knn_tta_n=10:186.9767,knn_ttm_n=10:126.0991,knn_tta_r_n=10:190.4062,knn_ttm_r_n=10:186.0222,knn_tta_n=20:214.105,knn_ttm_n=20:159.065,knn_tta_r_n=20:220.9249,knn_ttm_r_n=20:204.6621,knn_tta_n=50:228.0725,knn_ttm_n=50:195.661,knn_tta_r_n=50:241.4263,knn_ttm_r_n=50:227.4084,knn_tta_n=100:238.1707,knn_ttm_n=100:216.7715,knn_tta_r_n=100:253.3113,knn_ttm_r_n=100:240.313'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:388.5667,knn_ttm_n=5:434.6518,knn_tta_r_n=5:295.3217,knn_ttm_r_n=5:316.5964,knn_tta_n=10:335.7527,knn_ttm_n=10:371.6747,knn_tta_r_n=10:278.2623,knn_ttm_r_n=10:291.5498,knn_tta_n=20:309.4339,knn_ttm_n=20:328.227,knn_tta_r_n=20:275.2195,knn_ttm_r_n=20:279.797,knn_tta_n=50:283.162,knn_ttm_n=50:293.1495,knn_tta_r_n=50:274.7477,knn_ttm_r_n=50:274.4372,knn_tta_n=100:274.2568,knn_ttm_n=100:279.7816,knn_tta_r_n=100:277.4209,knn_ttm_r_n=100:275.0951'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:160.5563,knn_ttm_n=5:122.8101,knn_tta_r_n=5:172.6974,knn_ttm_r_n=5:212.1281,knn_tta_n=10:201.6566,knn_ttm_n=10:170.1981,knn_tta_r_n=10:224.6322,knn_ttm_r_n=10:220.7159,knn_tta_n=20:235.4538,knn_ttm_n=20:210.2829,knn_tta_r_n=20:255.7845,knn_ttm_r_n=20:239.7035,knn_tta_n=50:265.0227,knn_ttm_n=50:258.0787,knn_tta_r_n=50:284.4037,knn_ttm_r_n=50:267.4909,knn_tta_n=100:298.7998,knn_ttm_n=100:283.7523,knn_tta_r_n=100:300.1676,knn_ttm_r_n=100:283.5792'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:360.7309,knn_ttm_n=5:397.9635,knn_tta_r_n=5:334.3733,knn_ttm_r_n=5:352.6881,knn_tta_n=10:328.7328,knn_ttm_n=10:373.6028,knn_tta_r_n=10:317.6285,knn_ttm_r_n=10:326.637,knn_tta_n=20:313.9679,knn_ttm_n=20:349.291,knn_tta_r_n=20:316.674,knn_ttm_r_n=20:317.9472,knn_tta_n=50:311.3303,knn_ttm_n=50:339.9628,knn_tta_r_n=50:322.0998,knn_ttm_r_n=50:319.6705,knn_tta_n=100:335.7148,knn_ttm_n=100:341.9908,knn_tta_r_n=100:328.8338,knn_ttm_r_n=100:322.4359'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:211.3999,knn_ttm_n=5:181.0934,knn_tta_r_n=5:243.5959,knn_ttm_r_n=5:267.8908,knn_tta_n=10:264.0075,knn_ttm_n=10:229.7304,knn_tta_r_n=10:277.8573,knn_ttm_r_n=10:268.112,knn_tta_n=20:357.8788,knn_ttm_n=20:271.7257,knn_tta_r_n=20:304.2215,knn_ttm_r_n=20:284.4372,knn_tta_n=50:335.1535,knn_ttm_n=50:315.9063,knn_tta_r_n=50:329.3717,knn_ttm_r_n=50:309.217,knn_tta_n=100:395.1115,knn_ttm_n=100:336.6897,knn_tta_r_n=100:338.7731,knn_ttm_r_n=100:320.3716'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:405.8329,knn_ttm_n=5:454.0033,knn_tta_r_n=5:418.9319,knn_ttm_r_n=5:417.7725,knn_tta_n=10:381.8691,knn_ttm_n=10:423.2629,knn_tta_r_n=10:383.0587,knn_ttm_r_n=10:382.8378,knn_tta_n=20:428.1516,knn_ttm_n=20:401.1981,knn_tta_r_n=20:370.7,knn_ttm_r_n=20:365.5036,knn_tta_n=50:370.5465,knn_ttm_n=50:392.1312,knn_tta_r_n=50:367.7531,knn_ttm_r_n=50:362.0133,knn_tta_n=100:414.2276,knn_ttm_n=100:381.6816,knn_tta_r_n=100:363.827,knn_ttm_r_n=100:355.9226'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:107.028,knn_ttm_n=5:70.2618,knn_tta_r_n=5:102.0414,knn_ttm_r_n=5:136.9963,knn_tta_n=10:139.1687,knn_ttm_n=10:100.3988,knn_tta_r_n=10:141.6608,knn_ttm_r_n=10:138.4279,knn_tta_n=20:160.3535,knn_ttm_n=20:128.3062,knn_tta_r_n=20:164.3414,knn_ttm_r_n=20:152.1321,knn_tta_n=50:174.2467,knn_ttm_n=50:156.794,knn_tta_r_n=50:180.0677,knn_ttm_r_n=50:170.2458,knn_tta_n=100:182.8256,knn_ttm_n=100:172.5543,knn_tta_r_n=100:187.8681,knn_ttm_r_n=100:180.0422'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:268.8625,knn_ttm_n=5:312.2991,knn_tta_r_n=5:202.8944,knn_ttm_r_n=5:220.8628,knn_tta_n=10:229.8163,knn_ttm_n=10:271.2075,knn_tta_r_n=10:194.0693,knn_ttm_r_n=10:203.0976,knn_tta_n=20:209.9873,knn_ttm_n=20:239.531,knn_tta_r_n=20:190.2162,knn_ttm_r_n=20:195.7137,knn_tta_n=50:193.783,knn_ttm_n=50:214.7594,knn_tta_r_n=50:189.4923,knn_ttm_r_n=50:191.0783,knn_tta_n=100:190.1329,knn_ttm_n=100:203.6458,knn_tta_r_n=100:189.5863,knn_ttm_r_n=100:190.8675'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:111.0854,knn_ttm_n=5:68.4365,knn_tta_r_n=5:106.3983,knn_ttm_r_n=5:141.931,knn_tta_n=10:140.6773,knn_ttm_n=10:102.0741,knn_tta_r_n=10:149.2459,knn_ttm_r_n=10:145.9996,knn_tta_n=20:164.1304,knn_ttm_n=20:130.2658,knn_tta_r_n=20:174.4356,knn_ttm_r_n=20:161.6658,knn_tta_n=50:182.0737,knn_ttm_n=50:163.6888,knn_tta_r_n=50:191.5267,knn_ttm_r_n=50:181.0722,knn_tta_n=100:191.7813,knn_ttm_n=100:181.4582,knn_tta_r_n=100:200.1378,knn_ttm_r_n=100:191.8205'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:282.1375,knn_ttm_n=5:331.7566,knn_tta_r_n=5:204.1363,knn_ttm_r_n=5:216.3895,knn_tta_n=10:233.5459,knn_ttm_n=10:290.0812,knn_tta_r_n=10:198.0618,knn_ttm_r_n=10:202.5871,knn_tta_n=20:209.087,knn_ttm_n=20:251.9104,knn_tta_r_n=20:192.4091,knn_ttm_r_n=20:196.4795,knn_tta_n=50:197.4239,knn_ttm_n=50:220.9611,knn_tta_r_n=50:195.6216,knn_ttm_r_n=50:194.4579,knn_tta_n=100:196.2439,knn_ttm_n=100:208.6743,knn_tta_r_n=100:199.0934,knn_ttm_r_n=100:197.0347'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:68.5712,knn_ttm_n=5:40.7688,knn_tta_r_n=5:67.4419,knn_ttm_r_n=5:89.0456,knn_tta_n=10:90.6309,knn_ttm_n=10:63.5176,knn_tta_r_n=10:92.7497,knn_ttm_r_n=10:90.6599,knn_tta_n=20:103.4742,knn_ttm_n=20:83.0386,knn_tta_r_n=20:106.6539,knn_ttm_r_n=20:99.085,knn_tta_n=50:113.3114,knn_ttm_n=50:103.2634,knn_tta_r_n=50:117.0979,knn_ttm_r_n=50:110.2442,knn_tta_n=100:117.4787,knn_ttm_n=100:112.4393,knn_tta_r_n=100:121.3602,knn_ttm_r_n=100:116.2351'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:204.4921,knn_ttm_n=5:240.2079,knn_tta_r_n=5:154.6422,knn_ttm_r_n=5:164.7145,knn_tta_n=10:173.7297,knn_ttm_n=10:209.2016,knn_tta_r_n=10:146.1986,knn_ttm_r_n=10:150.8868,knn_tta_n=20:153.6394,knn_ttm_n=20:179.849,knn_tta_r_n=20:142.6973,knn_ttm_r_n=20:145.5116,knn_tta_n=50:147.3676,knn_ttm_n=50:158.5625,knn_tta_r_n=50:143.2879,knn_ttm_r_n=50:142.6498,knn_tta_n=100:143.9749,knn_ttm_n=100:151.3743,knn_tta_r_n=100:144.6105,knn_ttm_r_n=100:143.0329'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_73'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:115.0312,knn_ttm_n=5:60.6185,knn_tta_r_n=5:122.5318,knn_ttm_r_n=5:168.4522,knn_tta_n=10:164.5179,knn_ttm_n=10:100.8588,knn_tta_r_n=10:177.5348,knn_ttm_r_n=10:171.7595,knn_tta_n=20:199.4996,knn_ttm_n=20:142.4857,knn_tta_r_n=20:213.0308,knn_ttm_r_n=20:193.2557,knn_tta_n=50:232.2259,knn_ttm_n=50:198.4606,knn_tta_r_n=50:241.5879,knn_ttm_r_n=50:224.7752,knn_tta_n=100:248.7898,knn_ttm_n=100:232.7692,knn_tta_r_n=100:254.9007,knn_ttm_r_n=100:243.3542'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:337.1923,knn_ttm_n=5:403.8483,knn_tta_r_n=5:285.8664,knn_ttm_r_n=5:312.0013,knn_tta_n=10:295.1477,knn_ttm_n=10:344.395,knn_tta_r_n=10:275.4949,knn_ttm_r_n=10:285.1618,knn_tta_n=20:283.9175,knn_ttm_n=20:306.6798,knn_tta_r_n=20:275.2298,knn_ttm_r_n=20:276.8559,knn_tta_n=50:277.8973,knn_ttm_n=50:291.1372,knn_tta_r_n=50:280.5425,knn_ttm_r_n=50:279.9638,knn_tta_n=100:282.7754,knn_ttm_n=100:289.4206,knn_tta_r_n=100:285.0207,knn_ttm_r_n=100:282.5508'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:152.0596,knn_ttm_n=5:91.021,knn_tta_r_n=5:159.9359,knn_ttm_r_n=5:215.5942,knn_tta_n=10:216.1976,knn_ttm_n=10:160.4123,knn_tta_r_n=10:234.4837,knn_ttm_r_n=10:227.8989,knn_tta_n=20:270.628,knn_ttm_n=20:232.2948,knn_tta_r_n=20:287.5505,knn_ttm_r_n=20:258.3715,knn_tta_n=50:319.407,knn_ttm_n=50:318.6077,knn_tta_r_n=50:333.0916,knn_ttm_r_n=50:307.5123,knn_tta_n=100:343.9634,knn_ttm_n=100:373.1971,knn_tta_r_n=100:356.5333,knn_ttm_r_n=100:338.6887'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:401.4099,knn_ttm_n=5:462.6944,knn_tta_r_n=5:350.901,knn_ttm_r_n=5:376.0013,knn_tta_n=10:373.0583,knn_ttm_n=10:427.178,knn_tta_r_n=10:342.1028,knn_ttm_r_n=10:357.4933,knn_tta_n=20:360.7406,knn_ttm_n=20:413.6294,knn_tta_r_n=20:352.1502,knn_ttm_r_n=20:354.1101,knn_tta_n=50:367.1853,knn_ttm_n=50:415.8986,knn_tta_r_n=50:368.3616,knn_ttm_r_n=50:361.9717,knn_tta_n=100:378.7008,knn_ttm_n=100:432.1068,knn_tta_r_n=100:387.1923,knn_ttm_r_n=100:378.0247'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:161.8095,knn_ttm_n=5:95.2017,knn_tta_r_n=5:165.3267,knn_ttm_r_n=5:227.4107,knn_tta_n=10:231.8549,knn_ttm_n=10:172.1464,knn_tta_r_n=10:245.8813,knn_ttm_r_n=10:241.4024,knn_tta_n=20:276.4417,knn_ttm_n=20:242.1275,knn_tta_r_n=20:298.0125,knn_ttm_r_n=20:275.5291,knn_tta_n=50:324.8926,knn_ttm_n=50:320.4751,knn_tta_r_n=50:342.774,knn_ttm_r_n=50:323.0375,knn_tta_n=100:354.6441,knn_ttm_n=100:373.6913,knn_tta_r_n=100:369.7338,knn_ttm_r_n=100:353.7317'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:439.6007,knn_ttm_n=5:499.5655,knn_tta_r_n=5:393.7353,knn_ttm_r_n=5:420.9633,knn_tta_n=10:391.2494,knn_ttm_n=10:452.8602,knn_tta_r_n=10:369.2073,knn_ttm_r_n=10:393.6742,knn_tta_n=20:379.0759,knn_ttm_n=20:425.6543,knn_tta_r_n=20:364.8211,knn_ttm_r_n=20:377.4586,knn_tta_n=50:378.9644,knn_ttm_n=50:421.579,knn_tta_r_n=50:375.8975,knn_ttm_r_n=50:377.3145,knn_tta_n=100:389.6341,knn_ttm_n=100:434.402,knn_tta_r_n=100:391.182,knn_ttm_r_n=100:387.5168'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:97.1958,knn_ttm_n=5:50.2752,knn_tta_r_n=5:101.692,knn_ttm_r_n=5:139.1493,knn_tta_n=10:135.3348,knn_ttm_n=10:80.6039,knn_tta_r_n=10:145.7329,knn_ttm_r_n=10:138.068,knn_tta_n=20:164.2343,knn_ttm_n=20:111.1275,knn_tta_r_n=20:172.9413,knn_ttm_r_n=20:154.6979,knn_tta_n=50:186.5019,knn_ttm_n=50:154.1388,knn_tta_r_n=50:191.2362,knn_ttm_r_n=50:178.6282,knn_tta_n=100:197.0806,knn_ttm_n=100:179.7052,knn_tta_r_n=100:199.0107,knn_ttm_r_n=100:191.3941'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:302.0553,knn_ttm_n=5:343.6016,knn_tta_r_n=5:220.1644,knn_ttm_r_n=5:233.9548,knn_tta_n=10:253.8571,knn_ttm_n=10:302.1708,knn_tta_r_n=10:209.5532,knn_ttm_r_n=10:215.6093,knn_tta_n=20:223.8134,knn_ttm_n=20:261.477,knn_tta_r_n=20:205.6501,knn_ttm_r_n=20:208.3119,knn_tta_n=50:210.0678,knn_ttm_n=50:226.1222,knn_tta_r_n=50:203.9214,knn_ttm_r_n=50:204.3613,knn_tta_n=100:206.5495,knn_ttm_n=100:213.1612,knn_tta_r_n=100:203.5163,knn_ttm_r_n=100:203.6069'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:107.0628,knn_ttm_n=5:58.8368,knn_tta_r_n=5:110.0159,knn_ttm_r_n=5:152.8303,knn_tta_n=10:147.4032,knn_ttm_n=10:95.7476,knn_tta_r_n=10:157.8595,knn_ttm_r_n=10:153.1358,knn_tta_n=20:177.1353,knn_ttm_n=20:130.4249,knn_tta_r_n=20:187.4624,knn_ttm_r_n=20:170.6628,knn_tta_n=50:201.0671,knn_ttm_n=50:174.9117,knn_tta_r_n=50:208.256,knn_ttm_r_n=50:195.556,knn_tta_n=100:212.2707,knn_ttm_n=100:200.2036,knn_tta_r_n=100:216.8564,knn_ttm_r_n=100:209.0482'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:295.54,knn_ttm_n=5:336.1848,knn_tta_r_n=5:223.6568,knn_ttm_r_n=5:244.5245,knn_tta_n=10:254.3304,knn_ttm_n=10:298.4272,knn_tta_r_n=10:216.6986,knn_ttm_r_n=10:223.6358,knn_tta_n=20:240.5899,knn_ttm_n=20:268.8982,knn_tta_r_n=20:215.7702,knn_ttm_r_n=20:217.6193,knn_tta_n=50:222.7259,knn_ttm_n=50:243.2044,knn_tta_r_n=50:216.131,knn_ttm_r_n=50:216.2768,knn_tta_n=100:217.7086,knn_ttm_n=100:231.4798,knn_tta_r_n=100:216.4775,knn_ttm_r_n=100:216.3748'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:63.9801,knn_ttm_n=5:31.7784,knn_tta_r_n=5:61.8468,knn_ttm_r_n=5:84.8591,knn_tta_n=10:86.1272,knn_ttm_n=10:51.0592,knn_tta_r_n=10:88.2959,knn_ttm_r_n=10:84.1539,knn_tta_n=20:99.5347,knn_ttm_n=20:69.9054,knn_tta_r_n=20:103.216,knn_ttm_r_n=20:93.8986,knn_tta_n=50:109.3105,knn_ttm_n=50:91.9536,knn_tta_r_n=50:112.8944,knn_ttm_r_n=50:106.3955,knn_tta_n=100:114.2404,knn_ttm_n=100:104.1025,knn_tta_r_n=100:117.0107,knn_ttm_r_n=100:112.8142'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:200.7261,knn_ttm_n=5:230.4859,knn_tta_r_n=5:148.3061,knn_ttm_r_n=5:157.0798,knn_tta_n=10:174.3846,knn_ttm_n=10:200.7744,knn_tta_r_n=10:143.3906,knn_ttm_r_n=10:146.7992,knn_tta_n=20:156.1527,knn_ttm_n=20:176.5125,knn_tta_r_n=20:141.715,knn_ttm_r_n=20:141.9132,knn_tta_n=50:144.2032,knn_ttm_n=50:155.1809,knn_tta_r_n=50:139.8244,knn_ttm_r_n=50:140.36,knn_tta_n=100:140.084,knn_ttm_n=100:145.7746,knn_tta_r_n=100:139.374,knn_ttm_r_n=100:139.9315'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_74'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:132.2378,knn_ttm_n=5:89.1045,knn_tta_r_n=5:133.958,knn_ttm_r_n=5:180.5895,knn_tta_n=10:180.1983,knn_ttm_n=10:142.374,knn_tta_r_n=10:186.5839,knn_ttm_r_n=10:191.6164,knn_tta_n=20:209.285,knn_ttm_n=20:182.788,knn_tta_r_n=20:218.0373,knn_ttm_r_n=20:213.9104,knn_tta_n=50:233.9481,knn_ttm_n=50:221.0073,knn_tta_r_n=50:239.0849,knn_ttm_r_n=50:234.9446,knn_tta_n=100:245.1564,knn_ttm_n=100:241.299,knn_tta_r_n=100:248.6998,knn_ttm_r_n=100:245.5459'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:341.6012,knn_ttm_n=5:400.7969,knn_tta_r_n=5:281.2184,knn_ttm_r_n=5:300.2248,knn_tta_n=10:305.6267,knn_ttm_n=10:356.0161,knn_tta_r_n=10:272.7372,knn_ttm_r_n=10:283.4839,knn_tta_n=20:274.6927,knn_ttm_n=20:322.0217,knn_tta_r_n=20:265.8427,knn_ttm_r_n=20:274.2454,knn_tta_n=50:262.4927,knn_ttm_n=50:286.0628,knn_tta_r_n=50:263.9,knn_ttm_r_n=50:267.9765,knn_tta_n=100:264.2711,knn_ttm_n=100:276.3053,knn_tta_r_n=100:267.5964,knn_ttm_r_n=100:268.4323'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:179.3869,knn_ttm_n=5:137.9618,knn_tta_r_n=5:180.9891,knn_ttm_r_n=5:248.2604,knn_tta_n=10:241.9444,knn_ttm_n=10:213.9852,knn_tta_r_n=10:252.4674,knn_ttm_r_n=10:265.9398,knn_tta_n=20:283.0172,knn_ttm_n=20:271.0123,knn_tta_r_n=20:297.0756,knn_ttm_r_n=20:295.6284,knn_tta_n=50:316.0863,knn_ttm_n=50:328.5565,knn_tta_r_n=50:329.2821,knn_ttm_r_n=50:326.5071,knn_tta_n=100:329.3316,knn_ttm_n=100:355.877,knn_tta_r_n=100:343.1664,knn_ttm_r_n=100:341.4801'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:455.9995,knn_ttm_n=5:533.344,knn_tta_r_n=5:396.147,knn_ttm_r_n=5:440.6044,knn_tta_n=10:407.5424,knn_ttm_n=10:479.1438,knn_tta_r_n=10:371.1043,knn_ttm_r_n=10:398.3934,knn_tta_n=20:380.3345,knn_ttm_n=20:444.7464,knn_tta_r_n=20:369.5196,knn_ttm_r_n=20:382.8789,knn_tta_n=50:365.4878,knn_ttm_n=50:414.2221,knn_tta_r_n=50:367.8956,knn_ttm_r_n=50:378.3975,knn_tta_n=100:365.0716,knn_ttm_n=100:406.8347,knn_tta_r_n=100:373.7652,knn_ttm_r_n=100:378.6604'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:179.2287,knn_ttm_n=5:137.3286,knn_tta_r_n=5:172.3952,knn_ttm_r_n=5:246.5567,knn_tta_n=10:239.9043,knn_ttm_n=10:214.6603,knn_tta_r_n=10:246.3855,knn_ttm_r_n=10:263.897,knn_tta_n=20:280.6645,knn_ttm_n=20:275.1261,knn_tta_r_n=20:288.1749,knn_ttm_r_n=20:293.5817,knn_tta_n=50:310.8605,knn_ttm_n=50:325.5496,knn_tta_r_n=50:322.1266,knn_ttm_r_n=50:323.0232,knn_tta_n=100:324.4734,knn_ttm_n=100:349.9386,knn_tta_r_n=100:339.7866,knn_ttm_r_n=100:338.7087'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:420.5892,knn_ttm_n=5:474.0623,knn_tta_r_n=5:381.0975,knn_ttm_r_n=5:412.1302,knn_tta_n=10:376.3395,knn_ttm_n=10:434.2537,knn_tta_r_n=10:363.5047,knn_ttm_r_n=10:385.348,knn_tta_n=20:356.7755,knn_ttm_n=20:402.3868,knn_tta_r_n=20:351.7943,knn_ttm_r_n=20:371.4322,knn_tta_n=50:342.6561,knn_ttm_n=50:383.9814,knn_tta_r_n=50:353.5936,knn_ttm_r_n=50:364.6603,knn_tta_n=100:342.8158,knn_ttm_n=100:378.9685,knn_tta_r_n=100:362.0378,knn_ttm_r_n=100:367.1089'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:111.7952,knn_ttm_n=5:78.2595,knn_tta_r_n=5:111.1167,knn_ttm_r_n=5:150.0818,knn_tta_n=10:149.2455,knn_ttm_n=10:120.3343,knn_tta_r_n=10:155.3049,knn_ttm_r_n=10:158.4056,knn_tta_n=20:170.9121,knn_ttm_n=20:149.1589,knn_tta_r_n=20:178.6566,knn_ttm_r_n=20:174.1914,knn_tta_n=50:189.5866,knn_ttm_n=50:176.372,knn_tta_r_n=50:195.3339,knn_ttm_r_n=50:190.6757,knn_tta_n=100:197.0716,knn_ttm_n=100:189.5368,knn_tta_r_n=100:202.4221,knn_ttm_r_n=100:198.4282'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:276.511,knn_ttm_n=5:341.8518,knn_tta_r_n=5:207.9268,knn_ttm_r_n=5:220.8694,knn_tta_n=10:232.8209,knn_ttm_n=10:288.6835,knn_tta_r_n=10:198.151,knn_ttm_r_n=10:201.9598,knn_tta_n=20:211.0754,knn_ttm_n=20:250.0631,knn_tta_r_n=20:194.5513,knn_ttm_r_n=20:195.8034,knn_tta_n=50:197.4079,knn_ttm_n=50:215.9322,knn_tta_r_n=50:194.9674,knn_ttm_r_n=50:194.7238,knn_tta_n=100:192.5724,knn_ttm_n=100:201.7923,knn_tta_r_n=100:195.9706,knn_ttm_r_n=100:195.3155'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:113.1297,knn_ttm_n=5:78.771,knn_tta_r_n=5:115.1216,knn_ttm_r_n=5:159.4768,knn_tta_n=10:150.5014,knn_ttm_n=10:118.0649,knn_tta_r_n=10:159.2526,knn_ttm_r_n=10:164.9886,knn_tta_n=20:175.8806,knn_ttm_n=20:153.053,knn_tta_r_n=20:184.352,knn_ttm_r_n=20:180.2465,knn_tta_n=50:193.8196,knn_ttm_n=50:183.2635,knn_tta_r_n=50:199.9607,knn_ttm_r_n=50:195.3962,knn_tta_n=100:202.1474,knn_ttm_n=100:197.2041,knn_tta_r_n=100:206.9473,knn_ttm_r_n=100:203.0191'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:297.4004,knn_ttm_n=5:350.5097,knn_tta_r_n=5:216.4829,knn_ttm_r_n=5:234.81,knn_tta_n=10:249.9057,knn_ttm_n=10:310.3696,knn_tta_r_n=10:210.2855,knn_ttm_r_n=10:214.8656,knn_tta_n=20:223.4942,knn_ttm_n=20:264.1983,knn_tta_r_n=20:207.0533,knn_ttm_r_n=20:209.8332,knn_tta_n=50:211.6013,knn_ttm_n=50:232.0306,knn_tta_r_n=50:205.7087,knn_ttm_r_n=50:206.2051,knn_tta_n=100:208.0917,knn_ttm_n=100:220.3402,knn_tta_r_n=100:206.5119,knn_ttm_r_n=100:206.3719'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:76.1191,knn_ttm_n=5:52.626,knn_tta_r_n=5:73.922,knn_ttm_r_n=5:101.5463,knn_tta_n=10:98.662,knn_ttm_n=10:79.4227,knn_tta_r_n=10:101.5263,knn_ttm_r_n=10:103.5377,knn_tta_n=20:114.8761,knn_ttm_n=20:99.4154,knn_tta_r_n=20:117.6643,knn_ttm_r_n=20:113.0417,knn_tta_n=50:125.5426,knn_ttm_n=50:118.1335,knn_tta_r_n=50:128.3949,knn_ttm_r_n=50:124.5047,knn_tta_n=100:129.6254,knn_ttm_n=100:126.2262,knn_tta_r_n=100:132.8098,knn_ttm_r_n=100:129.9274'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:209.95,knn_ttm_n=5:256.0583,knn_tta_r_n=5:158.0526,knn_ttm_r_n=5:169.7337,knn_tta_n=10:186.2311,knn_ttm_n=10:220.8271,knn_tta_r_n=10:155.2784,knn_ttm_r_n=10:157.446,knn_tta_n=20:168.2559,knn_ttm_n=20:194.6458,knn_tta_r_n=20:152.769,knn_ttm_r_n=20:154.8625,knn_tta_n=50:155.715,knn_ttm_n=50:171.2499,knn_tta_r_n=50:150.7886,knn_ttm_r_n=50:151.6577,knn_tta_n=100:150.5137,knn_ttm_n=100:159.3142,knn_tta_r_n=100:150.2997,knn_ttm_r_n=100:150.3426'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_75'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:124.2225,knn_ttm_n=5:73.2959,knn_tta_r_n=5:128.5205,knn_ttm_r_n=5:177.4624,knn_tta_n=10:175.025,knn_ttm_n=10:117.7375,knn_tta_r_n=10:184.5927,knn_ttm_r_n=10:181.5224,knn_tta_n=20:209.0233,knn_ttm_n=20:160.3792,knn_tta_r_n=20:220.4188,knn_ttm_r_n=20:203.5393,knn_tta_n=50:242.5007,knn_ttm_n=50:212.235,knn_tta_r_n=50:248.753,knn_ttm_r_n=50:234.1082,knn_tta_n=100:258.9665,knn_ttm_n=100:243.9279,knn_tta_r_n=100:262.2993,knn_ttm_r_n=100:251.2811'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:351.5438,knn_ttm_n=5:397.9173,knn_tta_r_n=5:281.712,knn_ttm_r_n=5:300.0198,knn_tta_n=10:310.7073,knn_ttm_n=10:357.6309,knn_tta_r_n=10:269.3364,knn_ttm_r_n=10:279.5936,knn_tta_n=20:289.8333,knn_ttm_n=20:325.5899,knn_tta_r_n=20:267.5812,knn_ttm_r_n=20:270.1067,knn_tta_n=50:277.5738,knn_ttm_n=50:297.8581,knn_tta_r_n=50:271.3147,knn_ttm_r_n=50:269.2691,knn_tta_n=100:281.3111,knn_ttm_n=100:292.2807,knn_tta_r_n=100:276.0702,knn_ttm_r_n=100:272.6583'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:149.1252,knn_ttm_n=5:96.0832,knn_tta_r_n=5:156.2631,knn_ttm_r_n=5:214.3722,knn_tta_n=10:205.5795,knn_ttm_n=10:160.2046,knn_tta_r_n=10:225.5635,knn_ttm_r_n=10:228.1168,knn_tta_n=20:246.5713,knn_ttm_n=20:213.9174,knn_tta_r_n=20:271.1071,knn_ttm_r_n=20:254.6,knn_tta_n=50:281.7172,knn_ttm_n=50:272.2017,knn_tta_r_n=50:305.7002,knn_ttm_r_n=50:290.7553,knn_tta_n=100:299.7349,knn_ttm_n=100:303.0464,knn_tta_r_n=100:326.7587,knn_ttm_r_n=100:313.0025'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:377.3731,knn_ttm_n=5:423.4088,knn_tta_r_n=5:356.1095,knn_ttm_r_n=5:383.839,knn_tta_n=10:345.3862,knn_ttm_n=10:388.0182,knn_tta_r_n=10:335.7559,knn_ttm_r_n=10:355.3049,knn_tta_n=20:326.8524,knn_ttm_n=20:363.2936,knn_tta_r_n=20:328.7697,knn_ttm_r_n=20:340.9518,knn_tta_n=50:322.5032,knn_ttm_n=50:349.9425,knn_tta_r_n=50:336.9563,knn_ttm_r_n=50:338.0859,knn_tta_n=100:330.5746,knn_ttm_n=100:351.9097,knn_tta_r_n=100:352.7381,knn_ttm_r_n=100:345.6777'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:151.3836,knn_ttm_n=5:96.188,knn_tta_r_n=5:146.0885,knn_ttm_r_n=5:201.8651,knn_tta_n=10:210.2062,knn_ttm_n=10:166.0195,knn_tta_r_n=10:213.9904,knn_ttm_r_n=10:215.7102,knn_tta_n=20:251.2306,knn_ttm_n=20:224.6802,knn_tta_r_n=20:256.2799,knn_ttm_r_n=20:243.9495,knn_tta_n=50:284.292,knn_ttm_n=50:283.8809,knn_tta_r_n=50:291.1004,knn_ttm_r_n=50:277.4658,knn_tta_n=100:300.4714,knn_ttm_n=100:313.0007,knn_tta_r_n=100:312.2097,knn_ttm_r_n=100:299.0043'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:361.4478,knn_ttm_n=5:426.8001,knn_tta_r_n=5:346.7492,knn_ttm_r_n=5:385.6227,knn_tta_n=10:322.1872,knn_ttm_n=10:367.7802,knn_tta_r_n=10:317.0964,knn_ttm_r_n=10:344.5074,knn_tta_n=20:305.3809,knn_ttm_n=20:342.4294,knn_tta_r_n=20:306.5462,knn_ttm_r_n=20:325.2045,knn_tta_n=50:292.5337,knn_ttm_n=50:327.224,knn_tta_r_n=50:305.1372,knn_ttm_r_n=50:311.3042,knn_tta_n=100:294.2911,knn_ttm_n=100:324.9747,knn_tta_r_n=100:316.2482,knn_ttm_r_n=100:314.5981'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:100.0241,knn_ttm_n=5:59.5292,knn_tta_r_n=5:100.1636,knn_ttm_r_n=5:133.8425,knn_tta_n=10:137.6555,knn_ttm_n=10:96.7997,knn_tta_r_n=10:141.7939,knn_ttm_r_n=10:138.0953,knn_tta_n=20:160.836,knn_ttm_n=20:126.8598,knn_tta_r_n=20:165.6226,knn_ttm_r_n=20:153.9624,knn_tta_n=50:176.7697,knn_ttm_n=50:158.6969,knn_tta_r_n=50:182.5422,knn_ttm_r_n=50:172.984,knn_tta_n=100:184.239,knn_ttm_n=100:174.5313,knn_tta_r_n=100:190.2759,knn_ttm_r_n=100:183.3551'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:269.0268,knn_ttm_n=5:306.5727,knn_tta_r_n=5:195.6484,knn_ttm_r_n=5:211.2082,knn_tta_n=10:228.8226,knn_ttm_n=10:273.7018,knn_tta_r_n=10:190.0694,knn_ttm_r_n=10:195.3822,knn_tta_n=20:206.1723,knn_ttm_n=20:241.7438,knn_tta_r_n=20:189.5944,knn_ttm_r_n=20:189.676,knn_tta_n=50:195.4988,knn_ttm_n=50:213.3133,knn_tta_r_n=50:192.5834,knn_ttm_r_n=50:190.8249,knn_tta_n=100:196.1659,knn_ttm_n=100:205.1406,knn_tta_r_n=100:196.4635,knn_ttm_r_n=100:193.5774'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:112.6889,knn_ttm_n=5:70.4175,knn_tta_r_n=5:113.5447,knn_ttm_r_n=5:154.4017,knn_tta_n=10:149.3196,knn_ttm_n=10:109.8107,knn_tta_r_n=10:157.1717,knn_ttm_r_n=10:156.2601,knn_tta_n=20:174.5658,knn_ttm_n=20:143.1491,knn_tta_r_n=20:185.6937,knn_ttm_r_n=20:172.7741,knn_tta_n=50:196.4789,knn_ttm_n=50:178.4062,knn_tta_r_n=50:205.0236,knn_ttm_r_n=50:194.7146,knn_tta_n=100:207.6691,knn_ttm_n=100:198.098,knn_tta_r_n=100:214.7316,knn_ttm_r_n=100:206.2786'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:283.1848,knn_ttm_n=5:331.5483,knn_tta_r_n=5:208.9142,knn_ttm_r_n=5:221.2163,knn_tta_n=10:248.2656,knn_ttm_n=10:292.5076,knn_tta_r_n=10:202.2151,knn_ttm_r_n=10:205.9497,knn_tta_n=20:225.8432,knn_ttm_n=20:260.4699,knn_tta_r_n=20:201.5845,knn_ttm_r_n=20:201.3704,knn_tta_n=50:209.6665,knn_ttm_n=50:234.1352,knn_tta_r_n=50:199.7472,knn_ttm_r_n=50:199.7534,knn_tta_n=100:205.2832,knn_ttm_n=100:222.1756,knn_tta_r_n=100:202.2634,knn_ttm_r_n=100:200.5018'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:66.3848,knn_ttm_n=5:37.8467,knn_tta_r_n=5:64.9651,knn_ttm_r_n=5:88.4088,knn_tta_n=10:87.7396,knn_ttm_n=10:60.6968,knn_tta_r_n=10:92.0337,knn_ttm_r_n=10:89.9521,knn_tta_n=20:102.3034,knn_ttm_n=20:80.6118,knn_tta_r_n=20:106.7517,knn_ttm_r_n=20:98.6084,knn_tta_n=50:113.7719,knn_ttm_n=50:105.0901,knn_tta_r_n=50:117.7809,knn_ttm_r_n=50:111.2338,knn_tta_n=100:118.4891,knn_ttm_n=100:116.2925,knn_tta_r_n=100:123.0364,knn_ttm_r_n=100:118.0081'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:210.6578,knn_ttm_n=5:232.733,knn_tta_r_n=5:153.3046,knn_ttm_r_n=5:161.3927,knn_tta_n=10:175.5002,knn_ttm_n=10:212.064,knn_tta_r_n=10:147.5085,knn_ttm_r_n=10:150.8636,knn_tta_n=20:157.1344,knn_ttm_n=20:182.1704,knn_tta_r_n=20:146.3423,knn_ttm_r_n=20:146.9555,knn_tta_n=50:146.3312,knn_ttm_n=50:161.7281,knn_tta_r_n=50:144.4013,knn_ttm_r_n=50:144.5393,knn_tta_n=100:143.8025,knn_ttm_n=100:153.0193,knn_tta_r_n=100:146.6343,knn_ttm_r_n=100:144.9255'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_77'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:110.1502,knn_ttm_n=5:60.1846,knn_tta_r_n=5:111.4699,knn_ttm_r_n=5:152.3424,knn_tta_n=10:153.512,knn_ttm_n=10:97.4138,knn_tta_r_n=10:165.2772,knn_ttm_r_n=10:157.6923,knn_tta_n=20:182.2028,knn_ttm_n=20:134.6315,knn_tta_r_n=20:197.9963,knn_ttm_r_n=20:179.9318,knn_tta_n=50:210.7827,knn_ttm_n=50:181.2204,knn_tta_r_n=50:224.6545,knn_ttm_r_n=50:210.0403,knn_tta_n=100:229.5323,knn_ttm_n=100:211.544,knn_tta_r_n=100:240.8368,knn_ttm_r_n=100:228.7873'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:320.0389,knn_ttm_n=5:366.7814,knn_tta_r_n=5:266.9285,knn_ttm_r_n=5:284.0902,knn_tta_n=10:278.865,knn_ttm_n=10:325.1561,knn_tta_r_n=10:262.8658,knn_ttm_r_n=10:266.665,knn_tta_n=20:261.091,knn_ttm_n=20:288.1052,knn_tta_r_n=20:260.8327,knn_ttm_r_n=20:264.4677,knn_tta_n=50:260.0323,knn_ttm_n=50:268.6224,knn_tta_r_n=50:267.2303,knn_ttm_r_n=50:265.5029,knn_tta_n=100:264.3494,knn_ttm_n=100:266.8703,knn_tta_r_n=100:274.5707,knn_ttm_r_n=100:269.5709'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:142.3504,knn_ttm_n=5:90.4177,knn_tta_r_n=5:145.4998,knn_ttm_r_n=5:202.7744,knn_tta_n=10:200.6531,knn_ttm_n=10:153.3103,knn_tta_r_n=10:210.9708,knn_ttm_r_n=10:211.2947,knn_tta_n=20:237.4415,knn_ttm_n=20:209.9122,knn_tta_r_n=20:252.6045,knn_ttm_r_n=20:236.038,knn_tta_n=50:274.8343,knn_ttm_n=50:272.1145,knn_tta_r_n=50:292.9201,knn_ttm_r_n=50:276.229,knn_tta_n=100:292.081,knn_ttm_n=100:306.2954,knn_tta_r_n=100:317.0695,knn_ttm_r_n=100:302.4618'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:351.49,knn_ttm_n=5:393.1616,knn_tta_r_n=5:338.6185,knn_ttm_r_n=5:361.3828,knn_tta_n=10:319.49,knn_ttm_n=10:357.8021,knn_tta_r_n=10:324.7638,knn_ttm_r_n=10:341.657,knn_tta_n=20:309.2171,knn_ttm_n=20:342.0792,knn_tta_r_n=20:320.2369,knn_ttm_r_n=20:331.1499,knn_tta_n=50:304.0841,knn_ttm_n=50:330.8965,knn_tta_r_n=50:331.5263,knn_ttm_r_n=50:333.4885,knn_tta_n=100:310.8177,knn_ttm_n=100:335.3401,knn_tta_r_n=100:347.4623,knn_ttm_r_n=100:344.2368'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:136.0838,knn_ttm_n=5:78.6544,knn_tta_r_n=5:138.0991,knn_ttm_r_n=5:193.7575,knn_tta_n=10:189.7018,knn_ttm_n=10:140.0836,knn_tta_r_n=10:202.8899,knn_ttm_r_n=10:206.0103,knn_tta_n=20:231.3056,knn_ttm_n=20:197.5896,knn_tta_r_n=20:248.1835,knn_ttm_r_n=20:235.2272,knn_tta_n=50:270.7398,knn_ttm_n=50:261.737,knn_tta_r_n=50:288.3616,knn_ttm_r_n=50:275.8485,knn_tta_n=100:296.722,knn_ttm_n=100:299.6423,knn_tta_r_n=100:317.9897,knn_ttm_r_n=100:303.438'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:350.9192,knn_ttm_n=5:385.4438,knn_tta_r_n=5:336.6129,knn_ttm_r_n=5:369.4742,knn_tta_n=10:313.4805,knn_ttm_n=10:351.7484,knn_tta_r_n=10:310.8018,knn_ttm_r_n=10:335.9532,knn_tta_n=20:303.6041,knn_ttm_n=20:332.566,knn_tta_r_n=20:305.1451,knn_ttm_r_n=20:317.7635,knn_tta_n=50:308.9727,knn_ttm_n=50:332.2313,knn_tta_r_n=50:315.1782,knn_ttm_r_n=50:318.5123,knn_tta_n=100:316.171,knn_ttm_n=100:340.1096,knn_tta_r_n=100:333.3198,knn_ttm_r_n=100:328.5591'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:97.7225,knn_ttm_n=5:50.1073,knn_tta_r_n=5:101.837,knn_ttm_r_n=5:138.1802,knn_tta_n=10:136.9041,knn_ttm_n=10:83.544,knn_tta_r_n=10:145.6005,knn_ttm_r_n=10:139.7205,knn_tta_n=20:160.2667,knn_ttm_n=20:116.9178,knn_tta_r_n=20:170.8132,knn_ttm_r_n=20:156.6724,knn_tta_n=50:180.5692,knn_ttm_n=50:156.0233,knn_tta_r_n=50:188.1562,knn_ttm_r_n=50:177.7998,knn_tta_n=100:190.9386,knn_ttm_n=100:176.9563,knn_tta_r_n=100:196.3728,knn_ttm_r_n=100:189.0091'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:264.5923,knn_ttm_n=5:316.6242,knn_tta_r_n=5:193.688,knn_ttm_r_n=5:207.2871,knn_tta_n=10:229.4388,knn_ttm_n=10:270.6704,knn_tta_r_n=10:190.8395,knn_ttm_r_n=10:194.2729,knn_tta_n=20:205.8462,knn_ttm_n=20:236.6711,knn_tta_r_n=20:188.6921,knn_ttm_r_n=20:190.3493,knn_tta_n=50:189.7868,knn_ttm_n=50:207.5404,knn_tta_r_n=50:187.677,knn_ttm_r_n=50:188.3723,knn_tta_n=100:186.7467,knn_ttm_n=100:195.2604,knn_tta_r_n=100:188.2867,knn_ttm_r_n=100:187.9337'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:97.8319,knn_ttm_n=5:53.3588,knn_tta_r_n=5:107.2002,knn_ttm_r_n=5:146.0226,knn_tta_n=10:138.3798,knn_ttm_n=10:88.4265,knn_tta_r_n=10:154.9668,knn_ttm_r_n=10:150.6443,knn_tta_n=20:169.7045,knn_ttm_n=20:123.3975,knn_tta_r_n=20:185.9139,knn_ttm_r_n=20:170.6742,knn_tta_n=50:195.827,knn_ttm_n=50:169.3055,knn_tta_r_n=50:208.9073,knn_ttm_r_n=50:196.611,knn_tta_n=100:208.9019,knn_ttm_n=100:195.9344,knn_tta_r_n=100:220.3159,knn_ttm_r_n=100:211.4034'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:298.1541,knn_ttm_n=5:349.118,knn_tta_r_n=5:219.2384,knn_ttm_r_n=5:232.9704,knn_tta_n=10:246.3802,knn_ttm_n=10:303.1663,knn_tta_r_n=10:210.4741,knn_ttm_r_n=10:216.6332,knn_tta_n=20:220.8561,knn_ttm_n=20:261.4673,knn_tta_r_n=20:208.1216,knn_ttm_r_n=20:210.556,knn_tta_n=50:209.458,knn_ttm_n=50:229.5412,knn_tta_r_n=50:209.8703,knn_ttm_r_n=50:209.062,knn_tta_n=100:210.0877,knn_ttm_n=100:222.1232,knn_tta_r_n=100:213.9056,knn_ttm_r_n=100:211.914'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:69.7089,knn_ttm_n=5:36.2197,knn_tta_r_n=5:67.8412,knn_ttm_r_n=5:91.9281,knn_tta_n=10:94.7108,knn_ttm_n=10:59.1181,knn_tta_r_n=10:98.7741,knn_ttm_r_n=10:92.273,knn_tta_n=20:112.5446,knn_ttm_n=20:80.2773,knn_tta_r_n=20:116.2799,knn_ttm_r_n=20:104.7663,knn_tta_n=50:125.3079,knn_ttm_n=50:106.4843,knn_tta_r_n=50:128.1028,knn_ttm_r_n=50:120.1201,knn_tta_n=100:131.7779,knn_ttm_n=100:121.8973,knn_tta_r_n=100:133.1963,knn_ttm_r_n=100:128.1769'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:211.7694,knn_ttm_n=5:245.2589,knn_tta_r_n=5:152.8688,knn_ttm_r_n=5:160.1403,knn_tta_n=10:187.0753,knn_ttm_n=10:217.1196,knn_tta_r_n=10:148.8336,knn_ttm_r_n=10:151.4205,knn_tta_n=20:168.4738,knn_ttm_n=20:193.708,knn_tta_r_n=20:146.2141,knn_ttm_r_n=20:146.6988,knn_tta_n=50:153.6982,knn_ttm_n=50:170.32,knn_tta_r_n=50:144.6152,knn_ttm_r_n=50:145.005,knn_tta_n=100:149.4881,knn_ttm_n=100:159.039,knn_tta_r_n=100:144.5397,knn_ttm_r_n=100:144.5045'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_78'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:128.6894,knn_ttm_n=5:79.6606,knn_tta_r_n=5:131.9072,knn_ttm_r_n=5:178.7071,knn_tta_n=10:174.7442,knn_ttm_n=10:120.7925,knn_tta_r_n=10:188.2144,knn_ttm_r_n=10:184.743,knn_tta_n=20:208.4166,knn_ttm_n=20:160.9007,knn_tta_r_n=20:223.5333,knn_ttm_r_n=20:209.1668,knn_tta_n=50:238.4049,knn_ttm_n=50:214.3531,knn_tta_r_n=50:250.2835,knn_ttm_r_n=50:239.1844,knn_tta_n=100:254.7182,knn_ttm_n=100:246.6077,knn_tta_r_n=100:261.9058,knn_ttm_r_n=100:254.5774'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:335.2805,knn_ttm_n=5:400.274,knn_tta_r_n=5:279.6708,knn_ttm_r_n=5:305.7833,knn_tta_n=10:294.3062,knn_ttm_n=10:348.1301,knn_tta_r_n=10:273.7064,knn_ttm_r_n=10:282.1625,knn_tta_n=20:280.1541,knn_ttm_n=20:313.2171,knn_tta_r_n=20:274.5329,knn_ttm_r_n=20:276.6053,knn_tta_n=50:276.4675,knn_ttm_n=50:291.7698,knn_tta_r_n=50:280.8886,knn_ttm_r_n=50:279.8075,knn_tta_n=100:280.8437,knn_ttm_n=100:291.1447,knn_tta_r_n=100:284.8096,knn_ttm_r_n=100:283.4199'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:199.9824,knn_ttm_n=5:150.9293,knn_tta_r_n=5:207.4511,knn_ttm_r_n=5:282.9677,knn_tta_n=10:275.2128,knn_ttm_n=10:250.8673,knn_tta_r_n=10:290.2874,knn_ttm_r_n=10:295.5565,knn_tta_n=20:330.057,knn_ttm_n=20:330.1008,knn_tta_r_n=20:341.8622,knn_ttm_r_n=20:326.8363,knn_tta_n=50:375.7188,knn_ttm_n=50:415.9782,knn_tta_r_n=50:380.1482,knn_ttm_r_n=50:367.9104,knn_tta_n=100:394.8218,knn_ttm_n=100:462.3773,knn_tta_r_n=100:399.0332,knn_ttm_r_n=100:391.0836'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:517.7412,knn_ttm_n=5:594.609,knn_tta_r_n=5:438.9119,knn_ttm_r_n=5:487.1314,knn_tta_n=10:468.4245,knn_ttm_n=10:558.3481,knn_tta_r_n=10:421.8503,knn_ttm_r_n=10:446.4618,knn_tta_n=20:450.4985,knn_ttm_n=20:542.5267,knn_tta_r_n=20:419.6195,knn_ttm_r_n=20:429.4637,knn_tta_n=50:443.3114,knn_ttm_n=50:536.3133,knn_tta_r_n=50:425.3662,knn_ttm_r_n=50:427.8909,knn_tta_n=100:447.3879,knn_ttm_n=100:545.7803,knn_tta_r_n=100:434.8733,knn_ttm_r_n=100:432.8965'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:187.1787,knn_ttm_n=5:139.7403,knn_tta_r_n=5:195.6939,knn_ttm_r_n=5:269.2944,knn_tta_n=10:268.2543,knn_ttm_n=10:234.2074,knn_tta_r_n=10:282.7465,knn_ttm_r_n=10:291.1795,knn_tta_n=20:329.2661,knn_ttm_n=20:320.3376,knn_tta_r_n=20:338.5968,knn_ttm_r_n=20:328.2547,knn_tta_n=50:381.7183,knn_ttm_n=50:415.532,knn_tta_r_n=50:381.8875,knn_ttm_r_n=50:372.0841,knn_tta_n=100:410.4259,knn_ttm_n=100:472.1996,knn_tta_r_n=100:404.5128,knn_ttm_r_n=100:397.7244'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:502.7063,knn_ttm_n=5:570.4089,knn_tta_r_n=5:424.8388,knn_ttm_r_n=5:472.9052,knn_tta_n=10:454.8009,knn_ttm_n=10:533.998,knn_tta_r_n=10:406.9985,knn_ttm_r_n=10:436.0472,knn_tta_n=20:435.594,knn_ttm_n=20:505.8634,knn_tta_r_n=20:405.3565,knn_ttm_r_n=20:420.7354,knn_tta_n=50:425.6527,knn_ttm_n=50:498.5344,knn_tta_r_n=50:408.2723,knn_ttm_r_n=50:416.5571,knn_tta_n=100:433.9926,knn_ttm_n=100:512.6983,knn_tta_r_n=100:419.2969,knn_ttm_r_n=100:420.5908'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:111.5372,knn_ttm_n=5:62.9122,knn_tta_r_n=5:112.9522,knn_ttm_r_n=5:152.9653,knn_tta_n=10:150.9125,knn_ttm_n=10:99.6513,knn_tta_r_n=10:159.2097,knn_ttm_r_n=10:157.0968,knn_tta_n=20:177.2639,knn_ttm_n=20:136.6352,knn_tta_r_n=20:185.9008,knn_ttm_r_n=20:174.7017,knn_tta_n=50:198.8062,knn_ttm_n=50:176.1542,knn_tta_r_n=50:204.0582,knn_ttm_r_n=50:195.7941,knn_tta_n=100:208.2092,knn_ttm_n=100:196.4559,knn_tta_r_n=100:211.7101,knn_ttm_r_n=100:206.3723'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:306.3508,knn_ttm_n=5:370.9073,knn_tta_r_n=5:229.4963,knn_ttm_r_n=5:244.9993,knn_tta_n=10:263.5201,knn_ttm_n=10:318.6964,knn_tta_r_n=10:219.9602,knn_ttm_r_n=10:227.959,knn_tta_n=20:245.3125,knn_ttm_n=20:278.595,knn_tta_r_n=20:216.7194,knn_ttm_r_n=20:220.4978,knn_tta_n=50:219.3964,knn_ttm_n=50:240.9585,knn_tta_r_n=50:212.7412,knn_ttm_r_n=50:215.3703,knn_tta_n=100:214.7542,knn_ttm_n=100:224.7834,knn_tta_r_n=100:212.2124,knn_ttm_r_n=100:212.7722'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:107.9105,knn_ttm_n=5:66.891,knn_tta_r_n=5:116.843,knn_ttm_r_n=5:160.8667,knn_tta_n=10:152.6928,knn_ttm_n=10:106.5268,knn_tta_r_n=10:165.2423,knn_ttm_r_n=10:165.467,knn_tta_n=20:184.6231,knn_ttm_n=20:144.7942,knn_tta_r_n=20:195.3512,knn_ttm_r_n=20:184.887,knn_tta_n=50:208.8375,knn_ttm_n=50:188.418,knn_tta_r_n=50:215.9231,knn_ttm_r_n=50:207.3905,knn_tta_n=100:220.4044,knn_ttm_n=100:210.7849,knn_tta_r_n=100:225.5275,knn_ttm_r_n=100:220.0367'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:292.5575,knn_ttm_n=5:345.3661,knn_tta_r_n=5:232.5612,knn_ttm_r_n=5:250.5203,knn_tta_n=10:258.9986,knn_ttm_n=10:308.4476,knn_tta_r_n=10:223.746,knn_ttm_r_n=10:231.8763,knn_tta_n=20:238.1059,knn_ttm_n=20:271.967,knn_tta_r_n=20:220.2281,knn_ttm_r_n=20:223.521,knn_tta_n=50:225.5605,knn_ttm_n=50:247.9091,knn_tta_r_n=50:221.6847,knn_ttm_r_n=50:221.6822,knn_tta_n=100:225.5322,knn_ttm_n=100:236.9461,knn_tta_r_n=100:225.0908,knn_ttm_r_n=100:223.6088'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:65.0665,knn_ttm_n=5:38.1083,knn_tta_r_n=5:64.3595,knn_ttm_r_n=5:86.172,knn_tta_n=10:86.83,knn_ttm_n=10:58.7465,knn_tta_r_n=10:91.9905,knn_ttm_r_n=10:90.366,knn_tta_n=20:102.1341,knn_ttm_n=20:77.4626,knn_tta_r_n=20:107.4695,knn_ttm_r_n=20:100.9217,knn_tta_n=50:115.6269,knn_ttm_n=50:103.3878,knn_tta_r_n=50:117.8335,knn_ttm_r_n=50:112.9901,knn_tta_n=100:119.8631,knn_ttm_n=100:115.2963,knn_tta_r_n=100:121.9058,knn_ttm_r_n=100:118.8658'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:191.4127,knn_ttm_n=5:217.003,knn_tta_r_n=5:144.1125,knn_ttm_r_n=5:152.116,knn_tta_n=10:164.7478,knn_ttm_n=10:192.3543,knn_tta_r_n=10:139.3781,knn_ttm_r_n=10:142.7086,knn_tta_n=20:152.3503,knn_ttm_n=20:170.6357,knn_tta_r_n=20:137.0123,knn_ttm_r_n=20:138.0926,knn_tta_n=50:141.0873,knn_ttm_n=50:152.774,knn_tta_r_n=50:137.1806,knn_ttm_r_n=50:137.2021,knn_tta_n=100:138.1852,knn_ttm_n=100:145.0171,knn_tta_r_n=100:137.8381,knn_ttm_r_n=100:137.2137'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_80'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:174.1196,knn_ttm_n=5:157.3927,knn_tta_r_n=5:173.3516,knn_ttm_r_n=5:230.144,knn_tta_n=10:228.912,knn_ttm_n=10:227.1156,knn_tta_r_n=10:230.7725,knn_ttm_r_n=10:246.9679,knn_tta_n=20:258.815,knn_ttm_n=20:269.9001,knn_tta_r_n=20:259.7858,knn_ttm_r_n=20:265.8517,knn_tta_n=50:276.7763,knn_ttm_n=50:298.3345,knn_tta_r_n=50:275.2433,knn_ttm_r_n=50:277.6896,knn_tta_n=100:280.8307,knn_ttm_n=100:304.8101,knn_tta_r_n=100:279.0821,knn_ttm_r_n=100:281.0885'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:397.279,knn_ttm_n=5:500.3681,knn_tta_r_n=5:318.5379,knn_ttm_r_n=5:334.7653,knn_tta_n=10:342.6194,knn_ttm_n=10:422.0176,knn_tta_r_n=10:312.651,knn_ttm_r_n=10:318.5687,knn_tta_n=20:318.8801,knn_ttm_n=20:366.0849,knn_tta_r_n=20:309.5302,knn_ttm_r_n=20:314.9031,knn_tta_n=50:308.9516,knn_ttm_n=50:338.4671,knn_tta_r_n=50:308.2549,knn_ttm_r_n=50:311.6939,knn_tta_n=100:307.9981,knn_ttm_n=100:331.4799,knn_tta_r_n=100:307.3144,knn_ttm_r_n=100:310.7302'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:280.2476,knn_ttm_n=5:289.0559,knn_tta_r_n=5:272.7386,knn_ttm_r_n=5:370.6399,knn_tta_n=10:360.6689,knn_ttm_n=10:412.3141,knn_tta_r_n=10:359.4561,knn_ttm_r_n=10:393.8216,knn_tta_n=20:407.673,knn_ttm_n=20:485.7512,knn_tta_r_n=20:404.0521,knn_ttm_r_n=20:420.2972,knn_tta_n=50:431.6432,knn_ttm_n=50:528.713,knn_tta_r_n=50:427.8562,knn_ttm_r_n=50:437.798,knn_tta_n=100:438.658,knn_ttm_n=100:536.634,knn_tta_r_n=100:433.9244,knn_ttm_r_n=100:440.8166'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:692.6069,knn_ttm_n=5:869.5863,knn_tta_r_n=5:533.9212,knn_ttm_r_n=5:560.7041,knn_tta_n=10:599.7703,knn_ttm_n=10:783.6923,knn_tta_r_n=10:500.9881,knn_ttm_r_n=10:515.5317,knn_tta_n=20:542.3151,knn_ttm_n=20:719.6503,knn_tta_r_n=20:488.884,knn_ttm_r_n=20:497.7331,knn_tta_n=50:504.4006,knn_ttm_n=50:640.7601,knn_tta_r_n=50:478.9044,knn_ttm_r_n=50:486.0648,knn_tta_n=100:494.6191,knn_ttm_n=100:610.0075,knn_tta_r_n=100:476.5463,knn_ttm_r_n=100:480.9791'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:291.9012,knn_ttm_n=5:309.9973,knn_tta_r_n=5:278.7013,knn_ttm_r_n=5:379.1565,knn_tta_n=10:382.7831,knn_ttm_n=10:450.1787,knn_tta_r_n=10:371.1672,knn_ttm_r_n=10:410.6101,knn_tta_n=20:425.8581,knn_ttm_n=20:533.8659,knn_tta_r_n=20:415.4837,knn_ttm_r_n=20:440.1025,knn_tta_n=50:453.5641,knn_ttm_n=50:581.7095,knn_tta_r_n=50:444.7396,knn_ttm_r_n=50:460.5125,knn_tta_n=100:460.7165,knn_ttm_n=100:592.3681,knn_tta_r_n=100:452.5269,knn_ttm_r_n=100:465.0502'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:656.8937,knn_ttm_n=5:830.8186,knn_tta_r_n=5:547.3344,knn_ttm_r_n=5:599.2181,knn_tta_n=10:581.4463,knn_ttm_n=10:746.9771,knn_tta_r_n=10:508.576,knn_ttm_r_n=10:540.419,knn_tta_n=20:533.1511,knn_ttm_n=20:699.0893,knn_tta_r_n=20:494.0652,knn_ttm_r_n=20:514.4665,knn_tta_n=50:503.648,knn_ttm_n=50:653.466,knn_tta_r_n=50:482.2005,knn_ttm_r_n=50:498.0681,knn_tta_n=100:490.5649,knn_ttm_n=100:635.3936,knn_tta_r_n=100:476.8351,knn_ttm_r_n=100:490.4356'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:121.3522,knn_ttm_n=5:103.2699,knn_tta_r_n=5:120.5493,knn_ttm_r_n=5:159.9223,knn_tta_n=10:160.3123,knn_ttm_n=10:150.7121,knn_tta_r_n=10:163.9393,knn_ttm_r_n=10:173.8361,knn_tta_n=20:182.2202,knn_ttm_n=20:180.7576,knn_tta_r_n=20:184.6604,knn_ttm_r_n=20:187.1797,knn_tta_n=50:195.7842,knn_ttm_n=50:196.1137,knn_tta_r_n=50:197.516,knn_ttm_r_n=50:197.555,knn_tta_n=100:200.8502,knn_ttm_n=100:201.1423,knn_tta_r_n=100:201.9956,knn_ttm_r_n=100:201.6802'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:300.5056,knn_ttm_n=5:386.0034,knn_tta_r_n=5:226.0868,knn_ttm_r_n=5:232.7747,knn_tta_n=10:243.9275,knn_ttm_n=10:313.2497,knn_tta_r_n=10:209.8566,knn_ttm_r_n=10:213.0798,knn_tta_n=20:220.6873,knn_ttm_n=20:260.3468,knn_tta_r_n=20:202.6882,knn_ttm_r_n=20:203.9125,knn_tta_n=50:207.8378,knn_ttm_n=50:227.8034,knn_tta_r_n=50:200.7396,knn_ttm_r_n=50:200.1249,knn_tta_n=100:202.5819,knn_ttm_n=100:211.9905,knn_tta_r_n=100:200.0755,knn_ttm_r_n=100:199.9002'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:137.4605,knn_ttm_n=5:127.8707,knn_tta_r_n=5:141.9027,knn_ttm_r_n=5:187.3454,knn_tta_n=10:182.4233,knn_ttm_n=10:178.7468,knn_tta_r_n=10:189.462,knn_ttm_r_n=10:202.6647,knn_tta_n=20:207.4259,knn_ttm_n=20:212.1409,knn_tta_r_n=20:212.9434,knn_ttm_r_n=20:217.2311,knn_tta_n=50:223.6933,knn_ttm_n=50:230.3353,knn_tta_r_n=50:225.9779,knn_ttm_r_n=50:227.0135,knn_tta_n=100:229.773,knn_ttm_n=100:234.8317,knn_tta_r_n=100:230.6027,knn_ttm_r_n=100:230.7149'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:308.0342,knn_ttm_n=5:392.1672,knn_tta_r_n=5:237.4381,knn_ttm_r_n=5:249.677,knn_tta_n=10:263.2404,knn_ttm_n=10:331.4497,knn_tta_r_n=10:225.5204,knn_ttm_r_n=10:231.5611,knn_tta_n=20:241.7442,knn_ttm_n=20:289.6329,knn_tta_r_n=20:222.771,knn_ttm_r_n=20:223.3167,knn_tta_n=50:227.861,knn_ttm_n=50:256.7728,knn_tta_r_n=50:220.7747,knn_ttm_r_n=50:221.1882,knn_tta_n=100:222.4786,knn_ttm_n=100:239.2397,knn_tta_r_n=100:219.4239,knn_ttm_r_n=100:219.6421'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:82.8836,knn_ttm_n=5:72.7848,knn_tta_r_n=5:80.7956,knn_ttm_r_n=5:107.1568,knn_tta_n=10:107.4812,knn_ttm_n=10:104.9987,knn_tta_r_n=10:108.0963,knn_ttm_r_n=10:114.3513,knn_tta_n=20:121.3961,knn_ttm_n=20:122.4319,knn_tta_r_n=20:122.573,knn_ttm_r_n=20:124.1069,knn_tta_n=50:129.6539,knn_ttm_n=50:133.8517,knn_tta_r_n=50:130.1624,knn_ttm_r_n=50:130.5425,knn_tta_n=100:131.9751,knn_ttm_n=100:136.5887,knn_tta_r_n=100:132.943,knn_ttm_r_n=100:132.8207'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:209.2289,knn_ttm_n=5:251.9862,knn_tta_r_n=5:159.0557,knn_ttm_r_n=5:164.8693,knn_tta_n=10:175.9172,knn_ttm_n=10:216.5464,knn_tta_r_n=10:153.518,knn_ttm_r_n=10:154.6818,knn_tta_n=20:161.8023,knn_ttm_n=20:189.0783,knn_tta_r_n=20:150.8662,knn_ttm_r_n=20:151.6588,knn_tta_n=50:150.5801,knn_ttm_n=50:163.3974,knn_tta_r_n=50:148.3167,knn_ttm_r_n=50:148.6263,knn_tta_n=100:146.8333,knn_ttm_n=100:153.2808,knn_tta_r_n=100:147.1253,knn_ttm_r_n=100:147.3015'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_81'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:131.2525,knn_ttm_n=5:76.0762,knn_tta_r_n=5:136.6502,knn_ttm_r_n=5:186.4281,knn_tta_n=10:182.2778,knn_ttm_n=10:132.2955,knn_tta_r_n=10:197.3393,knn_ttm_r_n=10:200.1897,knn_tta_n=20:218.7312,knn_ttm_n=20:182.3683,knn_tta_r_n=20:232.1645,knn_ttm_r_n=20:225.5733,knn_tta_n=50:251.5751,knn_ttm_n=50:245.2746,knn_tta_r_n=50:257.2755,knn_ttm_r_n=50:254.2169,knn_tta_n=100:264.1704,knn_ttm_n=100:274.7036,knn_tta_r_n=100:265.0995,knn_ttm_r_n=100:264.8939'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:376.9681,knn_ttm_n=5:426.6467,knn_tta_r_n=5:296.5016,knn_ttm_r_n=5:310.4454,knn_tta_n=10:341.5825,knn_ttm_n=10:385.6167,knn_tta_r_n=10:295.3221,knn_ttm_r_n=10:299.6531,knn_tta_n=20:317.8134,knn_ttm_n=20:354.5291,knn_tta_r_n=20:298.0518,knn_ttm_r_n=20:299.6683,knn_tta_n=50:300.9633,knn_ttm_n=50:327.8069,knn_tta_r_n=50:296.3561,knn_ttm_r_n=50:298.4682,knn_tta_n=100:297.4259,knn_ttm_n=100:318.5758,knn_tta_r_n=100:294.738,knn_ttm_r_n=100:296.9949'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:195.7009,knn_ttm_n=5:149.0072,knn_tta_r_n=5:209.5274,knn_ttm_r_n=5:285.4712,knn_tta_n=10:282.5543,knn_ttm_n=10:263.8249,knn_tta_r_n=10:306.0036,knn_ttm_r_n=10:316.7257,knn_tta_n=20:346.2367,knn_ttm_n=20:367.5667,knn_tta_r_n=20:365.0819,knn_ttm_r_n=20:358.5592,knn_tta_n=50:407.7971,knn_ttm_n=50:493.2251,knn_tta_r_n=50:412.8472,knn_ttm_r_n=50:411.6638,knn_tta_n=100:436.1111,knn_ttm_n=100:555.1999,knn_tta_r_n=100:432.5336,knn_ttm_r_n=100:435.7782'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:538.5064,knn_ttm_n=5:620.7062,knn_tta_r_n=5:439.9788,knn_ttm_r_n=5:471.7811,knn_tta_n=10:494.4356,knn_ttm_n=10:598.4716,knn_tta_r_n=10:444.3168,knn_ttm_r_n=10:453.1539,knn_tta_n=20:482.8092,knn_ttm_n=20:597.1772,knn_tta_r_n=20:456.5445,knn_ttm_r_n=20:461.3955,knn_tta_n=50:481.2013,knn_ttm_n=50:613.225,knn_tta_r_n=50:468.4237,knn_ttm_r_n=50:472.3417,knn_tta_n=100:488.3392,knn_ttm_n=100:632.7901,knn_tta_r_n=100:476.1586,knn_ttm_r_n=100:480.7794'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:206.5066,knn_ttm_n=5:154.0967,knn_tta_r_n=5:210.8875,knn_ttm_r_n=5:282.4882,knn_tta_n=10:295.2655,knn_ttm_n=10:276.6319,knn_tta_r_n=10:311.1043,knn_ttm_r_n=10:321.7401,knn_tta_n=20:364.4223,knn_ttm_n=20:389.5918,knn_tta_r_n=20:374.3886,knn_ttm_r_n=20:371.3243,knn_tta_n=50:427.6434,knn_ttm_n=50:519.0002,knn_tta_r_n=50:426.6318,knn_ttm_r_n=50:428.7991,knn_tta_n=100:449.2376,knn_ttm_n=100:577.5224,knn_tta_r_n=100:443.8642,knn_ttm_r_n=100:449.7562'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:509.9413,knn_ttm_n=5:564.0468,knn_tta_r_n=5:456.5846,knn_ttm_r_n=5:501.8631,knn_tta_n=10:473.6498,knn_ttm_n=10:550.5348,knn_tta_r_n=10:443.5869,knn_ttm_r_n=10:465.358,knn_tta_n=20:466.0484,knn_ttm_n=20:563.9462,knn_tta_r_n=20:445.5504,knn_ttm_r_n=20:458.8046,knn_tta_n=50:461.6185,knn_ttm_n=50:577.6052,knn_tta_r_n=50:450.8261,knn_ttm_r_n=50:460.3698,knn_tta_n=100:468.8929,knn_ttm_n=100:597.521,knn_tta_r_n=100:458.5863,knn_ttm_r_n=100:467.2698'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:107.8855,knn_ttm_n=5:67.4175,knn_tta_r_n=5:107.0157,knn_ttm_r_n=5:145.4267,knn_tta_n=10:146.6647,knn_ttm_n=10:107.4425,knn_tta_r_n=10:152.185,knn_ttm_r_n=10:151.5985,knn_tta_n=20:173.5292,knn_ttm_n=20:147.8057,knn_tta_r_n=20:176.9121,knn_ttm_r_n=20:171.1846,knn_tta_n=50:190.7766,knn_ttm_n=50:184.3271,knn_tta_r_n=50:192.215,knn_ttm_r_n=50:189.8987,knn_tta_n=100:195.768,knn_ttm_n=100:197.5472,knn_tta_r_n=100:196.8002,knn_ttm_r_n=100:196.2121'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:286.2148,knn_ttm_n=5:348.2951,knn_tta_r_n=5:205.4422,knn_ttm_r_n=5:215.7796,knn_tta_n=10:236.7839,knn_ttm_n=10:294.1796,knn_tta_r_n=10:201.5398,knn_ttm_r_n=10:202.687,knn_tta_n=20:213.0798,knn_ttm_n=20:248.4249,knn_tta_r_n=20:197.7465,knn_ttm_r_n=20:199.0741,knn_tta_n=50:204.8269,knn_ttm_n=50:222.7325,knn_tta_r_n=50:197.3,knn_ttm_r_n=50:197.7382,knn_tta_n=100:198.8666,knn_ttm_n=100:211.8128,knn_tta_r_n=100:196.1186,knn_ttm_r_n=100:196.9301'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:110.2991,knn_ttm_n=5:67.9869,knn_tta_r_n=5:118.6524,knn_ttm_r_n=5:165.2049,knn_tta_n=10:155.7607,knn_ttm_n=10:115.5373,knn_tta_r_n=10:166.0185,knn_ttm_r_n=10:170.021,knn_tta_n=20:185.1887,knn_ttm_n=20:161.6716,knn_tta_r_n=20:192.4524,knn_ttm_r_n=20:188.1144,knn_tta_n=50:206.867,knn_ttm_n=50:205.1691,knn_tta_r_n=50:209.3471,knn_ttm_r_n=50:207.3438,knn_tta_n=100:215.0303,knn_ttm_n=100:222.6345,knn_tta_r_n=100:215.458,knn_ttm_r_n=100:214.7388'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:281.9599,knn_ttm_n=5:324.5084,knn_tta_r_n=5:216.9049,knn_ttm_r_n=5:229.456,knn_tta_n=10:252.7104,knn_ttm_n=10:299.5863,knn_tta_r_n=10:212.4496,knn_ttm_r_n=10:215.8356,knn_tta_n=20:227.5175,knn_ttm_n=20:270.1773,knn_tta_r_n=20:210.4845,knn_ttm_r_n=20:212.3405,knn_tta_n=50:213.5623,knn_ttm_n=50:237.029,knn_tta_r_n=50:210.0476,knn_ttm_r_n=50:211.0604,knn_tta_n=100:212.7933,knn_ttm_n=100:227.7421,knn_tta_r_n=100:210.5904,knn_ttm_r_n=100:211.3515'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:71.1262,knn_ttm_n=5:42.5093,knn_tta_r_n=5:71.6316,knn_ttm_r_n=5:99.0183,knn_tta_n=10:97.843,knn_ttm_n=10:72.6338,knn_tta_r_n=10:101.4303,knn_ttm_r_n=10:102.0565,knn_tta_n=20:114.6781,knn_ttm_n=20:99.0235,knn_tta_r_n=20:117.4907,knn_ttm_r_n=20:113.8377,knn_tta_n=50:126.7429,knn_ttm_n=50:125.4794,knn_tta_r_n=50:127.9151,knn_ttm_r_n=50:125.9848,knn_tta_n=100:130.3834,knn_ttm_n=100:136.0451,knn_tta_r_n=100:131.3499,knn_ttm_r_n=100:130.8005'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:212.469,knn_ttm_n=5:239.8597,knn_tta_r_n=5:150.965,knn_ttm_r_n=5:155.9094,knn_tta_n=10:184.8872,knn_ttm_n=10:219.1314,knn_tta_r_n=10:148.7468,knn_ttm_r_n=10:149.3554,knn_tta_n=20:160.9615,knn_ttm_n=20:193.4446,knn_tta_r_n=20:146.1611,knn_ttm_r_n=20:147.3275,knn_tta_n=50:148.6266,knn_ttm_n=50:165.8036,knn_tta_r_n=50:144.2084,knn_ttm_r_n=50:145.0481,knn_tta_n=100:144.5575,knn_ttm_n=100:154.7612,knn_tta_r_n=100:143.433,knn_ttm_r_n=100:143.671'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_82'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:133.0853,knn_ttm_n=5:80.9701,knn_tta_r_n=5:144.765,knn_ttm_r_n=5:199.5198,knn_tta_n=10:187.0695,knn_ttm_n=10:136.3488,knn_tta_r_n=10:207.146,knn_ttm_r_n=10:210.9618,knn_tta_n=20:224.8429,knn_ttm_n=20:183.6085,knn_tta_r_n=20:245.6812,knn_ttm_r_n=20:235.7078,knn_tta_n=50:259.1321,knn_ttm_n=50:238.8888,knn_tta_r_n=50:275.369,knn_ttm_r_n=50:268.0689,knn_tta_n=100:276.272,knn_ttm_n=100:271.1514,knn_tta_r_n=100:289.9359,knn_ttm_r_n=100:284.6484'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:369.946,knn_ttm_n=5:428.9644,knn_tta_r_n=5:312.0936,knn_ttm_r_n=5:329.9473,knn_tta_n=10:327.2412,knn_ttm_n=10:381.4169,knn_tta_r_n=10:301.693,knn_ttm_r_n=10:313.1033,knn_tta_n=20:315.4366,knn_ttm_n=20:348.1291,knn_tta_r_n=20:303.5375,knn_ttm_r_n=20:308.8864,knn_tta_n=50:305.2023,knn_ttm_n=50:327.8471,knn_tta_r_n=50:311.1661,knn_ttm_r_n=50:309.5883,knn_tta_n=100:310.0647,knn_ttm_n=100:325.4107,knn_tta_r_n=100:319.51,knn_ttm_r_n=100:317.2268'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:184.6529,knn_ttm_n=5:130.3267,knn_tta_r_n=5:201.7452,knn_ttm_r_n=5:282.7425,knn_tta_n=10:262.3097,knn_ttm_n=10:220.8097,knn_tta_r_n=10:287.6102,knn_ttm_r_n=10:294.1814,knn_tta_n=20:317.4295,knn_ttm_n=20:302.5333,knn_tta_r_n=20:341.8075,knn_ttm_r_n=20:331.788,knn_tta_n=50:365.1459,knn_ttm_n=50:386.2734,knn_tta_r_n=50:382.219,knn_ttm_r_n=50:374.0936,knn_tta_n=100:388.2942,knn_ttm_n=100:429.4293,knn_tta_r_n=100:402.038,knn_ttm_r_n=100:397.5264'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:507.2342,knn_ttm_n=5:588.7375,knn_tta_r_n=5:425.0074,knn_ttm_r_n=5:448.3041,knn_tta_n=10:448.8841,knn_ttm_n=10:540.6915,knn_tta_r_n=10:417.5113,knn_ttm_r_n=10:432.754,knn_tta_n=20:435.3541,knn_ttm_n=20:511.3363,knn_tta_r_n=20:416.1376,knn_ttm_r_n=20:427.7703,knn_tta_n=50:431.3628,knn_ttm_n=50:503.0512,knn_tta_r_n=50:425.0119,knn_ttm_r_n=50:430.138,knn_tta_n=100:437.5014,knn_ttm_n=100:510.454,knn_tta_r_n=100:435.7839,knn_ttm_r_n=100:438.0478'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:183.6254,knn_ttm_n=5:115.5103,knn_tta_r_n=5:197.2703,knn_ttm_r_n=5:278.6348,knn_tta_n=10:263.4871,knn_ttm_n=10:205.3285,knn_tta_r_n=10:286.0978,knn_ttm_r_n=10:298.1064,knn_tta_n=20:322.4818,knn_ttm_n=20:294.5473,knn_tta_r_n=20:344.2217,knn_ttm_r_n=20:337.5271,knn_tta_n=50:379.8694,knn_ttm_n=50:390.123,knn_tta_r_n=50:389.9092,knn_ttm_r_n=50:383.9361,knn_tta_n=100:411.0855,knn_ttm_n=100:446.5336,knn_tta_r_n=100:415.6424,knn_ttm_r_n=100:411.9864'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:480.3416,knn_ttm_n=5:551.7231,knn_tta_r_n=5:444.9637,knn_ttm_r_n=5:481.9562,knn_tta_n=10:438.7797,knn_ttm_n=10:496.0712,knn_tta_r_n=10:426.775,knn_ttm_r_n=10:446.8415,knn_tta_n=20:421.7462,knn_ttm_n=20:474.8123,knn_tta_r_n=20:420.1194,knn_ttm_r_n=20:433.5703,knn_tta_n=50:426.2118,knn_ttm_n=50:471.3019,knn_tta_r_n=50:428.2433,knn_ttm_r_n=50:435.737,knn_tta_n=100:438.6034,knn_ttm_n=100:489.618,knn_tta_r_n=100:436.617,knn_ttm_r_n=100:441.7891'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:106.7951,knn_ttm_n=5:68.2447,knn_tta_r_n=5:109.8107,knn_ttm_r_n=5:149.0987,knn_tta_n=10:141.6461,knn_ttm_n=10:104.8214,knn_tta_r_n=10:155.2635,knn_ttm_r_n=10:155.173,knn_tta_n=20:169.8905,knn_ttm_n=20:135.5927,knn_tta_r_n=20:183.14,knn_ttm_r_n=20:174.8726,knn_tta_n=50:192.3433,knn_ttm_n=50:174.8122,knn_tta_r_n=50:202.5054,knn_ttm_r_n=50:196.1655,knn_tta_n=100:203.4105,knn_ttm_n=100:195.8244,knn_tta_r_n=100:210.8553,knn_ttm_r_n=100:206.7262'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:287.4374,knn_ttm_n=5:345.4168,knn_tta_r_n=5:228.4392,knn_ttm_r_n=5:245.806,knn_tta_n=10:240.5138,knn_ttm_n=10:290.435,knn_tta_r_n=10:218.786,knn_ttm_r_n=10:227.3036,knn_tta_n=20:221.0231,knn_ttm_n=20:250.6204,knn_tta_r_n=20:216.2909,knn_ttm_r_n=20:219.3509,knn_tta_n=50:213.8752,knn_ttm_n=50:225.6484,knn_tta_r_n=50:216.8859,knn_ttm_r_n=50:217.4588,knn_tta_n=100:216.0792,knn_ttm_n=100:222.3238,knn_tta_r_n=100:219.0964,knn_ttm_r_n=100:218.7776'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:114.3302,knn_ttm_n=5:73.0514,knn_tta_r_n=5:120.8128,knn_ttm_r_n=5:166.0791,knn_tta_n=10:156.2596,knn_ttm_n=10:112.9725,knn_tta_r_n=10:171.72,knn_ttm_r_n=10:173.0646,knn_tta_n=20:184.2823,knn_ttm_n=20:149.1757,knn_tta_r_n=20:201.4038,knn_ttm_r_n=20:192.7609,knn_tta_n=50:212.3224,knn_ttm_n=50:194.261,knn_tta_r_n=50:222.5479,knn_ttm_r_n=50:215.89,knn_tta_n=100:225.4396,knn_ttm_n=100:220.66,knn_tta_r_n=100:231.9205,knn_ttm_r_n=100:227.7695'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:297.9322,knn_ttm_n=5:351.8494,knn_tta_r_n=5:227.649,knn_ttm_r_n=5:247.3396,knn_tta_n=10:256.334,knn_ttm_n=10:303.9828,knn_tta_r_n=10:222.8062,knn_ttm_r_n=10:230.2599,knn_tta_n=20:233.7748,knn_ttm_n=20:269.3008,knn_tta_r_n=20:219.7149,knn_ttm_r_n=20:223.5115,knn_tta_n=50:222.8694,knn_ttm_n=50:244.8833,knn_tta_r_n=50:220.9625,knn_ttm_r_n=50:222.1673,knn_tta_n=100:224.1117,knn_ttm_n=100:237.2977,knn_tta_r_n=100:224.9231,knn_ttm_r_n=100:224.0264'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:54.2212,knn_ttm_n=5:31.5715,knn_tta_r_n=5:52.4591,knn_ttm_r_n=5:70.3497,knn_tta_n=10:72.6886,knn_ttm_n=10:49.991,knn_tta_r_n=10:74.6359,knn_ttm_r_n=10:72.7619,knn_tta_n=20:83.8625,knn_ttm_n=20:65.6246,knn_tta_r_n=20:86.7694,knn_ttm_r_n=20:81.2794,knn_tta_n=50:93.0044,knn_ttm_n=50:82.1868,knn_tta_r_n=50:94.8225,knn_ttm_r_n=50:91.1229,knn_tta_n=100:96.7838,knn_ttm_n=100:90.9313,knn_tta_r_n=100:98.5964,knn_ttm_r_n=100:96.0588'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:184.4329,knn_ttm_n=5:216.2681,knn_tta_r_n=5:141.2143,knn_ttm_r_n=5:147.0455,knn_tta_n=10:158.4967,knn_ttm_n=10:188.5715,knn_tta_r_n=10:136.5837,knn_ttm_r_n=10:139.3062,knn_tta_n=20:146.2736,knn_ttm_n=20:164.0662,knn_tta_r_n=20:134.7622,knn_ttm_r_n=20:135.4807,knn_tta_n=50:137.1328,knn_ttm_n=50:146.1477,knn_tta_r_n=50:134.0661,knn_ttm_r_n=50:134.0847,knn_tta_n=100:135.7026,knn_ttm_n=100:138.6626,knn_tta_r_n=100:135.1679,knn_ttm_r_n=100:134.333'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_83'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:96.3797,knn_ttm_n=5:47.1496,knn_tta_r_n=5:103.267,knn_ttm_r_n=5:142.1604,knn_tta_n=10:133.9962,knn_ttm_n=10:81.6917,knn_tta_r_n=10:148.0708,knn_ttm_r_n=10:139.0987,knn_tta_n=20:162.9236,knn_ttm_n=20:113.6768,knn_tta_r_n=20:179.0912,knn_ttm_r_n=20:157.4536,knn_tta_n=50:188.3844,knn_ttm_n=50:155.8231,knn_tta_r_n=50:202.7462,knn_ttm_r_n=50:185.2775,knn_tta_n=100:201.6332,knn_ttm_n=100:180.5716,knn_tta_r_n=100:215.5375,knn_ttm_r_n=100:201.7992'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:269.3295,knn_ttm_n=5:303.5138,knn_tta_r_n=5:231.0064,knn_ttm_r_n=5:248.4798,knn_tta_n=10:235.5749,knn_ttm_n=10:266.7815,knn_tta_r_n=10:223.9276,knn_ttm_r_n=10:230.4436,knn_tta_n=20:222.0336,knn_ttm_n=20:240.3299,knn_tta_r_n=20:223.4788,knn_ttm_r_n=20:225.1251,knn_tta_n=50:219.1551,knn_ttm_n=50:225.966,knn_tta_r_n=50:228.094,knn_ttm_r_n=50:225.3099,knn_tta_n=100:225.1921,knn_ttm_n=100:224.9449,knn_tta_r_n=100:235.1984,knn_ttm_r_n=100:229.899'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:117.8312,knn_ttm_n=5:62.1327,knn_tta_r_n=5:125.7792,knn_ttm_r_n=5:173.9163,knn_tta_n=10:164.8062,knn_ttm_n=10:109.7389,knn_tta_r_n=10:186.5197,knn_ttm_r_n=10:178.1563,knn_tta_n=20:198.4836,knn_ttm_n=20:153.9055,knn_tta_r_n=20:225.6311,knn_ttm_r_n=20:199.5193,knn_tta_n=50:229.2799,knn_ttm_n=50:206.283,knn_tta_r_n=50:259.9081,knn_ttm_r_n=50:235.4322,knn_tta_n=100:246.002,knn_ttm_n=100:236.8371,knn_tta_r_n=100:280.4051,knn_ttm_r_n=100:259.2437'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:311.2135,knn_ttm_n=5:347.0645,knn_tta_r_n=5:296.5551,knn_ttm_r_n=5:323.1418,knn_tta_n=10:274.4911,knn_ttm_n=10:311.6235,knn_tta_r_n=10:279.304,knn_ttm_r_n=10:292.9232,knn_tta_n=20:256.1537,knn_ttm_n=20:285.313,knn_tta_r_n=20:275.1061,knn_ttm_r_n=20:279.8881,knn_tta_n=50:256.4122,knn_ttm_n=50:273.9671,knn_tta_r_n=50:280.689,knn_ttm_r_n=50:278.7343,knn_tta_n=100:260.9921,knn_ttm_n=100:276.8186,knn_tta_r_n=100:295.2631,knn_ttm_r_n=100:286.7452'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:113.6543,knn_ttm_n=5:57.6075,knn_tta_r_n=5:120.0463,knn_ttm_r_n=5:169.4157,knn_tta_n=10:158.0564,knn_ttm_n=10:105.197,knn_tta_r_n=10:175.7222,knn_ttm_r_n=10:172.4382,knn_tta_n=20:190.3973,knn_ttm_n=20:147.9778,knn_tta_r_n=20:212.3749,knn_ttm_r_n=20:191.4644,knn_tta_n=50:220.9736,knn_ttm_n=50:199.0075,knn_tta_r_n=50:245.8799,knn_ttm_r_n=50:224.548,knn_tta_n=100:238.7894,knn_ttm_n=100:229.8591,knn_tta_r_n=100:267.9458,knn_ttm_r_n=100:248.9496'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:308.5115,knn_ttm_n=5:345.3512,knn_tta_r_n=5:305.6033,knn_ttm_r_n=5:332.5677,knn_tta_n=10:283.4126,knn_ttm_n=10:314.553,knn_tta_r_n=10:280.9705,knn_ttm_r_n=10:299.3877,knn_tta_n=20:265.6518,knn_ttm_n=20:295.1936,knn_tta_r_n=20:275.8029,knn_ttm_r_n=20:284.7737,knn_tta_n=50:259.4126,knn_ttm_n=50:279.1578,knn_tta_r_n=50:282.7535,knn_ttm_r_n=50:282.4361,knn_tta_n=100:260.9137,knn_ttm_n=100:277.3823,knn_tta_r_n=100:291.9461,knn_ttm_r_n=100:286.2981'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:89.9019,knn_ttm_n=5:45.0275,knn_tta_r_n=5:91.8593,knn_ttm_r_n=5:123.3196,knn_tta_n=10:124.3271,knn_ttm_n=10:71.6897,knn_tta_r_n=10:132.3871,knn_ttm_r_n=10:121.0786,knn_tta_n=20:148.0525,knn_ttm_n=20:99.2015,knn_tta_r_n=20:158.0791,knn_ttm_r_n=20:136.8279,knn_tta_n=50:167.8653,knn_ttm_n=50:134.6728,knn_tta_r_n=50:177.0672,knn_ttm_r_n=50:160.8427,knn_tta_n=100:178.5023,knn_ttm_n=100:156.9825,knn_tta_r_n=100:186.4109,knn_ttm_r_n=100:174.0265'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:250.4116,knn_ttm_n=5:293.2044,knn_tta_r_n=5:194.5265,knn_ttm_r_n=5:209.0932,knn_tta_n=10:219.0422,knn_ttm_n=10:253.9408,knn_tta_r_n=10:184.6194,knn_ttm_r_n=10:191.7584,knn_tta_n=20:201.9232,knn_ttm_n=20:226.0546,knn_tta_r_n=20:183.9775,knn_ttm_r_n=20:185.648,knn_tta_n=50:188.0707,knn_ttm_n=50:202.6754,knn_tta_r_n=50:184.7248,knn_ttm_r_n=50:183.343,knn_tta_n=100:187.5816,knn_ttm_n=100:193.2386,knn_tta_r_n=100:188.5355,knn_ttm_r_n=100:184.8157'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:89.551,knn_ttm_n=5:43.9835,knn_tta_r_n=5:91.87,knn_ttm_r_n=5:124.7235,knn_tta_n=10:123.8173,knn_ttm_n=10:75.225,knn_tta_r_n=10:133.0177,knn_ttm_r_n=10:123.7437,knn_tta_n=20:146.9835,knn_ttm_n=20:105.0244,knn_tta_r_n=20:159.0525,knn_ttm_r_n=20:139.4894,knn_tta_n=50:167.6202,knn_ttm_n=50:142.6264,knn_tta_r_n=50:178.8715,knn_ttm_r_n=50:163.6915,knn_tta_n=100:177.8465,knn_ttm_n=100:163.084,knn_tta_r_n=100:188.6333,knn_ttm_r_n=100:177.1682'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:248.4358,knn_ttm_n=5:280.8652,knn_tta_r_n=5:203.015,knn_ttm_r_n=5:219.6733,knn_tta_n=10:219.5618,knn_ttm_n=10:249.7929,knn_tta_r_n=10:192.7223,knn_ttm_r_n=10:200.8432,knn_tta_n=20:196.3636,knn_ttm_n=20:224.3988,knn_tta_r_n=20:186.0001,knn_ttm_r_n=20:190.6363,knn_tta_n=50:186.1115,knn_ttm_n=50:202.0764,knn_tta_r_n=50:187.0659,knn_ttm_r_n=50:185.4401,knn_tta_n=100:186.6152,knn_ttm_n=100:195.1051,knn_tta_r_n=100:191.1925,knn_ttm_r_n=100:187.7149'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:61.3146,knn_ttm_n=5:28.9835,knn_tta_r_n=5:61.7348,knn_ttm_r_n=5:82.7055,knn_tta_n=10:83.85,knn_ttm_n=10:47.5968,knn_tta_r_n=10:89.4262,knn_ttm_r_n=10:82.5045,knn_tta_n=20:98.7078,knn_ttm_n=20:66.9383,knn_tta_r_n=20:106.8454,knn_ttm_r_n=20:93.1949,knn_tta_n=50:111.4118,knn_ttm_n=50:91.3537,knn_tta_r_n=50:120.3573,knn_ttm_r_n=50:109.2972,knn_tta_n=100:117.8387,knn_ttm_n=100:105.5702,knn_tta_r_n=100:126.9921,knn_ttm_r_n=100:118.5858'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:189.1941,knn_ttm_n=5:220.5301,knn_tta_r_n=5:156.71,knn_ttm_r_n=5:169.4671,knn_tta_n=10:169.2272,knn_ttm_n=10:190.019,knn_tta_r_n=10:148.6834,knn_ttm_r_n=10:153.2903,knn_tta_n=20:155.3534,knn_ttm_n=20:171.3481,knn_tta_r_n=20:148.7522,knn_ttm_r_n=20:148.2334,knn_tta_n=50:147.7246,knn_ttm_n=50:155.6366,knn_tta_r_n=50:149.3571,knn_ttm_r_n=50:148.2448,knn_tta_n=100:147.7727,knn_ttm_n=100:150.6132,knn_tta_r_n=100:153.4168,knn_ttm_r_n=100:149.9968'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_91'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:138.0621,knn_ttm_n=5:93.1851,knn_tta_r_n=5:136.7224,knn_ttm_r_n=5:182.1354,knn_tta_n=10:185.7248,knn_ttm_n=10:144.3121,knn_tta_r_n=10:191.0514,knn_ttm_r_n=10:191.316,knn_tta_n=20:216.7683,knn_ttm_n=20:187.6133,knn_tta_r_n=20:223.0243,knn_ttm_r_n=20:213.9005,knn_tta_n=50:241.2163,knn_ttm_n=50:228.9414,knn_tta_r_n=50:246.5307,knn_ttm_r_n=50:238.3286,knn_tta_n=100:252.5325,knn_ttm_n=100:248.9141,knn_tta_r_n=100:257.0664,knn_ttm_r_n=100:251.2562'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:391.8133,knn_ttm_n=5:442.8252,knn_tta_r_n=5:298.4174,knn_ttm_r_n=5:322.2608,knn_tta_n=10:332.136,knn_ttm_n=10:399.9687,knn_tta_r_n=10:287.1714,knn_ttm_r_n=10:296.7876,knn_tta_n=20:296.7324,knn_ttm_n=20:354.7426,knn_tta_r_n=20:280.7324,knn_ttm_r_n=20:286.1598,knn_tta_n=50:278.0618,knn_ttm_n=50:309.3936,knn_tta_r_n=50:280.9358,knn_ttm_r_n=50:282.5705,knn_tta_n=100:279.2242,knn_ttm_n=100:293.8273,knn_tta_r_n=100:283.4985,knn_ttm_r_n=100:283.1128'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:189.4185,knn_ttm_n=5:139.8854,knn_tta_r_n=5:182.8931,knn_ttm_r_n=5:248.464,knn_tta_n=10:247.7724,knn_ttm_n=10:220.318,knn_tta_r_n=10:252.4053,knn_ttm_r_n=10:260.9532,knn_tta_n=20:290.5212,knn_ttm_n=20:284.4051,knn_tta_r_n=20:296.2,knn_ttm_r_n=20:289.6605,knn_tta_n=50:320.0241,knn_ttm_n=50:349.2951,knn_tta_r_n=50:328.1044,knn_ttm_r_n=50:321.9216,knn_tta_n=100:334.3331,knn_ttm_n=100:377.3352,knn_tta_r_n=100:346.0234,knn_ttm_r_n=100:340.1683'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:494.0542,knn_ttm_n=5:566.0781,knn_tta_r_n=5:391.8671,knn_ttm_r_n=5:420.7327,knn_tta_n=10:455.735,knn_ttm_n=10:521.9411,knn_tta_r_n=10:373.591,knn_ttm_r_n=10:389.8045,knn_tta_n=20:411.4479,knn_ttm_n=20:497.0246,knn_tta_r_n=20:362.2816,knn_ttm_r_n=20:372.2853,knn_tta_n=50:384.6343,knn_ttm_n=50:467.3012,knn_tta_r_n=50:366.7988,knn_ttm_r_n=50:371.5174,knn_tta_n=100:376.4656,knn_ttm_n=100:453.2432,knn_tta_r_n=100:375.5419,knn_ttm_r_n=100:376.8193'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:195.2678,knn_ttm_n=5:156.0706,knn_tta_r_n=5:190.4292,knn_ttm_r_n=5:254.3958,knn_tta_n=10:261.8283,knn_ttm_n=10:236.6051,knn_tta_r_n=10:261.4134,knn_ttm_r_n=10:270.4148,knn_tta_n=20:303.5006,knn_ttm_n=20:299.949,knn_tta_r_n=20:303.9268,knn_ttm_r_n=20:296.0052,knn_tta_n=50:333.6161,knn_ttm_n=50:360.3125,knn_tta_r_n=50:336.9626,knn_ttm_r_n=50:329.3315,knn_tta_n=100:346.0486,knn_ttm_n=100:397.8872,knn_tta_r_n=100:353.5201,knn_ttm_r_n=100:349.2035'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:447.6099,knn_ttm_n=5:546.5331,knn_tta_r_n=5:378.432,knn_ttm_r_n=5:419.244,knn_tta_n=10:397.511,knn_ttm_n=10:486.8363,knn_tta_r_n=10:361.0843,knn_ttm_r_n=10:386.2717,knn_tta_n=20:378.7968,knn_ttm_n=20:444.2021,knn_tta_r_n=20:358.1317,knn_ttm_r_n=20:372.2422,knn_tta_n=50:364.6147,knn_ttm_n=50:425.0935,knn_tta_r_n=50:364.0605,knn_ttm_r_n=50:368.3503,knn_tta_n=100:362.5657,knn_ttm_n=100:430.0435,knn_tta_r_n=100:370.696,knn_ttm_r_n=100:372.2589'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:114.7732,knn_ttm_n=5:76.1648,knn_tta_r_n=5:110.8276,knn_ttm_r_n=5:149.7079,knn_tta_n=10:152.9292,knn_ttm_n=10:116.2985,knn_tta_r_n=10:154.2739,knn_ttm_r_n=10:153.6112,knn_tta_n=20:174.9189,knn_ttm_n=20:146.1418,knn_tta_r_n=20:179.7468,knn_ttm_r_n=20:171.0205,knn_tta_n=50:192.5483,knn_ttm_n=50:176.7503,knn_tta_r_n=50:195.6165,knn_ttm_r_n=50:189.6448,knn_tta_n=100:199.1888,knn_ttm_n=100:190.666,knn_tta_r_n=100:201.9033,knn_ttm_r_n=100:197.2733'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:291.2369,knn_ttm_n=5:352.3709,knn_tta_r_n=5:205.5148,knn_ttm_r_n=5:220.4291,knn_tta_n=10:241.83,knn_ttm_n=10:297.8432,knn_tta_r_n=10:198.0357,knn_ttm_r_n=10:201.7267,knn_tta_n=20:219.6634,knn_ttm_n=20:254.1431,knn_tta_r_n=20:196.5583,knn_ttm_r_n=20:197.7021,knn_tta_n=50:203.299,knn_ttm_n=50:221.7034,knn_tta_r_n=50:196.119,knn_ttm_r_n=50:195.9789,knn_tta_n=100:200.359,knn_ttm_n=100:209.2355,knn_tta_r_n=100:196.7132,knn_ttm_r_n=100:195.9431'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:116.5956,knn_ttm_n=5:77.9482,knn_tta_r_n=5:113.9885,knn_ttm_r_n=5:155.3735,knn_tta_n=10:155.458,knn_ttm_n=10:118.9282,knn_tta_r_n=10:160.5302,knn_ttm_r_n=10:162.3035,knn_tta_n=20:181.1453,knn_ttm_n=20:155.599,knn_tta_r_n=20:187.256,knn_ttm_r_n=20:178.9384,knn_tta_n=50:202.7361,knn_ttm_n=50:194.6703,knn_tta_r_n=50:205.8674,knn_ttm_r_n=50:199.3032,knn_tta_n=100:209.8762,knn_ttm_n=100:210.3783,knn_tta_r_n=100:213.234,knn_ttm_r_n=100:208.8405'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:273.352,knn_ttm_n=5:318.0661,knn_tta_r_n=5:217.0391,knn_ttm_r_n=5:236.4586,knn_tta_n=10:240.3072,knn_ttm_n=10:282.8388,knn_tta_r_n=10:207.9514,knn_ttm_r_n=10:214.0618,knn_tta_n=20:221.8206,knn_ttm_n=20:258.7997,knn_tta_r_n=20:206.3689,knn_ttm_r_n=20:207.6559,knn_tta_n=50:210.3579,knn_ttm_n=50:235.3866,knn_tta_r_n=50:206.2552,knn_ttm_r_n=50:206.4773,knn_tta_n=100:208.0771,knn_ttm_n=100:225.5852,knn_tta_r_n=100:208.687,knn_ttm_r_n=100:208.0415'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:67.5003,knn_ttm_n=5:42.9543,knn_tta_r_n=5:66.8518,knn_ttm_r_n=5:90.3375,knn_tta_n=10:89.4965,knn_ttm_n=10:66.479,knn_tta_r_n=10:93.983,knn_ttm_r_n=10:94.1889,knn_tta_n=20:104.808,knn_ttm_n=20:86.3631,knn_tta_r_n=20:108.9767,knn_ttm_r_n=20:104.4335,knn_tta_n=50:114.9499,knn_ttm_n=50:109.2749,knn_tta_r_n=50:118.2951,knn_ttm_r_n=50:114.7415,knn_tta_n=100:119.2263,knn_ttm_n=100:119.9132,knn_tta_r_n=100:122.0094,knn_ttm_r_n=100:119.2975'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:192.7956,knn_ttm_n=5:228.803,knn_tta_r_n=5:153.524,knn_ttm_r_n=5:160.4386,knn_tta_n=10:164.213,knn_ttm_n=10:194.2889,knn_tta_r_n=10:149.0433,knn_ttm_r_n=10:152.2159,knn_tta_n=20:151.0822,knn_ttm_n=20:170.6823,knn_tta_r_n=20:146.8597,knn_ttm_r_n=20:149.3938,knn_tta_n=50:146.504,knn_ttm_n=50:155.3481,knn_tta_r_n=50:146.6161,knn_ttm_r_n=50:146.9677,knn_tta_n=100:143.4512,knn_ttm_n=100:149.2847,knn_tta_r_n=100:146.5703,knn_ttm_r_n=100:146.0512'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_94'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:130.5514,knn_ttm_n=5:80.6473,knn_tta_r_n=5:138.7909,knn_ttm_r_n=5:190.6727,knn_tta_n=10:179.0507,knn_ttm_n=10:127.1782,knn_tta_r_n=10:196.6824,knn_ttm_r_n=10:199.7012,knn_tta_n=20:214.0815,knn_ttm_n=20:168.6351,knn_tta_r_n=20:231.5183,knn_ttm_r_n=20:221.4969,knn_tta_n=50:244.4965,knn_ttm_n=50:220.4961,knn_tta_r_n=50:257.8037,knn_ttm_r_n=50:248.7401,knn_tta_n=100:259.7193,knn_ttm_n=100:250.9533,knn_tta_r_n=100:269.5135,knn_ttm_r_n=100:263.271'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:359.3327,knn_ttm_n=5:423.0913,knn_tta_r_n=5:299.8386,knn_ttm_r_n=5:328.6962,knn_tta_n=10:314.0776,knn_ttm_n=10:369.6366,knn_tta_r_n=10:290.2219,knn_ttm_r_n=10:303.0425,knn_tta_n=20:296.0374,knn_ttm_n=20:328.3906,knn_tta_r_n=20:288.6513,knn_ttm_r_n=20:295.4231,knn_tta_n=50:288.0749,knn_ttm_n=50:303.5975,knn_tta_r_n=50:295.9211,knn_ttm_r_n=50:296.4365,knn_tta_n=100:290.7,knn_ttm_n=100:299.5859,knn_tta_r_n=100:297.4426,knn_ttm_r_n=100:297.9607'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:192.0906,knn_ttm_n=5:132.2509,knn_tta_r_n=5:196.9348,knn_ttm_r_n=5:269.24,knn_tta_n=10:264.021,knn_ttm_n=10:216.1323,knn_tta_r_n=10:279.0192,knn_ttm_r_n=10:282.7702,knn_tta_n=20:317.2736,knn_ttm_n=20:290.7765,knn_tta_r_n=20:331.1311,knn_ttm_r_n=20:315.1862,knn_tta_n=50:363.9682,knn_ttm_n=50:372.3075,knn_tta_r_n=50:372.4512,knn_ttm_r_n=50:359.2422,knn_tta_n=100:385.2332,knn_ttm_n=100:417.2564,knn_tta_r_n=100:391.1925,knn_ttm_r_n=100:383.1294'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:510.9079,knn_ttm_n=5:592.5203,knn_tta_r_n=5:418.6557,knn_ttm_r_n=5:449.5293,knn_tta_n=10:452.0629,knn_ttm_n=10:541.9971,knn_tta_r_n=10:404.2584,knn_ttm_r_n=10:421.1093,knn_tta_n=20:428.9913,knn_ttm_n=20:495.5732,knn_tta_r_n=20:403.244,knn_ttm_r_n=20:412.0794,knn_tta_n=50:422.3475,knn_ttm_n=50:475.7129,knn_tta_r_n=50:412.6302,knn_ttm_r_n=50:413.3909,knn_tta_n=100:426.8701,knn_ttm_n=100:482.0201,knn_tta_r_n=100:421.1058,knn_ttm_r_n=100:420.2429'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:208.5375,knn_ttm_n=5:146.5349,knn_tta_r_n=5:209.241,knn_ttm_r_n=5:298.77,knn_tta_n=10:284.2188,knn_ttm_n=10:237.3416,knn_tta_r_n=10:293.0686,knn_ttm_r_n=10:303.4147,knn_tta_n=20:344.277,knn_ttm_n=20:319.274,knn_tta_r_n=20:345.2727,knn_ttm_r_n=20:332.6122,knn_tta_n=50:395.8736,knn_ttm_n=50:416.9192,knn_tta_r_n=50:383.7992,knn_ttm_r_n=50:373.402,knn_tta_n=100:413.6217,knn_ttm_n=100:468.22,knn_tta_r_n=100:401.2456,knn_ttm_r_n=100:395.2193'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:533.2366,knn_ttm_n=5:595.8703,knn_tta_r_n=5:447.5596,knn_ttm_r_n=5:482.8893,knn_tta_n=10:483.7744,knn_ttm_n=10:554.2915,knn_tta_r_n=10:419.3406,knn_ttm_r_n=10:445.402,knn_tta_n=20:443.6729,knn_ttm_n=20:523.3581,knn_tta_r_n=20:409.4657,knn_ttm_r_n=20:422.2712,knn_tta_n=50:431.2674,knn_ttm_n=50:505.7244,knn_tta_r_n=50:406.6221,knn_ttm_r_n=50:412.3016,knn_tta_n=100:432.8887,knn_ttm_n=100:509.2075,knn_tta_r_n=100:413.6524,knn_ttm_r_n=100:416.3942'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:110.6674,knn_ttm_n=5:64.9099,knn_tta_r_n=5:110.9299,knn_ttm_r_n=5:153.3272,knn_tta_n=10:146.3575,knn_ttm_n=10:101.3227,knn_tta_r_n=10:155.7262,knn_ttm_r_n=10:154.6865,knn_tta_n=20:171.7659,knn_ttm_n=20:131.1863,knn_tta_r_n=20:181.7119,knn_ttm_r_n=20:171.7598,knn_tta_n=50:192.9219,knn_ttm_n=50:167.9667,knn_tta_r_n=50:199.5753,knn_ttm_r_n=50:191.6063,knn_tta_n=100:202.5741,knn_ttm_n=100:189.768,knn_tta_r_n=100:206.0959,knn_ttm_r_n=100:201.0693'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:281.6335,knn_ttm_n=5:342.7442,knn_tta_r_n=5:216.3462,knn_ttm_r_n=5:238.1699,knn_tta_n=10:239.5251,knn_ttm_n=10:290.2308,knn_tta_r_n=10:210.1177,knn_ttm_r_n=10:217.3728,knn_tta_n=20:217.9291,knn_ttm_n=20:244.313,knn_tta_r_n=20:207.9092,knn_ttm_r_n=20:210.3834,knn_tta_n=50:207.3418,knn_ttm_n=50:217.2901,knn_tta_r_n=50:207.0694,knn_ttm_r_n=50:207.9183,knn_tta_n=100:208.8777,knn_ttm_n=100:211.9474,knn_tta_r_n=100:208.3028,knn_ttm_r_n=100:207.5859'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:117.6072,knn_ttm_n=5:70.0994,knn_tta_r_n=5:122.3137,knn_ttm_r_n=5:168.639,knn_tta_n=10:160.7954,knn_ttm_n=10:114.1326,knn_tta_r_n=10:173.5243,knn_ttm_r_n=10:174.475,knn_tta_n=20:190.0798,knn_ttm_n=20:151.3057,knn_tta_r_n=20:203.6798,knn_ttm_r_n=20:193.6891,knn_tta_n=50:215.5323,knn_ttm_n=50:194.6508,knn_tta_r_n=50:226.1123,knn_ttm_r_n=50:216.7652,knn_tta_n=100:226.4278,knn_ttm_n=100:218.6017,knn_tta_r_n=100:234.9236,knn_ttm_r_n=100:229.0979'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:306.7926,knn_ttm_n=5:372.2661,knn_tta_r_n=5:237.9963,knn_ttm_r_n=5:256.9074,knn_tta_n=10:271.402,knn_ttm_n=10:318.3201,knn_tta_r_n=10:228.6261,knn_ttm_r_n=10:236.9015,knn_tta_n=20:251.1384,knn_ttm_n=20:288.7636,knn_tta_r_n=20:228.76,knn_ttm_r_n=20:229.5536,knn_tta_n=50:237.1419,knn_ttm_n=50:263.0052,knn_tta_r_n=50:229.0238,knn_ttm_r_n=50:228.0866,knn_tta_n=100:231.4288,knn_ttm_n=100:249.9558,knn_tta_r_n=100:230.1242,knn_ttm_r_n=100:229.4112'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:63.5384,knn_ttm_n=5:37.0767,knn_tta_r_n=5:62.2713,knn_ttm_r_n=5:83.4339,knn_tta_n=10:84.1022,knn_ttm_n=10:55.7269,knn_tta_r_n=10:87.3952,knn_ttm_r_n=10:86.107,knn_tta_n=20:97.5044,knn_ttm_n=20:73.0302,knn_tta_r_n=20:102.0833,knn_ttm_r_n=20:95.9769,knn_tta_n=50:109.5411,knn_ttm_n=50:94.1945,knn_tta_r_n=50:112.0376,knn_ttm_r_n=50:107.3183,knn_tta_n=100:115.0231,knn_ttm_n=100:107.0742,knn_tta_r_n=100:116.5656,knn_ttm_r_n=100:113.2182'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:204.0919,knn_ttm_n=5:234.1477,knn_tta_r_n=5:150.9237,knn_ttm_r_n=5:158.6938,knn_tta_n=10:174.1333,knn_ttm_n=10:206.4144,knn_tta_r_n=10:146.9205,knn_ttm_r_n=10:147.8031,knn_tta_n=20:157.8764,knn_ttm_n=20:179.8363,knn_tta_r_n=20:145.0265,knn_ttm_r_n=20:145.1192,knn_tta_n=50:148.9036,knn_ttm_n=50:158.2647,knn_tta_r_n=50:142.4116,knn_ttm_r_n=50:142.8461,knn_tta_n=100:142.8266,knn_ttm_n=100:148.3488,knn_tta_r_n=100:141.6215,knn_ttm_r_n=100:142.1397'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random_99'\n",
      "Running Cross Evaluation with 5 folds'\n",
      "-----------------------------------Fold 0 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:142.5047,knn_ttm_n=5:98.6229,knn_tta_r_n=5:143.1912,knn_ttm_r_n=5:195.95,knn_tta_n=10:190.271,knn_ttm_n=10:149.4379,knn_tta_r_n=10:200.2672,knn_ttm_r_n=10:206.2573,knn_tta_n=20:224.8848,knn_ttm_n=20:192.2244,knn_tta_r_n=20:235.2142,knn_ttm_r_n=20:229.8045,knn_tta_n=50:250.9505,knn_ttm_n=50:238.3435,knn_tta_r_n=50:259.1891,knn_ttm_r_n=50:254.0498,knn_tta_n=100:264.7121,knn_ttm_n=100:258.4349,knn_tta_r_n=100:269.476,knn_ttm_r_n=100:265.7484'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:385.5264,knn_ttm_n=5:462.373,knn_tta_r_n=5:306.4843,knn_ttm_r_n=5:333.4933,knn_tta_n=10:337.4142,knn_ttm_n=10:399.4674,knn_tta_r_n=10:297.5157,knn_ttm_r_n=10:305.5288,knn_tta_n=20:317.2372,knn_ttm_n=20:355.7344,knn_tta_r_n=20:294.3353,knn_ttm_r_n=20:299.1236,knn_tta_n=50:300.658,knn_ttm_n=50:322.7759,knn_tta_r_n=50:294.2268,knn_ttm_r_n=50:295.6829,knn_tta_n=100:297.0569,knn_ttm_n=100:310.4216,knn_tta_r_n=100:295.3929,knn_ttm_r_n=100:296.0719'\n",
      "-----------------------------------Fold 1 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:206.7097,knn_ttm_n=5:169.7446,knn_tta_r_n=5:205.9565,knn_ttm_r_n=5:283.054,knn_tta_n=10:284.6706,knn_ttm_n=10:268.5063,knn_tta_r_n=10:286.9937,knn_ttm_r_n=10:298.6684,knn_tta_n=20:333.2568,knn_ttm_n=20:345.7303,knn_tta_r_n=20:335.8421,knn_ttm_r_n=20:328.4534,knn_tta_n=50:373.7032,knn_ttm_n=50:421.1196,knn_tta_r_n=50:371.4938,knn_ttm_r_n=50:365.7135,knn_tta_n=100:396.1671,knn_ttm_n=100:463.4555,knn_tta_r_n=100:389.6173,knn_ttm_r_n=100:386.3237'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:537.4454,knn_ttm_n=5:636.7524,knn_tta_r_n=5:442.9635,knn_ttm_r_n=5:471.0564,knn_tta_n=10:484.7884,knn_ttm_n=10:581.942,knn_tta_r_n=10:421.2544,knn_ttm_r_n=10:441.1623,knn_tta_n=20:446.9975,knn_ttm_n=20:544.8491,knn_tta_r_n=20:417.7581,knn_ttm_r_n=20:429.0216,knn_tta_n=50:432.4534,knn_ttm_n=50:521.1111,knn_tta_r_n=50:419.4588,knn_ttm_r_n=50:425.7055,knn_tta_n=100:437.8933,knn_ttm_n=100:528.0904,knn_tta_r_n=100:427.072,knn_ttm_r_n=100:430.4201'\n",
      "-----------------------------------Fold 2 - Train 4999 - Val 1667 - Test 1667-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:225.7177,knn_ttm_n=5:198.8985,knn_tta_r_n=5:215.8559,knn_ttm_r_n=5:295.9531,knn_tta_n=10:311.13,knn_ttm_n=10:308.9243,knn_tta_r_n=10:301.1639,knn_ttm_r_n=10:316.0923,knn_tta_n=20:365.3901,knn_ttm_n=20:388.1861,knn_tta_r_n=20:356.1223,knn_ttm_r_n=20:352.6772,knn_tta_n=50:405.1425,knn_ttm_n=50:464.9667,knn_tta_r_n=50:392.7073,knn_ttm_r_n=50:390.5867,knn_tta_n=100:423.2153,knn_ttm_n=100:505.1027,knn_tta_r_n=100:409.5051,knn_ttm_r_n=100:409.5614'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:527.8757,knn_ttm_n=5:626.3521,knn_tta_r_n=5:452.5014,knn_ttm_r_n=5:488.4872,knn_tta_n=10:468.7093,knn_ttm_n=10:571.7144,knn_tta_r_n=10:422.1185,knn_ttm_r_n=10:453.1682,knn_tta_n=20:445.1959,knn_ttm_n=20:536.0944,knn_tta_r_n=20:414.9674,knn_ttm_r_n=20:431.869,knn_tta_n=50:434.704,knn_ttm_n=50:521.0855,knn_tta_r_n=50:417.5689,knn_ttm_r_n=50:425.6963,knn_tta_n=100:436.904,knn_ttm_n=100:529.4172,knn_tta_r_n=100:425.2147,knn_ttm_r_n=100:430.5058'\n",
      "-----------------------------------Fold 3 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:115.9031,knn_ttm_n=5:77.0476,knn_tta_r_n=5:115.0563,knn_ttm_r_n=5:159.7315,knn_tta_n=10:154.8948,knn_ttm_n=10:122.9496,knn_tta_r_n=10:158.5857,knn_ttm_r_n=10:163.0053,knn_tta_n=20:178.9136,knn_ttm_n=20:159.7609,knn_tta_r_n=20:181.8124,knn_ttm_r_n=20:177.4855,knn_tta_n=50:192.9452,knn_ttm_n=50:187.5044,knn_tta_r_n=50:196.3697,knn_ttm_r_n=50:192.6172,knn_tta_n=100:200.0337,knn_ttm_n=100:198.115,knn_tta_r_n=100:202.8019,knn_ttm_r_n=100:199.6883'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:304.4014,knn_ttm_n=5:370.9512,knn_tta_r_n=5:220.865,knn_ttm_r_n=5:236.6518,knn_tta_n=10:260.6958,knn_ttm_n=10:323.3996,knn_tta_r_n=10:214.7303,knn_ttm_r_n=10:216.3965,knn_tta_n=20:230.2686,knn_ttm_n=20:279.0853,knn_tta_r_n=20:209.607,knn_ttm_r_n=20:212.4583,knn_tta_n=50:210.5882,knn_ttm_n=50:234.1484,knn_tta_r_n=50:205.4714,knn_ttm_r_n=50:206.7516,knn_tta_n=100:203.5819,knn_ttm_n=100:214.9399,knn_tta_r_n=100:205.0494,knn_ttm_r_n=100:205.8463'\n",
      "-----------------------------------Fold 4 - Train 5001 - Val 1666 - Test 1666-----------------------------------'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:114.312,knn_ttm_n=5:84.0072,knn_tta_r_n=5:115.9921,knn_ttm_r_n=5:155.1017,knn_tta_n=10:155.3978,knn_ttm_n=10:127.9488,knn_tta_r_n=10:161.9143,knn_ttm_r_n=10:165.9845,knn_tta_n=20:182.8732,knn_ttm_n=20:164.9373,knn_tta_r_n=20:190.8717,knn_ttm_r_n=20:185.3671,knn_tta_n=50:203.2063,knn_ttm_n=50:197.9346,knn_tta_r_n=50:209.9725,knn_ttm_r_n=50:204.6966,knn_tta_n=100:214.7134,knn_ttm_n=100:215.0095,knn_tta_r_n=100:218.3778,knn_ttm_r_n=100:214.5299'\n",
      "Tested (test) on 1666 instances with mean losses of: knn_tta_n=5:308.7527,knn_ttm_n=5:355.9202,knn_tta_r_n=5:222.8879,knn_ttm_r_n=5:232.7129,knn_tta_n=10:264.4385,knn_ttm_n=10:330.4366,knn_tta_r_n=10:215.9462,knn_ttm_r_n=10:219.125,knn_tta_n=20:235.7287,knn_ttm_n=20:288.5783,knn_tta_r_n=20:210.2557,knn_ttm_r_n=20:213.1704,knn_tta_n=50:220.2035,knn_ttm_n=50:249.6472,knn_tta_r_n=50:210.4506,knn_ttm_r_n=50:210.9382,knn_tta_n=100:216.5679,knn_ttm_n=100:235.9113,knn_tta_r_n=100:212.5571,knn_ttm_r_n=100:211.7301'\n",
      "Building final model - Train 6666 - Test 1667'\n",
      "Finished training Boosted Models with a train loss of knn_tta_n=5:69.633,knn_ttm_n=5:50.3962,knn_tta_r_n=5:67.071,knn_ttm_r_n=5:92.2573,knn_tta_n=10:91.9612,knn_ttm_n=10:77.593,knn_tta_r_n=10:93.4402,knn_ttm_r_n=10:94.8317,knn_tta_n=20:106.8635,knn_ttm_n=20:99.6085,knn_tta_r_n=20:107.5515,knn_ttm_r_n=20:104.372,knn_tta_n=50:116.9142,knn_ttm_n=50:122.1822,knn_tta_r_n=50:116.4538,knn_ttm_r_n=50:114.2894,knn_tta_n=100:120.0257,knn_ttm_n=100:130.4248,knn_tta_r_n=100:119.9407,knn_ttm_r_n=100:118.2394'\n",
      "Tested (test) on 1667 instances with mean losses of: knn_tta_n=5:189.3952,knn_ttm_n=5:226.7512,knn_tta_r_n=5:151.3211,knn_ttm_r_n=5:164.3809,knn_tta_n=10:165.8634,knn_ttm_n=10:198.2631,knn_tta_r_n=10:143.9005,knn_ttm_r_n=10:150.614,knn_tta_n=20:150.0945,knn_ttm_n=20:178.0279,knn_tta_r_n=20:140.765,knn_ttm_r_n=20:142.9228,knn_tta_n=50:141.9163,knn_ttm_n=50:161.0334,knn_tta_r_n=50:139.601,knn_ttm_r_n=50:140.6638,knn_tta_n=100:139.1444,knn_ttm_n=100:153.1958,knn_tta_r_n=100:139.1087,knn_ttm_r_n=100:139.8336'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huonf\\.conda\\envs\\lazydeep\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "def build_predictors(n,deep):\n",
    "    predictors = {}\n",
    "    for i in [5,10,20,50,100]:\n",
    "        if i* 2 < n:\n",
    "            #predictors[f'knn_uu_n={i}'] = KNNBoost(deep,n_neighbors=i, weights='uniform',errors='uniform',convolution='additive',reverse=True)\n",
    "            #predictors[f'knn_ut_n={i}'] = KNNBoost(deep,n_neighbors=i, weights='uniform',errors='triangle',convolution='additive',reverse=True)\n",
    "           # predictors[f'knn_tu_n={i}'] = KNNBoost(deep,n_neighbors=i, weights='triangle',errors='uniform',convolution='additive',reverse=True)\n",
    "            predictors[f'knn_tta_n={i}'] = KNNBoost(deep,n_neighbors=i, weights='triangle',errors='triangle',convolution='additive',reverse=True)\n",
    "            predictors[f'knn_ttm_n={i}'] = KNNBoost(deep,n_neighbors=i, weights='triangle',errors='triangle',convolution='multiplicative',reverse=True)\n",
    "            predictors[f'knn_tta_r_n={i}'] = KNNBoost(deep,n_neighbors=i, weights='triangle',errors='triangle',convolution='additive',reverse=False)\n",
    "            predictors[f'knn_ttm_r_n={i}'] = KNNBoost(deep,n_neighbors=i, weights='triangle',errors='triangle',convolution='multiplicative',reverse=False)\n",
    "    return predictors\n",
    "deep_models = {k:v for k,v in deep_models.items() if k in best_n}\n",
    "for deep_name,deep_model in tqdm(deep_models.items()):\n",
    "        logging.getLogger().info(f\"Running model {deep_name}\")\n",
    "        temp_dict = {deep_name:deep_model}\n",
    "\n",
    "        lwr_scheme = BoostScheme(boost_models = build_predictors(nrow,deep_model),loss_fun_sk = mean_squared_error)\n",
    "        lwr_scores, lwr_preds, _ , _, _,_= eval_.evaluate(temp_dict,dataset,lwr_scheme,logger_name=\"log\")\n",
    "        lwr_scores_final, lwr_preds_final, _ , _, _,_= eval_.build(temp_dict,dataset,lwr_scheme,logger_name=\"test_log\")\n",
    "\n",
    "        #scores\n",
    "        for k,v in ut.flip_dicts(lwr_scores).items(): \n",
    "            dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "            all_scores.append({**dict1,**v})\n",
    "\n",
    "        for k,v in ut.flip_dicts(lwr_scores_final).items():\n",
    "            dict1 = {'model_num':deep_name,\"predictor\":k}\n",
    "            all_scores_final.append({**dict1,**v})\n",
    "\n",
    "        lwr_preds['deep'] = deep_preds[deep_name]\n",
    "        lwr_preds_final['deep'] = deep_preds_final[deep_name]\n",
    "\n",
    "        lwr_preds.to_csv(log_dir/deep_name/ f\"predictions.csv\",index=False)\n",
    "        lwr_preds_final.to_csv(log_dir/deep_name/ f\"predictions_test.csv\",index=False)\n",
    "\n",
    "        #preds\n",
    "        # todo save predictions - appending solns\n",
    "        plot_preds_and_res(lwr_preds,name_lambda=lambda x:f\"{deep_name} with {x} predictor\",save_lambda= lambda x:f\"deep_lwr{x}\",save_loc=log_dir/deep_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save scores\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank - model_num - predictor - fold_0 - fold_1 - fold_2 - fold_3 - fold_4 - MSE - R2'\n",
      "0 - random_82 - deep - 137.5075182648712 - 130.4421176006498 - 144.06449480977827 - 127.65992345271849 - 131.84387805109836 - 134.30467871071176 - 0.7199893993454223'\n",
      "1 - random_24 - deep - 144.41353603516356 - 132.81591498472767 - 145.4006378800839 - 121.6521948073663 - 130.38346345313028 - 134.9352893915091 - 0.7186746448841157'\n",
      "2 - random_10 - deep - 146.22829733827405 - 131.2531475577443 - 142.54620770487017 - 119.59081962557973 - 137.4023663176208 - 135.40582546692042 - 0.7176936285087342'\n",
      "3 - random_4 - deep - 149.52052070283574 - 139.50407097535572 - 143.93053564656333 - 124.70355024944548 - 135.62736985663406 - 138.6592477281742 - 0.7109105980863994'\n",
      "4 - random_73 - deep - 143.369752692833 - 138.57852169190184 - 150.11264153991405 - 130.9745516782763 - 134.5115186226468 - 139.51102111677213 - 0.7091347435111719'\n",
      "5 - random_94 - deep - 147.74845175007968 - 133.9410871426789 - 150.27850711595963 - 128.0872647581982 - 142.83391092032517 - 140.57907244776365 - 0.7069079730249028'\n",
      "6 - random_54 - deep - 143.3369931162083 - 153.02575410821157 - 146.23201375502487 - 126.75642759545224 - 144.33043288726623 - 142.73805122060224 - 0.7024067378573241'\n",
      "7 - random_71 - deep - 147.42106379444326 - 145.40249613651488 - 150.00145401522724 - 132.49321839331435 - 149.42633086865118 - 144.94986936347323 - 0.6977953383687179'\n",
      "8 - random_83 - deep - 145.02487304357976 - 147.3902957506643 - 156.12350985041334 - 130.14863648706552 - 147.72448534467497 - 145.28388368452516 - 0.6970989549548054'\n",
      "9 - random_14 - deep - 137.70490223702086 - 143.56642867593473 - 148.22834771195787 - 157.75380246092578 - 142.81907055730008 - 146.01348448413944 - 0.6955778168969267'\n",
      "10 - random_29 - deep - 154.446354651494 - 146.6859692697691 - 152.77725805089227 - 133.71976552461805 - 142.77998224741557 - 146.08374610812191 - 0.6954313290774168'\n",
      "11 - random_77 - deep - 148.77480655754835 - 136.91305230775134 - 150.08172788660042 - 139.1033063982429 - 157.03478088928443 - 146.38112929019692 - 0.6948113175913184'\n",
      "12 - random_0 - deep - 147.1445725308826 - 148.0008328900626 - 159.25217494953156 - 133.35702390544841 - 148.6052618496129 - 147.27348410121905 - 0.6929508551783186'\n",
      "13 - random_78 - deep - 158.89134197086364 - 146.8002499292622 - 152.97004405652683 - 132.92693485475246 - 145.22940014018303 - 147.3655830805905 - 0.6927588388555735'\n",
      "14 - random_74 - deep - 153.45526117669226 - 145.8329661643355 - 151.3222925590053 - 135.88923227372004 - 151.27763947375826 - 147.55643185984212 - 0.6923609399750175'\n",
      "15 - random_99 - deep - 158.52725067779411 - 145.02305100503338 - 154.38577592136906 - 135.91042533956943 - 144.576222038498 - 147.68633145297855 - 0.6920901134971309'\n",
      "16 - random_39 - deep - 164.36570207473397 - 142.62089369235528 - 152.7702025360309 - 132.3304426506931 - 147.9701933385659 - 148.01337385772723 - 0.6914082657679803'\n",
      "17 - random_81 - deep - 176.8159001927642 - 140.4785398633164 - 148.84839134010357 - 127.860574765795 - 146.1472452262155 - 148.03277671218763 - 0.6913678129335442'\n",
      "18 - random_32 - deep - 152.97942731705123 - 139.38026185656423 - 163.863112735119 - 136.49283807761387 - 148.11364142061853 - 148.16726493576093 - 0.6910874196618784'\n",
      "19 - random_75 - deep - 152.5712334255866 - 149.3129566561053 - 156.1371806041166 - 139.14811772487315 - 145.9744149170288 - 148.63023752479896 - 0.6901221723303064'\n",
      "20 - random_8 - deep - 151.23871260141283 - 152.04883586881257 - 153.77720893809519 - 135.3754873653563 - 151.5434860559214 - 148.7980271650407 - 0.6897723492385219'\n",
      "21 - random_25 - deep - 155.35112474689817 - 148.6119859463166 - 160.54683642167134 - 131.57825921506299 - 151.01910835440134 - 149.4234122263752 - 0.6884684896236095'\n",
      "22 - random_18 - deep - 159.2038448130076 - 150.7018404241515 - 154.32362722706924 - 133.1140560411176 - 149.97153083645568 - 149.46488185862907 - 0.6883820299652581'\n",
      "23 - random_40 - deep - 153.92921740664073 - 145.49475220312382 - 154.59019869304947 - 136.81229081903757 - 157.85874189763797 - 149.73761682867652 - 0.6878134073117839'\n",
      "24 - random_57 - deep - 149.14027304097286 - 156.1511642007536 - 154.7122040538639 - 128.37676139181258 - 162.0063626585888 - 150.07852621532834 - 0.6871026484384406'\n",
      "25 - random_91 - deep - 153.620345600222 - 150.31857823381614 - 162.8963279952957 - 127.11086940879868 - 156.4462514879609 - 150.08046612553136 - 0.6870986039373377'\n",
      "26 - random_37 - deep - 166.647212444413 - 139.12350676227058 - 159.6392497581569 - 131.68301010589784 - 157.36661104566338 - 150.8934462727633 - 0.6854036290374907'\n",
      "27 - random_34 - deep - 154.56817166077283 - 154.3920279847839 - 156.47700864566465 - 133.88745565975412 - 155.35841047234322 - 150.93813077537928 - 0.6853104667252201'\n",
      "28 - random_47 - deep - 154.46845284721132 - 150.39001206716665 - 161.25703940937888 - 138.767085484096 - 154.42642385933866 - 151.86306536051902 - 0.6833820790380791'\n",
      "29 - random_80 - deep - 159.3029143866051 - 146.6703013218157 - 161.24257640918717 - 137.27580574466114 - 155.53014179609832 - 152.0056930065216 - 0.6830847159587694'\n",
      "30 - random_60 - deep - 162.27312153917484 - 149.2188880888373 - 156.38646359091828 - 137.35813310309476 - 155.0632761466403 - 152.06138062313747 - 0.6829686133543975'\n",
      "31 - random_5 - deep - 134.66904243510427 - 142.32630676013235 - 147.27630952081068 - 123.81846252294864 - 212.8487847226293 - 152.18390586583163 - 0.6827131615925416'\n",
      "32 - random_20 - deep - 152.0456795123214 - 155.5693030491802 - 162.43784279643094 - 133.34324928091354 - 159.01298762913368 - 152.4833254194813 - 0.6820889044939058'\n",
      "33 - random_96 - deep - 156.74727865172204 - 152.73341804417436 - 161.63271283502698 - 140.3110226085063 - 153.38456757214604 - 152.9632668004845 - 0.6810882790826112'\n",
      "34 - random_12 - deep - 166.49045075780987 - 149.89121054573266 - 158.2286906720066 - 134.67502651695443 - 157.2720019282127 - 153.31323775183708 - 0.6803586278356061'\n",
      "35 - random_84 - deep - 160.86198042907898 - 145.30979812338313 - 160.11448720120782 - 145.51721045779152 - 155.1951267384395 - 153.40045155720236 - 0.6801767965676254'\n",
      "36 - random_66 - deep - 156.15075935313425 - 149.8862396771134 - 169.2090683418187 - 141.4422553200968 - 151.481117706482 - 153.63560923805974 - 0.6796865184619219'\n",
      "37 - random_86 - deep - 157.52297369505592 - 157.09822286641304 - 157.42790203288993 - 138.77506606890802 - 157.9949466389339 - 153.76511409923057 - 0.679416514957113'\n",
      "38 - random_33 - deep - 160.70834340974824 - 158.32827788080078 - 161.40144821148687 - 135.51153196263857 - 154.7793091754524 - 154.14794262294382 - 0.6786183592569415'\n",
      "39 - random_15 - deep - 156.9714350754727 - 148.15011470362177 - 172.83399741636757 - 136.3397816157713 - 157.8032911879962 - 154.42148773746416 - 0.678048047540639'\n",
      "40 - random_87 - deep - 152.88574119892817 - 163.5835175677267 - 170.45526103767438 - 139.37112779376886 - 148.0233774173732 - 154.8664841480599 - 0.6771202785796749'\n",
      "41 - random_69 - deep - 184.2796111630335 - 137.754818061046 - 157.21845980726036 - 136.21446411206085 - 160.2989878568615 - 155.1549236684153 - 0.6765189136523875'\n",
      "42 - random_46 - deep - 152.12944892100683 - 159.36474299988635 - 162.35117764292752 - 144.2390072606191 - 157.81001028035726 - 155.1798754199314 - 0.6764668919730501'\n",
      "43 - random_64 - deep - 162.2600555236853 - 158.24614114652655 - 164.60620457352317 - 132.91768263396668 - 161.85900162677376 - 155.97987831429353 - 0.6747989732294428'\n",
      "44 - random_61 - deep - 143.13800560963247 - 231.3233687979201 - 146.7110830511815 - 119.73905226763557 - 141.83969843888482 - 156.55642390768728 - 0.6735969385761402'\n",
      "45 - random_88 - deep - 162.0142171089708 - 155.0941768250354 - 169.8041499514886 - 142.91770699673913 - 157.7003786286243 - 157.50785300003724 - 0.6716133127323751'\n",
      "46 - random_65 - deep - 148.32248614058926 - 137.43423286167962 - 164.65849010373705 - 176.9313974735402 - 165.58588623742955 - 158.5834580233449 - 0.6693707936218369'\n",
      "47 - random_44 - deep - 148.39711365359375 - 163.68551773043828 - 172.85278245711942 - 138.85642161832996 - 170.60551890433908 - 158.8804664285704 - 0.6687515635045765'\n",
      "48 - random_56 - deep - 145.7448183184408 - 149.75511053184871 - 151.73036057003688 - 132.3274281880721 - 218.6768508856179 - 159.64310852601199 - 0.6671615379459803'\n",
      "49 - random_17 - deep - 144.94666282045105 - 183.60079701588978 - 151.14859541977103 - 133.23641724145713 - 188.5515621501286 - 160.29666370621445 - 0.6657989467069694'\n",
      "50 - random_7 - deep - 151.64223659632088 - 155.10397609809093 - 165.97125007066458 - 176.81070711976196 - 153.88882547953264 - 160.6822792508325 - 0.664994980372313'\n",
      "51 - random_45 - deep - 161.86059964139375 - 164.5138501291441 - 174.24633187338057 - 142.50278724771158 - 166.75869967127477 - 161.97821719709586 - 0.6622930911587146'\n",
      "52 - random_16 - deep - 169.35776610852145 - 185.41757143566403 - 166.89483514429926 - 145.3030489203738 - 160.2569451257676 - 165.44907279212296 - 0.6550567359603807'\n",
      "53 - random_22 - deep - 175.57371266072713 - 154.86078630526336 - 167.8061403939305 - 169.48919913119056 - 162.1374607246463 - 165.97349783560256 - 0.6539633669665921'\n",
      "54 - random_1 - deep - 161.12350827258865 - 144.26118596471136 - 165.96799771973096 - 192.24671431377726 - 168.71851978095927 - 166.4602206410644 - 0.6529486030252463'\n",
      "55 - random_98 - deep - 186.28815338921962 - 159.65621146400602 - 157.9569506539366 - 164.99110850394845 - 163.72338969309646 - 166.52368093492535 - 0.6528162952369228'\n",
      "56 - random_19 - deep - 166.27871105924078 - 156.45464102980185 - 188.3210877165082 - 161.82390342611654 - 162.3632909035196 - 167.04951569928306 - 0.651719987128923'\n",
      "57 - random_79 - deep - 145.949127256763 - 143.59269041577426 - 157.20897991269666 - 260.42908010677417 - 138.51477217473902 - 169.13165067791914 - 0.6473789628875591'\n",
      "58 - random_21 - deep - 182.35615583029633 - 153.01192431801726 - 164.3069572242778 - 138.46614069211668 - 215.37528136254502 - 170.70180058761753 - 0.6441053716504334'\n",
      "59 - random_59 - deep - 160.19059733738067 - 188.06666404756157 - 147.96422720155675 - 125.67558226293447 - 240.817212831788 - 172.5402877785584 - 0.6402723264611443'\n",
      "60 - random_67 - deep - 205.24045169603775 - 213.70926477241173 - 161.0261890615041 - 134.85159571030562 - 151.52847057402062 - 173.27841316296212 - 0.638733415574127'\n",
      "61 - random_62 - deep - 163.09446299826948 - 156.1511381866693 - 162.85520207588732 - 127.33779319222806 - 265.3790267083396 - 174.95838932791807 - 0.6352308485783194'\n",
      "62 - random_30 - deep - 173.3533757192043 - 185.50183336135507 - 186.08602185812836 - 164.8059586871858 - 170.15860179521027 - 175.98319842292648 - 0.6330942334357622'\n",
      "63 - random_93 - deep - 155.2179052699592 - 299.11956988485116 - 160.09105209368892 - 132.66151291754494 - 140.3846710223396 - 177.50477686591913 - 0.6299219084069139'\n",
      "64 - random_63 - deep - 191.53762106617984 - 200.61696854964944 - 153.1517904083673 - 210.61870356052577 - 143.03606591562405 - 179.79294112922187 - 0.6251513355876019'\n",
      "65 - random_55 - deep - 146.68073118240733 - 152.2477806562711 - 157.91743109279145 - 259.19905293660435 - 194.31572880922388 - 182.0614203569256 - 0.6204218039196103'\n",
      "66 - random_42 - deep - 251.2475656430451 - 153.05805732164114 - 152.6498317661297 - 174.24853471662104 - 214.23556274011068 - 189.08667258193154 - 0.6057749195805249'\n",
      "67 - random_9 - deep - 310.38463308314897 - 143.14187168059553 - 154.41544005880831 - 245.6378944644264 - 147.49568408906532 - 200.21598038757668 - 0.5825715271637883'\n",
      "68 - random_76 - deep - 152.16003187301993 - 144.8255891851415 - 174.76287267418343 - 407.24086128592063 - 154.56537553070544 - 206.69313749800142 - 0.5690673613340134'\n",
      "69 - random_36 - deep - 142.64040199925103 - 465.0107623983016 - 149.59706328082527 - 144.28972853789952 - 151.4863744921186 - 210.61991914337602 - 0.5608804500684044'\n",
      "70 - random_95 - deep - 466.0357204590576 - 127.00927894560247 - 145.0699664243482 - 143.12668319280837 - 182.96160533305118 - 212.85260281028292 - 0.5562255482388943'\n",
      "71 - random_28 - deep - 142.84624130166642 - 513.7774482640093 - 150.717256714215 - 136.66736076144326 - 133.51756206480394 - 215.52447263281496 - 0.5506549911960563'\n",
      "72 - random_90 - deep - 139.46011549566919 - 514.6729708501659 - 169.36498542195247 - 125.14263848239491 - 135.32623114019168 - 216.81416396538575 - 0.5479661254904169'\n",
      "73 - random_35 - deep - 465.99340326941933 - 142.59268921667328 - 176.4314055828971 - 146.57553641879116 - 158.82982911182052 - 218.10026291658392 - 0.545284749507962'\n",
      "74 - random_83 - knn_tta_n=50 - 219.15505531905816 - 256.4122340679322 - 259.4125677753915 - 188.07074836010196 - 186.11154798962158 - 221.84076894375735 - 0.5374862024799711'\n",
      "75 - random_83 - knn_tta_n=100 - 225.19212766108208 - 260.9920930639578 - 260.91370662531665 - 187.58158265330044 - 186.61515131093395 - 224.26785115534125 - 0.5324260008952137'\n",
      "76 - random_83 - knn_tta_n=20 - 222.03359284190464 - 256.15367831416347 - 265.65183974342665 - 201.92318856999208 - 196.36357532271072 - 228.43220286987886 - 0.5237437819556097'\n",
      "77 - random_83 - knn_tta_r_n=20 - 223.47878218678852 - 275.1060699638358 - 275.80294146079785 - 183.97753971287938 - 186.00014891975815 - 228.8836290906294 - 0.5228026075418463'\n",
      "78 - random_83 - knn_ttm_r_n=50 - 225.30988022591862 - 278.73427155614473 - 282.43613553108725 - 183.34303333343644 - 185.44013897146093 - 231.06389103695918 - 0.5182569992788266'\n",
      "79 - random_83 - knn_tta_r_n=10 - 223.9276319526152 - 279.3039552486543 - 280.97048226478836 - 184.61940898849582 - 192.72225647600504 - 232.3192205044734 - 0.5156397743119134'\n",
      "80 - random_83 - knn_tta_r_n=50 - 228.09404625011385 - 280.6890291082739 - 282.75350368753317 - 184.72481664377847 - 187.06593737803894 - 232.67669188406313 - 0.5148944854902692'\n",
      "81 - random_83 - knn_ttm_r_n=20 - 225.12506513167105 - 279.8881396843759 - 284.7737269694281 - 185.64799981013576 - 190.63628676954696 - 233.22506140983302 - 0.5137511948633222'\n",
      "82 - random_83 - knn_ttm_n=100 - 224.944918508541 - 276.8185682897969 - 277.38233491981345 - 193.2385775563116 - 195.10513404341322 - 233.50734529332766 - 0.5131626637670974'\n",
      "83 - random_83 - knn_ttm_r_n=100 - 229.89902047027687 - 286.745198664859 - 286.2981259238841 - 184.81568304504816 - 187.71489799076406 - 235.10630471847466 - 0.5098290078330402'\n",
      "84 - random_83 - knn_ttm_n=50 - 225.96602712830358 - 273.96710708362946 - 279.15779194927745 - 202.67537749887313 - 202.0764193409198 - 236.77679916546657 - 0.5063462091838423'\n",
      "85 - random_51 - deep - 325.73920026938214 - 385.0494466963541 - 170.60847450947432 - 145.6590373209831 - 157.09753128546342 - 236.85125326279024 - 0.5061909806228231'\n",
      "86 - random_29 - knn_tta_n=50 - 254.66881468746197 - 282.08484069759277 - 270.94731955636814 - 188.78442201061176 - 192.58202467987974 - 237.82479604148702 - 0.5041612500474979'\n",
      "87 - random_29 - knn_tta_n=100 - 253.5954025521664 - 288.6042178169416 - 277.90062976027593 - 183.8262131965451 - 190.72031962374993 - 238.94175454749725 - 0.5018325134372399'\n",
      "88 - random_83 - knn_tta_r_n=100 - 235.1984273430708 - 295.26308717126363 - 291.9460869065715 - 188.53546066113068 - 191.1925385458625 - 240.4392557599305 - 0.49871038680627366'\n",
      "89 - random_83 - knn_ttm_r_n=10 - 230.44357034272252 - 292.9231882675349 - 299.3877451729045 - 191.75842664874034 - 200.84324270265108 - 243.08245997191278 - 0.493199594432421'\n",
      "90 - random_34 - knn_tta_n=100 - 246.17313811547425 - 278.6577946799916 - 297.5066072498304 - 194.12850365038773 - 204.01406759426948 - 244.10682862703803 - 0.49106389755849533'\n",
      "91 - random_34 - knn_tta_n=50 - 248.32456591374302 - 275.82118408719134 - 295.62552518081947 - 196.06834754015543 - 205.77774549532933 - 244.33389016261864 - 0.4905904990321913'\n",
      "92 - random_83 - knn_tta_r_n=5 - 231.0063827992548 - 296.55509237370154 - 305.603335584292 - 194.526482872797 - 203.01500562371197 - 246.15262922927116 - 0.4867986265264268'\n",
      "93 - random_29 - knn_tta_n=20 - 266.8507485713287 - 286.24787175901827 - 274.58082122364766 - 199.9339470143411 - 204.2538264891122 - 246.38407053009269 - 0.4863160966674851'\n",
      "94 - random_83 - knn_tta_n=10 - 235.57493966086014 - 274.49105127322275 - 283.4125616931347 - 219.0422134840505 - 219.5617637997624 - 246.4230137266776 - 0.4862349043518174'\n",
      "95 - random_34 - knn_tta_r_n=50 - 241.6528906327464 - 296.02996863052886 - 307.6668646900257 - 189.80239536908903 - 199.51398910035715 - 246.94576819347776 - 0.4851450183278846'\n",
      "96 - random_34 - knn_tta_r_n=20 - 242.49275407104744 - 291.9685578483651 - 309.18611903693574 - 192.03295359171534 - 200.93794947428094 - 247.33586846420047 - 0.4843317018284665'\n",
      "97 - random_29 - knn_tta_r_n=20 - 253.52771115347068 - 312.3719713857418 - 303.2728963971209 - 184.1622420264234 - 191.8952618096498 - 249.06066128378325 - 0.48073569699707885'\n",
      "98 - random_34 - knn_ttm_r_n=50 - 244.5985275718333 - 298.7126772662416 - 315.0317917775698 - 191.4035672671025 - 201.24526595095384 - 250.21129623179667 - 0.4783367486797844'\n",
      "99 - random_34 - knn_ttm_r_n=100 - 243.2466523464879 - 303.8151673910506 - 314.81888516626054 - 190.16465722605346 - 200.83423017312728 - 250.58913734329394 - 0.47754899118971683'\n",
      "100 - random_34 - knn_tta_r_n=100 - 243.22607683523404 - 307.192624232462 - 312.2500551442746 - 191.49086245169315 - 202.0267782090287 - 251.25035472772322 - 0.47617042509064156'\n",
      "101 - random_29 - knn_tta_r_n=50 - 253.77838272048209 - 320.7260849534934 - 306.9485341714682 - 183.69843838108727 - 191.54110775070194 - 251.353802703938 - 0.4759547473477602'\n",
      "102 - random_29 - knn_ttm_n=100 - 263.30855954996747 - 302.849638499222 - 293.50827075683316 - 197.3010465279681 - 203.18124213506186 - 252.04218125671997 - 0.4745195531763081'\n",
      "103 - random_29 - knn_ttm_r_n=50 - 255.1786985801604 - 319.87548980233106 - 310.8499857137109 - 183.78328423300823 - 192.65736334015884 - 252.48438462441686 - 0.4735976074048278'\n",
      "104 - random_18 - knn_tta_n=50 - 236.25505360346693 - 310.7710929265352 - 332.05693157849095 - 180.65751828315928 - 203.0177812001757 - 252.56624746742995 - 0.47342693230945176'\n",
      "105 - random_34 - knn_tta_n=20 - 254.83782557731826 - 281.4039569899349 - 300.6680690319305 - 210.50488581612655 - 217.4820737856705 - 252.98871922626103 - 0.4725461247894802'\n",
      "106 - random_29 - knn_tta_r_n=10 - 258.7724755677203 - 311.7051915602039 - 313.37212869689563 - 185.89899647452302 - 195.86891962348253 - 253.13848048232956 - 0.472233888911488'\n",
      "107 - random_34 - knn_tta_r_n=10 - 248.13600701851422 - 298.15938830287695 - 315.2280120487359 - 197.18610535378892 - 207.11159378597475 - 253.17646548096099 - 0.47215469433400126'\n",
      "108 - random_18 - knn_tta_n=100 - 237.7187049065226 - 321.6369524301498 - 334.4101730035295 - 176.97604480364615 - 196.10418565685976 - 253.38525178498972 - 0.47171939767141635'\n",
      "109 - random_83 - knn_ttm_n=20 - 240.32986028155258 - 285.3130428688726 - 295.1935747610514 - 226.0545778224941 - 224.3988310426936 - 254.2649451395457 - 0.4698853330132111'\n",
      "110 - random_77 - knn_tta_n=50 - 260.0323130660767 - 304.08414413690497 - 308.9726990368627 - 189.78684609999107 - 209.45798874179192 - 254.4799613942435 - 0.4694370475832502'\n",
      "111 - random_29 - knn_ttm_r_n=100 - 256.1253315636877 - 326.78568912828683 - 315.0372986334115 - 183.7499354750731 - 193.14904571700103 - 254.98542553479106 - 0.46838321000295347'\n",
      "112 - random_34 - knn_ttm_r_n=20 - 246.86958321096773 - 302.5705400870751 - 322.9543809048005 - 196.87532845784563 - 206.86983086421972 - 255.24073850194412 - 0.4678509103244214'\n",
      "113 - random_29 - knn_ttm_r_n=20 - 259.28006432963446 - 318.78727347777294 - 318.6221028996061 - 186.48783260076303 - 195.61629360928245 - 255.7742436006873 - 0.4667386104059219'\n",
      "114 - random_18 - knn_tta_r_n=20 - 242.21916987142527 - 336.3963995825743 - 329.9465478424769 - 176.6237033956097 - 194.5075993791921 - 255.95557421769422 - 0.466360555855003'\n",
      "115 - random_77 - knn_tta_r_n=20 - 260.8326556089739 - 320.2368887885411 - 305.1450528346874 - 188.69213244168222 - 208.1216239673792 - 256.6196389971892 - 0.4649760532479038'\n",
      "116 - random_29 - knn_ttm_n=50 - 272.4438216015494 - 303.4421851950587 - 292.69021949657395 - 206.7990560484774 - 212.41698831343973 - 257.5699626950304 - 0.4629947320306427'\n",
      "117 - random_77 - knn_tta_n=100 - 264.3493672962742 - 310.81765559723084 - 316.17101928473693 - 186.746743126051 - 210.08768784182018 - 257.6487073447262 - 0.4628305580280976'\n",
      "118 - random_29 - knn_tta_r_n=100 - 257.45846366733565 - 333.83284129202815 - 318.8157314623717 - 184.24737115811953 - 194.11782964427616 - 257.71089094585676 - 0.462700912004784'\n",
      "119 - random_18 - knn_tta_r_n=10 - 244.69198637378108 - 340.1537281974515 - 331.9195393148316 - 178.57653068111745 - 196.45246717966936 - 258.3758536738437 - 0.46131453727305705'\n",
      "120 - random_18 - knn_tta_r_n=50 - 241.6364592139591 - 343.04854738374223 - 337.50092556670097 - 177.15216915226182 - 194.42208124097075 - 258.7695487907337 - 0.46049372591162474'\n",
      "121 - random_75 - knn_tta_r_n=20 - 267.5811555049306 - 328.769735234164 - 306.546150077717 - 189.59443259367285 - 201.58448753334014 - 258.8303669714663 - 0.4603669266408559'\n",
      "122 - random_18 - knn_ttm_r_n=50 - 244.4979775961414 - 342.88132613673514 - 337.3570093370349 - 176.7437081520404 - 193.6677630923025 - 259.04727528868574 - 0.45991469646698613'\n",
      "123 - random_75 - knn_tta_n=50 - 277.57383797067 - 322.5031899985258 - 292.53372479552604 - 195.4987706241938 - 209.66654429359792 - 259.5688874969198 - 0.4588271919275284'\n",
      "124 - random_77 - knn_tta_r_n=10 - 262.8658122726486 - 324.76384215426157 - 310.80181744130437 - 190.83953606570188 - 210.47407731837095 - 259.9632477501715 - 0.458004993829357'\n",
      "125 - random_77 - knn_tta_n=20 - 261.0910228482873 - 309.2170590648826 - 303.60410955096427 - 205.8462276961476 - 220.85605443835547 - 260.1341203896308 - 0.45764874302052294'\n",
      "126 - random_18 - knn_tta_n=20 - 242.16499881653263 - 318.42539183032477 - 332.2396604834327 - 192.18168096351658 - 217.18148336781786 - 260.4520253222365 - 0.45698594592362374'\n",
      "127 - random_18 - knn_ttm_r_n=20 - 247.9972542413626 - 345.29353630572786 - 336.14036403970255 - 177.98065997315337 - 195.5651194661245 - 260.61310491323906 - 0.4566501125522724'\n",
      "128 - random_75 - knn_tta_r_n=50 - 271.3146583126691 - 336.95627948491335 - 305.13724467379603 - 192.58339079079911 - 199.7472236215667 - 261.1633557891263 - 0.4555028995156106'\n",
      "129 - random_75 - knn_tta_n=100 - 281.31111370064775 - 330.57463318135206 - 294.291118684661 - 196.1659329628911 - 205.283206499976 - 261.5397937411209 - 0.4547180674600032'\n",
      "130 - random_75 - knn_ttm_r_n=50 - 269.2690588333094 - 338.0859225418446 - 311.3041865295867 - 190.824894246366 - 199.75342760098607 - 261.86347259029066 - 0.45404323237707767'\n",
      "131 - random_77 - knn_tta_r_n=50 - 267.23029854222085 - 331.5262533503801 - 315.1781506078793 - 187.6770095738078 - 209.87029731975787 - 262.3116479482756 - 0.45310883565746907'\n",
      "132 - random_18 - knn_ttm_r_n=100 - 244.80278828950372 - 352.0422275324172 - 344.6043870011962 - 177.9663249377987 - 193.81381175976998 - 262.66433004251604 - 0.4523735319732043'\n",
      "133 - random_77 - knn_ttm_r_n=20 - 264.4676588977375 - 331.14986498145817 - 317.76351405074445 - 190.34931067474548 - 210.55601378545637 - 262.8722501835961 - 0.4519400411658575'\n",
      "134 - random_75 - knn_tta_r_n=10 - 269.33636314640677 - 335.7558804739122 - 317.09644945507006 - 190.06939444080646 - 202.2151201524915 - 262.91066274680287 - 0.45185995516288424'\n",
      "135 - random_77 - knn_ttm_r_n=50 - 265.50289474390087 - 333.4884599410724 - 318.5123440033225 - 188.372276938512 - 209.06197755867242 - 263.0030161653304 - 0.4516674083622195'\n",
      "136 - random_4 - knn_tta_n=50 - 267.18239107151584 - 302.36381746334825 - 314.70420505714407 - 211.92792716723625 - 225.47738633545956 - 264.34209669427196 - 0.4488755715705659'\n",
      "137 - random_18 - knn_tta_r_n=100 - 244.95644111246114 - 356.77376805349235 - 347.99113086604916 - 179.71550520214373 - 194.48194546197502 - 264.80240329290416 - 0.4479158825378847'\n",
      "138 - random_75 - knn_ttm_r_n=100 - 272.6583104846882 - 345.6776971639498 - 314.5980872748202 - 193.57743505157714 - 200.5018182076261 - 265.4190774231654 - 0.44663018426349854'\n",
      "139 - random_75 - knn_ttm_r_n=20 - 270.1067110372905 - 340.95180910709377 - 325.2045252059392 - 189.67603865751408 - 201.3703577008986 - 265.4786742988245 - 0.4465059312805474'\n",
      "140 - random_29 - knn_ttm_r_n=10 - 269.3575682944214 - 327.55231508000406 - 337.12082825882914 - 192.25458595385155 - 203.01384816874196 - 265.8762039530633 - 0.4456771253271412'\n",
      "141 - random_34 - knn_ttm_r_n=10 - 254.55195485173553 - 318.1925191195887 - 338.8506845374209 - 204.00770493967204 - 217.2160306167179 - 266.5772078088352 - 0.44421560877654065'\n",
      "142 - random_83 - knn_ttm_r_n=5 - 248.47984263953737 - 323.1417806088327 - 332.5677253874171 - 209.09322016578383 - 219.67325207033556 - 266.60369457833093 - 0.4441603867521948'\n",
      "143 - random_29 - knn_tta_r_n=5 - 270.4821931865953 - 328.3310514885478 - 338.08960465931955 - 192.94316470476417 - 203.32184773155052 - 266.65001326766463 - 0.44406381733890854'\n",
      "144 - random_14 - knn_tta_r_n=20 - 255.06694258382493 - 347.91627766970987 - 357.7662514213957 - 186.45769546435338 - 186.65407846035475 - 266.7915018169535 - 0.44376882915189153'\n",
      "145 - random_34 - knn_ttm_n=100 - 261.54955578597963 - 314.25679093933354 - 339.1118994747035 - 203.70891984133291 - 215.61624839437835 - 266.8624080998587 - 0.4436209972888364'\n",
      "146 - random_34 - knn_tta_r_n=5 - 254.64254171739643 - 321.1906917699318 - 336.0498104974789 - 205.10790453282738 - 218.89619840146443 - 267.19067200422455 - 0.44293660286611647'\n",
      "147 - random_4 - knn_tta_n=20 - 272.3211652320037 - 292.05257363230936 - 310.7384565856453 - 223.5788543350403 - 238.6747336592198 - 267.4818801648288 - 0.4423294656258736'\n",
      "148 - random_18 - knn_ttm_r_n=10 - 254.07698370423174 - 356.7362466693378 - 344.5151119326962 - 183.50319940083048 - 198.95376679133466 - 267.57538129133474 - 0.4421345259793038'\n",
      "149 - random_27 - deep - 224.41219365074738 - 271.90993467261137 - 276.769445029146 - 216.84801762501877 - 348.33531820931495 - 267.6513971490468 - 0.4419760413323257'\n",
      "150 - random_29 - knn_tta_n=10 - 287.74510417525113 - 311.502530430004 - 294.81480289658066 - 220.41885833059226 - 225.23210134272648 - 267.95350799607695 - 0.44134617305848245'\n",
      "151 - random_14 - knn_ttm_r_n=50 - 255.77639985863598 - 355.3697432340068 - 357.6574120082913 - 186.06861977598 - 186.15416892907885 - 268.22497207918934 - 0.440780200065473'\n",
      "152 - random_71 - knn_ttm_r_n=100 - 275.09508727143447 - 322.4358818836504 - 355.922562468096 - 190.86753874676543 - 197.03470869058822 - 268.28899333331015 - 0.4406467227361869'\n",
      "153 - random_71 - knn_ttm_r_n=50 - 274.43716744690573 - 319.6704859566062 - 362.0133200346528 - 191.078300105982 - 194.4578805355021 - 268.34956674308575 - 0.4405204337861556'\n",
      "154 - random_77 - knn_ttm_r_n=100 - 269.5709336850685 - 344.2367606634016 - 328.55906116662135 - 187.93371889399108 - 211.91399073262704 - 268.4593382553226 - 0.4402915721606486'\n",
      "155 - random_14 - knn_tta_n=50 - 264.910434106708 - 342.55472139426496 - 344.9786988973506 - 190.55418168944325 - 200.69360904147118 - 268.75587719185273 - 0.4396733208342576'\n",
      "156 - random_75 - knn_tta_r_n=100 - 276.0702048619661 - 352.7381389303074 - 316.2481905417916 - 196.46352456904492 - 202.2634144355856 - 268.77334970798034 - 0.43963689254461136'\n",
      "157 - random_18 - knn_tta_r_n=5 - 253.2689328480715 - 354.7969124310771 - 348.7930333901181 - 185.15621697533365 - 201.92929156508302 - 268.8069372338896 - 0.43956686621792873'\n",
      "158 - random_71 - knn_tta_r_n=20 - 275.21945714471383 - 316.67402970607935 - 370.69998847834563 - 190.21618139115813 - 192.40910298622902 - 269.0624081538943 - 0.4390342372249356'\n",
      "159 - random_14 - knn_tta_r_n=50 - 256.5694341214549 - 358.55371200499917 - 357.2598219215952 - 186.94200356792396 - 186.47162080260594 - 269.1791078768032 - 0.43879093103613587'\n",
      "160 - random_71 - knn_tta_r_n=50 - 274.747664015565 - 322.0998488248257 - 367.75311046815074 - 189.4923025805911 - 195.62159247738802 - 269.9614770457136 - 0.43715977668566075'\n",
      "161 - random_14 - knn_tta_r_n=10 - 259.6486998575396 - 343.9805108996662 - 364.094304687503 - 190.64282124443707 - 191.53879050881815 - 269.9999598496643 - 0.43707954423840045'\n",
      "162 - random_75 - knn_tta_n=20 - 289.8332930450923 - 326.8523598914981 - 305.3809352582894 - 206.17225062366649 - 225.8431851753049 - 270.82955940981054 - 0.43534991967565184'\n",
      "163 - random_77 - knn_tta_r_n=5 - 266.9285429351175 - 338.6184927107787 - 336.61292478122067 - 193.68798527949195 - 219.23837267384758 - 271.0327572761632 - 0.43492627429584985'\n",
      "164 - random_77 - knn_ttm_r_n=10 - 266.66498323917597 - 341.65700224987285 - 335.9532449940942 - 194.2729104731218 - 216.63322559927076 - 271.0520139099971 - 0.43488612631545676'\n",
      "165 - random_71 - knn_ttm_r_n=20 - 279.79698238785386 - 317.94722822057327 - 365.503616256312 - 195.713698967337 - 196.4795323895519 - 271.10621034730553 - 0.4347731326572083'\n",
      "166 - random_14 - knn_ttm_r_n=100 - 257.92907265757253 - 362.129817356921 - 362.7582012639922 - 186.38968219239382 - 186.24387260240778 - 271.11047563295034 - 0.4347642400020373'\n",
      "167 - random_71 - knn_tta_n=50 - 283.16196238102253 - 311.3303326841909 - 370.5465008005138 - 193.78300029823748 - 197.42394371302123 - 271.26730366385743 - 0.43443727066958415'\n",
      "168 - random_34 - knn_ttm_n=50 - 267.79896411883715 - 314.2876141005424 - 334.4852031415938 - 215.64083448884162 - 224.10062300139617 - 271.27498232419043 - 0.4344212615006321'\n",
      "169 - random_4 - knn_tta_r_n=10 - 273.8963250708535 - 332.61541370329695 - 320.81207545054673 - 207.37871924584564 - 221.73869230955881 - 271.3018607900965 - 0.43436522283200996'\n",
      "170 - random_77 - knn_tta_r_n=100 - 274.5707376373198 - 347.4622980493604 - 333.31978140340175 - 188.28666425480463 - 213.90562382197223 - 271.5259207998412 - 0.43389808215956815'\n",
      "171 - random_71 - knn_tta_r_n=100 - 277.4208914460796 - 328.8337989624184 - 363.8270237842908 - 189.5863496960032 - 199.09341316414003 - 271.77087513313063 - 0.43338737910237934'\n",
      "172 - random_77 - knn_ttm_n=100 - 266.87033330613116 - 335.3401480694683 - 340.1095919031796 - 195.26044210592624 - 222.1232441217779 - 271.95593224661945 - 0.4330015552129052'\n",
      "173 - random_4 - knn_tta_n=100 - 268.6666270052932 - 325.41355993660267 - 332.4149085885104 - 209.7295331978497 - 224.16286907056002 - 272.09073160066697 - 0.4327205132680877'\n",
      "174 - random_4 - knn_tta_r_n=20 - 272.5612135764066 - 335.83964038725054 - 323.4777127083674 - 204.92865758111896 - 223.92033800034804 - 272.15936604836065 - 0.43257741793356175'\n",
      "175 - random_14 - knn_ttm_r_n=20 - 258.5072707458707 - 354.73930374614343 - 370.09879497861186 - 188.98381720407602 - 189.77979977359755 - 272.4417276841879 - 0.4319887247322074'\n",
      "176 - random_14 - knn_tta_n=100 - 267.0150291235924 - 352.2501076786481 - 357.2948864355312 - 188.20286596075564 - 197.36285931756538 - 272.4442646167104 - 0.4319834355047103'\n",
      "177 - random_34 - knn_tta_n=10 - 274.7420916248362 - 297.1130217573544 - 318.77535643187434 - 238.00771133757982 - 234.2572313809565 - 272.58783004309703 - 0.431684117255559'\n",
      "178 - random_6 - deep - 466.0828696321283 - 141.67080462386528 - 387.9102466539773 - 157.05710355431236 - 215.88066088251708 - 273.7412787156305 - 0.4292793027544586'\n",
      "179 - random_77 - knn_ttm_n=50 - 268.6224276415463 - 330.896524669297 - 332.23131311835056 - 207.5403962797436 - 229.54118673328153 - 273.77962435739425 - 0.4291993561505876'\n",
      "180 - random_14 - knn_tta_n=20 - 274.872360166712 - 339.2489505986511 - 341.7863271555597 - 202.89071066913635 - 210.2863048563627 - 273.8330661562054 - 0.42908793583126514'\n",
      "181 - random_71 - knn_tta_r_n=10 - 278.2622661121822 - 317.6284709151208 - 383.058698118654 - 194.0693315692177 - 198.06176713106987 - 274.2348636533049 - 0.42825023189117184'\n",
      "182 - random_74 - knn_tta_n=100 - 264.27107972909494 - 365.07160780997185 - 342.81583199098674 - 192.57236436488583 - 208.0916614190573 - 274.58232557454073 - 0.4275258116980325'\n",
      "183 - random_14 - knn_tta_r_n=100 - 259.4152596483829 - 368.5846014777144 - 368.72996026535793 - 189.20630404415988 - 188.48236729294064 - 274.9043488188126 - 0.426854428370671'\n",
      "184 - random_18 - knn_ttm_n=100 - 239.75212710906928 - 358.3458092786491 - 385.2408314487326 - 183.7878643338854 - 212.48689935732247 - 275.9413755301711 - 0.42469234083065843'\n",
      "185 - random_74 - knn_tta_n=50 - 262.4926618782866 - 365.48776283919386 - 342.6561496883266 - 197.40785129053202 - 211.60129764509688 - 275.9462872508386 - 0.42468210042899945'\n",
      "186 - random_4 - knn_ttm_r_n=20 - 275.7458941909174 - 341.9065729073499 - 332.6182636655362 - 206.79494053653562 - 223.1005236495316 - 276.04790009807374 - 0.4244702487298042'\n",
      "187 - random_75 - knn_ttm_r_n=10 - 279.5936176827199 - 355.3048726999606 - 344.5073858112567 - 195.38220948793165 - 205.94971871071402 - 276.1656771863959 - 0.42422469635167237'\n",
      "188 - random_74 - knn_tta_r_n=50 - 263.9000372870144 - 367.8956489695668 - 353.5936230169025 - 194.96743774791824 - 205.7086587329681 - 277.2315318968023 - 0.4220025055791562'\n",
      "189 - random_77 - knn_tta_n=10 - 278.8649994061834 - 319.48995999913836 - 313.48053554193586 - 229.4387935803607 - 246.38020223492916 - 277.54040766894894 - 0.4213585332966149'\n",
      "190 - random_83 - knn_tta_n=5 - 269.3295439588047 - 311.2135351209621 - 308.51154781138695 - 250.41162945656015 - 248.43578442536494 - 277.58716603322216 - 0.4212610472090539'\n",
      "191 - random_74 - knn_tta_r_n=20 - 265.8427345232817 - 369.51962109197007 - 351.7943322682257 - 194.55131116083444 - 207.0532835654738 - 277.7707252509044 - 0.42087834626889653'\n",
      "192 - random_75 - knn_tta_r_n=5 - 281.71199237934894 - 356.1094552198251 - 346.7492015911041 - 195.64843206598826 - 208.914217389089 - 277.8447913347357 - 0.42072392656568613'\n",
      "193 - random_18 - knn_ttm_n=50 - 245.0775800974712 - 351.4942812651348 - 377.88951648035084 - 194.51682114810808 - 225.5050241928303 - 278.9131778713804 - 0.4184964572117186'\n",
      "194 - random_18 - knn_tta_n=10 - 263.5234439284372 - 329.4164386648489 - 351.72007404462295 - 211.30867720600898 - 239.8355683017666 - 279.17370223585124 - 0.4179532923384105'\n",
      "195 - random_75 - knn_ttm_n=100 - 292.28067337796875 - 351.9097283421376 - 324.9746769713249 - 205.14055941089214 - 222.17558916077274 - 279.3119992438509 - 0.41766495816674254'\n",
      "196 - random_83 - knn_ttm_n=10 - 266.7814587296357 - 311.62348812495156 - 314.55304453279484 - 253.94079934721142 - 249.79290423516665 - 279.3449324146175 - 0.4175962960991336'\n",
      "197 - random_4 - knn_tta_r_n=5 - 280.0123867062109 - 339.9292044718998 - 330.63420003315116 - 220.23659587343616 - 226.24343593556227 - 279.4246462190046 - 0.41743010151480453'\n",
      "198 - random_4 - knn_ttm_r_n=50 - 276.36848081713003 - 351.6957845973471 - 343.45112433811244 - 205.09894720404662 - 222.76637155579797 - 279.89196877132696 - 0.41645578498421154'\n",
      "199 - random_14 - knn_tta_r_n=5 - 263.27634563311676 - 357.84362596470874 - 383.8235269116055 - 196.3818852871084 - 200.90462957980864 - 280.46563611946544 - 0.41525975115794933'\n",
      "200 - random_91 - knn_tta_r_n=20 - 280.7324170937967 - 362.28162413527264 - 358.1317258604898 - 196.5582966372346 - 206.3689190874629 - 280.83364156193943 - 0.41449249996459514'\n",
      "201 - random_74 - knn_tta_r_n=100 - 267.5963949648382 - 373.7652309890278 - 362.0377850208457 - 195.97058176413842 - 206.51187865322893 - 281.19555948040073 - 0.41373794059457913'\n",
      "202 - random_29 - knn_ttm_n=20 - 298.6384520668596 - 326.4934590167731 - 309.2883675353099 - 233.227840837399 - 238.68704309041502 - 281.27790724607166 - 0.4135662544883728'\n",
      "203 - random_71 - knn_ttm_r_n=10 - 291.5498330056056 - 326.6370461600756 - 382.83777328085006 - 203.09758292466154 - 202.58713175494228 - 281.36071406271304 - 0.41339361131098173'\n",
      "204 - random_4 - knn_ttm_r_n=10 - 278.1972309463643 - 346.5893396589556 - 340.431056356708 - 216.35005612154515 - 225.4003017051907 - 281.4081219590834 - 0.41329477101987067'\n",
      "205 - random_14 - knn_ttm_r_n=10 - 265.55987743599826 - 362.1983101834589 - 387.1100722679242 - 195.897651906668 - 196.77494158596792 - 281.5286127434292 - 0.4130435608816293'\n",
      "206 - random_4 - knn_tta_r_n=50 - 277.99603921839736 - 355.95301282597245 - 346.6954612811642 - 204.80944240635938 - 222.36418949084754 - 281.57994413229477 - 0.4129365405367701'\n",
      "207 - random_71 - knn_tta_n=100 - 274.25682400639954 - 335.7147683974057 - 414.22763085375993 - 190.1328892836782 - 196.24386532706737 - 282.13653886377807 - 0.41177610125338826'\n",
      "208 - random_74 - knn_ttm_r_n=50 - 267.97646963169547 - 378.39745448038605 - 364.660345348032 - 194.723800631229 - 206.20510003454092 - 282.41229757580487 - 0.41120117442769244'\n",
      "209 - random_73 - knn_tta_r_n=10 - 275.49491833980863 - 342.1028381874539 - 369.2072522182147 - 209.55324834048994 - 216.6986049609018 - 282.6280495834428 - 0.41075135503313165'\n",
      "210 - random_73 - knn_tta_r_n=20 - 275.229846352875 - 352.1502046092245 - 364.8210610051416 - 205.6500819868556 - 215.77015209329286 - 282.74155329736203 - 0.4105147121743489'\n",
      "211 - random_91 - knn_tta_r_n=50 - 280.9357516603069 - 366.79880730176023 - 364.0604940160411 - 196.11896030487782 - 206.25522684265727 - 282.85344403003717 - 0.41028143220546276'\n",
      "212 - random_4 - knn_ttm_n=50 - 274.4430910430254 - 325.3734317621426 - 342.23285750940954 - 229.70897327722324 - 243.77046792211266 - 283.1168925984033 - 0.4097321706861018'\n",
      "213 - random_71 - knn_ttm_n=100 - 279.7815539430873 - 341.9908434555537 - 381.6816259850529 - 203.64579011428802 - 208.67428239896043 - 283.17329866646946 - 0.4096145701888233'\n",
      "214 - random_74 - knn_tta_r_n=10 - 272.73724091088945 - 371.10430042992596 - 363.5046656183428 - 198.15096975219026 - 210.28545916585125 - 283.17547312833 - 0.40961003667310625'\n",
      "215 - random_74 - knn_ttm_r_n=100 - 268.4322832724346 - 378.6603573579347 - 367.10890966527654 - 195.3155020767097 - 206.37188164926502 - 283.1975477775489 - 0.40956401343811766'\n",
      "216 - random_75 - knn_ttm_n=50 - 297.8580637964139 - 349.9424571987309 - 327.2240028121711 - 213.3132571695527 - 234.13520244235846 - 284.50918215531493 - 0.40682939887693126'\n",
      "217 - random_4 - knn_ttm_n=100 - 269.2247332401067 - 343.2433936690595 - 355.1570491088461 - 219.55965961593083 - 235.51327714192936 - 284.5533038594289 - 0.40673740993810825'\n",
      "218 - random_40 - knn_tta_r_n=20 - 267.7279033696488 - 388.9127760560638 - 359.0306231600321 - 201.64987760447536 - 206.86390950393502 - 284.8563579422835 - 0.4061055752425182'\n",
      "219 - random_91 - knn_ttm_r_n=50 - 282.57046983361 - 371.517378480275 - 368.3503089812475 - 195.97893404907845 - 206.47733252451306 - 284.99898575814103 - 0.4058082118090144'\n",
      "220 - random_40 - knn_tta_r_n=10 - 268.7583965465704 - 385.1294500881486 - 360.82428302596696 - 204.44364655715884 - 207.4261277372533 - 285.33543311158695 - 0.4051067557878838'\n",
      "221 - random_91 - knn_tta_n=100 - 279.22415396035564 - 376.46562504953533 - 362.5656619469897 - 200.35904224464625 - 208.0771454926044 - 285.3577953732605 - 0.4050601329123096'\n",
      "222 - random_0 - knn_tta_r_n=50 - 281.8396511893027 - 374.47257462843214 - 364.9301149185472 - 194.4696018857102 - 211.9164608788467 - 285.54544132642917 - 0.4046689115745792'\n",
      "223 - random_91 - knn_tta_r_n=10 - 287.17143571666185 - 373.59103048720675 - 361.0842810950928 - 198.03571917189552 - 207.95137384340694 - 285.58658642876065 - 0.40458312852568656'\n",
      "224 - random_0 - knn_tta_r_n=20 - 287.0192128988564 - 367.92733873977284 - 361.77362946867004 - 197.92373677745195 - 213.34658261002957 - 285.6172919723283 - 0.40451911081772407'\n",
      "225 - random_0 - knn_tta_n=100 - 284.42028906238954 - 371.00883123698395 - 362.951108341563 - 191.84274185545183 - 219.7246655390683 - 286.0087773747403 - 0.40370290646986984'\n",
      "226 - random_40 - knn_tta_n=100 - 267.8221370389192 - 397.8778624598565 - 351.515678370292 - 201.76007372026368 - 211.4349161303633 - 286.10121062029043 - 0.4035101932385732'\n",
      "227 - random_11 - deep - 152.87669865929158 - 498.9816036487527 - 156.25594332808853 - 472.58464118069105 - 150.75741988842657 - 286.285171241492 - 0.4031266555463996'\n",
      "228 - random_40 - knn_tta_n=50 - 268.84804528164057 - 394.3009756543365 - 349.5495549890765 - 204.2403383002187 - 214.58292390514868 - 286.3228226210496 - 0.4030481563977564'\n",
      "229 - random_74 - knn_ttm_r_n=20 - 274.245388542041 - 382.8788713369503 - 371.4322495421882 - 195.8034423978386 - 209.83316740639478 - 286.8587895282562 - 0.40193072387722617'\n",
      "230 - random_4 - knn_tta_n=10 - 299.3343206049042 - 302.44309108334045 - 323.8281939239431 - 248.84135259010895 - 259.85143368465725 - 286.86748187798844 - 0.4019126012764834'\n",
      "231 - random_73 - knn_ttm_r_n=20 - 276.8558969717207 - 354.11012281170184 - 377.4586426020399 - 208.31192097903786 - 217.6192677489504 - 286.88890827041814 - 0.4018679295861669'\n",
      "232 - random_91 - knn_tta_r_n=100 - 283.4984665893246 - 375.5419425980468 - 370.69599135566466 - 196.7131737554417 - 208.68701578220026 - 287.04755735928865 - 0.40153716354656144'\n",
      "233 - random_91 - knn_ttm_r_n=20 - 286.1597615585777 - 372.28528762954016 - 372.2421861560636 - 197.7021450565484 - 207.65590805396332 - 287.229345709932 - 0.4011581546709554'\n",
      "234 - random_91 - knn_ttm_r_n=100 - 283.11284183762206 - 376.8193298337668 - 372.25887471033917 - 195.94308527379948 - 208.04148975429953 - 287.25558338115366 - 0.40110345198933106'\n",
      "235 - random_40 - knn_tta_r_n=50 - 266.3102561353225 - 395.5726770365698 - 365.35231877329767 - 200.9710350752321 - 208.12366416217864 - 287.28584350439917 - 0.40104036293413925'\n",
      "236 - random_0 - knn_tta_r_n=100 - 279.9122179925565 - 381.4616805382577 - 371.7350788294896 - 192.93033127060252 - 212.14505083441813 - 287.65729651345146 - 0.40026592394064386'\n",
      "237 - random_73 - knn_ttm_r_n=50 - 279.96383520451843 - 361.9716592403938 - 377.3144628228675 - 204.36134214543324 - 216.27684991741907 - 287.9962686597985 - 0.39955920400180245'\n",
      "238 - random_70 - deep - 187.49950451499055 - 160.10357839931038 - 152.40089890881077 - 472.4525561201043 - 467.87971077102713 - 288.0235480358472 - 0.3995023296105932'\n",
      "239 - random_18 - knn_ttm_r_n=5 - 275.8523642005255 - 376.408781645313 - 371.8165208880046 - 199.60900192847689 - 217.03962743603745 - 288.16441701267223 - 0.39920863303324383'\n",
      "240 - random_91 - knn_tta_n=50 - 278.06184093764125 - 384.63433009981196 - 364.6146792260768 - 203.2989815006566 - 210.3579484407069 - 288.2130844439717 - 0.3991071667492375'\n",
      "241 - random_4 - knn_ttm_r_n=100 - 281.1043024872091 - 370.00680320784346 - 363.0613600859792 - 205.89272617116384 - 222.9908460052389 - 288.62900896470256 - 0.39824000950631566'\n",
      "242 - random_73 - knn_tta_r_n=50 - 280.5424557264047 - 368.36163826332705 - 375.8974657092664 - 203.92135400096052 - 216.13095734975437 - 288.98972167628955 - 0.39748796286112875'\n",
      "243 - random_0 - knn_ttm_r_n=100 - 282.5413651834084 - 382.2532059628066 - 375.0146962543807 - 194.15340495063342 - 211.38345808721834 - 289.0899391069068 - 0.3972790204533234'\n",
      "244 - random_0 - knn_ttm_r_n=50 - 285.8125535462519 - 378.30956184602064 - 372.60862435401464 - 196.89431757650308 - 212.0231436756796 - 289.1499620308648 - 0.3971538792061565'\n",
      "245 - random_74 - knn_tta_n=20 - 274.6927451477215 - 380.33450155933184 - 356.7754711614913 - 211.07543074221059 - 223.4941989455068 - 289.2917477195009 - 0.39685827151602227'\n",
      "246 - random_40 - knn_ttm_r_n=50 - 268.1572758242088 - 398.05809579538067 - 371.72382135059473 - 202.09892613737722 - 207.55625862273638 - 289.5392022670882 - 0.39634235578482846'\n",
      "247 - random_29 - knn_ttm_r_n=5 - 291.038201934325 - 356.847543276506 - 369.19503438339444 - 210.72513343186557 - 220.58425409300477 - 289.6957997359905 - 0.39601586714899817'\n",
      "248 - random_14 - knn_tta_n=10 - 289.6980449693722 - 348.0787018327371 - 356.3070954092257 - 223.80284363734467 - 231.8397061032245 - 289.9601887476399 - 0.39546464490800615'\n",
      "249 - random_0 - knn_tta_n=50 - 292.3337399165522 - 373.77729847461035 - 362.4363491843972 - 197.2510701093626 - 224.8699601956726 - 290.1526618956734 - 0.3950633593956927'\n",
      "250 - random_14 - knn_ttm_n=50 - 283.13985204622884 - 374.25210002293227 - 370.1491783899613 - 205.33263244337672 - 219.51492690170983 - 290.496471660179 - 0.39434655355083803'\n",
      "251 - random_34 - knn_ttm_n=20 - 289.98933323159997 - 324.1927256164708 - 344.7135602522842 - 248.18110658846857 - 246.24617360632215 - 290.6750085017176 - 0.3939743237169331'\n",
      "252 - random_40 - knn_ttm_r_n=20 - 270.7227409231964 - 395.69027853569713 - 374.5107739782649 - 204.44884321039922 - 208.40580313612404 - 290.77592757386907 - 0.39376391846308734'\n",
      "253 - random_34 - knn_ttm_r_n=5 - 269.24975713952955 - 349.5257190226557 - 374.0590978894616 - 224.37332084775957 - 236.83390733578804 - 290.8228101641528 - 0.39366617337784915'\n",
      "254 - random_40 - knn_tta_r_n=100 - 267.50712927502514 - 403.04493141727056 - 374.1671068182676 - 201.09117653585363 - 209.0212391769058 - 290.9869358955438 - 0.3933239891361616'\n",
      "255 - random_77 - knn_ttm_r_n=5 - 284.09023389195477 - 361.38277812741416 - 369.47417277842436 - 207.28712229821107 - 232.97040923115983 - 291.0579628688171 - 0.3931759056468579'\n",
      "256 - random_75 - knn_tta_n=10 - 310.7072933054711 - 345.3861889618566 - 322.1872011091636 - 228.82261298493003 - 248.26560279289447 - 291.08638745643424 - 0.3931166434831703'\n",
      "257 - random_71 - knn_tta_r_n=5 - 295.3216969036011 - 334.3733054242255 - 418.9318616404637 - 202.8943992371555 - 204.13633724111563 - 291.15254880690503 - 0.39297870428650705'\n",
      "258 - random_14 - knn_ttm_n=100 - 278.17855251788245 - 385.29962481617713 - 381.1746667318046 - 196.5036042654885 - 214.54798380725225 - 291.1614348718327 - 0.3929601778107187'\n",
      "259 - random_73 - knn_tta_n=50 - 277.8972905539775 - 367.1852849095961 - 378.96440910283184 - 210.06775107667178 - 222.72586785279188 - 291.3861145336234 - 0.392491745231373'\n",
      "260 - random_40 - knn_ttm_r_n=100 - 267.7920260772844 - 403.96874466290745 - 376.779196599107 - 201.4888913250351 - 208.35612232061865 - 291.6978181073167 - 0.3918418772911568'\n",
      "261 - random_0 - knn_tta_r_n=10 - 294.19173713309965 - 371.65153223290747 - 373.7854973225176 - 203.602418082574 - 217.29375271581765 - 292.12458593782446 - 0.39095211293049703'\n",
      "262 - random_77 - knn_ttm_n=20 - 288.1051565054064 - 342.0792225810896 - 332.56600538547565 - 236.67112848969464 - 261.4672622940777 - 292.1881015193258 - 0.39081968987344695'\n",
      "263 - random_71 - knn_ttm_n=50 - 293.1495347981943 - 339.9627684328615 - 392.1312122395354 - 214.75944422357486 - 220.96110670970774 - 292.2106538034711 - 0.39077267082175304'\n",
      "264 - random_4 - knn_tta_r_n=100 - 282.82527532087823 - 379.8454067506112 - 371.76431243355137 - 206.85078247533383 - 223.8874418036958 - 293.0532842300212 - 0.3890158783243901'\n",
      "265 - random_72 - deep - 205.18874024114854 - 243.90843077112117 - 635.4182856421879 - 232.66252412830366 - 149.32667355577485 - 293.3254871819242 - 0.3884483650043056'\n",
      "266 - random_73 - knn_ttm_r_n=100 - 282.5507580672356 - 378.02469531716764 - 387.51679872413433 - 203.60685820060172 - 216.37481231531078 - 293.6348550755361 - 0.3878033665684728'\n",
      "267 - random_71 - knn_tta_n=20 - 309.4338958948322 - 313.9679192939878 - 428.1516300646781 - 209.9872687914023 - 209.08698820337597 - 294.14584248060504 - 0.38673801358430937'\n",
      "268 - random_0 - knn_ttm_r_n=20 - 294.12509659985733 - 380.8156026089244 - 379.57890402353485 - 201.5025810956404 - 215.74829881905933 - 294.3746723300326 - 0.38626092831658065'\n",
      "269 - random_73 - knn_tta_r_n=5 - 285.86635804402505 - 350.9010357010213 - 393.7353436139684 - 220.164369588504 - 223.6567525667608 - 294.88228161384245 - 0.38520261834664515'\n",
      "270 - random_73 - knn_tta_n=100 - 282.77539906038186 - 378.7008345137828 - 389.63412205252325 - 206.54945795049042 - 217.70861846998707 - 295.0935939213014 - 0.38476205524252827'\n",
      "271 - random_73 - knn_ttm_r_n=10 - 285.16176914660144 - 357.4933369382749 - 393.67415731217835 - 215.6093455247701 - 223.6357783950158 - 295.1329963438442 - 0.38467990549084585'\n",
      "272 - random_40 - knn_tta_n=20 - 280.6223170026629 - 404.6885080740225 - 354.2992114826975 - 215.64911637029726 - 222.59440860753168 - 295.5890607893381 - 0.3837290608845837'\n",
      "273 - random_18 - knn_ttm_n=20 - 270.9007201615218 - 355.94159196177566 - 384.48749173305765 - 221.54346958849715 - 249.82114601415304 - 296.5534900543093 - 0.38171833109895814'\n",
      "274 - random_74 - knn_tta_r_n=5 - 281.2183970991665 - 396.1470403974794 - 381.09750781419416 - 207.92676196775022 - 216.48290497797834 - 296.59477198664996 - 0.3816322627744263'\n",
      "275 - random_73 - knn_tta_r_n=100 - 285.02071168174035 - 387.1923043525568 - 391.18196309448365 - 203.5162702628488 - 216.47750282113813 - 296.69855468205924 - 0.3814158871785466'\n",
      "276 - random_74 - knn_ttm_r_n=10 - 283.48389896515505 - 398.3934197752506 - 385.3479792479827 - 201.95983432346637 - 214.86558983989372 - 296.8313606627627 - 0.3811390011996484'\n",
      "277 - random_74 - knn_ttm_n=100 - 276.3052622859313 - 406.834656403763 - 378.968522454948 - 201.7923356266224 - 220.3402030851493 - 296.8687844572099 - 0.38106097667165095'\n",
      "278 - random_57 - knn_tta_r_n=50 - 274.27364145717877 - 416.4042691353384 - 386.2484288172451 - 194.07253187725578 - 213.92469311879458 - 297.00703043795676 - 0.38077274888623747'\n",
      "279 - random_40 - knn_tta_r_n=5 - 274.2061295353594 - 407.11737653130496 - 383.33645935129084 - 208.00031613230587 - 215.25052117929772 - 297.6027909891831 - 0.37953065314219414'\n",
      "280 - random_73 - knn_tta_n=20 - 283.9175281614676 - 360.74060650563695 - 379.0759274800785 - 223.81338406217236 - 240.58993045311465 - 297.643178156945 - 0.3794464503041787'\n",
      "281 - random_91 - knn_ttm_r_n=10 - 296.7875607327258 - 389.8044613621631 - 386.2716525199532 - 201.72671132232873 - 214.06175501341386 - 297.7519897393842 - 0.3792195900275588'\n",
      "282 - random_57 - knn_tta_r_n=100 - 276.09200852884385 - 418.4046980194549 - 388.32336390725 - 193.382864686907 - 213.2715700055763 - 297.9175981815765 - 0.3788743144956337'\n",
      "283 - random_40 - knn_ttm_r_n=10 - 273.9627950073845 - 404.69019732593244 - 387.7294949973934 - 210.87179037058056 - 213.08932732339602 - 298.0893829903347 - 0.37851616191334103'\n",
      "284 - random_91 - knn_tta_r_n=5 - 298.417354601068 - 391.86713453577664 - 378.4319996730327 - 205.5147981303233 - 217.0390662555411 - 298.2749459873894 - 0.3781292833118306'\n",
      "285 - random_4 - knn_ttm_n=20 - 301.51872520101483 - 322.2220731079893 - 347.38951986584146 - 258.91539974215306 - 265.62563291256595 - 299.1431178207404 - 0.37631923976818915'\n",
      "286 - random_57 - knn_tta_n=100 - 278.2079841446253 - 419.7918684091813 - 391.0595884818841 - 192.37548363192008 - 215.10744334444271 - 299.3314106023181 - 0.3759266698638033'\n",
      "287 - random_4 - knn_ttm_r_n=5 - 292.28349071937134 - 367.6191851821996 - 366.39810987764196 - 232.64143743644817 - 242.3131361327636 - 300.2661381807579 - 0.3739778648537536'\n",
      "288 - random_75 - knn_ttm_r_n=5 - 300.01979774779477 - 383.83900989223 - 385.622671354351 - 211.20821357673842 - 221.2162674470646 - 300.401393360048 - 0.3736958725630417'\n",
      "289 - random_57 - knn_tta_r_n=20 - 272.66097499198315 - 418.65973836995886 - 396.4470037169011 - 197.37730477777475 - 216.82395620807662 - 300.41618686821795 - 0.37366502971267257'\n",
      "290 - random_57 - knn_ttm_r_n=100 - 276.3975801962924 - 422.9138533465982 - 396.62242090885167 - 193.59473314410624 - 213.60428987781248 - 300.6498629215854 - 0.37317784063851334'\n",
      "291 - random_57 - knn_ttm_r_n=50 - 273.92073353678626 - 423.3822273340286 - 400.5673144612161 - 194.8801414727709 - 214.4315153779623 - 301.459614699606 - 0.3714895965358441'\n",
      "292 - random_14 - knn_ttm_n=20 - 298.53811645721356 - 372.1096645093352 - 372.35409767887205 - 227.15571622834216 - 238.17541690711263 - 301.6831632672008 - 0.37102352216447987'\n",
      "293 - random_71 - knn_tta_n=10 - 335.75265688110346 - 328.73277151993847 - 381.8690599993555 - 229.81630200957278 - 233.5459062440742 - 301.96020294180227 - 0.37044592467158566'\n",
      "294 - random_23 - deep - 181.14561097866488 - 514.9816022025087 - 170.038321487619 - 472.512864423113 - 173.26917229294062 - 302.384593748075 - 0.3695611162849547'\n",
      "295 - random_57 - knn_tta_n=50 - 281.33828053655986 - 425.41280503750625 - 386.8529959327499 - 198.2102987176349 - 221.08007313549814 - 302.60119565332786 - 0.3691095248087384'\n",
      "296 - random_0 - knn_tta_n=20 - 309.73780648316915 - 384.6327961173393 - 372.35462214925883 - 209.81221347630228 - 238.5357221475379 - 303.0335545910453 - 0.3682081035996093'\n",
      "297 - random_0 - knn_ttm_r_n=10 - 305.7210765302147 - 391.8830896696315 - 395.8301112826723 - 209.05719733834457 - 221.04439328401978 - 304.72869201250666 - 0.3646739270375132'\n",
      "298 - random_71 - knn_ttm_r_n=5 - 316.596440843362 - 352.6881494913488 - 417.7725023712631 - 220.8628489091203 - 216.38947611875227 - 304.8825809477132 - 0.364353085398902'\n",
      "299 - random_10 - knn_tta_r_n=20 - 313.4744709824509 - 393.7028258578385 - 393.5545423121114 - 206.00770682137613 - 218.68158062516554 - 305.1064837097073 - 0.36388627257086237'\n",
      "300 - random_10 - knn_tta_r_n=50 - 312.577479114233 - 397.88210562217694 - 395.2284643800857 - 203.16241299229173 - 217.56268242959578 - 305.30541063843305 - 0.36347153162999746'\n",
      "301 - random_57 - knn_tta_r_n=10 - 275.0955538427282 - 423.6186135916403 - 408.3178864017547 - 200.87182440944605 - 219.13039424729826 - 305.42975279334615 - 0.3632122918043581'\n",
      "302 - random_91 - knn_tta_n=20 - 296.73238912392725 - 411.4478618975155 - 378.7967629299544 - 219.66336058520415 - 221.82062692471882 - 305.7125891573875 - 0.3626226088464761'\n",
      "303 - random_0 - knn_tta_r_n=5 - 311.08357431721925 - 388.13078936109537 - 391.0338934303077 - 212.49559076470945 - 226.19414876561206 - 305.8083464127672 - 0.36242296541737773'\n",
      "304 - random_74 - knn_ttm_n=50 - 286.0628270494734 - 414.22211378932224 - 383.98141267117916 - 215.9321627316936 - 232.03061273615546 - 306.4656180523898 - 0.3610526257656921'\n",
      "305 - random_75 - knn_ttm_n=20 - 325.58988241431155 - 363.2935914231294 - 342.4293855623033 - 241.74375692021172 - 260.46990479052965 - 306.71864838947187 - 0.3605250851217934'\n",
      "306 - random_78 - knn_tta_r_n=20 - 274.5329333078808 - 419.619461731384 - 405.3564621444665 - 216.71943124297712 - 220.2281280494816 - 307.3126003487959 - 0.3592867600945254'\n",
      "307 - random_94 - knn_tta_r_n=20 - 288.65134014682866 - 403.24400401312533 - 409.4657306608145 - 207.90917706364758 - 228.7600026475752 - 307.6274769140907 - 0.35863027681303483'\n",
      "308 - random_57 - knn_ttm_r_n=20 - 275.549033777279 - 430.2348644794375 - 415.877666336653 - 199.3254652103225 - 217.32902296898138 - 307.68705214014966 - 0.3585060689671379'\n",
      "309 - random_14 - knn_ttm_r_n=5 - 286.8626950671015 - 397.93957269686143 - 417.83965582381705 - 213.35848872701854 - 222.52170534618088 - 307.72596783232683 - 0.3584249339951593'\n",
      "310 - random_10 - knn_ttm_r_n=50 - 315.51164724178886 - 398.5430671342708 - 401.79840006837236 - 204.25664700339945 - 219.21339522759217 - 307.88770336441866 - 0.3580877330582085'\n",
      "311 - random_34 - knn_tta_n=5 - 313.9171338819104 - 326.72233245309445 - 349.08789449621867 - 271.3790105434812 - 278.94147038039677 - 308.01745250507986 - 0.35781722025725715'\n",
      "312 - random_40 - knn_ttm_n=100 - 284.8433938977138 - 438.19373346927455 - 385.55541167385826 - 209.5659134747855 - 222.47481053365186 - 308.1487590038579 - 0.3575434605345603'\n",
      "313 - random_78 - knn_tta_r_n=10 - 273.7063745549235 - 421.85028760683383 - 406.9985052865391 - 219.96021054779436 - 223.74596389802065 - 309.2732450213655 - 0.3551990298841804'\n",
      "314 - random_99 - knn_tta_r_n=20 - 294.3353142266841 - 417.75814918783465 - 414.96737828620707 - 209.6070265315985 - 210.25567015980025 - 309.4085774394552 - 0.3549168765589992'\n",
      "315 - random_99 - knn_tta_r_n=50 - 294.22680228632447 - 419.45879636587193 - 417.5688965954254 - 205.47140226591227 - 210.45056544920655 - 309.4596474008369 - 0.35481040126191865'\n",
      "316 - random_10 - knn_tta_n=50 - 316.2588522474768 - 413.3787687045909 - 388.9875870105304 - 207.55884013472595 - 221.60768232653152 - 309.5811410169333 - 0.3545571003288992'\n",
      "317 - random_78 - knn_tta_r_n=50 - 280.8886155047271 - 425.3661929330483 - 408.2722544896498 - 212.74118705334237 - 221.68471424347902 - 309.8128123677574 - 0.35407409084080377'\n",
      "318 - random_94 - knn_tta_r_n=50 - 295.9211065129737 - 412.6301655507399 - 406.62214931227595 - 207.06939234661684 - 229.02380021581672 - 310.27545328726615 - 0.3531095350037997'\n",
      "319 - random_10 - knn_tta_r_n=100 - 314.29431712682543 - 410.7001552526057 - 405.5047664784102 - 202.9365288622609 - 218.64255487028976 - 310.4395757439639 - 0.3527673575894903'\n",
      "320 - random_10 - knn_ttm_r_n=100 - 315.20680117167694 - 407.63867772318514 - 407.18195964335206 - 203.22178093539583 - 218.95824561022846 - 310.46533832571856 - 0.3527136454175662'\n",
      "321 - random_94 - knn_tta_r_n=10 - 290.22186611719405 - 404.2583554808227 - 419.3405862111186 - 210.11768580840348 - 228.6261004724332 - 310.53479353914594 - 0.35256883887604196'\n",
      "322 - random_10 - knn_tta_r_n=10 - 319.37009197662786 - 400.72190784931456 - 402.8529763086167 - 209.98924303922075 - 222.9732001779139 - 311.2042128424405 - 0.3511731726710692'\n",
      "323 - random_94 - knn_ttm_r_n=50 - 296.4365024410303 - 413.39089440530523 - 412.30164312362524 - 207.9182828692054 - 228.08658415943634 - 311.6492521420427 - 0.35024531429100336'\n",
      "324 - random_29 - knn_tta_n=5 - 326.850477218315 - 359.52965617220866 - 343.52906095286 - 260.4856353470539 - 268.44021741655257 - 311.77836285546493 - 0.34997613254118465'\n",
      "325 - random_39 - knn_tta_r_n=20 - 283.10095515083964 - 425.4571078505322 - 412.16170738499744 - 217.21190602141112 - 221.0741285843066 - 311.82339984245806 - 0.3498822353374279'\n",
      "326 - random_10 - knn_tta_n=100 - 315.4481974037698 - 422.379871376381 - 397.5723623281843 - 204.69611220437108 - 220.6007603452851 - 312.16333953261994 - 0.3491734981753041'\n",
      "327 - random_78 - knn_ttm_r_n=50 - 279.8074605601769 - 427.89085938885813 - 416.55708675176334 - 215.37031331961322 - 221.6821602202279 - 312.28407342944996 - 0.3489217811740599'\n",
      "328 - random_99 - knn_ttm_r_n=50 - 295.68294477896654 - 425.7055156607277 - 425.69626693374113 - 206.7516447091553 - 210.93819848727225 - 312.9799015116723 - 0.34747105554656565'\n",
      "329 - random_10 - knn_ttm_r_n=20 - 321.38627457704916 - 402.8705209109665 - 409.69890353279817 - 209.20339507362945 - 222.05990791348577 - 313.06718025251774 - 0.3472890888951544'\n",
      "330 - random_99 - knn_tta_r_n=100 - 295.39290377931536 - 427.0720333248918 - 425.21466661759627 - 205.04943348399746 - 212.55710355077886 - 313.0822501025062 - 0.34725766990224616'\n",
      "331 - random_39 - knn_tta_r_n=50 - 282.99625786017964 - 430.54931393444684 - 410.81466054253605 - 219.47000211149927 - 222.31769271748152 - 313.25174689681165 - 0.346904287580435'\n",
      "332 - random_73 - knn_tta_n=10 - 295.1476754324785 - 373.05834737020473 - 391.24944764381485 - 253.85708618497264 - 254.33044569149553 - 313.54286539547684 - 0.3462973372755518'\n",
      "333 - random_24 - knn_tta_r_n=20 - 315.64114855350783 - 407.07293751997224 - 417.90395122091 - 215.15572473469985 - 213.61497774815973 - 313.90162708582653 - 0.3455493582967627'\n",
      "334 - random_94 - knn_ttm_r_n=20 - 295.42312281962506 - 412.0794243965866 - 422.2712057796578 - 210.383396692879 - 229.55359791689742 - 313.96470409984425 - 0.3454178496050625'\n",
      "335 - random_83 - knn_ttm_n=5 - 303.51379244505205 - 347.0644944496133 - 345.35117876334294 - 293.204387896643 - 280.86521794427597 - 314.00628616139096 - 0.34533115554388405'\n",
      "336 - random_71 - knn_ttm_n=20 - 328.22695605770394 - 349.2910175315655 - 401.1980606042893 - 239.53101500495828 - 251.9104366838306 - 314.0478924173988 - 0.345244411039894'\n",
      "337 - random_94 - knn_tta_r_n=100 - 297.44259785019005 - 421.10578332037846 - 413.6523600803768 - 208.3027781475602 - 230.12422571323563 - 314.1483288248424 - 0.3450350120892991'\n",
      "338 - random_78 - knn_ttm_r_n=20 - 276.6053340927124 - 429.46373637326434 - 420.7353846222344 - 220.4977632067631 - 223.5209764986623 - 314.18675710803876 - 0.3449548933118627'\n",
      "339 - random_99 - knn_tta_r_n=10 - 297.51567082201433 - 421.2543545754298 - 422.11852559548674 - 214.7302587954378 - 215.9461552915512 - 314.3367479148133 - 0.34464217884569537'\n",
      "340 - random_94 - knn_ttm_r_n=100 - 297.96074529889654 - 420.24287755206825 - 416.3941658477542 - 207.58586799247564 - 229.4112219210983 - 314.34197354575525 - 0.344631283975366'\n",
      "341 - random_74 - knn_tta_n=10 - 305.62671241481735 - 407.5424474259408 - 376.3395345050232 - 232.820904773152 - 249.90573553851664 - 314.46460773234816 - 0.3443756050773127'\n",
      "342 - random_39 - knn_ttm_r_n=50 - 282.386753192305 - 434.812687811335 - 414.8052032401436 - 218.29458986628654 - 222.39204050796465 - 314.56086261345126 - 0.3441749241528784'\n",
      "343 - random_78 - knn_ttm_r_n=100 - 283.41993967672073 - 432.8965417699612 - 420.5908324951291 - 212.77215461546152 - 223.6088446517519 - 314.68081568704866 - 0.3439248350828761'\n",
      "344 - random_99 - knn_ttm_r_n=100 - 296.07189229418873 - 430.4201008610804 - 430.5058212625206 - 205.8463263103406 - 211.73013913700464 - 314.9403273814632 - 0.3433837815161399'\n",
      "345 - random_82 - knn_tta_r_n=20 - 303.5374973497931 - 416.13762765344114 - 420.11944299807897 - 216.29085138958774 - 219.7149189430204 - 315.1833863233307 - 0.342877030143254'\n",
      "346 - random_40 - knn_ttm_n=50 - 295.0129583626326 - 442.42262014445413 - 386.9340658519817 - 218.72247869646083 - 232.7752170537049 - 315.1949307891927 - 0.3428529611915837'\n",
      "347 - random_78 - knn_tta_r_n=100 - 284.8095955213012 - 434.8733447266982 - 419.29685915764344 - 212.21242612014672 - 225.09082202033636 - 315.27979563317547 - 0.3426760272517435'\n",
      "348 - random_39 - knn_tta_r_n=10 - 285.06762757742047 - 430.24059304308486 - 422.11242335333645 - 217.97096874741277 - 221.87277405852038 - 315.475805714518 - 0.34226736761940635'\n",
      "349 - random_18 - knn_tta_n=5 - 306.61225266403517 - 364.34099703619734 - 376.3371254482218 - 262.4125837034573 - 268.9579827080451 - 315.7442000496864 - 0.3417077947159106'\n",
      "350 - random_24 - knn_tta_r_n=10 - 318.7755586609413 - 406.28638398800825 - 419.31802492139497 - 219.48354575345766 - 216.50134996706385 - 316.0965129257354 - 0.34097326081128854'\n",
      "351 - random_39 - knn_ttm_r_n=100 - 284.5101979043606 - 436.6310646636159 - 415.90258678904087 - 220.1846329472524 - 223.65826802084783 - 316.19997238581584 - 0.3407575591258003'\n",
      "352 - random_8 - knn_tta_r_n=100 - 286.90868859649987 - 431.1168189030777 - 435.90210967155633 - 208.19053911878873 - 221.14087200330638 - 316.6762833017749 - 0.3397645028377726'\n",
      "353 - random_14 - knn_tta_n=5 - 314.70741002932726 - 376.5076347208076 - 383.00817229315203 - 250.8012291311066 - 259.333251529261 - 316.8863731658865 - 0.3393264883946504'\n",
      "354 - random_8 - knn_tta_r_n=50 - 286.82693925120657 - 432.928689170758 - 436.48144749774025 - 207.32999720321007 - 220.9820726256388 - 316.93449104680315 - 0.3392261678632289'\n",
      "355 - random_77 - knn_tta_n=5 - 320.0389363703658 - 351.4899682979631 - 350.91918753918964 - 264.59227164134546 - 298.15408477363184 - 317.0474498376678 - 0.3389906611095569'\n",
      "356 - random_39 - knn_tta_r_n=100 - 285.6381456269242 - 436.16333750281433 - 414.2083777773538 - 222.55399943512944 - 226.97171152584292 - 317.1292778822876 - 0.3388200585650337'\n",
      "357 - random_39 - knn_ttm_r_n=20 - 284.6063118801138 - 435.20912364433485 - 424.72813540856464 - 218.31196478403757 - 222.68032407208742 - 317.1303595319377 - 0.3388178034435354'\n",
      "358 - random_99 - knn_ttm_r_n=20 - 299.1235636792298 - 429.02161644799895 - 431.86895298875595 - 212.4583308068689 - 213.1703782125894 - 317.15360483988525 - 0.3387693395128317'\n",
      "359 - random_39 - knn_tta_n=100 - 291.05745399123236 - 431.84766600451564 - 411.3331469743609 - 221.58370235266437 - 230.0017093249826 - 317.1866658939315 - 0.33870041082253843'\n",
      "360 - random_94 - knn_tta_n=50 - 288.07485392729404 - 422.34748178654377 - 431.2674028613769 - 207.34183889574112 - 237.14186545803136 - 317.25748777850333 - 0.3385527549207996'\n",
      "361 - random_0 - knn_ttm_n=100 - 312.01873414107325 - 430.23829616420915 - 406.52683231142754 - 200.02146381498255 - 237.93274021717608 - 317.3712231968837 - 0.3383156289834973'\n",
      "362 - random_29 - knn_ttm_n=10 - 330.3923163785986 - 370.89910625813224 - 342.52345900122765 - 268.7283036244879 - 274.26104140898883 - 317.3718536560961 - 0.33831431454483085'\n",
      "363 - random_73 - knn_ttm_r_n=5 - 312.001288411789 - 376.0012959049748 - 420.9632931737284 - 233.95476035516305 - 244.52445304235056 - 317.5077987875805 - 0.33803088377907675'\n",
      "364 - random_82 - knn_tta_r_n=10 - 301.69295757060286 - 417.51131834644985 - 426.77501303463265 - 218.78604905533734 - 222.80622789991796 - 317.5375264718487 - 0.33796890480105646'\n",
      "365 - random_39 - knn_tta_n=50 - 293.8508747158076 - 431.8123142943817 - 411.3174527640702 - 220.50728418238472 - 230.93096609487765 - 317.7058508099856 - 0.33761796692242674'\n",
      "366 - random_40 - knn_tta_n=10 - 298.6579410157168 - 437.6229739612079 - 374.4329298662918 - 235.8089890724355 - 243.02460783870447 - 317.92832735000616 - 0.33715412761158237'\n",
      "367 - random_78 - knn_tta_n=50 - 276.467463050688 - 443.3113741950423 - 425.65274716833176 - 219.39638449061908 - 225.5605248821401 - 318.10064349373073 - 0.3367948672538603'\n",
      "368 - random_94 - knn_tta_n=100 - 290.69996373074133 - 426.87008085692355 - 432.8887237414344 - 208.87773542682905 - 231.42879324554653 - 318.17658029194604 - 0.3366365473152788'\n",
      "369 - random_99 - knn_tta_n=100 - 297.0568682614823 - 437.8932750380577 - 436.9040096536917 - 203.58192232304253 - 216.56789770943243 - 318.4267938494109 - 0.3361148793495343'\n",
      "370 - random_57 - knn_tta_n=20 - 291.80956001891093 - 443.9502518355646 - 405.6924832802278 - 215.24144760719915 - 236.73469311348862 - 318.7079354890455 - 0.335528729707124'\n",
      "371 - random_57 - knn_ttm_r_n=10 - 285.21549446643644 - 447.03851990852644 - 432.5090814629716 - 205.9870616027638 - 223.94877420074357 - 318.9647405748806 - 0.3349933191239496'\n",
      "372 - random_34 - knn_ttm_n=10 - 322.7752013301356 - 343.8654963534922 - 363.78638148041625 - 280.967857518723 - 284.675083454834 - 319.22273858495225 - 0.3344554214239055'\n",
      "373 - random_81 - knn_tta_r_n=10 - 295.3221350905093 - 444.3167590190405 - 443.5869078411955 - 201.5398363910635 - 212.44955611892703 - 319.4700275739273 - 0.3339398508643536'\n",
      "374 - random_73 - knn_ttm_n=50 - 291.13716530979275 - 415.89856299691564 - 421.57901826783586 - 226.12222564653226 - 243.20444052772422 - 319.6086653529434 - 0.33365080622229903'\n",
      "375 - random_99 - knn_tta_n=50 - 300.65801192356935 - 432.45344122098714 - 434.70395912364154 - 210.58824486697947 - 220.20353616803584 - 319.74647779376227 - 0.3333634823203304'\n",
      "376 - random_82 - knn_tta_n=50 - 305.20230686082334 - 431.36277625872907 - 426.21183655911784 - 213.87521964881034 - 222.86939611214075 - 319.92867574248027 - 0.33298361947743127'\n",
      "377 - random_24 - knn_tta_r_n=50 - 315.42332879599394 - 422.9167949373276 - 431.33381463452713 - 214.18598654531345 - 216.30320033354678 - 320.0577751829335 - 0.33271446123052273'\n",
      "378 - random_73 - knn_ttm_n=100 - 289.4206440421079 - 432.106758457378 - 434.4020158059142 - 213.1612008474616 - 231.47983236950614 - 320.1375617010164 - 0.33254811504607185'\n",
      "379 - random_8 - knn_ttm_r_n=100 - 289.19794920827485 - 438.142332257683 - 444.4027124117144 - 208.232570547085 - 220.78697738392353 - 320.1778636322021 - 0.33246408991701715'\n",
      "380 - random_4 - knn_tta_n=5 - 334.6771068268849 - 339.18019441607515 - 340.4279157058899 - 291.4630929967465 - 295.2623075831365 - 320.2085652249872 - 0.33240008044600544'\n",
      "381 - random_82 - knn_tta_r_n=50 - 311.16613715897836 - 425.0118731497555 - 428.2433330460556 - 216.88589649153582 - 220.9625331611605 - 320.4783227137677 - 0.3318376655159663'\n",
      "382 - random_78 - knn_tta_n=100 - 280.8436973531737 - 447.38791076461706 - 433.99260440472455 - 214.75424369529304 - 225.53215555605917 - 320.5262094597127 - 0.33173782687574094'\n",
      "383 - random_24 - knn_ttm_r_n=20 - 320.18922359890377 - 417.6770678016207 - 432.51895296482104 - 217.596463726707 - 215.8638540398586 - 320.7940827740465 - 0.331179340243835'\n",
      "384 - random_14 - knn_ttm_n=10 - 315.97048082098974 - 382.0504596038712 - 389.7601011948242 - 254.07506329807373 - 262.28384946867527 - 320.84302712701543 - 0.3310772966083635'\n",
      "385 - random_78 - knn_tta_r_n=5 - 279.67075608671587 - 438.91190650256493 - 424.8387853427998 - 229.49627737289035 - 232.56124782927185 - 321.11741157921284 - 0.33050523496446227'\n",
      "386 - random_54 - knn_tta_r_n=50 - 309.2568075596328 - 453.38259242914154 - 432.9232656204117 - 199.20356235539242 - 211.04574106373195 - 321.19024397777207 - 0.33035338736043296'\n",
      "387 - random_54 - knn_tta_r_n=20 - 306.9814363700183 - 451.74949752316036 - 426.6069539784688 - 205.68544886758534 - 214.9192135992756 - 321.21512381517186 - 0.33030151561416987'\n",
      "388 - random_54 - knn_tta_n=100 - 308.5587723690578 - 457.7232756913416 - 427.22622503032716 - 200.08982338035872 - 212.92262701652257 - 321.33169730030545 - 0.33005847261735743'\n",
      "389 - random_8 - knn_tta_r_n=20 - 290.03699895866055 - 441.72615041850685 - 443.01655612358724 - 209.14442640401413 - 222.84081164818625 - 321.3782762108153 - 0.32996136067131243'\n",
      "390 - random_10 - knn_tta_n=20 - 327.98156149499476 - 425.36278963679734 - 397.8402296874495 - 226.1161506846216 - 229.71381410594608 - 321.42534712189627 - 0.32986322295776027'\n",
      "391 - random_54 - knn_tta_r_n=100 - 308.2292720420801 - 452.2904558779908 - 438.1461093956773 - 198.27977962851998 - 210.52823926873808 - 321.52287414954804 - 0.3296598897465799'\n",
      "392 - random_81 - knn_tta_r_n=20 - 298.0517566939762 - 456.5444732465704 - 445.5503634492741 - 197.74645469849887 - 210.48445589251125 - 321.7037163357079 - 0.32928285352068287'\n",
      "393 - random_77 - knn_ttm_n=10 - 325.1560944287926 - 357.8021404773758 - 351.748449788147 - 270.6704188528384 - 303.166319384383 - 321.71703459601997 - 0.32925508640112866'\n",
      "394 - random_74 - knn_ttm_r_n=5 - 300.2248040135526 - 440.60444292608577 - 412.13019295461515 - 220.86937489693892 - 234.80995883902725 - 321.75028876849154 - 0.32918575507999015'\n",
      "395 - random_24 - knn_ttm_r_n=50 - 317.2147984537956 - 423.0020487105362 - 438.2643035407685 - 214.3574445358917 - 216.11982229326827 - 321.81725726182435 - 0.32904613307852937'\n",
      "396 - random_54 - knn_tta_n=50 - 310.73534963835823 - 458.62500990305017 - 419.41611544512466 - 203.78387437146756 - 218.30117118407588 - 322.1989763228232 - 0.3282502904868859'\n",
      "397 - random_57 - knn_tta_r_n=5 - 287.49151188638416 - 446.00841168921096 - 435.28091015910786 - 211.1486340523672 - 231.76981962087834 - 322.36406980143727 - 0.3279060885978322'\n",
      "398 - random_91 - knn_ttm_n=100 - 293.8273095742933 - 453.2431735220821 - 430.04345474979283 - 209.23546893070062 - 225.58523750881278 - 322.4121242431047 - 0.3278059003303233'\n",
      "399 - random_8 - knn_ttm_r_n=50 - 291.3203478820304 - 442.74235315943275 - 449.4958053282258 - 208.19630536900553 - 221.2686890256538 - 322.6305905171936 - 0.3273504219863742'\n",
      "400 - random_82 - knn_ttm_r_n=20 - 308.8863600502727 - 427.770343068915 - 433.5703081345524 - 219.35088805359953 - 223.51149525697292 - 322.6421646892354 - 0.32732629110056055'\n",
      "401 - random_82 - knn_ttm_r_n=50 - 309.58833950283065 - 430.13798940157375 - 435.7370366691455 - 217.45876679232782 - 222.16726569750566 - 323.0426497706913 - 0.3264913234038823'\n",
      "402 - random_81 - knn_tta_r_n=5 - 296.5015863325295 - 439.9788410527757 - 456.5846121676595 - 205.4421918602677 - 216.90493722069965 - 323.10929292975925 - 0.3263523796888653'\n",
      "403 - random_10 - knn_tta_r_n=5 - 322.42696398217083 - 420.74033259727474 - 429.6878394195247 - 216.99075136608747 - 226.8609438661557 - 323.36570694434187 - 0.3258177844465814'\n",
      "404 - random_54 - knn_ttm_r_n=50 - 307.82154558923514 - 457.29166732906924 - 438.60356626400716 - 200.14687847594945 - 213.67889610206356 - 323.5364948210588 - 0.32546171035881644'\n",
      "405 - random_24 - knn_tta_n=50 - 322.3905442095345 - 425.6856182515662 - 432.57472797151524 - 221.15431566021593 - 216.39134552556712 - 323.6644792855737 - 0.32519487671508085'\n",
      "406 - random_91 - knn_ttm_r_n=5 - 322.2608049328937 - 420.7326855682373 - 419.2439928971028 - 220.4290596253919 - 236.45860692745802 - 323.8479223931241 - 0.3248124178518792'\n",
      "407 - random_8 - knn_tta_n=100 - 292.5840804262115 - 439.3107477732543 - 448.44028096734735 - 210.18023336556416 - 228.91729721272145 - 323.9115700137407 - 0.32467971950768104'\n",
      "408 - random_40 - knn_ttm_r_n=5 - 291.8543078590047 - 438.3816629906018 - 428.872419847499 - 227.77078196997235 - 232.95649341293483 - 323.98959895355796 - 0.32451703768213935'\n",
      "409 - random_94 - knn_tta_r_n=5 - 299.8385630456827 - 418.6557025725557 - 447.55961012207325 - 216.3461628776996 - 237.99632860779337 - 324.1025323021638 - 0.3242815839728006'\n",
      "410 - random_54 - knn_ttm_r_n=100 - 310.8561045973026 - 456.9322006711513 - 442.7115037005444 - 198.97467238730175 - 212.26195334570278 - 324.37578303402205 - 0.3237118860121029'\n",
      "411 - random_81 - knn_tta_r_n=50 - 296.35605240329977 - 468.42370871630226 - 450.8261092008768 - 197.29997077538826 - 210.04757355833124 - 324.61970415027184 - 0.3232033370997044'\n",
      "412 - random_10 - knn_ttm_r_n=10 - 329.7066131104345 - 418.6880884999725 - 434.2407493130843 - 214.20491015336748 - 226.7271229948767 - 324.7385172104206 - 0.32295562483335216'\n",
      "413 - random_94 - knn_ttm_r_n=10 - 303.042467009123 - 421.10928475313113 - 445.4020231465202 - 217.37276973951143 - 236.90147222463034 - 324.78903514762834 - 0.32285030044644125'\n",
      "414 - random_78 - knn_ttm_r_n=10 - 282.16254174850525 - 446.46182909821283 - 436.04724316170933 - 227.95897495171238 - 231.87629530238675 - 324.9241738623998 - 0.322568550971543'\n",
      "415 - random_82 - knn_tta_n=100 - 310.0647450823239 - 437.5014392521846 - 438.6034393461718 - 216.0791644302826 - 224.11169234448508 - 325.29733950107493 - 0.32179054133215446'\n",
      "416 - random_82 - knn_tta_n=20 - 315.4366187757356 - 435.35408084248763 - 421.7462358989061 - 221.02311135937765 - 233.77476299089267 - 325.4904992409222 - 0.32138782435082547'\n",
      "417 - random_54 - knn_tta_r_n=10 - 307.54074996869304 - 452.20002748010313 - 435.011077700104 - 211.07741743212108 - 222.57272107635285 - 325.7065250556023 - 0.32093743409845754'\n",
      "418 - random_54 - knn_ttm_r_n=20 - 303.65359510836345 - 456.21226100767217 - 440.0457379094219 - 210.1645783824713 - 219.34761742225996 - 325.91142991133086 - 0.3205102298320618'\n",
      "419 - random_24 - knn_tta_r_n=5 - 321.34465459147054 - 416.8144986716018 - 438.74114757947746 - 226.46465224601576 - 227.4405363705505 - 326.18490888512304 - 0.31994005601183595'\n",
      "420 - random_81 - knn_ttm_r_n=20 - 299.6683084203207 - 461.395519104008 - 458.8045858751122 - 199.07414773554103 - 212.34046122326438 - 326.285537460967 - 0.3197302564110942'\n",
      "421 - random_24 - knn_tta_r_n=100 - 316.2619067419189 - 438.91310383834326 - 443.04261553330775 - 213.27629123687464 - 220.20037358923037 - 326.36516336632815 - 0.3195642450866434'\n",
      "422 - random_39 - knn_ttm_r_n=10 - 289.94609667714474 - 446.49194770346 - 441.7250490032856 - 226.4280790632381 - 229.0999499011307 - 326.76197923023926 - 0.31873692730818637'\n",
      "423 - random_18 - knn_ttm_n=10 - 307.99896085371904 - 378.22209916682925 - 400.09551725948694 - 265.79648743753796 - 281.82968129949694 - 326.8012638235592 - 0.3186550232175769'\n",
      "424 - random_24 - knn_ttm_r_n=100 - 317.2608201497393 - 436.5545291762072 - 448.0782435832896 - 213.9676358913038 - 219.13565586967164 - 327.0258854498358 - 0.3181867116359459'\n",
      "425 - random_99 - knn_ttm_r_n=10 - 305.5287717900588 - 441.1623346011958 - 453.1681709178957 - 216.39649755877764 - 219.12495331551222 - 327.10238238700595 - 0.3180272238687619'\n",
      "426 - random_82 - knn_tta_r_n=100 - 319.50995764161075 - 435.7839260249493 - 436.6170295618098 - 219.09638269036364 - 224.9231291835313 - 327.2113283491662 - 0.31780008342508637'\n",
      "427 - random_81 - knn_tta_r_n=100 - 294.7379607505228 - 476.1585841622809 - 458.5863204211689 - 196.1186412251713 - 210.59037104237896 - 327.26810883829 - 0.31768170230075676'\n",
      "428 - random_81 - knn_ttm_r_n=10 - 299.65308712327374 - 453.1539390591958 - 465.35803073759 - 202.68704272922744 - 215.83561964747165 - 327.3658832839697 - 0.3174778532499847'\n",
      "429 - random_94 - knn_tta_n=20 - 296.03741387027645 - 428.99131269461583 - 443.6729237828467 - 217.92905395292004 - 251.13844101350287 - 327.57615477544 - 0.3170394601336375'\n",
      "430 - random_0 - knn_tta_n=10 - 335.80105488254924 - 403.9495832124812 - 403.77823663109007 - 236.7976178551927 - 257.47359856295867 - 327.5793208593642 - 0.3170328591941166'\n",
      "431 - random_82 - knn_tta_r_n=5 - 312.09359658531685 - 425.0073655383461 - 444.96365272567056 - 228.43918579628115 - 227.64904472983017 - 327.6544707800721 - 0.3168761798092794'\n",
      "432 - random_24 - knn_tta_n=100 - 320.6762453717712 - 440.05596176271973 - 444.56198934773835 - 215.44090612716758 - 218.18887319612423 - 327.8114290037778 - 0.3165489390390468'\n",
      "433 - random_82 - knn_ttm_r_n=100 - 317.2268021811062 - 438.04777682541305 - 441.7890515786449 - 218.77755284778368 - 224.02635316953848 - 327.99908551665993 - 0.31615769568546614'\n",
      "434 - random_81 - knn_ttm_r_n=50 - 298.46820311317146 - 472.3416919136501 - 460.36975037803154 - 197.73815814611845 - 211.06041754641143 - 328.0253085315786 - 0.31610302356063436'\n",
      "435 - random_75 - knn_tta_n=5 - 351.5438331187116 - 377.37313401388013 - 361.4478260291631 - 269.0268044991714 - 283.18481058380877 - 328.5278604258839 - 0.31505525769598863'\n",
      "436 - random_0 - knn_ttm_n=50 - 326.6446797162293 - 441.4145451971657 - 410.3816805346651 - 213.796736992635 - 251.17368238642098 - 328.7053531822181 - 0.3146852046658116'\n",
      "437 - random_39 - knn_tta_r_n=5 - 296.49391926740486 - 442.73437435221257 - 445.19051253789144 - 228.6609237263208 - 230.81606783282623 - 328.8029302534629 - 0.3144817671192004'\n",
      "438 - random_4 - knn_ttm_n=10 - 341.3356576773759 - 345.4217170191443 - 362.39510573529964 - 295.059269890832 - 301.39665715162965 - 329.12909628376156 - 0.3138017465350049'\n",
      "439 - random_99 - knn_tta_r_n=5 - 306.48430947235715 - 442.96348224168105 - 452.5014069420354 - 220.86496834117 - 222.88785511126443 - 329.16614880972406 - 0.31372449606128816'\n",
      "440 - random_24 - knn_ttm_r_n=10 - 324.7491340005905 - 429.18103821913854 - 446.63874188857153 - 225.62458379479583 - 223.39771202642834 - 329.94354070043164 - 0.31210371879277987'\n",
      "441 - random_78 - knn_tta_n=20 - 280.15412654001113 - 450.4984622863092 - 435.5940306959626 - 245.3124567497367 - 238.1059033820767 - 329.95417049360935 - 0.31208155683385363'\n",
      "442 - random_82 - knn_ttm_r_n=10 - 313.1033049107463 - 432.7539571668186 - 446.84150407418394 - 227.30355935965855 - 230.259869158981 - 330.07674488023747 - 0.31182600261220195'\n",
      "443 - random_39 - knn_tta_n=20 - 303.5399779051285 - 448.9967345209734 - 425.09732830834093 - 230.14558802244596 - 245.09305461528504 - 330.5968468185259 - 0.31074164682079064'\n",
      "444 - random_81 - knn_ttm_r_n=100 - 296.994871055011 - 480.7793634699372 - 467.26982050096785 - 196.9301291239902 - 211.3515152671159 - 330.69550693433155 - 0.310535951244444'\n",
      "445 - random_24 - knn_tta_n=20 - 334.5169772989518 - 429.1967924680642 - 427.6101440731249 - 232.82387675025512 - 232.2088283981658 - 331.2950259388916 - 0.30928601953529633'\n",
      "446 - random_8 - knn_ttm_r_n=20 - 297.6282216145989 - 456.8096397769138 - 465.3925518421193 - 211.57302862908955 - 224.96738445572552 - 331.3012872986639 - 0.30927296528336723'\n",
      "447 - random_91 - knn_ttm_n=50 - 309.39358960321425 - 467.301196271604 - 425.09345304042023 - 221.70339553559063 - 235.38663276391364 - 331.8004297874327 - 0.3082323076572545'\n",
      "448 - random_8 - knn_tta_r_n=10 - 297.60919593661845 - 456.77588588397293 - 461.8619154768448 - 213.4333124626724 - 229.41609854402643 - 331.8457774189351 - 0.3081377627935913'\n",
      "449 - random_25 - knn_tta_r_n=100 - 304.1032831082876 - 460.7099745281061 - 465.0194602602925 - 208.4354402580742 - 221.2148404614957 - 331.9246979974294 - 0.3079732219986975'\n",
      "450 - random_8 - knn_tta_n=50 - 296.69342683554083 - 454.63317973190516 - 461.7905574450257 - 211.97405866262415 - 234.84162928849602 - 332.01263032945593 - 0.307789892680989'\n",
      "451 - random_0 - knn_ttm_r_n=5 - 335.7975770911535 - 421.6707193492527 - 438.5042087056626 - 225.87194015327353 - 239.87785827083422 - 332.3683343637418 - 0.3070482885814627'\n",
      "452 - random_81 - knn_tta_n=50 - 300.9633203314556 - 481.20133591371365 - 461.61849255339854 - 204.82690173471423 - 213.56232990700212 - 332.464054837671 - 0.3068487218376753'\n",
      "453 - random_25 - knn_tta_r_n=50 - 305.8273632490962 - 457.7760592394109 - 469.0807940611218 - 209.873557119114 - 220.59512157327094 - 332.6587552729803 - 0.306442792674418'\n",
      "454 - random_37 - knn_tta_r_n=100 - 300.74804892539345 - 470.4456109325093 - 476.44557799573647 - 193.57545909546386 - 223.26152133065182 - 332.92511927180186 - 0.305887452800669'\n",
      "455 - random_57 - knn_ttm_n=100 - 294.2749753952394 - 481.12004323601576 - 455.64794315983005 - 200.93811463597177 - 233.9684701886027 - 333.2176872223065 - 0.30527748054685455'\n",
      "456 - random_81 - knn_tta_n=100 - 297.42587782572775 - 488.3392068689776 - 468.8929465053572 - 198.86659948135795 - 212.793253497996 - 333.29416213537843 - 0.3051180386975122'\n",
      "457 - random_54 - knn_ttm_r_n=10 - 305.35272757737243 - 462.0050535583612 - 457.4025740807107 - 216.18456445701153 - 225.84005180420738 - 333.38395809876437 - 0.30493082391176596'\n",
      "458 - random_91 - knn_tta_n=10 - 332.13600921965474 - 455.7349998576936 - 397.5109696882099 - 241.82999006722994 - 240.30723206755775 - 333.5260255224699 - 0.3046346288347529'\n",
      "459 - random_25 - knn_tta_r_n=20 - 306.98749608361993 - 456.6089810943729 - 473.97560998279266 - 212.42737727276645 - 223.10130246757305 - 334.6481998973281 - 0.30229501770706646'\n",
      "460 - random_99 - knn_tta_n=20 - 317.2372036103091 - 446.99749859438055 - 445.1959249070055 - 230.2686143554928 - 235.7287063724075 - 335.11009141100175 - 0.3013320242994587'\n",
      "461 - random_73 - knn_ttm_n=20 - 306.6798173338523 - 413.6294178231191 - 425.65432445585253 - 261.4770261988906 - 268.8981626871168 - 335.28456960982425 - 0.300968256292766'\n",
      "462 - random_37 - knn_tta_r_n=50 - 302.2432064914032 - 475.4462990464819 - 481.75859104652653 - 195.20249597043644 - 222.98207920276695 - 335.5568797845639 - 0.3004005192910334'\n",
      "463 - random_25 - knn_ttm_r_n=100 - 306.59695169156277 - 463.77559721254806 - 478.65089602623374 - 209.12268229864412 - 221.2936570488227 - 335.9169211630582 - 0.2996498723020936'\n",
      "464 - random_75 - knn_ttm_n=10 - 357.6308743826537 - 388.0182475787093 - 367.78021996139506 - 273.70175591600116 - 292.50755270410923 - 335.9404081538871 - 0.29960090448895293'\n",
      "465 - random_80 - knn_tta_r_n=100 - 307.31436523834606 - 476.54631204686973 - 476.8351233995472 - 200.07550673825972 - 219.42388451310828 - 336.06934904191513 - 0.29933207680655083'\n",
      "466 - random_74 - knn_ttm_n=20 - 322.0216746712017 - 444.7463846924099 - 402.38682866741755 - 250.06306015172345 - 264.19827815683163 - 336.7023386499194 - 0.2980123625413025'\n",
      "467 - random_37 - knn_ttm_r_n=100 - 301.77594788600953 - 476.0359311857093 - 489.7029101220922 - 194.15042936375198 - 223.0376028362723 - 336.9713686825062 - 0.29745146427805225'\n",
      "468 - random_54 - knn_tta_n=20 - 322.72254153122776 - 474.96966160072344 - 424.1388267630103 - 232.84858519326883 - 232.61804900608755 - 337.4846681160481 - 0.2963812909667951'\n",
      "469 - random_25 - knn_tta_n=100 - 308.1391532316666 - 477.25397511624567 - 469.257118388439 - 210.52397819342326 - 222.5211559453086 - 337.568121299007 - 0.29620730018615904'\n",
      "470 - random_25 - knn_ttm_r_n=50 - 308.429622000237 - 462.8797713035365 - 485.10086521517513 - 210.9285614289703 - 221.15702816592372 - 337.7283683206746 - 0.2958732026310268'\n",
      "471 - random_80 - knn_tta_r_n=50 - 308.25489396261884 - 478.9043711294609 - 482.20047397667565 - 200.73962884656908 - 220.7747085309573 - 338.2053967476988 - 0.29487865041071826'\n",
      "472 - random_40 - knn_ttm_n=20 - 320.4742309361906 - 470.91470641161476 - 398.4811037805802 - 241.94875571510622 - 259.54426142922847 - 338.293618759568 - 0.2946947171421457'\n",
      "473 - random_54 - knn_tta_r_n=5 - 321.5831647220591 - 464.85862285947707 - 456.88109093030033 - 221.2318617565915 - 231.44338340899392 - 339.22671269951957 - 0.2927493180900924'\n",
      "474 - random_37 - knn_tta_n=100 - 307.48455054099634 - 487.4728312181435 - 484.0195919649337 - 195.3806317117601 - 226.4995948487499 - 340.2024568160134 - 0.29071499807364043'\n",
      "475 - random_80 - knn_ttm_r_n=100 - 310.7302218589202 - 480.97909381253237 - 490.4355509261285 - 199.9002356383678 - 219.64211078923498 - 340.36877976317703 - 0.290368232876812'\n",
      "476 - random_37 - knn_ttm_r_n=50 - 304.14814124860055 - 481.80766765040266 - 498.44773265444405 - 195.62356535401258 - 223.40598987858186 - 340.71810185852627 - 0.2896399344236157'\n",
      "477 - random_71 - knn_tta_n=5 - 388.5667499477566 - 360.7309408644425 - 405.8329012304925 - 268.8624646954923 - 282.1374722746815 - 341.2418807065255 - 0.28854791267665625'\n",
      "478 - random_81 - knn_tta_n=20 - 317.81343116474574 - 482.8092287830599 - 466.04842295969115 - 213.07979127386105 - 227.51749726720715 - 341.4827526600524 - 0.28804572093583125'\n",
      "479 - random_25 - knn_tta_r_n=10 - 312.65692901306016 - 461.86484009061576 - 487.62541651224217 - 217.4546284570948 - 228.27716985230103 - 341.6042883001547 - 0.2877923323873449'\n",
      "480 - random_25 - knn_tta_n=50 - 312.58794614855526 - 479.5488635219735 - 477.2825941213641 - 215.0706306995667 - 223.796318515327 - 341.68660548579123 - 0.2876207100371738'\n",
      "481 - random_37 - knn_tta_r_n=20 - 305.9582488732369 - 482.5507251721882 - 495.43500996256415 - 199.5509256036313 - 225.41056142017584 - 341.81212753185895 - 0.28735901026721855'\n",
      "482 - random_39 - knn_ttm_n=100 - 310.47748082301047 - 475.719137473072 - 447.3660984605116 - 228.09466760551436 - 248.73096075733415 - 342.10254958427316 - 0.28675351197677723'\n",
      "483 - random_82 - knn_tta_n=10 - 327.24116492963356 - 448.8841321928689 - 438.7796857951789 - 240.51377635646315 - 256.33404519381423 - 342.373104191352 - 0.28618943514206197'\n",
      "484 - random_57 - knn_ttm_n=50 - 301.83292879502164 - 491.23369120110954 - 454.071312516571 - 219.04407047238863 - 248.24113161038633 - 342.91084605407144 - 0.2850683020329583'\n",
      "485 - random_80 - knn_ttm_r_n=50 - 311.6939337183882 - 486.0648496968857 - 498.06807251997367 - 200.12494153782615 - 221.18824063360645 - 343.45987403596115 - 0.28392363859684777'\n",
      "486 - random_80 - knn_tta_r_n=20 - 309.5301593956098 - 488.8840072053858 - 494.065212462429 - 202.6882476883098 - 222.77103317001252 - 343.6191391826106 - 0.2835915881439931'\n",
      "487 - random_80 - knn_tta_n=100 - 307.99814703012186 - 494.6191311880916 - 490.56493809848104 - 202.58188914944313 - 222.4786228555802 - 343.6800153126483 - 0.28346466805524584'\n",
      "488 - random_25 - knn_ttm_r_n=20 - 312.14615720913645 - 469.7666437902092 - 496.5630310768888 - 215.99389117418653 - 225.8148737101577 - 344.08647718329536 - 0.2826172394052501'\n",
      "489 - random_47 - knn_ttm_r_n=100 - 320.602577753836 - 479.2156626628554 - 487.0412791399935 - 214.7290142852873 - 224.97368321165888 - 345.3425552779198 - 0.2799984536324971'\n",
      "490 - random_47 - knn_tta_r_n=100 - 317.70637787046536 - 477.6630480562232 - 491.259650701648 - 214.62154962958974 - 225.41377484009774 - 345.3629570749954 - 0.2799559181116973'\n",
      "491 - random_57 - knn_ttm_r_n=5 - 307.824715692376 - 480.2254307282033 - 466.59265582570663 - 225.535733618266 - 247.0655848990322 - 345.4750207601557 - 0.27972227755575096'\n",
      "492 - random_81 - knn_ttm_r_n=5 - 310.4454257309626 - 471.7811409519948 - 501.863077912578 - 215.77962047508836 - 229.45602171516086 - 345.8946378770806 - 0.27884742165267506'\n",
      "493 - random_71 - knn_ttm_n=10 - 371.6747030986597 - 373.6028327013587 - 423.26293525065745 - 271.20748210046344 - 290.0811932870307 - 345.98150707272794 - 0.2786663088583151'\n",
      "494 - random_47 - knn_tta_r_n=50 - 319.36690316369345 - 481.6284588091771 - 489.356131168507 - 214.97305327536031 - 225.59334469457824 - 346.2137955219721 - 0.2781820127873472'\n",
      "495 - random_57 - knn_tta_n=10 - 312.6936292646631 - 479.5746345393936 - 438.7003505851489 - 243.57511797199973 - 260.499257195989 - 347.03139196167945 - 0.2764774134210163'\n",
      "496 - random_8 - knn_ttm_r_n=10 - 310.61150558192367 - 482.8884090226983 - 493.40865410070785 - 218.5925409104838 - 232.7357170664113 - 347.67664248425444 - 0.27513213648671386'\n",
      "497 - random_37 - knn_tta_n=50 - 313.0877312743999 - 498.80638013912755 - 494.6500752002678 - 202.15578893079584 - 230.1864470023034 - 347.8088712528189 - 0.2748564539321441'\n",
      "498 - random_78 - knn_tta_n=10 - 294.3062020690598 - 468.42453165843733 - 454.8008606679423 - 263.5201303242996 - 258.9986362853912 - 348.03089319920105 - 0.2743935623994338'\n",
      "499 - random_32 - knn_ttm_r_n=100 - 321.7651851362642 - 478.4135710583004 - 475.1264629462937 - 228.49615715259412 - 237.58432439424897 - 348.3047980997061 - 0.2738225005684858'\n",
      "500 - random_10 - knn_ttm_r_n=5 - 345.8814278272511 - 455.44300052592484 - 471.8972760837678 - 227.68409006590582 - 240.56235235336075 - 348.32103136528065 - 0.2737886559810244'\n",
      "501 - random_47 - knn_ttm_r_n=50 - 324.3520906071171 - 483.91773155718346 - 492.9180124945137 - 215.15407783683207 - 225.55770033229902 - 348.41064956270435 - 0.27360181181791277'\n",
      "502 - random_32 - knn_tta_r_n=100 - 319.1675310409288 - 479.2458413421677 - 480.1559238979138 - 229.3161939543725 - 236.9852513374733 - 349.001947048681 - 0.27236902107793626'\n",
      "503 - random_39 - knn_ttm_n=50 - 316.9771692332638 - 483.17357850524917 - 451.2377079065866 - 235.63258939866796 - 258.1508651327038 - 349.05889725304775 - 0.27225028611584345'\n",
      "504 - random_10 - knn_tta_n=10 - 354.04927253071025 - 462.0717968525675 - 418.8860514743087 - 255.36296367324599 - 258.68588693150696 - 349.8334640078141 - 0.2706353989475133'\n",
      "505 - random_8 - knn_tta_n=20 - 308.4203246571196 - 482.91444354814104 - 485.0355314334771 - 225.26569306659724 - 248.68689621110047 - 350.09172005693273 - 0.27009696326421173'\n",
      "506 - random_37 - knn_ttm_r_n=20 - 307.85168495100527 - 495.8822879568658 - 521.0316542211349 - 199.88960718374312 - 226.33304521442395 - 350.23055794064555 - 0.2698075014256984'\n",
      "507 - random_80 - knn_tta_n=50 - 308.9515554569276 - 504.40060252767967 - 503.64802644017226 - 207.8377647670932 - 227.86095646968573 - 350.571628107114 - 0.26909640734382523'\n",
      "508 - random_94 - knn_ttm_n=100 - 299.58594832629836 - 482.02010758319847 - 509.20751284401297 - 211.94736005081748 - 249.95578830221174 - 350.57204659405346 - 0.2690955348442189'\n",
      "509 - random_82 - knn_ttm_r_n=5 - 329.94725189404414 - 448.3040620869754 - 481.95624079207494 - 245.80604308568925 - 247.3395716994952 - 350.6956183893995 - 0.26883790113422057'\n",
      "510 - random_37 - knn_tta_r_n=10 - 308.32543568011795 - 495.9409881922605 - 512.4802782936075 - 207.21447410005948 - 230.32646290490067 - 350.8892299965153 - 0.2684342420589412'\n",
      "511 - random_80 - knn_ttm_r_n=20 - 314.90308554478474 - 497.73310993649494 - 514.4664625331244 - 203.91254574761504 - 223.3166665455667 - 350.8993158034864 - 0.2684132142518999'\n",
      "512 - random_94 - knn_ttm_r_n=5 - 328.6962184154034 - 449.5292531527925 - 482.88926578907564 - 238.16985353958995 - 256.9074470227086 - 351.26329652122416 - 0.2676543541704708'\n",
      "513 - random_80 - knn_tta_r_n=10 - 312.65097339023396 - 500.9881153397447 - 508.57603899938863 - 209.85655495247366 - 225.52037875859446 - 351.55053275980976 - 0.267055497954248'\n",
      "514 - random_39 - knn_ttm_r_n=5 - 308.36337939867735 - 469.6788979103359 - 481.5784373319315 - 249.8479462667979 - 250.20520397996268 - 351.9592319233839 - 0.26620340479261695'\n",
      "515 - random_94 - knn_tta_n=10 - 314.0775924563653 - 452.06294448291186 - 483.77439830233453 - 239.52506385876006 - 271.40196871866743 - 352.1916036627578 - 0.2657189350708167'\n",
      "516 - random_78 - knn_ttm_r_n=5 - 305.7833394555771 - 487.1314048214984 - 472.9052151982139 - 244.99927604779597 - 250.52028144149702 - 352.2929863461502 - 0.2655075632381195'\n",
      "517 - random_32 - knn_ttm_r_n=50 - 324.70671452123867 - 482.0525019371443 - 483.92036421108435 - 231.36091284968865 - 239.90255155111097 - 352.41663178539955 - 0.2652497759886183'\n",
      "518 - random_99 - knn_ttm_r_n=5 - 333.4932768562897 - 471.05642323901884 - 488.48722077602923 - 236.6517948759253 - 232.71287560599663 - 352.5085909174849 - 0.26505805123216364'\n",
      "519 - random_10 - knn_ttm_n=100 - 336.93328657001194 - 512.3933453547163 - 460.5185783259384 - 213.51641225151957 - 239.10216131551093 - 352.5230420077444 - 0.26502792228577554'\n",
      "520 - random_10 - knn_ttm_n=50 - 341.82579629899516 - 498.3707691719508 - 452.7194407997288 - 226.77945552083386 - 243.1036511642749 - 352.5880521049569 - 0.26489238332653886'\n",
      "521 - random_94 - knn_ttm_n=50 - 303.5974628412156 - 475.7129070130614 - 505.7243946315558 - 217.29010427019733 - 263.0052307683898 - 353.09312139351607 - 0.2638393689695544'\n",
      "522 - random_8 - knn_tta_r_n=5 - 313.3429429011393 - 489.0751351121684 - 496.3387823270865 - 227.93466976202927 - 239.8928438669073 - 353.34553268849703 - 0.2633131189608908'\n",
      "523 - random_32 - knn_tta_r_n=50 - 325.44931670742005 - 480.9188941383576 - 489.0237089340494 - 232.9294748270744 - 239.10662810880876 - 353.51379788361373 - 0.2629623043890047'\n",
      "524 - random_39 - knn_tta_n=10 - 324.8445110593571 - 471.9222185079227 - 460.2850969625149 - 250.32141386060698 - 262.8756670673125 - 354.07317072495886 - 0.2617960730496891'\n",
      "525 - random_14 - knn_ttm_n=5 - 349.6226006879403 - 421.9973473653904 - 419.39298637227915 - 288.7446266988633 - 292.0635544988541 - 354.3795741705135 - 0.2611572552983288'\n",
      "526 - random_82 - knn_ttm_n=50 - 327.84710209214603 - 503.0512353685403 - 471.30188434606055 - 225.64836221136488 - 244.88326694014043 - 354.57499867013735 - 0.2607498165399804'\n",
      "527 - random_24 - knn_ttm_r_n=5 - 341.6288268839791 - 457.5496903338632 - 491.2401124811061 - 240.66875851416643 - 244.5044509615349 - 355.1453765384214 - 0.2595606409202894'\n",
      "528 - random_73 - knn_tta_n=5 - 337.19233893107787 - 401.4098841720732 - 439.6007436563697 - 302.0552930352527 - 295.53999796763316 - 355.17317897503045 - 0.2595026758735687'\n",
      "529 - random_54 - knn_ttm_r_n=5 - 325.0163630976279 - 487.78087930949664 - 490.4783076893207 - 233.90274139063473 - 241.16386926462067 - 355.69678571492017 - 0.25841101295323843'\n",
      "530 - random_34 - knn_ttm_n=5 - 366.24150973281206 - 366.44881364972684 - 395.8478349956905 - 326.617158871869 - 324.3625867099624 - 355.9108803739157 - 0.25796464894975857'\n",
      "531 - random_47 - knn_tta_r_n=20 - 324.543438825939 - 492.40893928949265 - 517.4451253276758 - 216.31646776747945 - 228.8944076277879 - 355.9536729446988 - 0.25787543110890465'\n",
      "532 - random_47 - knn_ttm_r_n=20 - 335.4217438983489 - 492.54202530562446 - 504.7148593895521 - 217.32345089662832 - 229.76124064769164 - 355.9844437751403 - 0.2578112772849339'\n",
      "533 - random_25 - knn_ttm_r_n=10 - 320.80392459802647 - 482.54088747759357 - 524.4866931366745 - 225.64289729835943 - 231.5672013724416 - 357.0391387944857 - 0.2556123532506118'\n",
      "534 - random_82 - knn_ttm_n=100 - 325.4106631796486 - 510.45396025694293 - 489.61798283080503 - 222.3238061936023 - 237.2977414134047 - 357.05136240981926 - 0.25558686834639777'\n",
      "535 - random_25 - knn_tta_n=20 - 325.9310287648029 - 498.41690266870444 - 496.33478537547757 - 231.46638213691418 - 234.62677687965413 - 357.3850104214785 - 0.2548912486474475'\n",
      "536 - random_24 - knn_tta_n=10 - 367.93801141114614 - 446.44536310654337 - 462.17255335901757 - 252.9759073688002 - 258.5329565918366 - 357.6374053916827 - 0.2543650326741622'\n",
      "537 - random_40 - knn_tta_n=5 - 333.4607425036672 - 489.89877523025694 - 408.178811375342 - 269.66822113371603 - 288.67587678087654 - 357.995399226072 - 0.25361865459126753'\n",
      "538 - random_0 - knn_ttm_n=20 - 358.1524194016991 - 465.6881881153039 - 438.91039241035435 - 247.53099176056145 - 279.70601504820144 - 358.0202532368059 - 0.2535668366907847'\n",
      "539 - random_29 - knn_ttm_n=5 - 367.9834840469325 - 423.04573797472784 - 381.44557119280137 - 308.9328627915199 - 309.5715853159068 - 358.20759520406574 - 0.2531762491305054'\n",
      "540 - random_74 - knn_tta_n=5 - 341.60123801075423 - 455.9994710679944 - 420.5892132214726 - 276.5109723498179 - 297.40039963681585 - 358.43741104094573 - 0.25269710818652247'\n",
      "541 - random_32 - knn_ttm_r_n=20 - 331.71914264854 - 489.82543710559617 - 491.5614377526738 - 236.790025491151 - 244.15560073430407 - 358.8387308862907 - 0.2518604000982192'\n",
      "542 - random_81 - knn_tta_n=10 - 341.58252852365734 - 494.43562409611604 - 473.6498107392373 - 236.78387800108908 - 252.71041123053573 - 359.8600720964067 - 0.24973101511680396'\n",
      "543 - random_25 - knn_tta_r_n=5 - 324.0543026852424 - 488.41556608642884 - 521.2420264214667 - 227.685475311877 - 240.23182559569923 - 360.35616855862037 - 0.24869670812369726'\n",
      "544 - random_32 - knn_tta_r_n=20 - 338.0915207238779 - 487.8211791857218 - 499.39034199943524 - 238.14771169201813 - 242.86909804817066 - 361.29295282485486 - 0.246743615144007'\n",
      "545 - random_91 - knn_ttm_n=20 - 354.74255199135314 - 497.02458736930953 - 444.20207484934946 - 254.1430975205309 - 258.7996627508523 - 361.8076705508478 - 0.245670484847744'\n",
      "546 - random_77 - knn_ttm_n=5 - 366.7813601018129 - 393.16155697442923 - 385.44378854325726 - 316.6241618985889 - 349.11796620120583 - 362.23281215432183 - 0.2447841109930068'\n",
      "547 - random_78 - knn_ttm_n=100 - 291.14474203732453 - 545.7802830957863 - 512.6983275789869 - 224.78344407366666 - 236.94612981729227 - 362.30212397376744 - 0.2446396034122882'\n",
      "548 - random_37 - knn_ttm_r_n=10 - 313.053598260178 - 515.3350082393298 - 548.2594745797478 - 206.5092370708498 - 231.68339716391222 - 363.00267368225514 - 0.2431790337092219'\n",
      "549 - random_78 - knn_ttm_n=50 - 291.7698165164171 - 536.3133012917253 - 498.5344404191312 - 240.95853391027987 - 247.90908232820516 - 363.12551520679 - 0.24292292253418268'\n",
      "550 - random_99 - knn_tta_n=10 - 337.4142314999631 - 484.7883987057032 - 468.70925538758144 - 260.69581277523423 - 264.43850549684055 - 363.23339583886 - 0.2426980031875039'\n",
      "551 - random_99 - knn_ttm_n=100 - 310.42161156754435 - 528.0903847076488 - 529.4171889647528 - 214.93992702285863 - 235.91131933622685 - 363.78928695898554 - 0.24153903085702977'\n",
      "552 - random_80 - knn_ttm_r_n=10 - 318.5687314653742 - 515.5316611602271 - 540.419000619142 - 213.079825074068 - 231.56114409312028 - 363.8660366220476 - 0.24137901618393676'\n",
      "553 - random_73 - knn_ttm_n=10 - 344.3950348773103 - 427.17799773892216 - 452.86018711669624 - 302.1707653078176 - 298.4272268618809 - 365.0217727408508 - 0.23896943248214997'\n",
      "554 - random_54 - knn_tta_n=10 - 351.1089017195125 - 490.7624602977174 - 458.1535768718432 - 265.2298448076521 - 260.2478074472658 - 365.1250860176141 - 0.23875403557292751'\n",
      "555 - random_47 - knn_ttm_r_n=10 - 346.7990077094017 - 507.02128932647304 - 519.2131774947817 - 222.54691341678236 - 235.93222608837402 - 366.33541923175267 - 0.23623062288462326'\n",
      "556 - random_47 - knn_tta_r_n=10 - 336.87304112568916 - 497.96447080373275 - 543.4435819272387 - 219.21245463161458 - 234.4791048477747 - 366.4280237071542 - 0.23603755265776982'\n",
      "557 - random_24 - knn_ttm_n=50 - 349.6519515284755 - 503.41437635852066 - 504.30407000040066 - 235.62804721663645 - 241.2859721903704 - 366.8877006612701 - 0.23507917636520248'\n",
      "558 - random_18 - knn_ttm_n=5 - 356.33740628375375 - 405.93131873786115 - 429.9998248656382 - 322.5290026027137 - 319.8814613560311 - 366.94677854522024 - 0.23495600542333595'\n",
      "559 - random_47 - knn_tta_n=100 - 329.439634760077 - 516.0881873071571 - 547.489717695452 - 217.68583403715013 - 230.59889898758004 - 368.2950442822031 - 0.23214501847514257'\n",
      "560 - random_37 - knn_tta_n=20 - 331.3181960085219 - 527.8949139737892 - 526.1613145642983 - 215.4451009369728 - 244.24877421224082 - 369.04706128858606 - 0.23057714507171945'\n",
      "561 - random_4 - knn_ttm_n=5 - 383.7000253502075 - 378.2499676604293 - 394.71690569252485 - 339.6750538384039 - 351.18646263799735 - 369.51146124899265 - 0.22960892182637793'\n",
      "562 - random_99 - knn_ttm_n=50 - 322.7758739369879 - 521.1111445785796 - 521.0855045499876 - 234.14843093118412 - 249.64719177054934 - 369.78431577719533 - 0.22904004990707094'\n",
      "563 - random_24 - knn_ttm_n=100 - 342.34864715734597 - 520.5618583408988 - 531.9626023274731 - 224.41463455565767 - 233.77313653072093 - 370.6461415307066 - 0.2272432372474551'\n",
      "564 - random_37 - knn_tta_r_n=5 - 318.75500601291895 - 527.3927146899023 - 544.1009673959005 - 219.37507778346395 - 243.87827122723206 - 370.73378645294474 - 0.22706050714779524'\n",
      "565 - random_82 - knn_ttm_n=20 - 348.1290761222183 - 511.3363025560845 - 474.81227433813507 - 250.6203792041861 - 269.3008383070266 - 370.8663861696966 - 0.22678405120672995'\n",
      "566 - random_32 - knn_ttm_r_n=10 - 348.73252743982505 - 504.42407274424875 - 508.95060041045724 - 243.13522354100294 - 249.4014544093695 - 370.9586954105849 - 0.22659159651162275'\n",
      "567 - random_80 - knn_tta_n=20 - 318.8800950501809 - 542.3150507761864 - 533.1510525007744 - 220.68729862231405 - 241.74417362135333 - 371.38916901107586 - 0.2256941060248958'\n",
      "568 - random_54 - knn_ttm_n=100 - 331.82617854683514 - 565.2889154749615 - 506.4926498823351 - 215.80300610566422 - 242.5460146010132 - 372.4257263393151 - 0.2235329970974712'\n",
      "569 - random_40 - knn_ttm_n=10 - 350.7436445045647 - 511.57180604149596 - 429.74086948811646 - 272.5630417373831 - 297.4939239709214 - 372.4436325893446 - 0.2234956645199655'\n",
      "570 - random_80 - knn_tta_r_n=5 - 318.53789569121795 - 533.9211818282406 - 547.334444690539 - 226.08676028530297 - 237.43813351303285 - 372.6975008510853 - 0.22296637689458199'\n",
      "571 - random_74 - knn_ttm_n=10 - 356.0160700926349 - 479.14377888733515 - 434.25370452871664 - 288.6834603573825 - 310.36963390956817 - 373.71113029493824 - 0.2208530701043706'\n",
      "572 - random_32 - knn_tta_n=100 - 337.6383073241351 - 510.99871733081 - 544.2520865708847 - 237.56803016586917 - 242.40163499396343 - 374.6040574306659 - 0.21899141445640102'\n",
      "573 - random_39 - knn_ttm_n=20 - 342.22870295614325 - 506.02761736993784 - 481.25333515719535 - 263.24690905826293 - 280.66328114520087 - 374.70862505335316 - 0.21877340237279252'\n",
      "574 - random_54 - knn_ttm_n=50 - 347.2303769077824 - 560.3146828337028 - 491.1817347225318 - 225.9275812644597 - 254.95825335221681 - 375.9550422228368 - 0.21617475857482493'\n",
      "575 - random_94 - knn_ttm_n=20 - 328.3905690027272 - 495.5732384412855 - 523.3580628766584 - 244.31304390328526 - 288.7636223470891 - 376.10599829565365 - 0.2158600316342827'\n",
      "576 - random_10 - knn_ttm_n=20 - 364.0212014527718 - 519.3610593126356 - 462.1874715119809 - 266.11970612011163 - 269.9055843926866 - 376.3449991240524 - 0.2153617409851858'\n",
      "577 - random_47 - knn_tta_n=50 - 339.483236682816 - 519.9220877978794 - 565.634268071975 - 221.2284348815374 - 236.41931451283423 - 376.5729210700018 - 0.21488654859714473'\n",
      "578 - random_32 - knn_tta_r_n=10 - 358.03522280891605 - 517.4319605086628 - 515.172474983208 - 245.19793089113122 - 248.14148457868868 - 376.8270462690665 - 0.214356725285476'\n",
      "579 - random_0 - knn_tta_n=5 - 385.8146957643144 - 453.8608828928616 - 451.08034136248597 - 290.8134333301681 - 303.3211282489505 - 376.99727568265786 - 0.21400181553239217'\n",
      "580 - random_57 - knn_ttm_n=20 - 329.9673451236044 - 530.9176391257314 - 484.905510885039 - 260.48072159969814 - 279.74661208319156 - 377.22926836729835 - 0.21351813609835113'\n",
      "581 - random_75 - knn_ttm_n=5 - 397.91734714696184 - 423.4088164863832 - 426.800140870362 - 306.5727431059645 - 331.54830008171064 - 377.26343544441943 - 0.2134469014706285'\n",
      "582 - random_32 - knn_tta_n=50 - 340.97688381677847 - 527.0167276864559 - 519.9116180683505 - 251.42024362212072 - 247.0270880220661 - 377.3012447155943 - 0.2133680732657146'\n",
      "583 - random_8 - knn_ttm_r_n=5 - 343.41085175547437 - 528.4329806321524 - 541.9448368702027 - 234.7517698919158 - 247.55103707310073 - 379.25143262408733 - 0.2093021442674995'\n",
      "584 - random_8 - knn_ttm_n=100 - 317.0402575172823 - 531.5631713542085 - 567.9862680688898 - 221.76409500010735 - 257.8499980955906 - 379.27422343658316 - 0.2092546279102213'\n",
      "585 - random_91 - knn_tta_n=5 - 391.8132889432148 - 494.054199475296 - 447.609893102771 - 291.23688979842467 - 273.35202916878035 - 379.6366175441426 - 0.20849907573789395'\n",
      "586 - random_78 - knn_ttm_n=20 - 313.2170545986921 - 542.5266773449289 - 505.8634483994033 - 278.5950405871134 - 271.9669529981946 - 382.45955249549314 - 0.2026135643834316'\n",
      "587 - random_8 - knn_tta_n=10 - 330.6928962341949 - 531.6522655655984 - 531.5567129535908 - 252.3022784533167 - 272.6167388931553 - 383.7932927052819 - 0.19983286157451308'\n",
      "588 - random_71 - knn_ttm_n=5 - 434.651807778722 - 397.96354305130353 - 454.00332307130407 - 312.29913696899683 - 331.7566303974853 - 386.15027455011113 - 0.194918811605573'\n",
      "589 - random_24 - knn_ttm_n=20 - 379.62763868766723 - 505.267087564932 - 509.10419603923447 - 262.4892987328184 - 278.7557056378701 - 387.07672875819674 - 0.19298725566997876'\n",
      "590 - random_47 - knn_tta_r_n=5 - 361.8995889932707 - 524.836707546712 - 572.3740589056198 - 230.95141915955688 - 247.39071866011957 - 387.5260967401177 - 0.19205037245959444'\n",
      "591 - random_25 - knn_ttm_r_n=5 - 343.00576826805514 - 525.200428587263 - 574.9330527867995 - 246.02799870493297 - 250.01033159442616 - 387.8690732547873 - 0.1913353038497293'\n",
      "592 - random_47 - knn_tta_n=20 - 365.6044436738877 - 548.3632208826281 - 543.5200738464248 - 235.40061922749 - 247.8926414656259 - 388.1913635224328 - 0.19066336380776938'\n",
      "593 - random_37 - knn_ttm_r_n=5 - 327.71821416205876 - 555.2072803223989 - 593.4873207748012 - 220.39704908763767 - 245.27823657908073 - 388.4549608733874 - 0.19011379209294577'\n",
      "594 - random_82 - knn_tta_n=5 - 369.9460292344957 - 507.23419037013855 - 480.3416155051923 - 287.4373905676445 - 297.93224747389127 - 388.60130998503297 - 0.1898086701637658'\n",
      "595 - random_25 - knn_ttm_n=100 - 334.921047318385 - 578.0327043997286 - 576.2293344674835 - 220.06175098369303 - 234.32001216705183 - 388.75173671913245 - 0.18949504683669138'\n",
      "596 - random_25 - knn_tta_n=10 - 351.92471492315985 - 540.9996786545302 - 532.0404474491087 - 256.4215149919653 - 267.30959980158326 - 389.7698820638096 - 0.18737232488600541'\n",
      "597 - random_78 - knn_tta_n=5 - 335.2804539337247 - 517.7411770976768 - 502.7063493124197 - 306.3508415089908 - 292.5575331056777 - 390.94922540995884 - 0.1849135226910591'\n",
      "598 - random_47 - knn_ttm_n=100 - 341.0290039333153 - 584.9653889886922 - 563.3050645661947 - 226.0343685915766 - 252.39867334905637 - 393.5835405623339 - 0.17942126303657513'\n",
      "599 - random_10 - knn_tta_n=5 - 396.29261728614944 - 510.82792930823456 - 458.92729091964037 - 300.3111799538051 - 306.5825471130756 - 394.6101877390258 - 0.1772808156937994'\n",
      "600 - random_0 - knn_ttm_n=10 - 395.24734475101224 - 490.20362810947756 - 474.81474273622786 - 300.6905519179022 - 315.99730664617056 - 395.4116068963727 - 0.17560994419603704'\n",
      "601 - random_80 - knn_ttm_r_n=5 - 334.7652817951734 - 560.7041292813607 - 599.2180618049281 - 232.77466003568838 - 249.67696378041074 - 395.4648293016944 - 0.1754989812882013'\n",
      "602 - random_8 - knn_ttm_n=50 - 325.94570589541974 - 558.9989467943747 - 583.0856671578573 - 233.56673173832826 - 276.3366527206255 - 395.62049462314326 - 0.1751744360781018'\n",
      "603 - random_81 - knn_ttm_n=50 - 327.8069109286331 - 613.2250433168326 - 577.6051557166758 - 222.73251540964242 - 237.0290077853485 - 395.71951997476833 - 0.17496797902492378'\n",
      "604 - random_32 - knn_ttm_n=100 - 339.4777973781095 - 584.4629926980435 - 541.6026796514675 - 253.2225059315468 - 260.0215111769029 - 395.7908912202833 - 0.17481917776556088'\n",
      "605 - random_32 - knn_ttm_r_n=5 - 367.2686106598926 - 538.858840163582 - 551.980091341292 - 258.0798430897713 - 262.8212840774543 - 395.8342194466895 - 0.17472884314117987'\n",
      "606 - random_25 - knn_ttm_n=50 - 346.58617474167306 - 581.0764015806014 - 579.9685622606015 - 233.01767631509702 - 243.7619707207669 - 396.9201968054007 - 0.1724646988425924'\n",
      "607 - random_47 - knn_ttm_r_n=5 - 376.4599986857536 - 547.1720289020745 - 564.9096657547848 - 243.5114452103212 - 252.988522689815 - 397.04403568027874 - 0.17220650830091166'\n",
      "608 - random_81 - knn_ttm_n=100 - 318.57581050988216 - 632.7900873991887 - 597.520987028808 - 211.81281325774734 - 227.74207537237763 - 397.7310550401095 - 0.17077414789845713'\n",
      "609 - random_91 - knn_ttm_n=10 - 399.96872502259157 - 521.9410943344989 - 486.83634289675535 - 297.84319740508363 - 282.83884357471425 - 397.911452388036 - 0.170398039111739'\n",
      "610 - random_94 - knn_tta_n=5 - 359.3327219524234 - 510.9078909653292 - 533.2365502279096 - 281.63347706677314 - 306.7925595379424 - 398.4056411793202 - 0.16936770940436852'\n",
      "611 - random_81 - knn_tta_n=5 - 376.9680858194251 - 538.5063562266637 - 509.941264194917 - 286.2147950094548 - 281.9599143435065 - 398.7455955941185 - 0.16865894154298433'\n",
      "612 - random_57 - knn_tta_n=5 - 352.8688922159334 - 549.6946850970944 - 493.23398961453813 - 291.7870542479826 - 310.94858435383674 - 399.7302433672007 - 0.16660605837405096'\n",
      "613 - random_39 - knn_tta_n=5 - 368.41654659700595 - 535.0494326123762 - 499.39109132416775 - 295.5189650960891 - 302.31607192983483 - 400.1627155003741 - 0.16570440116474738'\n",
      "614 - random_99 - knn_ttm_n=20 - 355.7343633497235 - 544.8491156577278 - 536.094368298427 - 279.08528200998063 - 288.5782769844728 - 400.89637114408475 - 0.16417480919903138'\n",
      "615 - random_82 - knn_ttm_n=10 - 381.41686105957257 - 540.6914803606863 - 496.07118089080535 - 290.4350017137815 - 303.98276955974103 - 402.5447342654786 - 0.16073815194888852'\n",
      "616 - random_37 - knn_tta_n=10 - 350.549011035631 - 579.9563728549695 - 574.0153244232844 - 246.73054602651362 - 267.8787306944729 - 403.86116353971073 - 0.15799354055175618'\n",
      "617 - random_24 - knn_tta_n=5 - 417.43112214886537 - 485.61628177272974 - 519.6824646759399 - 293.89974961377897 - 305.73018499422926 - 404.4970793242569 - 0.1566677255277018'\n",
      "618 - random_37 - knn_ttm_n=100 - 334.1290377039077 - 612.4514404432464 - 618.7428962461104 - 212.0869437851023 - 247.60202980855644 - 405.0445091948407 - 0.15552639397928936'\n",
      "619 - random_80 - knn_ttm_n=100 - 331.47987524502065 - 610.0074628191546 - 635.393580645414 - 211.99046924273182 - 239.23972270713182 - 405.6654255703058 - 0.15423185108653759'\n",
      "620 - random_80 - knn_tta_n=10 - 342.61941564986705 - 599.7702959918915 - 581.4462587850788 - 243.9274633460924 - 263.24039988722797 - 406.2373962376395 - 0.15303935465462326'\n",
      "621 - random_81 - knn_ttm_n=20 - 354.5291366755381 - 597.1771868703213 - 563.9461631278664 - 248.42493900083807 - 270.1772639770549 - 406.8863513076048 - 0.1516863541432265'\n",
      "622 - random_54 - knn_ttm_n=20 - 379.6554639588607 - 585.5151387260549 - 512.6389535856869 - 272.53526136029336 - 289.23414429402135 - 407.9462810660246 - 0.14947651624911285'\n",
      "623 - random_73 - knn_ttm_n=5 - 403.84828954964894 - 462.6944367509278 - 499.5654565713889 - 343.6016232977552 - 336.184767377397 - 409.1955439472423 - 0.14687193945268406'\n",
      "624 - random_32 - knn_tta_r_n=5 - 400.0580770650459 - 548.9340498458062 - 579.9387976401897 - 256.9402941738174 - 260.71351641875293 - 409.3530660835005 - 0.14654352298631002'\n",
      "625 - random_39 - knn_ttm_n=10 - 381.6170379532164 - 544.2135757941317 - 517.6554443634376 - 301.8269310260093 - 308.4863309759013 - 410.785209812296 - 0.14355765957737254'\n",
      "626 - random_47 - knn_ttm_n=50 - 353.4984105927534 - 619.2709363868154 - 578.8940196793042 - 236.1139403923341 - 267.0359049075931 - 411.0008969746814 - 0.14310797537808784'\n",
      "627 - random_10 - knn_ttm_n=10 - 404.2035823384959 - 549.8600046353224 - 480.04355445838576 - 309.78148148200125 - 314.7798061595413 - 411.7575554996153 - 0.14153042491493628'\n",
      "628 - random_99 - knn_tta_n=5 - 385.5264073423482 - 537.4454173563457 - 527.8757058652548 - 304.401447823143 - 308.75272065083436 - 412.82583440870616 - 0.13930317995267505'\n",
      "629 - random_78 - knn_ttm_n=10 - 348.1300533826485 - 558.3481318969758 - 533.9979935296935 - 318.69635633776164 - 308.44759587464125 - 413.5480156559458 - 0.13779751085159453'\n",
      "630 - random_94 - knn_ttm_n=10 - 369.636623246078 - 541.9970883783267 - 554.2915084467518 - 290.2307979082914 - 318.32013047603846 - 414.92177949680917 - 0.13493336313898674'\n",
      "631 - random_32 - knn_ttm_n=50 - 354.3099554419606 - 612.7037356664459 - 568.8298119474701 - 271.6929184609513 - 276.18836848611835 - 416.77923240705195 - 0.131060776493523'\n",
      "632 - random_57 - knn_ttm_n=10 - 365.60337269270883 - 578.4669308320542 - 525.7285205059511 - 304.1579933617839 - 319.3608345077419 - 418.68918839431547 - 0.12707872666124287'\n",
      "633 - random_74 - knn_ttm_n=5 - 400.79685401914185 - 533.343987941417 - 474.06226618620445 - 341.8518234545267 - 350.50965401283986 - 420.1306615554167 - 0.12407341240391101'\n",
      "634 - random_54 - knn_tta_n=5 - 403.40470398567044 - 563.5845676452215 - 514.9328641893853 - 316.6685831377579 - 309.5011563840366 - 421.64442415165144 - 0.12091738256204809'\n",
      "635 - random_47 - knn_tta_n=10 - 390.32026961821236 - 588.2487267596258 - 602.0295382508606 - 257.09965978634983 - 273.75970460318916 - 422.32922816500815 - 0.11948964091526881'\n",
      "636 - random_24 - knn_ttm_n=10 - 424.8239467358271 - 519.0589064022306 - 551.9607891787797 - 298.3039391108517 - 322.81392765056864 - 423.41938290731963 - 0.1172167872276818'\n",
      "637 - random_40 - knn_ttm_n=5 - 394.22851063837714 - 583.36890482408 - 476.4389131614779 - 315.49440359456963 - 347.62398500661 - 423.45299354682163 - 0.1171467127116802'\n",
      "638 - random_80 - knn_ttm_n=50 - 338.46713978866956 - 640.7601074546435 - 653.4659536440181 - 227.8034414732669 - 256.7727510239043 - 423.4973602039444 - 0.11705421307256147'\n",
      "639 - random_32 - knn_tta_n=20 - 345.92318322124163 - 627.7610054364866 - 622.9549944582307 - 261.1469585219427 - 260.6223649843755 - 423.72077417686654 - 0.11658841931640362'\n",
      "640 - random_37 - knn_ttm_n=50 - 352.99236580971063 - 638.137354608978 - 642.1339231513484 - 229.4391785168514 - 264.21345581108073 - 425.42611095902873 - 0.11303297820012992'\n",
      "641 - random_81 - knn_ttm_n=10 - 385.61667136403736 - 598.4716243743491 - 550.5347997336011 - 294.1795569981203 - 299.5863257217847 - 425.70870763988535 - 0.11244379495553569'\n",
      "642 - random_8 - knn_ttm_n=20 - 357.44397996986504 - 606.5312457173386 - 621.8038219068135 - 271.7865856317072 - 302.17938388947505 - 431.9837966592483 - 0.09936091904440136'\n",
      "643 - random_25 - knn_ttm_n=20 - 374.0412190124394 - 627.5651721532914 - 608.5598325155906 - 268.4534854212711 - 282.51096866808274 - 432.26375559697914 - 0.09877723520641224'\n",
      "644 - random_0 - knn_ttm_n=5 - 439.37989559463966 - 531.8506564913641 - 503.4450789332109 - 368.1650449242003 - 361.52837249399147 - 440.89205692160544 - 0.08078816840502656'\n",
      "645 - random_99 - knn_ttm_n=10 - 399.4673501940564 - 581.941953075993 - 571.7143610730667 - 323.39960301559154 - 330.43655528306726 - 441.41943935983926 - 0.07968863356562683'\n",
      "646 - random_91 - knn_ttm_n=5 - 442.82519104461534 - 566.0781402320711 - 546.5330753312829 - 352.37093222317844 - 318.06612343421585 - 445.20108298820395 - 0.0718043192272384'\n",
      "647 - random_8 - knn_tta_n=5 - 378.4287717206638 - 610.3175478134077 - 617.0249089860462 - 302.2272944962425 - 321.44243215989417 - 445.92036512086395 - 0.07030469446372511'\n",
      "648 - random_25 - knn_tta_n=5 - 394.89639472842066 - 611.0140668741799 - 612.7878904366694 - 299.1550660387179 - 328.9028671288313 - 449.3837356902196 - 0.06308394472561951'\n",
      "649 - random_82 - knn_ttm_n=5 - 428.9643550420598 - 588.7374665675736 - 551.7230894615263 - 345.4168202327671 - 351.8494071579713 - 453.3633579249482 - 0.05478686659501619'\n",
      "650 - random_54 - knn_ttm_n=10 - 423.7317847648822 - 626.4932307424579 - 565.781663085675 - 323.96263503862167 - 334.08290723028387 - 454.8406344215231 - 0.051706906289833654'\n",
      "651 - random_47 - knn_ttm_n=20 - 394.3841943503436 - 691.7042664220902 - 621.0007195061409 - 265.2538972234279 - 302.9961678467881 - 455.1088769868432 - 0.0511476498099116'\n",
      "652 - random_10 - knn_ttm_n=5 - 448.88304904989695 - 586.095598124465 - 524.3307104106466 - 359.40543867871287 - 362.0592185865597 - 456.1777052799896 - 0.04891925944183928'\n",
      "653 - random_78 - knn_ttm_n=5 - 400.2739826720328 - 594.608952312962 - 570.4088784625661 - 370.9073265217991 - 345.36605382072634 - 456.33660202420873 - 0.04858797706785434'\n",
      "654 - random_81 - knn_ttm_n=5 - 426.6466990503367 - 620.7062427135736 - 564.0467918216227 - 348.2951159746196 - 324.5084186599954 - 456.86956013300755 - 0.04747681756370503'\n",
      "655 - random_32 - knn_tta_n=10 - 375.9933670505104 - 584.615159745959 - 784.426946778128 - 277.9483075297749 - 277.1681184450632 - 460.0741749817514 - 0.04079554526944351'\n",
      "656 - random_32 - knn_ttm_n=20 - 408.5588582781363 - 670.1338236883435 - 619.7123141124425 - 305.85281285972474 - 305.8835676632084 - 462.065755239982 - 0.03664331773847207'\n",
      "657 - random_39 - knn_ttm_n=5 - 443.5312223532895 - 599.3024831957501 - 563.4126221464493 - 357.5224762988016 - 347.88765850570917 - 462.3576038464773 - 0.03603484523842726'\n",
      "658 - random_37 - knn_tta_n=5 - 393.5504150800016 - 659.2703453876169 - 658.0878096164578 - 297.5986697033375 - 312.0420519849701 - 464.1480893631196 - 0.03230187830160236'\n",
      "659 - random_94 - knn_ttm_n=5 - 423.09125595088227 - 592.5203010600359 - 595.8702521213708 - 342.74424899278694 - 372.26605158192126 - 465.3242933614532 - 0.029849621304308016'\n",
      "660 - random_80 - knn_ttm_n=20 - 366.0848711354965 - 719.6502952736067 - 699.0893382029172 - 260.34676110135456 - 289.632876667438 - 467.00690336146 - 0.02634156304903923'\n",
      "661 - random_32 - knn_tta_n=5 - 420.8920108104349 - 645.5369125085655 - 631.5988729099313 - 318.87133807287626 - 325.8195078316949 - 468.57881742357426 - 0.023064293745902575'\n",
      "662 - random_24 - knn_ttm_n=5 - 482.92526821679064 - 537.5780085042381 - 604.3663956320332 - 349.22661147671874 - 372.23239646192775 - 469.29178579603257 - 0.021577832483495984'\n",
      "663 - random_80 - knn_tta_n=5 - 397.278984287027 - 692.6068653776962 - 656.8936520406985 - 300.50564731970877 - 308.0341828779116 - 471.10389853020206 - 0.01779977515793918'\n",
      "664 - random_37 - knn_ttm_n=20 - 392.4723874308866 - 705.0804938519743 - 704.4298410542026 - 266.5469919220668 - 300.15664912114966 - 473.78296701234655 - 0.012214209694059064'\n",
      "665 - random_57 - knn_ttm_n=5 - 423.8556347622608 - 648.2280846708437 - 572.557276765299 - 355.8493940023245 - 371.3458772684424 - 474.393839265551 - 0.010940607700275717'\n",
      "666 - random_89 - deep - 466.10016369833943 - 513.9313962097717 - 477.69780327076677 - 472.3927264265081 - 467.86279575306685 - 479.5992494363184 - 8.789569117728657e-05'\n",
      "667 - random_68 - deep - 466.5929696415453 - 516.1761393326803 - 477.69639091285745 - 472.39263967305675 - 467.87135232510974 - 480.14830461973656 - -0.0010568244569015839'\n",
      "668 - random_8 - knn_ttm_n=10 - 402.4218616587741 - 672.2795556261298 - 677.0028495730444 - 317.63231570312604 - 346.59008500769585 - 483.22159275608163 - -0.007464295104182117'\n",
      "669 - random_47 - knn_tta_n=5 - 439.7858421134911 - 673.9405122918769 - 700.0144419194432 - 294.30323275527115 - 318.753234316185 - 485.40237388869633 - -0.012010985813955877'\n",
      "670 - random_25 - knn_ttm_n=10 - 414.74998636259454 - 692.2906982125737 - 667.3045097992454 - 313.6791175095029 - 345.73445131523505 - 486.7894449398969 - -0.014902877608126142'\n",
      "671 - random_99 - knn_ttm_n=5 - 462.3730220394709 - 636.7523576937351 - 626.3521167244617 - 370.95119894686445 - 355.9202105029254 - 490.500270579417 - -0.022639544166941805'\n",
      "672 - random_47 - knn_ttm_n=10 - 455.06387702700147 - 758.1821260152137 - 677.1471583787802 - 312.6090952551922 - 353.3240803781407 - 511.30806080570403 - -0.06602151638684539'\n",
      "673 - random_32 - knn_ttm_n=10 - 464.1743619740846 - 725.0342422212472 - 694.6768684811187 - 344.5430804123936 - 347.37659595844906 - 515.2016397198448 - -0.07413920358247417'\n",
      "674 - random_54 - knn_ttm_n=5 - 495.2399058427535 - 685.7265478223549 - 645.5699829144503 - 381.4598836078081 - 381.0156831726202 - 517.8351774912177 - -0.07962984248239136'\n",
      "675 - random_80 - knn_ttm_n=10 - 422.01756076424044 - 783.6922937706822 - 746.9771096915438 - 313.24968425529244 - 331.44974781177984 - 519.5245917663821 - -0.08315208690892817'\n",
      "676 - random_37 - knn_ttm_n=10 - 436.89200105387835 - 773.7880691490839 - 768.1477857142111 - 332.1148807377401 - 350.58080266653167 - 532.3505393454271 - -0.10989278813270076'\n",
      "677 - random_85 - deep - 189.664187206504 - 2002.3053440581416 - 172.63422487621617 - 142.53825361931882 - 162.46052386408664 - 534.0120498519592 - -0.11335685600283818'\n",
      "678 - random_8 - knn_ttm_n=5 - 454.70023337484815 - 742.2111663736833 - 752.743652733747 - 382.83766803347197 - 408.1596580720247 - 548.1671088179186 - -0.142868609688368'\n",
      "679 - random_25 - knn_ttm_n=5 - 470.133648596972 - 762.7968250464818 - 779.5998936103649 - 363.2441781043179 - 414.08437865753467 - 558.0124202300927 - -0.1633950097305823'\n",
      "680 - random_32 - knn_ttm_n=5 - 517.8799708300053 - 811.3773763216293 - 781.539827546757 - 407.0911214486375 - 421.88014093802803 - 587.9953214158651 - -0.22590608717647376'\n",
      "681 - random_47 - knn_ttm_n=5 - 541.1362901019876 - 835.7315886117245 - 786.7648161878009 - 365.897988052414 - 428.66946088895133 - 591.6866761475022 - -0.23360215901688397'\n",
      "682 - random_80 - knn_ttm_n=5 - 500.36813353423986 - 869.5863235078115 - 830.8186399623411 - 386.0034159939778 - 392.167170425065 - 595.8383474955535 - -0.24225794077595797'\n",
      "683 - random_37 - knn_ttm_n=5 - 500.6880837485499 - 845.1829191013113 - 869.609116079784 - 385.42068679702743 - 410.38934565793306 - 602.3070769621603 - -0.25574453589089163'\n",
      "684 - random_13 - deep - 684.0451448894792 - 513.7775837898827 - 663.1098745216777 - 713.0094548073135 - 490.8966737818174 - 612.9703903896211 - -0.2779763806008002'\n",
      "685 - random_50 - deep - 160.36521464017744 - 157.49689449317168 - 2884.4273858851275 - 152.93569041386087 - 159.3630966424656 - 703.0488874300769 - -0.46578021814758475'\n",
      "686 - random_26 - deep - 466.1744460647665 - 514.5890979640986 - 477.68216640790496 - 1624.6619264893457 - 468.0707411382522 - 710.1549983181146 - -0.48059568397631747'\n",
      "687 - random_3 - deep - 2762.2157660508915 - 152.03450223651558 - 477.6611929963861 - 134.97366123268154 - 163.90448042925667 - 738.2992173620416 - -0.5392733097678863'\n",
      "688 - random_2 - deep - 148.015276594797 - 145.04986391027458 - 1801.2777444511098 - 1415.5632643682472 - 208.26263287602637 - 743.6173708804092 - -0.5503610795711924'\n",
      "689 - random_92 - deep - 2781.880973683193 - 160.88361652010417 - 161.82161745942133 - 474.5243501697554 - 153.89610513089514 - 746.7051138217261 - -0.5567986866893138'\n",
      "690 - random_58 - deep - 152.50841684804823 - 146.70903570750693 - 2853.6657045544016 - 471.6211347820378 - 152.60657100059262 - 755.5285603548361 - -0.5751946099534722'\n",
      "691 - random_53 - deep - 152.05613927949884 - 326.86451718445375 - 421.2239868402052 - 200.31568483716728 - 2693.718315793114 - 758.6705613181265 - -0.5817453391271239'\n",
      "692 - random_41 - deep - 155.9941819882636 - 192.3752413579784 - 477.6774804310378 - 181.3127581721165 - 2854.716855418925 - 772.2363557107115 - -0.6100285402239836'\n",
      "693 - random_31 - deep - 1270.8496071781738 - 159.0032286206333 - 162.1829776523638 - 1935.4499854629353 - 1409.312398518978 - 987.1952277860047 - -1.0581943335801665'\n",
      "694 - random_49 - deep - 395.3791950651465 - 602.4050220473483 - 2530.0331304832785 - 495.751736607729 - 1791.4050561142426 - 1162.9994843727166 - -1.424727025940872'\n",
      "695 - random_48 - deep - 1020.651579016472 - 1222.5734120753975 - 183.74350586349405 - 1977.4979138139631 - 2254.889812785466 - 1331.6829908161287 - -1.7764137312229638'\n",
      "696 - random_97 - deep - 665.7361578801183 - 2592.074283776057 - 2368.449622599894 - 471.79004052792993 - 1080.923870585832 - 1435.9530618911933 - -1.993805452139204'\n",
      "697 - random_38 - deep - 162.02848151835698 - 177.5097919869151 - 2554.732763701166 - 2431.4705829597465 - 2674.5695529676714 - 1599.8335232421664 - -2.3354783324807538'\n",
      "698 - random_52 - deep - 1543.3301443593118 - 164.7967505131786 - 3121.0219840797467 - 2846.5280823266808 - 2159.3965115587253 - 1966.8860678431233 - -3.1007428375758224'\n",
      "699 - random_43 - deep - 339.4360802735693 - 2904.689921634814 - 2874.169992539578 - 2686.9450581013657 - 2789.4853359556714 - 2318.8446419293336 - -3.8345380611040127'\n"
     ]
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(all_scores)\n",
    "scores_df.to_csv(log_dir/f\"scores.csv\",index=False)\n",
    "\n",
    "scores_df_sorted = pd.DataFrame(scores_df).sort_values(by='MSE')\n",
    "\n",
    "best_5 = []\n",
    "summary_logger.info(f\"Rank - \" +\" - \".join(list(scores_df_sorted.columns)))\n",
    "for i,(index,row) in enumerate(scores_df_sorted.iterrows()):\n",
    "    if i < 5:\n",
    "        best_5.append((row[\"model_num\"],row[\"predictor\"],row[\"MSE\"],row[\"R2\"]))\n",
    "    s = f\"{i} - \" + \" - \".join([f\"{i}\" for i in row.tolist()])\n",
    "    summary_logger.info(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% save scores\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      " Best 5 on Test Sest \n",
      " ---------------------'\n",
      "Rank -  Deep Model - Predictor - Val Set - Test Set'\n",
      "0 - random_82 - deep - 134.30467871071176 - 0.7199893993454223 - 133.67391071679515 - 0.722209097820552'\n",
      "1 - random_24 - deep - 134.9352893915091 - 0.7186746448841157 - 130.74223126740614 - 0.7283014899319201'\n",
      "2 - random_10 - deep - 135.40582546692042 - 0.7176936285087342 - 142.43745544334988 - 0.7039973691232655'\n",
      "3 - random_4 - deep - 138.6592477281742 - 0.7109105980863994 - 146.59803687853068 - 0.6953511668518396'\n",
      "4 - random_73 - deep - 139.51102111677213 - 0.7091347435111719 - 138.22997518795154 - 0.7127410329375573'\n"
     ]
    }
   ],
   "source": [
    "scores_df_final = pd.DataFrame(all_scores_final)\n",
    "scores_df_final.to_csv(log_dir/f\"test_scores.csv\",index=False)\n",
    "\n",
    "summary_logger.info(\"-----------------------\\n Best 5 on Test Sest \\n ---------------------\")\n",
    "summary_logger.info(f\"Rank -  Deep Model - Predictor - Val Set - Test Set\")\n",
    "for i, (j,k,v,x) in enumerate(best_5):\n",
    "\n",
    "    row = scores_df_final.loc[(scores_df_final['model_num']==j) & (scores_df_final['predictor'] == k)].iloc[0]\n",
    "    #print(row)\n",
    "    s = f\"{i} - {j} - {k} - {v} - {x} - {row['MSE']} - {row['R2']}\"\n",
    "    summary_logger.info(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote Summary Graph'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#take 1 is a scatter plot - lets, for each dataset\n",
    "#graph our deep models by rank - plot - then overlay our knn moels\n",
    "#plot points\n",
    "\n",
    "deep_set = scores_df[scores_df[\"predictor\"]==\"deep\"].sort_values(\"R2\")\n",
    "deep_set[\"order\"] = [i for i in range(0,100)]\n",
    "deep_ordering = {row[\"model_num\"]:row[\"order\"] for index, row in deep_set.iterrows()}\n",
    "\n",
    "def order_models(x):\n",
    "    x = [deep_ordering[i] for i in x]\n",
    "    return x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df[scores_df[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    if knn_model == \"deep\":\n",
    "        s=10\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot.png\", bbox_inches='tight')\n",
    "logging.getLogger().info(\"Wrote Summary Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (30,) (100,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22108\\3535465147.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"R2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mscores_df_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscores_df_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"predictor\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'deep'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"R2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model_num\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mknn_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (30,) (100,) "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graph our deep models by rank on final set - plot - then overlay our knn moels\n",
    "\n",
    "deep_set = scores_df_final[scores_df_final[\"predictor\"]==\"deep\"].sort_values(\"R2\")\n",
    "deep_set[\"order\"] = [i for i in range(0,100)]\n",
    "deep_ordering = {row[\"model_num\"]:row[\"order\"] for index, row in deep_set.iterrows()}\n",
    "\n",
    "def order_models(x):\n",
    "    x = [deep_ordering[i] for i in x]\n",
    "    return x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df_final[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df_final[scores_df_final[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    if knn_model == \"deep\":\n",
    "        s=10\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot_final.png\", bbox_inches='tight')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "set_deep = False\n",
    "knn_models = scores_df_final[\"predictor\"].unique()\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df_final[scores_df_final[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    if knn_model == \"deep\":\n",
    "        pass\n",
    "    else:\n",
    "        y1 = subset[\"R2\"].to_numpy() - scores_df_final[scores_df_final[\"predictor\"]=='deep'][\"R2\"].to_numpy()\n",
    "        ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=y1, s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"improvement_plot_final.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df_base = scores_df[scores_df[\"predictor\"]=='deep']\n",
    "scores_df_uu = scores_df[scores_df[\"predictor\"].str.contains('_uu')]   #val_eq_list(scores_df[\"predictor\"],'dist')] #np.logical_or(scores_df[\"predictor\"]==\"deep\",'dist' in scores_df[\"predictor\"])]\n",
    "scores_df_ut = scores_df[scores_df[\"predictor\"].str.contains('_ut')] \n",
    "scores_df_tu = scores_df[scores_df[\"predictor\"].str.contains('_tu')]   #val_eq_list(scores_df[\"predictor\"],'dist')] #np.logical_or(scores_df[\"predictor\"]==\"deep\",'dist' in scores_df[\"predictor\"])]\n",
    "scores_df_tta = scores_df[scores_df[\"predictor\"].str.contains('_tta')] \n",
    "scores_df_ttm = scores_df[scores_df[\"predictor\"].str.contains('_ttm')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "knn_models = scores_df_tta[\"predictor\"].unique()\n",
    "ax.scatter(x=order_models(scores_df_base[\"model_num\"].tolist()), y=scores_df_base[\"R2\"], s=10, label='deep')\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df_tta[scores_df_tta[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot_tta.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "knn_models = scores_df_ttm[\"predictor\"].unique()\n",
    "ax.scatter(x=order_models(scores_df_base[\"model_num\"].tolist()), y=scores_df_base[\"R2\"], s=10, label='deep')\n",
    "for knn_model in knn_models:\n",
    "    subset = scores_df_ttm[scores_df_ttm[\"predictor\"]==knn_model]\n",
    "    s=3\n",
    "    ax.scatter(x=order_models(subset[\"model_num\"].tolist()), y=subset[\"R2\"], s=s, label=knn_model)\n",
    "\n",
    "#ax.set_ylim(0,scores_db[\"deep_mean\"].max())\n",
    "ax.set_ylim(0,1)\n",
    "# plot residuals\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_xlabel(\"Deep Model Rank\")\n",
    "#ax.set_ylim(0,200)\n",
    "#ax.set_yscale(\"symlog\")\n",
    "ax.set_title(\"Summary of LWR improvements over Deep Models\")\n",
    "plt.savefig(log_dir/f\"summary_plot_ttm.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (lazydeep)",
   "language": "python",
   "name": "pycharm-12fcba0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
