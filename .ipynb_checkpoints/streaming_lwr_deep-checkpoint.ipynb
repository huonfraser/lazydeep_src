{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import logging\n",
    "import torch\n",
    "# set seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils as ut\n",
    "import experiment as ex\n",
    "from evaluation import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import random\n",
    "#define fixed_hyperparams and create a config gen\n",
    "from configurations import RandomConfigGen, Configuration\n",
    "from torch import nn\n",
    "from deep_net import RandomNet\n",
    "from experiment import run_experiment\n",
    "import regex as re\n",
    "from pathlib import *\n",
    "from sk_models import PLSRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sk_models import PLSRegression, StandardScaler,LocalWeightedRegression,PLSLWR,LinearRidge\n",
    "from river_models import *\n",
    "\n",
    "from river import stream,linear_model,preprocessing, ensemble, metrics, optim\n",
    "from river.neighbors import KNNRegressor \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from river.utils import dict2numpy, numpy2dict\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "random_state = np.random.RandomState(seed)\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"GPU detected is {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup input and output directories\n",
    "\n",
    "#setup input and outpu t formats, load data\n",
    "\n",
    "#we need to set parametesr\n",
    "file_name = \"PLN7.csv\" #\"mango_684_990.csv\" #\"mango_729_975.csv\" #fitlered=513-1050\n",
    "id_cols =[\"db_id\",\"sample_id\"] #\n",
    "output_cols = None\n",
    "data_path = Path('D:/workspace/lazydeep/data/soil_data/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/5.03_v2\") #1.01/\")\n",
    "if not log_path.exists():\n",
    "    log_path.mkdir()\n",
    "\n",
    "data_file = data_path / file_name\n",
    "log_dir = log_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "print(f\"Output directory is {log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data=data.sample(frac=1,random_state=random_state)\n",
    "\n",
    "pre_ind =[i for i in range(0,10000)]\n",
    "pretrain_ind,pretest_ind = train_test_split(pre_ind,train_size=5/6,random_state=random_state,shuffle=False)\n",
    "stream_ind = [i for i in range(10000,110000)]\n",
    "\n",
    "pretrain_data =  ut.TabularDataset(data.iloc[pretrain_ind,:],id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "pretest_data = ut.TabularDataset(data.iloc[pretest_ind,:],id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "stream_data = ut.TabularDataset(data.iloc[stream_ind,:],id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "\n",
    "nrow, ncol = data.shape\n",
    "nrow_train = len(pretrain_data)\n",
    "nrow_test = len(pretest_data)\n",
    "nrow_stream = len(stream_data)\n",
    "\n",
    "print(f\"train: {nrow_train}, test: {nrow_test}, stream: {nrow_stream}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_dir = Path(\"D:/workspace/lazydeep/experiments/1.01/PLN7\")\n",
    "pls_deep_model = torch.load(deep_model_dir/\"models\"/\"random_82\"/\"_model\")\n",
    "pls_deep_model.load_state(deep_model_dir/\"models\"/\"random_82\"/\"_final\")\n",
    "pls_scaler = PLSRegression(n_components=34).from_state(PLSRegression(n_components=34).load_state(deep_model_dir/'preprocessing'/f\"_final\"))                       \n",
    "pls_deep_lwr = StreamLocalWeightedRegression(n_neighbors=1000,floor=True)\n",
    "\n",
    "\n",
    "#stream_pls_deep = StreamDeep(pls_scaler,pls_deep_model)\n",
    "#stream_pls_deep_lwr = StreamDeepLWR(pls_scaler,pls_deep_model,pls_deep_lwr)\n",
    "stream_pls_deep = (StreamWrapper(pls_scaler)|StreamDeep(pls_deep_model))\n",
    "stream_pls_deep_lwr = (StreamWrapper(pls_scaler)|StreamDeep(pls_deep_model)|preprocessing.StandardScaler()|StreamLocalWeightedRegression(n_neighbors=1000,floor=True))\n",
    "                          \n",
    "deep_model_dir = Path(\"D:/workspace/lazydeep/experiments/2.00/PLN7\")\n",
    "deep_model = torch.load(deep_model_dir/\"models\"/\"random_29\"/\"_model\")\n",
    "deep_model.load_state(deep_model_dir/\"models\"/\"random_29\"/\"_final\")\n",
    "deep_scaler = StandardScaler().from_state(StandardScaler().load_state(deep_model_dir/'preprocessing'/f\"_final\"))                \n",
    "                      \n",
    "deep_lwr = StreamLocalWeightedRegression(n_neighbors=1000,floor=True)\n",
    "\n",
    "#stream_deep = StreamDeep(deep_scaler,deep_model)\n",
    "#stream_deep_lwr = StreamDeepLWR(deep_scaler,deep_model,deep_lwr)\n",
    "stream_deep = (StreamWrapper(deep_scaler)|StreamDeep(deep_model))\n",
    "stream_deep_lwr = (StreamWrapper(deep_scaler)|StreamDeep(deep_model)|preprocessing.StandardScaler()|StreamLocalWeightedRegression(n_neighbors=1000,floor=True))\n",
    "\n",
    "river_models = {'deep':stream_deep,\n",
    "               'deep_lwr':stream_pls_deep_lwr,\n",
    "               'pls_deep':stream_pls_deep,\n",
    "               'pls_deep_lwr':stream_deep_lwr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup our metrics and stores of results\n",
    "full_set = river_models.keys()\n",
    "metrics = {'R2':{name:metrics.R2() for name in full_set},\n",
    "           'R2_rolling':{name:metrics.Rolling(metrics.R2(), window_size=1000) for name in full_set},\n",
    "           'MSE':{name:metrics.MSE() for name in river_models.keys()},\n",
    "           'MSE_rolling':{name:metrics.Rolling(metrics.MSE(), window_size=1000) for name in full_set}\n",
    "          }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so sofar we have establish our metrics and scores are correct\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take our pretrained models, now evaluate them on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_,_,river_models,metrics = prequential_evaluate(pretrain_data,river_models,metrics,pretrain = len(pretrain_data),num_its=len(pretrain_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test,scores_test,metrics = score_evaluate(pretest_data,river_models,metrics,num_its=len(pretest_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_stream, scores_stream,river_models,metrics = prequential_evaluate(stream_data,river_models,metrics,pretrain=0,num_its=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_dict(dict1,dict2):\n",
    "\n",
    "    dict12 = {k:dict1[k]+dict2[k] for k in dict1.keys()}   \n",
    "    return dict12\n",
    "\n",
    "def zip_nested_dict(dict1,dict2):\n",
    "    dict12 = {}\n",
    "    \n",
    "    for k in dict1.keys():\n",
    "        dict12[k] = {name:dict1[k][name]+dict2[k][name] for name in dict1[k].keys()}\n",
    "    return dict12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = zip_dict(preds_test,preds_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = zip_nested_dict(scores_test,scores_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(preds)\n",
    "preds_df.to_csv(log_dir/\"preds_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#findings\n",
    "#1) preprocessing works, random lr things for lr don't\n",
    "#) standardisation asks as regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_title(\"Streaming performance \")\n",
    "\n",
    "scores_df = pd.DataFrame(scores['R2'])\n",
    "scores_df.to_csv(log_dir/\"r2_scores.csv\")\n",
    "for (columnName, columnData) in scores_df.iteritems():\n",
    "\n",
    "    ax.plot(columnData.index,columnData,'-',label = f\"{columnName}\")\n",
    "ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_v2.png\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_title(\"Streaming performance (rolling average) \")\n",
    "    \n",
    "scores_df = pd.DataFrame(scores['R2_rolling'])\n",
    "scores_df.to_csv(log_dir/\"r2_scores_rolling.csv\")\n",
    "for (columnName, columnData) in scores_df.iteritems():\n",
    "    columnData\n",
    "    ax.plot(columnData.index,columnData,label = f\"{columnName}\")\n",
    "ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling_v2.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.set_title(\"Streaming performance \")\n",
    "\n",
    "scores_df = pd.DataFrame(scores['MSE'])\n",
    "scores_df.to_csv(log_dir/\"MSE.csv\")\n",
    "for (columnName, columnData) in scores_df.iteritems():\n",
    "    ax.plot(columnData.index,columnData,'-',label = f\"{columnName}\")\n",
    "ax.plot([len(pretest_data),len(pretest_data)],[0,1000],c=\"black\",ls='--')\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"mse_plot.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1000)\n",
    "plt.savefig(log_dir / f\"mse_plot_v2.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.set_title(\"Streaming performance (rolling average) \")\n",
    "\n",
    "scores_df = pd.DataFrame(scores['MSE_rolling'])\n",
    "scores_df.to_csv(log_dir/\"MSE_rolling.csv\")\n",
    "for (columnName, columnData) in scores_df.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label = f\"{columnName}\")\n",
    "ax.plot([len(pretest_data),len(pretest_data)],[0,1000],c=\"black\",ls='--')\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"mse_plot_rolling.png\",bbox_inches='tight')\n",
    "ax.set_ylim(-1,200)\n",
    "plt.savefig(log_dir / f\"mse_plot_rolling_v2.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel('y_pred')\n",
    "ax.set_xlabel('y_true')\n",
    "\n",
    "for (columnName, columnData) in preds_df.iteritems():\n",
    "        if not columnName == 'y':\n",
    "            ax.scatter(preds_df['y'],columnData,label = f\"{columnName}\",s=0.5)\n",
    "            \n",
    "            corr_coef = scipy.stats.pearsonr(columnData, preds_df['y'])\n",
    "            #slope, intercept, r, p, stderr = scipy.stats.linregress(columnData, preds_df['y'])\n",
    "            loss = mean_squared_error(preds_df['y'], columnData)\n",
    "            mae = mean_absolute_error(preds_df['y'], columnData)    \n",
    "            print(f\"{columnName}, R^2 = {corr_coef[0]}, MSE = {loss}\")\n",
    "            \n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylim(-500,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = {i:deepcopy(deep_model) for i in range(0,10)}\n",
    "configs = {i:1e-i for i in range(0,10)\n",
    "opts = {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
