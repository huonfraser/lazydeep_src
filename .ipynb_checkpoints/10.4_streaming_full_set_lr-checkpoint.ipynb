{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detected is GeForce GTX 970\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import logging\n",
    "import torch\n",
    "# set seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils as ut\n",
    "import experiment as ex\n",
    "from evaluation import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from river.neighbors import KNNRegressor\n",
    "import random\n",
    "#define fixed_hyperparams and create a config gen\n",
    "from configurations import RandomConfigGen, Configuration\n",
    "from torch import nn\n",
    "from deep_net import RandomNet\n",
    "from experiment import run_experiment\n",
    "import regex as re\n",
    "from pathlib import *\n",
    "#from sk_models import PLSRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sk_models import PLSRegression, StandardScaler,LocalWeightedRegression,PLSLWR,LinearRidge\n",
    "from river_models import *\n",
    "\n",
    "from river import stream,linear_model,preprocessing, ensemble, metrics, optim\n",
    "from river.neighbors import KNNRegressor \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from river.utils import dict2numpy, numpy2dict\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed + 1)\n",
    "np.random.seed(seed + 2)\n",
    "random_state = np.random.RandomState(seed)\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"GPU detected is {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory is D:\\workspace\\lazydeep\\experiments\\10.4\\PLN7\n"
     ]
    }
   ],
   "source": [
    "#setup input and output directories\n",
    "\n",
    "#setup input and outpu t formats, load data\n",
    "\n",
    "#we need to set parametesr\n",
    "file_name = \"PLN7.csv\" #\"mango_684_990.csv\" #\"mango_729_975.csv\" #fitlered=513-1050\n",
    "id_cols =[\"db_id\",\"sample_id\"] #\n",
    "output_cols = None\n",
    "data_path = Path('D:/workspace/lazydeep/data/soil_data/')\n",
    "log_path = Path(\"D:/workspace/lazydeep/experiments/10.4\") #1.01/\")\n",
    "if not log_path.exists():\n",
    "    log_path.mkdir()\n",
    "\n",
    "data_file = data_path / file_name\n",
    "log_dir = log_path / re.sub(r'\\.(?=csv$)[^.]+$', '',file_name)\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir()\n",
    "print(f\"Output directory is {log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 8333, test: 1667, stream: 100000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data=data.sample(frac=1,random_state=random_state)\n",
    "\n",
    "pre_ind =[i for i in range(0,10000)]\n",
    "pretrain_ind,pretest_ind = train_test_split(pre_ind,train_size=5/6,random_state=random_state,shuffle=False)\n",
    "stream_ind = [i for i in range(10000,110000)]\n",
    "\n",
    "pretrain_data =  ut.TabularDataset(data.iloc[pretrain_ind,:],id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "pretest_data = ut.TabularDataset(data.iloc[pretest_ind,:],id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "stream_data = ut.TabularDataset(data.iloc[stream_ind,:],id_cols = id_cols, cat_cols=None, output_cols=output_cols, ignore_cols= None)\n",
    "\n",
    "nrow, ncol = data.shape\n",
    "nrow_train = len(pretrain_data)\n",
    "nrow_test = len(pretest_data)\n",
    "nrow_stream = len(stream_data)\n",
    "\n",
    "print(f\"train: {nrow_train}, test: {nrow_test}, stream: {nrow_stream}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep, deep_lwr, ensemble_deep, deep_ensemble_lwr, ensemble_deep\n",
    "\n",
    "pls_nums = [\"random_82\",\"random_24\",\"random_10\",\"random_4\",\"random_73\"]\n",
    "deep_nums = [\"random_29\",\"random_60\",\"random_63\",\"random_41\",\"random_15\"]  #[13,57,77,60,76]\n",
    "\n",
    "pls_model_dir = Path(\"D:/workspace/lazydeep/experiments/1.01/PLN7\")\n",
    "deep_model_dir = Path(\"D:/workspace/lazydeep/experiments/2.00/PLN7\")\n",
    "\n",
    "pls_scaler = PLSRegression(n_components=34).from_state(PLSRegression(n_components=34).load_state(pls_model_dir/'preprocessing'/f\"_final\"))      \n",
    "deep_scaler = StandardScaler().from_state(StandardScaler().load_state(deep_model_dir/'preprocessing'/f\"_final\"))      \n",
    "\n",
    "def build_model(dir_,id_,scaler_):\n",
    "    deep_ = torch.load(dir_/\"models\"/id_/\"_model\")\n",
    "    deep_.load_state(dir_/\"models\"/id_/\"_final\")\n",
    "    \n",
    "    return (StreamWrapper(scaler_)|StreamDeep(deep_))\n",
    "\n",
    "def build_model_lwr(dir_,id_,scaler_,k_=1000):\n",
    "    model = build_model(dir_,id_,scaler_)\n",
    "    \n",
    "    return (model|StreamLocalWeightedRegression(n_neighbors=k_,floor=True))\n",
    "\n",
    "def build_model_knn(dir_,id_,scaler_,k_=5):\n",
    "    model = build_model(dir_,id_,scaler_)\n",
    "    \n",
    "    return (model|KNNRegressor(n_neighbors=k_))\n",
    "\n",
    "def build_model_lr(dir_,id_,scaler_,k_=5):\n",
    "    model = build_model(dir_,id_,scaler_)\n",
    "    \n",
    "    return (model|SlidingWindowLR())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_neighbors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16076\\197263179.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#build deep lwr models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpls_nums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mriver_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'pls-deep{i}-lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpls_model_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpls_scaler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep_nums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mriver_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'std-deep{i}-lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep_model_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdeep_scaler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16076\\196304145.py\u001b[0m in \u001b[0;36mbuild_model_lr\u001b[1;34m(dir_, id_, scaler_, k_)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mid_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscaler_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m|\u001b[0m\u001b[0mSlidingWindowLR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_neighbors'"
     ]
    }
   ],
   "source": [
    "river_models = {}\n",
    "\n",
    "#build deep models\n",
    "for i,k in enumerate(pls_nums):\n",
    "    river_models[f'pls-deep{i}'] = build_model(pls_model_dir,k,pls_scaler)\n",
    "for i,k in enumerate(deep_nums):\n",
    "    river_models[f'std-deep{i}'] = build_model(deep_model_dir,k,deep_scaler)\n",
    "    \n",
    "#build deep lwr models\n",
    "for i,k in enumerate(pls_nums):\n",
    "    river_models[f'pls-deep{i}-lr'] = build_model_lr(pls_model_dir,k,pls_scaler)\n",
    "for i,k in enumerate(deep_nums):\n",
    "    river_models[f'std-deep{i}-lr'] = build_model_lr(deep_model_dir,k,deep_scaler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#setup our metrics and stores of results\n",
    "full_set = river_models.keys()\n",
    "metrics = {'R2':{name:metrics.R2() for name in full_set},\n",
    "           'R2_rolling':{name:RollingR2(window_size=1000) for name in full_set},\n",
    "           'MSE':{name:metrics.MSE() for name in river_models.keys()},\n",
    "           'MSE_rolling':{name:RollingMSE(window_size=1000) for name in full_set}\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set = river_models.keys()\n",
    "metrics = {'R2':{name:metrics.R2() for name in full_set},\n",
    "           'R2_rolling': {name:RollingR2(window_size=1000) for name in full_set},\n",
    "           'MSE':{name:metrics.MSE() for name in river_models.keys()},\n",
    "           'MSE_rolling':{name:RollingMSE(window_size=1000) for name in full_set}\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take our pretrained models, now evaluate them on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_,_,river_models,metrics = prequential_evaluate(pretrain_data,river_models,metrics,pretrain = len(pretrain_data),num_its=len(pretrain_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test,scores_test,metrics = score_evaluate(pretest_data,river_models,metrics,num_its=len(pretest_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_stream, scores_stream,river_models,metrics = prequential_evaluate(stream_data,river_models,metrics,pretrain=0,num_its=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_dict(dict1,dict2):\n",
    " \n",
    "    dict12 = {k:dict1[k]+dict2[k] for k in dict1.keys()}   \n",
    "    return dict12\n",
    "\n",
    "def zip_nested_dict(dict1,dict2):\n",
    "    dict12 = {}\n",
    "    \n",
    "    for k in dict1.keys():\n",
    "        dict12[k] = {name:dict1[k][name]+dict2[k][name] for name in dict1[k].keys()}\n",
    "    return dict12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = zip_dict(preds_test,preds_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = zip_nested_dict(scores_test,scores_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(preds)\n",
    "\n",
    "for (columnName, columnData) in preds_df.iteritems():\n",
    "    preds_df[f'diff_{columnName}'] = columnData-preds_df['y']\n",
    "\n",
    "preds_df.to_csv(log_dir/\"preds_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#findings\n",
    "#1) preprocessing works, random lr things for lr don't\n",
    "#) standardisation asks as regularisation\n",
    "\n",
    "scores_df_rolling = pd.DataFrame(scores['R2_rolling'])\n",
    "scores_df_total = pd.DataFrame(scores['R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.set_xlabel(\"Stream Index\")\n",
    "    ax.set_ylabel(\"R^2 Score\")\n",
    "    ax.set_title(\"Streaming performance \")\n",
    "\n",
    "    for (columnName, columnData) in scores_df.iteritems():\n",
    "\n",
    "        ax.plot(columnData.index,columnData,'-',label = f\"{columnName}\")\n",
    "    ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "    ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "    plt.savefig(log_dir / f\"r2_plot.png\",bbox_inches='tight')\n",
    "    ax.set_ylim(0,1)\n",
    "    plt.savefig(log_dir / f\"r2_plot_v2.png\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R^2 Score\")\n",
    "ax.set_title(\"Streaming performance (rolling average) \")\n",
    "    \n",
    "scores_df = pd.DataFrame(scores['R2_rolling'])\n",
    "scores_df.to_csv(log_dir/\"r2_scores_rolling.csv\")\n",
    "for (columnName, columnData) in scores_df.iteritems():\n",
    "    columnData\n",
    "    ax.plot(columnData.index,columnData,label = f\"{columnName}\")\n",
    "ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling_v2.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.set_title(\"Streaming performance \")\n",
    "\n",
    "scores_df = pd.DataFrame(scores['MSE'])\n",
    "scores_df.to_csv(log_dir/\"MSE.csv\")\n",
    "for (columnName, columnData) in scores_df.iteritems():\n",
    "    ax.plot(columnData.index,columnData,'-',label = f\"{columnName}\")\n",
    "ax.plot([len(pretest_data),len(pretest_data)],[0,1000],c=\"black\",ls='--')\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"mse_plot.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1000)\n",
    "plt.savefig(log_dir / f\"mse_plot_v2.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.set_title(\"Streaming performance (rolling average) \")\n",
    "\n",
    "scores_df = pd.DataFrame(scores['MSE_rolling'])\n",
    "scores_df.to_csv(log_dir/\"MSE_rolling.csv\")\n",
    "for (columnName, columnData) in scores_df.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label = f\"{columnName}\")\n",
    "ax.plot([len(pretest_data),len(pretest_data)],[0,1000],c=\"black\",ls='--')\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"mse_plot_rolling.png\",bbox_inches='tight')\n",
    "ax.set_ylim(-1,200)\n",
    "plt.savefig(log_dir / f\"mse_plot_rolling_v2.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylabel('y_pred')\n",
    "ax.set_xlabel('y_true')\n",
    "\n",
    "for (columnName, columnData) in preds_df.iteritems():\n",
    "        if not columnName == 'y':\n",
    "            ax.scatter(preds_df['y'],columnData,label = f\"{columnName}\",s=1)\n",
    "            \n",
    "            corr_coef = scipy.stats.pearsonr(columnData, preds_df['y'])\n",
    "            #slope, intercept, r, p, stderr = scipy.stats.linregress(columnData, preds_df['y'])\n",
    "            loss = mean_squared_error(preds_df['y'], columnData)\n",
    "            mae = mean_absolute_error(preds_df['y'], columnData)    \n",
    "            print(f\"{columnName}, R^2 = {corr_coef[0]}, MSE = {loss}\")\n",
    "            \n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "ax.set_ylim(0,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_subset_by_str(dataset,s,reverse=False):\n",
    "    col_names = dataset.columns.tolist()\n",
    "    if reverse:\n",
    "        encoding = [i for i in col_names if not (s in i)]\n",
    "    else:\n",
    "        encoding = [i for i in col_names if (s in i)]\n",
    "    return dataset[encoding]\n",
    "\n",
    "def take_subset_by_re(dataset,s,reverse=False):\n",
    "    col_names = dataset.columns.tolist()\n",
    "    if reverse:\n",
    "        encoding = [i for i in col_names if not s.match(i)]\n",
    "    else:\n",
    "        encoding = [i for i in col_names if s.match(i)]\n",
    "    return dataset[encoding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    subset2 = take_subset_by_str(scores_df ,'pls')\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.set_xlabel(\"Stream Index\")\n",
    "    ax.set_ylabel(\"R2\")\n",
    "    ax.set_title(\"Streaming performance (rolling average) \")\n",
    "\n",
    "\n",
    "    for (columnName, columnData) in subset2.iteritems():\n",
    "        ax.plot(columnData.index,columnData,label = f\"{columnName.replace('pls_deep_',' ').replace('pls_deep','base_model')}\",linewidth=1.5)\n",
    "    ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "    ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "    plt.savefig(log_dir / f\"r2_plot_pls.png\",bbox_inches='tight')\n",
    "    ax.set_ylim(0,1)\n",
    "    plt.savefig(log_dir / f\"r2_plot_v2_pls.png\",bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    subset2 = take_subset_by_str(scores_df ,'pls',reverse=True)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.set_xlabel(\"Stream Index\")\n",
    "    ax.set_ylabel(\"R2\")\n",
    "    ax.set_title(\"Streaming performance (rolling average) \")\n",
    "\n",
    "\n",
    "    for (columnName, columnData) in subset2.iteritems():\n",
    "        ax.plot(columnData.index,columnData,label =  f\"{columnName.replace('deep_',' ').replace('deep','base_model')}\")\n",
    "    ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "    ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "    plt.savefig(log_dir / f\"r2_plot_deep.png\",bbox_inches='tight')\n",
    "    ax.set_ylim(0,1)\n",
    "    plt.savefig(log_dir / f\"r2_plot_v2_deep.png\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "if False:\n",
    "    pp_opts = ['deep_lwr']\n",
    "    ws_opts = ['_s1','_s2','_s3','_s4']\n",
    "    for pp_opt in pp_opts:\n",
    "        subset1 = take_subset_by_str(scores_df,pp_opt)\n",
    "\n",
    "        for ws_opt in ws_opts:\n",
    "            subset2 = take_subset_by_str(subset1,ws_opt)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "            ax.set_xlabel(\"Stream Index\")\n",
    "            ax.set_ylabel(\"R2\")\n",
    "            ax.set_title(\"Streaming performance (rolling average) \")\n",
    "\n",
    "\n",
    "            for (columnName, columnData) in subset2.iteritems():\n",
    "                ax.plot(columnData.index,columnData,label = f\"{columnName}\")\n",
    "            ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "            ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "            #plt.savefig(log_dir / f\"r2_plot_{pp_opt}{ws_opt}.png\",bbox_inches='tight')\n",
    "            ax.set_ylim(-1,1)\n",
    "            #plt.savefig(log_dir / f\"r2_plot_v2_{pp_opt}{ws_opt}.png\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep subset\n",
    "p = re.compile('(pls-deep\\d)(?!-lwr)')\n",
    "subset = take_subset_by_re(scores_df_total ,p,reverse=False)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R2\")\n",
    "ax.set_title(\"Streaming performance \")\n",
    "\n",
    "\n",
    "for (columnName, columnData) in subset.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label =  f\"{columnName}\")\n",
    "ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_pls-deep.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_v2_pls-deep.png\",bbox_inches='tight')\n",
    "\n",
    "subset = take_subset_by_re(scores_df_rolling ,p,reverse=False)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R2\")\n",
    "ax.set_title(\"Streaming performance (rolling average) \")\n",
    "\n",
    "\n",
    "for (columnName, columnData) in subset.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label =  f\"{columnName}\")\n",
    "#ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling_pls-deep.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling_v2_pls-deep.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile('(std-deep\\d)(?!-lwr)')\n",
    "subset = take_subset_by_re(scores_df_total ,p,reverse=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R2\")\n",
    "ax.set_title(\"Streaming performance\")\n",
    "\n",
    "\n",
    "for (columnName, columnData) in subset.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label =  f\"{columnName}\")\n",
    "#ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_std-deep.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_v2_std-deep.png\",bbox_inches='tight')\n",
    "\n",
    "subset = take_subset_by_re(scores_df_rolling ,p,reverse=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R2\")\n",
    "ax.set_title(\"Streaming performance (rolling average) \")\n",
    "\n",
    "\n",
    "for (columnName, columnData) in subset.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label =  f\"{columnName}\")\n",
    "#ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling_std-deep.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling_v2_std-deep.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pls-deep-lwr subset\n",
    "\n",
    "p = re.compile('(pls-deep\\d-lr)')\n",
    "subset = take_subset_by_re(scores_df_total ,p,reverse=False)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R2\")\n",
    "ax.set_title(\"Streaming performance \")\n",
    "\n",
    "\n",
    "for (columnName, columnData) in subset.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label =  f\"{columnName}\")\n",
    "#ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_pls-deep-lwr.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_v2_pls-deep-lwr.png\",bbox_inches='tight')\n",
    "\n",
    "subset = take_subset_by_re(scores_df_rolling ,p,reverse=False)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R2\")\n",
    "ax.set_title(\"Streaming performance (rolling average) \")\n",
    "\n",
    "\n",
    "for (columnName, columnData) in subset.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label =  f\"{columnName}\")\n",
    "#ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling_pls-deep-lwr.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling_v2_pls-deep-lwr.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std-deep-lwr subset\n",
    "\n",
    "p = re.compile('(std-deep\\d-lr)')\n",
    "subset = take_subset_by_re(scores_df_total ,p,reverse=False)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R2\")\n",
    "ax.set_title(\"Streaming performance \")\n",
    "\n",
    "\n",
    "for (columnName, columnData) in subset.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label =  f\"{columnName}\")\n",
    "#ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_std-deep-lwr.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_v2_std-deep-lwr.png\",bbox_inches='tight')\n",
    "\n",
    "\n",
    "subset = take_subset_by_re(scores_df_rolling ,p,reverse=False)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"Stream Index\")\n",
    "ax.set_ylabel(\"R2\")\n",
    "ax.set_title(\"Streaming performance (rolling average) \")\n",
    "\n",
    "for (columnName, columnData) in subset.iteritems():\n",
    "    ax.plot(columnData.index,columnData,label =  f\"{columnName}\")\n",
    "#ax.plot([len(pretest_data),len(pretest_data)],[-1,1],c=\"black\",ls='--')\n",
    "\n",
    "ax.legend(loc='upper right',bbox_to_anchor=(1.4, 1))\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling_std-deep-lwr.png\",bbox_inches='tight')\n",
    "ax.set_ylim(0,1)\n",
    "plt.savefig(log_dir / f\"r2_plot_rolling_v2_std-deep-lwr.png\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = 87217-len(pretest_data)\n",
    "x1,y1=stream_data[id1]\n",
    "river_models[f'std-deep0'].predict_one(numpy2dict(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
